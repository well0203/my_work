{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `3`\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "/usr/local/anaconda3-2023.03/envs/python311/bin/python: can't open file '/vol/cs-hu/riabchuv/hu-home/my_work/run_main.py': [Errno 2] No such file or directory\n",
      "/usr/local/anaconda3-2023.03/envs/python311/bin/python: can't open file '/vol/cs-hu/riabchuv/hu-home/my_work/run_main.py': [Errno 2] No such file or directory\n",
      "/usr/local/anaconda3-2023.03/envs/python311/bin/python: can't open file '/vol/cs-hu/riabchuv/hu-home/my_work/run_main.py': [Errno 2] No such file or directory\n",
      "^C\n",
      "[2024-04-29 19:58:47,148] torch.distributed.elastic.agent.server.api: [WARNING] Received 2 death signal, shutting down workers\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/.local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1048, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 702, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 803, in run\n",
      "    elastic_launch(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 135, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 259, in launch_agent\n",
      "    result = agent.run()\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py\", line 123, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py\", line 727, in run\n",
      "    result = self._invoke_run(role)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py\", line 868, in _invoke_run\n",
      "    time.sleep(monitor_interval)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
      "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
      "torch.distributed.elastic.multiprocessing.api.SignalException: Process 19687 got signal: 2\n"
     ]
    }
   ],
   "source": [
    "train_epochs=10\n",
    "learning_rate=0.01\n",
    "llama_layers=6\n",
    "\n",
    "#master_port=00097\n",
    "num_process=1\n",
    "batch_size=2\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --main_process_port \"00097\"\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-ETTh1'\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --dynamo_backend \"no\" run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path ETTh1.csv \\\n",
    "  --model_id ETTh1_512_96 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data ETTh1 \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --num_processes $num_process \\\n",
    "  --model_comment $comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.4398238\n",
      "\tspeed: 0.0615s/iter; left time: 157.3993s\n",
      "\titers: 200, epoch: 1 | loss: 0.4088117\n",
      "\tspeed: 0.0421s/iter; left time: 103.4920s\n",
      "Epoch: 1 running time: 0.20338455438613892 min.\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.4484731 Vali Loss: 0.7442934 Test Loss: 0.5967928\n",
      "Validation loss decreased (inf --> 0.744293).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3025567\n",
      "\tspeed: 0.1056s/iter; left time: 242.2739s\n",
      "\titers: 200, epoch: 2 | loss: 0.3389409\n",
      "\tspeed: 0.0412s/iter; left time: 90.4293s\n",
      "Epoch: 2 running time: 0.1889899214108785 min.\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.3259072 Vali Loss: 0.7888978 Test Loss: 0.8300452\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3365152\n",
      "\tspeed: 0.1008s/iter; left time: 204.5376s\n",
      "\titers: 200, epoch: 3 | loss: 0.3098605\n",
      "\tspeed: 0.0443s/iter; left time: 85.5222s\n",
      "Epoch: 3 running time: 0.1919772744178772 min.\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.3231263 Vali Loss: 0.7388420 Test Loss: 0.6724409\n",
      "Validation loss decreased (0.744293 --> 0.738842).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2971177\n",
      "\tspeed: 0.1036s/iter; left time: 182.5999s\n",
      "\titers: 200, epoch: 4 | loss: 0.3051086\n",
      "\tspeed: 0.0421s/iter; left time: 70.0455s\n",
      "Epoch: 4 running time: 0.18961451450983682 min.\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2939822 Vali Loss: 0.7674699 Test Loss: 0.6608061\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2550912\n",
      "\tspeed: 0.1022s/iter; left time: 152.9219s\n",
      "\titers: 200, epoch: 5 | loss: 0.2714912\n",
      "\tspeed: 0.0416s/iter; left time: 58.1149s\n",
      "Epoch: 5 running time: 0.1904783805211385 min.\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.2918414 Vali Loss: 0.7861078 Test Loss: 0.6900674\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2783736\n",
      "\tspeed: 0.1006s/iter; left time: 123.8722s\n",
      "\titers: 200, epoch: 6 | loss: 0.2760369\n",
      "\tspeed: 0.0423s/iter; left time: 47.7909s\n",
      "Epoch: 6 running time: 0.19101029237111408 min.\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.2922943 Vali Loss: 0.7818955 Test Loss: 0.6706946\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.6715533137321472, mae:0.6105679869651794\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.4033915\n",
      "\tspeed: 0.0448s/iter; left time: 114.7466s\n",
      "\titers: 200, epoch: 1 | loss: 0.3719254\n",
      "\tspeed: 0.0431s/iter; left time: 106.0270s\n",
      "Epoch: 1 running time: 0.19453486601511638 min.\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.4404117 Vali Loss: 0.7318097 Test Loss: 0.5701032\n",
      "Validation loss decreased (inf --> 0.731810).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3270476\n",
      "\tspeed: 0.1093s/iter; left time: 250.8669s\n",
      "\titers: 200, epoch: 2 | loss: 0.3579375\n",
      "\tspeed: 0.0426s/iter; left time: 93.4300s\n",
      "Epoch: 2 running time: 0.1949563185373942 min.\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.3267081 Vali Loss: 0.7091760 Test Loss: 0.6095570\n",
      "Validation loss decreased (0.731810 --> 0.709176).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2849426\n",
      "\tspeed: 0.1109s/iter; left time: 224.9408s\n",
      "\titers: 200, epoch: 3 | loss: 0.3405750\n",
      "\tspeed: 0.0456s/iter; left time: 88.0161s\n",
      "Epoch: 3 running time: 0.2094225565592448 min.\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.2812904 Vali Loss: 0.7478794 Test Loss: 0.7363982\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3145991\n",
      "\tspeed: 0.1043s/iter; left time: 183.8408s\n",
      "\titers: 200, epoch: 4 | loss: 0.2818594\n",
      "\tspeed: 0.0432s/iter; left time: 71.7648s\n",
      "Epoch: 4 running time: 0.1930421034495036 min.\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2808226 Vali Loss: 0.7154712 Test Loss: 0.7434014\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2638505\n",
      "\tspeed: 0.1022s/iter; left time: 152.9238s\n",
      "\titers: 200, epoch: 5 | loss: 0.2780595\n",
      "\tspeed: 0.0413s/iter; left time: 57.6388s\n",
      "Epoch: 5 running time: 0.19026060104370118 min.\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.2794391 Vali Loss: 0.7288657 Test Loss: 0.7669990\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.7681576013565063, mae:0.663279116153717\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "dataset = 'ETTh1.csv'\n",
    "\n",
    "!python -u /vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path $current_path \\\n",
    "  --data_path $dataset \\\n",
    "  --model_id 1 \\\n",
    "  --model \"Informer\" \\\n",
    "  --data ETTh1 \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonstationary Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Take ETTh1 dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Nonstationary_Transformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.4032110\n",
      "\tspeed: 0.0425s/iter; left time: 108.7739s\n",
      "\titers: 200, epoch: 1 | loss: 0.2413542\n",
      "\tspeed: 0.0303s/iter; left time: 74.4774s\n",
      "Epoch: 1 running time: 0.14791139761606853 min.\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.3329230 Vali Loss: 0.5292587 Test Loss: 0.4346158\n",
      "Validation loss decreased (inf --> 0.529259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2218050\n",
      "\tspeed: 0.0818s/iter; left time: 187.7564s\n",
      "\titers: 200, epoch: 2 | loss: 0.1747543\n",
      "\tspeed: 0.0303s/iter; left time: 66.6066s\n",
      "Epoch: 2 running time: 0.13974119822184244 min.\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.2002304 Vali Loss: 0.5843881 Test Loss: 0.4940403\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1968130\n",
      "\tspeed: 0.0798s/iter; left time: 161.9372s\n",
      "\titers: 200, epoch: 3 | loss: 0.1974325\n",
      "\tspeed: 0.0314s/iter; left time: 60.5634s\n",
      "Epoch: 3 running time: 0.14282973607381186 min.\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.2029117 Vali Loss: 0.5480784 Test Loss: 0.5344843\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1831751\n",
      "\tspeed: 0.0798s/iter; left time: 140.6710s\n",
      "\titers: 200, epoch: 4 | loss: 0.2052629\n",
      "\tspeed: 0.0306s/iter; left time: 50.8891s\n",
      "Epoch: 4 running time: 0.13883942763010662 min.\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2075438 Vali Loss: 0.5416115 Test Loss: 0.4574961\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_1_Nonstationary_Transformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.4574960470199585, mae:0.4423450231552124\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Nonstationary_Transformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.3820704\n",
      "\tspeed: 0.0333s/iter; left time: 85.2836s\n",
      "\titers: 200, epoch: 1 | loss: 0.3020872\n",
      "\tspeed: 0.0304s/iter; left time: 74.7169s\n",
      "Epoch: 1 running time: 0.14107250372568766 min.\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.3374152 Vali Loss: 0.5224627 Test Loss: 0.5286707\n",
      "Validation loss decreased (inf --> 0.522463).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2075538\n",
      "\tspeed: 0.0841s/iter; left time: 193.0941s\n",
      "\titers: 200, epoch: 2 | loss: 0.1820664\n",
      "\tspeed: 0.0315s/iter; left time: 69.0627s\n",
      "Epoch: 2 running time: 0.14458661079406737 min.\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.1996413 Vali Loss: 0.5388003 Test Loss: 0.4569951\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1800281\n",
      "\tspeed: 0.0846s/iter; left time: 171.5520s\n",
      "\titers: 200, epoch: 3 | loss: 0.2106483\n",
      "\tspeed: 0.0329s/iter; left time: 63.5486s\n",
      "Epoch: 3 running time: 0.15072846015294392 min.\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.2013317 Vali Loss: 0.5524824 Test Loss: 0.4881700\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1988516\n",
      "\tspeed: 0.0800s/iter; left time: 141.0401s\n",
      "\titers: 200, epoch: 4 | loss: 0.1926844\n",
      "\tspeed: 0.0303s/iter; left time: 50.3688s\n",
      "Epoch: 4 running time: 0.13976478974024456 min.\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2065603 Vali Loss: 0.5147283 Test Loss: 0.4762118\n",
      "Validation loss decreased (0.522463 --> 0.514728).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1665130\n",
      "\tspeed: 0.0825s/iter; left time: 123.5455s\n",
      "\titers: 200, epoch: 5 | loss: 0.1787640\n",
      "\tspeed: 0.0306s/iter; left time: 42.7495s\n",
      "Epoch: 5 running time: 0.13996146917343139 min.\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.1806230 Vali Loss: 0.5275848 Test Loss: 0.4744250\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1520860\n",
      "\tspeed: 0.0804s/iter; left time: 98.9729s\n",
      "\titers: 200, epoch: 6 | loss: 0.1752529\n",
      "\tspeed: 0.0315s/iter; left time: 35.5976s\n",
      "Epoch: 6 running time: 0.14372676610946655 min.\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.1827901 Vali Loss: 0.5246465 Test Loss: 0.4702681\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1918269\n",
      "\tspeed: 0.0810s/iter; left time: 78.1443s\n",
      "\titers: 200, epoch: 7 | loss: 0.1843904\n",
      "\tspeed: 0.0310s/iter; left time: 26.8331s\n",
      "Epoch: 7 running time: 0.14251970052719115 min.\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.1839595 Vali Loss: 0.5199484 Test Loss: 0.4777840\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_1_Nonstationary_Transformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.4777839183807373, mae:0.4456425905227661\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "dataset = 'ETTh1.csv'\n",
    "\n",
    "!python -u /vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path $current_path \\\n",
    "  --data_path $dataset \\\n",
    "  --model_id 1 \\\n",
    "  --model \"Nonstationary_Transformer\" \\\n",
    "  --data ETTh1 \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informer custom dataloader\n",
    "## 2. Take custom dataloader (70/10/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12049\n",
      "val 1729\n",
      "test 3457\n",
      "\titers: 100, epoch: 1 | loss: 0.3763643\n",
      "\tspeed: 0.0612s/iter; left time: 224.0905s\n",
      "\titers: 200, epoch: 1 | loss: 0.3861512\n",
      "\tspeed: 0.0426s/iter; left time: 151.6734s\n",
      "\titers: 300, epoch: 1 | loss: 0.3227999\n",
      "\tspeed: 0.0416s/iter; left time: 143.8868s\n",
      "Epoch: 1 running time: 0.279414435227712 min.\n",
      "Epoch: 1, Steps: 376 | Train Loss: 0.4270375 Vali Loss: 0.3774065 Test Loss: 0.5083119\n",
      "Validation loss decreased (inf --> 0.377407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2685055\n",
      "\tspeed: 0.1075s/iter; left time: 353.1104s\n",
      "\titers: 200, epoch: 2 | loss: 0.3208056\n",
      "\tspeed: 0.0424s/iter; left time: 134.9305s\n",
      "\titers: 300, epoch: 2 | loss: 0.2855017\n",
      "\tspeed: 0.0419s/iter; left time: 129.1765s\n",
      "Epoch: 2 running time: 0.27010714213053383 min.\n",
      "Epoch: 2, Steps: 376 | Train Loss: 0.3087647 Vali Loss: 0.4340892 Test Loss: 0.5661222\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2973501\n",
      "\tspeed: 0.1050s/iter; left time: 305.5227s\n",
      "\titers: 200, epoch: 3 | loss: 0.3534546\n",
      "\tspeed: 0.0429s/iter; left time: 120.4476s\n",
      "\titers: 300, epoch: 3 | loss: 0.2793282\n",
      "\tspeed: 0.0428s/iter; left time: 116.0800s\n",
      "Epoch: 3 running time: 0.27220173279444376 min.\n",
      "Epoch: 3, Steps: 376 | Train Loss: 0.3058979 Vali Loss: 0.3791290 Test Loss: 0.5009486\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2573522\n",
      "\tspeed: 0.1041s/iter; left time: 263.7696s\n",
      "\titers: 200, epoch: 4 | loss: 0.3572222\n",
      "\tspeed: 0.0418s/iter; left time: 101.6115s\n",
      "\titers: 300, epoch: 4 | loss: 0.2734126\n",
      "\tspeed: 0.0419s/iter; left time: 97.7239s\n",
      "Epoch: 4 running time: 0.2683360457420349 min.\n",
      "Epoch: 4, Steps: 376 | Train Loss: 0.3056111 Vali Loss: 0.3939413 Test Loss: 0.5136320\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3457\n",
      "test shape: (108, 32, 24, 7) (108, 32, 24, 7)\n",
      "test shape: (3456, 24, 7) (3456, 24, 7)\n",
      "mse:0.5130395889282227, mae:0.5022826790809631\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12049\n",
      "val 1729\n",
      "test 3457\n",
      "\titers: 100, epoch: 1 | loss: 0.5019252\n",
      "\tspeed: 0.0449s/iter; left time: 164.3238s\n",
      "\titers: 200, epoch: 1 | loss: 0.4028457\n",
      "\tspeed: 0.0426s/iter; left time: 151.6056s\n",
      "\titers: 300, epoch: 1 | loss: 0.3882335\n",
      "\tspeed: 0.0418s/iter; left time: 144.8355s\n",
      "Epoch: 1 running time: 0.27097949186960857 min.\n",
      "Epoch: 1, Steps: 376 | Train Loss: 0.4198319 Vali Loss: 0.3992383 Test Loss: 0.5310426\n",
      "Validation loss decreased (inf --> 0.399238).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2972021\n",
      "\tspeed: 0.1146s/iter; left time: 376.3312s\n",
      "\titers: 200, epoch: 2 | loss: 0.2698340\n",
      "\tspeed: 0.0432s/iter; left time: 137.5767s\n",
      "\titers: 300, epoch: 2 | loss: 0.2805445\n",
      "\tspeed: 0.0426s/iter; left time: 131.3819s\n",
      "Epoch: 2 running time: 0.2731630007425944 min.\n",
      "Epoch: 2, Steps: 376 | Train Loss: 0.3083024 Vali Loss: 0.4084678 Test Loss: 0.5384812\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3182303\n",
      "\tspeed: 0.1047s/iter; left time: 304.4933s\n",
      "\titers: 200, epoch: 3 | loss: 0.3282709\n",
      "\tspeed: 0.0417s/iter; left time: 117.2655s\n",
      "\titers: 300, epoch: 3 | loss: 0.3526133\n",
      "\tspeed: 0.0419s/iter; left time: 113.5572s\n",
      "Epoch: 3 running time: 0.26793367862701417 min.\n",
      "Epoch: 3, Steps: 376 | Train Loss: 0.3042798 Vali Loss: 0.4125516 Test Loss: 0.5289951\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2659876\n",
      "\tspeed: 0.1046s/iter; left time: 264.9956s\n",
      "\titers: 200, epoch: 4 | loss: 0.2697616\n",
      "\tspeed: 0.0427s/iter; left time: 103.9628s\n",
      "\titers: 300, epoch: 4 | loss: 0.2760201\n",
      "\tspeed: 0.0421s/iter; left time: 98.3315s\n",
      "Epoch: 4 running time: 0.2722969969113668 min.\n",
      "Epoch: 4, Steps: 376 | Train Loss: 0.3038059 Vali Loss: 0.3869793 Test Loss: 0.5084223\n",
      "Validation loss decreased (0.399238 --> 0.386979).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3010871\n",
      "\tspeed: 0.1086s/iter; left time: 234.3525s\n",
      "\titers: 200, epoch: 5 | loss: 0.2351170\n",
      "\tspeed: 0.0417s/iter; left time: 85.8335s\n",
      "\titers: 300, epoch: 5 | loss: 0.2761097\n",
      "\tspeed: 0.0417s/iter; left time: 81.5498s\n",
      "Epoch: 5 running time: 0.26801210244496665 min.\n",
      "Epoch: 5, Steps: 376 | Train Loss: 0.2840520 Vali Loss: 0.4014679 Test Loss: 0.5266926\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2871152\n",
      "\tspeed: 0.1043s/iter; left time: 185.7647s\n",
      "\titers: 200, epoch: 6 | loss: 0.2237932\n",
      "\tspeed: 0.0432s/iter; left time: 72.6943s\n",
      "\titers: 300, epoch: 6 | loss: 0.2746004\n",
      "\tspeed: 0.0430s/iter; left time: 67.9642s\n",
      "Epoch: 6 running time: 0.2726265986760457 min.\n",
      "Epoch: 6, Steps: 376 | Train Loss: 0.2833494 Vali Loss: 0.3722942 Test Loss: 0.4993932\n",
      "Validation loss decreased (0.386979 --> 0.372294).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2468189\n",
      "\tspeed: 0.1086s/iter; left time: 152.5703s\n",
      "\titers: 200, epoch: 7 | loss: 0.2441047\n",
      "\tspeed: 0.0424s/iter; left time: 55.2674s\n",
      "\titers: 300, epoch: 7 | loss: 0.3101768\n",
      "\tspeed: 0.0421s/iter; left time: 50.6903s\n",
      "Epoch: 7 running time: 0.2693111658096313 min.\n",
      "Epoch: 7, Steps: 376 | Train Loss: 0.2786444 Vali Loss: 0.3816466 Test Loss: 0.5018377\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3210349\n",
      "\tspeed: 0.1044s/iter; left time: 107.4601s\n",
      "\titers: 200, epoch: 8 | loss: 0.2475036\n",
      "\tspeed: 0.0426s/iter; left time: 39.5969s\n",
      "\titers: 300, epoch: 8 | loss: 0.2491158\n",
      "\tspeed: 0.0420s/iter; left time: 34.8248s\n",
      "Epoch: 8 running time: 0.2719109932581584 min.\n",
      "Epoch: 8, Steps: 376 | Train Loss: 0.2780708 Vali Loss: 0.3791690 Test Loss: 0.5050891\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3423782\n",
      "\tspeed: 0.1048s/iter; left time: 68.4461s\n",
      "\titers: 200, epoch: 9 | loss: 0.3209715\n",
      "\tspeed: 0.0427s/iter; left time: 23.6237s\n",
      "\titers: 300, epoch: 9 | loss: 0.2941921\n",
      "\tspeed: 0.0425s/iter; left time: 19.2650s\n",
      "Epoch: 9 running time: 0.269273833433787 min.\n",
      "Epoch: 9, Steps: 376 | Train Loss: 0.2785888 Vali Loss: 0.3869219 Test Loss: 0.5090706\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_1_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3457\n",
      "test shape: (108, 32, 24, 7) (108, 32, 24, 7)\n",
      "test shape: (3456, 24, 7) (3456, 24, 7)\n",
      "mse:0.5089989900588989, mae:0.5047451853752136\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "dataset = 'ETTh1.csv'\n",
    "\n",
    "!python -u /vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path $current_path \\\n",
    "  --data_path $dataset \\\n",
    "  --model_id 1 \\\n",
    "  --model \"Informer\" \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12049\n",
      "val 1729\n",
      "test 3457\n",
      "\titers: 100, epoch: 1 | loss: 0.3439233\n",
      "\tspeed: 0.0499s/iter; left time: 182.7363s\n",
      "\titers: 200, epoch: 1 | loss: 0.2601243\n",
      "\tspeed: 0.0298s/iter; left time: 105.9431s\n",
      "\titers: 300, epoch: 1 | loss: 0.2160712\n",
      "\tspeed: 0.0297s/iter; left time: 102.7219s\n",
      "Epoch: 1 running time: 0.20175397793451946 min.\n",
      "Epoch: 1, Steps: 376 | Train Loss: 0.3064217 Vali Loss: 0.3423961 Test Loss: 0.4702770\n",
      "Validation loss decreased (inf --> 0.342396).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2497098\n",
      "\tspeed: 0.0836s/iter; left time: 274.5945s\n",
      "\titers: 200, epoch: 2 | loss: 0.1729961\n",
      "\tspeed: 0.0315s/iter; left time: 100.4086s\n",
      "\titers: 300, epoch: 2 | loss: 0.1423871\n",
      "\tspeed: 0.0301s/iter; left time: 92.9549s\n",
      "Epoch: 2 running time: 0.1974997361501058 min.\n",
      "Epoch: 2, Steps: 376 | Train Loss: 0.1893995 Vali Loss: 0.4065197 Test Loss: 0.5507415\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2167805\n",
      "\tspeed: 0.0814s/iter; left time: 236.8709s\n",
      "\titers: 200, epoch: 3 | loss: 0.2130049\n",
      "\tspeed: 0.0303s/iter; left time: 85.0882s\n",
      "\titers: 300, epoch: 3 | loss: 0.1654096\n",
      "\tspeed: 0.0303s/iter; left time: 82.1661s\n",
      "Epoch: 3 running time: 0.19456719557444255 min.\n",
      "Epoch: 3, Steps: 376 | Train Loss: 0.1892117 Vali Loss: 0.4059986 Test Loss: 0.6194497\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1725365\n",
      "\tspeed: 0.0812s/iter; left time: 205.7403s\n",
      "\titers: 200, epoch: 4 | loss: 0.2271558\n",
      "\tspeed: 0.0303s/iter; left time: 73.7655s\n",
      "\titers: 300, epoch: 4 | loss: 0.1790380\n",
      "\tspeed: 0.0300s/iter; left time: 70.0968s\n",
      "Epoch: 4 running time: 0.19361739953358967 min.\n",
      "Epoch: 4, Steps: 376 | Train Loss: 0.1917897 Vali Loss: 0.3334178 Test Loss: 0.4570390\n",
      "Validation loss decreased (0.342396 --> 0.333418).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1877303\n",
      "\tspeed: 0.0832s/iter; left time: 179.4736s\n",
      "\titers: 200, epoch: 5 | loss: 0.1639780\n",
      "\tspeed: 0.0305s/iter; left time: 62.8043s\n",
      "\titers: 300, epoch: 5 | loss: 0.1463934\n",
      "\tspeed: 0.0303s/iter; left time: 59.3492s\n",
      "Epoch: 5 running time: 0.1951754848162333 min.\n",
      "Epoch: 5, Steps: 376 | Train Loss: 0.1702654 Vali Loss: 0.3556059 Test Loss: 0.4975217\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1795468\n",
      "\tspeed: 0.0817s/iter; left time: 145.5653s\n",
      "\titers: 200, epoch: 6 | loss: 0.1762074\n",
      "\tspeed: 0.0303s/iter; left time: 50.9467s\n",
      "\titers: 300, epoch: 6 | loss: 0.1572039\n",
      "\tspeed: 0.0305s/iter; left time: 48.1724s\n",
      "Epoch: 6 running time: 0.19580333630243937 min.\n",
      "Epoch: 6, Steps: 376 | Train Loss: 0.1721736 Vali Loss: 0.3426207 Test Loss: 0.4705714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1834904\n",
      "\tspeed: 0.0813s/iter; left time: 114.2165s\n",
      "\titers: 200, epoch: 7 | loss: 0.1909758\n",
      "\tspeed: 0.0303s/iter; left time: 39.6003s\n",
      "\titers: 300, epoch: 7 | loss: 0.1599865\n",
      "\tspeed: 0.0304s/iter; left time: 36.6373s\n",
      "Epoch: 7 running time: 0.19557210604349773 min.\n",
      "Epoch: 7, Steps: 376 | Train Loss: 0.1725239 Vali Loss: 0.3443522 Test Loss: 0.4725480\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_1_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3457\n",
      "test shape: (108, 32, 24, 7) (108, 32, 24, 7)\n",
      "test shape: (3456, 24, 7) (3456, 24, 7)\n",
      "mse:0.4725480079650879, mae:0.4540554881095886\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_1_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12049\n",
      "val 1729\n",
      "test 3457\n",
      "\titers: 100, epoch: 1 | loss: 0.4283315\n",
      "\tspeed: 0.0333s/iter; left time: 121.8596s\n",
      "\titers: 200, epoch: 1 | loss: 0.2863144\n",
      "\tspeed: 0.0303s/iter; left time: 107.9274s\n",
      "\titers: 300, epoch: 1 | loss: 0.2357405\n",
      "\tspeed: 0.0303s/iter; left time: 104.9565s\n",
      "Epoch: 1 running time: 0.19587277968724567 min.\n",
      "Epoch: 1, Steps: 376 | Train Loss: 0.3107746 Vali Loss: 0.3486830 Test Loss: 0.4519618\n",
      "Validation loss decreased (inf --> 0.348683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1853765\n",
      "\tspeed: 0.0914s/iter; left time: 300.2315s\n",
      "\titers: 200, epoch: 2 | loss: 0.1758094\n",
      "\tspeed: 0.0303s/iter; left time: 96.5739s\n",
      "\titers: 300, epoch: 2 | loss: 0.1572566\n",
      "\tspeed: 0.0303s/iter; left time: 93.5269s\n",
      "Epoch: 2 running time: 0.19562453031539917 min.\n",
      "Epoch: 2, Steps: 376 | Train Loss: 0.1883700 Vali Loss: 0.3887401 Test Loss: 0.5013038\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1982545\n",
      "\tspeed: 0.0819s/iter; left time: 238.2690s\n",
      "\titers: 200, epoch: 3 | loss: 0.1620250\n",
      "\tspeed: 0.0305s/iter; left time: 85.5994s\n",
      "\titers: 300, epoch: 3 | loss: 0.1444402\n",
      "\tspeed: 0.0303s/iter; left time: 82.2053s\n",
      "Epoch: 3 running time: 0.1960221250851949 min.\n",
      "Epoch: 3, Steps: 376 | Train Loss: 0.1863801 Vali Loss: 0.3318806 Test Loss: 0.4623333\n",
      "Validation loss decreased (0.348683 --> 0.331881).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1407222\n",
      "\tspeed: 0.0845s/iter; left time: 214.1112s\n",
      "\titers: 200, epoch: 4 | loss: 0.1465210\n",
      "\tspeed: 0.0299s/iter; left time: 72.8648s\n",
      "\titers: 300, epoch: 4 | loss: 0.1446191\n",
      "\tspeed: 0.0303s/iter; left time: 70.7334s\n",
      "Epoch: 4 running time: 0.1930636207262675 min.\n",
      "Epoch: 4, Steps: 376 | Train Loss: 0.1518662 Vali Loss: 0.3590532 Test Loss: 0.4636130\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1559750\n",
      "\tspeed: 0.0821s/iter; left time: 177.1619s\n",
      "\titers: 200, epoch: 5 | loss: 0.1581355\n",
      "\tspeed: 0.0305s/iter; left time: 62.7827s\n",
      "\titers: 300, epoch: 5 | loss: 0.1456286\n",
      "\tspeed: 0.0303s/iter; left time: 59.3351s\n",
      "Epoch: 5 running time: 0.1960824489593506 min.\n",
      "Epoch: 5, Steps: 376 | Train Loss: 0.1528051 Vali Loss: 0.3554018 Test Loss: 0.4566228\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1734525\n",
      "\tspeed: 0.0821s/iter; left time: 146.2516s\n",
      "\titers: 200, epoch: 6 | loss: 0.1547164\n",
      "\tspeed: 0.0305s/iter; left time: 51.3322s\n",
      "\titers: 300, epoch: 6 | loss: 0.1589387\n",
      "\tspeed: 0.0306s/iter; left time: 48.3050s\n",
      "Epoch: 6 running time: 0.19663306474685668 min.\n",
      "Epoch: 6, Steps: 376 | Train Loss: 0.1539220 Vali Loss: 0.3506889 Test Loss: 0.4660089\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_1_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3457\n",
      "test shape: (108, 32, 24, 7) (108, 32, 24, 7)\n",
      "test shape: (3456, 24, 7) (3456, 24, 7)\n",
      "mse:0.46600884199142456, mae:0.460347056388855\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "dataset = 'ETTh1.csv'\n",
    "\n",
    "!python -u /vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path $current_path \\\n",
    "  --data_path $dataset \\\n",
    "  --model_id 1 \\\n",
    "  --model \"Nonstationary_Transformer\" \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_2_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.3649494\n",
      "\tspeed: 0.0503s/iter; left time: 468.2175s\n",
      "\titers: 200, epoch: 1 | loss: 0.2716310\n",
      "\tspeed: 0.0294s/iter; left time: 270.5235s\n",
      "\titers: 300, epoch: 1 | loss: 0.2221682\n",
      "\tspeed: 0.0303s/iter; left time: 275.7582s\n",
      "\titers: 400, epoch: 1 | loss: 0.2238553\n",
      "\tspeed: 0.0300s/iter; left time: 270.0177s\n",
      "\titers: 500, epoch: 1 | loss: 0.1720495\n",
      "\tspeed: 0.0298s/iter; left time: 265.8888s\n",
      "\titers: 600, epoch: 1 | loss: 0.1457593\n",
      "\tspeed: 0.0324s/iter; left time: 285.8974s\n",
      "\titers: 700, epoch: 1 | loss: 0.2382891\n",
      "\tspeed: 0.0324s/iter; left time: 282.3693s\n",
      "\titers: 800, epoch: 1 | loss: 0.1409248\n",
      "\tspeed: 0.0331s/iter; left time: 285.1973s\n",
      "\titers: 900, epoch: 1 | loss: 0.1688729\n",
      "\tspeed: 0.0336s/iter; left time: 286.2149s\n",
      "Epoch: 1 running time: 0.5064127008120219 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.2424076 Vali Loss: 0.2439631 Test Loss: 0.3741519\n",
      "Validation loss decreased (inf --> 0.243963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1753821\n",
      "\tspeed: 0.1057s/iter; left time: 884.6645s\n",
      "\titers: 200, epoch: 2 | loss: 0.1914740\n",
      "\tspeed: 0.0324s/iter; left time: 268.0927s\n",
      "\titers: 300, epoch: 2 | loss: 0.2191539\n",
      "\tspeed: 0.0336s/iter; left time: 274.1695s\n",
      "\titers: 400, epoch: 2 | loss: 0.1353402\n",
      "\tspeed: 0.0337s/iter; left time: 271.7329s\n",
      "\titers: 500, epoch: 2 | loss: 0.1659905\n",
      "\tspeed: 0.0336s/iter; left time: 268.1286s\n",
      "\titers: 600, epoch: 2 | loss: 0.1339594\n",
      "\tspeed: 0.0329s/iter; left time: 258.8487s\n",
      "\titers: 700, epoch: 2 | loss: 0.1474677\n",
      "\tspeed: 0.0328s/iter; left time: 254.6432s\n",
      "\titers: 800, epoch: 2 | loss: 0.1287255\n",
      "\tspeed: 0.0329s/iter; left time: 252.1326s\n",
      "\titers: 900, epoch: 2 | loss: 0.1421609\n",
      "\tspeed: 0.0328s/iter; left time: 248.0537s\n",
      "Epoch: 2 running time: 0.5277679999669392 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.1599604 Vali Loss: 0.2334695 Test Loss: 0.4192858\n",
      "Validation loss decreased (0.243963 --> 0.233470).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1820426\n",
      "\tspeed: 0.1076s/iter; left time: 799.1201s\n",
      "\titers: 200, epoch: 3 | loss: 0.0856391\n",
      "\tspeed: 0.0332s/iter; left time: 243.4229s\n",
      "\titers: 300, epoch: 3 | loss: 0.1498381\n",
      "\tspeed: 0.0336s/iter; left time: 242.9904s\n",
      "\titers: 400, epoch: 3 | loss: 0.1241259\n",
      "\tspeed: 0.0336s/iter; left time: 239.5445s\n",
      "\titers: 500, epoch: 3 | loss: 0.1229033\n",
      "\tspeed: 0.0334s/iter; left time: 235.0287s\n",
      "\titers: 600, epoch: 3 | loss: 0.1329610\n",
      "\tspeed: 0.0328s/iter; left time: 227.0273s\n",
      "\titers: 700, epoch: 3 | loss: 0.1320104\n",
      "\tspeed: 0.0326s/iter; left time: 222.4082s\n",
      "\titers: 800, epoch: 3 | loss: 0.0782566\n",
      "\tspeed: 0.0324s/iter; left time: 218.3261s\n",
      "\titers: 900, epoch: 3 | loss: 0.1005376\n",
      "\tspeed: 0.0329s/iter; left time: 218.1353s\n",
      "Epoch: 3 running time: 0.5213340163230896 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1187469 Vali Loss: 0.2380019 Test Loss: 0.3915616\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1256370\n",
      "\tspeed: 0.0989s/iter; left time: 641.3418s\n",
      "\titers: 200, epoch: 4 | loss: 0.1112389\n",
      "\tspeed: 0.0343s/iter; left time: 219.1239s\n",
      "\titers: 300, epoch: 4 | loss: 0.1441912\n",
      "\tspeed: 0.0337s/iter; left time: 211.8790s\n",
      "\titers: 400, epoch: 4 | loss: 0.1018379\n",
      "\tspeed: 0.0339s/iter; left time: 209.9072s\n",
      "\titers: 500, epoch: 4 | loss: 0.1053373\n",
      "\tspeed: 0.0329s/iter; left time: 200.3589s\n",
      "\titers: 600, epoch: 4 | loss: 0.0954452\n",
      "\tspeed: 0.0330s/iter; left time: 197.5662s\n",
      "\titers: 700, epoch: 4 | loss: 0.0715525\n",
      "\tspeed: 0.0320s/iter; left time: 188.1421s\n",
      "\titers: 800, epoch: 4 | loss: 0.1012617\n",
      "\tspeed: 0.0333s/iter; left time: 192.5038s\n",
      "\titers: 900, epoch: 4 | loss: 0.0891881\n",
      "\tspeed: 0.0335s/iter; left time: 190.6165s\n",
      "Epoch: 4 running time: 0.5262671311696371 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1154948 Vali Loss: 0.2312799 Test Loss: 0.4190405\n",
      "Validation loss decreased (0.233470 --> 0.231280).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1281390\n",
      "\tspeed: 0.1026s/iter; left time: 569.2892s\n",
      "\titers: 200, epoch: 5 | loss: 0.1241634\n",
      "\tspeed: 0.0303s/iter; left time: 164.9879s\n",
      "\titers: 300, epoch: 5 | loss: 0.0919050\n",
      "\tspeed: 0.0303s/iter; left time: 162.2099s\n",
      "\titers: 400, epoch: 5 | loss: 0.1062234\n",
      "\tspeed: 0.0303s/iter; left time: 159.0870s\n",
      "\titers: 500, epoch: 5 | loss: 0.0997440\n",
      "\tspeed: 0.0303s/iter; left time: 155.9860s\n",
      "\titers: 600, epoch: 5 | loss: 0.0978204\n",
      "\tspeed: 0.0303s/iter; left time: 153.0221s\n",
      "\titers: 700, epoch: 5 | loss: 0.0917097\n",
      "\tspeed: 0.0304s/iter; left time: 150.4778s\n",
      "\titers: 800, epoch: 5 | loss: 0.0869811\n",
      "\tspeed: 0.0306s/iter; left time: 148.4950s\n",
      "\titers: 900, epoch: 5 | loss: 0.1033960\n",
      "\tspeed: 0.0303s/iter; left time: 143.9864s\n",
      "Epoch: 5 running time: 0.48328140179316204 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.0988040 Vali Loss: 0.2375574 Test Loss: 0.4368379\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0996406\n",
      "\tspeed: 0.0965s/iter; left time: 444.4113s\n",
      "\titers: 200, epoch: 6 | loss: 0.0902802\n",
      "\tspeed: 0.0303s/iter; left time: 136.6363s\n",
      "\titers: 300, epoch: 6 | loss: 0.0818197\n",
      "\tspeed: 0.0303s/iter; left time: 133.6743s\n",
      "\titers: 400, epoch: 6 | loss: 0.1253380\n",
      "\tspeed: 0.0303s/iter; left time: 130.5699s\n",
      "\titers: 500, epoch: 6 | loss: 0.1042850\n",
      "\tspeed: 0.0304s/iter; left time: 127.9766s\n",
      "\titers: 600, epoch: 6 | loss: 0.0933647\n",
      "\tspeed: 0.0301s/iter; left time: 123.4081s\n",
      "\titers: 700, epoch: 6 | loss: 0.1299158\n",
      "\tspeed: 0.0299s/iter; left time: 119.7504s\n",
      "\titers: 800, epoch: 6 | loss: 0.0768160\n",
      "\tspeed: 0.0294s/iter; left time: 114.9645s\n",
      "\titers: 900, epoch: 6 | loss: 0.0879112\n",
      "\tspeed: 0.0304s/iter; left time: 115.8675s\n",
      "Epoch: 6 running time: 0.478377103805542 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.0988807 Vali Loss: 0.2350616 Test Loss: 0.4207011\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1003239\n",
      "\tspeed: 0.0961s/iter; left time: 352.2474s\n",
      "\titers: 200, epoch: 7 | loss: 0.0638872\n",
      "\tspeed: 0.0303s/iter; left time: 108.0994s\n",
      "\titers: 300, epoch: 7 | loss: 0.0900476\n",
      "\tspeed: 0.0303s/iter; left time: 105.0876s\n",
      "\titers: 400, epoch: 7 | loss: 0.1184118\n",
      "\tspeed: 0.0303s/iter; left time: 102.0316s\n",
      "\titers: 500, epoch: 7 | loss: 0.1026696\n",
      "\tspeed: 0.0303s/iter; left time: 99.0204s\n",
      "\titers: 600, epoch: 7 | loss: 0.0926221\n",
      "\tspeed: 0.0303s/iter; left time: 96.0009s\n",
      "\titers: 700, epoch: 7 | loss: 0.1023391\n",
      "\tspeed: 0.0303s/iter; left time: 93.0041s\n",
      "\titers: 800, epoch: 7 | loss: 0.0725346\n",
      "\tspeed: 0.0303s/iter; left time: 89.9605s\n",
      "\titers: 900, epoch: 7 | loss: 0.1009707\n",
      "\tspeed: 0.0303s/iter; left time: 86.8875s\n",
      "Epoch: 7 running time: 0.4796355684598287 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.0992355 Vali Loss: 0.2335942 Test Loss: 0.4185007\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_2_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.4185006320476532, mae:0.3560675084590912\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_2_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.2731359\n",
      "\tspeed: 0.0339s/iter; left time: 315.4005s\n",
      "\titers: 200, epoch: 1 | loss: 0.1884836\n",
      "\tspeed: 0.0297s/iter; left time: 273.8726s\n",
      "\titers: 300, epoch: 1 | loss: 0.2569596\n",
      "\tspeed: 0.0304s/iter; left time: 276.6298s\n",
      "\titers: 400, epoch: 1 | loss: 0.1859279\n",
      "\tspeed: 0.0303s/iter; left time: 273.2460s\n",
      "\titers: 500, epoch: 1 | loss: 0.2273879\n",
      "\tspeed: 0.0303s/iter; left time: 270.2642s\n",
      "\titers: 600, epoch: 1 | loss: 0.2375675\n",
      "\tspeed: 0.0305s/iter; left time: 268.3951s\n",
      "\titers: 700, epoch: 1 | loss: 0.1646313\n",
      "\tspeed: 0.0303s/iter; left time: 263.9768s\n",
      "\titers: 800, epoch: 1 | loss: 0.1446381\n",
      "\tspeed: 0.0303s/iter; left time: 261.1127s\n",
      "\titers: 900, epoch: 1 | loss: 0.1685647\n",
      "\tspeed: 0.0303s/iter; left time: 258.0836s\n",
      "Epoch: 1 running time: 0.4821917176246643 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.2409703 Vali Loss: 0.2562571 Test Loss: 0.4007153\n",
      "Validation loss decreased (inf --> 0.256257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1871088\n",
      "\tspeed: 0.1068s/iter; left time: 894.1316s\n",
      "\titers: 200, epoch: 2 | loss: 0.2135085\n",
      "\tspeed: 0.0303s/iter; left time: 250.9347s\n",
      "\titers: 300, epoch: 2 | loss: 0.1674735\n",
      "\tspeed: 0.0303s/iter; left time: 247.9313s\n",
      "\titers: 400, epoch: 2 | loss: 0.1612284\n",
      "\tspeed: 0.0304s/iter; left time: 245.6190s\n",
      "\titers: 500, epoch: 2 | loss: 0.1620193\n",
      "\tspeed: 0.0303s/iter; left time: 241.8593s\n",
      "\titers: 600, epoch: 2 | loss: 0.1387914\n",
      "\tspeed: 0.0305s/iter; left time: 239.6551s\n",
      "\titers: 700, epoch: 2 | loss: 0.1594162\n",
      "\tspeed: 0.0299s/iter; left time: 232.2265s\n",
      "\titers: 800, epoch: 2 | loss: 0.1239896\n",
      "\tspeed: 0.0294s/iter; left time: 225.6907s\n",
      "\titers: 900, epoch: 2 | loss: 0.1156637\n",
      "\tspeed: 0.0294s/iter; left time: 222.7096s\n",
      "Epoch: 2 running time: 0.4779095451037089 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.1588787 Vali Loss: 0.2401303 Test Loss: 0.4074917\n",
      "Validation loss decreased (0.256257 --> 0.240130).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1163753\n",
      "\tspeed: 0.1032s/iter; left time: 766.8405s\n",
      "\titers: 200, epoch: 3 | loss: 0.1547621\n",
      "\tspeed: 0.0303s/iter; left time: 222.0651s\n",
      "\titers: 300, epoch: 3 | loss: 0.1538612\n",
      "\tspeed: 0.0295s/iter; left time: 213.3517s\n",
      "\titers: 400, epoch: 3 | loss: 0.0704265\n",
      "\tspeed: 0.0294s/iter; left time: 209.6549s\n",
      "\titers: 500, epoch: 3 | loss: 0.0968177\n",
      "\tspeed: 0.0299s/iter; left time: 210.4290s\n",
      "\titers: 600, epoch: 3 | loss: 0.0919446\n",
      "\tspeed: 0.0303s/iter; left time: 210.1643s\n",
      "\titers: 700, epoch: 3 | loss: 0.1079663\n",
      "\tspeed: 0.0305s/iter; left time: 208.1828s\n",
      "\titers: 800, epoch: 3 | loss: 0.1015540\n",
      "\tspeed: 0.0304s/iter; left time: 204.7625s\n",
      "\titers: 900, epoch: 3 | loss: 0.0926717\n",
      "\tspeed: 0.0295s/iter; left time: 195.7463s\n",
      "Epoch: 3 running time: 0.47651477257410685 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1153157 Vali Loss: 0.2490718 Test Loss: 0.4367783\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0979401\n",
      "\tspeed: 0.0980s/iter; left time: 635.5748s\n",
      "\titers: 200, epoch: 4 | loss: 0.1521533\n",
      "\tspeed: 0.0306s/iter; left time: 195.4904s\n",
      "\titers: 300, epoch: 4 | loss: 0.1329225\n",
      "\tspeed: 0.0303s/iter; left time: 190.7201s\n",
      "\titers: 400, epoch: 4 | loss: 0.1141531\n",
      "\tspeed: 0.0303s/iter; left time: 187.7609s\n",
      "\titers: 500, epoch: 4 | loss: 0.1457931\n",
      "\tspeed: 0.0303s/iter; left time: 184.5392s\n",
      "\titers: 600, epoch: 4 | loss: 0.1227031\n",
      "\tspeed: 0.0303s/iter; left time: 181.4883s\n",
      "\titers: 700, epoch: 4 | loss: 0.0860027\n",
      "\tspeed: 0.0303s/iter; left time: 178.6051s\n",
      "\titers: 800, epoch: 4 | loss: 0.1590327\n",
      "\tspeed: 0.0303s/iter; left time: 175.3989s\n",
      "\titers: 900, epoch: 4 | loss: 0.1059401\n",
      "\tspeed: 0.0304s/iter; left time: 172.7476s\n",
      "Epoch: 4 running time: 0.48279032707214353 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1137171 Vali Loss: 0.2371623 Test Loss: 0.4192760\n",
      "Validation loss decreased (0.240130 --> 0.237162).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0769886\n",
      "\tspeed: 0.1017s/iter; left time: 564.1747s\n",
      "\titers: 200, epoch: 5 | loss: 0.0864938\n",
      "\tspeed: 0.0304s/iter; left time: 165.6313s\n",
      "\titers: 300, epoch: 5 | loss: 0.0888699\n",
      "\tspeed: 0.0303s/iter; left time: 162.2192s\n",
      "\titers: 400, epoch: 5 | loss: 0.1183761\n",
      "\tspeed: 0.0303s/iter; left time: 159.1135s\n",
      "\titers: 500, epoch: 5 | loss: 0.1200526\n",
      "\tspeed: 0.0303s/iter; left time: 155.9431s\n",
      "\titers: 600, epoch: 5 | loss: 0.1035982\n",
      "\tspeed: 0.0303s/iter; left time: 153.0473s\n",
      "\titers: 700, epoch: 5 | loss: 0.1336754\n",
      "\tspeed: 0.0303s/iter; left time: 150.0730s\n",
      "\titers: 800, epoch: 5 | loss: 0.0880266\n",
      "\tspeed: 0.0303s/iter; left time: 146.9583s\n",
      "\titers: 900, epoch: 5 | loss: 0.0900785\n",
      "\tspeed: 0.0303s/iter; left time: 144.0543s\n",
      "Epoch: 5 running time: 0.48159571886062624 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.0957260 Vali Loss: 0.2335084 Test Loss: 0.4423597\n",
      "Validation loss decreased (0.237162 --> 0.233508).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0882687\n",
      "\tspeed: 0.1015s/iter; left time: 467.4357s\n",
      "\titers: 200, epoch: 6 | loss: 0.0867047\n",
      "\tspeed: 0.0299s/iter; left time: 134.8391s\n",
      "\titers: 300, epoch: 6 | loss: 0.0696609\n",
      "\tspeed: 0.0310s/iter; left time: 136.7227s\n",
      "\titers: 400, epoch: 6 | loss: 0.0715951\n",
      "\tspeed: 0.0332s/iter; left time: 142.7629s\n",
      "\titers: 500, epoch: 6 | loss: 0.0637181\n",
      "\tspeed: 0.0386s/iter; left time: 162.3155s\n",
      "\titers: 600, epoch: 6 | loss: 0.1058032\n",
      "\tspeed: 0.0348s/iter; left time: 143.0405s\n",
      "\titers: 700, epoch: 6 | loss: 0.0872834\n",
      "\tspeed: 0.0306s/iter; left time: 122.5258s\n",
      "\titers: 800, epoch: 6 | loss: 0.0809019\n",
      "\tspeed: 0.0302s/iter; left time: 117.9903s\n",
      "\titers: 900, epoch: 6 | loss: 0.1025396\n",
      "\tspeed: 0.0303s/iter; left time: 115.1590s\n",
      "Epoch: 6 running time: 0.5082146445910136 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.0875614 Vali Loss: 0.2392100 Test Loss: 0.4456812\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1046127\n",
      "\tspeed: 0.0995s/iter; left time: 364.5205s\n",
      "\titers: 200, epoch: 7 | loss: 0.1214155\n",
      "\tspeed: 0.0303s/iter; left time: 108.1273s\n",
      "\titers: 300, epoch: 7 | loss: 0.0855777\n",
      "\tspeed: 0.0303s/iter; left time: 105.0931s\n",
      "\titers: 400, epoch: 7 | loss: 0.0945399\n",
      "\tspeed: 0.0303s/iter; left time: 102.1035s\n",
      "\titers: 500, epoch: 7 | loss: 0.0991366\n",
      "\tspeed: 0.0306s/iter; left time: 100.0204s\n",
      "\titers: 600, epoch: 7 | loss: 0.0934048\n",
      "\tspeed: 0.0308s/iter; left time: 97.3238s\n",
      "\titers: 700, epoch: 7 | loss: 0.0785186\n",
      "\tspeed: 0.0303s/iter; left time: 92.9964s\n",
      "\titers: 800, epoch: 7 | loss: 0.0857852\n",
      "\tspeed: 0.0305s/iter; left time: 90.3474s\n",
      "\titers: 900, epoch: 7 | loss: 0.0888223\n",
      "\tspeed: 0.0304s/iter; left time: 87.0131s\n",
      "Epoch: 7 running time: 0.483351735273997 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.0877508 Vali Loss: 0.2424996 Test Loss: 0.4491255\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0739731\n",
      "\tspeed: 0.0988s/iter; left time: 269.1609s\n",
      "\titers: 200, epoch: 8 | loss: 0.0761647\n",
      "\tspeed: 0.0304s/iter; left time: 79.7980s\n",
      "\titers: 300, epoch: 8 | loss: 0.0789619\n",
      "\tspeed: 0.0303s/iter; left time: 76.5358s\n",
      "\titers: 400, epoch: 8 | loss: 0.0796092\n",
      "\tspeed: 0.0303s/iter; left time: 73.4503s\n",
      "\titers: 500, epoch: 8 | loss: 0.0788658\n",
      "\tspeed: 0.0303s/iter; left time: 70.5057s\n",
      "\titers: 600, epoch: 8 | loss: 0.0703726\n",
      "\tspeed: 0.0303s/iter; left time: 67.4465s\n",
      "\titers: 700, epoch: 8 | loss: 0.0866863\n",
      "\tspeed: 0.0306s/iter; left time: 65.0544s\n",
      "\titers: 800, epoch: 8 | loss: 0.0786046\n",
      "\tspeed: 0.0303s/iter; left time: 61.3869s\n",
      "\titers: 900, epoch: 8 | loss: 0.0898354\n",
      "\tspeed: 0.0303s/iter; left time: 58.3469s\n",
      "Epoch: 8 running time: 0.4826579054196676 min.\n",
      "Epoch: 8, Steps: 941 | Train Loss: 0.0881281 Vali Loss: 0.2373293 Test Loss: 0.4422513\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_2_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.4422512650489807, mae:0.3639376163482666\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "dataset = 'FR_data.csv'\n",
    "\n",
    "!python -u /vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path $current_path \\\n",
    "  --data_path $dataset \\\n",
    "  --model_id 2 \\\n",
    "  --model \"Nonstationary_Transformer\" \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_2_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.4307346\n",
      "\tspeed: 0.0616s/iter; left time: 573.7312s\n",
      "\titers: 200, epoch: 1 | loss: 0.3016012\n",
      "\tspeed: 0.0413s/iter; left time: 380.0273s\n",
      "\titers: 300, epoch: 1 | loss: 0.2942957\n",
      "\tspeed: 0.0410s/iter; left time: 373.1251s\n",
      "\titers: 400, epoch: 1 | loss: 0.2671357\n",
      "\tspeed: 0.0411s/iter; left time: 370.2236s\n",
      "\titers: 500, epoch: 1 | loss: 0.2435258\n",
      "\tspeed: 0.0425s/iter; left time: 378.4515s\n",
      "\titers: 600, epoch: 1 | loss: 0.2217858\n",
      "\tspeed: 0.0416s/iter; left time: 366.8701s\n",
      "\titers: 700, epoch: 1 | loss: 0.2125417\n",
      "\tspeed: 0.0419s/iter; left time: 365.0124s\n",
      "\titers: 800, epoch: 1 | loss: 0.1906348\n",
      "\tspeed: 0.0425s/iter; left time: 365.8513s\n",
      "\titers: 900, epoch: 1 | loss: 0.2647261\n",
      "\tspeed: 0.0418s/iter; left time: 355.5297s\n",
      "Epoch: 1 running time: 0.6710273027420044 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.3047330 Vali Loss: 0.2980494 Test Loss: 0.4696968\n",
      "Validation loss decreased (inf --> 0.298049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1999377\n",
      "\tspeed: 0.1154s/iter; left time: 965.9133s\n",
      "\titers: 200, epoch: 2 | loss: 0.2411886\n",
      "\tspeed: 0.0317s/iter; left time: 262.3150s\n",
      "\titers: 300, epoch: 2 | loss: 0.1997966\n",
      "\tspeed: 0.0317s/iter; left time: 258.7489s\n",
      "\titers: 400, epoch: 2 | loss: 0.2423015\n",
      "\tspeed: 0.0317s/iter; left time: 255.7888s\n",
      "\titers: 500, epoch: 2 | loss: 0.2103719\n",
      "\tspeed: 0.0317s/iter; left time: 252.5366s\n",
      "\titers: 600, epoch: 2 | loss: 0.2181772\n",
      "\tspeed: 0.0317s/iter; left time: 249.1341s\n",
      "\titers: 700, epoch: 2 | loss: 0.1343314\n",
      "\tspeed: 0.0317s/iter; left time: 246.6029s\n",
      "\titers: 800, epoch: 2 | loss: 0.1816992\n",
      "\tspeed: 0.0317s/iter; left time: 242.8006s\n",
      "\titers: 900, epoch: 2 | loss: 0.2507245\n",
      "\tspeed: 0.0318s/iter; left time: 241.0987s\n",
      "Epoch: 2 running time: 0.5101820588111877 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.2009419 Vali Loss: 0.2374241 Test Loss: 0.3929982\n",
      "Validation loss decreased (0.298049 --> 0.237424).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1378951\n",
      "\tspeed: 0.1243s/iter; left time: 923.4387s\n",
      "\titers: 200, epoch: 3 | loss: 0.1840836\n",
      "\tspeed: 0.0421s/iter; left time: 308.7552s\n",
      "\titers: 300, epoch: 3 | loss: 0.1439371\n",
      "\tspeed: 0.0417s/iter; left time: 301.4029s\n",
      "\titers: 400, epoch: 3 | loss: 0.1691880\n",
      "\tspeed: 0.0411s/iter; left time: 292.6991s\n",
      "\titers: 500, epoch: 3 | loss: 0.2097439\n",
      "\tspeed: 0.0414s/iter; left time: 291.1982s\n",
      "\titers: 600, epoch: 3 | loss: 0.1543123\n",
      "\tspeed: 0.0416s/iter; left time: 288.4141s\n",
      "\titers: 700, epoch: 3 | loss: 0.1390960\n",
      "\tspeed: 0.0417s/iter; left time: 284.5239s\n",
      "\titers: 800, epoch: 3 | loss: 0.1357650\n",
      "\tspeed: 0.0422s/iter; left time: 283.8093s\n",
      "\titers: 900, epoch: 3 | loss: 0.1640382\n",
      "\tspeed: 0.0416s/iter; left time: 275.9675s\n",
      "Epoch: 3 running time: 0.6603500644365946 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1671244 Vali Loss: 0.2403744 Test Loss: 0.3891172\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1505874\n",
      "\tspeed: 0.1201s/iter; left time: 779.1247s\n",
      "\titers: 200, epoch: 4 | loss: 0.1424225\n",
      "\tspeed: 0.0420s/iter; left time: 268.3882s\n",
      "\titers: 300, epoch: 4 | loss: 0.2556826\n",
      "\tspeed: 0.0422s/iter; left time: 265.0678s\n",
      "\titers: 400, epoch: 4 | loss: 0.1678195\n",
      "\tspeed: 0.0414s/iter; left time: 256.4716s\n",
      "\titers: 500, epoch: 4 | loss: 0.2357220\n",
      "\tspeed: 0.0416s/iter; left time: 253.0795s\n",
      "\titers: 600, epoch: 4 | loss: 0.2023128\n",
      "\tspeed: 0.0417s/iter; left time: 249.8521s\n",
      "\titers: 700, epoch: 4 | loss: 0.1220490\n",
      "\tspeed: 0.0428s/iter; left time: 251.9283s\n",
      "\titers: 800, epoch: 4 | loss: 0.1661522\n",
      "\tspeed: 0.0420s/iter; left time: 242.8434s\n",
      "\titers: 900, epoch: 4 | loss: 0.1767304\n",
      "\tspeed: 0.0417s/iter; left time: 237.1997s\n",
      "Epoch: 4 running time: 0.661781394481659 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1644363 Vali Loss: 0.2195735 Test Loss: 0.3726886\n",
      "Validation loss decreased (0.237424 --> 0.219574).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1773134\n",
      "\tspeed: 0.1244s/iter; left time: 689.9702s\n",
      "\titers: 200, epoch: 5 | loss: 0.1255830\n",
      "\tspeed: 0.0416s/iter; left time: 226.6639s\n",
      "\titers: 300, epoch: 5 | loss: 0.1193427\n",
      "\tspeed: 0.0416s/iter; left time: 222.6041s\n",
      "\titers: 400, epoch: 5 | loss: 0.1698360\n",
      "\tspeed: 0.0416s/iter; left time: 218.2126s\n",
      "\titers: 500, epoch: 5 | loss: 0.1337725\n",
      "\tspeed: 0.0423s/iter; left time: 217.7648s\n",
      "\titers: 600, epoch: 5 | loss: 0.1658793\n",
      "\tspeed: 0.0413s/iter; left time: 208.2563s\n",
      "\titers: 700, epoch: 5 | loss: 0.1875621\n",
      "\tspeed: 0.0417s/iter; left time: 206.4398s\n",
      "\titers: 800, epoch: 5 | loss: 0.1225298\n",
      "\tspeed: 0.0412s/iter; left time: 199.7934s\n",
      "\titers: 900, epoch: 5 | loss: 0.1603958\n",
      "\tspeed: 0.0418s/iter; left time: 198.5854s\n",
      "Epoch: 5 running time: 0.6587576349576314 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.1532387 Vali Loss: 0.2136416 Test Loss: 0.3710597\n",
      "Validation loss decreased (0.219574 --> 0.213642).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1444450\n",
      "\tspeed: 0.1242s/iter; left time: 572.2034s\n",
      "\titers: 200, epoch: 6 | loss: 0.1285003\n",
      "\tspeed: 0.0416s/iter; left time: 187.6034s\n",
      "\titers: 300, epoch: 6 | loss: 0.1322310\n",
      "\tspeed: 0.0418s/iter; left time: 183.9824s\n",
      "\titers: 400, epoch: 6 | loss: 0.1218058\n",
      "\tspeed: 0.0422s/iter; left time: 181.8759s\n",
      "\titers: 500, epoch: 6 | loss: 0.1354525\n",
      "\tspeed: 0.0410s/iter; left time: 172.5590s\n",
      "\titers: 600, epoch: 6 | loss: 0.1586091\n",
      "\tspeed: 0.0413s/iter; left time: 169.4818s\n",
      "\titers: 700, epoch: 6 | loss: 0.1131854\n",
      "\tspeed: 0.0412s/iter; left time: 164.9178s\n",
      "\titers: 800, epoch: 6 | loss: 0.1432222\n",
      "\tspeed: 0.0411s/iter; left time: 160.5055s\n",
      "\titers: 900, epoch: 6 | loss: 0.1418107\n",
      "\tspeed: 0.0413s/iter; left time: 157.1124s\n",
      "Epoch: 6 running time: 0.6554659406344095 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.1480593 Vali Loss: 0.2241328 Test Loss: 0.3779618\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1416633\n",
      "\tspeed: 0.1198s/iter; left time: 439.1899s\n",
      "\titers: 200, epoch: 7 | loss: 0.1592746\n",
      "\tspeed: 0.0410s/iter; left time: 146.2238s\n",
      "\titers: 300, epoch: 7 | loss: 0.1746203\n",
      "\tspeed: 0.0411s/iter; left time: 142.5466s\n",
      "\titers: 400, epoch: 7 | loss: 0.1233166\n",
      "\tspeed: 0.0414s/iter; left time: 139.3104s\n",
      "\titers: 500, epoch: 7 | loss: 0.1567521\n",
      "\tspeed: 0.0412s/iter; left time: 134.6476s\n",
      "\titers: 600, epoch: 7 | loss: 0.1532848\n",
      "\tspeed: 0.0435s/iter; left time: 137.5686s\n",
      "\titers: 700, epoch: 7 | loss: 0.1331247\n",
      "\tspeed: 0.0422s/iter; left time: 129.2832s\n",
      "\titers: 800, epoch: 7 | loss: 0.1659495\n",
      "\tspeed: 0.0411s/iter; left time: 121.8576s\n",
      "\titers: 900, epoch: 7 | loss: 0.1159406\n",
      "\tspeed: 0.0419s/iter; left time: 120.1569s\n",
      "Epoch: 7 running time: 0.6590675234794616 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.1475889 Vali Loss: 0.2195016 Test Loss: 0.3746070\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1614273\n",
      "\tspeed: 0.1219s/iter; left time: 332.1754s\n",
      "\titers: 200, epoch: 8 | loss: 0.1280121\n",
      "\tspeed: 0.0413s/iter; left time: 108.4573s\n",
      "\titers: 300, epoch: 8 | loss: 0.1291548\n",
      "\tspeed: 0.0419s/iter; left time: 105.8604s\n",
      "\titers: 400, epoch: 8 | loss: 0.1368238\n",
      "\tspeed: 0.0413s/iter; left time: 100.1597s\n",
      "\titers: 500, epoch: 8 | loss: 0.1330273\n",
      "\tspeed: 0.0414s/iter; left time: 96.1807s\n",
      "\titers: 600, epoch: 8 | loss: 0.1594829\n",
      "\tspeed: 0.0413s/iter; left time: 91.8717s\n",
      "\titers: 700, epoch: 8 | loss: 0.1077357\n",
      "\tspeed: 0.0413s/iter; left time: 87.6540s\n",
      "\titers: 800, epoch: 8 | loss: 0.1062815\n",
      "\tspeed: 0.0412s/iter; left time: 83.4712s\n",
      "\titers: 900, epoch: 8 | loss: 0.1380857\n",
      "\tspeed: 0.0412s/iter; left time: 79.3059s\n",
      "Epoch: 8 running time: 0.6559543490409852 min.\n",
      "Epoch: 8, Steps: 941 | Train Loss: 0.1471529 Vali Loss: 0.2222877 Test Loss: 0.3764268\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_2_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.37598633766174316, mae:0.36164385080337524\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_2_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.4221524\n",
      "\tspeed: 0.0442s/iter; left time: 411.7057s\n",
      "\titers: 200, epoch: 1 | loss: 0.3022940\n",
      "\tspeed: 0.0412s/iter; left time: 379.4394s\n",
      "\titers: 300, epoch: 1 | loss: 0.3190881\n",
      "\tspeed: 0.0421s/iter; left time: 383.1333s\n",
      "\titers: 400, epoch: 1 | loss: 0.3538178\n",
      "\tspeed: 0.0420s/iter; left time: 378.4202s\n",
      "\titers: 500, epoch: 1 | loss: 0.2297910\n",
      "\tspeed: 0.0421s/iter; left time: 374.9146s\n",
      "\titers: 600, epoch: 1 | loss: 0.2097442\n",
      "\tspeed: 0.0418s/iter; left time: 368.3916s\n",
      "\titers: 700, epoch: 1 | loss: 0.2324205\n",
      "\tspeed: 0.0415s/iter; left time: 361.1435s\n",
      "\titers: 800, epoch: 1 | loss: 0.2425459\n",
      "\tspeed: 0.0415s/iter; left time: 357.6179s\n",
      "\titers: 900, epoch: 1 | loss: 0.3420942\n",
      "\tspeed: 0.0424s/iter; left time: 360.6927s\n",
      "Epoch: 1 running time: 0.662228238582611 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.3092180 Vali Loss: 0.2832312 Test Loss: 0.4451061\n",
      "Validation loss decreased (inf --> 0.283231).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1899024\n",
      "\tspeed: 0.1294s/iter; left time: 1082.9657s\n",
      "\titers: 200, epoch: 2 | loss: 0.2064055\n",
      "\tspeed: 0.0418s/iter; left time: 345.3500s\n",
      "\titers: 300, epoch: 2 | loss: 0.2203534\n",
      "\tspeed: 0.0412s/iter; left time: 336.9017s\n",
      "\titers: 400, epoch: 2 | loss: 0.2075656\n",
      "\tspeed: 0.0418s/iter; left time: 337.2778s\n",
      "\titers: 500, epoch: 2 | loss: 0.1645342\n",
      "\tspeed: 0.0418s/iter; left time: 333.1141s\n",
      "\titers: 600, epoch: 2 | loss: 0.1748864\n",
      "\tspeed: 0.0417s/iter; left time: 328.0103s\n",
      "\titers: 700, epoch: 2 | loss: 0.1484652\n",
      "\tspeed: 0.0414s/iter; left time: 321.6127s\n",
      "\titers: 800, epoch: 2 | loss: 0.2393705\n",
      "\tspeed: 0.0407s/iter; left time: 312.5370s\n",
      "\titers: 900, epoch: 2 | loss: 0.1936065\n",
      "\tspeed: 0.0423s/iter; left time: 319.8519s\n",
      "Epoch: 2 running time: 0.660804537932078 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.2024827 Vali Loss: 0.2371813 Test Loss: 0.3859681\n",
      "Validation loss decreased (0.283231 --> 0.237181).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1590785\n",
      "\tspeed: 0.1274s/iter; left time: 946.4960s\n",
      "\titers: 200, epoch: 3 | loss: 0.1916021\n",
      "\tspeed: 0.0428s/iter; left time: 313.8181s\n",
      "\titers: 300, epoch: 3 | loss: 0.1212917\n",
      "\tspeed: 0.0426s/iter; left time: 307.8706s\n",
      "\titers: 400, epoch: 3 | loss: 0.1645994\n",
      "\tspeed: 0.0426s/iter; left time: 303.8560s\n",
      "\titers: 500, epoch: 3 | loss: 0.1566514\n",
      "\tspeed: 0.0420s/iter; left time: 295.1585s\n",
      "\titers: 600, epoch: 3 | loss: 0.1633545\n",
      "\tspeed: 0.0416s/iter; left time: 288.2636s\n",
      "\titers: 700, epoch: 3 | loss: 0.1973340\n",
      "\tspeed: 0.0408s/iter; left time: 278.3610s\n",
      "\titers: 800, epoch: 3 | loss: 0.1457533\n",
      "\tspeed: 0.0414s/iter; left time: 278.2680s\n",
      "\titers: 900, epoch: 3 | loss: 0.1036521\n",
      "\tspeed: 0.0418s/iter; left time: 276.8518s\n",
      "Epoch: 3 running time: 0.6643726348876953 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1698548 Vali Loss: 0.2314968 Test Loss: 0.3865038\n",
      "Validation loss decreased (0.237181 --> 0.231497).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1836326\n",
      "\tspeed: 0.1256s/iter; left time: 814.9567s\n",
      "\titers: 200, epoch: 4 | loss: 0.1178099\n",
      "\tspeed: 0.0418s/iter; left time: 267.2141s\n",
      "\titers: 300, epoch: 4 | loss: 0.1697673\n",
      "\tspeed: 0.0415s/iter; left time: 261.0620s\n",
      "\titers: 400, epoch: 4 | loss: 0.1538090\n",
      "\tspeed: 0.0416s/iter; left time: 257.3929s\n",
      "\titers: 500, epoch: 4 | loss: 0.1281122\n",
      "\tspeed: 0.0416s/iter; left time: 253.5237s\n",
      "\titers: 600, epoch: 4 | loss: 0.1791037\n",
      "\tspeed: 0.0423s/iter; left time: 253.1407s\n",
      "\titers: 700, epoch: 4 | loss: 0.1650171\n",
      "\tspeed: 0.0424s/iter; left time: 249.7931s\n",
      "\titers: 800, epoch: 4 | loss: 0.2254826\n",
      "\tspeed: 0.0420s/iter; left time: 243.3851s\n",
      "\titers: 900, epoch: 4 | loss: 0.1532446\n",
      "\tspeed: 0.0425s/iter; left time: 241.9472s\n",
      "Epoch: 4 running time: 0.6654042363166809 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1541656 Vali Loss: 0.2206749 Test Loss: 0.3899144\n",
      "Validation loss decreased (0.231497 --> 0.220675).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1717126\n",
      "\tspeed: 0.1267s/iter; left time: 702.7097s\n",
      "\titers: 200, epoch: 5 | loss: 0.1353924\n",
      "\tspeed: 0.0421s/iter; left time: 229.2167s\n",
      "\titers: 300, epoch: 5 | loss: 0.1549057\n",
      "\tspeed: 0.0426s/iter; left time: 227.7206s\n",
      "\titers: 400, epoch: 5 | loss: 0.1590300\n",
      "\tspeed: 0.0430s/iter; left time: 225.5789s\n",
      "\titers: 500, epoch: 5 | loss: 0.0945694\n",
      "\tspeed: 0.0433s/iter; left time: 222.6866s\n",
      "\titers: 600, epoch: 5 | loss: 0.1322617\n",
      "\tspeed: 0.0417s/iter; left time: 210.3032s\n",
      "\titers: 700, epoch: 5 | loss: 0.1762114\n",
      "\tspeed: 0.0423s/iter; left time: 209.3977s\n",
      "\titers: 800, epoch: 5 | loss: 0.2514132\n",
      "\tspeed: 0.0423s/iter; left time: 205.2091s\n",
      "\titers: 900, epoch: 5 | loss: 0.1239216\n",
      "\tspeed: 0.0430s/iter; left time: 204.1813s\n",
      "Epoch: 5 running time: 0.6732069174448649 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.1442522 Vali Loss: 0.2203114 Test Loss: 0.3810680\n",
      "Validation loss decreased (0.220675 --> 0.220311).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1286100\n",
      "\tspeed: 0.1268s/iter; left time: 583.9553s\n",
      "\titers: 200, epoch: 6 | loss: 0.1503711\n",
      "\tspeed: 0.0426s/iter; left time: 191.7948s\n",
      "\titers: 300, epoch: 6 | loss: 0.1217610\n",
      "\tspeed: 0.0420s/iter; left time: 185.2128s\n",
      "\titers: 400, epoch: 6 | loss: 0.1419614\n",
      "\tspeed: 0.0422s/iter; left time: 181.9072s\n",
      "\titers: 500, epoch: 6 | loss: 0.1411858\n",
      "\tspeed: 0.0413s/iter; left time: 173.6357s\n",
      "\titers: 600, epoch: 6 | loss: 0.1317008\n",
      "\tspeed: 0.0415s/iter; left time: 170.2887s\n",
      "\titers: 700, epoch: 6 | loss: 0.1172206\n",
      "\tspeed: 0.0424s/iter; left time: 169.9581s\n",
      "\titers: 800, epoch: 6 | loss: 0.1491046\n",
      "\tspeed: 0.0425s/iter; left time: 165.8261s\n",
      "\titers: 900, epoch: 6 | loss: 0.1402738\n",
      "\tspeed: 0.0426s/iter; left time: 161.9548s\n",
      "Epoch: 6 running time: 0.6652531226476034 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.1389750 Vali Loss: 0.2172811 Test Loss: 0.3756799\n",
      "Validation loss decreased (0.220311 --> 0.217281).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1235027\n",
      "\tspeed: 0.1252s/iter; left time: 458.7720s\n",
      "\titers: 200, epoch: 7 | loss: 0.0993671\n",
      "\tspeed: 0.0421s/iter; left time: 150.1616s\n",
      "\titers: 300, epoch: 7 | loss: 0.1172262\n",
      "\tspeed: 0.0416s/iter; left time: 144.0720s\n",
      "\titers: 400, epoch: 7 | loss: 0.1247887\n",
      "\tspeed: 0.0426s/iter; left time: 143.4393s\n",
      "\titers: 500, epoch: 7 | loss: 0.1151194\n",
      "\tspeed: 0.0418s/iter; left time: 136.5916s\n",
      "\titers: 600, epoch: 7 | loss: 0.1377131\n",
      "\tspeed: 0.0423s/iter; left time: 133.7232s\n",
      "\titers: 700, epoch: 7 | loss: 0.1034992\n",
      "\tspeed: 0.0423s/iter; left time: 129.5021s\n",
      "\titers: 800, epoch: 7 | loss: 0.1134244\n",
      "\tspeed: 0.0426s/iter; left time: 126.1753s\n",
      "\titers: 900, epoch: 7 | loss: 0.1425553\n",
      "\tspeed: 0.0431s/iter; left time: 123.3686s\n",
      "Epoch: 7 running time: 0.6683483322461446 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.1358188 Vali Loss: 0.2179322 Test Loss: 0.3747880\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1226921\n",
      "\tspeed: 0.1209s/iter; left time: 329.4202s\n",
      "\titers: 200, epoch: 8 | loss: 0.1632318\n",
      "\tspeed: 0.0416s/iter; left time: 109.1855s\n",
      "\titers: 300, epoch: 8 | loss: 0.0959632\n",
      "\tspeed: 0.0423s/iter; left time: 106.7425s\n",
      "\titers: 400, epoch: 8 | loss: 0.1597323\n",
      "\tspeed: 0.0368s/iter; left time: 89.1604s\n",
      "\titers: 500, epoch: 8 | loss: 0.1169432\n",
      "\tspeed: 0.0339s/iter; left time: 78.6710s\n",
      "\titers: 600, epoch: 8 | loss: 0.1297148\n",
      "\tspeed: 0.0329s/iter; left time: 73.1398s\n",
      "\titers: 700, epoch: 8 | loss: 0.1734155\n",
      "\tspeed: 0.0408s/iter; left time: 86.6240s\n",
      "\titers: 800, epoch: 8 | loss: 0.1339870\n",
      "\tspeed: 0.0383s/iter; left time: 77.5757s\n",
      "\titers: 900, epoch: 8 | loss: 0.1039812\n",
      "\tspeed: 0.0316s/iter; left time: 60.8665s\n",
      "Epoch: 8 running time: 0.5940584341684977 min.\n",
      "Epoch: 8, Steps: 941 | Train Loss: 0.1357500 Vali Loss: 0.2137352 Test Loss: 0.3758407\n",
      "Validation loss decreased (0.217281 --> 0.213735).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1299870\n",
      "\tspeed: 0.1221s/iter; left time: 217.6702s\n",
      "\titers: 200, epoch: 9 | loss: 0.1501092\n",
      "\tspeed: 0.0421s/iter; left time: 70.9275s\n",
      "\titers: 300, epoch: 9 | loss: 0.1522894\n",
      "\tspeed: 0.0429s/iter; left time: 67.9648s\n",
      "\titers: 400, epoch: 9 | loss: 0.1450945\n",
      "\tspeed: 0.0427s/iter; left time: 63.2971s\n",
      "\titers: 500, epoch: 9 | loss: 0.1441568\n",
      "\tspeed: 0.0428s/iter; left time: 59.1845s\n",
      "\titers: 600, epoch: 9 | loss: 0.1496249\n",
      "\tspeed: 0.0414s/iter; left time: 53.1212s\n",
      "\titers: 700, epoch: 9 | loss: 0.1019884\n",
      "\tspeed: 0.0424s/iter; left time: 50.1710s\n",
      "\titers: 800, epoch: 9 | loss: 0.1744356\n",
      "\tspeed: 0.0426s/iter; left time: 46.1024s\n",
      "\titers: 900, epoch: 9 | loss: 0.1388854\n",
      "\tspeed: 0.0415s/iter; left time: 40.7768s\n",
      "Epoch: 9 running time: 0.6706543604532877 min.\n",
      "Epoch: 9, Steps: 941 | Train Loss: 0.1345192 Vali Loss: 0.2141867 Test Loss: 0.3740620\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1065069\n",
      "\tspeed: 0.1227s/iter; left time: 103.2917s\n",
      "\titers: 200, epoch: 10 | loss: 0.1462813\n",
      "\tspeed: 0.0422s/iter; left time: 31.3443s\n",
      "\titers: 300, epoch: 10 | loss: 0.1166390\n",
      "\tspeed: 0.0425s/iter; left time: 27.2685s\n",
      "\titers: 400, epoch: 10 | loss: 0.1132310\n",
      "\tspeed: 0.0430s/iter; left time: 23.3031s\n",
      "\titers: 500, epoch: 10 | loss: 0.1061669\n",
      "\tspeed: 0.0424s/iter; left time: 18.7513s\n",
      "\titers: 600, epoch: 10 | loss: 0.1742484\n",
      "\tspeed: 0.0427s/iter; left time: 14.6165s\n",
      "\titers: 700, epoch: 10 | loss: 0.1317799\n",
      "\tspeed: 0.0430s/iter; left time: 10.4036s\n",
      "\titers: 800, epoch: 10 | loss: 0.1238614\n",
      "\tspeed: 0.0424s/iter; left time: 6.0166s\n",
      "\titers: 900, epoch: 10 | loss: 0.1375245\n",
      "\tspeed: 0.0424s/iter; left time: 1.7799s\n",
      "Epoch: 10 running time: 0.6735942403475443 min.\n",
      "Epoch: 10, Steps: 941 | Train Loss: 0.1345916 Vali Loss: 0.2165541 Test Loss: 0.3745810\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast_2_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.3768013119697571, mae:0.3561086356639862\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "dataset = 'FR_data.csv'\n",
    "\n",
    "!python -u /vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path $current_path \\\n",
    "  --data_path $dataset \\\n",
    "  --model_id 2 \\\n",
    "  --model \"Informer\" \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test size = 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_2_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 8641\n",
      "test 4297\n",
      "\titers: 100, epoch: 1 | loss: 0.4307346\n",
      "\tspeed: 0.0659s/iter; left time: 613.9549s\n",
      "\titers: 200, epoch: 1 | loss: 0.3016012\n",
      "\tspeed: 0.0416s/iter; left time: 382.9985s\n",
      "\titers: 300, epoch: 1 | loss: 0.2942957\n",
      "\tspeed: 0.0433s/iter; left time: 394.7428s\n",
      "\titers: 400, epoch: 1 | loss: 0.2671357\n",
      "\tspeed: 0.0464s/iter; left time: 418.4276s\n",
      "\titers: 500, epoch: 1 | loss: 0.2435258\n",
      "\tspeed: 0.0450s/iter; left time: 400.9178s\n",
      "\titers: 600, epoch: 1 | loss: 0.2217858\n",
      "\tspeed: 0.0455s/iter; left time: 401.1528s\n",
      "\titers: 700, epoch: 1 | loss: 0.2125417\n",
      "\tspeed: 0.0454s/iter; left time: 395.8421s\n",
      "\titers: 800, epoch: 1 | loss: 0.1906348\n",
      "\tspeed: 0.0456s/iter; left time: 392.4626s\n",
      "\titers: 900, epoch: 1 | loss: 0.2647261\n",
      "\tspeed: 0.0457s/iter; left time: 388.5857s\n",
      "Epoch: 1 running time: 0.7219364841779073 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.3047330 Vali Loss: 0.4236676 Test Loss: 0.3926425\n",
      "Validation loss decreased (inf --> 0.423668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1999377\n",
      "\tspeed: 0.1295s/iter; left time: 1084.2032s\n",
      "\titers: 200, epoch: 2 | loss: 0.2411886\n",
      "\tspeed: 0.0456s/iter; left time: 376.9328s\n",
      "\titers: 300, epoch: 2 | loss: 0.1997966\n",
      "\tspeed: 0.0457s/iter; left time: 373.3974s\n",
      "\titers: 400, epoch: 2 | loss: 0.2423015\n",
      "\tspeed: 0.0457s/iter; left time: 368.6864s\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py\", line 156, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/exp/exp_long_term_forecasting.py\", line 159, in train\n",
      "    loss.backward()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "dataset = 'FR_data.csv'\n",
    "\n",
    "!python -u /vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path $current_path \\\n",
    "  --data_path $dataset \\\n",
    "  --model_id 2 \\\n",
    "  --model \"Informer\" \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test size=15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_2_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 6481\n",
      "test 6457\n",
      "\titers: 100, epoch: 1 | loss: 0.4307346\n",
      "\tspeed: 0.0617s/iter; left time: 574.1480s\n",
      "\titers: 200, epoch: 1 | loss: 0.3016012\n",
      "\tspeed: 0.0419s/iter; left time: 386.2439s\n",
      "\titers: 300, epoch: 1 | loss: 0.2942957\n",
      "\tspeed: 0.0414s/iter; left time: 376.7422s\n",
      "\titers: 400, epoch: 1 | loss: 0.2671357\n",
      "\tspeed: 0.0417s/iter; left time: 376.0170s\n",
      "\titers: 500, epoch: 1 | loss: 0.2435258\n",
      "\tspeed: 0.0418s/iter; left time: 372.3048s\n",
      "\titers: 600, epoch: 1 | loss: 0.2217858\n",
      "\tspeed: 0.0418s/iter; left time: 367.9268s\n",
      "\titers: 700, epoch: 1 | loss: 0.2125417\n",
      "\tspeed: 0.0418s/iter; left time: 364.1971s\n",
      "\titers: 800, epoch: 1 | loss: 0.1906348\n",
      "\tspeed: 0.0417s/iter; left time: 359.4593s\n",
      "\titers: 900, epoch: 1 | loss: 0.2647261\n",
      "\tspeed: 0.0415s/iter; left time: 353.4896s\n",
      "Epoch: 1 running time: 0.6700607419013977 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.3047330 Vali Loss: 0.3466743 Test Loss: 0.4806783\n",
      "Validation loss decreased (inf --> 0.346674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2324897\n",
      "\tspeed: 0.1342s/iter; left time: 1123.5569s\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py\", line 156, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/exp/exp_long_term_forecasting.py\", line 159, in train\n",
      "    loss.backward()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "dataset = 'FR_data.csv'\n",
    "\n",
    "!python -u /vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path $current_path \\\n",
    "  --data_path $dataset \\\n",
    "  --model_id 2 \\\n",
    "  --model \"Informer\" \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time LLM\n",
    "## small, 15%, 15%\n",
    "\n",
    "### torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 610.88 MiB is free. Process 42461 has 2.24 GiB memory in use. Process 20767 has 1.78 GiB memory in use. Process 10768 has 2.56 GiB memory in use. Process 42631 has 13.69 GiB memory in use. Process 47813 has 7.21 GiB memory in use. Including non-PyTorch memory, this process has 3.63 GiB memory in use. Of the allocated memory 2.62 GiB is allocated by PyTorch, and 338.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: Tesla V100-PCIE-32GB\n",
      "Device 1: Tesla V100-PCIE-32GB\n",
      "Device 2: Quadro RTX 6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the number of available CUDA devices\n",
    "num_devices = torch.cuda.device_count()\n",
    "\n",
    "# Loop through each device and print its name\n",
    "for i in range(num_devices):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "[2024-05-03 15:31:27,516] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 15:31:28,873] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 15:31:28,873] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 15:31:28,873] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 15:31:29,768] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-03 15:31:29,769] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 15:31:30,539] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 15:31:30,540] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 15:31:30,540] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 15:31:30,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 15:31:30,541] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 15:31:30,541] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 15:31:30,541] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 15:31:30,541] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 15:31:30,541] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 15:31:30,541] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 15:31:31,003] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 15:31:31,004] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:31:31,004] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 89.18 GB, percent = 11.8%\n",
      "[2024-05-03 15:31:31,143] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 15:31:31,143] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:31:31,144] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 89.22 GB, percent = 11.8%\n",
      "[2024-05-03 15:31:31,144] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 15:31:31,313] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 15:31:31,315] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:31:31,315] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 89.25 GB, percent = 11.8%\n",
      "[2024-05-03 15:31:31,316] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 15:31:31,316] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 15:31:31,316] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 15:31:31,316] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 15:31:31,317] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7faa79743610>\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 15:31:31,318] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 15:31:31,319] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 15:31:31,320] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 15:31:31,321] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:15,  6.72it/s]\titers: 100, epoch: 1 | loss: 0.5468196\n",
      "\tspeed: 0.2003s/iter; left time: 734.1552s\n",
      "199it [00:30,  7.22it/s]\titers: 200, epoch: 1 | loss: 0.4214458\n",
      "\tspeed: 0.1453s/iter; left time: 518.0681s\n",
      "299it [00:45,  6.76it/s]\titers: 300, epoch: 1 | loss: 0.4011628\n",
      "\tspeed: 0.1504s/iter; left time: 521.3495s\n",
      "399it [01:00,  6.01it/s]\titers: 400, epoch: 1 | loss: 0.5255764\n",
      "\tspeed: 0.1471s/iter; left time: 495.2141s\n",
      "499it [01:14,  6.59it/s]\titers: 500, epoch: 1 | loss: 0.2808782\n",
      "\tspeed: 0.1478s/iter; left time: 482.6114s\n",
      "599it [01:30,  6.71it/s]\titers: 600, epoch: 1 | loss: 0.5445550\n",
      "\tspeed: 0.1548s/iter; left time: 490.0809s\n",
      "699it [01:45,  7.23it/s]\titers: 700, epoch: 1 | loss: 0.2627008\n",
      "\tspeed: 0.1484s/iter; left time: 454.8922s\n",
      "799it [02:00,  7.21it/s]\titers: 800, epoch: 1 | loss: 0.3114898\n",
      "\tspeed: 0.1523s/iter; left time: 451.8232s\n",
      "899it [02:16,  5.85it/s]\titers: 900, epoch: 1 | loss: 0.2767449\n",
      "\tspeed: 0.1640s/iter; left time: 470.0796s\n",
      "999it [02:32,  6.19it/s]\titers: 1000, epoch: 1 | loss: 0.2889755\n",
      "\tspeed: 0.1538s/iter; left time: 425.2956s\n",
      "1099it [02:47,  7.41it/s]\titers: 1100, epoch: 1 | loss: 0.2072158\n",
      "\tspeed: 0.1547s/iter; left time: 412.5457s\n",
      "1199it [03:02,  6.28it/s]\titers: 1200, epoch: 1 | loss: 0.1756039\n",
      "\tspeed: 0.1485s/iter; left time: 380.9509s\n",
      "1299it [03:17,  7.17it/s]\titers: 1300, epoch: 1 | loss: 0.1881783\n",
      "\tspeed: 0.1536s/iter; left time: 378.8370s\n",
      "1399it [03:33,  7.34it/s]\titers: 1400, epoch: 1 | loss: 0.2366187\n",
      "\tspeed: 0.1521s/iter; left time: 359.9760s\n",
      "1499it [03:47,  7.32it/s]\titers: 1500, epoch: 1 | loss: 0.4451137\n",
      "\tspeed: 0.1472s/iter; left time: 333.5190s\n",
      "1599it [04:02,  7.09it/s]\titers: 1600, epoch: 1 | loss: 0.4389757\n",
      "\tspeed: 0.1503s/iter; left time: 325.5284s\n",
      "1699it [04:17,  5.95it/s]\titers: 1700, epoch: 1 | loss: 0.2678942\n",
      "\tspeed: 0.1499s/iter; left time: 309.6764s\n",
      "1799it [04:32,  7.13it/s]\titers: 1800, epoch: 1 | loss: 0.2379295\n",
      "\tspeed: 0.1463s/iter; left time: 287.5315s\n",
      "1899it [04:47,  6.17it/s]\titers: 1900, epoch: 1 | loss: 0.1710269\n",
      "\tspeed: 0.1512s/iter; left time: 282.0733s\n",
      "1999it [05:02,  6.78it/s]\titers: 2000, epoch: 1 | loss: 0.1779455\n",
      "\tspeed: 0.1474s/iter; left time: 260.2522s\n",
      "2099it [05:17,  6.90it/s]\titers: 2100, epoch: 1 | loss: 0.2390940\n",
      "\tspeed: 0.1471s/iter; left time: 245.0705s\n",
      "2199it [05:32,  7.43it/s]\titers: 2200, epoch: 1 | loss: 0.4671702\n",
      "\tspeed: 0.1508s/iter; left time: 236.0952s\n",
      "2299it [05:45,  7.29it/s]\titers: 2300, epoch: 1 | loss: 0.2660964\n",
      "\tspeed: 0.1376s/iter; left time: 201.6830s\n",
      "2399it [06:00,  6.20it/s]\titers: 2400, epoch: 1 | loss: 0.4123612\n",
      "\tspeed: 0.1493s/iter; left time: 203.9067s\n",
      "2499it [06:14,  7.27it/s]\titers: 2500, epoch: 1 | loss: 0.1834874\n",
      "\tspeed: 0.1407s/iter; left time: 178.1314s\n",
      "2599it [06:28,  7.25it/s]\titers: 2600, epoch: 1 | loss: 0.2996213\n",
      "\tspeed: 0.1413s/iter; left time: 164.7838s\n",
      "2699it [06:44,  6.28it/s]\titers: 2700, epoch: 1 | loss: 0.4658841\n",
      "\tspeed: 0.1546s/iter; left time: 164.7644s\n",
      "2799it [07:00,  6.65it/s]\titers: 2800, epoch: 1 | loss: 0.2089916\n",
      "\tspeed: 0.1591s/iter; left time: 153.7254s\n",
      "2899it [07:15,  6.61it/s]\titers: 2900, epoch: 1 | loss: 0.3584861\n",
      "\tspeed: 0.1473s/iter; left time: 127.5209s\n",
      "2999it [07:30,  6.75it/s]\titers: 3000, epoch: 1 | loss: 0.3548172\n",
      "\tspeed: 0.1499s/iter; left time: 114.8503s\n",
      "3099it [07:44,  6.36it/s]\titers: 3100, epoch: 1 | loss: 0.3082316\n",
      "\tspeed: 0.1497s/iter; left time: 99.6967s\n",
      "3199it [07:59,  6.72it/s]\titers: 3200, epoch: 1 | loss: 0.4097749\n",
      "\tspeed: 0.1485s/iter; left time: 84.0279s\n",
      "3299it [08:15,  7.03it/s]\titers: 3300, epoch: 1 | loss: 0.2170641\n",
      "\tspeed: 0.1514s/iter; left time: 70.5686s\n",
      "3399it [08:29,  6.03it/s]\titers: 3400, epoch: 1 | loss: 0.4186157\n",
      "\tspeed: 0.1447s/iter; left time: 52.9657s\n",
      "3499it [08:44,  6.84it/s]\titers: 3500, epoch: 1 | loss: 0.2876329\n",
      "\tspeed: 0.1528s/iter; left time: 40.6424s\n",
      "3599it [08:59,  6.00it/s]\titers: 3600, epoch: 1 | loss: 0.3456867\n",
      "\tspeed: 0.1467s/iter; left time: 24.3444s\n",
      "3699it [09:14,  7.14it/s]\titers: 3700, epoch: 1 | loss: 0.2103202\n",
      "\tspeed: 0.1515s/iter; left time: 9.9983s\n",
      "3765it [09:24,  6.67it/s]\n",
      "Epoch: 1 cost time: 564.7272717952728\n",
      "810it [01:06, 12.18it/s]\n",
      "807it [01:04, 12.60it/s]\n",
      "Epoch: 1 | Train Loss: 0.3082688 Vali Loss: 0.3276033 Test Loss: 0.3916928 MAE Loss: 0.3958873\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "Total time: 11.988454163074493 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate 0.1 and COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 00:55:33,780] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 00:55:34,706] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 00:55:34,706] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 00:55:34,706] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 00:55:35,629] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 00:55:35,630] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 00:55:36,489] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 00:55:36,490] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 00:55:36,490] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 00:55:36,491] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 00:55:36,491] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 00:55:36,491] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 00:55:36,492] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 00:55:36,492] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 00:55:36,492] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 00:55:36,492] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 00:55:36,760] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 00:55:36,760] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-04 00:55:36,760] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.55 GB, percent = 16.0%\n",
      "[2024-05-04 00:55:36,877] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 00:55:36,878] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 00:55:36,878] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.65 GB, percent = 16.0%\n",
      "[2024-05-04 00:55:36,878] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 00:55:36,998] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 00:55:36,999] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 00:55:36,999] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 120.91 GB, percent = 16.0%\n",
      "[2024-05-04 00:55:36,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 00:55:36,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 00:55:36,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 00:55:36,999] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.1], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8efcb28d90>\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 00:55:37,000] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 00:55:37,001] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:06, 19.71it/s]\titers: 100, epoch: 1 | loss: 2.3399429\n",
      "\tspeed: 0.1048s/iter; left time: 384.2641s\n",
      "197it [00:11, 22.15it/s]\titers: 200, epoch: 1 | loss: 0.7920554\n",
      "\tspeed: 0.0490s/iter; left time: 174.8364s\n",
      "297it [00:16, 21.15it/s]\titers: 300, epoch: 1 | loss: 0.8496119\n",
      "\tspeed: 0.0480s/iter; left time: 166.2888s\n",
      "399it [00:21, 19.41it/s]\titers: 400, epoch: 1 | loss: 0.7877753\n",
      "\tspeed: 0.0529s/iter; left time: 178.0721s\n",
      "499it [00:27, 19.71it/s]\titers: 500, epoch: 1 | loss: 0.5706695\n",
      "\tspeed: 0.0521s/iter; left time: 170.2929s\n",
      "598it [00:32, 19.76it/s]\titers: 600, epoch: 1 | loss: 0.6946025\n",
      "\tspeed: 0.0507s/iter; left time: 160.4279s\n",
      "699it [00:37, 19.68it/s]\titers: 700, epoch: 1 | loss: 0.6073106\n",
      "\tspeed: 0.0509s/iter; left time: 156.0419s\n",
      "797it [00:42, 19.04it/s]\titers: 800, epoch: 1 | loss: 0.4599146\n",
      "\tspeed: 0.0558s/iter; left time: 165.4963s\n",
      "898it [00:47, 19.78it/s]\titers: 900, epoch: 1 | loss: 0.4064088\n",
      "\tspeed: 0.0505s/iter; left time: 144.7993s\n",
      "998it [00:52, 19.55it/s]\titers: 1000, epoch: 1 | loss: 0.4211301\n",
      "\tspeed: 0.0506s/iter; left time: 140.0576s\n",
      "1098it [00:58, 19.61it/s]\titers: 1100, epoch: 1 | loss: 0.3501645\n",
      "\tspeed: 0.0528s/iter; left time: 140.6342s\n",
      "1198it [01:03, 19.80it/s]\titers: 1200, epoch: 1 | loss: 0.4622425\n",
      "\tspeed: 0.0514s/iter; left time: 131.7736s\n",
      "1299it [01:08, 19.71it/s]\titers: 1300, epoch: 1 | loss: 0.5496085\n",
      "\tspeed: 0.0505s/iter; left time: 124.6213s\n",
      "1398it [01:13, 19.12it/s]\titers: 1400, epoch: 1 | loss: 0.4305887\n",
      "\tspeed: 0.0497s/iter; left time: 117.5330s\n",
      "1498it [01:18, 19.79it/s]\titers: 1500, epoch: 1 | loss: 0.5792931\n",
      "\tspeed: 0.0503s/iter; left time: 113.8895s\n",
      "1598it [01:23, 19.74it/s]\titers: 1600, epoch: 1 | loss: 0.8634565\n",
      "\tspeed: 0.0514s/iter; left time: 111.3422s\n",
      "1698it [01:28, 19.72it/s]\titers: 1700, epoch: 1 | loss: 0.4591581\n",
      "\tspeed: 0.0513s/iter; left time: 106.0389s\n",
      "1798it [01:33, 19.44it/s]\titers: 1800, epoch: 1 | loss: 0.5615884\n",
      "\tspeed: 0.0497s/iter; left time: 97.6214s\n",
      "1899it [01:38, 19.12it/s]\titers: 1900, epoch: 1 | loss: 0.2650222\n",
      "\tspeed: 0.0521s/iter; left time: 97.2151s\n",
      "1998it [01:43, 19.35it/s]\titers: 2000, epoch: 1 | loss: 0.2934964\n",
      "\tspeed: 0.0513s/iter; left time: 90.5302s\n",
      "2099it [01:48, 24.81it/s]\titers: 2100, epoch: 1 | loss: 0.4234182\n",
      "\tspeed: 0.0438s/iter; left time: 73.0245s\n",
      "2198it [01:52, 24.55it/s]\titers: 2200, epoch: 1 | loss: 0.8064783\n",
      "\tspeed: 0.0407s/iter; left time: 63.7582s\n",
      "2297it [01:56, 24.29it/s]\titers: 2300, epoch: 1 | loss: 0.4523402\n",
      "\tspeed: 0.0426s/iter; left time: 62.4038s\n",
      "2399it [02:00, 24.59it/s]\titers: 2400, epoch: 1 | loss: 0.8422226\n",
      "\tspeed: 0.0418s/iter; left time: 57.0409s\n",
      "2498it [02:04, 24.41it/s]\titers: 2500, epoch: 1 | loss: 0.3995953\n",
      "\tspeed: 0.0408s/iter; left time: 51.7143s\n",
      "2597it [02:09, 24.43it/s]\titers: 2600, epoch: 1 | loss: 0.5259956\n",
      "\tspeed: 0.0411s/iter; left time: 47.9438s\n",
      "2698it [02:14, 18.66it/s]\titers: 2700, epoch: 1 | loss: 0.6131414\n",
      "\tspeed: 0.0523s/iter; left time: 55.7895s\n",
      "2799it [02:19, 19.30it/s]\titers: 2800, epoch: 1 | loss: 0.3428200\n",
      "\tspeed: 0.0535s/iter; left time: 51.6506s\n",
      "2899it [02:24, 19.18it/s]\titers: 2900, epoch: 1 | loss: 0.6192741\n",
      "\tspeed: 0.0509s/iter; left time: 44.1182s\n",
      "2997it [02:29, 20.83it/s]\titers: 3000, epoch: 1 | loss: 0.6037298\n",
      "\tspeed: 0.0507s/iter; left time: 38.8089s\n",
      "3099it [02:35, 18.09it/s]\titers: 3100, epoch: 1 | loss: 0.5096310\n",
      "\tspeed: 0.0525s/iter; left time: 34.9383s\n",
      "3198it [02:40, 21.59it/s]\titers: 3200, epoch: 1 | loss: 0.8142599\n",
      "\tspeed: 0.0518s/iter; left time: 29.3185s\n",
      "3298it [02:45, 19.31it/s]\titers: 3300, epoch: 1 | loss: 0.3007298\n",
      "\tspeed: 0.0535s/iter; left time: 24.9203s\n",
      "3398it [02:50, 19.55it/s]\titers: 3400, epoch: 1 | loss: 0.7066584\n",
      "\tspeed: 0.0525s/iter; left time: 19.2007s\n",
      "3498it [02:56, 19.68it/s]\titers: 3500, epoch: 1 | loss: 0.7107752\n",
      "\tspeed: 0.0549s/iter; left time: 14.6028s\n",
      "3598it [03:01, 19.28it/s]\titers: 3600, epoch: 1 | loss: 0.6457136\n",
      "\tspeed: 0.0507s/iter; left time: 8.4086s\n",
      "3699it [03:07, 18.12it/s]\titers: 3700, epoch: 1 | loss: 0.4646868\n",
      "\tspeed: 0.0557s/iter; left time: 3.6784s\n",
      "3765it [03:10, 19.76it/s]\n",
      "Epoch: 1 cost time: 190.57677745819092\n",
      "810it [00:21, 37.58it/s]\n",
      "807it [00:22, 36.60it/s]\n",
      "Epoch: 1 | Train Loss: 2.8133810 Vali Loss: 1.0487908 Test Loss: 1.3057802 MAE Loss: 0.8279922\n",
      "lr = 0.0993844171\n",
      "Total time: 4.262420868873596 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.1\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COS, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 01:00:42,930] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 01:00:43,947] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 01:00:43,947] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 01:00:43,947] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 01:00:44,862] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 01:00:44,862] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 01:00:45,821] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 01:00:45,822] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 01:00:45,823] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 01:00:45,823] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 01:00:45,824] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 01:00:45,824] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 01:00:45,824] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 01:00:45,824] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 01:00:45,824] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 01:00:45,824] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 01:00:46,245] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 01:00:46,245] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:00:46,246] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 141.6 GB, percent = 18.8%\n",
      "[2024-05-04 01:00:46,406] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 01:00:46,406] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:00:46,407] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 143.21 GB, percent = 19.0%\n",
      "[2024-05-04 01:00:46,407] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 01:00:46,562] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 01:00:46,563] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:00:46,563] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 144.73 GB, percent = 19.2%\n",
      "[2024-05-04 01:00:46,563] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 01:00:46,563] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 01:00:46,563] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 01:00:46,563] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.01], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f93dcae3a50>\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 01:00:46,564] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 01:00:46,565] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "98it [00:05, 19.74it/s]\titers: 100, epoch: 1 | loss: 0.3833525\n",
      "\tspeed: 0.0991s/iter; left time: 363.4518s\n",
      "199it [00:11, 18.14it/s]\titers: 200, epoch: 1 | loss: 0.4552666\n",
      "\tspeed: 0.0513s/iter; left time: 182.8345s\n",
      "298it [00:16, 19.32it/s]\titers: 300, epoch: 1 | loss: 0.4083411\n",
      "\tspeed: 0.0520s/iter; left time: 180.1069s\n",
      "398it [00:22, 18.00it/s]\titers: 400, epoch: 1 | loss: 0.6283149\n",
      "\tspeed: 0.0581s/iter; left time: 195.4085s\n",
      "498it [00:27, 17.33it/s]\titers: 500, epoch: 1 | loss: 0.4329080\n",
      "\tspeed: 0.0567s/iter; left time: 185.1532s\n",
      "598it [00:33, 17.63it/s]\titers: 600, epoch: 1 | loss: 0.6069039\n",
      "\tspeed: 0.0549s/iter; left time: 173.9277s\n",
      "698it [00:39, 12.99it/s]\titers: 700, epoch: 1 | loss: 0.2976454\n",
      "\tspeed: 0.0610s/iter; left time: 186.8963s\n",
      "799it [00:44, 15.92it/s]\titers: 800, epoch: 1 | loss: 0.4251925\n",
      "\tspeed: 0.0562s/iter; left time: 166.6386s\n",
      "899it [00:49, 22.97it/s]\titers: 900, epoch: 1 | loss: 0.3497310\n",
      "\tspeed: 0.0501s/iter; left time: 143.7281s\n",
      "998it [00:54, 17.70it/s]\titers: 1000, epoch: 1 | loss: 0.3576183\n",
      "\tspeed: 0.0484s/iter; left time: 133.8296s\n",
      "1099it [00:59, 22.52it/s]\titers: 1100, epoch: 1 | loss: 0.2790441\n",
      "\tspeed: 0.0483s/iter; left time: 128.7607s\n",
      "1198it [01:04, 22.76it/s]\titers: 1200, epoch: 1 | loss: 0.2876119\n",
      "\tspeed: 0.0439s/iter; left time: 112.7725s\n",
      "1299it [01:09, 16.51it/s]\titers: 1300, epoch: 1 | loss: 0.3232446\n",
      "\tspeed: 0.0572s/iter; left time: 141.0901s\n",
      "1398it [01:15, 18.89it/s]\titers: 1400, epoch: 1 | loss: 0.3362528\n",
      "\tspeed: 0.0537s/iter; left time: 127.1556s\n",
      "1498it [01:20, 19.80it/s]\titers: 1500, epoch: 1 | loss: 0.5864910\n",
      "\tspeed: 0.0552s/iter; left time: 125.1710s\n",
      "1598it [01:25, 16.45it/s]\titers: 1600, epoch: 1 | loss: 0.4934716\n",
      "\tspeed: 0.0528s/iter; left time: 114.4164s\n",
      "1698it [01:31, 17.16it/s]\titers: 1700, epoch: 1 | loss: 0.3434920\n",
      "\tspeed: 0.0534s/iter; left time: 110.3824s\n",
      "1799it [01:36, 17.48it/s]\titers: 1800, epoch: 1 | loss: 0.3418876\n",
      "\tspeed: 0.0538s/iter; left time: 105.7837s\n",
      "1898it [01:41, 20.05it/s]\titers: 1900, epoch: 1 | loss: 0.2126407\n",
      "\tspeed: 0.0461s/iter; left time: 86.0041s\n",
      "1998it [01:45, 23.09it/s]\titers: 2000, epoch: 1 | loss: 0.2516538\n",
      "\tspeed: 0.0472s/iter; left time: 83.2785s\n",
      "2097it [01:50, 24.43it/s]\titers: 2100, epoch: 1 | loss: 0.2494175\n",
      "\tspeed: 0.0411s/iter; left time: 68.5439s\n",
      "2197it [01:54, 21.58it/s]\titers: 2200, epoch: 1 | loss: 0.7722250\n",
      "\tspeed: 0.0491s/iter; left time: 76.8812s\n",
      "2299it [02:00, 19.08it/s]\titers: 2300, epoch: 1 | loss: 0.3824512\n",
      "\tspeed: 0.0537s/iter; left time: 78.7065s\n",
      "2398it [02:06, 15.90it/s]\titers: 2400, epoch: 1 | loss: 0.5584468\n",
      "\tspeed: 0.0588s/iter; left time: 80.3414s\n",
      "2498it [02:11, 18.05it/s]\titers: 2500, epoch: 1 | loss: 0.3547414\n",
      "\tspeed: 0.0577s/iter; left time: 73.0801s\n",
      "2597it [02:17, 22.18it/s]\titers: 2600, epoch: 1 | loss: 0.4724534\n",
      "\tspeed: 0.0596s/iter; left time: 69.4480s\n",
      "2698it [02:22, 19.66it/s]\titers: 2700, epoch: 1 | loss: 0.5569499\n",
      "\tspeed: 0.0488s/iter; left time: 52.0168s\n",
      "2799it [02:28, 18.37it/s]\titers: 2800, epoch: 1 | loss: 0.2892987\n",
      "\tspeed: 0.0559s/iter; left time: 53.9638s\n",
      "2897it [02:33, 20.49it/s]\titers: 2900, epoch: 1 | loss: 0.5243725\n",
      "\tspeed: 0.0513s/iter; left time: 44.3949s\n",
      "2999it [02:39, 17.36it/s]\titers: 3000, epoch: 1 | loss: 0.5551785\n",
      "\tspeed: 0.0564s/iter; left time: 43.2289s\n",
      "3098it [02:44, 19.04it/s]\titers: 3100, epoch: 1 | loss: 0.4308146\n",
      "\tspeed: 0.0528s/iter; left time: 35.1929s\n",
      "3198it [02:49, 19.82it/s]\titers: 3200, epoch: 1 | loss: 0.4954969\n",
      "\tspeed: 0.0509s/iter; left time: 28.8101s\n",
      "3298it [02:54, 19.26it/s]\titers: 3300, epoch: 1 | loss: 0.4035384\n",
      "\tspeed: 0.0510s/iter; left time: 23.7868s\n",
      "3399it [03:00, 16.37it/s]\titers: 3400, epoch: 1 | loss: 0.4612993\n",
      "\tspeed: 0.0600s/iter; left time: 21.9721s\n",
      "3499it [03:06, 19.38it/s]\titers: 3500, epoch: 1 | loss: 0.4572044\n",
      "\tspeed: 0.0547s/iter; left time: 14.5440s\n",
      "3599it [03:11, 19.59it/s]\titers: 3600, epoch: 1 | loss: 0.4272820\n",
      "\tspeed: 0.0516s/iter; left time: 8.5640s\n",
      "3699it [03:16, 18.58it/s]\titers: 3700, epoch: 1 | loss: 0.3220913\n",
      "\tspeed: 0.0565s/iter; left time: 3.7313s\n",
      "3765it [03:20, 18.79it/s]\n",
      "Epoch: 1 cost time: 200.42578125\n",
      "810it [00:21, 37.89it/s]\n",
      "807it [00:21, 37.21it/s]\n",
      "Epoch: 1 | Train Loss: 0.4341944 Vali Loss: 0.4873109 Test Loss: 0.5950663 MAE Loss: 0.5342518\n",
      "lr = 0.0099384418\n",
      "Total time: 4.399978641668955 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.01\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.001 LR, COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 01:05:42,797] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 01:05:43,797] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 01:05:43,797] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 01:05:43,797] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 01:05:44,691] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 01:05:44,691] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 01:05:45,496] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 01:05:45,497] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 01:05:45,497] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 01:05:45,498] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 01:05:45,498] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 01:05:45,498] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 01:05:45,498] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 01:05:45,499] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 01:05:45,499] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 01:05:45,499] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 01:05:45,775] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 01:05:45,776] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:05:45,776] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.75 GB, percent = 15.2%\n",
      "[2024-05-04 01:05:45,889] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 01:05:45,889] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:05:45,889] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.75 GB, percent = 15.2%\n",
      "[2024-05-04 01:05:45,889] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 01:05:46,006] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 01:05:46,006] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:05:46,006] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.75 GB, percent = 15.2%\n",
      "[2024-05-04 01:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 01:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 01:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 01:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 01:05:46,007] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f99955b3310>\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 01:05:46,008] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 01:05:46,009] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "97it [00:05, 21.81it/s]\titers: 100, epoch: 1 | loss: 0.3218488\n",
      "\tspeed: 0.0931s/iter; left time: 341.4297s\n",
      "197it [00:10, 20.03it/s]\titers: 200, epoch: 1 | loss: 0.3640255\n",
      "\tspeed: 0.0497s/iter; left time: 177.3949s\n",
      "298it [00:15, 19.25it/s]\titers: 300, epoch: 1 | loss: 0.3463034\n",
      "\tspeed: 0.0531s/iter; left time: 184.1536s\n",
      "398it [00:20, 19.35it/s]\titers: 400, epoch: 1 | loss: 0.4982204\n",
      "\tspeed: 0.0503s/iter; left time: 169.4555s\n",
      "499it [00:26, 18.99it/s]\titers: 500, epoch: 1 | loss: 0.3414853\n",
      "\tspeed: 0.0525s/iter; left time: 171.4618s\n",
      "598it [00:31, 18.81it/s]\titers: 600, epoch: 1 | loss: 0.4336272\n",
      "\tspeed: 0.0554s/iter; left time: 175.3656s\n",
      "697it [00:37, 18.15it/s]\titers: 700, epoch: 1 | loss: 0.2342097\n",
      "\tspeed: 0.0554s/iter; left time: 169.8075s\n",
      "798it [00:42, 19.69it/s]\titers: 800, epoch: 1 | loss: 0.4338324\n",
      "\tspeed: 0.0494s/iter; left time: 146.5944s\n",
      "897it [00:47, 22.03it/s]\titers: 900, epoch: 1 | loss: 0.2272563\n",
      "\tspeed: 0.0500s/iter; left time: 143.1758s\n",
      "999it [00:52, 19.83it/s]\titers: 1000, epoch: 1 | loss: 0.3176199\n",
      "\tspeed: 0.0518s/iter; left time: 143.2047s\n",
      "1098it [00:57, 19.82it/s]\titers: 1100, epoch: 1 | loss: 0.2765396\n",
      "\tspeed: 0.0513s/iter; left time: 136.8769s\n",
      "1198it [01:02, 19.82it/s]\titers: 1200, epoch: 1 | loss: 0.2411615\n",
      "\tspeed: 0.0505s/iter; left time: 129.6712s\n",
      "1299it [01:07, 19.74it/s]\titers: 1300, epoch: 1 | loss: 0.2387251\n",
      "\tspeed: 0.0506s/iter; left time: 124.7376s\n",
      "1399it [01:13, 19.56it/s]\titers: 1400, epoch: 1 | loss: 0.2932905\n",
      "\tspeed: 0.0561s/iter; left time: 132.6344s\n",
      "1498it [01:18, 19.80it/s]\titers: 1500, epoch: 1 | loss: 0.4869284\n",
      "\tspeed: 0.0509s/iter; left time: 115.2751s\n",
      "1598it [01:23, 19.80it/s]\titers: 1600, epoch: 1 | loss: 0.4639114\n",
      "\tspeed: 0.0505s/iter; left time: 109.4299s\n",
      "1698it [01:28, 19.78it/s]\titers: 1700, epoch: 1 | loss: 0.2877363\n",
      "\tspeed: 0.0529s/iter; left time: 109.2087s\n",
      "1798it [01:33, 19.76it/s]\titers: 1800, epoch: 1 | loss: 0.3020300\n",
      "\tspeed: 0.0513s/iter; left time: 100.8949s\n",
      "1899it [01:38, 21.15it/s]\titers: 1900, epoch: 1 | loss: 0.1911741\n",
      "\tspeed: 0.0501s/iter; left time: 93.4019s\n",
      "1998it [01:43, 19.75it/s]\titers: 2000, epoch: 1 | loss: 0.2240178\n",
      "\tspeed: 0.0498s/iter; left time: 87.9272s\n",
      "2098it [01:49, 19.12it/s]\titers: 2100, epoch: 1 | loss: 0.2505400\n",
      "\tspeed: 0.0528s/iter; left time: 87.9313s\n",
      "2198it [01:54, 19.85it/s]\titers: 2200, epoch: 1 | loss: 0.7034073\n",
      "\tspeed: 0.0506s/iter; left time: 79.1717s\n",
      "2299it [01:59, 19.83it/s]\titers: 2300, epoch: 1 | loss: 0.3349081\n",
      "\tspeed: 0.0505s/iter; left time: 74.0502s\n",
      "2398it [02:04, 19.78it/s]\titers: 2400, epoch: 1 | loss: 0.4542590\n",
      "\tspeed: 0.0522s/iter; left time: 71.2671s\n",
      "2499it [02:09, 19.71it/s]\titers: 2500, epoch: 1 | loss: 0.2569482\n",
      "\tspeed: 0.0514s/iter; left time: 65.1099s\n",
      "2598it [02:14, 19.82it/s]\titers: 2600, epoch: 1 | loss: 0.4264008\n",
      "\tspeed: 0.0505s/iter; left time: 58.8988s\n",
      "2698it [02:19, 19.79it/s]\titers: 2700, epoch: 1 | loss: 0.5491066\n",
      "\tspeed: 0.0507s/iter; left time: 54.0757s\n",
      "2799it [02:25, 19.42it/s]\titers: 2800, epoch: 1 | loss: 0.2827885\n",
      "\tspeed: 0.0537s/iter; left time: 51.8541s\n",
      "2898it [02:30, 19.76it/s]\titers: 2900, epoch: 1 | loss: 0.4395315\n",
      "\tspeed: 0.0507s/iter; left time: 43.8695s\n",
      "2997it [02:35, 17.76it/s]\titers: 3000, epoch: 1 | loss: 0.3619106\n",
      "\tspeed: 0.0513s/iter; left time: 39.2710s\n",
      "3098it [02:40, 19.04it/s]\titers: 3100, epoch: 1 | loss: 0.3247359\n",
      "\tspeed: 0.0497s/iter; left time: 33.1289s\n",
      "3199it [02:45, 19.75it/s]\titers: 3200, epoch: 1 | loss: 0.4476379\n",
      "\tspeed: 0.0515s/iter; left time: 29.1428s\n",
      "3298it [02:50, 19.70it/s]\titers: 3300, epoch: 1 | loss: 0.2920132\n",
      "\tspeed: 0.0506s/iter; left time: 23.5638s\n",
      "3398it [02:55, 19.55it/s]\titers: 3400, epoch: 1 | loss: 0.4767970\n",
      "\tspeed: 0.0512s/iter; left time: 18.7401s\n",
      "3498it [03:00, 19.68it/s]\titers: 3500, epoch: 1 | loss: 0.3559366\n",
      "\tspeed: 0.0546s/iter; left time: 14.5164s\n",
      "3599it [03:06, 19.75it/s]\titers: 3600, epoch: 1 | loss: 0.3848062\n",
      "\tspeed: 0.0513s/iter; left time: 8.5223s\n",
      "3699it [03:11, 19.69it/s]\titers: 3700, epoch: 1 | loss: 0.2997992\n",
      "\tspeed: 0.0505s/iter; left time: 3.3363s\n",
      "3765it [03:14, 19.35it/s]\n",
      "Epoch: 1 cost time: 194.56459307670593\n",
      "810it [00:20, 38.77it/s]\n",
      "807it [00:21, 36.91it/s]\n",
      "Epoch: 1 | Train Loss: 0.3494510 Vali Loss: 0.4042036 Test Loss: 0.4891832 MAE Loss: 0.4678651\n",
      "lr = 0.0009938442\n",
      "Total time: 4.295554093519846 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04.05.2024, START FROM HERE:\n",
    "# 0.001, COS, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 01:12:44,664] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 01:12:45,708] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 01:12:45,709] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 01:12:45,709] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 01:12:46,639] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 01:12:46,639] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 01:12:47,491] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 01:12:47,492] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 01:12:47,492] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 01:12:47,493] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 01:12:47,493] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 01:12:47,493] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 01:12:47,493] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 01:12:47,493] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 01:12:47,493] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 01:12:47,493] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 01:12:47,804] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 01:12:47,804] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:12:47,805] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 122.83 GB, percent = 16.3%\n",
      "[2024-05-04 01:12:47,979] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 01:12:47,980] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:12:47,980] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 126.28 GB, percent = 16.7%\n",
      "[2024-05-04 01:12:47,980] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 01:12:48,151] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 01:12:48,152] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:12:48,152] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 129.6 GB, percent = 17.2%\n",
      "[2024-05-04 01:12:48,153] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 01:12:48,153] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 01:12:48,153] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 01:12:48,153] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 01:12:48,153] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbaad018490>\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 01:12:48,154] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 01:12:48,155] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 01:12:48,156] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "97it [00:05, 24.52it/s]\titers: 100, epoch: 1 | loss: 0.3218488\n",
      "\tspeed: 0.0899s/iter; left time: 3375.8297s\n",
      "199it [00:09, 20.81it/s]\titers: 200, epoch: 1 | loss: 0.3640255\n",
      "\tspeed: 0.0420s/iter; left time: 1572.7611s\n",
      "298it [00:14, 19.02it/s]\titers: 300, epoch: 1 | loss: 0.3463034\n",
      "\tspeed: 0.0513s/iter; left time: 1915.8920s\n",
      "399it [00:19, 14.70it/s]\titers: 400, epoch: 1 | loss: 0.4982204\n",
      "\tspeed: 0.0532s/iter; left time: 1983.2761s\n",
      "498it [00:24, 19.84it/s]\titers: 500, epoch: 1 | loss: 0.3414853\n",
      "\tspeed: 0.0511s/iter; left time: 1899.9747s\n",
      "598it [00:29, 20.41it/s]\titers: 600, epoch: 1 | loss: 0.4336272\n",
      "\tspeed: 0.0460s/iter; left time: 1705.1351s\n",
      "699it [00:34, 19.57it/s]\titers: 700, epoch: 1 | loss: 0.2342097\n",
      "\tspeed: 0.0491s/iter; left time: 1815.6723s\n",
      "799it [00:39, 16.66it/s]\titers: 800, epoch: 1 | loss: 0.4338324\n",
      "\tspeed: 0.0528s/iter; left time: 1946.3409s\n",
      "898it [00:44, 19.81it/s]\titers: 900, epoch: 1 | loss: 0.2272563\n",
      "\tspeed: 0.0523s/iter; left time: 1922.6969s\n",
      "998it [00:49, 19.69it/s]\titers: 1000, epoch: 1 | loss: 0.3176199\n",
      "\tspeed: 0.0508s/iter; left time: 1860.9846s\n",
      "1099it [00:55, 19.29it/s]\titers: 1100, epoch: 1 | loss: 0.2765396\n",
      "\tspeed: 0.0514s/iter; left time: 1878.2548s\n",
      "1198it [01:00, 19.65it/s]\titers: 1200, epoch: 1 | loss: 0.2411615\n",
      "\tspeed: 0.0528s/iter; left time: 1926.2170s\n",
      "1299it [01:05, 19.82it/s]\titers: 1300, epoch: 1 | loss: 0.2387251\n",
      "\tspeed: 0.0512s/iter; left time: 1862.6276s\n",
      "1398it [01:10, 19.72it/s]\titers: 1400, epoch: 1 | loss: 0.2932905\n",
      "\tspeed: 0.0506s/iter; left time: 1832.5454s\n",
      "1499it [01:15, 19.81it/s]\titers: 1500, epoch: 1 | loss: 0.4869284\n",
      "\tspeed: 0.0506s/iter; left time: 1830.1516s\n",
      "1598it [01:21, 18.08it/s]\titers: 1600, epoch: 1 | loss: 0.4639114\n",
      "\tspeed: 0.0546s/iter; left time: 1967.5195s\n",
      "1698it [01:26, 19.82it/s]\titers: 1700, epoch: 1 | loss: 0.2877363\n",
      "\tspeed: 0.0506s/iter; left time: 1818.3207s\n",
      "1798it [01:31, 21.20it/s]\titers: 1800, epoch: 1 | loss: 0.3020300\n",
      "\tspeed: 0.0498s/iter; left time: 1785.8629s\n",
      "1898it [01:36, 18.23it/s]\titers: 1900, epoch: 1 | loss: 0.1911741\n",
      "\tspeed: 0.0501s/iter; left time: 1790.8680s\n",
      "1997it [01:40, 22.64it/s]\titers: 2000, epoch: 1 | loss: 0.2240178\n",
      "\tspeed: 0.0459s/iter; left time: 1635.2162s\n",
      "2099it [01:44, 25.17it/s]\titers: 2100, epoch: 1 | loss: 0.2505400\n",
      "\tspeed: 0.0396s/iter; left time: 1408.1162s\n",
      "2198it [01:48, 24.92it/s]\titers: 2200, epoch: 1 | loss: 0.7034073\n",
      "\tspeed: 0.0403s/iter; left time: 1427.2466s\n",
      "2297it [01:52, 24.78it/s]\titers: 2300, epoch: 1 | loss: 0.3349081\n",
      "\tspeed: 0.0404s/iter; left time: 1429.3990s\n",
      "2399it [01:57, 21.37it/s]\titers: 2400, epoch: 1 | loss: 0.4542590\n",
      "\tspeed: 0.0427s/iter; left time: 1504.8166s\n",
      "2498it [02:01, 24.14it/s]\titers: 2500, epoch: 1 | loss: 0.2569482\n",
      "\tspeed: 0.0410s/iter; left time: 1439.8893s\n",
      "2597it [02:05, 25.32it/s]\titers: 2600, epoch: 1 | loss: 0.4264008\n",
      "\tspeed: 0.0396s/iter; left time: 1389.3301s\n",
      "2699it [02:09, 25.08it/s]\titers: 2700, epoch: 1 | loss: 0.5491066\n",
      "\tspeed: 0.0398s/iter; left time: 1392.4019s\n",
      "2798it [02:13, 24.86it/s]\titers: 2800, epoch: 1 | loss: 0.2827885\n",
      "\tspeed: 0.0402s/iter; left time: 1399.8930s\n",
      "2897it [02:17, 25.21it/s]\titers: 2900, epoch: 1 | loss: 0.4395315\n",
      "\tspeed: 0.0425s/iter; left time: 1475.3369s\n",
      "2999it [02:21, 25.46it/s]\titers: 3000, epoch: 1 | loss: 0.3619106\n",
      "\tspeed: 0.0404s/iter; left time: 1400.6069s\n",
      "3098it [02:25, 24.67it/s]\titers: 3100, epoch: 1 | loss: 0.3247359\n",
      "\tspeed: 0.0400s/iter; left time: 1381.6410s\n",
      "3197it [02:29, 24.76it/s]\titers: 3200, epoch: 1 | loss: 0.4476379\n",
      "\tspeed: 0.0403s/iter; left time: 1387.4492s\n",
      "3299it [02:33, 21.57it/s]\titers: 3300, epoch: 1 | loss: 0.2920132\n",
      "\tspeed: 0.0415s/iter; left time: 1424.1715s\n",
      "3398it [02:37, 20.86it/s]\titers: 3400, epoch: 1 | loss: 0.4767970\n",
      "\tspeed: 0.0420s/iter; left time: 1439.9707s\n",
      "3497it [02:41, 25.03it/s]\titers: 3500, epoch: 1 | loss: 0.3559366\n",
      "\tspeed: 0.0396s/iter; left time: 1351.2094s\n",
      "3599it [02:45, 25.02it/s]\titers: 3600, epoch: 1 | loss: 0.3848062\n",
      "\tspeed: 0.0400s/iter; left time: 1361.9900s\n",
      "3698it [02:49, 24.68it/s]\titers: 3700, epoch: 1 | loss: 0.2997992\n",
      "\tspeed: 0.0402s/iter; left time: 1364.0844s\n",
      "3765it [02:52, 21.82it/s]\n",
      "Epoch: 1 cost time: 172.53425121307373\n",
      "810it [00:21, 38.14it/s]\n",
      "807it [00:20, 38.44it/s]\n",
      "Epoch: 1 | Train Loss: 0.3494510 Vali Loss: 0.4042036 Test Loss: 0.4891832 MAE Loss: 0.4678651\n",
      "lr = 0.0009938442\n",
      "97it [00:04, 23.65it/s]\titers: 100, epoch: 2 | loss: 0.1884180\n",
      "\tspeed: 0.5119s/iter; left time: 17295.5830s\n",
      "199it [00:09, 19.76it/s]\titers: 200, epoch: 2 | loss: 0.5682016\n",
      "\tspeed: 0.0501s/iter; left time: 1687.3782s\n",
      "299it [00:15, 20.03it/s]\titers: 300, epoch: 2 | loss: 0.1953925\n",
      "\tspeed: 0.0538s/iter; left time: 1807.3006s\n",
      "397it [00:20, 20.95it/s]\titers: 400, epoch: 2 | loss: 0.1639849\n",
      "\tspeed: 0.0494s/iter; left time: 1654.2717s\n",
      "499it [00:24, 21.20it/s]\titers: 500, epoch: 2 | loss: 0.2742581\n",
      "\tspeed: 0.0474s/iter; left time: 1581.3881s\n",
      "598it [00:29, 20.65it/s]\titers: 600, epoch: 2 | loss: 0.1830232\n",
      "\tspeed: 0.0476s/iter; left time: 1584.9567s\n",
      "699it [00:35, 20.47it/s]\titers: 700, epoch: 2 | loss: 0.4593197\n",
      "\tspeed: 0.0540s/iter; left time: 1792.4596s\n",
      "798it [00:39, 21.35it/s]\titers: 800, epoch: 2 | loss: 0.2955022\n",
      "\tspeed: 0.0471s/iter; left time: 1558.4398s\n",
      "897it [00:44, 21.24it/s]\titers: 900, epoch: 2 | loss: 0.3457933\n",
      "\tspeed: 0.0471s/iter; left time: 1552.3766s\n",
      "998it [00:49, 21.07it/s]\titers: 1000, epoch: 2 | loss: 0.3679632\n",
      "\tspeed: 0.0498s/iter; left time: 1637.0270s\n",
      "1099it [00:54, 21.19it/s]\titers: 1100, epoch: 2 | loss: 0.6786941\n",
      "\tspeed: 0.0480s/iter; left time: 1573.0370s\n",
      "1198it [00:59, 21.13it/s]\titers: 1200, epoch: 2 | loss: 0.3862898\n",
      "\tspeed: 0.0474s/iter; left time: 1550.5010s\n",
      "1297it [01:03, 21.03it/s]\titers: 1300, epoch: 2 | loss: 0.2986697\n",
      "\tspeed: 0.0474s/iter; left time: 1544.0944s\n",
      "1399it [01:08, 27.22it/s]\titers: 1400, epoch: 2 | loss: 0.2336269\n",
      "\tspeed: 0.0426s/iter; left time: 1385.1263s\n",
      "1498it [01:12, 21.25it/s]\titers: 1500, epoch: 2 | loss: 0.2864751\n",
      "\tspeed: 0.0471s/iter; left time: 1524.7288s\n",
      "1597it [01:17, 21.05it/s]\titers: 1600, epoch: 2 | loss: 0.2528131\n",
      "\tspeed: 0.0474s/iter; left time: 1531.6752s\n",
      "1699it [01:22, 20.46it/s]\titers: 1700, epoch: 2 | loss: 0.3811564\n",
      "\tspeed: 0.0446s/iter; left time: 1434.7995s\n",
      "1798it [01:26, 21.14it/s]\titers: 1800, epoch: 2 | loss: 0.3493163\n",
      "\tspeed: 0.0500s/iter; left time: 1604.7663s\n",
      "1897it [01:31, 21.28it/s]\titers: 1900, epoch: 2 | loss: 0.2031413\n",
      "\tspeed: 0.0480s/iter; left time: 1536.1018s\n",
      "1999it [01:36, 20.90it/s]\titers: 2000, epoch: 2 | loss: 0.3165319\n",
      "\tspeed: 0.0471s/iter; left time: 1503.2753s\n",
      "2098it [01:41, 18.25it/s]\titers: 2100, epoch: 2 | loss: 0.2364211\n",
      "\tspeed: 0.0488s/iter; left time: 1552.2675s\n",
      "2198it [01:45, 23.36it/s]\titers: 2200, epoch: 2 | loss: 0.3688861\n",
      "\tspeed: 0.0408s/iter; left time: 1292.4452s\n",
      "2297it [01:49, 27.72it/s]\titers: 2300, epoch: 2 | loss: 0.2263474\n",
      "\tspeed: 0.0363s/iter; left time: 1146.5078s\n",
      "2399it [01:52, 27.44it/s]\titers: 2400, epoch: 2 | loss: 0.1810660\n",
      "\tspeed: 0.0362s/iter; left time: 1141.2930s\n",
      "2498it [01:56, 27.35it/s]\titers: 2500, epoch: 2 | loss: 0.3030196\n",
      "\tspeed: 0.0365s/iter; left time: 1147.0440s\n",
      "2597it [02:00, 21.23it/s]\titers: 2600, epoch: 2 | loss: 0.3515817\n",
      "\tspeed: 0.0454s/iter; left time: 1420.8245s\n",
      "2698it [02:05, 21.24it/s]\titers: 2700, epoch: 2 | loss: 0.2677218\n",
      "\tspeed: 0.0479s/iter; left time: 1493.7406s\n",
      "2797it [02:10, 21.21it/s]\titers: 2800, epoch: 2 | loss: 0.1962819\n",
      "\tspeed: 0.0471s/iter; left time: 1464.4102s\n",
      "2899it [02:14, 24.79it/s]\titers: 2900, epoch: 2 | loss: 0.3394377\n",
      "\tspeed: 0.0376s/iter; left time: 1166.5003s\n",
      "2997it [02:19, 21.18it/s]\titers: 3000, epoch: 2 | loss: 0.3117361\n",
      "\tspeed: 0.0501s/iter; left time: 1547.0080s\n",
      "3099it [02:24, 21.01it/s]\titers: 3100, epoch: 2 | loss: 0.4270400\n",
      "\tspeed: 0.0484s/iter; left time: 1490.0564s\n",
      "3198it [02:28, 21.11it/s]\titers: 3200, epoch: 2 | loss: 0.5073355\n",
      "\tspeed: 0.0477s/iter; left time: 1464.7755s\n",
      "3299it [02:33, 18.97it/s]\titers: 3300, epoch: 2 | loss: 0.3378738\n",
      "\tspeed: 0.0487s/iter; left time: 1488.3815s\n",
      "3397it [02:38, 20.06it/s]\titers: 3400, epoch: 2 | loss: 0.3007434\n",
      "\tspeed: 0.0493s/iter; left time: 1502.5871s\n",
      "3499it [02:43, 21.01it/s]\titers: 3500, epoch: 2 | loss: 0.2726682\n",
      "\tspeed: 0.0477s/iter; left time: 1448.9228s\n",
      "3598it [02:48, 20.80it/s]\titers: 3600, epoch: 2 | loss: 0.4995877\n",
      "\tspeed: 0.0478s/iter; left time: 1448.1655s\n",
      "3698it [02:53, 15.41it/s]\titers: 3700, epoch: 2 | loss: 0.3445364\n",
      "\tspeed: 0.0521s/iter; left time: 1571.4180s\n",
      "3765it [02:56, 21.32it/s]\n",
      "Epoch: 2 cost time: 176.63169884681702\n",
      "810it [00:18, 44.35it/s]\n",
      "807it [00:17, 44.84it/s]\n",
      "Epoch: 2 | Train Loss: 0.3222216 Vali Loss: 0.3956181 Test Loss: 0.4783413 MAE Loss: 0.4657086\n",
      "lr = 0.0009755285\n",
      "99it [00:05, 21.00it/s]\titers: 100, epoch: 3 | loss: 0.2258751\n",
      "\tspeed: 0.4593s/iter; left time: 13789.0348s\n",
      "198it [00:09, 21.00it/s]\titers: 200, epoch: 3 | loss: 0.3039617\n",
      "\tspeed: 0.0475s/iter; left time: 1422.1909s\n",
      "297it [00:14, 21.15it/s]\titers: 300, epoch: 3 | loss: 0.3753062\n",
      "\tspeed: 0.0494s/iter; left time: 1472.1753s\n",
      "399it [00:19, 21.06it/s]\titers: 400, epoch: 3 | loss: 0.3365389\n",
      "\tspeed: 0.0483s/iter; left time: 1435.3169s\n",
      "498it [00:24, 20.59it/s]\titers: 500, epoch: 3 | loss: 0.2426460\n",
      "\tspeed: 0.0477s/iter; left time: 1413.5959s\n",
      "597it [00:29, 20.64it/s]\titers: 600, epoch: 3 | loss: 0.2107975\n",
      "\tspeed: 0.0478s/iter; left time: 1411.8247s\n",
      "698it [00:34, 21.24it/s]\titers: 700, epoch: 3 | loss: 0.3931471\n",
      "\tspeed: 0.0501s/iter; left time: 1475.0841s\n",
      "797it [00:38, 20.97it/s]\titers: 800, epoch: 3 | loss: 0.1803274\n",
      "\tspeed: 0.0483s/iter; left time: 1416.4358s\n",
      "899it [00:43, 20.88it/s]\titers: 900, epoch: 3 | loss: 0.4390911\n",
      "\tspeed: 0.0476s/iter; left time: 1390.9931s\n",
      "999it [00:48, 19.57it/s]\titers: 1000, epoch: 3 | loss: 0.2596957\n",
      "\tspeed: 0.0484s/iter; left time: 1410.3691s\n",
      "1099it [00:53, 21.23it/s]\titers: 1100, epoch: 3 | loss: 0.3385699\n",
      "\tspeed: 0.0502s/iter; left time: 1457.7535s\n",
      "1198it [00:58, 21.10it/s]\titers: 1200, epoch: 3 | loss: 0.2414210\n",
      "\tspeed: 0.0480s/iter; left time: 1388.7373s\n",
      "1297it [01:03, 20.73it/s]\titers: 1300, epoch: 3 | loss: 0.1900485\n",
      "\tspeed: 0.0478s/iter; left time: 1379.0185s\n",
      "1399it [01:07, 22.96it/s]\titers: 1400, epoch: 3 | loss: 0.3608666\n",
      "\tspeed: 0.0429s/iter; left time: 1231.9189s\n",
      "1498it [01:12, 21.11it/s]\titers: 1500, epoch: 3 | loss: 0.4074781\n",
      "\tspeed: 0.0483s/iter; left time: 1382.6899s\n",
      "1597it [01:16, 21.16it/s]\titers: 1600, epoch: 3 | loss: 0.3291973\n",
      "\tspeed: 0.0478s/iter; left time: 1364.5941s\n",
      "1699it [01:21, 20.94it/s]\titers: 1700, epoch: 3 | loss: 0.2674252\n",
      "\tspeed: 0.0476s/iter; left time: 1352.1213s\n",
      "1798it [01:26, 20.74it/s]\titers: 1800, epoch: 3 | loss: 0.2115812\n",
      "\tspeed: 0.0480s/iter; left time: 1358.7219s\n",
      "1897it [01:31, 26.81it/s]\titers: 1900, epoch: 3 | loss: 0.4105255\n",
      "\tspeed: 0.0458s/iter; left time: 1292.6668s\n",
      "1999it [01:35, 23.01it/s]\titers: 2000, epoch: 3 | loss: 0.3016213\n",
      "\tspeed: 0.0472s/iter; left time: 1328.5290s\n",
      "2097it [01:40, 21.64it/s]\titers: 2100, epoch: 3 | loss: 0.2844736\n",
      "\tspeed: 0.0475s/iter; left time: 1329.7423s\n",
      "2199it [01:45, 20.41it/s]\titers: 2200, epoch: 3 | loss: 0.2430025\n",
      "\tspeed: 0.0477s/iter; left time: 1333.0817s\n",
      "2298it [01:50, 17.59it/s]\titers: 2300, epoch: 3 | loss: 0.3116939\n",
      "\tspeed: 0.0502s/iter; left time: 1395.4890s\n",
      "2398it [01:55, 20.07it/s]\titers: 2400, epoch: 3 | loss: 0.2711376\n",
      "\tspeed: 0.0505s/iter; left time: 1399.0249s\n",
      "2499it [01:59, 24.21it/s]\titers: 2500, epoch: 3 | loss: 0.2704870\n",
      "\tspeed: 0.0444s/iter; left time: 1225.4879s\n",
      "2599it [02:04, 20.30it/s]\titers: 2600, epoch: 3 | loss: 0.2521930\n",
      "\tspeed: 0.0460s/iter; left time: 1264.9958s\n",
      "2697it [02:09, 20.98it/s]\titers: 2700, epoch: 3 | loss: 0.4915278\n",
      "\tspeed: 0.0494s/iter; left time: 1353.5384s\n",
      "2798it [02:14, 20.36it/s]\titers: 2800, epoch: 3 | loss: 0.1962674\n",
      "\tspeed: 0.0490s/iter; left time: 1337.7393s\n",
      "2897it [02:19, 20.90it/s]\titers: 2900, epoch: 3 | loss: 0.3470823\n",
      "\tspeed: 0.0483s/iter; left time: 1316.0824s\n",
      "2999it [02:24, 20.32it/s]\titers: 3000, epoch: 3 | loss: 0.2476108\n",
      "\tspeed: 0.0483s/iter; left time: 1309.8367s\n",
      "3099it [02:29, 21.16it/s]\titers: 3100, epoch: 3 | loss: 0.2597793\n",
      "\tspeed: 0.0523s/iter; left time: 1413.8309s\n",
      "3197it [02:34, 20.79it/s]\titers: 3200, epoch: 3 | loss: 0.3018452\n",
      "\tspeed: 0.0481s/iter; left time: 1295.1872s\n",
      "3299it [02:38, 20.66it/s]\titers: 3300, epoch: 3 | loss: 0.2853025\n",
      "\tspeed: 0.0482s/iter; left time: 1293.8346s\n",
      "3398it [02:43, 20.50it/s]\titers: 3400, epoch: 3 | loss: 0.1616981\n",
      "\tspeed: 0.0483s/iter; left time: 1291.6865s\n",
      "3497it [02:48, 21.15it/s]\titers: 3500, epoch: 3 | loss: 0.4743453\n",
      "\tspeed: 0.0512s/iter; left time: 1361.7858s\n",
      "3598it [02:53, 21.19it/s]\titers: 3600, epoch: 3 | loss: 0.1709010\n",
      "\tspeed: 0.0479s/iter; left time: 1269.2155s\n",
      "3697it [02:58, 21.25it/s]\titers: 3700, epoch: 3 | loss: 0.1959947\n",
      "\tspeed: 0.0472s/iter; left time: 1246.1218s\n",
      "3765it [03:01, 20.73it/s]\n",
      "Epoch: 3 cost time: 181.61116743087769\n",
      "810it [00:18, 44.29it/s]\n",
      "807it [00:18, 44.46it/s]\n",
      "Epoch: 3 | Train Loss: 0.3183608 Vali Loss: 0.3893458 Test Loss: 0.4791180 MAE Loss: 0.4585129\n",
      "lr = 0.0009455038\n",
      "99it [00:04, 23.59it/s]\titers: 100, epoch: 4 | loss: 0.2845196\n",
      "\tspeed: 0.4555s/iter; left time: 11958.7077s\n",
      "198it [00:08, 26.88it/s]\titers: 200, epoch: 4 | loss: 0.4451150\n",
      "\tspeed: 0.0374s/iter; left time: 978.0496s\n",
      "297it [00:12, 26.60it/s]\titers: 300, epoch: 4 | loss: 0.1756459\n",
      "\tspeed: 0.0374s/iter; left time: 974.1361s\n",
      "399it [00:15, 26.84it/s]\titers: 400, epoch: 4 | loss: 0.5349078\n",
      "\tspeed: 0.0374s/iter; left time: 972.0196s\n",
      "498it [00:19, 26.63it/s]\titers: 500, epoch: 4 | loss: 0.5543185\n",
      "\tspeed: 0.0377s/iter; left time: 973.6663s\n",
      "599it [00:24, 21.02it/s]\titers: 600, epoch: 4 | loss: 0.3005570\n",
      "\tspeed: 0.0467s/iter; left time: 1202.7182s\n",
      "698it [00:29, 21.06it/s]\titers: 700, epoch: 4 | loss: 0.3341551\n",
      "\tspeed: 0.0481s/iter; left time: 1234.0499s\n",
      "797it [00:33, 21.20it/s]\titers: 800, epoch: 4 | loss: 0.4031752\n",
      "\tspeed: 0.0474s/iter; left time: 1211.4897s\n",
      "899it [00:38, 21.72it/s]\titers: 900, epoch: 4 | loss: 0.2782830\n",
      "\tspeed: 0.0480s/iter; left time: 1221.9241s\n",
      "998it [00:42, 27.34it/s]\titers: 1000, epoch: 4 | loss: 0.4282401\n",
      "\tspeed: 0.0382s/iter; left time: 968.0250s\n",
      "1097it [00:46, 27.46it/s]\titers: 1100, epoch: 4 | loss: 0.4354928\n",
      "\tspeed: 0.0373s/iter; left time: 941.1677s\n",
      "1199it [00:49, 27.28it/s]\titers: 1200, epoch: 4 | loss: 0.4087144\n",
      "\tspeed: 0.0368s/iter; left time: 926.7109s\n",
      "1298it [00:53, 26.90it/s]\titers: 1300, epoch: 4 | loss: 0.2480121\n",
      "\tspeed: 0.0370s/iter; left time: 925.9840s\n",
      "1397it [00:57, 22.94it/s]\titers: 1400, epoch: 4 | loss: 0.3314148\n",
      "\tspeed: 0.0387s/iter; left time: 965.0886s\n",
      "1499it [01:01, 27.02it/s]\titers: 1500, epoch: 4 | loss: 0.4992851\n",
      "\tspeed: 0.0389s/iter; left time: 967.9335s\n",
      "1598it [01:04, 27.58it/s]\titers: 1600, epoch: 4 | loss: 0.2349755\n",
      "\tspeed: 0.0365s/iter; left time: 902.9021s\n",
      "1697it [01:09, 21.23it/s]\titers: 1700, epoch: 4 | loss: 0.7015923\n",
      "\tspeed: 0.0472s/iter; left time: 1164.1638s\n",
      "1797it [01:14, 23.60it/s]\titers: 1800, epoch: 4 | loss: 0.3498228\n",
      "\tspeed: 0.0493s/iter; left time: 1210.3181s\n",
      "1899it [01:18, 27.37it/s]\titers: 1900, epoch: 4 | loss: 0.4449454\n",
      "\tspeed: 0.0376s/iter; left time: 920.5018s\n",
      "1998it [01:22, 27.09it/s]\titers: 2000, epoch: 4 | loss: 0.4502485\n",
      "\tspeed: 0.0366s/iter; left time: 891.3059s\n",
      "2097it [01:25, 27.19it/s]\titers: 2100, epoch: 4 | loss: 0.2690628\n",
      "\tspeed: 0.0369s/iter; left time: 894.3936s\n",
      "2199it [01:29, 27.16it/s]\titers: 2200, epoch: 4 | loss: 0.3947301\n",
      "\tspeed: 0.0367s/iter; left time: 886.9535s\n",
      "2298it [01:33, 26.00it/s]\titers: 2300, epoch: 4 | loss: 0.3304965\n",
      "\tspeed: 0.0393s/iter; left time: 944.8989s\n",
      "2397it [01:37, 27.32it/s]\titers: 2400, epoch: 4 | loss: 0.3419580\n",
      "\tspeed: 0.0377s/iter; left time: 903.0345s\n",
      "2499it [01:40, 27.58it/s]\titers: 2500, epoch: 4 | loss: 0.2142911\n",
      "\tspeed: 0.0363s/iter; left time: 865.4773s\n",
      "2598it [01:44, 27.24it/s]\titers: 2600, epoch: 4 | loss: 0.3281462\n",
      "\tspeed: 0.0366s/iter; left time: 868.3157s\n",
      "2697it [01:47, 27.06it/s]\titers: 2700, epoch: 4 | loss: 0.2933129\n",
      "\tspeed: 0.0368s/iter; left time: 870.6020s\n",
      "2799it [01:52, 21.15it/s]\titers: 2800, epoch: 4 | loss: 0.3378268\n",
      "\tspeed: 0.0437s/iter; left time: 1028.8432s\n",
      "2899it [01:56, 21.29it/s]\titers: 2900, epoch: 4 | loss: 0.3537287\n",
      "\tspeed: 0.0452s/iter; left time: 1060.6516s\n",
      "2998it [02:01, 20.69it/s]\titers: 3000, epoch: 4 | loss: 0.2953578\n",
      "\tspeed: 0.0482s/iter; left time: 1126.2479s\n",
      "3097it [02:06, 20.62it/s]\titers: 3100, epoch: 4 | loss: 0.2514821\n",
      "\tspeed: 0.0483s/iter; left time: 1123.0122s\n",
      "3198it [02:11, 21.08it/s]\titers: 3200, epoch: 4 | loss: 0.2664630\n",
      "\tspeed: 0.0516s/iter; left time: 1194.3097s\n",
      "3299it [02:16, 21.24it/s]\titers: 3300, epoch: 4 | loss: 0.3089044\n",
      "\tspeed: 0.0479s/iter; left time: 1104.7481s\n",
      "3398it [02:21, 21.09it/s]\titers: 3400, epoch: 4 | loss: 0.2029448\n",
      "\tspeed: 0.0471s/iter; left time: 1081.0275s\n",
      "3497it [02:25, 20.95it/s]\titers: 3500, epoch: 4 | loss: 0.3088215\n",
      "\tspeed: 0.0476s/iter; left time: 1087.5622s\n",
      "3599it [02:30, 27.27it/s]\titers: 3600, epoch: 4 | loss: 0.1561490\n",
      "\tspeed: 0.0401s/iter; left time: 912.9358s\n",
      "3698it [02:33, 27.36it/s]\titers: 3700, epoch: 4 | loss: 0.3454553\n",
      "\tspeed: 0.0376s/iter; left time: 852.8090s\n",
      "3765it [02:36, 24.09it/s]\n",
      "Epoch: 4 cost time: 156.27535557746887\n",
      "810it [00:17, 45.01it/s]\n",
      "807it [00:18, 43.44it/s]\n",
      "Epoch: 4 | Train Loss: 0.3204753 Vali Loss: 0.3905744 Test Loss: 0.4751004 MAE Loss: 0.4565349\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009045095\n",
      "99it [00:05, 20.50it/s]\titers: 100, epoch: 5 | loss: 0.5114356\n",
      "\tspeed: 0.4423s/iter; left time: 9947.7212s\n",
      "198it [00:10, 21.05it/s]\titers: 200, epoch: 5 | loss: 0.2971494\n",
      "\tspeed: 0.0505s/iter; left time: 1131.6382s\n",
      "297it [00:14, 21.01it/s]\titers: 300, epoch: 5 | loss: 0.3125830\n",
      "\tspeed: 0.0483s/iter; left time: 1077.4839s\n",
      "399it [00:19, 21.21it/s]\titers: 400, epoch: 5 | loss: 0.4674928\n",
      "\tspeed: 0.0473s/iter; left time: 1050.3463s\n",
      "498it [00:24, 20.48it/s]\titers: 500, epoch: 5 | loss: 0.3742061\n",
      "\tspeed: 0.0480s/iter; left time: 1059.8783s\n",
      "599it [00:29, 21.20it/s]\titers: 600, epoch: 5 | loss: 0.3702931\n",
      "\tspeed: 0.0518s/iter; left time: 1138.2132s\n",
      "697it [00:34, 21.15it/s]\titers: 700, epoch: 5 | loss: 0.4345067\n",
      "\tspeed: 0.0481s/iter; left time: 1053.7569s\n",
      "799it [00:39, 20.85it/s]\titers: 800, epoch: 5 | loss: 0.3023509\n",
      "\tspeed: 0.0477s/iter; left time: 1038.7366s\n",
      "898it [00:43, 20.56it/s]\titers: 900, epoch: 5 | loss: 0.3903047\n",
      "\tspeed: 0.0475s/iter; left time: 1030.5947s\n",
      "997it [00:47, 27.38it/s]\titers: 1000, epoch: 5 | loss: 0.4191611\n",
      "\tspeed: 0.0387s/iter; left time: 834.5451s\n",
      "1099it [00:51, 27.36it/s]\titers: 1100, epoch: 5 | loss: 0.3491889\n",
      "\tspeed: 0.0374s/iter; left time: 803.4166s\n",
      "1198it [00:55, 27.15it/s]\titers: 1200, epoch: 5 | loss: 0.2972980\n",
      "\tspeed: 0.0366s/iter; left time: 783.1440s\n",
      "1297it [00:58, 26.84it/s]\titers: 1300, epoch: 5 | loss: 0.2884289\n",
      "\tspeed: 0.0370s/iter; left time: 786.9208s\n",
      "1399it [01:02, 22.90it/s]\titers: 1400, epoch: 5 | loss: 0.3549766\n",
      "\tspeed: 0.0386s/iter; left time: 817.0576s\n",
      "1498it [01:06, 22.84it/s]\titers: 1500, epoch: 5 | loss: 0.3484952\n",
      "\tspeed: 0.0392s/iter; left time: 825.7628s\n",
      "1597it [01:10, 27.13it/s]\titers: 1600, epoch: 5 | loss: 0.5403878\n",
      "\tspeed: 0.0365s/iter; left time: 765.5356s\n",
      "1699it [01:14, 27.05it/s]\titers: 1700, epoch: 5 | loss: 0.1983688\n",
      "\tspeed: 0.0368s/iter; left time: 769.0428s\n",
      "1798it [01:17, 27.02it/s]\titers: 1800, epoch: 5 | loss: 0.2171077\n",
      "\tspeed: 0.0371s/iter; left time: 770.3824s\n",
      "1897it [01:21, 22.84it/s]\titers: 1900, epoch: 5 | loss: 0.4971854\n",
      "\tspeed: 0.0391s/iter; left time: 808.3311s\n",
      "1998it [01:26, 21.04it/s]\titers: 2000, epoch: 5 | loss: 0.2002450\n",
      "\tspeed: 0.0483s/iter; left time: 995.2059s\n",
      "2097it [01:31, 20.99it/s]\titers: 2100, epoch: 5 | loss: 0.5598083\n",
      "\tspeed: 0.0474s/iter; left time: 971.8616s\n",
      "2199it [01:36, 20.69it/s]\titers: 2200, epoch: 5 | loss: 0.3465590\n",
      "\tspeed: 0.0478s/iter; left time: 975.7022s\n",
      "2298it [01:41, 15.77it/s]\titers: 2300, epoch: 5 | loss: 0.2491348\n",
      "\tspeed: 0.0517s/iter; left time: 1049.8368s\n",
      "2397it [01:46, 20.88it/s]\titers: 2400, epoch: 5 | loss: 0.2876121\n",
      "\tspeed: 0.0492s/iter; left time: 992.6685s\n",
      "2499it [01:50, 21.08it/s]\titers: 2500, epoch: 5 | loss: 0.2320451\n",
      "\tspeed: 0.0473s/iter; left time: 950.2775s\n",
      "2598it [01:55, 20.96it/s]\titers: 2600, epoch: 5 | loss: 0.2770251\n",
      "\tspeed: 0.0476s/iter; left time: 950.9846s\n",
      "2699it [02:00, 25.32it/s]\titers: 2700, epoch: 5 | loss: 0.4038777\n",
      "\tspeed: 0.0466s/iter; left time: 927.1267s\n",
      "2798it [02:04, 26.62it/s]\titers: 2800, epoch: 5 | loss: 0.2016129\n",
      "\tspeed: 0.0385s/iter; left time: 761.9415s\n",
      "2897it [02:07, 26.76it/s]\titers: 2900, epoch: 5 | loss: 0.2829544\n",
      "\tspeed: 0.0374s/iter; left time: 736.9993s\n",
      "2999it [02:11, 20.61it/s]\titers: 3000, epoch: 5 | loss: 0.2861705\n",
      "\tspeed: 0.0395s/iter; left time: 774.4572s\n",
      "3099it [02:16, 19.57it/s]\titers: 3100, epoch: 5 | loss: 0.2588844\n",
      "\tspeed: 0.0507s/iter; left time: 987.3758s\n",
      "3197it [02:21, 26.86it/s]\titers: 3200, epoch: 5 | loss: 0.2216300\n",
      "\tspeed: 0.0445s/iter; left time: 862.0830s\n",
      "3299it [02:25, 21.27it/s]\titers: 3300, epoch: 5 | loss: 0.1830666\n",
      "\tspeed: 0.0459s/iter; left time: 884.6158s\n",
      "3398it [02:30, 20.26it/s]\titers: 3400, epoch: 5 | loss: 0.2615009\n",
      "\tspeed: 0.0468s/iter; left time: 898.1271s\n",
      "3499it [02:35, 20.10it/s]\titers: 3500, epoch: 5 | loss: 0.2588952\n",
      "\tspeed: 0.0478s/iter; left time: 913.2631s\n",
      "3598it [02:40, 20.94it/s]\titers: 3600, epoch: 5 | loss: 0.3004991\n",
      "\tspeed: 0.0500s/iter; left time: 949.7210s\n",
      "3699it [02:45, 19.94it/s]\titers: 3700, epoch: 5 | loss: 0.1559768\n",
      "\tspeed: 0.0493s/iter; left time: 930.9505s\n",
      "3765it [02:48, 22.35it/s]\n",
      "Epoch: 5 cost time: 168.4597749710083\n",
      "810it [00:18, 44.00it/s]\n",
      "807it [00:18, 43.17it/s]\n",
      "Epoch: 5 | Train Loss: 0.3224744 Vali Loss: 0.3772124 Test Loss: 0.4597662 MAE Loss: 0.4469471\n",
      "lr = 0.0008535549\n",
      "99it [00:05, 21.19it/s]\titers: 100, epoch: 6 | loss: 0.2958024\n",
      "\tspeed: 0.4623s/iter; left time: 8656.4711s\n",
      "199it [00:10, 21.03it/s]\titers: 200, epoch: 6 | loss: 0.2543693\n",
      "\tspeed: 0.0516s/iter; left time: 961.6236s\n",
      "298it [00:14, 23.69it/s]\titers: 300, epoch: 6 | loss: 0.2879804\n",
      "\tspeed: 0.0473s/iter; left time: 876.2281s\n",
      "397it [00:19, 20.96it/s]\titers: 400, epoch: 6 | loss: 0.2328642\n",
      "\tspeed: 0.0442s/iter; left time: 814.7067s\n",
      "499it [00:24, 22.62it/s]\titers: 500, epoch: 6 | loss: 0.1856288\n",
      "\tspeed: 0.0475s/iter; left time: 869.6534s\n",
      "599it [00:29, 21.18it/s]\titers: 600, epoch: 6 | loss: 0.2731483\n",
      "\tspeed: 0.0507s/iter; left time: 923.5205s\n",
      "698it [00:33, 21.82it/s]\titers: 700, epoch: 6 | loss: 0.3817542\n",
      "\tspeed: 0.0475s/iter; left time: 860.8417s\n",
      "797it [00:38, 23.05it/s]\titers: 800, epoch: 6 | loss: 0.8012062\n",
      "\tspeed: 0.0442s/iter; left time: 795.8678s\n",
      "899it [00:43, 20.84it/s]\titers: 900, epoch: 6 | loss: 0.2722598\n",
      "\tspeed: 0.0476s/iter; left time: 852.5490s\n",
      "997it [00:47, 21.14it/s]\titers: 1000, epoch: 6 | loss: 0.2642626\n",
      "\tspeed: 0.0496s/iter; left time: 883.4337s\n",
      "1099it [00:52, 20.92it/s]\titers: 1100, epoch: 6 | loss: 0.2800905\n",
      "\tspeed: 0.0484s/iter; left time: 857.7048s\n",
      "1198it [00:57, 20.84it/s]\titers: 1200, epoch: 6 | loss: 0.3022359\n",
      "\tspeed: 0.0479s/iter; left time: 843.8720s\n",
      "1297it [01:02, 20.70it/s]\titers: 1300, epoch: 6 | loss: 0.2131541\n",
      "\tspeed: 0.0482s/iter; left time: 844.5874s\n",
      "1397it [01:07, 18.02it/s]\titers: 1400, epoch: 6 | loss: 0.2865126\n",
      "\tspeed: 0.0504s/iter; left time: 878.1772s\n",
      "1499it [01:12, 21.13it/s]\titers: 1500, epoch: 6 | loss: 0.2035251\n",
      "\tspeed: 0.0473s/iter; left time: 819.0392s\n",
      "1598it [01:16, 20.96it/s]\titers: 1600, epoch: 6 | loss: 0.3789158\n",
      "\tspeed: 0.0476s/iter; left time: 819.1669s\n",
      "1699it [01:21, 20.07it/s]\titers: 1700, epoch: 6 | loss: 0.4201375\n",
      "\tspeed: 0.0494s/iter; left time: 846.8244s\n",
      "1797it [01:26, 21.17it/s]\titers: 1800, epoch: 6 | loss: 0.2539242\n",
      "\tspeed: 0.0481s/iter; left time: 818.6785s\n",
      "1899it [01:31, 21.15it/s]\titers: 1900, epoch: 6 | loss: 0.3878720\n",
      "\tspeed: 0.0474s/iter; left time: 802.3934s\n",
      "1998it [01:36, 20.89it/s]\titers: 2000, epoch: 6 | loss: 0.3672203\n",
      "\tspeed: 0.0476s/iter; left time: 801.1784s\n",
      "2097it [01:41, 21.08it/s]\titers: 2100, epoch: 6 | loss: 0.3250736\n",
      "\tspeed: 0.0494s/iter; left time: 826.8834s\n",
      "2198it [01:45, 21.17it/s]\titers: 2200, epoch: 6 | loss: 0.3259186\n",
      "\tspeed: 0.0481s/iter; left time: 799.0424s\n",
      "2297it [01:50, 20.97it/s]\titers: 2300, epoch: 6 | loss: 0.2795841\n",
      "\tspeed: 0.0474s/iter; left time: 784.0305s\n",
      "2399it [01:55, 20.55it/s]\titers: 2400, epoch: 6 | loss: 0.1800817\n",
      "\tspeed: 0.0480s/iter; left time: 788.5787s\n",
      "2498it [02:00, 19.51it/s]\titers: 2500, epoch: 6 | loss: 0.2662502\n",
      "\tspeed: 0.0498s/iter; left time: 812.4997s\n",
      "2597it [02:05, 20.44it/s]\titers: 2600, epoch: 6 | loss: 0.3422699\n",
      "\tspeed: 0.0482s/iter; left time: 782.3520s\n",
      "2697it [02:10, 21.08it/s]\titers: 2700, epoch: 6 | loss: 0.2123109\n",
      "\tspeed: 0.0477s/iter; left time: 769.9223s\n",
      "2798it [02:15, 20.55it/s]\titers: 2800, epoch: 6 | loss: 0.2100588\n",
      "\tspeed: 0.0512s/iter; left time: 820.7193s\n",
      "2899it [02:20, 21.42it/s]\titers: 2900, epoch: 6 | loss: 0.3533497\n",
      "\tspeed: 0.0536s/iter; left time: 853.6616s\n",
      "2999it [02:25, 21.12it/s]\titers: 3000, epoch: 6 | loss: 0.2326804\n",
      "\tspeed: 0.0481s/iter; left time: 761.5920s\n",
      "3098it [02:30, 20.74it/s]\titers: 3100, epoch: 6 | loss: 0.3390313\n",
      "\tspeed: 0.0469s/iter; left time: 737.9092s\n",
      "3197it [02:34, 19.97it/s]\titers: 3200, epoch: 6 | loss: 0.2468730\n",
      "\tspeed: 0.0488s/iter; left time: 761.9891s\n",
      "3298it [02:39, 18.75it/s]\titers: 3300, epoch: 6 | loss: 0.2851472\n",
      "\tspeed: 0.0467s/iter; left time: 725.0941s\n",
      "3397it [02:44, 21.01it/s]\titers: 3400, epoch: 6 | loss: 0.2096411\n",
      "\tspeed: 0.0475s/iter; left time: 732.9611s\n",
      "3499it [02:49, 20.83it/s]\titers: 3500, epoch: 6 | loss: 0.2350686\n",
      "\tspeed: 0.0478s/iter; left time: 732.5273s\n",
      "3599it [02:54, 14.74it/s]\titers: 3600, epoch: 6 | loss: 0.5517228\n",
      "\tspeed: 0.0498s/iter; left time: 757.5323s\n",
      "3699it [02:59, 21.10it/s]\titers: 3700, epoch: 6 | loss: 0.1718680\n",
      "\tspeed: 0.0493s/iter; left time: 746.2608s\n",
      "3765it [03:02, 20.65it/s]\n",
      "Epoch: 6 cost time: 182.2835602760315\n",
      "810it [00:18, 44.60it/s]\n",
      "807it [00:17, 44.92it/s]\n",
      "Epoch: 6 | Train Loss: 0.3213154 Vali Loss: 0.4017328 Test Loss: 0.4942164 MAE Loss: 0.4657476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007938947\n",
      "99it [00:05, 20.55it/s]\titers: 100, epoch: 7 | loss: 0.2587365\n",
      "\tspeed: 0.4454s/iter; left time: 6662.9005s\n",
      "198it [00:10, 16.38it/s]\titers: 200, epoch: 7 | loss: 0.2547185\n",
      "\tspeed: 0.0510s/iter; left time: 757.5494s\n",
      "299it [00:15, 20.93it/s]\titers: 300, epoch: 7 | loss: 0.1711255\n",
      "\tspeed: 0.0489s/iter; left time: 721.7260s\n",
      "398it [00:19, 21.09it/s]\titers: 400, epoch: 7 | loss: 0.2923927\n",
      "\tspeed: 0.0476s/iter; left time: 697.2360s\n",
      "497it [00:23, 26.99it/s]\titers: 500, epoch: 7 | loss: 0.1488027\n",
      "\tspeed: 0.0366s/iter; left time: 532.9011s\n",
      "599it [00:27, 25.63it/s]\titers: 600, epoch: 7 | loss: 0.2476059\n",
      "\tspeed: 0.0375s/iter; left time: 542.8747s\n",
      "698it [00:31, 27.17it/s]\titers: 700, epoch: 7 | loss: 0.3122873\n",
      "\tspeed: 0.0390s/iter; left time: 560.4698s\n",
      "797it [00:34, 27.43it/s]\titers: 800, epoch: 7 | loss: 0.3172768\n",
      "\tspeed: 0.0376s/iter; left time: 536.6844s\n",
      "899it [00:38, 27.41it/s]\titers: 900, epoch: 7 | loss: 0.3705570\n",
      "\tspeed: 0.0365s/iter; left time: 517.0791s\n",
      "998it [00:42, 26.85it/s]\titers: 1000, epoch: 7 | loss: 0.3579290\n",
      "\tspeed: 0.0369s/iter; left time: 518.3106s\n",
      "1097it [00:46, 22.44it/s]\titers: 1100, epoch: 7 | loss: 0.2547010\n",
      "\tspeed: 0.0390s/iter; left time: 544.1085s\n",
      "1198it [00:51, 20.64it/s]\titers: 1200, epoch: 7 | loss: 0.2480060\n",
      "\tspeed: 0.0496s/iter; left time: 687.8022s\n",
      "1297it [00:55, 26.54it/s]\titers: 1300, epoch: 7 | loss: 0.3988118\n",
      "\tspeed: 0.0450s/iter; left time: 619.4049s\n",
      "1399it [00:59, 27.14it/s]\titers: 1400, epoch: 7 | loss: 0.5011163\n",
      "\tspeed: 0.0369s/iter; left time: 503.7082s\n",
      "1498it [01:02, 26.86it/s]\titers: 1500, epoch: 7 | loss: 0.4515625\n",
      "\tspeed: 0.0370s/iter; left time: 501.9912s\n",
      "1599it [01:07, 20.30it/s]\titers: 1600, epoch: 7 | loss: 0.3117883\n",
      "\tspeed: 0.0421s/iter; left time: 567.0180s\n",
      "1697it [01:11, 21.14it/s]\titers: 1700, epoch: 7 | loss: 0.2716990\n",
      "\tspeed: 0.0479s/iter; left time: 640.2915s\n",
      "1799it [01:16, 20.88it/s]\titers: 1800, epoch: 7 | loss: 0.7125716\n",
      "\tspeed: 0.0476s/iter; left time: 631.4124s\n",
      "1898it [01:21, 20.75it/s]\titers: 1900, epoch: 7 | loss: 0.2071300\n",
      "\tspeed: 0.0482s/iter; left time: 634.4243s\n",
      "1997it [01:26, 20.86it/s]\titers: 2000, epoch: 7 | loss: 0.2426393\n",
      "\tspeed: 0.0518s/iter; left time: 676.1557s\n",
      "2098it [01:31, 21.27it/s]\titers: 2100, epoch: 7 | loss: 0.1984317\n",
      "\tspeed: 0.0481s/iter; left time: 623.0700s\n",
      "2197it [01:36, 21.06it/s]\titers: 2200, epoch: 7 | loss: 0.1494288\n",
      "\tspeed: 0.0473s/iter; left time: 608.5924s\n",
      "2299it [01:41, 20.81it/s]\titers: 2300, epoch: 7 | loss: 0.5832052\n",
      "\tspeed: 0.0478s/iter; left time: 610.3334s\n",
      "2398it [01:46, 21.22it/s]\titers: 2400, epoch: 7 | loss: 0.3682876\n",
      "\tspeed: 0.0497s/iter; left time: 629.0434s\n",
      "2499it [01:50, 21.03it/s]\titers: 2500, epoch: 7 | loss: 0.2163977\n",
      "\tspeed: 0.0482s/iter; left time: 605.6113s\n",
      "2598it [01:55, 20.55it/s]\titers: 2600, epoch: 7 | loss: 0.2967719\n",
      "\tspeed: 0.0483s/iter; left time: 601.8369s\n",
      "2697it [02:00, 20.62it/s]\titers: 2700, epoch: 7 | loss: 0.1685931\n",
      "\tspeed: 0.0483s/iter; left time: 596.8250s\n",
      "2798it [02:05, 21.09it/s]\titers: 2800, epoch: 7 | loss: 0.3736131\n",
      "\tspeed: 0.0479s/iter; left time: 587.8981s\n",
      "2899it [02:10, 21.22it/s]\titers: 2900, epoch: 7 | loss: 0.3515452\n",
      "\tspeed: 0.0480s/iter; left time: 583.2520s\n",
      "2998it [02:14, 21.02it/s]\titers: 3000, epoch: 7 | loss: 0.2952559\n",
      "\tspeed: 0.0474s/iter; left time: 571.1567s\n",
      "3097it [02:19, 20.23it/s]\titers: 3100, epoch: 7 | loss: 0.2084351\n",
      "\tspeed: 0.0478s/iter; left time: 571.7854s\n",
      "3198it [02:24, 20.42it/s]\titers: 3200, epoch: 7 | loss: 0.3070467\n",
      "\tspeed: 0.0506s/iter; left time: 599.6979s\n",
      "3297it [02:29, 21.60it/s]\titers: 3300, epoch: 7 | loss: 0.6324226\n",
      "\tspeed: 0.0466s/iter; left time: 548.0819s\n",
      "3399it [02:34, 21.10it/s]\titers: 3400, epoch: 7 | loss: 0.3521353\n",
      "\tspeed: 0.0476s/iter; left time: 555.4930s\n",
      "3498it [02:39, 19.67it/s]\titers: 3500, epoch: 7 | loss: 0.4087745\n",
      "\tspeed: 0.0500s/iter; left time: 577.7285s\n",
      "3599it [02:43, 21.24it/s]\titers: 3600, epoch: 7 | loss: 0.3843343\n",
      "\tspeed: 0.0479s/iter; left time: 548.7708s\n",
      "3698it [02:48, 20.73it/s]\titers: 3700, epoch: 7 | loss: 0.3293202\n",
      "\tspeed: 0.0478s/iter; left time: 543.4140s\n",
      "3765it [02:51, 21.90it/s]\n",
      "Epoch: 7 cost time: 171.95327973365784\n",
      "810it [00:18, 44.44it/s]\n",
      "807it [00:18, 42.84it/s]\n",
      "Epoch: 7 | Train Loss: 0.3234013 Vali Loss: 0.3747493 Test Loss: 0.4566241 MAE Loss: 0.4435625\n",
      "lr = 0.0007269980\n",
      "98it [00:04, 26.95it/s]\titers: 100, epoch: 8 | loss: 0.2370737\n",
      "\tspeed: 0.4635s/iter; left time: 5188.9216s\n",
      "199it [00:10, 26.83it/s]\titers: 200, epoch: 8 | loss: 0.2688916\n",
      "\tspeed: 0.0574s/iter; left time: 636.9600s\n",
      "298it [00:14, 26.09it/s]\titers: 300, epoch: 8 | loss: 0.3205290\n",
      "\tspeed: 0.0375s/iter; left time: 412.0353s\n",
      "397it [00:17, 27.66it/s]\titers: 400, epoch: 8 | loss: 0.3317786\n",
      "\tspeed: 0.0362s/iter; left time: 394.7026s\n",
      "499it [00:21, 27.31it/s]\titers: 500, epoch: 8 | loss: 0.2706827\n",
      "\tspeed: 0.0367s/iter; left time: 396.6736s\n",
      "599it [00:26, 18.93it/s]\titers: 600, epoch: 8 | loss: 0.2474581\n",
      "\tspeed: 0.0469s/iter; left time: 501.6240s\n",
      "697it [00:31, 20.77it/s]\titers: 700, epoch: 8 | loss: 0.2209042\n",
      "\tspeed: 0.0507s/iter; left time: 536.8410s\n",
      "798it [00:36, 21.10it/s]\titers: 800, epoch: 8 | loss: 0.2024046\n",
      "\tspeed: 0.0477s/iter; left time: 500.4043s\n",
      "897it [00:40, 21.11it/s]\titers: 900, epoch: 8 | loss: 0.2397825\n",
      "\tspeed: 0.0470s/iter; left time: 488.4791s\n",
      "999it [00:45, 20.11it/s]\titers: 1000, epoch: 8 | loss: 0.2143180\n",
      "\tspeed: 0.0491s/iter; left time: 505.1641s\n",
      "1097it [00:50, 20.93it/s]\titers: 1100, epoch: 8 | loss: 0.2608615\n",
      "\tspeed: 0.0483s/iter; left time: 492.8664s\n",
      "1199it [00:55, 20.71it/s]\titers: 1200, epoch: 8 | loss: 0.4630672\n",
      "\tspeed: 0.0482s/iter; left time: 486.8689s\n",
      "1298it [01:00, 20.90it/s]\titers: 1300, epoch: 8 | loss: 0.1618113\n",
      "\tspeed: 0.0477s/iter; left time: 477.2932s\n",
      "1399it [01:05, 20.78it/s]\titers: 1400, epoch: 8 | loss: 0.3430657\n",
      "\tspeed: 0.0498s/iter; left time: 493.3012s\n",
      "1497it [01:09, 21.07it/s]\titers: 1500, epoch: 8 | loss: 0.4110596\n",
      "\tspeed: 0.0481s/iter; left time: 470.7673s\n",
      "1599it [01:14, 21.13it/s]\titers: 1600, epoch: 8 | loss: 0.2552519\n",
      "\tspeed: 0.0473s/iter; left time: 458.6032s\n",
      "1698it [01:19, 21.21it/s]\titers: 1700, epoch: 8 | loss: 0.3897755\n",
      "\tspeed: 0.0473s/iter; left time: 453.4321s\n",
      "1797it [01:24, 21.12it/s]\titers: 1800, epoch: 8 | loss: 0.2326892\n",
      "\tspeed: 0.0507s/iter; left time: 481.2013s\n",
      "1897it [01:29, 20.96it/s]\titers: 1900, epoch: 8 | loss: 0.3441693\n",
      "\tspeed: 0.0483s/iter; left time: 453.9980s\n",
      "1999it [01:34, 20.81it/s]\titers: 2000, epoch: 8 | loss: 0.2448245\n",
      "\tspeed: 0.0477s/iter; left time: 443.7403s\n",
      "2097it [01:38, 27.13it/s]\titers: 2100, epoch: 8 | loss: 0.4092216\n",
      "\tspeed: 0.0417s/iter; left time: 383.5085s\n",
      "2199it [01:42, 21.21it/s]\titers: 2200, epoch: 8 | loss: 0.2047655\n",
      "\tspeed: 0.0457s/iter; left time: 415.7672s\n",
      "2297it [01:47, 21.10it/s]\titers: 2300, epoch: 8 | loss: 0.1774275\n",
      "\tspeed: 0.0481s/iter; left time: 432.8215s\n",
      "2399it [01:52, 22.97it/s]\titers: 2400, epoch: 8 | loss: 0.4591852\n",
      "\tspeed: 0.0467s/iter; left time: 415.1618s\n",
      "2498it [01:57, 18.88it/s]\titers: 2500, epoch: 8 | loss: 0.2251620\n",
      "\tspeed: 0.0473s/iter; left time: 416.1399s\n",
      "2599it [02:02, 19.77it/s]\titers: 2600, epoch: 8 | loss: 0.5411199\n",
      "\tspeed: 0.0537s/iter; left time: 467.2429s\n",
      "2699it [02:07, 19.82it/s]\titers: 2700, epoch: 8 | loss: 0.2770391\n",
      "\tspeed: 0.0509s/iter; left time: 437.8115s\n",
      "2799it [02:12, 23.03it/s]\titers: 2800, epoch: 8 | loss: 0.3129892\n",
      "\tspeed: 0.0470s/iter; left time: 399.5721s\n",
      "2898it [02:17, 19.29it/s]\titers: 2900, epoch: 8 | loss: 0.2220390\n",
      "\tspeed: 0.0523s/iter; left time: 438.7485s\n",
      "2998it [02:22, 18.97it/s]\titers: 3000, epoch: 8 | loss: 0.3038004\n",
      "\tspeed: 0.0523s/iter; left time: 433.5256s\n",
      "3098it [02:27, 22.55it/s]\titers: 3100, epoch: 8 | loss: 0.3250084\n",
      "\tspeed: 0.0476s/iter; left time: 389.7898s\n",
      "3197it [02:31, 21.86it/s]\titers: 3200, epoch: 8 | loss: 0.4287906\n",
      "\tspeed: 0.0454s/iter; left time: 367.3743s\n",
      "3299it [02:37, 18.40it/s]\titers: 3300, epoch: 8 | loss: 0.3246199\n",
      "\tspeed: 0.0546s/iter; left time: 436.3940s\n",
      "3399it [02:42, 25.38it/s]\titers: 3400, epoch: 8 | loss: 0.4069696\n",
      "\tspeed: 0.0465s/iter; left time: 366.9141s\n",
      "3498it [02:46, 23.40it/s]\titers: 3500, epoch: 8 | loss: 0.4347954\n",
      "\tspeed: 0.0467s/iter; left time: 364.4541s\n",
      "3597it [02:51, 18.77it/s]\titers: 3600, epoch: 8 | loss: 0.2451416\n",
      "\tspeed: 0.0505s/iter; left time: 388.9816s\n",
      "3698it [02:56, 21.19it/s]\titers: 3700, epoch: 8 | loss: 0.2654694\n",
      "\tspeed: 0.0462s/iter; left time: 350.9345s\n",
      "3765it [02:59, 20.98it/s]\n",
      "Epoch: 8 cost time: 179.48489117622375\n",
      "810it [00:17, 45.07it/s]\n",
      "807it [00:18, 43.79it/s]\n",
      "Epoch: 8 | Train Loss: 0.3110532 Vali Loss: 0.3892361 Test Loss: 0.4766645 MAE Loss: 0.4625494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0006545120\n",
      "97it [00:04, 20.07it/s]\titers: 100, epoch: 9 | loss: 0.3401400\n",
      "\tspeed: 0.4453s/iter; left time: 3308.8656s\n",
      "199it [00:09, 22.79it/s]\titers: 200, epoch: 9 | loss: 0.2310641\n",
      "\tspeed: 0.0475s/iter; left time: 347.9327s\n",
      "298it [00:14, 24.71it/s]\titers: 300, epoch: 9 | loss: 0.2725943\n",
      "\tspeed: 0.0459s/iter; left time: 332.1790s\n",
      "397it [00:19, 21.19it/s]\titers: 400, epoch: 9 | loss: 0.3125853\n",
      "\tspeed: 0.0480s/iter; left time: 342.1198s\n",
      "499it [00:23, 21.19it/s]\titers: 500, epoch: 9 | loss: 0.2465193\n",
      "\tspeed: 0.0437s/iter; left time: 307.1876s\n",
      "598it [00:28, 20.00it/s]\titers: 600, epoch: 9 | loss: 0.2563796\n",
      "\tspeed: 0.0475s/iter; left time: 329.4982s\n",
      "697it [00:33, 20.48it/s]\titers: 700, epoch: 9 | loss: 0.3062128\n",
      "\tspeed: 0.0502s/iter; left time: 343.0219s\n",
      "798it [00:38, 19.81it/s]\titers: 800, epoch: 9 | loss: 0.1679011\n",
      "\tspeed: 0.0490s/iter; left time: 329.5344s\n",
      "899it [00:42, 21.04it/s]\titers: 900, epoch: 9 | loss: 0.2823606\n",
      "\tspeed: 0.0482s/iter; left time: 319.4853s\n",
      "999it [00:47, 19.97it/s]\titers: 1000, epoch: 9 | loss: 0.2486612\n",
      "\tspeed: 0.0497s/iter; left time: 324.8969s\n",
      "1099it [00:53, 19.86it/s]\titers: 1100, epoch: 9 | loss: 0.2816679\n",
      "\tspeed: 0.0505s/iter; left time: 324.8751s\n",
      "1198it [00:58, 20.45it/s]\titers: 1200, epoch: 9 | loss: 0.4455756\n",
      "\tspeed: 0.0513s/iter; left time: 324.8918s\n",
      "1299it [01:02, 25.79it/s]\titers: 1300, epoch: 9 | loss: 0.5901271\n",
      "\tspeed: 0.0408s/iter; left time: 254.0769s\n",
      "1399it [01:07, 20.32it/s]\titers: 1400, epoch: 9 | loss: 0.2027962\n",
      "\tspeed: 0.0485s/iter; left time: 297.2910s\n",
      "1498it [01:12, 19.76it/s]\titers: 1500, epoch: 9 | loss: 0.2655527\n",
      "\tspeed: 0.0511s/iter; left time: 308.2946s\n",
      "1598it [01:17, 20.08it/s]\titers: 1600, epoch: 9 | loss: 0.3382596\n",
      "\tspeed: 0.0497s/iter; left time: 294.7743s\n",
      "1698it [01:22, 18.41it/s]\titers: 1700, epoch: 9 | loss: 0.2737886\n",
      "\tspeed: 0.0519s/iter; left time: 302.3528s\n",
      "1797it [01:27, 19.66it/s]\titers: 1800, epoch: 9 | loss: 0.4017577\n",
      "\tspeed: 0.0517s/iter; left time: 296.3614s\n",
      "1899it [01:32, 20.79it/s]\titers: 1900, epoch: 9 | loss: 0.2776239\n",
      "\tspeed: 0.0489s/iter; left time: 275.2311s\n",
      "1998it [01:37, 20.12it/s]\titers: 2000, epoch: 9 | loss: 0.1964203\n",
      "\tspeed: 0.0484s/iter; left time: 267.9413s\n",
      "2097it [01:42, 20.25it/s]\titers: 2100, epoch: 9 | loss: 0.2677019\n",
      "\tspeed: 0.0511s/iter; left time: 277.5615s\n",
      "2199it [01:47, 23.40it/s]\titers: 2200, epoch: 9 | loss: 0.1595493\n",
      "\tspeed: 0.0473s/iter; left time: 252.1521s\n",
      "2298it [01:50, 27.52it/s]\titers: 2300, epoch: 9 | loss: 0.1916599\n",
      "\tspeed: 0.0368s/iter; left time: 192.3084s\n",
      "2397it [01:54, 27.19it/s]\titers: 2400, epoch: 9 | loss: 0.2173805\n",
      "\tspeed: 0.0367s/iter; left time: 188.4590s\n",
      "2499it [01:58, 23.81it/s]\titers: 2500, epoch: 9 | loss: 0.2299462\n",
      "\tspeed: 0.0378s/iter; left time: 190.1064s\n",
      "2598it [02:02, 27.32it/s]\titers: 2600, epoch: 9 | loss: 0.1971519\n",
      "\tspeed: 0.0382s/iter; left time: 188.4613s\n",
      "2697it [02:05, 27.84it/s]\titers: 2700, epoch: 9 | loss: 0.3081047\n",
      "\tspeed: 0.0370s/iter; left time: 178.9160s\n",
      "2799it [02:09, 27.65it/s]\titers: 2800, epoch: 9 | loss: 0.2252719\n",
      "\tspeed: 0.0360s/iter; left time: 170.1578s\n",
      "2898it [02:13, 21.04it/s]\titers: 2900, epoch: 9 | loss: 0.2207107\n",
      "\tspeed: 0.0430s/iter; left time: 199.3611s\n",
      "2998it [02:18, 20.97it/s]\titers: 3000, epoch: 9 | loss: 0.2741799\n",
      "\tspeed: 0.0475s/iter; left time: 215.2740s\n",
      "3099it [02:23, 21.48it/s]\titers: 3100, epoch: 9 | loss: 0.2624743\n",
      "\tspeed: 0.0478s/iter; left time: 211.9831s\n",
      "3198it [02:27, 21.43it/s]\titers: 3200, epoch: 9 | loss: 0.3671949\n",
      "\tspeed: 0.0469s/iter; left time: 203.0407s\n",
      "3297it [02:32, 21.11it/s]\titers: 3300, epoch: 9 | loss: 0.4108158\n",
      "\tspeed: 0.0472s/iter; left time: 199.7667s\n",
      "3397it [02:37, 19.04it/s]\titers: 3400, epoch: 9 | loss: 0.3032409\n",
      "\tspeed: 0.0502s/iter; left time: 207.5606s\n",
      "3498it [02:42, 21.19it/s]\titers: 3500, epoch: 9 | loss: 0.3279886\n",
      "\tspeed: 0.0472s/iter; left time: 190.1387s\n",
      "3597it [02:46, 21.26it/s]\titers: 3600, epoch: 9 | loss: 0.2641124\n",
      "\tspeed: 0.0472s/iter; left time: 185.4518s\n",
      "3699it [02:52, 19.24it/s]\titers: 3700, epoch: 9 | loss: 0.2115594\n",
      "\tspeed: 0.0529s/iter; left time: 202.6749s\n",
      "3765it [02:55, 21.42it/s]\n",
      "Epoch: 9 cost time: 175.78775358200073\n",
      "810it [00:18, 44.60it/s]\n",
      "807it [00:18, 44.68it/s]\n",
      "Epoch: 9 | Train Loss: 0.3078297 Vali Loss: 0.3715478 Test Loss: 0.4544242 MAE Loss: 0.4413584\n",
      "lr = 0.0005782215\n",
      "98it [00:05, 20.49it/s]\titers: 100, epoch: 10 | loss: 0.2440642\n",
      "\tspeed: 0.4611s/iter; left time: 1690.4033s\n",
      "198it [00:10, 18.75it/s]\titers: 200, epoch: 10 | loss: 0.2456951\n",
      "\tspeed: 0.0508s/iter; left time: 181.2130s\n",
      "299it [00:16, 16.75it/s]\titers: 300, epoch: 10 | loss: 0.4275633\n",
      "\tspeed: 0.0571s/iter; left time: 197.8642s\n",
      "398it [00:20, 19.65it/s]\titers: 400, epoch: 10 | loss: 0.3124236\n",
      "\tspeed: 0.0499s/iter; left time: 167.8328s\n",
      "499it [00:26, 18.82it/s]\titers: 500, epoch: 10 | loss: 0.3608543\n",
      "\tspeed: 0.0520s/iter; left time: 169.6971s\n",
      "598it [00:31, 18.83it/s]\titers: 600, epoch: 10 | loss: 0.2916918\n",
      "\tspeed: 0.0563s/iter; left time: 178.1282s\n",
      "698it [00:36, 19.80it/s]\titers: 700, epoch: 10 | loss: 0.4221830\n",
      "\tspeed: 0.0519s/iter; left time: 159.2734s\n",
      "798it [00:41, 21.07it/s]\titers: 800, epoch: 10 | loss: 0.1877646\n",
      "\tspeed: 0.0490s/iter; left time: 145.1963s\n",
      "897it [00:46, 20.93it/s]\titers: 900, epoch: 10 | loss: 0.2650401\n",
      "\tspeed: 0.0477s/iter; left time: 136.8025s\n",
      "998it [00:51, 18.27it/s]\titers: 1000, epoch: 10 | loss: 0.2981644\n",
      "\tspeed: 0.0509s/iter; left time: 140.7337s\n",
      "1097it [00:56, 20.92it/s]\titers: 1100, epoch: 10 | loss: 0.2430556\n",
      "\tspeed: 0.0473s/iter; left time: 125.9905s\n",
      "1199it [01:00, 24.66it/s]\titers: 1200, epoch: 10 | loss: 0.2154697\n",
      "\tspeed: 0.0425s/iter; left time: 109.0328s\n",
      "1298it [01:04, 24.02it/s]\titers: 1300, epoch: 10 | loss: 0.1716341\n",
      "\tspeed: 0.0425s/iter; left time: 104.7664s\n",
      "1397it [01:09, 21.16it/s]\titers: 1400, epoch: 10 | loss: 0.4797420\n",
      "\tspeed: 0.0457s/iter; left time: 108.1160s\n",
      "1498it [01:14, 20.97it/s]\titers: 1500, epoch: 10 | loss: 0.2266493\n",
      "\tspeed: 0.0481s/iter; left time: 109.0207s\n",
      "1597it [01:18, 27.21it/s]\titers: 1600, epoch: 10 | loss: 0.2267359\n",
      "\tspeed: 0.0437s/iter; left time: 94.7149s\n",
      "1699it [01:22, 26.79it/s]\titers: 1700, epoch: 10 | loss: 0.4768562\n",
      "\tspeed: 0.0369s/iter; left time: 76.3260s\n",
      "1798it [01:27, 18.57it/s]\titers: 1800, epoch: 10 | loss: 0.4119195\n",
      "\tspeed: 0.0479s/iter; left time: 94.2515s\n",
      "1899it [01:32, 21.39it/s]\titers: 1900, epoch: 10 | loss: 0.2874663\n",
      "\tspeed: 0.0477s/iter; left time: 89.0469s\n",
      "1998it [01:36, 20.95it/s]\titers: 2000, epoch: 10 | loss: 0.3070314\n",
      "\tspeed: 0.0472s/iter; left time: 83.3069s\n",
      "2097it [01:41, 21.01it/s]\titers: 2100, epoch: 10 | loss: 0.1895691\n",
      "\tspeed: 0.0475s/iter; left time: 79.0555s\n",
      "2197it [01:46, 21.23it/s]\titers: 2200, epoch: 10 | loss: 0.3342938\n",
      "\tspeed: 0.0489s/iter; left time: 76.6476s\n",
      "2298it [01:51, 21.24it/s]\titers: 2300, epoch: 10 | loss: 0.1965497\n",
      "\tspeed: 0.0478s/iter; left time: 70.0648s\n",
      "2397it [01:55, 21.04it/s]\titers: 2400, epoch: 10 | loss: 0.2242428\n",
      "\tspeed: 0.0474s/iter; left time: 64.7221s\n",
      "2499it [02:00, 20.78it/s]\titers: 2500, epoch: 10 | loss: 0.2465717\n",
      "\tspeed: 0.0479s/iter; left time: 60.6908s\n",
      "2599it [02:05, 21.36it/s]\titers: 2600, epoch: 10 | loss: 0.1841516\n",
      "\tspeed: 0.0484s/iter; left time: 56.4208s\n",
      "2698it [02:10, 21.34it/s]\titers: 2700, epoch: 10 | loss: 0.3883455\n",
      "\tspeed: 0.0477s/iter; left time: 50.8751s\n",
      "2797it [02:14, 20.98it/s]\titers: 2800, epoch: 10 | loss: 0.2909786\n",
      "\tspeed: 0.0473s/iter; left time: 45.6642s\n",
      "2899it [02:19, 17.78it/s]\titers: 2900, epoch: 10 | loss: 0.3305136\n",
      "\tspeed: 0.0489s/iter; left time: 42.3234s\n",
      "2997it [02:24, 20.91it/s]\titers: 3000, epoch: 10 | loss: 0.3906245\n",
      "\tspeed: 0.0500s/iter; left time: 38.3041s\n",
      "3099it [02:29, 21.30it/s]\titers: 3100, epoch: 10 | loss: 0.4345736\n",
      "\tspeed: 0.0469s/iter; left time: 31.2521s\n",
      "3198it [02:34, 20.88it/s]\titers: 3200, epoch: 10 | loss: 0.2772962\n",
      "\tspeed: 0.0472s/iter; left time: 26.6893s\n",
      "3297it [02:39, 21.25it/s]\titers: 3300, epoch: 10 | loss: 0.2467601\n",
      "\tspeed: 0.0484s/iter; left time: 22.5409s\n",
      "3399it [02:43, 21.24it/s]\titers: 3400, epoch: 10 | loss: 0.2804783\n",
      "\tspeed: 0.0478s/iter; left time: 17.4899s\n",
      "3498it [02:48, 21.22it/s]\titers: 3500, epoch: 10 | loss: 0.3329879\n",
      "\tspeed: 0.0469s/iter; left time: 12.4780s\n",
      "3597it [02:53, 21.12it/s]\titers: 3600, epoch: 10 | loss: 0.2088789\n",
      "\tspeed: 0.0471s/iter; left time: 7.8167s\n",
      "3698it [02:58, 20.99it/s]\titers: 3700, epoch: 10 | loss: 0.2641986\n",
      "\tspeed: 0.0486s/iter; left time: 3.2051s\n",
      "3765it [03:01, 20.75it/s]\n",
      "Epoch: 10 cost time: 181.4452724456787\n",
      "810it [00:18, 43.47it/s]\n",
      "807it [00:17, 44.88it/s]\n",
      "Epoch: 10 | Train Loss: 0.3051014 Vali Loss: 0.3621393 Test Loss: 0.4520630 MAE Loss: 0.4392797\n",
      "lr = 0.0005000050\n",
      "Total time: 35.74961925347646 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same but medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-04 01:48:31,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 01:48:32,846] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 01:48:32,846] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 01:48:32,846] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 01:48:33,757] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 01:48:33,757] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 01:48:34,760] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 01:48:34,761] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 01:48:34,761] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 01:48:34,762] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 01:48:34,762] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 01:48:34,762] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 01:48:34,762] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 01:48:34,762] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 01:48:34,763] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 01:48:34,763] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 01:48:35,014] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 01:48:35,015] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:48:35,015] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.67 GB, percent = 15.2%\n",
      "[2024-05-04 01:48:35,247] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 01:48:35,248] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:48:35,248] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.67 GB, percent = 15.2%\n",
      "[2024-05-04 01:48:35,248] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 01:48:35,354] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 01:48:35,354] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 01:48:35,354] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 114.73 GB, percent = 15.2%\n",
      "[2024-05-04 01:48:35,355] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 01:48:35,355] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 01:48:35,355] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 01:48:35,355] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6c62b06a10>\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 01:48:35,356] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 01:48:35,357] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:11,  9.48it/s]\titers: 100, epoch: 1 | loss: 0.3093423\n",
      "\tspeed: 0.1584s/iter; left time: 5946.8943s\n",
      "199it [00:22,  9.01it/s]\titers: 200, epoch: 1 | loss: 0.2864971\n",
      "\tspeed: 0.1088s/iter; left time: 4074.6686s\n",
      "299it [00:34,  9.46it/s]\titers: 300, epoch: 1 | loss: 0.3281956\n",
      "\tspeed: 0.1127s/iter; left time: 4210.5223s\n",
      "399it [00:44,  9.10it/s]\titers: 400, epoch: 1 | loss: 0.2650904\n",
      "\tspeed: 0.1072s/iter; left time: 3991.9999s\n",
      "499it [00:56,  9.73it/s]\titers: 500, epoch: 1 | loss: 0.5327372\n",
      "\tspeed: 0.1122s/iter; left time: 4169.3313s\n",
      "599it [01:06,  9.20it/s]\titers: 600, epoch: 1 | loss: 0.4221294\n",
      "\tspeed: 0.1087s/iter; left time: 4028.9816s\n",
      "698it [01:17,  9.21it/s]\titers: 700, epoch: 1 | loss: 0.2700348\n",
      "\tspeed: 0.1081s/iter; left time: 3995.3631s\n",
      "799it [01:28,  9.62it/s]\titers: 800, epoch: 1 | loss: 0.1736799\n",
      "\tspeed: 0.1114s/iter; left time: 4103.4003s\n",
      "899it [01:39,  9.13it/s]\titers: 900, epoch: 1 | loss: 0.2950753\n",
      "\tspeed: 0.1092s/iter; left time: 4012.7293s\n",
      "999it [01:50,  9.60it/s]\titers: 1000, epoch: 1 | loss: 0.2127067\n",
      "\tspeed: 0.1071s/iter; left time: 3925.3058s\n",
      "1099it [02:01,  7.74it/s]\titers: 1100, epoch: 1 | loss: 0.2738011\n",
      "\tspeed: 0.1085s/iter; left time: 3966.7339s\n",
      "1199it [02:12,  9.47it/s]\titers: 1200, epoch: 1 | loss: 0.2650603\n",
      "\tspeed: 0.1072s/iter; left time: 3906.5220s\n",
      "1299it [02:22,  9.52it/s]\titers: 1300, epoch: 1 | loss: 0.2692506\n",
      "\tspeed: 0.1090s/iter; left time: 3960.5764s\n",
      "1399it [02:33,  9.11it/s]\titers: 1400, epoch: 1 | loss: 0.3322053\n",
      "\tspeed: 0.1071s/iter; left time: 3881.7457s\n",
      "1499it [02:44,  9.21it/s]\titers: 1500, epoch: 1 | loss: 0.4773281\n",
      "\tspeed: 0.1112s/iter; left time: 4018.2073s\n",
      "1599it [02:55,  9.46it/s]\titers: 1600, epoch: 1 | loss: 0.2954048\n",
      "\tspeed: 0.1119s/iter; left time: 4034.9733s\n",
      "1699it [03:06,  9.14it/s]\titers: 1700, epoch: 1 | loss: 0.2433645\n",
      "\tspeed: 0.1081s/iter; left time: 3884.9978s\n",
      "1799it [03:17,  9.23it/s]\titers: 1800, epoch: 1 | loss: 0.3445834\n",
      "\tspeed: 0.1100s/iter; left time: 3943.7320s\n",
      "1899it [03:28,  9.62it/s]\titers: 1900, epoch: 1 | loss: 0.3814037\n",
      "\tspeed: 0.1054s/iter; left time: 3768.5342s\n",
      "1999it [03:38, 10.13it/s]\titers: 2000, epoch: 1 | loss: 0.2499830\n",
      "\tspeed: 0.1025s/iter; left time: 3654.7135s\n",
      "2099it [03:48,  9.24it/s]\titers: 2100, epoch: 1 | loss: 0.3895558\n",
      "\tspeed: 0.1018s/iter; left time: 3619.6134s\n",
      "2199it [03:59,  9.91it/s]\titers: 2200, epoch: 1 | loss: 0.1822312\n",
      "\tspeed: 0.1024s/iter; left time: 3628.8298s\n",
      "2299it [04:09,  9.79it/s]\titers: 2300, epoch: 1 | loss: 0.3100661\n",
      "\tspeed: 0.1024s/iter; left time: 3619.9211s\n",
      "2399it [04:19,  9.92it/s]\titers: 2400, epoch: 1 | loss: 0.2622257\n",
      "\tspeed: 0.1015s/iter; left time: 3579.0270s\n",
      "2499it [04:30,  9.30it/s]\titers: 2500, epoch: 1 | loss: 0.2354961\n",
      "\tspeed: 0.1068s/iter; left time: 3754.3658s\n",
      "2598it [04:40,  9.84it/s]\titers: 2600, epoch: 1 | loss: 0.1916121\n",
      "\tspeed: 0.1053s/iter; left time: 3689.8174s\n",
      "2699it [04:50,  9.93it/s]\titers: 2700, epoch: 1 | loss: 0.1694384\n",
      "\tspeed: 0.1028s/iter; left time: 3591.6183s\n",
      "2799it [05:00,  9.83it/s]\titers: 2800, epoch: 1 | loss: 0.1786753\n",
      "\tspeed: 0.1003s/iter; left time: 3497.2293s\n",
      "2899it [05:11,  9.99it/s]\titers: 2900, epoch: 1 | loss: 0.3141781\n",
      "\tspeed: 0.1036s/iter; left time: 3601.2490s\n",
      "2999it [05:21,  9.59it/s]\titers: 3000, epoch: 1 | loss: 0.2984454\n",
      "\tspeed: 0.1018s/iter; left time: 3528.7325s\n",
      "3099it [05:31,  9.91it/s]\titers: 3100, epoch: 1 | loss: 0.2226067\n",
      "\tspeed: 0.1012s/iter; left time: 3495.2641s\n",
      "3199it [05:42,  9.50it/s]\titers: 3200, epoch: 1 | loss: 0.6298969\n",
      "\tspeed: 0.1047s/iter; left time: 3606.6730s\n",
      "3299it [05:52,  9.61it/s]\titers: 3300, epoch: 1 | loss: 0.4334720\n",
      "\tspeed: 0.1028s/iter; left time: 3529.7041s\n",
      "3399it [06:03,  8.81it/s]\titers: 3400, epoch: 1 | loss: 0.2399489\n",
      "\tspeed: 0.1113s/iter; left time: 3812.3927s\n",
      "3499it [06:14,  9.52it/s]\titers: 3500, epoch: 1 | loss: 0.3380310\n",
      "\tspeed: 0.1087s/iter; left time: 3710.7799s\n",
      "3599it [06:25,  9.38it/s]\titers: 3600, epoch: 1 | loss: 0.4184629\n",
      "\tspeed: 0.1088s/iter; left time: 3704.9598s\n",
      "3699it [06:36,  8.23it/s]\titers: 3700, epoch: 1 | loss: 0.2152787\n",
      "\tspeed: 0.1085s/iter; left time: 3683.8254s\n",
      "3765it [06:43,  9.34it/s]\n",
      "Epoch: 1 cost time: 403.2825710773468\n",
      "810it [00:41, 19.64it/s]\n",
      "807it [00:40, 19.79it/s]\n",
      "Epoch: 1 | Train Loss: 0.3339224 Vali Loss: 0.3933200 Test Loss: 0.4867423 MAE Loss: 0.4654253\n",
      "lr = 0.0009938442\n",
      "99it [00:10,  9.75it/s]\titers: 100, epoch: 2 | loss: 0.3026230\n",
      "\tspeed: 1.0596s/iter; left time: 35800.3769s\n",
      "199it [00:21,  9.75it/s]\titers: 200, epoch: 2 | loss: 0.6705697\n",
      "\tspeed: 0.1094s/iter; left time: 3685.7311s\n",
      "299it [00:32,  8.00it/s]\titers: 300, epoch: 2 | loss: 0.3486599\n",
      "\tspeed: 0.1070s/iter; left time: 3593.1762s\n",
      "399it [00:42,  9.70it/s]\titers: 400, epoch: 2 | loss: 0.2858748\n",
      "\tspeed: 0.1036s/iter; left time: 3468.8140s\n",
      "499it [00:53,  8.56it/s]\titers: 500, epoch: 2 | loss: 0.2096060\n",
      "\tspeed: 0.1101s/iter; left time: 3675.0399s\n",
      "599it [01:03,  9.84it/s]\titers: 600, epoch: 2 | loss: 0.5453781\n",
      "\tspeed: 0.1036s/iter; left time: 3447.8249s\n",
      "699it [01:14,  9.73it/s]\titers: 700, epoch: 2 | loss: 0.5345441\n",
      "\tspeed: 0.1089s/iter; left time: 3615.4011s\n",
      "799it [01:25,  9.32it/s]\titers: 800, epoch: 2 | loss: 0.2707790\n",
      "\tspeed: 0.1051s/iter; left time: 3476.6797s\n",
      "899it [01:36,  9.73it/s]\titers: 900, epoch: 2 | loss: 0.2026536\n",
      "\tspeed: 0.1080s/iter; left time: 3563.1702s\n",
      "999it [01:46,  9.34it/s]\titers: 1000, epoch: 2 | loss: 0.3182488\n",
      "\tspeed: 0.1078s/iter; left time: 3543.4688s\n",
      "1099it [01:57,  9.78it/s]\titers: 1100, epoch: 2 | loss: 0.2403988\n",
      "\tspeed: 0.1050s/iter; left time: 3440.9071s\n",
      "1199it [02:08,  9.70it/s]\titers: 1200, epoch: 2 | loss: 0.2817720\n",
      "\tspeed: 0.1072s/iter; left time: 3504.6224s\n",
      "1299it [02:18,  9.51it/s]\titers: 1300, epoch: 2 | loss: 0.1941828\n",
      "\tspeed: 0.1044s/iter; left time: 3401.5516s\n",
      "1399it [02:29, 10.03it/s]\titers: 1400, epoch: 2 | loss: 0.3358688\n",
      "\tspeed: 0.1075s/iter; left time: 3493.1088s\n",
      "1499it [02:39,  9.48it/s]\titers: 1500, epoch: 2 | loss: 0.4084879\n",
      "\tspeed: 0.1037s/iter; left time: 3359.9955s\n",
      "1599it [02:50,  9.58it/s]\titers: 1600, epoch: 2 | loss: 0.3015815\n",
      "\tspeed: 0.1049s/iter; left time: 3386.8216s\n",
      "1699it [03:00,  7.68it/s]\titers: 1700, epoch: 2 | loss: 0.1584121\n",
      "\tspeed: 0.1044s/iter; left time: 3361.2192s\n",
      "1799it [03:11,  8.99it/s]\titers: 1800, epoch: 2 | loss: 0.3174228\n",
      "\tspeed: 0.1113s/iter; left time: 3572.3644s\n",
      "1898it [03:22,  9.57it/s]\titers: 1900, epoch: 2 | loss: 0.5479672\n",
      "\tspeed: 0.1100s/iter; left time: 3517.3226s\n",
      "1999it [03:33,  8.98it/s]\titers: 2000, epoch: 2 | loss: 0.2074919\n",
      "\tspeed: 0.1093s/iter; left time: 3484.0727s\n",
      "2099it [03:44,  8.51it/s]\titers: 2100, epoch: 2 | loss: 0.3709853\n",
      "\tspeed: 0.1109s/iter; left time: 3526.5575s\n",
      "2198it [03:55,  9.56it/s]\titers: 2200, epoch: 2 | loss: 0.2229371\n",
      "\tspeed: 0.1036s/iter; left time: 3283.5040s\n",
      "2299it [04:05,  9.82it/s]\titers: 2300, epoch: 2 | loss: 0.4249352\n",
      "\tspeed: 0.1070s/iter; left time: 3380.7852s\n",
      "2399it [04:16,  9.38it/s]\titers: 2400, epoch: 2 | loss: 0.1989166\n",
      "\tspeed: 0.1028s/iter; left time: 3237.2893s\n",
      "2499it [04:26,  9.58it/s]\titers: 2500, epoch: 2 | loss: 0.3395654\n",
      "\tspeed: 0.1027s/iter; left time: 3224.4578s\n",
      "2599it [04:37,  7.79it/s]\titers: 2600, epoch: 2 | loss: 0.3081344\n",
      "\tspeed: 0.1083s/iter; left time: 3387.8909s\n",
      "2699it [04:47,  9.70it/s]\titers: 2700, epoch: 2 | loss: 0.2423075\n",
      "\tspeed: 0.1036s/iter; left time: 3229.7875s\n",
      "2799it [04:58,  9.79it/s]\titers: 2800, epoch: 2 | loss: 0.2690123\n",
      "\tspeed: 0.1069s/iter; left time: 3324.4085s\n",
      "2899it [05:08,  9.59it/s]\titers: 2900, epoch: 2 | loss: 0.2901224\n",
      "\tspeed: 0.1040s/iter; left time: 3222.4379s\n",
      "2998it [05:19, 10.01it/s]\titers: 3000, epoch: 2 | loss: 0.3037252\n",
      "\tspeed: 0.1065s/iter; left time: 3288.2516s\n",
      "3098it [05:28, 10.10it/s]\titers: 3100, epoch: 2 | loss: 0.3903669\n",
      "\tspeed: 0.0970s/iter; left time: 2987.7573s\n",
      "3199it [05:39,  9.65it/s]\titers: 3200, epoch: 2 | loss: 0.4314175\n",
      "\tspeed: 0.1032s/iter; left time: 3167.6665s\n",
      "3299it [05:49,  7.80it/s]\titers: 3300, epoch: 2 | loss: 0.3700314\n",
      "\tspeed: 0.1048s/iter; left time: 3204.6503s\n",
      "3398it [06:00,  9.60it/s]\titers: 3400, epoch: 2 | loss: 0.4604722\n",
      "\tspeed: 0.1066s/iter; left time: 3249.2283s\n",
      "3498it [06:10, 10.50it/s]\titers: 3500, epoch: 2 | loss: 0.3726371\n",
      "\tspeed: 0.0992s/iter; left time: 3014.9430s\n",
      "3598it [06:20, 10.35it/s]\titers: 3600, epoch: 2 | loss: 0.2676335\n",
      "\tspeed: 0.0988s/iter; left time: 2991.4927s\n",
      "3699it [06:30,  9.82it/s]\titers: 3700, epoch: 2 | loss: 0.4028404\n",
      "\tspeed: 0.1020s/iter; left time: 3077.6406s\n",
      "3765it [06:37,  9.48it/s]\n",
      "Epoch: 2 cost time: 397.1639528274536\n",
      "810it [00:38, 21.10it/s]\n",
      "807it [00:37, 21.50it/s]\n",
      "Epoch: 2 | Train Loss: 0.3257510 Vali Loss: 0.4141207 Test Loss: 0.5072606 MAE Loss: 0.4774968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009755285\n",
      "99it [00:11,  9.53it/s]\titers: 100, epoch: 3 | loss: 0.3383845\n",
      "\tspeed: 0.9421s/iter; left time: 28282.3833s\n",
      "199it [00:22,  8.06it/s]\titers: 200, epoch: 3 | loss: 0.3268642\n",
      "\tspeed: 0.1080s/iter; left time: 3230.3864s\n",
      "299it [00:33,  9.34it/s]\titers: 300, epoch: 3 | loss: 0.4416980\n",
      "\tspeed: 0.1099s/iter; left time: 3278.1821s\n",
      "399it [00:44,  7.40it/s]\titers: 400, epoch: 3 | loss: 0.2697511\n",
      "\tspeed: 0.1147s/iter; left time: 3410.1332s\n",
      "499it [00:55,  9.33it/s]\titers: 500, epoch: 3 | loss: 0.3242953\n",
      "\tspeed: 0.1063s/iter; left time: 3147.7233s\n",
      "599it [01:06,  9.15it/s]\titers: 600, epoch: 3 | loss: 0.3206148\n",
      "\tspeed: 0.1104s/iter; left time: 3258.2496s\n",
      "699it [01:17,  9.06it/s]\titers: 700, epoch: 3 | loss: 0.5695320\n",
      "\tspeed: 0.1109s/iter; left time: 3262.9177s\n",
      "799it [01:28,  9.27it/s]\titers: 800, epoch: 3 | loss: 0.4981947\n",
      "\tspeed: 0.1146s/iter; left time: 3360.6864s\n",
      "899it [01:40,  6.84it/s]\titers: 900, epoch: 3 | loss: 0.3123422\n",
      "\tspeed: 0.1114s/iter; left time: 3256.2875s\n",
      "999it [01:50,  9.65it/s]\titers: 1000, epoch: 3 | loss: 0.1778338\n",
      "\tspeed: 0.1049s/iter; left time: 3054.6220s\n",
      "1099it [02:01,  8.98it/s]\titers: 1100, epoch: 3 | loss: 0.5068719\n",
      "\tspeed: 0.1078s/iter; left time: 3129.7124s\n",
      "1199it [02:11,  9.76it/s]\titers: 1200, epoch: 3 | loss: 0.4546197\n",
      "\tspeed: 0.1040s/iter; left time: 3007.6559s\n",
      "1299it [02:22,  9.88it/s]\titers: 1300, epoch: 3 | loss: 0.3733933\n",
      "\tspeed: 0.1059s/iter; left time: 3051.2828s\n",
      "1399it [02:32,  9.61it/s]\titers: 1400, epoch: 3 | loss: 0.3663713\n",
      "\tspeed: 0.1043s/iter; left time: 2996.4174s\n",
      "1499it [02:43,  9.22it/s]\titers: 1500, epoch: 3 | loss: 0.2073531\n",
      "\tspeed: 0.1078s/iter; left time: 3084.4813s\n",
      "1599it [02:53,  9.47it/s]\titers: 1600, epoch: 3 | loss: 0.2994351\n",
      "\tspeed: 0.1037s/iter; left time: 2957.2193s\n",
      "1699it [03:04,  8.94it/s]\titers: 1700, epoch: 3 | loss: 0.3227765\n",
      "\tspeed: 0.1095s/iter; left time: 3112.4007s\n",
      "1798it [03:14,  9.72it/s]\titers: 1800, epoch: 3 | loss: 0.1974620\n",
      "\tspeed: 0.1011s/iter; left time: 2862.2583s\n",
      "1899it [03:25,  9.64it/s]\titers: 1900, epoch: 3 | loss: 0.4105817\n",
      "\tspeed: 0.1032s/iter; left time: 2912.1915s\n",
      "1999it [03:36,  9.57it/s]\titers: 2000, epoch: 3 | loss: 0.3660118\n",
      "\tspeed: 0.1090s/iter; left time: 3064.2632s\n",
      "2098it [03:46,  9.23it/s]\titers: 2100, epoch: 3 | loss: 0.4231451\n",
      "\tspeed: 0.1045s/iter; left time: 2928.1176s\n",
      "2198it [03:57,  9.49it/s]\titers: 2200, epoch: 3 | loss: 0.2297770\n",
      "\tspeed: 0.1044s/iter; left time: 2914.9079s\n",
      "2299it [04:07,  9.47it/s]\titers: 2300, epoch: 3 | loss: 0.2101880\n",
      "\tspeed: 0.1041s/iter; left time: 2894.8797s\n",
      "2399it [04:18,  8.91it/s]\titers: 2400, epoch: 3 | loss: 0.4476412\n",
      "\tspeed: 0.1099s/iter; left time: 3046.2710s\n",
      "2499it [04:29,  9.39it/s]\titers: 2500, epoch: 3 | loss: 0.2514104\n",
      "\tspeed: 0.1061s/iter; left time: 2931.0728s\n",
      "2599it [04:39,  9.38it/s]\titers: 2600, epoch: 3 | loss: 0.7028185\n",
      "\tspeed: 0.1077s/iter; left time: 2964.6940s\n",
      "2699it [04:50,  7.76it/s]\titers: 2700, epoch: 3 | loss: 0.4084406\n",
      "\tspeed: 0.1079s/iter; left time: 2959.1886s\n",
      "2799it [05:01,  9.63it/s]\titers: 2800, epoch: 3 | loss: 0.2733059\n",
      "\tspeed: 0.1063s/iter; left time: 2904.1495s\n",
      "2898it [05:12,  9.50it/s]\titers: 2900, epoch: 3 | loss: 0.3173958\n",
      "\tspeed: 0.1100s/iter; left time: 2995.0001s\n",
      "2999it [05:22,  9.57it/s]\titers: 3000, epoch: 3 | loss: 0.3915953\n",
      "\tspeed: 0.1059s/iter; left time: 2870.7663s\n",
      "3099it [05:33,  9.55it/s]\titers: 3100, epoch: 3 | loss: 0.2433289\n",
      "\tspeed: 0.1078s/iter; left time: 2913.6327s\n",
      "3199it [05:44,  9.62it/s]\titers: 3200, epoch: 3 | loss: 0.4921427\n",
      "\tspeed: 0.1043s/iter; left time: 2806.5776s\n",
      "3298it [05:55,  9.65it/s]\titers: 3300, epoch: 3 | loss: 0.1721545\n",
      "\tspeed: 0.1111s/iter; left time: 2980.9524s\n",
      "3399it [06:05,  8.50it/s]\titers: 3400, epoch: 3 | loss: 0.5224946\n",
      "\tspeed: 0.1062s/iter; left time: 2838.4068s\n",
      "3499it [06:16,  9.55it/s]\titers: 3500, epoch: 3 | loss: 0.2213157\n",
      "\tspeed: 0.1042s/iter; left time: 2774.0132s\n",
      "3599it [06:26,  9.64it/s]\titers: 3600, epoch: 3 | loss: 0.1954922\n",
      "\tspeed: 0.1020s/iter; left time: 2705.3499s\n",
      "3698it [06:36, 10.16it/s]\titers: 3700, epoch: 3 | loss: 0.2193892\n",
      "\tspeed: 0.1031s/iter; left time: 2722.8698s\n",
      "3765it [06:43,  9.33it/s]\n",
      "Epoch: 3 cost time: 403.5474615097046\n",
      "810it [00:38, 21.23it/s]\n",
      "807it [00:37, 21.29it/s]\n",
      "Epoch: 3 | Train Loss: 0.3365060 Vali Loss: 0.4064021 Test Loss: 0.4940262 MAE Loss: 0.4583008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0009455038\n",
      "99it [00:10,  9.65it/s]\titers: 100, epoch: 4 | loss: 0.3006406\n",
      "\tspeed: 0.9365s/iter; left time: 24589.2484s\n",
      "199it [00:21,  8.70it/s]\titers: 200, epoch: 4 | loss: 0.2440619\n",
      "\tspeed: 0.1068s/iter; left time: 2792.8925s\n",
      "299it [00:31,  9.70it/s]\titers: 300, epoch: 4 | loss: 0.4133818\n",
      "\tspeed: 0.1041s/iter; left time: 2712.2798s\n",
      "399it [00:42,  8.95it/s]\titers: 400, epoch: 4 | loss: 0.6025497\n",
      "\tspeed: 0.1078s/iter; left time: 2797.0879s\n",
      "499it [00:53,  9.20it/s]\titers: 500, epoch: 4 | loss: 0.3256566\n",
      "\tspeed: 0.1092s/iter; left time: 2822.5117s\n",
      "599it [01:04,  9.16it/s]\titers: 600, epoch: 4 | loss: 0.2037105\n",
      "\tspeed: 0.1096s/iter; left time: 2823.0682s\n",
      "699it [01:15,  9.24it/s]\titers: 700, epoch: 4 | loss: 0.3724228\n",
      "\tspeed: 0.1109s/iter; left time: 2845.2889s\n",
      "799it [01:26,  9.66it/s]\titers: 800, epoch: 4 | loss: 0.2472870\n",
      "\tspeed: 0.1092s/iter; left time: 2790.6920s\n",
      "899it [01:37,  9.60it/s]\titers: 900, epoch: 4 | loss: 0.3435126\n",
      "\tspeed: 0.1139s/iter; left time: 2899.5130s\n",
      "999it [01:48,  9.30it/s]\titers: 1000, epoch: 4 | loss: 0.4202377\n",
      "\tspeed: 0.1068s/iter; left time: 2707.3878s\n",
      "1099it [01:59,  9.06it/s]\titers: 1100, epoch: 4 | loss: 0.2549579\n",
      "\tspeed: 0.1110s/iter; left time: 2804.1028s\n",
      "1199it [02:10,  9.30it/s]\titers: 1200, epoch: 4 | loss: 0.2879125\n",
      "\tspeed: 0.1065s/iter; left time: 2678.8811s\n",
      "1299it [02:21,  9.06it/s]\titers: 1300, epoch: 4 | loss: 0.1979164\n",
      "\tspeed: 0.1111s/iter; left time: 2784.7450s\n",
      "1399it [02:32,  9.31it/s]\titers: 1400, epoch: 4 | loss: 0.2354831\n",
      "\tspeed: 0.1082s/iter; left time: 2700.0427s\n",
      "1499it [02:43,  8.98it/s]\titers: 1500, epoch: 4 | loss: 0.5307850\n",
      "\tspeed: 0.1117s/iter; left time: 2777.6061s\n",
      "1599it [02:54,  9.06it/s]\titers: 1600, epoch: 4 | loss: 0.3924909\n",
      "\tspeed: 0.1135s/iter; left time: 2809.7371s\n",
      "1698it [03:05,  9.14it/s]\titers: 1700, epoch: 4 | loss: 0.1585459\n",
      "\tspeed: 0.1101s/iter; left time: 2713.7867s\n",
      "1799it [03:17,  9.12it/s]\titers: 1800, epoch: 4 | loss: 0.2648713\n",
      "\tspeed: 0.1132s/iter; left time: 2779.7125s\n",
      "1899it [03:27,  9.37it/s]\titers: 1900, epoch: 4 | loss: 0.1933755\n",
      "\tspeed: 0.1091s/iter; left time: 2668.2363s\n",
      "1999it [03:39,  9.54it/s]\titers: 2000, epoch: 4 | loss: 0.2984614\n",
      "\tspeed: 0.1121s/iter; left time: 2729.1897s\n",
      "2099it [03:49,  7.91it/s]\titers: 2100, epoch: 4 | loss: 0.2081639\n",
      "\tspeed: 0.1069s/iter; left time: 2593.6631s\n",
      "2199it [04:00,  9.94it/s]\titers: 2200, epoch: 4 | loss: 0.2385168\n",
      "\tspeed: 0.1053s/iter; left time: 2543.4003s\n",
      "2299it [04:10,  9.71it/s]\titers: 2300, epoch: 4 | loss: 0.2389357\n",
      "\tspeed: 0.1049s/iter; left time: 2522.4361s\n",
      "2399it [04:21,  9.99it/s]\titers: 2400, epoch: 4 | loss: 0.4422472\n",
      "\tspeed: 0.1036s/iter; left time: 2482.7354s\n",
      "2499it [04:31,  9.41it/s]\titers: 2500, epoch: 4 | loss: 0.3745276\n",
      "\tspeed: 0.1060s/iter; left time: 2529.1474s\n",
      "2598it [04:42,  9.53it/s]\titers: 2600, epoch: 4 | loss: 0.1556063\n",
      "\tspeed: 0.1086s/iter; left time: 2580.9266s\n",
      "2699it [04:53,  9.79it/s]\titers: 2700, epoch: 4 | loss: 0.2270570\n",
      "\tspeed: 0.1075s/iter; left time: 2542.4833s\n",
      "2799it [05:03,  9.71it/s]\titers: 2800, epoch: 4 | loss: 0.5380667\n",
      "\tspeed: 0.1033s/iter; left time: 2432.7690s\n",
      "2899it [05:14,  9.85it/s]\titers: 2900, epoch: 4 | loss: 0.2240163\n",
      "\tspeed: 0.1068s/iter; left time: 2504.2984s\n",
      "2998it [05:24, 10.11it/s]\titers: 3000, epoch: 4 | loss: 0.4558466\n",
      "\tspeed: 0.0999s/iter; left time: 2334.0007s\n",
      "3099it [05:34,  9.57it/s]\titers: 3100, epoch: 4 | loss: 0.1970499\n",
      "\tspeed: 0.1016s/iter; left time: 2363.7400s\n",
      "3198it [05:44,  9.35it/s]\titers: 3200, epoch: 4 | loss: 0.1851226\n",
      "\tspeed: 0.1040s/iter; left time: 2408.6476s\n",
      "3299it [05:55,  9.65it/s]\titers: 3300, epoch: 4 | loss: 0.2274571\n",
      "\tspeed: 0.1058s/iter; left time: 2438.7342s\n",
      "3399it [06:05,  9.86it/s]\titers: 3400, epoch: 4 | loss: 0.1840156\n",
      "\tspeed: 0.1034s/iter; left time: 2374.1294s\n",
      "3499it [06:15,  9.93it/s]\titers: 3500, epoch: 4 | loss: 0.2138825\n",
      "\tspeed: 0.0990s/iter; left time: 2261.7788s\n",
      "3598it [06:25, 10.08it/s]\titers: 3600, epoch: 4 | loss: 0.5029134\n",
      "\tspeed: 0.0998s/iter; left time: 2271.5586s\n",
      "3698it [06:35, 10.10it/s]\titers: 3700, epoch: 4 | loss: 0.3877670\n",
      "\tspeed: 0.0984s/iter; left time: 2228.2400s\n",
      "3765it [06:42,  9.36it/s]\n",
      "Epoch: 4 cost time: 402.32713747024536\n",
      "810it [00:38, 21.00it/s]\n",
      "807it [00:37, 21.24it/s]\n",
      "Epoch: 4 | Train Loss: 0.3288738 Vali Loss: 0.3850609 Test Loss: 0.4727391 MAE Loss: 0.4528556\n",
      "lr = 0.0009045095\n",
      "98it [00:10,  9.57it/s]\titers: 100, epoch: 5 | loss: 0.3697329\n",
      "\tspeed: 0.9807s/iter; left time: 22056.6805s\n",
      "199it [00:21,  9.60it/s]\titers: 200, epoch: 5 | loss: 0.1628610\n",
      "\tspeed: 0.1065s/iter; left time: 2384.8409s\n",
      "299it [00:32,  9.61it/s]\titers: 300, epoch: 5 | loss: 0.2121016\n",
      "\tspeed: 0.1060s/iter; left time: 2362.1967s\n",
      "399it [00:42,  9.66it/s]\titers: 400, epoch: 5 | loss: 0.1544528\n",
      "\tspeed: 0.1031s/iter; left time: 2288.6718s\n",
      "499it [00:52,  9.25it/s]\titers: 500, epoch: 5 | loss: 0.4195973\n",
      "\tspeed: 0.1057s/iter; left time: 2334.4984s\n",
      "599it [01:03,  9.66it/s]\titers: 600, epoch: 5 | loss: 0.2264196\n",
      "\tspeed: 0.1032s/iter; left time: 2268.7560s\n",
      "699it [01:13,  9.81it/s]\titers: 700, epoch: 5 | loss: 0.2859807\n",
      "\tspeed: 0.1069s/iter; left time: 2340.1122s\n",
      "798it [01:24,  9.52it/s]\titers: 800, epoch: 5 | loss: 0.2172444\n",
      "\tspeed: 0.1025s/iter; left time: 2233.7452s\n",
      "899it [01:35,  8.97it/s]\titers: 900, epoch: 5 | loss: 0.3640499\n",
      "\tspeed: 0.1096s/iter; left time: 2377.9766s\n",
      "999it [01:46,  8.50it/s]\titers: 1000, epoch: 5 | loss: 0.2475604\n",
      "\tspeed: 0.1088s/iter; left time: 2350.1354s\n",
      "1099it [01:56,  9.10it/s]\titers: 1100, epoch: 5 | loss: 0.2546253\n",
      "\tspeed: 0.1085s/iter; left time: 2330.7301s\n",
      "1199it [02:07,  8.29it/s]\titers: 1200, epoch: 5 | loss: 0.3203272\n",
      "\tspeed: 0.1079s/iter; left time: 2307.9205s\n",
      "1298it [02:18,  9.42it/s]\titers: 1300, epoch: 5 | loss: 0.1788185\n",
      "\tspeed: 0.1053s/iter; left time: 2241.1018s\n",
      "1399it [02:28,  9.24it/s]\titers: 1400, epoch: 5 | loss: 0.3036068\n",
      "\tspeed: 0.1065s/iter; left time: 2255.9854s\n",
      "1499it [02:39,  9.68it/s]\titers: 1500, epoch: 5 | loss: 0.3591381\n",
      "\tspeed: 0.1041s/iter; left time: 2195.8683s\n",
      "1599it [02:49,  9.65it/s]\titers: 1600, epoch: 5 | loss: 0.2231094\n",
      "\tspeed: 0.1061s/iter; left time: 2228.0437s\n",
      "1699it [03:00,  9.67it/s]\titers: 1700, epoch: 5 | loss: 0.1675793\n",
      "\tspeed: 0.1033s/iter; left time: 2157.3278s\n",
      "1798it [03:10,  9.75it/s]\titers: 1800, epoch: 5 | loss: 0.2167388\n",
      "\tspeed: 0.1071s/iter; left time: 2226.6393s\n",
      "1899it [03:21,  6.53it/s]\titers: 1900, epoch: 5 | loss: 0.1690843\n",
      "\tspeed: 0.1084s/iter; left time: 2243.0477s\n",
      "1998it [03:32,  9.55it/s]\titers: 2000, epoch: 5 | loss: 0.2814294\n",
      "\tspeed: 0.1053s/iter; left time: 2168.9499s\n",
      "2099it [03:43,  9.60it/s]\titers: 2100, epoch: 5 | loss: 0.2111902\n",
      "\tspeed: 0.1071s/iter; left time: 2194.5880s\n",
      "2199it [03:53,  9.88it/s]\titers: 2200, epoch: 5 | loss: 0.2084986\n",
      "\tspeed: 0.1034s/iter; left time: 2107.7322s\n",
      "2299it [04:03,  8.05it/s]\titers: 2300, epoch: 5 | loss: 0.3536089\n",
      "\tspeed: 0.1065s/iter; left time: 2161.1423s\n",
      "2398it [04:14,  9.70it/s]\titers: 2400, epoch: 5 | loss: 0.2249711\n",
      "\tspeed: 0.1032s/iter; left time: 2084.4123s\n",
      "2499it [04:25,  9.16it/s]\titers: 2500, epoch: 5 | loss: 0.3869133\n",
      "\tspeed: 0.1077s/iter; left time: 2163.0574s\n",
      "2598it [04:35,  9.51it/s]\titers: 2600, epoch: 5 | loss: 0.2205029\n",
      "\tspeed: 0.1082s/iter; left time: 2163.9587s\n",
      "2699it [04:47,  9.33it/s]\titers: 2700, epoch: 5 | loss: 0.2206600\n",
      "\tspeed: 0.1118s/iter; left time: 2224.6232s\n",
      "2799it [04:58,  7.88it/s]\titers: 2800, epoch: 5 | loss: 0.1981445\n",
      "\tspeed: 0.1092s/iter; left time: 2161.3167s\n",
      "2899it [05:09,  9.16it/s]\titers: 2900, epoch: 5 | loss: 0.4340478\n",
      "\tspeed: 0.1124s/iter; left time: 2213.1588s\n",
      "2999it [05:20,  8.14it/s]\titers: 3000, epoch: 5 | loss: 0.1314150\n",
      "\tspeed: 0.1132s/iter; left time: 2216.9487s\n",
      "3099it [05:31,  9.29it/s]\titers: 3100, epoch: 5 | loss: 0.8493554\n",
      "\tspeed: 0.1071s/iter; left time: 2086.5402s\n",
      "3198it [05:41, 10.25it/s]\titers: 3200, epoch: 5 | loss: 0.3208412\n",
      "\tspeed: 0.1043s/iter; left time: 2021.6738s\n",
      "3299it [05:52,  9.47it/s]\titers: 3300, epoch: 5 | loss: 0.5492241\n",
      "\tspeed: 0.1039s/iter; left time: 2005.1032s\n",
      "3399it [06:02,  9.68it/s]\titers: 3400, epoch: 5 | loss: 0.1734876\n",
      "\tspeed: 0.1070s/iter; left time: 2052.7945s\n",
      "3498it [06:13,  9.86it/s]\titers: 3500, epoch: 5 | loss: 0.4444863\n",
      "\tspeed: 0.1029s/iter; left time: 1964.3687s\n",
      "3599it [06:23,  9.59it/s]\titers: 3600, epoch: 5 | loss: 0.2006109\n",
      "\tspeed: 0.1014s/iter; left time: 1926.1800s\n",
      "3698it [06:33, 10.16it/s]\titers: 3700, epoch: 5 | loss: 0.2729193\n",
      "\tspeed: 0.1027s/iter; left time: 1940.2358s\n",
      "3765it [06:40,  9.41it/s]\n",
      "Epoch: 5 cost time: 400.11252617836\n",
      "810it [00:38, 21.25it/s]\n",
      "807it [00:38, 21.07it/s]\n",
      "Epoch: 5 | Train Loss: 0.3146382 Vali Loss: 0.3828572 Test Loss: 0.4580813 MAE Loss: 0.4429606\n",
      "lr = 0.0008535549\n",
      "98it [00:10,  9.67it/s]\titers: 100, epoch: 6 | loss: 0.3527882\n",
      "\tspeed: 0.9767s/iter; left time: 18290.2537s\n",
      "199it [00:21,  9.60it/s]\titers: 200, epoch: 6 | loss: 0.4540844\n",
      "\tspeed: 0.1065s/iter; left time: 1983.9355s\n",
      "299it [00:32,  9.55it/s]\titers: 300, epoch: 6 | loss: 0.2982931\n",
      "\tspeed: 0.1045s/iter; left time: 1935.2531s\n",
      "399it [00:42,  9.65it/s]\titers: 400, epoch: 6 | loss: 0.2235317\n",
      "\tspeed: 0.1048s/iter; left time: 1930.3456s\n",
      "499it [00:52,  9.67it/s]\titers: 500, epoch: 6 | loss: 0.3145299\n",
      "\tspeed: 0.1050s/iter; left time: 1923.4370s\n",
      "599it [01:03,  8.76it/s]\titers: 600, epoch: 6 | loss: 0.1592099\n",
      "\tspeed: 0.1061s/iter; left time: 1932.8868s\n",
      "699it [01:13,  9.73it/s]\titers: 700, epoch: 6 | loss: 0.2417821\n",
      "\tspeed: 0.1027s/iter; left time: 1861.6354s\n",
      "799it [01:24,  9.70it/s]\titers: 800, epoch: 6 | loss: 0.2456377\n",
      "\tspeed: 0.1032s/iter; left time: 1860.3074s\n",
      "899it [01:34,  9.48it/s]\titers: 900, epoch: 6 | loss: 0.2679962\n",
      "\tspeed: 0.1034s/iter; left time: 1852.6825s\n",
      "999it [01:45,  9.88it/s]\titers: 1000, epoch: 6 | loss: 0.2351329\n",
      "\tspeed: 0.1056s/iter; left time: 1882.7089s\n",
      "1099it [01:55,  7.43it/s]\titers: 1100, epoch: 6 | loss: 0.2918243\n",
      "\tspeed: 0.1068s/iter; left time: 1893.6354s\n",
      "1199it [02:06,  9.66it/s]\titers: 1200, epoch: 6 | loss: 0.3308031\n",
      "\tspeed: 0.1065s/iter; left time: 1877.8160s\n",
      "1298it [02:16,  9.39it/s]\titers: 1300, epoch: 6 | loss: 0.2857048\n",
      "\tspeed: 0.1063s/iter; left time: 1863.6819s\n",
      "1399it [02:27,  9.54it/s]\titers: 1400, epoch: 6 | loss: 0.4260607\n",
      "\tspeed: 0.1049s/iter; left time: 1828.4893s\n",
      "1499it [02:38,  9.22it/s]\titers: 1500, epoch: 6 | loss: 0.3776047\n",
      "\tspeed: 0.1086s/iter; left time: 1882.2114s\n",
      "1599it [02:49,  9.31it/s]\titers: 1600, epoch: 6 | loss: 0.4883596\n",
      "\tspeed: 0.1100s/iter; left time: 1895.5811s\n",
      "1698it [03:00,  9.14it/s]\titers: 1700, epoch: 6 | loss: 0.1718704\n",
      "\tspeed: 0.1141s/iter; left time: 1954.2993s\n",
      "1799it [03:11,  9.49it/s]\titers: 1800, epoch: 6 | loss: 0.2323518\n",
      "\tspeed: 0.1038s/iter; left time: 1767.7985s\n",
      "1899it [03:21,  9.34it/s]\titers: 1900, epoch: 6 | loss: 0.2103265\n",
      "\tspeed: 0.1072s/iter; left time: 1815.0085s\n",
      "1999it [03:33,  8.73it/s]\titers: 2000, epoch: 6 | loss: 0.5393614\n",
      "\tspeed: 0.1149s/iter; left time: 1932.9169s\n",
      "2099it [03:44,  9.49it/s]\titers: 2100, epoch: 6 | loss: 0.3311533\n",
      "\tspeed: 0.1074s/iter; left time: 1796.4609s\n",
      "2199it [03:55,  8.68it/s]\titers: 2200, epoch: 6 | loss: 0.3651102\n",
      "\tspeed: 0.1154s/iter; left time: 1918.7244s\n",
      "2299it [04:06,  9.08it/s]\titers: 2300, epoch: 6 | loss: 0.2251655\n",
      "\tspeed: 0.1123s/iter; left time: 1856.3010s\n",
      "2399it [04:18,  9.59it/s]\titers: 2400, epoch: 6 | loss: 0.5597059\n",
      "\tspeed: 0.1138s/iter; left time: 1868.6022s\n",
      "2499it [04:28, 10.11it/s]\titers: 2500, epoch: 6 | loss: 0.3596122\n",
      "\tspeed: 0.1000s/iter; left time: 1633.2772s\n",
      "2598it [04:38, 10.31it/s]\titers: 2600, epoch: 6 | loss: 0.2383562\n",
      "\tspeed: 0.1000s/iter; left time: 1622.0284s\n",
      "2699it [04:48, 10.48it/s]\titers: 2700, epoch: 6 | loss: 0.3861879\n",
      "\tspeed: 0.0974s/iter; left time: 1571.4211s\n",
      "2798it [04:58, 10.04it/s]\titers: 2800, epoch: 6 | loss: 0.4158143\n",
      "\tspeed: 0.1052s/iter; left time: 1685.9160s\n",
      "2899it [05:08,  9.14it/s]\titers: 2900, epoch: 6 | loss: 0.3263055\n",
      "\tspeed: 0.1035s/iter; left time: 1648.5936s\n",
      "2999it [05:19,  9.25it/s]\titers: 3000, epoch: 6 | loss: 0.3912396\n",
      "\tspeed: 0.1075s/iter; left time: 1701.9287s\n",
      "3099it [05:30,  9.56it/s]\titers: 3100, epoch: 6 | loss: 0.3799257\n",
      "\tspeed: 0.1083s/iter; left time: 1702.4882s\n",
      "3199it [05:40,  9.78it/s]\titers: 3200, epoch: 6 | loss: 0.2861125\n",
      "\tspeed: 0.1045s/iter; left time: 1632.4576s\n",
      "3299it [05:51,  9.73it/s]\titers: 3300, epoch: 6 | loss: 0.3709390\n",
      "\tspeed: 0.1059s/iter; left time: 1643.9071s\n",
      "3398it [06:01,  9.53it/s]\titers: 3400, epoch: 6 | loss: 0.3677102\n",
      "\tspeed: 0.1038s/iter; left time: 1600.8728s\n",
      "3499it [06:12,  9.44it/s]\titers: 3500, epoch: 6 | loss: 0.2940361\n",
      "\tspeed: 0.1077s/iter; left time: 1650.2003s\n",
      "3599it [06:23,  7.96it/s]\titers: 3600, epoch: 6 | loss: 0.2552347\n",
      "\tspeed: 0.1071s/iter; left time: 1631.0413s\n",
      "3699it [06:33,  9.48it/s]\titers: 3700, epoch: 6 | loss: 0.4274861\n",
      "\tspeed: 0.1055s/iter; left time: 1596.2979s\n",
      "3765it [06:40,  9.39it/s]\n",
      "Epoch: 6 cost time: 400.92169427871704\n",
      "810it [00:38, 21.22it/s]\n",
      "807it [00:37, 21.33it/s]\n",
      "Epoch: 6 | Train Loss: 0.3144608 Vali Loss: 0.3866889 Test Loss: 0.4698494 MAE Loss: 0.4478628\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007938947\n",
      "99it [00:10,  9.69it/s]\titers: 100, epoch: 7 | loss: 0.2766097\n",
      "\tspeed: 0.9393s/iter; left time: 14053.4931s\n",
      "198it [00:21,  9.66it/s]\titers: 200, epoch: 7 | loss: 0.2215559\n",
      "\tspeed: 0.1050s/iter; left time: 1560.6977s\n",
      "299it [00:32,  9.49it/s]\titers: 300, epoch: 7 | loss: 0.2655707\n",
      "\tspeed: 0.1074s/iter; left time: 1584.6198s\n",
      "398it [00:42, 10.44it/s]\titers: 400, epoch: 7 | loss: 0.3384075\n",
      "\tspeed: 0.1034s/iter; left time: 1516.3137s\n",
      "498it [00:52, 10.28it/s]\titers: 500, epoch: 7 | loss: 0.2274809\n",
      "\tspeed: 0.0973s/iter; left time: 1417.0023s\n",
      "599it [01:02, 10.15it/s]\titers: 600, epoch: 7 | loss: 0.5672334\n",
      "\tspeed: 0.1004s/iter; left time: 1451.3940s\n",
      "699it [01:11, 10.20it/s]\titers: 700, epoch: 7 | loss: 0.2923414\n",
      "\tspeed: 0.0975s/iter; left time: 1400.5236s\n",
      "799it [01:22,  9.71it/s]\titers: 800, epoch: 7 | loss: 0.2110776\n",
      "\tspeed: 0.1020s/iter; left time: 1454.9960s\n",
      "899it [01:32, 10.21it/s]\titers: 900, epoch: 7 | loss: 0.2511860\n",
      "\tspeed: 0.1035s/iter; left time: 1465.1328s\n",
      "999it [01:42,  9.58it/s]\titers: 1000, epoch: 7 | loss: 0.2923205\n",
      "\tspeed: 0.1031s/iter; left time: 1449.4838s\n",
      "1099it [01:53,  9.43it/s]\titers: 1100, epoch: 7 | loss: 0.4265242\n",
      "\tspeed: 0.1060s/iter; left time: 1480.1346s\n",
      "1199it [02:03,  9.85it/s]\titers: 1200, epoch: 7 | loss: 0.2488056\n",
      "\tspeed: 0.1030s/iter; left time: 1427.2138s\n",
      "1298it [02:14,  9.72it/s]\titers: 1300, epoch: 7 | loss: 0.4552926\n",
      "\tspeed: 0.1067s/iter; left time: 1468.6090s\n",
      "1399it [02:24,  9.72it/s]\titers: 1400, epoch: 7 | loss: 0.2100385\n",
      "\tspeed: 0.1022s/iter; left time: 1395.9238s\n",
      "1499it [02:35,  9.72it/s]\titers: 1500, epoch: 7 | loss: 0.1981146\n",
      "\tspeed: 0.1057s/iter; left time: 1433.1419s\n",
      "1599it [02:45,  8.09it/s]\titers: 1600, epoch: 7 | loss: 0.1996202\n",
      "\tspeed: 0.1041s/iter; left time: 1401.9463s\n",
      "1699it [02:56,  9.66it/s]\titers: 1700, epoch: 7 | loss: 0.4045314\n",
      "\tspeed: 0.1046s/iter; left time: 1397.3142s\n",
      "1799it [03:06,  9.82it/s]\titers: 1800, epoch: 7 | loss: 0.4244358\n",
      "\tspeed: 0.1072s/iter; left time: 1422.2228s\n",
      "1899it [03:17,  9.79it/s]\titers: 1900, epoch: 7 | loss: 0.3827047\n",
      "\tspeed: 0.1038s/iter; left time: 1366.4658s\n",
      "1999it [03:27,  9.56it/s]\titers: 2000, epoch: 7 | loss: 0.2950183\n",
      "\tspeed: 0.1064s/iter; left time: 1390.0204s\n",
      "2099it [03:38, 10.01it/s]\titers: 2100, epoch: 7 | loss: 0.2155664\n",
      "\tspeed: 0.1031s/iter; left time: 1336.0705s\n",
      "2199it [03:48,  9.76it/s]\titers: 2200, epoch: 7 | loss: 0.2658345\n",
      "\tspeed: 0.1070s/iter; left time: 1375.6107s\n",
      "2299it [03:59,  7.94it/s]\titers: 2300, epoch: 7 | loss: 0.3027633\n",
      "\tspeed: 0.1045s/iter; left time: 1334.0831s\n",
      "2399it [04:09, 10.13it/s]\titers: 2400, epoch: 7 | loss: 0.1367843\n",
      "\tspeed: 0.1027s/iter; left time: 1300.5635s\n",
      "2499it [04:19,  9.97it/s]\titers: 2500, epoch: 7 | loss: 0.2204079\n",
      "\tspeed: 0.0997s/iter; left time: 1252.8228s\n",
      "2599it [04:29, 10.26it/s]\titers: 2600, epoch: 7 | loss: 0.2870556\n",
      "\tspeed: 0.0984s/iter; left time: 1226.1897s\n",
      "2699it [04:39,  9.50it/s]\titers: 2700, epoch: 7 | loss: 0.3269806\n",
      "\tspeed: 0.1030s/iter; left time: 1272.6501s\n",
      "2798it [04:49,  9.52it/s]\titers: 2800, epoch: 7 | loss: 0.2898161\n",
      "\tspeed: 0.1039s/iter; left time: 1274.0178s\n",
      "2899it [05:00,  9.64it/s]\titers: 2900, epoch: 7 | loss: 0.2370246\n",
      "\tspeed: 0.1069s/iter; left time: 1300.5794s\n",
      "2998it [05:10,  9.78it/s]\titers: 3000, epoch: 7 | loss: 0.2406136\n",
      "\tspeed: 0.1029s/iter; left time: 1240.6607s\n",
      "3099it [05:21,  9.56it/s]\titers: 3100, epoch: 7 | loss: 0.2754480\n",
      "\tspeed: 0.1060s/iter; left time: 1267.2683s\n",
      "3199it [05:32,  9.22it/s]\titers: 3200, epoch: 7 | loss: 0.2271497\n",
      "\tspeed: 0.1043s/iter; left time: 1236.9959s\n",
      "3299it [05:42,  9.70it/s]\titers: 3300, epoch: 7 | loss: 0.2487942\n",
      "\tspeed: 0.1047s/iter; left time: 1231.4371s\n",
      "3399it [05:53,  9.64it/s]\titers: 3400, epoch: 7 | loss: 0.4404836\n",
      "\tspeed: 0.1057s/iter; left time: 1232.6984s\n",
      "3499it [06:03,  9.51it/s]\titers: 3500, epoch: 7 | loss: 0.3071925\n",
      "\tspeed: 0.1037s/iter; left time: 1198.5147s\n",
      "3599it [06:14,  9.95it/s]\titers: 3600, epoch: 7 | loss: 0.3677044\n",
      "\tspeed: 0.1067s/iter; left time: 1222.7271s\n",
      "3699it [06:24,  9.81it/s]\titers: 3700, epoch: 7 | loss: 0.1839146\n",
      "\tspeed: 0.1022s/iter; left time: 1161.3444s\n",
      "3765it [06:31,  9.61it/s]\n",
      "Epoch: 7 cost time: 391.9281368255615\n",
      "810it [00:38, 21.17it/s]\n",
      "807it [00:37, 21.36it/s]\n",
      "Epoch: 7 | Train Loss: 0.3154384 Vali Loss: 0.3861398 Test Loss: 0.4686438 MAE Loss: 0.4534865\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0007269980\n",
      "99it [00:11,  8.41it/s]\titers: 100, epoch: 8 | loss: 0.3832764\n",
      "\tspeed: 0.9560s/iter; left time: 10703.4860s\n",
      "199it [00:22,  9.70it/s]\titers: 200, epoch: 8 | loss: 0.1886065\n",
      "\tspeed: 0.1028s/iter; left time: 1140.7303s\n",
      "299it [00:32,  9.80it/s]\titers: 300, epoch: 8 | loss: 0.4559154\n",
      "\tspeed: 0.1051s/iter; left time: 1155.9730s\n",
      "399it [00:43,  8.64it/s]\titers: 400, epoch: 8 | loss: 0.3812473\n",
      "\tspeed: 0.1046s/iter; left time: 1139.2307s\n",
      "499it [00:53,  9.66it/s]\titers: 500, epoch: 8 | loss: 0.3267179\n",
      "\tspeed: 0.1042s/iter; left time: 1124.9120s\n",
      "598it [01:03,  9.69it/s]\titers: 600, epoch: 8 | loss: 0.2668023\n",
      "\tspeed: 0.1048s/iter; left time: 1120.4212s\n",
      "699it [01:14,  9.60it/s]\titers: 700, epoch: 8 | loss: 0.2609872\n",
      "\tspeed: 0.1044s/iter; left time: 1106.2763s\n",
      "799it [01:25,  9.40it/s]\titers: 800, epoch: 8 | loss: 0.1738905\n",
      "\tspeed: 0.1084s/iter; left time: 1137.2608s\n",
      "899it [01:35,  9.65it/s]\titers: 900, epoch: 8 | loss: 0.3560578\n",
      "\tspeed: 0.1056s/iter; left time: 1097.8498s\n",
      "999it [01:46,  9.45it/s]\titers: 1000, epoch: 8 | loss: 0.3271933\n",
      "\tspeed: 0.1106s/iter; left time: 1138.6926s\n",
      "1098it [01:57,  9.45it/s]\titers: 1100, epoch: 8 | loss: 0.1889334\n",
      "\tspeed: 0.1041s/iter; left time: 1061.5199s\n",
      "1199it [02:08,  9.75it/s]\titers: 1200, epoch: 8 | loss: 0.1721085\n",
      "\tspeed: 0.1110s/iter; left time: 1120.8325s\n",
      "1299it [02:19,  8.06it/s]\titers: 1300, epoch: 8 | loss: 0.1364835\n",
      "\tspeed: 0.1072s/iter; left time: 1071.5019s\n",
      "1399it [02:29,  9.49it/s]\titers: 1400, epoch: 8 | loss: 0.2132577\n",
      "\tspeed: 0.1042s/iter; left time: 1031.5919s\n",
      "1499it [02:40,  9.60it/s]\titers: 1500, epoch: 8 | loss: 0.2948199\n",
      "\tspeed: 0.1067s/iter; left time: 1045.4131s\n",
      "1599it [02:50,  9.64it/s]\titers: 1600, epoch: 8 | loss: 0.2719065\n",
      "\tspeed: 0.1041s/iter; left time: 1008.9411s\n",
      "1698it [03:01,  9.47it/s]\titers: 1700, epoch: 8 | loss: 0.5983642\n",
      "\tspeed: 0.1068s/iter; left time: 1024.6048s\n",
      "1799it [03:11,  9.59it/s]\titers: 1800, epoch: 8 | loss: 0.2435260\n",
      "\tspeed: 0.1052s/iter; left time: 998.6127s\n",
      "1898it [03:22,  9.67it/s]\titers: 1900, epoch: 8 | loss: 0.5071118\n",
      "\tspeed: 0.1068s/iter; left time: 1003.1613s\n",
      "1999it [03:32,  9.66it/s]\titers: 2000, epoch: 8 | loss: 0.2458218\n",
      "\tspeed: 0.1032s/iter; left time: 959.0613s\n",
      "2099it [03:43,  9.82it/s]\titers: 2100, epoch: 8 | loss: 0.2351027\n",
      "\tspeed: 0.1075s/iter; left time: 988.6236s\n",
      "2199it [03:53,  8.70it/s]\titers: 2200, epoch: 8 | loss: 0.3429770\n",
      "\tspeed: 0.1032s/iter; left time: 938.8874s\n",
      "2299it [04:04,  9.50it/s]\titers: 2300, epoch: 8 | loss: 0.3239320\n",
      "\tspeed: 0.1049s/iter; left time: 943.3134s\n",
      "2399it [04:15,  9.47it/s]\titers: 2400, epoch: 8 | loss: 0.2651787\n",
      "\tspeed: 0.1081s/iter; left time: 962.1000s\n",
      "2499it [04:25,  9.17it/s]\titers: 2500, epoch: 8 | loss: 0.2158675\n",
      "\tspeed: 0.1077s/iter; left time: 947.3929s\n",
      "2599it [04:36,  9.78it/s]\titers: 2600, epoch: 8 | loss: 0.3791750\n",
      "\tspeed: 0.1078s/iter; left time: 937.1172s\n",
      "2698it [04:46,  9.74it/s]\titers: 2700, epoch: 8 | loss: 0.2922384\n",
      "\tspeed: 0.1036s/iter; left time: 890.8047s\n",
      "2799it [04:57,  9.55it/s]\titers: 2800, epoch: 8 | loss: 0.3538107\n",
      "\tspeed: 0.1061s/iter; left time: 901.3016s\n",
      "2899it [05:08,  8.72it/s]\titers: 2900, epoch: 8 | loss: 0.2782777\n",
      "\tspeed: 0.1041s/iter; left time: 873.8480s\n",
      "2999it [05:18,  9.67it/s]\titers: 3000, epoch: 8 | loss: 0.3099686\n",
      "\tspeed: 0.1043s/iter; left time: 865.3465s\n",
      "3099it [05:29,  9.86it/s]\titers: 3100, epoch: 8 | loss: 0.5087923\n",
      "\tspeed: 0.1048s/iter; left time: 858.8735s\n",
      "3199it [05:39,  9.60it/s]\titers: 3200, epoch: 8 | loss: 0.2369916\n",
      "\tspeed: 0.1015s/iter; left time: 821.6928s\n",
      "3299it [05:50,  8.63it/s]\titers: 3300, epoch: 8 | loss: 0.2496143\n",
      "\tspeed: 0.1090s/iter; left time: 871.9151s\n",
      "3399it [06:00,  9.70it/s]\titers: 3400, epoch: 8 | loss: 0.1929604\n",
      "\tspeed: 0.1028s/iter; left time: 811.7157s\n",
      "3498it [06:10,  9.76it/s]\titers: 3500, epoch: 8 | loss: 0.3483635\n",
      "\tspeed: 0.1065s/iter; left time: 830.5807s\n",
      "3599it [06:21,  9.79it/s]\titers: 3600, epoch: 8 | loss: 0.3154856\n",
      "\tspeed: 0.1032s/iter; left time: 794.1908s\n",
      "3699it [06:31,  9.81it/s]\titers: 3700, epoch: 8 | loss: 0.2141601\n",
      "\tspeed: 0.1057s/iter; left time: 802.5324s\n",
      "3765it [06:38,  9.44it/s]\n",
      "Epoch: 8 cost time: 398.6782970428467\n",
      "810it [00:38, 20.95it/s]\n",
      "807it [00:37, 21.45it/s]\n",
      "Epoch: 8 | Train Loss: 0.3081620 Vali Loss: 0.3698395 Test Loss: 0.4500522 MAE Loss: 0.4384237\n",
      "lr = 0.0006545120\n",
      "99it [00:10,  9.47it/s]\titers: 100, epoch: 9 | loss: 0.4172454\n",
      "\tspeed: 0.9732s/iter; left time: 7231.6675s\n",
      "198it [00:21,  9.68it/s]\titers: 200, epoch: 9 | loss: 0.2407860\n",
      "\tspeed: 0.1055s/iter; left time: 773.5456s\n",
      "299it [00:31,  8.85it/s]\titers: 300, epoch: 9 | loss: 0.7410207\n",
      "\tspeed: 0.1065s/iter; left time: 770.2217s\n",
      "399it [00:42,  9.78it/s]\titers: 400, epoch: 9 | loss: 0.3043884\n",
      "\tspeed: 0.1034s/iter; left time: 737.1353s\n",
      "499it [00:52, 10.15it/s]\titers: 500, epoch: 9 | loss: 0.2168303\n",
      "\tspeed: 0.1042s/iter; left time: 732.5906s\n",
      "599it [01:02, 10.30it/s]\titers: 600, epoch: 9 | loss: 0.2391678\n",
      "\tspeed: 0.0984s/iter; left time: 682.0614s\n",
      "698it [01:12, 10.10it/s]\titers: 700, epoch: 9 | loss: 0.3864079\n",
      "\tspeed: 0.1004s/iter; left time: 685.9758s\n",
      "798it [01:22, 10.19it/s]\titers: 800, epoch: 9 | loss: 0.3468738\n",
      "\tspeed: 0.0976s/iter; left time: 656.9957s\n",
      "898it [01:32, 10.33it/s]\titers: 900, epoch: 9 | loss: 0.2983672\n",
      "\tspeed: 0.1002s/iter; left time: 664.5568s\n",
      "998it [01:41, 10.15it/s]\titers: 1000, epoch: 9 | loss: 0.4912311\n",
      "\tspeed: 0.0980s/iter; left time: 639.9150s\n",
      "1099it [01:51, 10.48it/s]\titers: 1100, epoch: 9 | loss: 0.2415686\n",
      "\tspeed: 0.0991s/iter; left time: 637.0319s\n",
      "1198it [02:01,  9.29it/s]\titers: 1200, epoch: 9 | loss: 0.2453928\n",
      "\tspeed: 0.0995s/iter; left time: 630.0571s\n",
      "1299it [02:12,  9.93it/s]\titers: 1300, epoch: 9 | loss: 0.3458133\n",
      "\tspeed: 0.1038s/iter; left time: 646.9191s\n",
      "1399it [02:22,  9.76it/s]\titers: 1400, epoch: 9 | loss: 0.4955222\n",
      "\tspeed: 0.1055s/iter; left time: 646.6042s\n",
      "1499it [02:33,  9.74it/s]\titers: 1500, epoch: 9 | loss: 0.6986639\n",
      "\tspeed: 0.1041s/iter; left time: 627.5466s\n",
      "1599it [02:45,  8.88it/s]\titers: 1600, epoch: 9 | loss: 0.3215896\n",
      "\tspeed: 0.1244s/iter; left time: 737.8703s\n",
      "1699it [02:56,  9.79it/s]\titers: 1700, epoch: 9 | loss: 0.2229681\n",
      "\tspeed: 0.1052s/iter; left time: 613.5362s\n",
      "1798it [03:06, 10.16it/s]\titers: 1800, epoch: 9 | loss: 0.1331144\n",
      "\tspeed: 0.1041s/iter; left time: 596.6073s\n",
      "1899it [03:16,  9.80it/s]\titers: 1900, epoch: 9 | loss: 0.1843282\n",
      "\tspeed: 0.1024s/iter; left time: 576.8526s\n",
      "1999it [03:27,  9.84it/s]\titers: 2000, epoch: 9 | loss: 0.2304826\n",
      "\tspeed: 0.1066s/iter; left time: 589.5561s\n",
      "2099it [03:37,  7.93it/s]\titers: 2100, epoch: 9 | loss: 0.2355656\n",
      "\tspeed: 0.1043s/iter; left time: 566.6198s\n",
      "2199it [03:48,  9.89it/s]\titers: 2200, epoch: 9 | loss: 0.3708421\n",
      "\tspeed: 0.1055s/iter; left time: 562.3546s\n",
      "2299it [03:59,  9.63it/s]\titers: 2300, epoch: 9 | loss: 0.1615562\n",
      "\tspeed: 0.1075s/iter; left time: 562.4153s\n",
      "2399it [04:09,  9.74it/s]\titers: 2400, epoch: 9 | loss: 0.2267844\n",
      "\tspeed: 0.1038s/iter; left time: 532.7161s\n",
      "2498it [04:20,  9.65it/s]\titers: 2500, epoch: 9 | loss: 0.3005913\n",
      "\tspeed: 0.1064s/iter; left time: 535.2934s\n",
      "2599it [04:30,  9.64it/s]\titers: 2600, epoch: 9 | loss: 0.3416082\n",
      "\tspeed: 0.1034s/iter; left time: 509.8112s\n",
      "2699it [04:41,  8.87it/s]\titers: 2700, epoch: 9 | loss: 0.2608914\n",
      "\tspeed: 0.1103s/iter; left time: 533.0795s\n",
      "2799it [04:52,  9.71it/s]\titers: 2800, epoch: 9 | loss: 0.2637911\n",
      "\tspeed: 0.1037s/iter; left time: 490.4766s\n",
      "2898it [05:02, 10.31it/s]\titers: 2900, epoch: 9 | loss: 0.5400911\n",
      "\tspeed: 0.1009s/iter; left time: 467.2591s\n",
      "2999it [05:12,  9.35it/s]\titers: 3000, epoch: 9 | loss: 0.3736081\n",
      "\tspeed: 0.0998s/iter; left time: 452.1764s\n",
      "3099it [05:22, 10.24it/s]\titers: 3100, epoch: 9 | loss: 0.1216166\n",
      "\tspeed: 0.0988s/iter; left time: 437.8249s\n",
      "3199it [05:31,  9.88it/s]\titers: 3200, epoch: 9 | loss: 0.1708410\n",
      "\tspeed: 0.0998s/iter; left time: 432.1336s\n",
      "3299it [05:42,  8.97it/s]\titers: 3300, epoch: 9 | loss: 0.3920317\n",
      "\tspeed: 0.1040s/iter; left time: 440.1644s\n",
      "3399it [05:53,  9.42it/s]\titers: 3400, epoch: 9 | loss: 0.3019211\n",
      "\tspeed: 0.1107s/iter; left time: 457.1223s\n",
      "3499it [06:04,  9.93it/s]\titers: 3500, epoch: 9 | loss: 0.2480297\n",
      "\tspeed: 0.1057s/iter; left time: 425.8761s\n",
      "3599it [06:14,  9.99it/s]\titers: 3600, epoch: 9 | loss: 0.1873797\n",
      "\tspeed: 0.1035s/iter; left time: 406.9306s\n",
      "3699it [06:24,  9.28it/s]\titers: 3700, epoch: 9 | loss: 0.2981409\n",
      "\tspeed: 0.0976s/iter; left time: 373.7836s\n",
      "3765it [06:31,  9.61it/s]\n",
      "Epoch: 9 cost time: 391.5813522338867\n",
      "810it [00:38, 21.16it/s]\n",
      "807it [00:37, 21.29it/s]\n",
      "Epoch: 9 | Train Loss: 0.3077733 Vali Loss: 0.3734228 Test Loss: 0.4564576 MAE Loss: 0.4407051\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0005782215\n",
      "98it [00:10,  9.56it/s]\titers: 100, epoch: 10 | loss: 0.2235445\n",
      "\tspeed: 0.9477s/iter; left time: 3474.2043s\n",
      "199it [00:21,  9.70it/s]\titers: 200, epoch: 10 | loss: 0.2402189\n",
      "\tspeed: 0.1042s/iter; left time: 371.6368s\n",
      "299it [00:32,  8.73it/s]\titers: 300, epoch: 10 | loss: 0.5548694\n",
      "\tspeed: 0.1063s/iter; left time: 368.4635s\n",
      "399it [00:42,  9.57it/s]\titers: 400, epoch: 10 | loss: 0.3081375\n",
      "\tspeed: 0.1037s/iter; left time: 348.9831s\n",
      "499it [00:52, 10.40it/s]\titers: 500, epoch: 10 | loss: 0.1438293\n",
      "\tspeed: 0.1054s/iter; left time: 344.2893s\n",
      "599it [01:02, 10.12it/s]\titers: 600, epoch: 10 | loss: 0.1651071\n",
      "\tspeed: 0.0975s/iter; left time: 308.7098s\n",
      "699it [01:12, 10.48it/s]\titers: 700, epoch: 10 | loss: 0.3478526\n",
      "\tspeed: 0.1019s/iter; left time: 312.3460s\n",
      "799it [01:23,  8.42it/s]\titers: 800, epoch: 10 | loss: 0.4412026\n",
      "\tspeed: 0.1038s/iter; left time: 307.8485s\n",
      "899it [01:33,  9.69it/s]\titers: 900, epoch: 10 | loss: 0.2612309\n",
      "\tspeed: 0.1036s/iter; left time: 296.7759s\n",
      "999it [01:44,  9.77it/s]\titers: 1000, epoch: 10 | loss: 0.4381417\n",
      "\tspeed: 0.1086s/iter; left time: 300.3090s\n",
      "1099it [01:54,  9.91it/s]\titers: 1100, epoch: 10 | loss: 0.1829154\n",
      "\tspeed: 0.1035s/iter; left time: 275.9823s\n",
      "1199it [02:05,  9.77it/s]\titers: 1200, epoch: 10 | loss: 0.1931322\n",
      "\tspeed: 0.1072s/iter; left time: 274.9729s\n",
      "1299it [02:15,  9.69it/s]\titers: 1300, epoch: 10 | loss: 0.3105976\n",
      "\tspeed: 0.1022s/iter; left time: 252.0209s\n",
      "1399it [02:26,  9.71it/s]\titers: 1400, epoch: 10 | loss: 0.3464423\n",
      "\tspeed: 0.1061s/iter; left time: 251.1273s\n",
      "1499it [02:36,  8.35it/s]\titers: 1500, epoch: 10 | loss: 0.2159579\n",
      "\tspeed: 0.1048s/iter; left time: 237.3680s\n",
      "1599it [02:47,  9.70it/s]\titers: 1600, epoch: 10 | loss: 0.2101147\n",
      "\tspeed: 0.1037s/iter; left time: 224.7141s\n",
      "1699it [02:57,  9.72it/s]\titers: 1700, epoch: 10 | loss: 0.2680765\n",
      "\tspeed: 0.1052s/iter; left time: 217.3551s\n",
      "1799it [03:08,  9.65it/s]\titers: 1800, epoch: 10 | loss: 0.3047492\n",
      "\tspeed: 0.1038s/iter; left time: 204.0131s\n",
      "1898it [03:18,  9.58it/s]\titers: 1900, epoch: 10 | loss: 0.3055594\n",
      "\tspeed: 0.1056s/iter; left time: 197.0826s\n",
      "1999it [03:29,  9.58it/s]\titers: 2000, epoch: 10 | loss: 0.2841032\n",
      "\tspeed: 0.1032s/iter; left time: 182.1843s\n",
      "2099it [03:39,  9.62it/s]\titers: 2100, epoch: 10 | loss: 0.1702823\n",
      "\tspeed: 0.1064s/iter; left time: 177.2616s\n",
      "2199it [03:50,  9.57it/s]\titers: 2200, epoch: 10 | loss: 0.2562758\n",
      "\tspeed: 0.1043s/iter; left time: 163.3920s\n",
      "2299it [04:00,  9.53it/s]\titers: 2300, epoch: 10 | loss: 0.2052799\n",
      "\tspeed: 0.1074s/iter; left time: 157.3759s\n",
      "2399it [04:11,  9.37it/s]\titers: 2400, epoch: 10 | loss: 0.3252999\n",
      "\tspeed: 0.1075s/iter; left time: 146.8542s\n",
      "2498it [04:21,  9.70it/s]\titers: 2500, epoch: 10 | loss: 0.2862371\n",
      "\tspeed: 0.1037s/iter; left time: 131.2815s\n",
      "2598it [04:32,  9.07it/s]\titers: 2600, epoch: 10 | loss: 0.3570297\n",
      "\tspeed: 0.1063s/iter; left time: 123.9402s\n",
      "2699it [04:42,  9.47it/s]\titers: 2700, epoch: 10 | loss: 0.3802657\n",
      "\tspeed: 0.1032s/iter; left time: 109.9757s\n",
      "2799it [04:53,  9.81it/s]\titers: 2800, epoch: 10 | loss: 0.2016282\n",
      "\tspeed: 0.1062s/iter; left time: 102.6062s\n",
      "2899it [05:03,  9.52it/s]\titers: 2900, epoch: 10 | loss: 0.1697121\n",
      "\tspeed: 0.1028s/iter; left time: 89.0158s\n",
      "2998it [05:13, 10.10it/s]\titers: 3000, epoch: 10 | loss: 0.1719423\n",
      "\tspeed: 0.1020s/iter; left time: 78.1295s\n",
      "3098it [05:23,  9.66it/s]\titers: 3100, epoch: 10 | loss: 0.2578464\n",
      "\tspeed: 0.0979s/iter; left time: 65.1740s\n",
      "3199it [05:33, 10.08it/s]\titers: 3200, epoch: 10 | loss: 0.5257652\n",
      "\tspeed: 0.1004s/iter; left time: 56.8479s\n",
      "3299it [05:43, 10.30it/s]\titers: 3300, epoch: 10 | loss: 0.2391298\n",
      "\tspeed: 0.1000s/iter; left time: 46.5836s\n",
      "3399it [05:53, 10.32it/s]\titers: 3400, epoch: 10 | loss: 0.2701829\n",
      "\tspeed: 0.0980s/iter; left time: 35.8851s\n",
      "3499it [06:03,  8.63it/s]\titers: 3500, epoch: 10 | loss: 0.2347176\n",
      "\tspeed: 0.1007s/iter; left time: 26.7815s\n",
      "3599it [06:13,  9.98it/s]\titers: 3600, epoch: 10 | loss: 0.5563565\n",
      "\tspeed: 0.0973s/iter; left time: 16.1568s\n",
      "3698it [06:23,  9.86it/s]\titers: 3700, epoch: 10 | loss: 0.1695818\n",
      "\tspeed: 0.1005s/iter; left time: 6.6339s\n",
      "3765it [06:29,  9.65it/s]\n",
      "Epoch: 10 cost time: 389.96201753616333\n",
      "810it [00:38, 21.27it/s]\n",
      "807it [00:38, 21.04it/s]\n",
      "Epoch: 10 | Train Loss: 0.3064355 Vali Loss: 0.3727824 Test Loss: 0.4499831 MAE Loss: 0.4320601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0005000050\n",
      "Total time: 79.78484623829523 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input 512, medium, COS, lr 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-04 03:08:19,084] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 03:08:19,915] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 03:08:19,915] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 03:08:19,916] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 03:08:20,800] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 03:08:20,800] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 03:08:22,011] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 03:08:22,012] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 03:08:22,012] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 03:08:22,013] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 03:08:22,013] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 03:08:22,013] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 03:08:22,013] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 03:08:22,013] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 03:08:22,013] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 03:08:22,013] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 03:08:22,273] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 03:08:22,274] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-04 03:08:22,274] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 117.82 GB, percent = 15.6%\n",
      "[2024-05-04 03:08:22,395] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 03:08:22,396] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 03:08:22,396] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 117.93 GB, percent = 15.6%\n",
      "[2024-05-04 03:08:22,396] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 03:08:22,504] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 03:08:22,505] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 03:08:22,505] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 118.01 GB, percent = 15.6%\n",
      "[2024-05-04 03:08:22,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 03:08:22,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 03:08:22,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 03:08:22,506] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 03:08:22,506] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc834602850>\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 03:08:22,507] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 03:08:22,508] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:14,  7.74it/s]\titers: 100, epoch: 1 | loss: 0.6284837\n",
      "\tspeed: 0.1825s/iter; left time: 6758.5335s\n",
      "199it [00:27,  7.66it/s]\titers: 200, epoch: 1 | loss: 0.5352426\n",
      "\tspeed: 0.1329s/iter; left time: 4908.0318s\n",
      "299it [00:40,  7.62it/s]\titers: 300, epoch: 1 | loss: 0.4914316\n",
      "\tspeed: 0.1304s/iter; left time: 4802.2571s\n",
      "399it [00:54,  7.66it/s]\titers: 400, epoch: 1 | loss: 0.2820175\n",
      "\tspeed: 0.1336s/iter; left time: 4906.3689s\n",
      "499it [01:07,  7.69it/s]\titers: 500, epoch: 1 | loss: 0.2728907\n",
      "\tspeed: 0.1328s/iter; left time: 4864.8639s\n",
      "599it [01:20,  7.51it/s]\titers: 600, epoch: 1 | loss: 0.3732491\n",
      "\tspeed: 0.1304s/iter; left time: 4763.9140s\n",
      "699it [01:33,  7.57it/s]\titers: 700, epoch: 1 | loss: 0.4083984\n",
      "\tspeed: 0.1313s/iter; left time: 4783.2062s\n",
      "799it [01:46,  7.57it/s]\titers: 800, epoch: 1 | loss: 0.2888259\n",
      "\tspeed: 0.1337s/iter; left time: 4858.1393s\n",
      "899it [02:00,  6.07it/s]\titers: 900, epoch: 1 | loss: 0.4882275\n",
      "\tspeed: 0.1347s/iter; left time: 4880.3047s\n",
      "999it [02:13,  6.74it/s]\titers: 1000, epoch: 1 | loss: 0.4720700\n",
      "\tspeed: 0.1318s/iter; left time: 4763.1939s\n",
      "1099it [02:26,  7.57it/s]\titers: 1100, epoch: 1 | loss: 0.2710172\n",
      "\tspeed: 0.1337s/iter; left time: 4815.7645s\n",
      "1199it [02:40,  7.70it/s]\titers: 1200, epoch: 1 | loss: 0.3366533\n",
      "\tspeed: 0.1330s/iter; left time: 4777.9649s\n",
      "1299it [02:53,  7.54it/s]\titers: 1300, epoch: 1 | loss: 0.4391926\n",
      "\tspeed: 0.1318s/iter; left time: 4720.8618s\n",
      "1399it [03:06,  7.67it/s]\titers: 1400, epoch: 1 | loss: 0.2492006\n",
      "\tspeed: 0.1329s/iter; left time: 4750.3584s\n",
      "1499it [03:19,  7.65it/s]\titers: 1500, epoch: 1 | loss: 0.2428142\n",
      "\tspeed: 0.1336s/iter; left time: 4758.6254s\n",
      "1599it [03:33,  7.41it/s]\titers: 1600, epoch: 1 | loss: 0.4292324\n",
      "\tspeed: 0.1334s/iter; left time: 4738.6990s\n",
      "1699it [03:46,  7.44it/s]\titers: 1700, epoch: 1 | loss: 0.4312639\n",
      "\tspeed: 0.1314s/iter; left time: 4654.7521s\n",
      "1799it [03:59,  7.63it/s]\titers: 1800, epoch: 1 | loss: 0.6051976\n",
      "\tspeed: 0.1326s/iter; left time: 4685.7490s\n",
      "1899it [04:12,  7.76it/s]\titers: 1900, epoch: 1 | loss: 0.2817806\n",
      "\tspeed: 0.1326s/iter; left time: 4672.3742s\n",
      "1999it [04:26,  7.62it/s]\titers: 2000, epoch: 1 | loss: 0.3776010\n",
      "\tspeed: 0.1333s/iter; left time: 4683.4772s\n",
      "2099it [04:39,  6.72it/s]\titers: 2100, epoch: 1 | loss: 0.2727109\n",
      "\tspeed: 0.1322s/iter; left time: 4630.2796s\n",
      "2199it [04:52,  7.68it/s]\titers: 2200, epoch: 1 | loss: 0.4344987\n",
      "\tspeed: 0.1321s/iter; left time: 4615.1725s\n",
      "2299it [05:06,  7.70it/s]\titers: 2300, epoch: 1 | loss: 0.4113905\n",
      "\tspeed: 0.1328s/iter; left time: 4626.6593s\n",
      "2399it [05:19,  7.58it/s]\titers: 2400, epoch: 1 | loss: 0.2870833\n",
      "\tspeed: 0.1336s/iter; left time: 4638.4309s\n",
      "2499it [05:32,  7.70it/s]\titers: 2500, epoch: 1 | loss: 0.3584269\n",
      "\tspeed: 0.1306s/iter; left time: 4524.3395s\n",
      "2599it [05:45,  7.79it/s]\titers: 2600, epoch: 1 | loss: 0.2931449\n",
      "\tspeed: 0.1320s/iter; left time: 4557.8968s\n",
      "2699it [05:58,  7.30it/s]\titers: 2700, epoch: 1 | loss: 0.3084987\n",
      "\tspeed: 0.1319s/iter; left time: 4542.7686s\n",
      "2799it [06:11,  7.76it/s]\titers: 2800, epoch: 1 | loss: 0.3998558\n",
      "\tspeed: 0.1296s/iter; left time: 4448.9414s\n",
      "2899it [06:24,  7.73it/s]\titers: 2900, epoch: 1 | loss: 0.2582986\n",
      "\tspeed: 0.1319s/iter; left time: 4513.3672s\n",
      "2999it [06:38,  7.51it/s]\titers: 3000, epoch: 1 | loss: 0.3260675\n",
      "\tspeed: 0.1337s/iter; left time: 4563.8411s\n",
      "3099it [06:51,  7.52it/s]\titers: 3100, epoch: 1 | loss: 0.2262339\n",
      "\tspeed: 0.1350s/iter; left time: 4592.6461s\n",
      "3199it [07:05,  7.44it/s]\titers: 3200, epoch: 1 | loss: 0.2288827\n",
      "\tspeed: 0.1344s/iter; left time: 4559.3638s\n",
      "3299it [07:18,  7.54it/s]\titers: 3300, epoch: 1 | loss: 0.4653212\n",
      "\tspeed: 0.1348s/iter; left time: 4561.2596s\n",
      "3399it [07:32,  7.36it/s]\titers: 3400, epoch: 1 | loss: 0.5665098\n",
      "\tspeed: 0.1347s/iter; left time: 4542.2462s\n",
      "3499it [07:45,  7.02it/s]\titers: 3500, epoch: 1 | loss: 0.3672006\n",
      "\tspeed: 0.1353s/iter; left time: 4549.9972s\n",
      "3599it [07:59,  7.60it/s]\titers: 3600, epoch: 1 | loss: 0.2720945\n",
      "\tspeed: 0.1353s/iter; left time: 4537.0406s\n",
      "3699it [08:12,  7.25it/s]\titers: 3700, epoch: 1 | loss: 0.2639223\n",
      "\tspeed: 0.1371s/iter; left time: 4581.8765s\n",
      "3713it [08:14,  7.50it/s]\n",
      "Epoch: 1 cost time: 494.9174425601959\n",
      "810it [00:52, 15.51it/s]\n",
      "807it [00:51, 15.80it/s]\n",
      "Epoch: 1 | Train Loss: 0.3539966 Vali Loss: 0.4033258 Test Loss: 0.5074162 MAE Loss: 0.4763052\n",
      "lr = 0.0009938442\n",
      "99it [00:13,  7.75it/s]\titers: 100, epoch: 2 | loss: 0.3767157\n",
      "\tspeed: 1.2266s/iter; left time: 40868.5269s\n",
      "199it [00:26,  7.83it/s]\titers: 200, epoch: 2 | loss: 0.4751770\n",
      "\tspeed: 0.1318s/iter; left time: 4377.4247s\n",
      "299it [00:39,  7.91it/s]\titers: 300, epoch: 2 | loss: 0.4254152\n",
      "\tspeed: 0.1301s/iter; left time: 4310.1532s\n",
      "399it [00:52,  7.87it/s]\titers: 400, epoch: 2 | loss: 0.6282481\n",
      "\tspeed: 0.1293s/iter; left time: 4269.4003s\n",
      "499it [01:05,  7.98it/s]\titers: 500, epoch: 2 | loss: 0.2911870\n",
      "\tspeed: 0.1288s/iter; left time: 4238.8766s\n",
      "599it [01:18,  7.62it/s]\titers: 600, epoch: 2 | loss: 0.4708160\n",
      "\tspeed: 0.1301s/iter; left time: 4269.1307s\n",
      "699it [01:31,  7.77it/s]\titers: 700, epoch: 2 | loss: 0.3043123\n",
      "\tspeed: 0.1278s/iter; left time: 4182.9421s\n",
      "799it [01:44,  8.01it/s]\titers: 800, epoch: 2 | loss: 0.4478506\n",
      "\tspeed: 0.1300s/iter; left time: 4240.3812s\n",
      "899it [01:57,  7.87it/s]\titers: 900, epoch: 2 | loss: 0.3069436\n",
      "\tspeed: 0.1298s/iter; left time: 4221.0939s\n",
      "999it [02:09,  7.07it/s]\titers: 1000, epoch: 2 | loss: 0.3549146\n",
      "\tspeed: 0.1300s/iter; left time: 4214.1144s\n",
      "1099it [02:22,  7.76it/s]\titers: 1100, epoch: 2 | loss: 0.3372775\n",
      "\tspeed: 0.1290s/iter; left time: 4168.1278s\n",
      "1199it [02:36,  7.82it/s]\titers: 1200, epoch: 2 | loss: 0.5666034\n",
      "\tspeed: 0.1316s/iter; left time: 4238.8931s\n",
      "1299it [02:48,  7.43it/s]\titers: 1300, epoch: 2 | loss: 0.2821845\n",
      "\tspeed: 0.1292s/iter; left time: 4150.2258s\n",
      "1399it [03:02,  7.47it/s]\titers: 1400, epoch: 2 | loss: 0.2186523\n",
      "\tspeed: 0.1317s/iter; left time: 4217.9144s\n",
      "1499it [03:15,  7.73it/s]\titers: 1500, epoch: 2 | loss: 0.6387949\n",
      "\tspeed: 0.1322s/iter; left time: 4220.0501s\n",
      "1599it [03:28,  7.83it/s]\titers: 1600, epoch: 2 | loss: 0.3126513\n",
      "\tspeed: 0.1308s/iter; left time: 4161.4719s\n",
      "1699it [03:41,  7.91it/s]\titers: 1700, epoch: 2 | loss: 0.4256271\n",
      "\tspeed: 0.1288s/iter; left time: 4084.1310s\n",
      "1799it [03:54,  7.88it/s]\titers: 1800, epoch: 2 | loss: 0.2084496\n",
      "\tspeed: 0.1299s/iter; left time: 4106.5499s\n",
      "1899it [04:07,  7.50it/s]\titers: 1900, epoch: 2 | loss: 0.3614881\n",
      "\tspeed: 0.1307s/iter; left time: 4119.0550s\n",
      "1999it [04:20,  7.72it/s]\titers: 2000, epoch: 2 | loss: 0.2827127\n",
      "\tspeed: 0.1277s/iter; left time: 4010.8100s\n",
      "2099it [04:33,  7.76it/s]\titers: 2100, epoch: 2 | loss: 0.4691244\n",
      "\tspeed: 0.1297s/iter; left time: 4061.1959s\n",
      "2199it [04:46,  8.00it/s]\titers: 2200, epoch: 2 | loss: 0.4235355\n",
      "\tspeed: 0.1311s/iter; left time: 4091.5665s\n",
      "2299it [04:59,  7.80it/s]\titers: 2300, epoch: 2 | loss: 0.3109887\n",
      "\tspeed: 0.1303s/iter; left time: 4055.4639s\n",
      "2399it [05:12,  7.80it/s]\titers: 2400, epoch: 2 | loss: 0.5009397\n",
      "\tspeed: 0.1284s/iter; left time: 3984.0013s\n",
      "2499it [05:25,  7.73it/s]\titers: 2500, epoch: 2 | loss: 0.2803027\n",
      "\tspeed: 0.1295s/iter; left time: 4004.7365s\n",
      "2599it [05:37,  7.87it/s]\titers: 2600, epoch: 2 | loss: 0.3870358\n",
      "\tspeed: 0.1288s/iter; left time: 3969.7501s\n",
      "2699it [05:50,  7.88it/s]\titers: 2700, epoch: 2 | loss: 0.2980010\n",
      "\tspeed: 0.1280s/iter; left time: 3931.4102s\n",
      "2799it [06:03,  7.90it/s]\titers: 2800, epoch: 2 | loss: 0.4731279\n",
      "\tspeed: 0.1297s/iter; left time: 3970.0222s\n",
      "2899it [06:16,  7.90it/s]\titers: 2900, epoch: 2 | loss: 0.3358819\n",
      "\tspeed: 0.1296s/iter; left time: 3956.4440s\n",
      "2999it [06:29,  7.31it/s]\titers: 3000, epoch: 2 | loss: 0.2284171\n",
      "\tspeed: 0.1277s/iter; left time: 3884.4715s\n",
      "3099it [06:42,  7.90it/s]\titers: 3100, epoch: 2 | loss: 0.3610570\n",
      "\tspeed: 0.1287s/iter; left time: 3901.1419s\n",
      "3199it [06:55,  7.97it/s]\titers: 3200, epoch: 2 | loss: 0.3276180\n",
      "\tspeed: 0.1301s/iter; left time: 3931.5115s\n",
      "3299it [07:08,  7.72it/s]\titers: 3300, epoch: 2 | loss: 0.2031095\n",
      "\tspeed: 0.1279s/iter; left time: 3852.2568s\n",
      "3399it [07:20,  7.78it/s]\titers: 3400, epoch: 2 | loss: 0.2928004\n",
      "\tspeed: 0.1284s/iter; left time: 3854.6565s\n",
      "3499it [07:33,  7.88it/s]\titers: 3500, epoch: 2 | loss: 0.3029553\n",
      "\tspeed: 0.1302s/iter; left time: 3895.4882s\n",
      "3599it [07:47,  7.87it/s]\titers: 3600, epoch: 2 | loss: 0.2909013\n",
      "\tspeed: 0.1304s/iter; left time: 3888.8744s\n",
      "3699it [07:59,  6.24it/s]\titers: 3700, epoch: 2 | loss: 0.1638605\n",
      "\tspeed: 0.1301s/iter; left time: 3866.8603s\n",
      "3713it [08:01,  7.70it/s]\n",
      "Epoch: 2 cost time: 481.89586758613586\n",
      "810it [00:48, 16.65it/s]\n",
      "807it [00:48, 16.70it/s]\n",
      "Epoch: 2 | Train Loss: 0.3426453 Vali Loss: 0.4419988 Test Loss: 0.5359442 MAE Loss: 0.4935539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009755285\n",
      "99it [00:13,  7.70it/s]\titers: 100, epoch: 3 | loss: 0.5224727\n",
      "\tspeed: 1.1222s/iter; left time: 33221.9927s\n",
      "199it [00:26,  7.86it/s]\titers: 200, epoch: 3 | loss: 0.2085290\n",
      "\tspeed: 0.1287s/iter; left time: 3797.0288s\n",
      "299it [00:39,  7.81it/s]\titers: 300, epoch: 3 | loss: 0.3238280\n",
      "\tspeed: 0.1309s/iter; left time: 3849.7742s\n",
      "399it [00:52,  7.82it/s]\titers: 400, epoch: 3 | loss: 0.6686686\n",
      "\tspeed: 0.1290s/iter; left time: 3781.6329s\n",
      "499it [01:05,  7.88it/s]\titers: 500, epoch: 3 | loss: 0.3294648\n",
      "\tspeed: 0.1294s/iter; left time: 3778.8103s\n",
      "599it [01:18,  7.80it/s]\titers: 600, epoch: 3 | loss: 0.3629559\n",
      "\tspeed: 0.1297s/iter; left time: 3774.0650s\n",
      "699it [01:31,  7.93it/s]\titers: 700, epoch: 3 | loss: 0.3475680\n",
      "\tspeed: 0.1297s/iter; left time: 3761.5347s\n",
      "799it [01:43,  7.88it/s]\titers: 800, epoch: 3 | loss: 1.0025202\n",
      "\tspeed: 0.1285s/iter; left time: 3713.5177s\n",
      "899it [01:56,  7.88it/s]\titers: 900, epoch: 3 | loss: 0.5751390\n",
      "\tspeed: 0.1296s/iter; left time: 3731.7946s\n",
      "999it [02:09,  7.84it/s]\titers: 1000, epoch: 3 | loss: 0.3736329\n",
      "\tspeed: 0.1298s/iter; left time: 3725.5384s\n",
      "1099it [02:22,  7.10it/s]\titers: 1100, epoch: 3 | loss: 0.2845280\n",
      "\tspeed: 0.1286s/iter; left time: 3679.9374s\n",
      "1199it [02:35,  7.87it/s]\titers: 1200, epoch: 3 | loss: 0.2719593\n",
      "\tspeed: 0.1293s/iter; left time: 3685.0346s\n",
      "1299it [02:48,  7.83it/s]\titers: 1300, epoch: 3 | loss: 0.2924204\n",
      "\tspeed: 0.1304s/iter; left time: 3703.9041s\n",
      "1399it [03:01,  7.73it/s]\titers: 1400, epoch: 3 | loss: 0.4612133\n",
      "\tspeed: 0.1291s/iter; left time: 3654.3062s\n",
      "1499it [03:14,  7.91it/s]\titers: 1500, epoch: 3 | loss: 0.1913575\n",
      "\tspeed: 0.1285s/iter; left time: 3625.3737s\n",
      "1599it [03:27,  7.79it/s]\titers: 1600, epoch: 3 | loss: 0.7234213\n",
      "\tspeed: 0.1306s/iter; left time: 3669.8067s\n",
      "1699it [03:40,  7.74it/s]\titers: 1700, epoch: 3 | loss: 0.4735206\n",
      "\tspeed: 0.1311s/iter; left time: 3670.5548s\n",
      "1799it [03:53,  7.68it/s]\titers: 1800, epoch: 3 | loss: 0.2808116\n",
      "\tspeed: 0.1287s/iter; left time: 3592.2362s\n",
      "1899it [04:06,  7.77it/s]\titers: 1900, epoch: 3 | loss: 0.3126731\n",
      "\tspeed: 0.1331s/iter; left time: 3700.0253s\n",
      "1999it [04:20,  7.63it/s]\titers: 2000, epoch: 3 | loss: 0.2936290\n",
      "\tspeed: 0.1333s/iter; left time: 3693.9308s\n",
      "2099it [04:32,  7.82it/s]\titers: 2100, epoch: 3 | loss: 0.3481406\n",
      "\tspeed: 0.1289s/iter; left time: 3557.2027s\n",
      "2199it [04:46,  7.89it/s]\titers: 2200, epoch: 3 | loss: 0.2055496\n",
      "\tspeed: 0.1307s/iter; left time: 3594.6466s\n",
      "2299it [04:59,  7.61it/s]\titers: 2300, epoch: 3 | loss: 0.2287608\n",
      "\tspeed: 0.1317s/iter; left time: 3609.6501s\n",
      "2399it [05:11,  7.83it/s]\titers: 2400, epoch: 3 | loss: 0.2860211\n",
      "\tspeed: 0.1271s/iter; left time: 3469.2007s\n",
      "2499it [05:24,  7.91it/s]\titers: 2500, epoch: 3 | loss: 0.3091559\n",
      "\tspeed: 0.1297s/iter; left time: 3528.4626s\n",
      "2599it [05:37,  6.18it/s]\titers: 2600, epoch: 3 | loss: 0.3608786\n",
      "\tspeed: 0.1297s/iter; left time: 3515.5358s\n",
      "2699it [05:50,  7.86it/s]\titers: 2700, epoch: 3 | loss: 0.2663588\n",
      "\tspeed: 0.1278s/iter; left time: 3451.4829s\n",
      "2799it [06:03,  7.71it/s]\titers: 2800, epoch: 3 | loss: 0.3184358\n",
      "\tspeed: 0.1305s/iter; left time: 3511.9522s\n",
      "2899it [06:16,  7.72it/s]\titers: 2900, epoch: 3 | loss: 0.2107174\n",
      "\tspeed: 0.1299s/iter; left time: 3483.0505s\n",
      "2999it [06:29,  7.64it/s]\titers: 3000, epoch: 3 | loss: 0.3653926\n",
      "\tspeed: 0.1278s/iter; left time: 3412.7191s\n",
      "3099it [06:42,  7.83it/s]\titers: 3100, epoch: 3 | loss: 0.3442631\n",
      "\tspeed: 0.1285s/iter; left time: 3419.4389s\n",
      "3199it [06:55,  7.94it/s]\titers: 3200, epoch: 3 | loss: 0.2078412\n",
      "\tspeed: 0.1289s/iter; left time: 3416.8147s\n",
      "3299it [07:07,  7.57it/s]\titers: 3300, epoch: 3 | loss: 0.2802461\n",
      "\tspeed: 0.1272s/iter; left time: 3359.8345s\n",
      "3399it [07:20,  7.89it/s]\titers: 3400, epoch: 3 | loss: 0.3181832\n",
      "\tspeed: 0.1273s/iter; left time: 3349.9316s\n",
      "3499it [07:33,  7.91it/s]\titers: 3500, epoch: 3 | loss: 0.3222934\n",
      "\tspeed: 0.1280s/iter; left time: 3354.7279s\n",
      "3599it [07:46,  7.90it/s]\titers: 3600, epoch: 3 | loss: 0.1407734\n",
      "\tspeed: 0.1271s/iter; left time: 3316.7924s\n",
      "3699it [07:58,  7.75it/s]\titers: 3700, epoch: 3 | loss: 0.6066621\n",
      "\tspeed: 0.1278s/iter; left time: 3322.1774s\n",
      "3713it [08:00,  7.72it/s]\n",
      "Epoch: 3 cost time: 480.8268074989319\n",
      "810it [00:48, 16.72it/s]\n",
      "807it [00:48, 16.70it/s]\n",
      "Epoch: 3 | Train Loss: 0.3307373 Vali Loss: 0.4145984 Test Loss: 0.5158148 MAE Loss: 0.4856396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0009455038\n",
      "99it [00:13,  7.51it/s]\titers: 100, epoch: 4 | loss: 0.3085895\n",
      "\tspeed: 1.1182s/iter; left time: 28953.1088s\n",
      "199it [00:26,  7.87it/s]\titers: 200, epoch: 4 | loss: 0.3190602\n",
      "\tspeed: 0.1305s/iter; left time: 3366.6959s\n",
      "299it [00:39,  7.81it/s]\titers: 300, epoch: 4 | loss: 0.3972897\n",
      "\tspeed: 0.1298s/iter; left time: 3335.2319s\n",
      "399it [00:52,  7.62it/s]\titers: 400, epoch: 4 | loss: 0.6874273\n",
      "\tspeed: 0.1296s/iter; left time: 3317.5713s\n",
      "499it [01:04,  7.76it/s]\titers: 500, epoch: 4 | loss: 0.1665531\n",
      "\tspeed: 0.1292s/iter; left time: 3293.8501s\n",
      "599it [01:18,  7.70it/s]\titers: 600, epoch: 4 | loss: 0.3449117\n",
      "\tspeed: 0.1308s/iter; left time: 3321.0708s\n",
      "699it [01:30,  7.40it/s]\titers: 700, epoch: 4 | loss: 0.4637513\n",
      "\tspeed: 0.1286s/iter; left time: 3253.0285s\n",
      "799it [01:43,  7.88it/s]\titers: 800, epoch: 4 | loss: 0.3791815\n",
      "\tspeed: 0.1284s/iter; left time: 3235.0704s\n",
      "899it [01:56,  7.85it/s]\titers: 900, epoch: 4 | loss: 0.3098664\n",
      "\tspeed: 0.1319s/iter; left time: 3309.7433s\n",
      "999it [02:10,  7.68it/s]\titers: 1000, epoch: 4 | loss: 0.3481237\n",
      "\tspeed: 0.1320s/iter; left time: 3298.2259s\n",
      "1099it [02:22,  7.76it/s]\titers: 1100, epoch: 4 | loss: 0.2980776\n",
      "\tspeed: 0.1283s/iter; left time: 3192.8146s\n",
      "1199it [02:35,  7.78it/s]\titers: 1200, epoch: 4 | loss: 0.4521514\n",
      "\tspeed: 0.1302s/iter; left time: 3227.6695s\n",
      "1299it [02:48,  7.89it/s]\titers: 1300, epoch: 4 | loss: 0.4708442\n",
      "\tspeed: 0.1299s/iter; left time: 3207.9989s\n",
      "1399it [03:01,  7.94it/s]\titers: 1400, epoch: 4 | loss: 0.3791539\n",
      "\tspeed: 0.1285s/iter; left time: 3160.4429s\n",
      "1499it [03:14,  7.83it/s]\titers: 1500, epoch: 4 | loss: 0.3401311\n",
      "\tspeed: 0.1304s/iter; left time: 3193.4302s\n",
      "1599it [03:27,  8.04it/s]\titers: 1600, epoch: 4 | loss: 0.3305887\n",
      "\tspeed: 0.1294s/iter; left time: 3156.2043s\n",
      "1699it [03:40,  7.83it/s]\titers: 1700, epoch: 4 | loss: 0.3038333\n",
      "\tspeed: 0.1285s/iter; left time: 3120.7782s\n",
      "1799it [03:53,  7.69it/s]\titers: 1800, epoch: 4 | loss: 0.2486874\n",
      "\tspeed: 0.1287s/iter; left time: 3113.7273s\n",
      "1899it [04:06,  7.85it/s]\titers: 1900, epoch: 4 | loss: 0.4243304\n",
      "\tspeed: 0.1299s/iter; left time: 3128.6855s\n",
      "1999it [04:19,  7.01it/s]\titers: 2000, epoch: 4 | loss: 0.2149484\n",
      "\tspeed: 0.1296s/iter; left time: 3109.3499s\n",
      "2099it [04:32,  7.79it/s]\titers: 2100, epoch: 4 | loss: 0.3770129\n",
      "\tspeed: 0.1273s/iter; left time: 3040.4074s\n",
      "2199it [04:45,  7.82it/s]\titers: 2200, epoch: 4 | loss: 0.1947407\n",
      "\tspeed: 0.1293s/iter; left time: 3076.9328s\n",
      "2299it [04:58,  7.89it/s]\titers: 2300, epoch: 4 | loss: 0.2886204\n",
      "\tspeed: 0.1309s/iter; left time: 3101.3148s\n",
      "2399it [05:11,  6.82it/s]\titers: 2400, epoch: 4 | loss: 0.2057156\n",
      "\tspeed: 0.1292s/iter; left time: 3048.7349s\n",
      "2499it [05:24,  7.90it/s]\titers: 2500, epoch: 4 | loss: 0.2986284\n",
      "\tspeed: 0.1299s/iter; left time: 3051.4168s\n",
      "2599it [05:37,  7.90it/s]\titers: 2600, epoch: 4 | loss: 0.3845401\n",
      "\tspeed: 0.1311s/iter; left time: 3065.9263s\n",
      "2699it [05:50,  7.85it/s]\titers: 2700, epoch: 4 | loss: 0.2046233\n",
      "\tspeed: 0.1283s/iter; left time: 2987.9317s\n",
      "2799it [06:02,  7.86it/s]\titers: 2800, epoch: 4 | loss: 0.5872942\n",
      "\tspeed: 0.1280s/iter; left time: 2967.4331s\n",
      "2899it [06:15,  7.95it/s]\titers: 2900, epoch: 4 | loss: 0.2787766\n",
      "\tspeed: 0.1280s/iter; left time: 2954.9400s\n",
      "2999it [06:28,  7.84it/s]\titers: 3000, epoch: 4 | loss: 0.3276455\n",
      "\tspeed: 0.1278s/iter; left time: 2938.9111s\n",
      "3099it [06:41,  7.95it/s]\titers: 3100, epoch: 4 | loss: 0.2882536\n",
      "\tspeed: 0.1272s/iter; left time: 2912.6387s\n",
      "3199it [06:54,  8.04it/s]\titers: 3200, epoch: 4 | loss: 0.3190152\n",
      "\tspeed: 0.1290s/iter; left time: 2940.3293s\n",
      "3299it [07:06,  7.83it/s]\titers: 3300, epoch: 4 | loss: 0.2534955\n",
      "\tspeed: 0.1284s/iter; left time: 2912.5527s\n",
      "3399it [07:19,  7.49it/s]\titers: 3400, epoch: 4 | loss: 0.2013041\n",
      "\tspeed: 0.1267s/iter; left time: 2862.8180s\n",
      "3499it [07:32,  7.91it/s]\titers: 3500, epoch: 4 | loss: 0.3635070\n",
      "\tspeed: 0.1283s/iter; left time: 2884.7892s\n",
      "3599it [07:45,  7.81it/s]\titers: 3600, epoch: 4 | loss: 0.3619284\n",
      "\tspeed: 0.1299s/iter; left time: 2909.0581s\n",
      "3699it [07:58,  7.77it/s]\titers: 3700, epoch: 4 | loss: 0.1722519\n",
      "\tspeed: 0.1289s/iter; left time: 2874.1823s\n",
      "3713it [08:00,  7.73it/s]\n",
      "Epoch: 4 cost time: 480.4098255634308\n",
      "810it [00:48, 16.82it/s]\n",
      "807it [00:48, 16.50it/s]\n",
      "Epoch: 4 | Train Loss: 0.3298674 Vali Loss: 0.3902555 Test Loss: 0.4786931 MAE Loss: 0.4599794\n",
      "lr = 0.0009045095\n",
      "99it [00:13,  7.92it/s]\titers: 100, epoch: 5 | loss: 0.2062469\n",
      "\tspeed: 1.1639s/iter; left time: 25814.7147s\n",
      "199it [00:26,  7.70it/s]\titers: 200, epoch: 5 | loss: 0.2092327\n",
      "\tspeed: 0.1285s/iter; left time: 2838.1422s\n",
      "299it [00:39,  7.74it/s]\titers: 300, epoch: 5 | loss: 0.3449670\n",
      "\tspeed: 0.1288s/iter; left time: 2830.2166s\n",
      "399it [00:52,  7.87it/s]\titers: 400, epoch: 5 | loss: 0.3249771\n",
      "\tspeed: 0.1317s/iter; left time: 2881.0262s\n",
      "499it [01:05,  7.79it/s]\titers: 500, epoch: 5 | loss: 0.1315668\n",
      "\tspeed: 0.1296s/iter; left time: 2823.3163s\n",
      "599it [01:18,  7.73it/s]\titers: 600, epoch: 5 | loss: 0.2624253\n",
      "\tspeed: 0.1288s/iter; left time: 2792.2911s\n",
      "699it [01:31,  7.84it/s]\titers: 700, epoch: 5 | loss: 0.3038742\n",
      "\tspeed: 0.1304s/iter; left time: 2814.2567s\n",
      "799it [01:44,  7.06it/s]\titers: 800, epoch: 5 | loss: 0.3684295\n",
      "\tspeed: 0.1302s/iter; left time: 2797.4030s\n",
      "899it [01:56,  7.56it/s]\titers: 900, epoch: 5 | loss: 0.4144670\n",
      "\tspeed: 0.1270s/iter; left time: 2715.9057s\n",
      "999it [02:09,  7.81it/s]\titers: 1000, epoch: 5 | loss: 0.3208720\n",
      "\tspeed: 0.1291s/iter; left time: 2747.1078s\n",
      "1099it [02:22,  7.97it/s]\titers: 1100, epoch: 5 | loss: 0.3457694\n",
      "\tspeed: 0.1294s/iter; left time: 2740.8900s\n",
      "1199it [02:35,  7.88it/s]\titers: 1200, epoch: 5 | loss: 0.3169947\n",
      "\tspeed: 0.1284s/iter; left time: 2705.9622s\n",
      "1299it [02:48,  7.74it/s]\titers: 1300, epoch: 5 | loss: 0.1993393\n",
      "\tspeed: 0.1291s/iter; left time: 2709.2905s\n",
      "1399it [03:01,  7.85it/s]\titers: 1400, epoch: 5 | loss: 0.1898936\n",
      "\tspeed: 0.1296s/iter; left time: 2706.8976s\n",
      "1499it [03:14,  7.89it/s]\titers: 1500, epoch: 5 | loss: 0.1944701\n",
      "\tspeed: 0.1286s/iter; left time: 2672.7828s\n",
      "1599it [03:27,  7.99it/s]\titers: 1600, epoch: 5 | loss: 0.2967289\n",
      "\tspeed: 0.1272s/iter; left time: 2629.8862s\n",
      "1699it [03:39,  7.92it/s]\titers: 1700, epoch: 5 | loss: 0.2972065\n",
      "\tspeed: 0.1282s/iter; left time: 2638.7958s\n",
      "1799it [03:52,  7.94it/s]\titers: 1800, epoch: 5 | loss: 0.2943450\n",
      "\tspeed: 0.1293s/iter; left time: 2647.0468s\n",
      "1899it [04:05,  7.69it/s]\titers: 1900, epoch: 5 | loss: 0.3562803\n",
      "\tspeed: 0.1287s/iter; left time: 2621.8298s\n",
      "1999it [04:18,  7.74it/s]\titers: 2000, epoch: 5 | loss: 0.2711124\n",
      "\tspeed: 0.1288s/iter; left time: 2611.6762s\n",
      "2099it [04:31,  7.84it/s]\titers: 2100, epoch: 5 | loss: 0.3655235\n",
      "\tspeed: 0.1297s/iter; left time: 2617.1938s\n",
      "2199it [04:44,  7.87it/s]\titers: 2200, epoch: 5 | loss: 0.2359903\n",
      "\tspeed: 0.1303s/iter; left time: 2617.1788s\n",
      "2299it [04:57,  7.65it/s]\titers: 2300, epoch: 5 | loss: 0.5608481\n",
      "\tspeed: 0.1295s/iter; left time: 2587.4068s\n",
      "2399it [05:10,  7.77it/s]\titers: 2400, epoch: 5 | loss: 0.3043300\n",
      "\tspeed: 0.1289s/iter; left time: 2562.4152s\n",
      "2499it [05:23,  7.93it/s]\titers: 2500, epoch: 5 | loss: 0.3357579\n",
      "\tspeed: 0.1292s/iter; left time: 2555.5241s\n",
      "2599it [05:36,  6.55it/s]\titers: 2600, epoch: 5 | loss: 0.4537764\n",
      "\tspeed: 0.1300s/iter; left time: 2558.2860s\n",
      "2699it [05:48,  7.81it/s]\titers: 2700, epoch: 5 | loss: 0.2674872\n",
      "\tspeed: 0.1265s/iter; left time: 2476.2457s\n",
      "2799it [06:01,  7.88it/s]\titers: 2800, epoch: 5 | loss: 0.2827784\n",
      "\tspeed: 0.1286s/iter; left time: 2504.9350s\n",
      "2899it [06:14,  7.86it/s]\titers: 2900, epoch: 5 | loss: 0.3093247\n",
      "\tspeed: 0.1284s/iter; left time: 2488.0927s\n",
      "2999it [06:27,  7.49it/s]\titers: 3000, epoch: 5 | loss: 0.3517567\n",
      "\tspeed: 0.1272s/iter; left time: 2452.1209s\n",
      "3099it [06:40,  7.82it/s]\titers: 3100, epoch: 5 | loss: 0.3229257\n",
      "\tspeed: 0.1280s/iter; left time: 2454.3884s\n",
      "3199it [06:53,  7.79it/s]\titers: 3200, epoch: 5 | loss: 0.3408239\n",
      "\tspeed: 0.1306s/iter; left time: 2491.7868s\n",
      "3299it [07:06,  7.57it/s]\titers: 3300, epoch: 5 | loss: 0.3052003\n",
      "\tspeed: 0.1288s/iter; left time: 2444.1325s\n",
      "3399it [07:18,  7.83it/s]\titers: 3400, epoch: 5 | loss: 0.3453138\n",
      "\tspeed: 0.1289s/iter; left time: 2432.7699s\n",
      "3499it [07:31,  7.77it/s]\titers: 3500, epoch: 5 | loss: 0.4115940\n",
      "\tspeed: 0.1302s/iter; left time: 2445.2985s\n",
      "3599it [07:44,  7.71it/s]\titers: 3600, epoch: 5 | loss: 0.4233800\n",
      "\tspeed: 0.1286s/iter; left time: 2401.7575s\n",
      "3699it [07:57,  7.65it/s]\titers: 3700, epoch: 5 | loss: 0.2183217\n",
      "\tspeed: 0.1309s/iter; left time: 2431.9265s\n",
      "3713it [07:59,  7.74it/s]\n",
      "Epoch: 5 cost time: 479.80248856544495\n",
      "810it [00:48, 16.59it/s]\n",
      "807it [00:48, 16.62it/s]\n",
      "Epoch: 5 | Train Loss: 0.3223494 Vali Loss: 0.3899679 Test Loss: 0.5002480 MAE Loss: 0.4720434\n",
      "lr = 0.0008535549\n",
      "99it [00:13,  7.90it/s]\titers: 100, epoch: 6 | loss: 0.3981171\n",
      "\tspeed: 1.1652s/iter; left time: 21515.9685s\n",
      "199it [00:26,  7.80it/s]\titers: 200, epoch: 6 | loss: 0.2415454\n",
      "\tspeed: 0.1302s/iter; left time: 2391.0793s\n",
      "299it [00:39,  7.84it/s]\titers: 300, epoch: 6 | loss: 0.4251336\n",
      "\tspeed: 0.1305s/iter; left time: 2384.4531s\n",
      "399it [00:51,  6.97it/s]\titers: 400, epoch: 6 | loss: 0.2379706\n",
      "\tspeed: 0.1285s/iter; left time: 2334.1756s\n",
      "499it [01:04,  7.98it/s]\titers: 500, epoch: 6 | loss: 0.2679409\n",
      "\tspeed: 0.1290s/iter; left time: 2330.0865s\n",
      "599it [01:17,  7.79it/s]\titers: 600, epoch: 6 | loss: 0.4484220\n",
      "\tspeed: 0.1301s/iter; left time: 2337.4122s\n",
      "699it [01:30,  7.91it/s]\titers: 700, epoch: 6 | loss: 0.4534326\n",
      "\tspeed: 0.1306s/iter; left time: 2332.5761s\n",
      "799it [01:43,  7.79it/s]\titers: 800, epoch: 6 | loss: 0.4298534\n",
      "\tspeed: 0.1290s/iter; left time: 2291.8798s\n",
      "899it [01:56,  7.71it/s]\titers: 900, epoch: 6 | loss: 0.4534819\n",
      "\tspeed: 0.1317s/iter; left time: 2325.7789s\n",
      "999it [02:10,  7.61it/s]\titers: 1000, epoch: 6 | loss: 0.2164369\n",
      "\tspeed: 0.1316s/iter; left time: 2311.7164s\n",
      "1099it [02:23,  7.64it/s]\titers: 1100, epoch: 6 | loss: 0.2568227\n",
      "\tspeed: 0.1322s/iter; left time: 2309.7600s\n",
      "1199it [02:36,  7.54it/s]\titers: 1200, epoch: 6 | loss: 0.3906294\n",
      "\tspeed: 0.1334s/iter; left time: 2317.1080s\n",
      "1299it [02:49,  7.92it/s]\titers: 1300, epoch: 6 | loss: 0.3052442\n",
      "\tspeed: 0.1307s/iter; left time: 2256.9674s\n",
      "1399it [03:02,  7.83it/s]\titers: 1400, epoch: 6 | loss: 0.2060187\n",
      "\tspeed: 0.1284s/iter; left time: 2204.4717s\n",
      "1499it [03:15,  7.97it/s]\titers: 1500, epoch: 6 | loss: 0.2281263\n",
      "\tspeed: 0.1312s/iter; left time: 2239.5127s\n",
      "1599it [03:28,  7.96it/s]\titers: 1600, epoch: 6 | loss: 0.1834518\n",
      "\tspeed: 0.1310s/iter; left time: 2222.3549s\n",
      "1699it [03:41,  7.69it/s]\titers: 1700, epoch: 6 | loss: 0.4229937\n",
      "\tspeed: 0.1309s/iter; left time: 2208.4349s\n",
      "1799it [03:54,  7.91it/s]\titers: 1800, epoch: 6 | loss: 0.3029844\n",
      "\tspeed: 0.1284s/iter; left time: 2152.1588s\n",
      "1899it [04:08,  7.85it/s]\titers: 1900, epoch: 6 | loss: 0.3882581\n",
      "\tspeed: 0.1338s/iter; left time: 2230.5745s\n",
      "1999it [04:21,  7.81it/s]\titers: 2000, epoch: 6 | loss: 0.2055421\n",
      "\tspeed: 0.1320s/iter; left time: 2186.9107s\n",
      "2099it [04:34,  6.73it/s]\titers: 2100, epoch: 6 | loss: 0.3976897\n",
      "\tspeed: 0.1298s/iter; left time: 2137.3712s\n",
      "2199it [04:47,  7.85it/s]\titers: 2200, epoch: 6 | loss: 0.1607098\n",
      "\tspeed: 0.1288s/iter; left time: 2108.6785s\n",
      "2299it [05:00,  7.63it/s]\titers: 2300, epoch: 6 | loss: 0.2873370\n",
      "\tspeed: 0.1327s/iter; left time: 2157.9190s\n",
      "2399it [05:13,  7.54it/s]\titers: 2400, epoch: 6 | loss: 0.2190129\n",
      "\tspeed: 0.1322s/iter; left time: 2137.3461s\n",
      "2499it [05:26,  7.60it/s]\titers: 2500, epoch: 6 | loss: 0.5059695\n",
      "\tspeed: 0.1314s/iter; left time: 2110.3991s\n",
      "2599it [05:40,  7.71it/s]\titers: 2600, epoch: 6 | loss: 0.2571782\n",
      "\tspeed: 0.1326s/iter; left time: 2117.3160s\n",
      "2699it [05:53,  7.68it/s]\titers: 2700, epoch: 6 | loss: 0.3782385\n",
      "\tspeed: 0.1299s/iter; left time: 2060.4116s\n",
      "2799it [06:06,  7.74it/s]\titers: 2800, epoch: 6 | loss: 0.4393087\n",
      "\tspeed: 0.1293s/iter; left time: 2039.2107s\n",
      "2899it [06:19,  7.81it/s]\titers: 2900, epoch: 6 | loss: 0.3307942\n",
      "\tspeed: 0.1328s/iter; left time: 2080.4202s\n",
      "2999it [06:32,  7.82it/s]\titers: 3000, epoch: 6 | loss: 0.3004380\n",
      "\tspeed: 0.1286s/iter; left time: 2002.4571s\n",
      "3099it [06:44,  7.89it/s]\titers: 3100, epoch: 6 | loss: 0.3270711\n",
      "\tspeed: 0.1281s/iter; left time: 1980.8992s\n",
      "3199it [06:58,  7.72it/s]\titers: 3200, epoch: 6 | loss: 0.2833447\n",
      "\tspeed: 0.1312s/iter; left time: 2016.2186s\n",
      "3299it [07:11,  7.88it/s]\titers: 3300, epoch: 6 | loss: 0.1918054\n",
      "\tspeed: 0.1316s/iter; left time: 2008.5078s\n",
      "3399it [07:24,  6.86it/s]\titers: 3400, epoch: 6 | loss: 0.3671283\n",
      "\tspeed: 0.1282s/iter; left time: 1944.1188s\n",
      "3499it [07:36,  7.86it/s]\titers: 3500, epoch: 6 | loss: 0.1911821\n",
      "\tspeed: 0.1285s/iter; left time: 1936.4761s\n",
      "3599it [07:49,  7.76it/s]\titers: 3600, epoch: 6 | loss: 0.3678643\n",
      "\tspeed: 0.1297s/iter; left time: 1940.8470s\n",
      "3699it [08:02,  7.84it/s]\titers: 3700, epoch: 6 | loss: 0.5699005\n",
      "\tspeed: 0.1279s/iter; left time: 1900.6644s\n",
      "3713it [08:04,  7.66it/s]\n",
      "Epoch: 6 cost time: 484.68526124954224\n",
      "810it [00:48, 16.87it/s]\n",
      "807it [00:48, 16.55it/s]\n",
      "Epoch: 6 | Train Loss: 0.3198384 Vali Loss: 0.3886737 Test Loss: 0.4846429 MAE Loss: 0.4600995\n",
      "lr = 0.0007938947\n",
      "99it [00:13,  7.85it/s]\titers: 100, epoch: 7 | loss: 0.2265851\n",
      "\tspeed: 1.1605s/iter; left time: 17120.6246s\n",
      "199it [00:26,  7.73it/s]\titers: 200, epoch: 7 | loss: 0.2100025\n",
      "\tspeed: 0.1293s/iter; left time: 1895.2212s\n",
      "299it [00:39,  7.86it/s]\titers: 300, epoch: 7 | loss: 0.5523100\n",
      "\tspeed: 0.1285s/iter; left time: 1870.5693s\n",
      "399it [00:52,  7.77it/s]\titers: 400, epoch: 7 | loss: 0.4162106\n",
      "\tspeed: 0.1316s/iter; left time: 1902.3327s\n",
      "499it [01:05,  7.99it/s]\titers: 500, epoch: 7 | loss: 0.3099052\n",
      "\tspeed: 0.1306s/iter; left time: 1874.0942s\n",
      "599it [01:18,  7.78it/s]\titers: 600, epoch: 7 | loss: 0.1792604\n",
      "\tspeed: 0.1275s/iter; left time: 1817.4460s\n",
      "699it [01:31,  7.80it/s]\titers: 700, epoch: 7 | loss: 0.2216137\n",
      "\tspeed: 0.1296s/iter; left time: 1833.6153s\n",
      "799it [01:44,  7.91it/s]\titers: 800, epoch: 7 | loss: 0.4571757\n",
      "\tspeed: 0.1317s/iter; left time: 1850.3749s\n",
      "899it [01:57,  7.67it/s]\titers: 900, epoch: 7 | loss: 0.2167834\n",
      "\tspeed: 0.1290s/iter; left time: 1799.6207s\n",
      "999it [02:10,  7.92it/s]\titers: 1000, epoch: 7 | loss: 0.2711854\n",
      "\tspeed: 0.1281s/iter; left time: 1775.1611s\n",
      "1099it [02:22,  7.81it/s]\titers: 1100, epoch: 7 | loss: 0.3673321\n",
      "\tspeed: 0.1291s/iter; left time: 1774.9210s\n",
      "1199it [02:36,  7.91it/s]\titers: 1200, epoch: 7 | loss: 0.3153488\n",
      "\tspeed: 0.1316s/iter; left time: 1796.4371s\n",
      "1299it [02:49,  7.24it/s]\titers: 1300, epoch: 7 | loss: 0.2096113\n",
      "\tspeed: 0.1301s/iter; left time: 1763.3571s\n",
      "1399it [03:01,  7.94it/s]\titers: 1400, epoch: 7 | loss: 0.5648524\n",
      "\tspeed: 0.1279s/iter; left time: 1720.7785s\n",
      "1499it [03:14,  7.73it/s]\titers: 1500, epoch: 7 | loss: 0.1719721\n",
      "\tspeed: 0.1299s/iter; left time: 1734.2475s\n",
      "1599it [03:28,  7.84it/s]\titers: 1600, epoch: 7 | loss: 0.6261527\n",
      "\tspeed: 0.1316s/iter; left time: 1744.2192s\n",
      "1699it [03:40,  7.70it/s]\titers: 1700, epoch: 7 | loss: 0.4650384\n",
      "\tspeed: 0.1275s/iter; left time: 1677.0732s\n",
      "1799it [03:54,  7.87it/s]\titers: 1800, epoch: 7 | loss: 0.5716541\n",
      "\tspeed: 0.1319s/iter; left time: 1721.9950s\n",
      "1899it [04:07,  7.77it/s]\titers: 1900, epoch: 7 | loss: 0.3695265\n",
      "\tspeed: 0.1319s/iter; left time: 1707.8587s\n",
      "1999it [04:20,  7.81it/s]\titers: 2000, epoch: 7 | loss: 0.4043526\n",
      "\tspeed: 0.1283s/iter; left time: 1648.5378s\n",
      "2099it [04:33,  7.90it/s]\titers: 2100, epoch: 7 | loss: 0.2021791\n",
      "\tspeed: 0.1305s/iter; left time: 1663.7812s\n",
      "2199it [04:46,  7.82it/s]\titers: 2200, epoch: 7 | loss: 0.2972278\n",
      "\tspeed: 0.1320s/iter; left time: 1670.7707s\n",
      "2299it [04:59,  6.82it/s]\titers: 2300, epoch: 7 | loss: 0.3575771\n",
      "\tspeed: 0.1327s/iter; left time: 1665.2835s\n",
      "2399it [05:12,  7.67it/s]\titers: 2400, epoch: 7 | loss: 0.2037572\n",
      "\tspeed: 0.1291s/iter; left time: 1607.7650s\n",
      "2499it [05:25,  7.75it/s]\titers: 2500, epoch: 7 | loss: 0.1965705\n",
      "\tspeed: 0.1315s/iter; left time: 1624.1397s\n",
      "2599it [05:38,  7.47it/s]\titers: 2600, epoch: 7 | loss: 0.3151780\n",
      "\tspeed: 0.1317s/iter; left time: 1613.1828s\n",
      "2699it [05:58,  5.72it/s]\titers: 2700, epoch: 7 | loss: 0.2034536\n",
      "\tspeed: 0.1955s/iter; left time: 2376.5054s\n",
      "2799it [06:14,  7.87it/s]\titers: 2800, epoch: 7 | loss: 0.2483424\n",
      "\tspeed: 0.1607s/iter; left time: 1936.7520s\n",
      "2899it [06:32,  7.50it/s]\titers: 2900, epoch: 7 | loss: 0.2180000\n",
      "\tspeed: 0.1771s/iter; left time: 2117.1396s\n",
      "2999it [06:48,  7.76it/s]\titers: 3000, epoch: 7 | loss: 0.4697379\n",
      "\tspeed: 0.1616s/iter; left time: 1916.0038s\n",
      "3099it [07:06,  4.15it/s]\titers: 3100, epoch: 7 | loss: 0.2891927\n",
      "\tspeed: 0.1776s/iter; left time: 2087.4338s\n",
      "3199it [07:22,  3.66it/s]\titers: 3200, epoch: 7 | loss: 0.2120788\n",
      "\tspeed: 0.1681s/iter; left time: 1959.1010s\n",
      "3299it [07:39,  7.95it/s]\titers: 3300, epoch: 7 | loss: 0.2999848\n",
      "\tspeed: 0.1686s/iter; left time: 1947.7734s\n",
      "3399it [07:55,  8.03it/s]\titers: 3400, epoch: 7 | loss: 0.2691816\n",
      "\tspeed: 0.1602s/iter; left time: 1834.6933s\n",
      "3499it [08:12,  4.37it/s]\titers: 3500, epoch: 7 | loss: 0.1904802\n",
      "\tspeed: 0.1658s/iter; left time: 1882.1558s\n",
      "3599it [08:29,  7.99it/s]\titers: 3600, epoch: 7 | loss: 0.3413115\n",
      "\tspeed: 0.1718s/iter; left time: 1933.1138s\n",
      "3699it [08:47,  7.54it/s]\titers: 3700, epoch: 7 | loss: 0.3261745\n",
      "\tspeed: 0.1767s/iter; left time: 1970.5429s\n",
      "3713it [08:49,  7.02it/s]\n",
      "Epoch: 7 cost time: 529.0069010257721\n",
      "810it [01:03, 12.79it/s]\n",
      "807it [01:03, 12.74it/s]\n",
      "Epoch: 7 | Train Loss: 0.3178822 Vali Loss: 0.4026718 Test Loss: 0.5029341 MAE Loss: 0.4814337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007269980\n",
      "99it [00:16,  7.80it/s]\titers: 100, epoch: 8 | loss: 0.1936937\n",
      "\tspeed: 1.4497s/iter; left time: 16004.8470s\n",
      "199it [00:32,  7.90it/s]\titers: 200, epoch: 8 | loss: 0.3481279\n",
      "\tspeed: 0.1602s/iter; left time: 1752.4219s\n",
      "299it [00:50,  5.17it/s]\titers: 300, epoch: 8 | loss: 0.2465445\n",
      "\tspeed: 0.1776s/iter; left time: 1925.0643s\n",
      "399it [01:06,  7.67it/s]\titers: 400, epoch: 8 | loss: 0.3907549\n",
      "\tspeed: 0.1601s/iter; left time: 1719.3119s\n",
      "499it [01:23,  4.24it/s]\titers: 500, epoch: 8 | loss: 0.2190004\n",
      "\tspeed: 0.1766s/iter; left time: 1879.2375s\n",
      "599it [01:39,  7.77it/s]\titers: 600, epoch: 8 | loss: 0.3313726\n",
      "\tspeed: 0.1601s/iter; left time: 1687.7808s\n",
      "699it [01:55,  7.81it/s]\titers: 700, epoch: 8 | loss: 0.5199006\n",
      "\tspeed: 0.1603s/iter; left time: 1673.2073s\n",
      "799it [02:11,  7.69it/s]\titers: 800, epoch: 8 | loss: 0.4603224\n",
      "\tspeed: 0.1615s/iter; left time: 1669.4008s\n",
      "899it [02:29,  7.81it/s]\titers: 900, epoch: 8 | loss: 0.3747466\n",
      "\tspeed: 0.1761s/iter; left time: 1802.9596s\n",
      "999it [02:46,  4.16it/s]\titers: 1000, epoch: 8 | loss: 0.3959230\n",
      "\tspeed: 0.1659s/iter; left time: 1681.7440s\n",
      "1099it [03:03,  7.25it/s]\titers: 1100, epoch: 8 | loss: 0.3026269\n",
      "\tspeed: 0.1708s/iter; left time: 1714.4424s\n",
      "1199it [03:19,  7.93it/s]\titers: 1200, epoch: 8 | loss: 0.2920355\n",
      "\tspeed: 0.1606s/iter; left time: 1596.8015s\n",
      "1299it [03:36,  5.94it/s]\titers: 1300, epoch: 8 | loss: 0.5332096\n",
      "\tspeed: 0.1767s/iter; left time: 1738.8630s\n",
      "1399it [03:52,  7.81it/s]\titers: 1400, epoch: 8 | loss: 0.3614319\n",
      "\tspeed: 0.1597s/iter; left time: 1555.1866s\n",
      "1499it [04:08,  7.90it/s]\titers: 1500, epoch: 8 | loss: 0.1590936\n",
      "\tspeed: 0.1600s/iter; left time: 1542.6985s\n",
      "1599it [04:25,  6.78it/s]\titers: 1600, epoch: 8 | loss: 0.3205967\n",
      "\tspeed: 0.1627s/iter; left time: 1552.0248s\n",
      "1699it [04:42,  7.60it/s]\titers: 1700, epoch: 8 | loss: 0.2919439\n",
      "\tspeed: 0.1761s/iter; left time: 1662.2957s\n",
      "1799it [04:59,  4.31it/s]\titers: 1800, epoch: 8 | loss: 0.1961195\n",
      "\tspeed: 0.1658s/iter; left time: 1548.5392s\n",
      "1899it [05:16,  7.74it/s]\titers: 1900, epoch: 8 | loss: 0.2501426\n",
      "\tspeed: 0.1717s/iter; left time: 1586.8218s\n",
      "1999it [05:32,  7.78it/s]\titers: 2000, epoch: 8 | loss: 0.4652239\n",
      "\tspeed: 0.1607s/iter; left time: 1468.4399s\n",
      "2099it [05:48,  7.85it/s]\titers: 2100, epoch: 8 | loss: 0.3647101\n",
      "\tspeed: 0.1615s/iter; left time: 1460.3492s\n",
      "2199it [06:06,  3.16it/s]\titers: 2200, epoch: 8 | loss: 0.3905986\n",
      "\tspeed: 0.1746s/iter; left time: 1561.3123s\n",
      "2299it [06:22,  7.96it/s]\titers: 2300, epoch: 8 | loss: 0.2619036\n",
      "\tspeed: 0.1612s/iter; left time: 1424.8560s\n",
      "2399it [06:40,  3.16it/s]\titers: 2400, epoch: 8 | loss: 0.2907792\n",
      "\tspeed: 0.1769s/iter; left time: 1546.2383s\n",
      "2499it [06:56,  7.00it/s]\titers: 2500, epoch: 8 | loss: 0.3323463\n",
      "\tspeed: 0.1604s/iter; left time: 1386.1326s\n",
      "2599it [07:12,  7.81it/s]\titers: 2600, epoch: 8 | loss: 0.1633468\n",
      "\tspeed: 0.1601s/iter; left time: 1367.4884s\n",
      "2699it [07:28,  7.80it/s]\titers: 2700, epoch: 8 | loss: 0.3098654\n",
      "\tspeed: 0.1604s/iter; left time: 1353.6409s\n",
      "2799it [07:45,  7.86it/s]\titers: 2800, epoch: 8 | loss: 0.1567122\n",
      "\tspeed: 0.1765s/iter; left time: 1472.2065s\n",
      "2899it [08:01,  7.87it/s]\titers: 2900, epoch: 8 | loss: 0.3251747\n",
      "\tspeed: 0.1606s/iter; left time: 1323.5757s\n",
      "2999it [08:17,  7.84it/s]\titers: 3000, epoch: 8 | loss: 0.3707897\n",
      "\tspeed: 0.1610s/iter; left time: 1310.9310s\n",
      "3099it [08:35,  7.12it/s]\titers: 3100, epoch: 8 | loss: 0.5539950\n",
      "\tspeed: 0.1761s/iter; left time: 1415.7535s\n",
      "3199it [08:51,  7.91it/s]\titers: 3200, epoch: 8 | loss: 0.2189280\n",
      "\tspeed: 0.1599s/iter; left time: 1269.8108s\n",
      "3299it [09:09,  3.17it/s]\titers: 3300, epoch: 8 | loss: 0.4177049\n",
      "\tspeed: 0.1768s/iter; left time: 1385.7510s\n",
      "3399it [09:25,  7.67it/s]\titers: 3400, epoch: 8 | loss: 0.2371941\n",
      "\tspeed: 0.1604s/iter; left time: 1241.7680s\n",
      "3499it [09:41,  7.93it/s]\titers: 3500, epoch: 8 | loss: 0.3518778\n",
      "\tspeed: 0.1600s/iter; left time: 1222.5921s\n",
      "3599it [09:57,  7.89it/s]\titers: 3600, epoch: 8 | loss: 0.2310055\n",
      "\tspeed: 0.1601s/iter; left time: 1207.1333s\n",
      "3699it [10:15,  5.64it/s]\titers: 3700, epoch: 8 | loss: 0.2773418\n",
      "\tspeed: 0.1776s/iter; left time: 1321.5845s\n",
      "3713it [10:16,  6.02it/s]\n",
      "Epoch: 8 cost time: 616.9081826210022\n",
      "810it [01:01, 13.15it/s]\n",
      "807it [01:02, 12.96it/s]\n",
      "Epoch: 8 | Train Loss: 0.3127520 Vali Loss: 0.3726595 Test Loss: 0.4752736 MAE Loss: 0.4556114\n",
      "lr = 0.0006545120\n",
      "99it [00:18,  6.47it/s]\titers: 100, epoch: 9 | loss: 0.2628272\n",
      "\tspeed: 1.4736s/iter; left time: 10797.3625s\n",
      "199it [00:34,  7.90it/s]\titers: 200, epoch: 9 | loss: 0.3388748\n",
      "\tspeed: 0.1599s/iter; left time: 1155.6492s\n",
      "299it [00:50,  7.82it/s]\titers: 300, epoch: 9 | loss: 0.2200371\n",
      "\tspeed: 0.1605s/iter; left time: 1144.1664s\n",
      "399it [01:07,  3.32it/s]\titers: 400, epoch: 9 | loss: 0.2471333\n",
      "\tspeed: 0.1725s/iter; left time: 1212.0049s\n",
      "499it [01:23,  6.52it/s]\titers: 500, epoch: 9 | loss: 0.2086286\n",
      "\tspeed: 0.1645s/iter; left time: 1139.2523s\n",
      "599it [01:39,  8.02it/s]\titers: 600, epoch: 9 | loss: 0.2185426\n",
      "\tspeed: 0.1598s/iter; left time: 1090.9307s\n",
      "699it [01:57,  3.18it/s]\titers: 700, epoch: 9 | loss: 0.2660626\n",
      "\tspeed: 0.1762s/iter; left time: 1185.0198s\n",
      "799it [02:13,  4.69it/s]\titers: 800, epoch: 9 | loss: 0.3809134\n",
      "\tspeed: 0.1616s/iter; left time: 1070.8380s\n",
      "899it [02:29,  7.93it/s]\titers: 900, epoch: 9 | loss: 0.2144846\n",
      "\tspeed: 0.1603s/iter; left time: 1046.2685s\n",
      "999it [02:45,  7.88it/s]\titers: 1000, epoch: 9 | loss: 0.3710669\n",
      "\tspeed: 0.1606s/iter; left time: 1031.9545s\n",
      "1099it [03:03,  7.77it/s]\titers: 1100, epoch: 9 | loss: 0.3881444\n",
      "\tspeed: 0.1768s/iter; left time: 1118.6652s\n",
      "1199it [03:19,  7.96it/s]\titers: 1200, epoch: 9 | loss: 0.1951334\n",
      "\tspeed: 0.1610s/iter; left time: 1002.4101s\n",
      "1299it [03:35,  7.83it/s]\titers: 1300, epoch: 9 | loss: 0.1992106\n",
      "\tspeed: 0.1604s/iter; left time: 982.7264s\n",
      "1399it [03:51,  4.55it/s]\titers: 1400, epoch: 9 | loss: 0.3933530\n",
      "\tspeed: 0.1647s/iter; left time: 992.3875s\n",
      "1499it [04:09,  4.44it/s]\titers: 1500, epoch: 9 | loss: 0.4240173\n",
      "\tspeed: 0.1723s/iter; left time: 1021.4244s\n",
      "1599it [04:25,  7.88it/s]\titers: 1600, epoch: 9 | loss: 0.2480144\n",
      "\tspeed: 0.1599s/iter; left time: 931.6150s\n",
      "1699it [04:41,  7.93it/s]\titers: 1700, epoch: 9 | loss: 0.2983743\n",
      "\tspeed: 0.1609s/iter; left time: 921.5593s\n",
      "1799it [04:58,  3.26it/s]\titers: 1800, epoch: 9 | loss: 0.3400280\n",
      "\tspeed: 0.1747s/iter; left time: 982.7688s\n",
      "1899it [05:15,  7.76it/s]\titers: 1900, epoch: 9 | loss: 0.1634814\n",
      "\tspeed: 0.1638s/iter; left time: 905.1555s\n",
      "1999it [05:31,  7.89it/s]\titers: 2000, epoch: 9 | loss: 0.4274901\n",
      "\tspeed: 0.1613s/iter; left time: 875.3299s\n",
      "2099it [05:47,  7.90it/s]\titers: 2100, epoch: 9 | loss: 0.2724287\n",
      "\tspeed: 0.1603s/iter; left time: 854.0704s\n",
      "2199it [06:04,  4.54it/s]\titers: 2200, epoch: 9 | loss: 0.3248950\n",
      "\tspeed: 0.1767s/iter; left time: 923.8101s\n",
      "2299it [06:20,  7.84it/s]\titers: 2300, epoch: 9 | loss: 0.5053042\n",
      "\tspeed: 0.1598s/iter; left time: 819.4681s\n",
      "2399it [06:37,  3.54it/s]\titers: 2400, epoch: 9 | loss: 0.2094833\n",
      "\tspeed: 0.1699s/iter; left time: 854.1963s\n",
      "2499it [06:54,  7.71it/s]\titers: 2500, epoch: 9 | loss: 0.2380140\n",
      "\tspeed: 0.1689s/iter; left time: 832.0038s\n",
      "2599it [07:10,  7.89it/s]\titers: 2600, epoch: 9 | loss: 0.2187919\n",
      "\tspeed: 0.1601s/iter; left time: 772.6694s\n",
      "2699it [07:26,  7.91it/s]\titers: 2700, epoch: 9 | loss: 0.1760520\n",
      "\tspeed: 0.1605s/iter; left time: 758.7391s\n",
      "2799it [07:44,  3.22it/s]\titers: 2800, epoch: 9 | loss: 0.4936087\n",
      "\tspeed: 0.1745s/iter; left time: 807.3472s\n",
      "2899it [08:00,  7.88it/s]\titers: 2900, epoch: 9 | loss: 0.3552023\n",
      "\tspeed: 0.1629s/iter; left time: 737.5330s\n",
      "2999it [08:18,  3.25it/s]\titers: 3000, epoch: 9 | loss: 0.3080100\n",
      "\tspeed: 0.1766s/iter; left time: 781.6089s\n",
      "3099it [08:34,  7.35it/s]\titers: 3100, epoch: 9 | loss: 0.3906256\n",
      "\tspeed: 0.1619s/iter; left time: 700.3686s\n",
      "3199it [08:50,  7.67it/s]\titers: 3200, epoch: 9 | loss: 0.3656609\n",
      "\tspeed: 0.1599s/iter; left time: 675.7984s\n",
      "3299it [09:06,  7.89it/s]\titers: 3300, epoch: 9 | loss: 0.3032006\n",
      "\tspeed: 0.1606s/iter; left time: 662.8936s\n",
      "3399it [09:23,  3.24it/s]\titers: 3400, epoch: 9 | loss: 0.3217273\n",
      "\tspeed: 0.1744s/iter; left time: 702.2125s\n",
      "3499it [09:40,  8.06it/s]\titers: 3500, epoch: 9 | loss: 0.2078187\n",
      "\tspeed: 0.1625s/iter; left time: 638.0813s\n",
      "3599it [09:56,  7.86it/s]\titers: 3600, epoch: 9 | loss: 0.2604896\n",
      "\tspeed: 0.1602s/iter; left time: 613.1821s\n",
      "3699it [10:12,  7.92it/s]\titers: 3700, epoch: 9 | loss: 0.3178231\n",
      "\tspeed: 0.1604s/iter; left time: 597.9816s\n",
      "3713it [10:14,  6.04it/s]\n",
      "Epoch: 9 cost time: 614.6166231632233\n",
      "810it [01:02, 12.93it/s]\n",
      "807it [01:02, 12.97it/s]\n",
      "Epoch: 9 | Train Loss: 0.3058381 Vali Loss: 0.3785458 Test Loss: 0.4643720 MAE Loss: 0.4581837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0005782215\n",
      "99it [00:16,  7.88it/s]\titers: 100, epoch: 10 | loss: 0.2262759\n",
      "\tspeed: 1.4374s/iter; left time: 5194.7168s\n",
      "199it [00:34,  7.65it/s]\titers: 200, epoch: 10 | loss: 0.4223031\n",
      "\tspeed: 0.1772s/iter; left time: 622.6074s\n",
      "299it [00:50,  7.90it/s]\titers: 300, epoch: 10 | loss: 0.3500025\n",
      "\tspeed: 0.1619s/iter; left time: 552.5803s\n",
      "399it [01:06,  7.74it/s]\titers: 400, epoch: 10 | loss: 0.2686449\n",
      "\tspeed: 0.1622s/iter; left time: 537.4179s\n",
      "499it [01:23,  3.32it/s]\titers: 500, epoch: 10 | loss: 0.3244149\n",
      "\tspeed: 0.1743s/iter; left time: 560.1771s\n",
      "599it [01:40,  7.83it/s]\titers: 600, epoch: 10 | loss: 0.2174947\n",
      "\tspeed: 0.1645s/iter; left time: 512.2369s\n",
      "699it [01:56,  7.76it/s]\titers: 700, epoch: 10 | loss: 0.2414598\n",
      "\tspeed: 0.1619s/iter; left time: 487.8523s\n",
      "799it [02:14,  7.55it/s]\titers: 800, epoch: 10 | loss: 0.2375075\n",
      "\tspeed: 0.1784s/iter; left time: 519.7394s\n",
      "899it [02:30,  7.85it/s]\titers: 900, epoch: 10 | loss: 0.3952787\n",
      "\tspeed: 0.1609s/iter; left time: 452.7128s\n",
      "999it [02:46,  7.68it/s]\titers: 1000, epoch: 10 | loss: 0.3944128\n",
      "\tspeed: 0.1614s/iter; left time: 438.0993s\n",
      "1099it [03:02,  7.81it/s]\titers: 1100, epoch: 10 | loss: 0.1583472\n",
      "\tspeed: 0.1615s/iter; left time: 422.1788s\n",
      "1199it [03:20,  7.76it/s]\titers: 1200, epoch: 10 | loss: 0.3862383\n",
      "\tspeed: 0.1780s/iter; left time: 447.5933s\n",
      "1299it [03:37,  4.21it/s]\titers: 1300, epoch: 10 | loss: 0.2872093\n",
      "\tspeed: 0.1675s/iter; left time: 404.3623s\n",
      "1399it [03:54,  6.80it/s]\titers: 1400, epoch: 10 | loss: 0.3244129\n",
      "\tspeed: 0.1722s/iter; left time: 398.5571s\n",
      "1499it [04:10,  7.64it/s]\titers: 1500, epoch: 10 | loss: 0.6322581\n",
      "\tspeed: 0.1610s/iter; left time: 356.4014s\n",
      "1599it [04:26,  7.81it/s]\titers: 1600, epoch: 10 | loss: 0.3227021\n",
      "\tspeed: 0.1604s/iter; left time: 339.0974s\n",
      "1699it [04:44,  5.54it/s]\titers: 1700, epoch: 10 | loss: 0.1612948\n",
      "\tspeed: 0.1782s/iter; left time: 358.9472s\n",
      "1799it [05:00,  7.81it/s]\titers: 1800, epoch: 10 | loss: 0.5255820\n",
      "\tspeed: 0.1616s/iter; left time: 309.2098s\n",
      "1899it [05:16,  6.72it/s]\titers: 1900, epoch: 10 | loss: 0.4663216\n",
      "\tspeed: 0.1633s/iter; left time: 296.2506s\n",
      "1999it [05:33,  6.45it/s]\titers: 2000, epoch: 10 | loss: 0.2521797\n",
      "\tspeed: 0.1617s/iter; left time: 277.1406s\n",
      "2099it [05:50,  7.83it/s]\titers: 2100, epoch: 10 | loss: 0.3337621\n",
      "\tspeed: 0.1757s/iter; left time: 283.5797s\n",
      "2199it [06:06,  6.79it/s]\titers: 2200, epoch: 10 | loss: 0.4249370\n",
      "\tspeed: 0.1625s/iter; left time: 245.9759s\n",
      "2299it [06:24,  8.00it/s]\titers: 2300, epoch: 10 | loss: 0.2716905\n",
      "\tspeed: 0.1754s/iter; left time: 248.0646s\n",
      "2399it [06:40,  7.92it/s]\titers: 2400, epoch: 10 | loss: 0.2343171\n",
      "\tspeed: 0.1612s/iter; left time: 211.8517s\n",
      "2499it [06:56,  7.76it/s]\titers: 2500, epoch: 10 | loss: 0.2048771\n",
      "\tspeed: 0.1619s/iter; left time: 196.6038s\n",
      "2599it [07:14,  7.74it/s]\titers: 2600, epoch: 10 | loss: 0.7223256\n",
      "\tspeed: 0.1777s/iter; left time: 197.9930s\n",
      "2699it [07:30,  7.78it/s]\titers: 2700, epoch: 10 | loss: 0.2624083\n",
      "\tspeed: 0.1612s/iter; left time: 163.4652s\n",
      "2799it [07:48,  3.66it/s]\titers: 2800, epoch: 10 | loss: 0.2136997\n",
      "\tspeed: 0.1784s/iter; left time: 163.0185s\n",
      "2899it [08:04,  6.68it/s]\titers: 2900, epoch: 10 | loss: 0.3243578\n",
      "\tspeed: 0.1619s/iter; left time: 131.7625s\n",
      "2999it [08:20,  7.90it/s]\titers: 3000, epoch: 10 | loss: 0.2444431\n",
      "\tspeed: 0.1605s/iter; left time: 114.6203s\n",
      "3099it [08:37,  3.70it/s]\titers: 3100, epoch: 10 | loss: 0.5657013\n",
      "\tspeed: 0.1695s/iter; left time: 104.0767s\n",
      "3199it [08:54,  6.83it/s]\titers: 3200, epoch: 10 | loss: 0.1933448\n",
      "\tspeed: 0.1704s/iter; left time: 87.5894s\n",
      "3299it [09:10,  7.76it/s]\titers: 3300, epoch: 10 | loss: 0.4643233\n",
      "\tspeed: 0.1614s/iter; left time: 66.8053s\n",
      "3399it [09:27,  6.78it/s]\titers: 3400, epoch: 10 | loss: 0.2606220\n",
      "\tspeed: 0.1627s/iter; left time: 51.0721s\n",
      "3499it [09:44,  6.71it/s]\titers: 3500, epoch: 10 | loss: 0.3533718\n",
      "\tspeed: 0.1744s/iter; left time: 37.3228s\n",
      "3599it [10:00,  6.40it/s]\titers: 3600, epoch: 10 | loss: 0.1801219\n",
      "\tspeed: 0.1638s/iter; left time: 18.6722s\n",
      "3699it [10:18,  6.00it/s]\titers: 3700, epoch: 10 | loss: 0.1827157\n",
      "\tspeed: 0.1758s/iter; left time: 2.4617s\n",
      "3713it [10:20,  5.98it/s]\n",
      "Epoch: 10 cost time: 620.4689009189606\n",
      "810it [01:02, 12.93it/s]\n",
      "807it [01:01, 13.04it/s]\n",
      "Epoch: 10 | Train Loss: 0.3102723 Vali Loss: 0.3692426 Test Loss: 0.4556622 MAE Loss: 0.4397559\n",
      "lr = 0.0005000050\n",
      "Total time: 106.95236794948578 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-04 16:16:17,335] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 16:16:18,175] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 16:16:18,175] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 16:16:18,175] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 16:16:19,121] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 16:16:19,121] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 16:16:20,439] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 16:16:20,440] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 16:16:20,440] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 16:16:20,441] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 16:16:20,441] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 16:16:20,441] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 16:16:20,442] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 16:16:20,442] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 16:16:20,442] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 16:16:20,442] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 16:16:20,765] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 16:16:20,765] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-04 16:16:20,766] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.73 GB, percent = 16.1%\n",
      "[2024-05-04 16:16:20,895] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 16:16:20,895] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 16:16:20,895] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.73 GB, percent = 16.1%\n",
      "[2024-05-04 16:16:20,895] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 16:16:21,024] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 16:16:21,025] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-04 16:16:21,025] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.78 GB, percent = 16.1%\n",
      "[2024-05-04 16:16:21,026] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 16:16:21,026] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 16:16:21,026] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 16:16:21,026] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 16:16:21,026] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f32921e4fd0>\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 16:16:21,027] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 16:16:21,028] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:14,  7.74it/s]\titers: 100, epoch: 1 | loss: 0.6284837\n",
      "\tspeed: 0.1876s/iter; left time: 13915.7058s\n",
      "199it [00:27,  7.41it/s]\titers: 200, epoch: 1 | loss: 0.5352426\n",
      "\tspeed: 0.1343s/iter; left time: 9947.9736s\n",
      "299it [00:41,  7.67it/s]\titers: 300, epoch: 1 | loss: 0.4914316\n",
      "\tspeed: 0.1336s/iter; left time: 9880.1304s\n",
      "399it [00:54,  7.43it/s]\titers: 400, epoch: 1 | loss: 0.2820175\n",
      "\tspeed: 0.1337s/iter; left time: 9874.2349s\n",
      "499it [01:08,  7.34it/s]\titers: 500, epoch: 1 | loss: 0.2728907\n",
      "\tspeed: 0.1356s/iter; left time: 10000.4083s\n",
      "599it [01:21,  6.21it/s]\titers: 600, epoch: 1 | loss: 0.3732491\n",
      "\tspeed: 0.1360s/iter; left time: 10015.1694s\n",
      "699it [01:35,  7.25it/s]\titers: 700, epoch: 1 | loss: 0.4083984\n",
      "\tspeed: 0.1348s/iter; left time: 9917.8573s\n",
      "799it [01:48,  7.55it/s]\titers: 800, epoch: 1 | loss: 0.2888259\n",
      "\tspeed: 0.1361s/iter; left time: 9996.9018s\n",
      "899it [02:02,  6.72it/s]\titers: 900, epoch: 1 | loss: 0.4882275\n",
      "\tspeed: 0.1370s/iter; left time: 10048.0103s\n",
      "999it [02:15,  6.58it/s]\titers: 1000, epoch: 1 | loss: 0.4720700\n",
      "\tspeed: 0.1349s/iter; left time: 9880.6875s\n",
      "1099it [02:29,  7.26it/s]\titers: 1100, epoch: 1 | loss: 0.2710172\n",
      "\tspeed: 0.1366s/iter; left time: 9996.8565s\n",
      "1199it [02:43,  7.65it/s]\titers: 1200, epoch: 1 | loss: 0.3366533\n",
      "\tspeed: 0.1362s/iter; left time: 9948.7259s\n",
      "1299it [02:56,  7.18it/s]\titers: 1300, epoch: 1 | loss: 0.4391926\n",
      "\tspeed: 0.1335s/iter; left time: 9742.0886s\n",
      "1399it [03:09,  7.69it/s]\titers: 1400, epoch: 1 | loss: 0.2492006\n",
      "\tspeed: 0.1317s/iter; left time: 9596.5261s\n",
      "1499it [03:23,  7.59it/s]\titers: 1500, epoch: 1 | loss: 0.2428142\n",
      "\tspeed: 0.1356s/iter; left time: 9864.3843s\n",
      "1599it [03:36,  7.52it/s]\titers: 1600, epoch: 1 | loss: 0.4292324\n",
      "\tspeed: 0.1347s/iter; left time: 9790.6208s\n",
      "1699it [03:50,  7.53it/s]\titers: 1700, epoch: 1 | loss: 0.4312639\n",
      "\tspeed: 0.1338s/iter; left time: 9711.9058s\n",
      "1799it [04:03,  7.47it/s]\titers: 1800, epoch: 1 | loss: 0.6051976\n",
      "\tspeed: 0.1339s/iter; left time: 9703.7280s\n",
      "1899it [04:17,  7.68it/s]\titers: 1900, epoch: 1 | loss: 0.2817806\n",
      "\tspeed: 0.1366s/iter; left time: 9886.5703s\n",
      "1999it [04:30,  7.52it/s]\titers: 2000, epoch: 1 | loss: 0.3776010\n",
      "\tspeed: 0.1361s/iter; left time: 9834.5234s\n",
      "2099it [04:44,  6.98it/s]\titers: 2100, epoch: 1 | loss: 0.2727109\n",
      "\tspeed: 0.1354s/iter; left time: 9772.2686s\n",
      "2199it [04:58,  7.57it/s]\titers: 2200, epoch: 1 | loss: 0.4344987\n",
      "\tspeed: 0.1376s/iter; left time: 9912.8875s\n",
      "2299it [05:11,  7.70it/s]\titers: 2300, epoch: 1 | loss: 0.4113905\n",
      "\tspeed: 0.1360s/iter; left time: 9789.4647s\n",
      "2399it [05:24,  7.68it/s]\titers: 2400, epoch: 1 | loss: 0.2870833\n",
      "\tspeed: 0.1320s/iter; left time: 9482.6861s\n",
      "2499it [05:38,  7.67it/s]\titers: 2500, epoch: 1 | loss: 0.3584269\n",
      "\tspeed: 0.1306s/iter; left time: 9372.8803s\n",
      "2599it [05:51,  7.60it/s]\titers: 2600, epoch: 1 | loss: 0.2931449\n",
      "\tspeed: 0.1324s/iter; left time: 9486.9149s\n",
      "2699it [06:05,  7.69it/s]\titers: 2700, epoch: 1 | loss: 0.3084987\n",
      "\tspeed: 0.1373s/iter; left time: 9826.7383s\n",
      "2799it [06:18,  7.37it/s]\titers: 2800, epoch: 1 | loss: 0.3998558\n",
      "\tspeed: 0.1339s/iter; left time: 9565.4951s\n",
      "2899it [06:31,  7.62it/s]\titers: 2900, epoch: 1 | loss: 0.2582986\n",
      "\tspeed: 0.1308s/iter; left time: 9334.5554s\n",
      "2999it [06:45,  7.31it/s]\titers: 3000, epoch: 1 | loss: 0.3260675\n",
      "\tspeed: 0.1381s/iter; left time: 9838.7775s\n",
      "3099it [06:59,  7.34it/s]\titers: 3100, epoch: 1 | loss: 0.2262339\n",
      "\tspeed: 0.1382s/iter; left time: 9831.0693s\n",
      "3199it [07:12,  6.60it/s]\titers: 3200, epoch: 1 | loss: 0.2288827\n",
      "\tspeed: 0.1349s/iter; left time: 9585.7569s\n",
      "3299it [07:25,  7.53it/s]\titers: 3300, epoch: 1 | loss: 0.4653212\n",
      "\tspeed: 0.1331s/iter; left time: 9443.4561s\n",
      "3399it [07:39,  7.60it/s]\titers: 3400, epoch: 1 | loss: 0.5665098\n",
      "\tspeed: 0.1357s/iter; left time: 9614.1041s\n",
      "3499it [07:53,  7.68it/s]\titers: 3500, epoch: 1 | loss: 0.3672006\n",
      "\tspeed: 0.1385s/iter; left time: 9801.5900s\n",
      "3599it [08:06,  7.45it/s]\titers: 3600, epoch: 1 | loss: 0.2720945\n",
      "\tspeed: 0.1342s/iter; left time: 9480.4788s\n",
      "3699it [08:19,  7.27it/s]\titers: 3700, epoch: 1 | loss: 0.2639223\n",
      "\tspeed: 0.1324s/iter; left time: 9339.1803s\n",
      "3713it [08:22,  7.40it/s]\n",
      "Epoch: 1 cost time: 502.0084307193756\n",
      "810it [00:52, 15.44it/s]\n",
      "807it [00:52, 15.45it/s]\n",
      "Epoch: 1 | Train Loss: 0.3539966 Vali Loss: 0.4033258 Test Loss: 0.5074162 MAE Loss: 0.4763052\n",
      "lr = 0.0009938442\n",
      "99it [00:13,  7.82it/s]\titers: 100, epoch: 2 | loss: 0.3767157\n",
      "\tspeed: 1.2354s/iter; left time: 87031.8176s\n",
      "199it [00:26,  7.85it/s]\titers: 200, epoch: 2 | loss: 0.4751770\n",
      "\tspeed: 0.1316s/iter; left time: 9256.6548s\n",
      "299it [00:39,  7.73it/s]\titers: 300, epoch: 2 | loss: 0.4254152\n",
      "\tspeed: 0.1290s/iter; left time: 9064.9641s\n",
      "399it [00:52,  7.67it/s]\titers: 400, epoch: 2 | loss: 0.6282481\n",
      "\tspeed: 0.1332s/iter; left time: 9342.7318s\n",
      "499it [01:05,  7.97it/s]\titers: 500, epoch: 2 | loss: 0.2911870\n",
      "\tspeed: 0.1269s/iter; left time: 8888.6148s\n",
      "599it [01:18,  7.58it/s]\titers: 600, epoch: 2 | loss: 0.4708160\n",
      "\tspeed: 0.1299s/iter; left time: 9087.4770s\n",
      "699it [01:31,  7.83it/s]\titers: 700, epoch: 2 | loss: 0.3043123\n",
      "\tspeed: 0.1324s/iter; left time: 9249.2041s\n",
      "799it [01:45,  7.93it/s]\titers: 800, epoch: 2 | loss: 0.4478506\n",
      "\tspeed: 0.1348s/iter; left time: 9404.4022s\n",
      "899it [01:57,  7.97it/s]\titers: 900, epoch: 2 | loss: 0.3069436\n",
      "\tspeed: 0.1269s/iter; left time: 8840.5351s\n",
      "999it [02:11,  7.77it/s]\titers: 1000, epoch: 2 | loss: 0.3549146\n",
      "\tspeed: 0.1310s/iter; left time: 9113.6516s\n",
      "1099it [02:24,  7.71it/s]\titers: 1100, epoch: 2 | loss: 0.3372775\n",
      "\tspeed: 0.1324s/iter; left time: 9192.5102s\n",
      "1199it [02:37,  6.40it/s]\titers: 1200, epoch: 2 | loss: 0.5666034\n",
      "\tspeed: 0.1324s/iter; left time: 9184.4587s\n",
      "1299it [02:50,  7.79it/s]\titers: 1300, epoch: 2 | loss: 0.2821845\n",
      "\tspeed: 0.1305s/iter; left time: 9039.8004s\n",
      "1399it [03:03,  7.75it/s]\titers: 1400, epoch: 2 | loss: 0.2186523\n",
      "\tspeed: 0.1331s/iter; left time: 9203.5185s\n",
      "1499it [03:17,  7.75it/s]\titers: 1500, epoch: 2 | loss: 0.6387949\n",
      "\tspeed: 0.1340s/iter; left time: 9252.3968s\n",
      "1599it [03:30,  7.17it/s]\titers: 1600, epoch: 2 | loss: 0.3126513\n",
      "\tspeed: 0.1293s/iter; left time: 8916.6711s\n",
      "1699it [03:43,  7.99it/s]\titers: 1700, epoch: 2 | loss: 0.4256271\n",
      "\tspeed: 0.1298s/iter; left time: 8938.4403s\n",
      "1799it [03:56,  7.81it/s]\titers: 1800, epoch: 2 | loss: 0.2084496\n",
      "\tspeed: 0.1307s/iter; left time: 8984.3558s\n",
      "1899it [04:09,  7.77it/s]\titers: 1900, epoch: 2 | loss: 0.3614881\n",
      "\tspeed: 0.1323s/iter; left time: 9082.5856s\n",
      "1999it [04:22,  7.99it/s]\titers: 2000, epoch: 2 | loss: 0.2827127\n",
      "\tspeed: 0.1271s/iter; left time: 8709.2345s\n",
      "2099it [04:35,  7.87it/s]\titers: 2100, epoch: 2 | loss: 0.4691244\n",
      "\tspeed: 0.1321s/iter; left time: 9041.1273s\n",
      "2199it [04:48,  8.05it/s]\titers: 2200, epoch: 2 | loss: 0.4235355\n",
      "\tspeed: 0.1309s/iter; left time: 8948.4373s\n",
      "2299it [05:01,  6.64it/s]\titers: 2300, epoch: 2 | loss: 0.3109887\n",
      "\tspeed: 0.1309s/iter; left time: 8931.5205s\n",
      "2399it [05:14,  7.88it/s]\titers: 2400, epoch: 2 | loss: 0.5009397\n",
      "\tspeed: 0.1284s/iter; left time: 8746.8135s\n",
      "2499it [05:27,  7.90it/s]\titers: 2500, epoch: 2 | loss: 0.2803027\n",
      "\tspeed: 0.1278s/iter; left time: 8698.1500s\n",
      "2599it [05:39,  7.96it/s]\titers: 2600, epoch: 2 | loss: 0.3870358\n",
      "\tspeed: 0.1268s/iter; left time: 8615.2595s\n",
      "2699it [05:52,  7.92it/s]\titers: 2700, epoch: 2 | loss: 0.2980010\n",
      "\tspeed: 0.1270s/iter; left time: 8617.2763s\n",
      "2799it [06:05,  8.03it/s]\titers: 2800, epoch: 2 | loss: 0.4731279\n",
      "\tspeed: 0.1276s/iter; left time: 8644.1447s\n",
      "2899it [06:17,  7.88it/s]\titers: 2900, epoch: 2 | loss: 0.3358819\n",
      "\tspeed: 0.1252s/iter; left time: 8467.8203s\n",
      "2999it [06:30,  7.93it/s]\titers: 3000, epoch: 2 | loss: 0.2284171\n",
      "\tspeed: 0.1288s/iter; left time: 8697.1577s\n",
      "3099it [06:43,  7.96it/s]\titers: 3100, epoch: 2 | loss: 0.3610570\n",
      "\tspeed: 0.1283s/iter; left time: 8652.1581s\n",
      "3199it [06:56,  7.57it/s]\titers: 3200, epoch: 2 | loss: 0.3276180\n",
      "\tspeed: 0.1316s/iter; left time: 8862.7783s\n",
      "3299it [07:09,  7.66it/s]\titers: 3300, epoch: 2 | loss: 0.2031095\n",
      "\tspeed: 0.1294s/iter; left time: 8703.4038s\n",
      "3399it [07:22,  7.71it/s]\titers: 3400, epoch: 2 | loss: 0.2928004\n",
      "\tspeed: 0.1336s/iter; left time: 8969.3977s\n",
      "3499it [07:36,  7.85it/s]\titers: 3500, epoch: 2 | loss: 0.3029553\n",
      "\tspeed: 0.1327s/iter; left time: 8899.8084s\n",
      "3599it [07:49,  7.24it/s]\titers: 3600, epoch: 2 | loss: 0.2909013\n",
      "\tspeed: 0.1296s/iter; left time: 8676.4067s\n",
      "3699it [08:02,  7.70it/s]\titers: 3700, epoch: 2 | loss: 0.1638605\n",
      "\tspeed: 0.1294s/iter; left time: 8650.1459s\n",
      "3713it [08:04,  7.67it/s]\n",
      "Epoch: 2 cost time: 484.02700996398926\n",
      "810it [00:48, 16.64it/s]\n",
      "807it [00:48, 16.56it/s]\n",
      "Epoch: 2 | Train Loss: 0.3426453 Vali Loss: 0.4419988 Test Loss: 0.5359442 MAE Loss: 0.4935539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009755285\n",
      "99it [00:18,  6.85it/s]\titers: 100, epoch: 3 | loss: 0.5224727\n",
      "\tspeed: 1.1759s/iter; left time: 78471.1245s\n",
      "199it [00:35,  7.05it/s]\titers: 200, epoch: 3 | loss: 0.2085290\n",
      "\tspeed: 0.1765s/iter; left time: 11760.4065s\n",
      "299it [00:51,  7.92it/s]\titers: 300, epoch: 3 | loss: 0.3238280\n",
      "\tspeed: 0.1599s/iter; left time: 10638.3345s\n",
      "399it [01:09,  3.34it/s]\titers: 400, epoch: 3 | loss: 0.6686686\n",
      "\tspeed: 0.1750s/iter; left time: 11628.7958s\n",
      "499it [01:25,  7.93it/s]\titers: 500, epoch: 3 | loss: 0.3294648\n",
      "\tspeed: 0.1660s/iter; left time: 11010.4714s\n",
      "599it [01:43,  7.66it/s]\titers: 600, epoch: 3 | loss: 0.3629559\n",
      "\tspeed: 0.1771s/iter; left time: 11729.1922s\n",
      "699it [02:01,  5.33it/s]\titers: 700, epoch: 3 | loss: 0.3475680\n",
      "\tspeed: 0.1786s/iter; left time: 11813.5674s\n",
      "799it [02:17,  6.82it/s]\titers: 800, epoch: 3 | loss: 1.0025202\n",
      "\tspeed: 0.1620s/iter; left time: 10695.7079s\n",
      "899it [02:33,  7.83it/s]\titers: 900, epoch: 3 | loss: 0.5751390\n",
      "\tspeed: 0.1618s/iter; left time: 10669.4735s\n",
      "999it [02:51,  7.69it/s]\titers: 1000, epoch: 3 | loss: 0.3736329\n",
      "\tspeed: 0.1779s/iter; left time: 11711.1436s\n",
      "1099it [03:09,  6.92it/s]\titers: 1100, epoch: 3 | loss: 0.2845280\n",
      "\tspeed: 0.1777s/iter; left time: 11678.9447s\n",
      "1199it [03:25,  7.81it/s]\titers: 1200, epoch: 3 | loss: 0.2719593\n",
      "\tspeed: 0.1610s/iter; left time: 10567.4903s\n",
      "1299it [03:41,  7.76it/s]\titers: 1300, epoch: 3 | loss: 0.2924204\n",
      "\tspeed: 0.1615s/iter; left time: 10585.9738s\n",
      "1399it [03:59,  3.18it/s]\titers: 1400, epoch: 3 | loss: 0.4612133\n",
      "\tspeed: 0.1780s/iter; left time: 11646.2157s\n",
      "1499it [04:17,  4.33it/s]\titers: 1500, epoch: 3 | loss: 0.1913575\n",
      "\tspeed: 0.1789s/iter; left time: 11685.1920s\n",
      "1599it [04:33,  7.88it/s]\titers: 1600, epoch: 3 | loss: 0.7234213\n",
      "\tspeed: 0.1601s/iter; left time: 10442.6105s\n",
      "1699it [04:49,  7.98it/s]\titers: 1700, epoch: 3 | loss: 0.4735206\n",
      "\tspeed: 0.1597s/iter; left time: 10401.0815s\n",
      "1799it [05:06,  3.34it/s]\titers: 1800, epoch: 3 | loss: 0.2808116\n",
      "\tspeed: 0.1726s/iter; left time: 11223.3976s\n",
      "1899it [05:23,  5.19it/s]\titers: 1900, epoch: 3 | loss: 0.3126731\n",
      "\tspeed: 0.1665s/iter; left time: 10811.8993s\n",
      "1999it [05:40,  7.85it/s]\titers: 2000, epoch: 3 | loss: 0.2936290\n",
      "\tspeed: 0.1723s/iter; left time: 11169.8051s\n",
      "2099it [05:56,  7.98it/s]\titers: 2100, epoch: 3 | loss: 0.3481406\n",
      "\tspeed: 0.1601s/iter; left time: 10361.0314s\n",
      "2199it [06:12,  7.02it/s]\titers: 2200, epoch: 3 | loss: 0.2055496\n",
      "\tspeed: 0.1620s/iter; left time: 10471.4823s\n",
      "2299it [06:29,  3.39it/s]\titers: 2300, epoch: 3 | loss: 0.2287608\n",
      "\tspeed: 0.1691s/iter; left time: 10914.8780s\n",
      "2399it [06:46,  7.65it/s]\titers: 2400, epoch: 3 | loss: 0.2860211\n",
      "\tspeed: 0.1638s/iter; left time: 10555.2478s\n",
      "2499it [07:03,  4.61it/s]\titers: 2500, epoch: 3 | loss: 0.3091559\n",
      "\tspeed: 0.1795s/iter; left time: 11547.5902s\n",
      "2599it [07:19,  7.73it/s]\titers: 2600, epoch: 3 | loss: 0.3608786\n",
      "\tspeed: 0.1592s/iter; left time: 10224.3207s\n",
      "2699it [07:35,  7.99it/s]\titers: 2700, epoch: 3 | loss: 0.2663588\n",
      "\tspeed: 0.1596s/iter; left time: 10237.0679s\n",
      "2799it [07:53,  3.22it/s]\titers: 2800, epoch: 3 | loss: 0.3184358\n",
      "\tspeed: 0.1756s/iter; left time: 11244.9298s\n",
      "2899it [08:09,  7.89it/s]\titers: 2900, epoch: 3 | loss: 0.2107174\n",
      "\tspeed: 0.1598s/iter; left time: 10217.5892s\n",
      "2999it [08:26,  3.25it/s]\titers: 3000, epoch: 3 | loss: 0.3653926\n",
      "\tspeed: 0.1737s/iter; left time: 11087.9408s\n",
      "3099it [08:43,  7.78it/s]\titers: 3100, epoch: 3 | loss: 0.3442631\n",
      "\tspeed: 0.1626s/iter; left time: 10365.8649s\n",
      "3199it [09:00,  3.57it/s]\titers: 3200, epoch: 3 | loss: 0.2078412\n",
      "\tspeed: 0.1714s/iter; left time: 10904.0258s\n",
      "3299it [09:16,  8.00it/s]\titers: 3300, epoch: 3 | loss: 0.2802461\n",
      "\tspeed: 0.1643s/iter; left time: 10441.6303s\n",
      "3399it [09:32,  7.93it/s]\titers: 3400, epoch: 3 | loss: 0.3181832\n",
      "\tspeed: 0.1590s/iter; left time: 10087.2003s\n",
      "3499it [09:48,  7.93it/s]\titers: 3500, epoch: 3 | loss: 0.3222934\n",
      "\tspeed: 0.1590s/iter; left time: 10067.3045s\n",
      "3599it [10:06,  7.14it/s]\titers: 3600, epoch: 3 | loss: 0.1407734\n",
      "\tspeed: 0.1765s/iter; left time: 11162.1196s\n",
      "3699it [10:22,  4.85it/s]\titers: 3700, epoch: 3 | loss: 0.6066621\n",
      "\tspeed: 0.1642s/iter; left time: 10364.7122s\n",
      "3713it [10:25,  5.94it/s]\n",
      "Epoch: 3 cost time: 625.6101150512695\n",
      "810it [01:02, 12.94it/s]\n",
      "807it [01:03, 12.79it/s]\n",
      "Epoch: 3 | Train Loss: 0.3307373 Vali Loss: 0.4145984 Test Loss: 0.5158148 MAE Loss: 0.4856396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0009455038\n",
      "99it [00:16,  7.91it/s]\titers: 100, epoch: 4 | loss: 0.3085895\n",
      "\tspeed: 1.4526s/iter; left time: 91542.8712s\n",
      "199it [00:34,  3.17it/s]\titers: 200, epoch: 4 | loss: 0.3190602\n",
      "\tspeed: 0.1768s/iter; left time: 11125.0141s\n",
      "299it [00:50,  7.72it/s]\titers: 300, epoch: 4 | loss: 0.3972897\n",
      "\tspeed: 0.1613s/iter; left time: 10133.4762s\n",
      "399it [01:06,  7.72it/s]\titers: 400, epoch: 4 | loss: 0.6874273\n",
      "\tspeed: 0.1601s/iter; left time: 10040.4261s\n",
      "499it [01:22,  7.80it/s]\titers: 500, epoch: 4 | loss: 0.1665531\n",
      "\tspeed: 0.1605s/iter; left time: 10051.9121s\n",
      "599it [01:39,  7.48it/s]\titers: 600, epoch: 4 | loss: 0.3449117\n",
      "\tspeed: 0.1771s/iter; left time: 11070.9815s\n",
      "699it [01:56,  3.78it/s]\titers: 700, epoch: 4 | loss: 0.4637513\n",
      "\tspeed: 0.1681s/iter; left time: 10493.0736s\n",
      "799it [02:13,  3.35it/s]\titers: 800, epoch: 4 | loss: 0.3791815\n",
      "\tspeed: 0.1653s/iter; left time: 10300.8781s\n",
      "899it [02:29,  7.98it/s]\titers: 900, epoch: 4 | loss: 0.3098664\n",
      "\tspeed: 0.1629s/iter; left time: 10133.1336s\n",
      "999it [02:45,  7.82it/s]\titers: 1000, epoch: 4 | loss: 0.3481237\n",
      "\tspeed: 0.1599s/iter; left time: 9935.8547s\n",
      "1099it [03:03,  3.17it/s]\titers: 1100, epoch: 4 | loss: 0.2980776\n",
      "\tspeed: 0.1763s/iter; left time: 10936.7920s\n",
      "1199it [03:19,  7.76it/s]\titers: 1200, epoch: 4 | loss: 0.4521514\n",
      "\tspeed: 0.1594s/iter; left time: 9867.7863s\n",
      "1299it [03:34,  8.06it/s]\titers: 1300, epoch: 4 | loss: 0.4708442\n",
      "\tspeed: 0.1589s/iter; left time: 9820.7229s\n",
      "1399it [03:50,  8.02it/s]\titers: 1400, epoch: 4 | loss: 0.3791539\n",
      "\tspeed: 0.1598s/iter; left time: 9861.9848s\n",
      "1499it [04:08,  7.62it/s]\titers: 1500, epoch: 4 | loss: 0.3401311\n",
      "\tspeed: 0.1767s/iter; left time: 10888.9815s\n",
      "1599it [04:24,  8.07it/s]\titers: 1600, epoch: 4 | loss: 0.3305887\n",
      "\tspeed: 0.1593s/iter; left time: 9801.7008s\n",
      "1699it [04:42,  3.20it/s]\titers: 1700, epoch: 4 | loss: 0.3038333\n",
      "\tspeed: 0.1786s/iter; left time: 10970.0495s\n",
      "1799it [04:58,  5.73it/s]\titers: 1800, epoch: 4 | loss: 0.2486874\n",
      "\tspeed: 0.1621s/iter; left time: 9942.0597s\n",
      "1899it [05:14,  7.85it/s]\titers: 1900, epoch: 4 | loss: 0.4243304\n",
      "\tspeed: 0.1609s/iter; left time: 9847.7676s\n",
      "1999it [05:32,  7.81it/s]\titers: 2000, epoch: 4 | loss: 0.2149484\n",
      "\tspeed: 0.1775s/iter; left time: 10849.3953s\n",
      "2099it [05:48,  7.87it/s]\titers: 2100, epoch: 4 | loss: 0.3770129\n",
      "\tspeed: 0.1600s/iter; left time: 9766.5620s\n",
      "2199it [06:04,  7.90it/s]\titers: 2200, epoch: 4 | loss: 0.1947407\n",
      "\tspeed: 0.1602s/iter; left time: 9762.2845s\n",
      "2299it [06:22,  6.41it/s]\titers: 2300, epoch: 4 | loss: 0.2886204\n",
      "\tspeed: 0.1775s/iter; left time: 10796.5014s\n",
      "2399it [06:38,  7.94it/s]\titers: 2400, epoch: 4 | loss: 0.2057156\n",
      "\tspeed: 0.1604s/iter; left time: 9742.1178s\n",
      "2499it [06:55,  3.39it/s]\titers: 2500, epoch: 4 | loss: 0.2986284\n",
      "\tspeed: 0.1718s/iter; left time: 10417.7064s\n",
      "2599it [07:11,  7.65it/s]\titers: 2600, epoch: 4 | loss: 0.3845401\n",
      "\tspeed: 0.1645s/iter; left time: 9954.8857s\n",
      "2699it [07:27,  7.79it/s]\titers: 2700, epoch: 4 | loss: 0.2046233\n",
      "\tspeed: 0.1602s/iter; left time: 9678.0164s\n",
      "2799it [07:43,  7.91it/s]\titers: 2800, epoch: 4 | loss: 0.5872942\n",
      "\tspeed: 0.1598s/iter; left time: 9640.7367s\n",
      "2899it [08:00,  5.27it/s]\titers: 2900, epoch: 4 | loss: 0.2787766\n",
      "\tspeed: 0.1629s/iter; left time: 9812.0477s\n",
      "2999it [08:17,  7.69it/s]\titers: 3000, epoch: 4 | loss: 0.3276455\n",
      "\tspeed: 0.1759s/iter; left time: 10577.9545s\n",
      "3099it [08:34,  7.84it/s]\titers: 3100, epoch: 4 | loss: 0.2882536\n",
      "\tspeed: 0.1627s/iter; left time: 9765.2681s\n",
      "3199it [08:50,  7.74it/s]\titers: 3200, epoch: 4 | loss: 0.3190152\n",
      "\tspeed: 0.1634s/iter; left time: 9792.2205s\n",
      "3299it [09:08,  7.74it/s]\titers: 3300, epoch: 4 | loss: 0.2534955\n",
      "\tspeed: 0.1777s/iter; left time: 10631.2351s\n",
      "3399it [09:24,  7.90it/s]\titers: 3400, epoch: 4 | loss: 0.2013041\n",
      "\tspeed: 0.1597s/iter; left time: 9538.1898s\n",
      "3499it [09:41,  4.20it/s]\titers: 3500, epoch: 4 | loss: 0.3635070\n",
      "\tspeed: 0.1763s/iter; left time: 10510.9046s\n",
      "3599it [09:57,  7.55it/s]\titers: 3600, epoch: 4 | loss: 0.3619284\n",
      "\tspeed: 0.1605s/iter; left time: 9550.5720s\n",
      "3699it [10:13,  7.92it/s]\titers: 3700, epoch: 4 | loss: 0.1722519\n",
      "\tspeed: 0.1598s/iter; left time: 9493.9337s\n",
      "3713it [10:16,  6.02it/s]\n",
      "Epoch: 4 cost time: 616.487078666687\n",
      "810it [01:02, 12.94it/s]\n",
      "807it [01:01, 13.15it/s]\n",
      "Epoch: 4 | Train Loss: 0.3298674 Vali Loss: 0.3902555 Test Loss: 0.4786931 MAE Loss: 0.4599794\n",
      "lr = 0.0009045095\n",
      "99it [00:17,  3.42it/s]\titers: 100, epoch: 5 | loss: 0.2062469\n",
      "\tspeed: 1.4749s/iter; left time: 87472.6921s\n",
      "199it [00:33,  7.95it/s]\titers: 200, epoch: 5 | loss: 0.2092327\n",
      "\tspeed: 0.1648s/iter; left time: 9760.0556s\n",
      "299it [00:51,  5.12it/s]\titers: 300, epoch: 5 | loss: 0.3449670\n",
      "\tspeed: 0.1766s/iter; left time: 10436.2987s\n",
      "399it [01:07,  7.97it/s]\titers: 400, epoch: 5 | loss: 0.3249771\n",
      "\tspeed: 0.1598s/iter; left time: 9428.9798s\n",
      "499it [01:23,  7.87it/s]\titers: 500, epoch: 5 | loss: 0.1315668\n",
      "\tspeed: 0.1597s/iter; left time: 9408.0825s\n",
      "599it [01:39,  7.88it/s]\titers: 600, epoch: 5 | loss: 0.2624253\n",
      "\tspeed: 0.1591s/iter; left time: 9359.2569s\n",
      "699it [01:56,  3.23it/s]\titers: 700, epoch: 5 | loss: 0.3038742\n",
      "\tspeed: 0.1756s/iter; left time: 10309.6072s\n",
      "799it [02:12,  7.81it/s]\titers: 800, epoch: 5 | loss: 0.3684295\n",
      "\tspeed: 0.1607s/iter; left time: 9419.5264s\n",
      "899it [02:28,  7.97it/s]\titers: 900, epoch: 5 | loss: 0.4144670\n",
      "\tspeed: 0.1592s/iter; left time: 9317.5061s\n",
      "999it [02:44,  7.90it/s]\titers: 1000, epoch: 5 | loss: 0.3208720\n",
      "\tspeed: 0.1600s/iter; left time: 9346.3959s\n",
      "1099it [03:02,  6.88it/s]\titers: 1100, epoch: 5 | loss: 0.3457694\n",
      "\tspeed: 0.1757s/iter; left time: 10247.4172s\n",
      "1199it [03:18,  7.96it/s]\titers: 1200, epoch: 5 | loss: 0.3169947\n",
      "\tspeed: 0.1603s/iter; left time: 9330.1545s\n",
      "1299it [03:35,  3.16it/s]\titers: 1300, epoch: 5 | loss: 0.1993393\n",
      "\tspeed: 0.1761s/iter; left time: 10233.5726s\n",
      "1399it [03:51,  6.70it/s]\titers: 1400, epoch: 5 | loss: 0.1898936\n",
      "\tspeed: 0.1595s/iter; left time: 9253.9140s\n",
      "1499it [04:07,  4.98it/s]\titers: 1500, epoch: 5 | loss: 0.1944701\n",
      "\tspeed: 0.1595s/iter; left time: 9234.1909s\n",
      "1599it [04:23,  8.06it/s]\titers: 1600, epoch: 5 | loss: 0.2967289\n",
      "\tspeed: 0.1588s/iter; left time: 9180.1303s\n",
      "1699it [04:40,  4.03it/s]\titers: 1700, epoch: 5 | loss: 0.2972065\n",
      "\tspeed: 0.1657s/iter; left time: 9563.4352s\n",
      "1799it [04:57,  8.00it/s]\titers: 1800, epoch: 5 | loss: 0.2943450\n",
      "\tspeed: 0.1695s/iter; left time: 9764.2437s\n",
      "1899it [05:13,  7.83it/s]\titers: 1900, epoch: 5 | loss: 0.3562803\n",
      "\tspeed: 0.1603s/iter; left time: 9219.3087s\n",
      "1999it [05:29,  7.87it/s]\titers: 2000, epoch: 5 | loss: 0.2711124\n",
      "\tspeed: 0.1599s/iter; left time: 9179.1367s\n",
      "2099it [05:46,  5.51it/s]\titers: 2100, epoch: 5 | loss: 0.3655235\n",
      "\tspeed: 0.1759s/iter; left time: 10078.7581s\n",
      "2199it [06:02,  7.33it/s]\titers: 2200, epoch: 5 | loss: 0.2359903\n",
      "\tspeed: 0.1601s/iter; left time: 9159.1422s\n",
      "2299it [06:18,  7.84it/s]\titers: 2300, epoch: 5 | loss: 0.5608481\n",
      "\tspeed: 0.1595s/iter; left time: 9111.2330s\n",
      "2399it [06:34,  7.94it/s]\titers: 2400, epoch: 5 | loss: 0.3043300\n",
      "\tspeed: 0.1596s/iter; left time: 9097.9746s\n",
      "2499it [06:51,  3.29it/s]\titers: 2500, epoch: 5 | loss: 0.3357579\n",
      "\tspeed: 0.1727s/iter; left time: 9830.3465s\n",
      "2599it [07:08,  7.88it/s]\titers: 2600, epoch: 5 | loss: 0.4537764\n",
      "\tspeed: 0.1632s/iter; left time: 9269.7316s\n",
      "2699it [07:26,  4.68it/s]\titers: 2700, epoch: 5 | loss: 0.2674872\n",
      "\tspeed: 0.1771s/iter; left time: 10042.0639s\n",
      "2799it [07:42,  7.73it/s]\titers: 2800, epoch: 5 | loss: 0.2827784\n",
      "\tspeed: 0.1598s/iter; left time: 9046.1901s\n",
      "2899it [07:58,  7.90it/s]\titers: 2900, epoch: 5 | loss: 0.3093247\n",
      "\tspeed: 0.1595s/iter; left time: 9015.0581s\n",
      "2999it [08:13,  7.89it/s]\titers: 3000, epoch: 5 | loss: 0.3517567\n",
      "\tspeed: 0.1593s/iter; left time: 8987.5907s\n",
      "3099it [08:31,  7.00it/s]\titers: 3100, epoch: 5 | loss: 0.3229257\n",
      "\tspeed: 0.1769s/iter; left time: 9959.9333s\n",
      "3199it [08:47,  7.90it/s]\titers: 3200, epoch: 5 | loss: 0.3408239\n",
      "\tspeed: 0.1599s/iter; left time: 8987.6888s\n",
      "3299it [09:03,  8.00it/s]\titers: 3300, epoch: 5 | loss: 0.3052003\n",
      "\tspeed: 0.1610s/iter; left time: 9035.2123s\n",
      "3399it [09:19,  7.85it/s]\titers: 3400, epoch: 5 | loss: 0.3453138\n",
      "\tspeed: 0.1598s/iter; left time: 8948.6346s\n",
      "3499it [09:37,  7.81it/s]\titers: 3500, epoch: 5 | loss: 0.4115940\n",
      "\tspeed: 0.1769s/iter; left time: 9892.8208s\n",
      "3599it [09:53,  7.93it/s]\titers: 3600, epoch: 5 | loss: 0.4233800\n",
      "\tspeed: 0.1590s/iter; left time: 8874.2877s\n",
      "3699it [10:10,  7.32it/s]\titers: 3700, epoch: 5 | loss: 0.2183217\n",
      "\tspeed: 0.1763s/iter; left time: 9823.1006s\n",
      "3713it [10:12,  6.06it/s]\n",
      "Epoch: 5 cost time: 612.7998220920563\n",
      "810it [01:01, 13.22it/s]\n",
      "807it [01:01, 13.12it/s]\n",
      "Epoch: 5 | Train Loss: 0.3223494 Vali Loss: 0.3899679 Test Loss: 0.5002480 MAE Loss: 0.4720434\n",
      "lr = 0.0008535549\n",
      "99it [00:16,  3.71it/s]\titers: 100, epoch: 6 | loss: 0.3981171\n",
      "\tspeed: 1.4497s/iter; left time: 80598.3957s\n",
      "199it [00:33,  3.71it/s]\titers: 200, epoch: 6 | loss: 0.2415454\n",
      "\tspeed: 0.1689s/iter; left time: 9373.7112s\n",
      "299it [00:49,  6.22it/s]\titers: 300, epoch: 6 | loss: 0.4251336\n",
      "\tspeed: 0.1597s/iter; left time: 8845.8571s\n",
      "399it [01:05,  7.46it/s]\titers: 400, epoch: 6 | loss: 0.2379706\n",
      "\tspeed: 0.1607s/iter; left time: 8884.1520s\n",
      "499it [01:22,  3.40it/s]\titers: 500, epoch: 6 | loss: 0.2679409\n",
      "\tspeed: 0.1705s/iter; left time: 9411.8526s\n",
      "599it [01:39,  7.46it/s]\titers: 600, epoch: 6 | loss: 0.4484220\n",
      "\tspeed: 0.1650s/iter; left time: 9089.1034s\n",
      "699it [01:55,  8.04it/s]\titers: 700, epoch: 6 | loss: 0.4534326\n",
      "\tspeed: 0.1594s/iter; left time: 8765.9907s\n",
      "799it [02:11,  7.86it/s]\titers: 800, epoch: 6 | loss: 0.4298534\n",
      "\tspeed: 0.1590s/iter; left time: 8728.9859s\n",
      "899it [02:29,  7.94it/s]\titers: 900, epoch: 6 | loss: 0.4534819\n",
      "\tspeed: 0.1766s/iter; left time: 9674.5915s\n",
      "999it [02:45,  3.97it/s]\titers: 1000, epoch: 6 | loss: 0.2164369\n",
      "\tspeed: 0.1676s/iter; left time: 9167.4563s\n",
      "1099it [03:02,  7.15it/s]\titers: 1100, epoch: 6 | loss: 0.2568227\n",
      "\tspeed: 0.1704s/iter; left time: 9302.2156s\n",
      "1199it [03:18,  7.84it/s]\titers: 1200, epoch: 6 | loss: 0.3906294\n",
      "\tspeed: 0.1595s/iter; left time: 8691.4124s\n",
      "1299it [03:34,  7.94it/s]\titers: 1300, epoch: 6 | loss: 0.3052442\n",
      "\tspeed: 0.1596s/iter; left time: 8682.9470s\n",
      "1399it [03:52,  7.81it/s]\titers: 1400, epoch: 6 | loss: 0.2060187\n",
      "\tspeed: 0.1770s/iter; left time: 9610.3462s\n",
      "1499it [04:08,  7.95it/s]\titers: 1500, epoch: 6 | loss: 0.2281263\n",
      "\tspeed: 0.1596s/iter; left time: 8648.0252s\n",
      "1599it [04:24,  5.21it/s]\titers: 1600, epoch: 6 | loss: 0.1834518\n",
      "\tspeed: 0.1631s/iter; left time: 8823.0301s\n",
      "1699it [04:41,  3.43it/s]\titers: 1700, epoch: 6 | loss: 0.4229937\n",
      "\tspeed: 0.1672s/iter; left time: 9028.4465s\n",
      "1799it [04:58,  3.46it/s]\titers: 1800, epoch: 6 | loss: 0.3029844\n",
      "\tspeed: 0.1762s/iter; left time: 9493.9423s\n",
      "1899it [05:15,  7.02it/s]\titers: 1900, epoch: 6 | loss: 0.3882581\n",
      "\tspeed: 0.1659s/iter; left time: 8925.1278s\n",
      "1999it [05:31,  8.04it/s]\titers: 2000, epoch: 6 | loss: 0.2055421\n",
      "\tspeed: 0.1603s/iter; left time: 8606.3734s\n",
      "2099it [05:47,  8.05it/s]\titers: 2100, epoch: 6 | loss: 0.3976897\n",
      "\tspeed: 0.1599s/iter; left time: 8571.7885s\n",
      "2199it [06:05,  6.58it/s]\titers: 2200, epoch: 6 | loss: 0.1607098\n",
      "\tspeed: 0.1755s/iter; left time: 9389.6446s\n",
      "2299it [06:21,  3.93it/s]\titers: 2300, epoch: 6 | loss: 0.2873370\n",
      "\tspeed: 0.1665s/iter; left time: 8889.4087s\n",
      "2399it [06:38,  7.86it/s]\titers: 2400, epoch: 6 | loss: 0.2190129\n",
      "\tspeed: 0.1689s/iter; left time: 9000.2203s\n",
      "2499it [06:54,  7.87it/s]\titers: 2500, epoch: 6 | loss: 0.5059695\n",
      "\tspeed: 0.1598s/iter; left time: 8502.0240s\n",
      "2599it [07:11,  3.47it/s]\titers: 2600, epoch: 6 | loss: 0.2571782\n",
      "\tspeed: 0.1706s/iter; left time: 9059.8871s\n",
      "2699it [07:29,  3.21it/s]\titers: 2700, epoch: 6 | loss: 0.3782385\n",
      "\tspeed: 0.1794s/iter; left time: 9504.9728s\n",
      "2799it [07:45,  7.74it/s]\titers: 2800, epoch: 6 | loss: 0.4393087\n",
      "\tspeed: 0.1617s/iter; left time: 8554.1814s\n",
      "2899it [08:01,  7.91it/s]\titers: 2900, epoch: 6 | loss: 0.3307942\n",
      "\tspeed: 0.1598s/iter; left time: 8436.1197s\n",
      "2999it [08:17,  7.96it/s]\titers: 3000, epoch: 6 | loss: 0.3004380\n",
      "\tspeed: 0.1605s/iter; left time: 8455.9151s\n",
      "3099it [08:36,  3.60it/s]\titers: 3100, epoch: 6 | loss: 0.3270711\n",
      "\tspeed: 0.1843s/iter; left time: 9692.2653s\n",
      "3199it [08:51,  7.86it/s]\titers: 3200, epoch: 6 | loss: 0.2833447\n",
      "\tspeed: 0.1503s/iter; left time: 7889.2977s\n",
      "3299it [09:03,  8.05it/s]\titers: 3300, epoch: 6 | loss: 0.1918054\n",
      "\tspeed: 0.1257s/iter; left time: 6586.9386s\n",
      "3399it [09:16,  7.82it/s]\titers: 3400, epoch: 6 | loss: 0.3671283\n",
      "\tspeed: 0.1277s/iter; left time: 6678.1502s\n",
      "3499it [09:29,  7.34it/s]\titers: 3500, epoch: 6 | loss: 0.1911821\n",
      "\tspeed: 0.1295s/iter; left time: 6760.8940s\n",
      "3599it [09:42,  7.74it/s]\titers: 3600, epoch: 6 | loss: 0.3678643\n",
      "\tspeed: 0.1273s/iter; left time: 6632.4934s\n",
      "3699it [09:55,  7.86it/s]\titers: 3700, epoch: 6 | loss: 0.5699005\n",
      "\tspeed: 0.1284s/iter; left time: 6676.4397s\n",
      "3713it [09:57,  6.22it/s]\n",
      "Epoch: 6 cost time: 597.1113939285278\n",
      "810it [00:48, 16.64it/s]\n",
      "807it [00:48, 16.52it/s]\n",
      "Epoch: 6 | Train Loss: 0.3198384 Vali Loss: 0.3886737 Test Loss: 0.4846429 MAE Loss: 0.4600995\n",
      "lr = 0.0007938947\n",
      "99it [00:13,  7.82it/s]\titers: 100, epoch: 7 | loss: 0.2265851\n",
      "\tspeed: 1.1590s/iter; left time: 60133.9246s\n",
      "199it [00:26,  7.48it/s]\titers: 200, epoch: 7 | loss: 0.2100025\n",
      "\tspeed: 0.1332s/iter; left time: 6895.9622s\n",
      "299it [00:39,  7.85it/s]\titers: 300, epoch: 7 | loss: 0.5523100\n",
      "\tspeed: 0.1289s/iter; left time: 6663.0723s\n",
      "399it [00:53,  7.63it/s]\titers: 400, epoch: 7 | loss: 0.4162106\n",
      "\tspeed: 0.1330s/iter; left time: 6862.7439s\n",
      "499it [01:06,  7.78it/s]\titers: 500, epoch: 7 | loss: 0.3099052\n",
      "\tspeed: 0.1316s/iter; left time: 6776.9242s\n",
      "599it [01:19,  7.30it/s]\titers: 600, epoch: 7 | loss: 0.1792604\n",
      "\tspeed: 0.1306s/iter; left time: 6709.8898s\n",
      "699it [01:32,  7.88it/s]\titers: 700, epoch: 7 | loss: 0.2216137\n",
      "\tspeed: 0.1287s/iter; left time: 6602.6147s\n",
      "799it [01:45,  7.97it/s]\titers: 800, epoch: 7 | loss: 0.4571757\n",
      "\tspeed: 0.1297s/iter; left time: 6638.7903s\n",
      "899it [01:57,  7.65it/s]\titers: 900, epoch: 7 | loss: 0.2167834\n",
      "\tspeed: 0.1271s/iter; left time: 6494.0746s\n",
      "999it [02:10,  8.00it/s]\titers: 1000, epoch: 7 | loss: 0.2711854\n",
      "\tspeed: 0.1276s/iter; left time: 6504.6479s\n",
      "1099it [02:23,  7.84it/s]\titers: 1100, epoch: 7 | loss: 0.3673321\n",
      "\tspeed: 0.1286s/iter; left time: 6543.5676s\n",
      "1199it [02:36,  7.50it/s]\titers: 1200, epoch: 7 | loss: 0.3153488\n",
      "\tspeed: 0.1319s/iter; left time: 6700.7263s\n",
      "1299it [02:49,  7.88it/s]\titers: 1300, epoch: 7 | loss: 0.2096113\n",
      "\tspeed: 0.1278s/iter; left time: 6476.7992s\n",
      "1399it [03:02,  7.85it/s]\titers: 1400, epoch: 7 | loss: 0.5648524\n",
      "\tspeed: 0.1303s/iter; left time: 6589.1690s\n",
      "1499it [03:15,  7.29it/s]\titers: 1500, epoch: 7 | loss: 0.1719721\n",
      "\tspeed: 0.1297s/iter; left time: 6547.8810s\n",
      "1599it [03:28,  7.93it/s]\titers: 1600, epoch: 7 | loss: 0.6261527\n",
      "\tspeed: 0.1282s/iter; left time: 6459.5033s\n",
      "1699it [03:41,  7.69it/s]\titers: 1700, epoch: 7 | loss: 0.4650384\n",
      "\tspeed: 0.1320s/iter; left time: 6637.0661s\n",
      "1799it [03:54,  6.81it/s]\titers: 1800, epoch: 7 | loss: 0.5716541\n",
      "\tspeed: 0.1313s/iter; left time: 6589.4724s\n",
      "1899it [04:07,  7.76it/s]\titers: 1900, epoch: 7 | loss: 0.3695265\n",
      "\tspeed: 0.1274s/iter; left time: 6382.7734s\n",
      "1999it [04:20,  7.44it/s]\titers: 2000, epoch: 7 | loss: 0.4043526\n",
      "\tspeed: 0.1310s/iter; left time: 6546.8440s\n",
      "2099it [04:33,  7.55it/s]\titers: 2100, epoch: 7 | loss: 0.2021791\n",
      "\tspeed: 0.1323s/iter; left time: 6601.0589s\n",
      "2199it [04:46,  7.94it/s]\titers: 2200, epoch: 7 | loss: 0.2972278\n",
      "\tspeed: 0.1285s/iter; left time: 6398.9046s\n",
      "2299it [04:59,  7.67it/s]\titers: 2300, epoch: 7 | loss: 0.3575771\n",
      "\tspeed: 0.1329s/iter; left time: 6600.5495s\n",
      "2399it [05:13,  7.83it/s]\titers: 2400, epoch: 7 | loss: 0.2037572\n",
      "\tspeed: 0.1324s/iter; left time: 6565.4608s\n",
      "2499it [05:26,  7.86it/s]\titers: 2500, epoch: 7 | loss: 0.1965705\n",
      "\tspeed: 0.1309s/iter; left time: 6479.5562s\n",
      "2599it [05:38,  7.86it/s]\titers: 2600, epoch: 7 | loss: 0.3151780\n",
      "\tspeed: 0.1281s/iter; left time: 6324.4644s\n",
      "2699it [05:52,  7.85it/s]\titers: 2700, epoch: 7 | loss: 0.2034536\n",
      "\tspeed: 0.1323s/iter; left time: 6520.5107s\n",
      "2799it [06:05,  7.88it/s]\titers: 2800, epoch: 7 | loss: 0.2483424\n",
      "\tspeed: 0.1302s/iter; left time: 6405.4563s\n",
      "2899it [06:17,  7.95it/s]\titers: 2900, epoch: 7 | loss: 0.2180000\n",
      "\tspeed: 0.1274s/iter; left time: 6254.1374s\n",
      "2999it [06:31,  7.75it/s]\titers: 3000, epoch: 7 | loss: 0.4697379\n",
      "\tspeed: 0.1318s/iter; left time: 6458.3909s\n",
      "3099it [06:44,  7.93it/s]\titers: 3100, epoch: 7 | loss: 0.2891927\n",
      "\tspeed: 0.1291s/iter; left time: 6311.8378s\n",
      "3199it [06:56,  7.80it/s]\titers: 3200, epoch: 7 | loss: 0.2120788\n",
      "\tspeed: 0.1287s/iter; left time: 6279.7677s\n",
      "3299it [07:10,  7.81it/s]\titers: 3300, epoch: 7 | loss: 0.2999848\n",
      "\tspeed: 0.1312s/iter; left time: 6387.3773s\n",
      "3399it [07:23,  7.98it/s]\titers: 3400, epoch: 7 | loss: 0.2691816\n",
      "\tspeed: 0.1301s/iter; left time: 6320.5846s\n",
      "3499it [07:36,  7.63it/s]\titers: 3500, epoch: 7 | loss: 0.1904802\n",
      "\tspeed: 0.1305s/iter; left time: 6324.9169s\n",
      "3599it [07:49,  7.75it/s]\titers: 3600, epoch: 7 | loss: 0.3413115\n",
      "\tspeed: 0.1330s/iter; left time: 6434.3642s\n",
      "3699it [08:02,  7.89it/s]\titers: 3700, epoch: 7 | loss: 0.3261745\n",
      "\tspeed: 0.1336s/iter; left time: 6450.8191s\n",
      "3713it [08:04,  7.66it/s]\n",
      "Epoch: 7 cost time: 484.6030158996582\n",
      "810it [00:48, 16.64it/s]\n",
      "807it [00:49, 16.44it/s]\n",
      "Epoch: 7 | Train Loss: 0.3178822 Vali Loss: 0.4026718 Test Loss: 0.5029341 MAE Loss: 0.4814337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007269980\n",
      "99it [00:13,  7.62it/s]\titers: 100, epoch: 8 | loss: 0.1936937\n",
      "\tspeed: 1.1304s/iter; left time: 54451.4699s\n",
      "199it [00:26,  7.55it/s]\titers: 200, epoch: 8 | loss: 0.3481279\n",
      "\tspeed: 0.1299s/iter; left time: 6243.8612s\n",
      "299it [00:39,  7.77it/s]\titers: 300, epoch: 8 | loss: 0.2465445\n",
      "\tspeed: 0.1336s/iter; left time: 6410.0930s\n",
      "399it [00:52,  7.66it/s]\titers: 400, epoch: 8 | loss: 0.3907549\n",
      "\tspeed: 0.1311s/iter; left time: 6274.9684s\n",
      "499it [01:05,  7.80it/s]\titers: 500, epoch: 8 | loss: 0.2190004\n",
      "\tspeed: 0.1321s/iter; left time: 6308.1225s\n",
      "599it [01:18,  7.76it/s]\titers: 600, epoch: 8 | loss: 0.3313726\n",
      "\tspeed: 0.1291s/iter; left time: 6153.4880s\n",
      "699it [01:32,  7.72it/s]\titers: 700, epoch: 8 | loss: 0.5199006\n",
      "\tspeed: 0.1320s/iter; left time: 6281.4071s\n",
      "799it [01:45,  7.77it/s]\titers: 800, epoch: 8 | loss: 0.4603224\n",
      "\tspeed: 0.1295s/iter; left time: 6147.0396s\n",
      "899it [01:57,  8.05it/s]\titers: 900, epoch: 8 | loss: 0.3747466\n",
      "\tspeed: 0.1282s/iter; left time: 6072.7396s\n",
      "999it [02:10,  8.14it/s]\titers: 1000, epoch: 8 | loss: 0.3959230\n",
      "\tspeed: 0.1289s/iter; left time: 6091.9026s\n",
      "1099it [02:23,  7.13it/s]\titers: 1100, epoch: 8 | loss: 0.3026269\n",
      "\tspeed: 0.1268s/iter; left time: 5981.9211s\n",
      "1199it [02:36,  7.92it/s]\titers: 1200, epoch: 8 | loss: 0.2920355\n",
      "\tspeed: 0.1282s/iter; left time: 6034.3071s\n",
      "1299it [02:49,  7.87it/s]\titers: 1300, epoch: 8 | loss: 0.5332096\n",
      "\tspeed: 0.1298s/iter; left time: 6096.9731s\n",
      "1399it [03:02,  6.55it/s]\titers: 1400, epoch: 8 | loss: 0.3614319\n",
      "\tspeed: 0.1302s/iter; left time: 6101.2353s\n",
      "1499it [03:15,  7.78it/s]\titers: 1500, epoch: 8 | loss: 0.1590936\n",
      "\tspeed: 0.1286s/iter; left time: 6014.1734s\n",
      "1599it [03:28,  7.81it/s]\titers: 1600, epoch: 8 | loss: 0.3205967\n",
      "\tspeed: 0.1325s/iter; left time: 6183.4313s\n",
      "1699it [03:41,  6.90it/s]\titers: 1700, epoch: 8 | loss: 0.2919439\n",
      "\tspeed: 0.1298s/iter; left time: 6045.3835s\n",
      "1799it [03:54,  7.87it/s]\titers: 1800, epoch: 8 | loss: 0.1961195\n",
      "\tspeed: 0.1288s/iter; left time: 5986.3663s\n",
      "1899it [04:07,  7.78it/s]\titers: 1900, epoch: 8 | loss: 0.2501426\n",
      "\tspeed: 0.1328s/iter; left time: 6157.0688s\n",
      "1999it [04:20,  6.16it/s]\titers: 2000, epoch: 8 | loss: 0.4652239\n",
      "\tspeed: 0.1309s/iter; left time: 6055.9857s\n",
      "2099it [04:33,  7.86it/s]\titers: 2100, epoch: 8 | loss: 0.3647101\n",
      "\tspeed: 0.1298s/iter; left time: 5990.8541s\n",
      "2199it [04:46,  7.72it/s]\titers: 2200, epoch: 8 | loss: 0.3905986\n",
      "\tspeed: 0.1318s/iter; left time: 6072.0517s\n",
      "2299it [04:59,  7.61it/s]\titers: 2300, epoch: 8 | loss: 0.2619036\n",
      "\tspeed: 0.1313s/iter; left time: 6037.6951s\n",
      "2399it [05:12,  7.84it/s]\titers: 2400, epoch: 8 | loss: 0.2907792\n",
      "\tspeed: 0.1285s/iter; left time: 5892.4569s\n",
      "2499it [05:25,  8.01it/s]\titers: 2500, epoch: 8 | loss: 0.3323463\n",
      "\tspeed: 0.1313s/iter; left time: 6008.2418s\n",
      "2599it [05:39,  6.29it/s]\titers: 2600, epoch: 8 | loss: 0.1633468\n",
      "\tspeed: 0.1320s/iter; left time: 6029.1540s\n",
      "2699it [05:51,  7.66it/s]\titers: 2700, epoch: 8 | loss: 0.3098654\n",
      "\tspeed: 0.1279s/iter; left time: 5828.4606s\n",
      "2799it [06:04,  7.81it/s]\titers: 2800, epoch: 8 | loss: 0.1567122\n",
      "\tspeed: 0.1301s/iter; left time: 5917.6665s\n",
      "2899it [06:17,  7.29it/s]\titers: 2900, epoch: 8 | loss: 0.3251747\n",
      "\tspeed: 0.1301s/iter; left time: 5903.3621s\n",
      "2999it [06:30,  7.81it/s]\titers: 3000, epoch: 8 | loss: 0.3707897\n",
      "\tspeed: 0.1270s/iter; left time: 5748.5596s\n",
      "3099it [06:43,  8.04it/s]\titers: 3100, epoch: 8 | loss: 0.5539950\n",
      "\tspeed: 0.1283s/iter; left time: 5795.8474s\n",
      "3199it [06:56,  7.61it/s]\titers: 3200, epoch: 8 | loss: 0.2189280\n",
      "\tspeed: 0.1316s/iter; left time: 5929.4858s\n",
      "3299it [07:09,  7.62it/s]\titers: 3300, epoch: 8 | loss: 0.4177049\n",
      "\tspeed: 0.1312s/iter; left time: 5898.2675s\n",
      "3399it [07:22,  7.87it/s]\titers: 3400, epoch: 8 | loss: 0.2371941\n",
      "\tspeed: 0.1327s/iter; left time: 5953.2572s\n",
      "3499it [07:35,  7.84it/s]\titers: 3500, epoch: 8 | loss: 0.3518778\n",
      "\tspeed: 0.1304s/iter; left time: 5837.8332s\n",
      "3599it [07:49,  7.67it/s]\titers: 3600, epoch: 8 | loss: 0.2310055\n",
      "\tspeed: 0.1307s/iter; left time: 5838.1202s\n",
      "3699it [08:01,  7.75it/s]\titers: 3700, epoch: 8 | loss: 0.2773418\n",
      "\tspeed: 0.1293s/iter; left time: 5764.2123s\n",
      "3713it [08:03,  7.67it/s]\n",
      "Epoch: 8 cost time: 483.83397150039673\n",
      "810it [00:48, 16.69it/s]\n",
      "807it [00:48, 16.53it/s]\n",
      "Epoch: 8 | Train Loss: 0.3127520 Vali Loss: 0.3726595 Test Loss: 0.4752736 MAE Loss: 0.4556114\n",
      "lr = 0.0006545120\n",
      "99it [00:13,  7.72it/s]\titers: 100, epoch: 9 | loss: 0.2628272\n",
      "\tspeed: 1.1500s/iter; left time: 51124.4471s\n",
      "199it [00:26,  7.84it/s]\titers: 200, epoch: 9 | loss: 0.3388748\n",
      "\tspeed: 0.1301s/iter; left time: 5770.9124s\n",
      "299it [00:39,  7.61it/s]\titers: 300, epoch: 9 | loss: 0.2200371\n",
      "\tspeed: 0.1299s/iter; left time: 5750.8353s\n",
      "399it [00:52,  7.71it/s]\titers: 400, epoch: 9 | loss: 0.2471333\n",
      "\tspeed: 0.1284s/iter; left time: 5671.2795s\n",
      "499it [01:05,  7.73it/s]\titers: 500, epoch: 9 | loss: 0.2086286\n",
      "\tspeed: 0.1314s/iter; left time: 5787.6475s\n",
      "599it [01:18,  6.80it/s]\titers: 600, epoch: 9 | loss: 0.2185426\n",
      "\tspeed: 0.1332s/iter; left time: 5854.2293s\n",
      "699it [01:31,  7.37it/s]\titers: 700, epoch: 9 | loss: 0.2660626\n",
      "\tspeed: 0.1302s/iter; left time: 5712.1031s\n",
      "799it [01:45,  7.79it/s]\titers: 800, epoch: 9 | loss: 0.3809134\n",
      "\tspeed: 0.1358s/iter; left time: 5941.6482s\n",
      "899it [01:58,  7.43it/s]\titers: 900, epoch: 9 | loss: 0.2144846\n",
      "\tspeed: 0.1350s/iter; left time: 5894.7358s\n",
      "999it [02:11,  7.27it/s]\titers: 1000, epoch: 9 | loss: 0.3710669\n",
      "\tspeed: 0.1340s/iter; left time: 5838.8126s\n",
      "1099it [02:25,  7.60it/s]\titers: 1100, epoch: 9 | loss: 0.3881444\n",
      "\tspeed: 0.1309s/iter; left time: 5687.9321s\n",
      "1199it [02:38,  7.78it/s]\titers: 1200, epoch: 9 | loss: 0.1951334\n",
      "\tspeed: 0.1324s/iter; left time: 5738.7300s\n",
      "1299it [02:51,  7.57it/s]\titers: 1300, epoch: 9 | loss: 0.1992106\n",
      "\tspeed: 0.1313s/iter; left time: 5680.2175s\n",
      "1399it [03:04,  6.15it/s]\titers: 1400, epoch: 9 | loss: 0.3933530\n",
      "\tspeed: 0.1325s/iter; left time: 5716.5602s\n",
      "1499it [03:17,  7.86it/s]\titers: 1500, epoch: 9 | loss: 0.4240173\n",
      "\tspeed: 0.1290s/iter; left time: 5556.1867s\n",
      "1599it [03:30,  7.88it/s]\titers: 1600, epoch: 9 | loss: 0.2480144\n",
      "\tspeed: 0.1307s/iter; left time: 5613.7809s\n",
      "1699it [03:43,  7.92it/s]\titers: 1700, epoch: 9 | loss: 0.2983743\n",
      "\tspeed: 0.1261s/iter; left time: 5403.6111s\n",
      "1799it [03:56,  7.78it/s]\titers: 1800, epoch: 9 | loss: 0.3400280\n",
      "\tspeed: 0.1284s/iter; left time: 5489.5114s\n",
      "1899it [04:09,  7.73it/s]\titers: 1900, epoch: 9 | loss: 0.1634814\n",
      "\tspeed: 0.1305s/iter; left time: 5565.7552s\n",
      "1999it [04:22,  7.83it/s]\titers: 2000, epoch: 9 | loss: 0.4274901\n",
      "\tspeed: 0.1288s/iter; left time: 5481.3031s\n",
      "2099it [04:35,  7.86it/s]\titers: 2100, epoch: 9 | loss: 0.2724287\n",
      "\tspeed: 0.1302s/iter; left time: 5529.7662s\n",
      "2199it [04:48,  7.88it/s]\titers: 2200, epoch: 9 | loss: 0.3248950\n",
      "\tspeed: 0.1301s/iter; left time: 5508.6458s\n",
      "2299it [05:00,  7.65it/s]\titers: 2300, epoch: 9 | loss: 0.5053042\n",
      "\tspeed: 0.1287s/iter; left time: 5437.3247s\n",
      "2399it [05:13,  7.83it/s]\titers: 2400, epoch: 9 | loss: 0.2094833\n",
      "\tspeed: 0.1292s/iter; left time: 5447.7039s\n",
      "2499it [05:26,  7.07it/s]\titers: 2500, epoch: 9 | loss: 0.2380140\n",
      "\tspeed: 0.1299s/iter; left time: 5465.3030s\n",
      "2599it [05:39,  7.90it/s]\titers: 2600, epoch: 9 | loss: 0.2187919\n",
      "\tspeed: 0.1285s/iter; left time: 5391.9227s\n",
      "2699it [05:52,  7.83it/s]\titers: 2700, epoch: 9 | loss: 0.1760520\n",
      "\tspeed: 0.1304s/iter; left time: 5457.8236s\n",
      "2799it [06:05,  7.40it/s]\titers: 2800, epoch: 9 | loss: 0.4936087\n",
      "\tspeed: 0.1280s/iter; left time: 5346.9478s\n",
      "2899it [06:18,  7.75it/s]\titers: 2900, epoch: 9 | loss: 0.3552023\n",
      "\tspeed: 0.1311s/iter; left time: 5459.7563s\n",
      "2999it [06:31,  8.14it/s]\titers: 3000, epoch: 9 | loss: 0.3080100\n",
      "\tspeed: 0.1288s/iter; left time: 5352.4616s\n",
      "3099it [06:44,  7.83it/s]\titers: 3100, epoch: 9 | loss: 0.3906256\n",
      "\tspeed: 0.1261s/iter; left time: 5227.9863s\n",
      "3199it [06:56,  7.98it/s]\titers: 3200, epoch: 9 | loss: 0.3656609\n",
      "\tspeed: 0.1264s/iter; left time: 5225.5108s\n",
      "3299it [07:09,  7.90it/s]\titers: 3300, epoch: 9 | loss: 0.3032006\n",
      "\tspeed: 0.1286s/iter; left time: 5305.0685s\n",
      "3399it [07:22,  7.83it/s]\titers: 3400, epoch: 9 | loss: 0.3217273\n",
      "\tspeed: 0.1294s/iter; left time: 5324.1779s\n",
      "3499it [07:35,  8.01it/s]\titers: 3500, epoch: 9 | loss: 0.2078187\n",
      "\tspeed: 0.1268s/iter; left time: 5207.8928s\n",
      "3599it [07:48,  7.92it/s]\titers: 3600, epoch: 9 | loss: 0.2604896\n",
      "\tspeed: 0.1302s/iter; left time: 5334.0637s\n",
      "3699it [08:01,  7.89it/s]\titers: 3700, epoch: 9 | loss: 0.3178231\n",
      "\tspeed: 0.1291s/iter; left time: 5275.2265s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 9 cost time: 483.153706073761\n",
      "810it [00:47, 16.89it/s]\n",
      "807it [00:48, 16.71it/s]\n",
      "Epoch: 9 | Train Loss: 0.3058381 Vali Loss: 0.3785458 Test Loss: 0.4643720 MAE Loss: 0.4581837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0005782215\n",
      "99it [00:13,  7.88it/s]\titers: 100, epoch: 10 | loss: 0.2262759\n",
      "\tspeed: 1.1134s/iter; left time: 45366.0471s\n",
      "199it [00:26,  7.90it/s]\titers: 200, epoch: 10 | loss: 0.4223031\n",
      "\tspeed: 0.1310s/iter; left time: 5325.4521s\n",
      "299it [00:39,  7.74it/s]\titers: 300, epoch: 10 | loss: 0.3500025\n",
      "\tspeed: 0.1310s/iter; left time: 5309.2464s\n",
      "399it [00:51,  7.87it/s]\titers: 400, epoch: 10 | loss: 0.2686449\n",
      "\tspeed: 0.1269s/iter; left time: 5133.6761s\n",
      "499it [01:04,  7.86it/s]\titers: 500, epoch: 10 | loss: 0.3244149\n",
      "\tspeed: 0.1293s/iter; left time: 5215.2839s\n",
      "599it [01:17,  7.66it/s]\titers: 600, epoch: 10 | loss: 0.2174947\n",
      "\tspeed: 0.1296s/iter; left time: 5213.6200s\n",
      "699it [01:30,  7.81it/s]\titers: 700, epoch: 10 | loss: 0.2414598\n",
      "\tspeed: 0.1269s/iter; left time: 5096.2261s\n",
      "799it [01:43,  7.85it/s]\titers: 800, epoch: 10 | loss: 0.2375075\n",
      "\tspeed: 0.1303s/iter; left time: 5216.3621s\n",
      "899it [01:56,  6.47it/s]\titers: 900, epoch: 10 | loss: 0.3952787\n",
      "\tspeed: 0.1302s/iter; left time: 5200.6778s\n",
      "999it [02:09,  7.72it/s]\titers: 1000, epoch: 10 | loss: 0.3944128\n",
      "\tspeed: 0.1274s/iter; left time: 5075.0013s\n",
      "1099it [02:22,  7.85it/s]\titers: 1100, epoch: 10 | loss: 0.1583472\n",
      "\tspeed: 0.1298s/iter; left time: 5160.2243s\n",
      "1199it [02:35,  7.68it/s]\titers: 1200, epoch: 10 | loss: 0.3862383\n",
      "\tspeed: 0.1315s/iter; left time: 5214.3048s\n",
      "1299it [02:48,  7.71it/s]\titers: 1300, epoch: 10 | loss: 0.2872093\n",
      "\tspeed: 0.1321s/iter; left time: 5222.6327s\n",
      "1399it [03:01,  7.69it/s]\titers: 1400, epoch: 10 | loss: 0.3244129\n",
      "\tspeed: 0.1333s/iter; left time: 5257.8564s\n",
      "1499it [03:15,  7.62it/s]\titers: 1500, epoch: 10 | loss: 0.6322581\n",
      "\tspeed: 0.1322s/iter; left time: 5201.9276s\n",
      "1599it [03:28,  6.21it/s]\titers: 1600, epoch: 10 | loss: 0.3227021\n",
      "\tspeed: 0.1320s/iter; left time: 5180.4430s\n",
      "1699it [03:41,  7.82it/s]\titers: 1700, epoch: 10 | loss: 0.1612948\n",
      "\tspeed: 0.1309s/iter; left time: 5124.5768s\n",
      "1799it [03:54,  7.52it/s]\titers: 1800, epoch: 10 | loss: 0.5255820\n",
      "\tspeed: 0.1342s/iter; left time: 5238.1576s\n",
      "1899it [04:07,  7.86it/s]\titers: 1900, epoch: 10 | loss: 0.4663216\n",
      "\tspeed: 0.1285s/iter; left time: 5002.6393s\n",
      "1999it [04:20,  7.74it/s]\titers: 2000, epoch: 10 | loss: 0.2521797\n",
      "\tspeed: 0.1321s/iter; left time: 5131.0726s\n",
      "2099it [04:33,  7.86it/s]\titers: 2100, epoch: 10 | loss: 0.3337621\n",
      "\tspeed: 0.1303s/iter; left time: 5048.0179s\n",
      "2199it [04:46,  7.86it/s]\titers: 2200, epoch: 10 | loss: 0.4249370\n",
      "\tspeed: 0.1296s/iter; left time: 5006.3465s\n",
      "2299it [04:59,  7.96it/s]\titers: 2300, epoch: 10 | loss: 0.2716905\n",
      "\tspeed: 0.1285s/iter; left time: 4951.7710s\n",
      "2399it [05:12,  7.96it/s]\titers: 2400, epoch: 10 | loss: 0.2343171\n",
      "\tspeed: 0.1305s/iter; left time: 5016.4483s\n",
      "2499it [05:25,  6.64it/s]\titers: 2500, epoch: 10 | loss: 0.2048771\n",
      "\tspeed: 0.1299s/iter; left time: 4979.7063s\n",
      "2599it [05:38,  7.73it/s]\titers: 2600, epoch: 10 | loss: 0.7223256\n",
      "\tspeed: 0.1296s/iter; left time: 4957.9676s\n",
      "2699it [05:51,  7.88it/s]\titers: 2700, epoch: 10 | loss: 0.2624083\n",
      "\tspeed: 0.1307s/iter; left time: 4987.0147s\n",
      "2799it [06:04,  7.35it/s]\titers: 2800, epoch: 10 | loss: 0.2136997\n",
      "\tspeed: 0.1303s/iter; left time: 4956.8213s\n",
      "2899it [06:17,  7.83it/s]\titers: 2900, epoch: 10 | loss: 0.3243578\n",
      "\tspeed: 0.1284s/iter; left time: 4873.8017s\n",
      "2999it [06:30,  8.06it/s]\titers: 3000, epoch: 10 | loss: 0.2444431\n",
      "\tspeed: 0.1311s/iter; left time: 4962.9081s\n",
      "3099it [06:43,  7.29it/s]\titers: 3100, epoch: 10 | loss: 0.5657013\n",
      "\tspeed: 0.1303s/iter; left time: 4919.2540s\n",
      "3199it [06:56,  7.87it/s]\titers: 3200, epoch: 10 | loss: 0.1933448\n",
      "\tspeed: 0.1296s/iter; left time: 4879.9794s\n",
      "3299it [07:09,  7.92it/s]\titers: 3300, epoch: 10 | loss: 0.4643233\n",
      "\tspeed: 0.1310s/iter; left time: 4917.0145s\n",
      "3399it [07:22,  7.56it/s]\titers: 3400, epoch: 10 | loss: 0.2606220\n",
      "\tspeed: 0.1297s/iter; left time: 4858.1817s\n",
      "3499it [07:35,  7.63it/s]\titers: 3500, epoch: 10 | loss: 0.3533718\n",
      "\tspeed: 0.1283s/iter; left time: 4791.3079s\n",
      "3599it [07:49,  7.90it/s]\titers: 3600, epoch: 10 | loss: 0.1801219\n",
      "\tspeed: 0.1327s/iter; left time: 4940.6256s\n",
      "3699it [08:01,  6.97it/s]\titers: 3700, epoch: 10 | loss: 0.1827157\n",
      "\tspeed: 0.1273s/iter; left time: 4728.8132s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 10 cost time: 483.7591094970703\n",
      "810it [00:48, 16.82it/s]\n",
      "807it [00:48, 16.59it/s]\n",
      "Epoch: 10 | Train Loss: 0.3102723 Vali Loss: 0.3692426 Test Loss: 0.4556622 MAE Loss: 0.4397559\n",
      "lr = 0.0005000050\n",
      "99it [00:13,  7.81it/s]\titers: 100, epoch: 11 | loss: 0.2129110\n",
      "\tspeed: 1.1518s/iter; left time: 42653.6751s\n",
      "199it [00:26,  7.93it/s]\titers: 200, epoch: 11 | loss: 0.2160179\n",
      "\tspeed: 0.1312s/iter; left time: 4844.9970s\n",
      "299it [00:39,  7.96it/s]\titers: 300, epoch: 11 | loss: 0.3672554\n",
      "\tspeed: 0.1297s/iter; left time: 4778.7015s\n",
      "399it [00:52,  7.87it/s]\titers: 400, epoch: 11 | loss: 0.1934277\n",
      "\tspeed: 0.1279s/iter; left time: 4698.5955s\n",
      "499it [01:04,  7.87it/s]\titers: 500, epoch: 11 | loss: 0.3040694\n",
      "\tspeed: 0.1291s/iter; left time: 4730.7069s\n",
      "599it [01:17,  7.95it/s]\titers: 600, epoch: 11 | loss: 0.2192571\n",
      "\tspeed: 0.1273s/iter; left time: 4651.0085s\n",
      "699it [01:30,  7.74it/s]\titers: 700, epoch: 11 | loss: 0.2925890\n",
      "\tspeed: 0.1276s/iter; left time: 4649.6643s\n",
      "799it [01:43,  7.88it/s]\titers: 800, epoch: 11 | loss: 0.2212382\n",
      "\tspeed: 0.1279s/iter; left time: 4647.6951s\n",
      "899it [01:56,  6.28it/s]\titers: 900, epoch: 11 | loss: 0.2900137\n",
      "\tspeed: 0.1295s/iter; left time: 4693.1083s\n",
      "999it [02:09,  7.77it/s]\titers: 1000, epoch: 11 | loss: 0.2751674\n",
      "\tspeed: 0.1309s/iter; left time: 4728.7479s\n",
      "1099it [02:22,  7.75it/s]\titers: 1100, epoch: 11 | loss: 0.2574169\n",
      "\tspeed: 0.1340s/iter; left time: 4826.5211s\n",
      "1199it [02:35,  7.91it/s]\titers: 1200, epoch: 11 | loss: 0.2747743\n",
      "\tspeed: 0.1330s/iter; left time: 4779.9813s\n",
      "1299it [02:49,  7.44it/s]\titers: 1300, epoch: 11 | loss: 0.3564970\n",
      "\tspeed: 0.1335s/iter; left time: 4783.8734s\n",
      "1399it [03:02,  7.74it/s]\titers: 1400, epoch: 11 | loss: 0.5411083\n",
      "\tspeed: 0.1317s/iter; left time: 4704.9062s\n",
      "1499it [03:15,  7.72it/s]\titers: 1500, epoch: 11 | loss: 0.2462977\n",
      "\tspeed: 0.1324s/iter; left time: 4717.7038s\n",
      "1599it [03:29,  7.79it/s]\titers: 1600, epoch: 11 | loss: 0.2471355\n",
      "\tspeed: 0.1335s/iter; left time: 4742.9347s\n",
      "1699it [03:42,  7.44it/s]\titers: 1700, epoch: 11 | loss: 0.1639506\n",
      "\tspeed: 0.1300s/iter; left time: 4605.1258s\n",
      "1799it [03:55,  7.80it/s]\titers: 1800, epoch: 11 | loss: 0.2586036\n",
      "\tspeed: 0.1327s/iter; left time: 4688.0089s\n",
      "1899it [04:08,  7.68it/s]\titers: 1900, epoch: 11 | loss: 0.3037385\n",
      "\tspeed: 0.1334s/iter; left time: 4698.7780s\n",
      "1999it [04:21,  7.78it/s]\titers: 2000, epoch: 11 | loss: 0.1892585\n",
      "\tspeed: 0.1313s/iter; left time: 4612.6265s\n",
      "2099it [04:34,  7.79it/s]\titers: 2100, epoch: 11 | loss: 0.4631732\n",
      "\tspeed: 0.1280s/iter; left time: 4485.5432s\n",
      "2199it [04:47,  8.09it/s]\titers: 2200, epoch: 11 | loss: 0.2377860\n",
      "\tspeed: 0.1309s/iter; left time: 4571.2328s\n",
      "2299it [05:00,  7.84it/s]\titers: 2300, epoch: 11 | loss: 0.3413148\n",
      "\tspeed: 0.1283s/iter; left time: 4470.0003s\n",
      "2399it [05:13,  7.86it/s]\titers: 2400, epoch: 11 | loss: 0.3775562\n",
      "\tspeed: 0.1273s/iter; left time: 4422.1625s\n",
      "2499it [05:26,  7.90it/s]\titers: 2500, epoch: 11 | loss: 0.3154799\n",
      "\tspeed: 0.1303s/iter; left time: 4512.7993s\n",
      "2599it [05:39,  7.90it/s]\titers: 2600, epoch: 11 | loss: 0.1894463\n",
      "\tspeed: 0.1301s/iter; left time: 4491.3173s\n",
      "2699it [05:52,  7.77it/s]\titers: 2700, epoch: 11 | loss: 0.3944624\n",
      "\tspeed: 0.1281s/iter; left time: 4409.5140s\n",
      "2799it [06:05,  7.69it/s]\titers: 2800, epoch: 11 | loss: 0.2589108\n",
      "\tspeed: 0.1311s/iter; left time: 4501.1055s\n",
      "2899it [06:17,  7.75it/s]\titers: 2900, epoch: 11 | loss: 0.1958744\n",
      "\tspeed: 0.1277s/iter; left time: 4371.3311s\n",
      "2999it [06:30,  7.76it/s]\titers: 3000, epoch: 11 | loss: 0.1716838\n",
      "\tspeed: 0.1289s/iter; left time: 4400.5202s\n",
      "3099it [06:44,  7.58it/s]\titers: 3100, epoch: 11 | loss: 0.3659455\n",
      "\tspeed: 0.1318s/iter; left time: 4485.8658s\n",
      "3199it [06:57,  7.67it/s]\titers: 3200, epoch: 11 | loss: 0.3893860\n",
      "\tspeed: 0.1315s/iter; left time: 4460.9065s\n",
      "3299it [07:10,  7.57it/s]\titers: 3300, epoch: 11 | loss: 0.1999049\n",
      "\tspeed: 0.1307s/iter; left time: 4422.7002s\n",
      "3399it [07:23,  7.50it/s]\titers: 3400, epoch: 11 | loss: 0.2926213\n",
      "\tspeed: 0.1352s/iter; left time: 4559.5938s\n",
      "3499it [07:37,  7.85it/s]\titers: 3500, epoch: 11 | loss: 0.3677039\n",
      "\tspeed: 0.1323s/iter; left time: 4449.8691s\n",
      "3599it [07:50,  6.42it/s]\titers: 3600, epoch: 11 | loss: 0.5320395\n",
      "\tspeed: 0.1315s/iter; left time: 4408.8302s\n",
      "3699it [08:03,  7.90it/s]\titers: 3700, epoch: 11 | loss: 0.2099393\n",
      "\tspeed: 0.1309s/iter; left time: 4376.9844s\n",
      "3713it [08:05,  7.65it/s]\n",
      "Epoch: 11 cost time: 485.1285970211029\n",
      "810it [00:48, 16.76it/s]\n",
      "807it [00:47, 16.83it/s]\n",
      "Epoch: 11 | Train Loss: 0.3060894 Vali Loss: 0.3763532 Test Loss: 0.4703912 MAE Loss: 0.4487230\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0004217885\n",
      "99it [00:13,  7.81it/s]\titers: 100, epoch: 12 | loss: 0.4451583\n",
      "\tspeed: 1.1181s/iter; left time: 37253.6590s\n",
      "199it [00:26,  7.91it/s]\titers: 200, epoch: 12 | loss: 0.3723551\n",
      "\tspeed: 0.1290s/iter; left time: 4284.2554s\n",
      "299it [00:39,  7.97it/s]\titers: 300, epoch: 12 | loss: 0.7867625\n",
      "\tspeed: 0.1272s/iter; left time: 4213.1953s\n",
      "399it [00:52,  8.01it/s]\titers: 400, epoch: 12 | loss: 0.4089924\n",
      "\tspeed: 0.1292s/iter; left time: 4265.0037s\n",
      "499it [01:04,  7.96it/s]\titers: 500, epoch: 12 | loss: 0.2734602\n",
      "\tspeed: 0.1268s/iter; left time: 4174.6290s\n",
      "599it [01:17,  8.01it/s]\titers: 600, epoch: 12 | loss: 0.3724054\n",
      "\tspeed: 0.1277s/iter; left time: 4189.3415s\n",
      "699it [01:30,  7.92it/s]\titers: 700, epoch: 12 | loss: 0.2675925\n",
      "\tspeed: 0.1309s/iter; left time: 4281.7743s\n",
      "799it [01:43,  7.97it/s]\titers: 800, epoch: 12 | loss: 0.4542611\n",
      "\tspeed: 0.1304s/iter; left time: 4253.6951s\n",
      "899it [01:56,  7.86it/s]\titers: 900, epoch: 12 | loss: 0.3660057\n",
      "\tspeed: 0.1288s/iter; left time: 4189.7509s\n",
      "999it [02:09,  7.96it/s]\titers: 1000, epoch: 12 | loss: 0.2336639\n",
      "\tspeed: 0.1314s/iter; left time: 4258.5665s\n",
      "1099it [02:22,  7.78it/s]\titers: 1100, epoch: 12 | loss: 0.2432279\n",
      "\tspeed: 0.1304s/iter; left time: 4214.3380s\n",
      "1199it [02:35,  7.81it/s]\titers: 1200, epoch: 12 | loss: 0.2511365\n",
      "\tspeed: 0.1281s/iter; left time: 4127.3664s\n",
      "1299it [02:48,  7.76it/s]\titers: 1300, epoch: 12 | loss: 0.2882995\n",
      "\tspeed: 0.1306s/iter; left time: 4194.4716s\n",
      "1399it [03:01,  7.76it/s]\titers: 1400, epoch: 12 | loss: 0.2748743\n",
      "\tspeed: 0.1289s/iter; left time: 4127.4515s\n",
      "1499it [03:14,  7.89it/s]\titers: 1500, epoch: 12 | loss: 0.2179293\n",
      "\tspeed: 0.1297s/iter; left time: 4138.7008s\n",
      "1599it [03:27,  7.69it/s]\titers: 1600, epoch: 12 | loss: 0.2599665\n",
      "\tspeed: 0.1319s/iter; left time: 4196.8211s\n",
      "1699it [03:40,  7.90it/s]\titers: 1700, epoch: 12 | loss: 0.2231337\n",
      "\tspeed: 0.1309s/iter; left time: 4150.8066s\n",
      "1799it [03:53,  7.99it/s]\titers: 1800, epoch: 12 | loss: 0.5538921\n",
      "\tspeed: 0.1310s/iter; left time: 4140.5646s\n",
      "1899it [04:06,  7.90it/s]\titers: 1900, epoch: 12 | loss: 0.2112475\n",
      "\tspeed: 0.1295s/iter; left time: 4080.3184s\n",
      "1999it [04:19,  7.98it/s]\titers: 2000, epoch: 12 | loss: 0.4534957\n",
      "\tspeed: 0.1311s/iter; left time: 4119.9882s\n",
      "2099it [04:32,  7.83it/s]\titers: 2100, epoch: 12 | loss: 0.3825724\n",
      "\tspeed: 0.1281s/iter; left time: 4012.9954s\n",
      "2199it [04:45,  7.84it/s]\titers: 2200, epoch: 12 | loss: 0.3424095\n",
      "\tspeed: 0.1301s/iter; left time: 4062.5791s\n",
      "2299it [04:58,  7.89it/s]\titers: 2300, epoch: 12 | loss: 0.3868873\n",
      "\tspeed: 0.1297s/iter; left time: 4036.9453s\n",
      "2399it [05:11,  7.82it/s]\titers: 2400, epoch: 12 | loss: 0.1467975\n",
      "\tspeed: 0.1287s/iter; left time: 3992.4494s\n",
      "2499it [05:24,  7.91it/s]\titers: 2500, epoch: 12 | loss: 0.3604757\n",
      "\tspeed: 0.1293s/iter; left time: 3996.6577s\n",
      "2599it [05:37,  7.48it/s]\titers: 2600, epoch: 12 | loss: 0.2767126\n",
      "\tspeed: 0.1280s/iter; left time: 3943.4171s\n",
      "2699it [05:50,  7.74it/s]\titers: 2700, epoch: 12 | loss: 0.3347688\n",
      "\tspeed: 0.1305s/iter; left time: 4007.5343s\n",
      "2799it [06:03,  7.66it/s]\titers: 2800, epoch: 12 | loss: 0.2294650\n",
      "\tspeed: 0.1330s/iter; left time: 4073.3134s\n",
      "2899it [06:16,  7.16it/s]\titers: 2900, epoch: 12 | loss: 0.3583461\n",
      "\tspeed: 0.1326s/iter; left time: 4046.6202s\n",
      "2999it [06:29,  7.57it/s]\titers: 3000, epoch: 12 | loss: 0.1683756\n",
      "\tspeed: 0.1294s/iter; left time: 3936.0762s\n",
      "3099it [06:43,  7.67it/s]\titers: 3100, epoch: 12 | loss: 0.3235675\n",
      "\tspeed: 0.1332s/iter; left time: 4038.0278s\n",
      "3199it [06:56,  7.80it/s]\titers: 3200, epoch: 12 | loss: 0.2619195\n",
      "\tspeed: 0.1307s/iter; left time: 3950.0211s\n",
      "3299it [07:08,  7.85it/s]\titers: 3300, epoch: 12 | loss: 0.4199897\n",
      "\tspeed: 0.1270s/iter; left time: 3825.8208s\n",
      "3399it [07:21,  7.90it/s]\titers: 3400, epoch: 12 | loss: 0.4128708\n",
      "\tspeed: 0.1290s/iter; left time: 3872.3080s\n",
      "3499it [07:34,  7.90it/s]\titers: 3500, epoch: 12 | loss: 0.2648334\n",
      "\tspeed: 0.1309s/iter; left time: 3915.0784s\n",
      "3599it [07:47,  7.56it/s]\titers: 3600, epoch: 12 | loss: 0.1982488\n",
      "\tspeed: 0.1289s/iter; left time: 3843.7286s\n",
      "3699it [08:00,  7.96it/s]\titers: 3700, epoch: 12 | loss: 0.2565594\n",
      "\tspeed: 0.1320s/iter; left time: 3921.8288s\n",
      "3713it [08:02,  7.69it/s]\n",
      "Epoch: 12 cost time: 482.8574950695038\n",
      "810it [00:48, 16.71it/s]\n",
      "807it [00:48, 16.73it/s]\n",
      "Epoch: 12 | Train Loss: 0.3065538 Vali Loss: 0.3683239 Test Loss: 0.4609763 MAE Loss: 0.4485395\n",
      "lr = 0.0003454980\n",
      "99it [00:13,  7.93it/s]\titers: 100, epoch: 13 | loss: 0.3363740\n",
      "\tspeed: 1.1565s/iter; left time: 34238.7882s\n",
      "199it [00:26,  7.98it/s]\titers: 200, epoch: 13 | loss: 0.3640074\n",
      "\tspeed: 0.1281s/iter; left time: 3780.8571s\n",
      "299it [00:39,  7.86it/s]\titers: 300, epoch: 13 | loss: 0.2458785\n",
      "\tspeed: 0.1281s/iter; left time: 3765.4629s\n",
      "399it [00:51,  7.97it/s]\titers: 400, epoch: 13 | loss: 0.2756783\n",
      "\tspeed: 0.1291s/iter; left time: 3784.0502s\n",
      "499it [01:04,  6.60it/s]\titers: 500, epoch: 13 | loss: 0.2335281\n",
      "\tspeed: 0.1289s/iter; left time: 3764.1565s\n",
      "599it [01:17,  8.02it/s]\titers: 600, epoch: 13 | loss: 0.6429272\n",
      "\tspeed: 0.1288s/iter; left time: 3749.9148s\n",
      "699it [01:30,  7.76it/s]\titers: 700, epoch: 13 | loss: 0.5281091\n",
      "\tspeed: 0.1317s/iter; left time: 3819.6806s\n",
      "799it [01:44,  6.56it/s]\titers: 800, epoch: 13 | loss: 0.1731703\n",
      "\tspeed: 0.1321s/iter; left time: 3818.3824s\n",
      "899it [01:56,  7.75it/s]\titers: 900, epoch: 13 | loss: 0.2627284\n",
      "\tspeed: 0.1285s/iter; left time: 3701.5099s\n",
      "999it [02:10,  7.86it/s]\titers: 1000, epoch: 13 | loss: 0.1809685\n",
      "\tspeed: 0.1321s/iter; left time: 3792.7349s\n",
      "1099it [02:23,  7.62it/s]\titers: 1100, epoch: 13 | loss: 0.4497292\n",
      "\tspeed: 0.1342s/iter; left time: 3837.4096s\n",
      "1199it [02:36,  7.35it/s]\titers: 1200, epoch: 13 | loss: 0.2162245\n",
      "\tspeed: 0.1330s/iter; left time: 3790.8714s\n",
      "1299it [02:50,  7.74it/s]\titers: 1300, epoch: 13 | loss: 0.2238567\n",
      "\tspeed: 0.1314s/iter; left time: 3733.0806s\n",
      "1399it [03:03,  7.84it/s]\titers: 1400, epoch: 13 | loss: 0.2818368\n",
      "\tspeed: 0.1295s/iter; left time: 3666.7009s\n",
      "1499it [03:15,  7.71it/s]\titers: 1500, epoch: 13 | loss: 0.3685950\n",
      "\tspeed: 0.1293s/iter; left time: 3647.4809s\n",
      "1599it [03:28,  7.87it/s]\titers: 1600, epoch: 13 | loss: 0.3698236\n",
      "\tspeed: 0.1297s/iter; left time: 3646.1547s\n",
      "1699it [03:41,  7.90it/s]\titers: 1700, epoch: 13 | loss: 0.2485504\n",
      "\tspeed: 0.1297s/iter; left time: 3632.2469s\n",
      "1799it [03:54,  7.77it/s]\titers: 1800, epoch: 13 | loss: 0.2669769\n",
      "\tspeed: 0.1300s/iter; left time: 3627.2914s\n",
      "1899it [04:07,  7.89it/s]\titers: 1900, epoch: 13 | loss: 0.4667847\n",
      "\tspeed: 0.1283s/iter; left time: 3566.4209s\n",
      "1999it [04:20,  7.74it/s]\titers: 2000, epoch: 13 | loss: 0.2173596\n",
      "\tspeed: 0.1326s/iter; left time: 3673.8088s\n",
      "2099it [04:34,  7.87it/s]\titers: 2100, epoch: 13 | loss: 0.2209276\n",
      "\tspeed: 0.1314s/iter; left time: 3628.1962s\n",
      "2199it [04:47,  7.89it/s]\titers: 2200, epoch: 13 | loss: 0.4442954\n",
      "\tspeed: 0.1290s/iter; left time: 3548.7188s\n",
      "2299it [05:00,  7.78it/s]\titers: 2300, epoch: 13 | loss: 0.3759520\n",
      "\tspeed: 0.1313s/iter; left time: 3597.7875s\n",
      "2399it [05:13,  7.61it/s]\titers: 2400, epoch: 13 | loss: 0.5501200\n",
      "\tspeed: 0.1327s/iter; left time: 3623.4260s\n",
      "2499it [05:26,  7.36it/s]\titers: 2500, epoch: 13 | loss: 0.4024843\n",
      "\tspeed: 0.1328s/iter; left time: 3612.0721s\n",
      "2599it [05:39,  7.72it/s]\titers: 2600, epoch: 13 | loss: 0.1932005\n",
      "\tspeed: 0.1312s/iter; left time: 3556.2496s\n",
      "2699it [05:53,  7.83it/s]\titers: 2700, epoch: 13 | loss: 0.2030459\n",
      "\tspeed: 0.1321s/iter; left time: 3568.3088s\n",
      "2799it [06:06,  7.63it/s]\titers: 2800, epoch: 13 | loss: 0.2934235\n",
      "\tspeed: 0.1317s/iter; left time: 3544.6409s\n",
      "2899it [06:18,  7.90it/s]\titers: 2900, epoch: 13 | loss: 0.4285493\n",
      "\tspeed: 0.1278s/iter; left time: 3426.1214s\n",
      "2999it [06:32,  7.68it/s]\titers: 3000, epoch: 13 | loss: 0.3863086\n",
      "\tspeed: 0.1331s/iter; left time: 3555.2962s\n",
      "3099it [06:45,  7.75it/s]\titers: 3100, epoch: 13 | loss: 0.3603980\n",
      "\tspeed: 0.1337s/iter; left time: 3557.0455s\n",
      "3199it [06:58,  7.58it/s]\titers: 3200, epoch: 13 | loss: 0.2137440\n",
      "\tspeed: 0.1287s/iter; left time: 3412.0791s\n",
      "3299it [07:11,  7.78it/s]\titers: 3300, epoch: 13 | loss: 0.2188578\n",
      "\tspeed: 0.1285s/iter; left time: 3393.0224s\n",
      "3399it [07:24,  7.79it/s]\titers: 3400, epoch: 13 | loss: 0.3768244\n",
      "\tspeed: 0.1313s/iter; left time: 3452.8826s\n",
      "3499it [07:37,  7.79it/s]\titers: 3500, epoch: 13 | loss: 0.2691181\n",
      "\tspeed: 0.1278s/iter; left time: 3348.5358s\n",
      "3599it [07:50,  7.96it/s]\titers: 3600, epoch: 13 | loss: 0.1857215\n",
      "\tspeed: 0.1283s/iter; left time: 3348.0581s\n",
      "3699it [08:03,  7.67it/s]\titers: 3700, epoch: 13 | loss: 0.2113648\n",
      "\tspeed: 0.1303s/iter; left time: 3389.0673s\n",
      "3713it [08:05,  7.66it/s]\n",
      "Epoch: 13 cost time: 485.0195662975311\n",
      "810it [00:49, 16.38it/s]\n",
      "807it [00:50, 16.11it/s]\n",
      "Epoch: 13 | Train Loss: 0.3022796 Vali Loss: 0.3618374 Test Loss: 0.4513295 MAE Loss: 0.4417399\n",
      "lr = 0.0002730120\n",
      "99it [00:13,  7.89it/s]\titers: 100, epoch: 14 | loss: 0.4755971\n",
      "\tspeed: 1.1775s/iter; left time: 30486.9808s\n",
      "199it [00:26,  7.68it/s]\titers: 200, epoch: 14 | loss: 0.4937988\n",
      "\tspeed: 0.1322s/iter; left time: 3409.8632s\n",
      "299it [00:39,  7.50it/s]\titers: 300, epoch: 14 | loss: 0.1939005\n",
      "\tspeed: 0.1346s/iter; left time: 3457.1361s\n",
      "399it [00:53,  7.95it/s]\titers: 400, epoch: 14 | loss: 0.5124890\n",
      "\tspeed: 0.1323s/iter; left time: 3386.0505s\n",
      "499it [01:06,  7.93it/s]\titers: 500, epoch: 14 | loss: 0.2696610\n",
      "\tspeed: 0.1304s/iter; left time: 3324.0154s\n",
      "599it [01:19,  7.62it/s]\titers: 600, epoch: 14 | loss: 0.2908652\n",
      "\tspeed: 0.1303s/iter; left time: 3307.7081s\n",
      "699it [01:32,  7.65it/s]\titers: 700, epoch: 14 | loss: 0.1846792\n",
      "\tspeed: 0.1310s/iter; left time: 3313.9933s\n",
      "799it [01:44,  7.86it/s]\titers: 800, epoch: 14 | loss: 0.2378728\n",
      "\tspeed: 0.1277s/iter; left time: 3216.1648s\n",
      "899it [01:58,  7.92it/s]\titers: 900, epoch: 14 | loss: 0.2225063\n",
      "\tspeed: 0.1313s/iter; left time: 3295.0650s\n",
      "999it [02:11,  7.15it/s]\titers: 1000, epoch: 14 | loss: 0.3362010\n",
      "\tspeed: 0.1315s/iter; left time: 3285.6730s\n",
      "1099it [02:24,  7.73it/s]\titers: 1100, epoch: 14 | loss: 0.2668234\n",
      "\tspeed: 0.1288s/iter; left time: 3206.0033s\n",
      "1199it [02:37,  7.89it/s]\titers: 1200, epoch: 14 | loss: 0.3582336\n",
      "\tspeed: 0.1321s/iter; left time: 3276.0256s\n",
      "1299it [02:50,  7.83it/s]\titers: 1300, epoch: 14 | loss: 0.2051454\n",
      "\tspeed: 0.1336s/iter; left time: 3298.8086s\n",
      "1399it [03:03,  6.23it/s]\titers: 1400, epoch: 14 | loss: 0.2071019\n",
      "\tspeed: 0.1330s/iter; left time: 3270.7416s\n",
      "1499it [03:16,  7.84it/s]\titers: 1500, epoch: 14 | loss: 0.2094268\n",
      "\tspeed: 0.1298s/iter; left time: 3178.7678s\n",
      "1599it [03:30,  7.75it/s]\titers: 1600, epoch: 14 | loss: 0.2260860\n",
      "\tspeed: 0.1319s/iter; left time: 3217.2032s\n",
      "1699it [03:43,  7.82it/s]\titers: 1700, epoch: 14 | loss: 0.2423266\n",
      "\tspeed: 0.1322s/iter; left time: 3210.7010s\n",
      "1799it [03:56,  7.64it/s]\titers: 1800, epoch: 14 | loss: 0.2314711\n",
      "\tspeed: 0.1302s/iter; left time: 3150.6853s\n",
      "1899it [04:09,  7.81it/s]\titers: 1900, epoch: 14 | loss: 0.5312371\n",
      "\tspeed: 0.1329s/iter; left time: 3202.4768s\n",
      "1999it [04:22,  7.63it/s]\titers: 2000, epoch: 14 | loss: 0.1695830\n",
      "\tspeed: 0.1297s/iter; left time: 3112.7563s\n",
      "2099it [04:35,  7.61it/s]\titers: 2100, epoch: 14 | loss: 0.2617297\n",
      "\tspeed: 0.1309s/iter; left time: 3127.1634s\n",
      "2199it [04:48,  7.56it/s]\titers: 2200, epoch: 14 | loss: 0.2946777\n",
      "\tspeed: 0.1323s/iter; left time: 3146.9614s\n",
      "2299it [05:02,  7.83it/s]\titers: 2300, epoch: 14 | loss: 0.3260429\n",
      "\tspeed: 0.1308s/iter; left time: 3099.9737s\n",
      "2399it [05:15,  7.69it/s]\titers: 2400, epoch: 14 | loss: 0.5888684\n",
      "\tspeed: 0.1298s/iter; left time: 3061.2641s\n",
      "2499it [05:28,  7.82it/s]\titers: 2500, epoch: 14 | loss: 0.4731840\n",
      "\tspeed: 0.1317s/iter; left time: 3093.0598s\n",
      "2599it [05:41,  7.59it/s]\titers: 2600, epoch: 14 | loss: 0.4229459\n",
      "\tspeed: 0.1321s/iter; left time: 3090.3311s\n",
      "2699it [05:54,  7.71it/s]\titers: 2700, epoch: 14 | loss: 0.2471594\n",
      "\tspeed: 0.1282s/iter; left time: 2985.8733s\n",
      "2799it [06:07,  7.96it/s]\titers: 2800, epoch: 14 | loss: 0.3193118\n",
      "\tspeed: 0.1336s/iter; left time: 3097.5424s\n",
      "2899it [06:20,  7.74it/s]\titers: 2900, epoch: 14 | loss: 0.4108343\n",
      "\tspeed: 0.1299s/iter; left time: 2998.6096s\n",
      "2999it [06:33,  7.21it/s]\titers: 3000, epoch: 14 | loss: 0.1736975\n",
      "\tspeed: 0.1301s/iter; left time: 2990.8089s\n",
      "3099it [06:46,  7.71it/s]\titers: 3100, epoch: 14 | loss: 0.2235859\n",
      "\tspeed: 0.1313s/iter; left time: 3004.7416s\n",
      "3199it [07:00,  7.74it/s]\titers: 3200, epoch: 14 | loss: 0.2457025\n",
      "\tspeed: 0.1336s/iter; left time: 3045.2450s\n",
      "3299it [07:13,  7.49it/s]\titers: 3300, epoch: 14 | loss: 0.2814765\n",
      "\tspeed: 0.1310s/iter; left time: 2972.3766s\n",
      "3399it [07:26,  7.71it/s]\titers: 3400, epoch: 14 | loss: 0.2147318\n",
      "\tspeed: 0.1297s/iter; left time: 2930.3769s\n",
      "3499it [07:39,  7.83it/s]\titers: 3500, epoch: 14 | loss: 0.2412813\n",
      "\tspeed: 0.1317s/iter; left time: 2961.4606s\n",
      "3599it [07:52,  6.91it/s]\titers: 3600, epoch: 14 | loss: 0.2531735\n",
      "\tspeed: 0.1317s/iter; left time: 2949.5234s\n",
      "3699it [08:05,  7.80it/s]\titers: 3700, epoch: 14 | loss: 0.1618023\n",
      "\tspeed: 0.1295s/iter; left time: 2887.5022s\n",
      "3713it [08:07,  7.62it/s]\n",
      "Epoch: 14 cost time: 487.2845046520233\n",
      "810it [00:48, 16.62it/s]\n",
      "807it [00:49, 16.15it/s]\n",
      "Epoch: 14 | Train Loss: 0.2987254 Vali Loss: 0.3576874 Test Loss: 0.4430876 MAE Loss: 0.4305773\n",
      "lr = 0.0002061153\n",
      "99it [00:13,  7.75it/s]\titers: 100, epoch: 15 | loss: 0.2353320\n",
      "\tspeed: 1.1769s/iter; left time: 26101.9068s\n",
      "199it [00:26,  7.49it/s]\titers: 200, epoch: 15 | loss: 0.3292054\n",
      "\tspeed: 0.1325s/iter; left time: 2926.4512s\n",
      "299it [00:39,  6.96it/s]\titers: 300, epoch: 15 | loss: 0.3044077\n",
      "\tspeed: 0.1289s/iter; left time: 2833.9186s\n",
      "399it [00:52,  7.92it/s]\titers: 400, epoch: 15 | loss: 0.3659534\n",
      "\tspeed: 0.1304s/iter; left time: 2852.9828s\n",
      "499it [01:06,  7.74it/s]\titers: 500, epoch: 15 | loss: 0.1894791\n",
      "\tspeed: 0.1342s/iter; left time: 2921.9719s\n",
      "599it [01:19,  7.00it/s]\titers: 600, epoch: 15 | loss: 0.3411899\n",
      "\tspeed: 0.1307s/iter; left time: 2832.8850s\n",
      "699it [01:32,  7.92it/s]\titers: 700, epoch: 15 | loss: 0.1325692\n",
      "\tspeed: 0.1293s/iter; left time: 2789.9447s\n",
      "799it [01:45,  7.92it/s]\titers: 800, epoch: 15 | loss: 0.2170790\n",
      "\tspeed: 0.1290s/iter; left time: 2769.8560s\n",
      "899it [01:57,  6.80it/s]\titers: 900, epoch: 15 | loss: 0.3053609\n",
      "\tspeed: 0.1282s/iter; left time: 2740.6307s\n",
      "999it [02:10,  7.87it/s]\titers: 1000, epoch: 15 | loss: 0.2961984\n",
      "\tspeed: 0.1313s/iter; left time: 2792.8887s\n",
      "1099it [02:24,  7.86it/s]\titers: 1100, epoch: 15 | loss: 0.3711877\n",
      "\tspeed: 0.1317s/iter; left time: 2790.0513s\n",
      "1199it [02:37,  7.76it/s]\titers: 1200, epoch: 15 | loss: 0.2997461\n",
      "\tspeed: 0.1307s/iter; left time: 2754.0577s\n",
      "1299it [02:50,  7.71it/s]\titers: 1300, epoch: 15 | loss: 0.3191172\n",
      "\tspeed: 0.1305s/iter; left time: 2737.6555s\n",
      "1399it [03:03,  7.85it/s]\titers: 1400, epoch: 15 | loss: 0.4231580\n",
      "\tspeed: 0.1296s/iter; left time: 2705.6100s\n",
      "1499it [03:16,  7.59it/s]\titers: 1500, epoch: 15 | loss: 0.1601920\n",
      "\tspeed: 0.1302s/iter; left time: 2704.4343s\n",
      "1599it [03:29,  7.79it/s]\titers: 1600, epoch: 15 | loss: 0.3274886\n",
      "\tspeed: 0.1292s/iter; left time: 2672.2863s\n",
      "1699it [03:42,  7.69it/s]\titers: 1700, epoch: 15 | loss: 0.2691060\n",
      "\tspeed: 0.1325s/iter; left time: 2727.0206s\n",
      "1799it [03:55,  7.88it/s]\titers: 1800, epoch: 15 | loss: 0.2709500\n",
      "\tspeed: 0.1327s/iter; left time: 2717.6164s\n",
      "1899it [04:08,  7.10it/s]\titers: 1900, epoch: 15 | loss: 0.3565255\n",
      "\tspeed: 0.1308s/iter; left time: 2665.6166s\n",
      "1999it [04:21,  7.68it/s]\titers: 2000, epoch: 15 | loss: 0.3223369\n",
      "\tspeed: 0.1307s/iter; left time: 2650.5786s\n",
      "2099it [04:34,  7.70it/s]\titers: 2100, epoch: 15 | loss: 0.2985791\n",
      "\tspeed: 0.1309s/iter; left time: 2640.6604s\n",
      "2199it [04:47,  7.60it/s]\titers: 2200, epoch: 15 | loss: 0.2233403\n",
      "\tspeed: 0.1298s/iter; left time: 2605.5311s\n",
      "2299it [05:00,  7.91it/s]\titers: 2300, epoch: 15 | loss: 0.3149113\n",
      "\tspeed: 0.1298s/iter; left time: 2592.7437s\n",
      "2399it [05:14,  7.83it/s]\titers: 2400, epoch: 15 | loss: 0.2272493\n",
      "\tspeed: 0.1326s/iter; left time: 2636.6394s\n",
      "2499it [05:27,  6.52it/s]\titers: 2500, epoch: 15 | loss: 0.2959761\n",
      "\tspeed: 0.1340s/iter; left time: 2650.4106s\n",
      "2599it [05:40,  7.84it/s]\titers: 2600, epoch: 15 | loss: 0.3312805\n",
      "\tspeed: 0.1293s/iter; left time: 2543.5266s\n",
      "2699it [05:53,  7.32it/s]\titers: 2700, epoch: 15 | loss: 0.1984944\n",
      "\tspeed: 0.1328s/iter; left time: 2601.0290s\n",
      "2799it [06:07,  7.32it/s]\titers: 2800, epoch: 15 | loss: 0.2295475\n",
      "\tspeed: 0.1333s/iter; left time: 2597.0366s\n",
      "2899it [06:19,  7.78it/s]\titers: 2900, epoch: 15 | loss: 0.1922981\n",
      "\tspeed: 0.1287s/iter; left time: 2493.5818s\n",
      "2999it [06:33,  7.77it/s]\titers: 3000, epoch: 15 | loss: 0.1390029\n",
      "\tspeed: 0.1328s/iter; left time: 2560.7462s\n",
      "3099it [06:46,  7.75it/s]\titers: 3100, epoch: 15 | loss: 0.2850018\n",
      "\tspeed: 0.1310s/iter; left time: 2512.9950s\n",
      "3199it [06:59,  7.61it/s]\titers: 3200, epoch: 15 | loss: 0.4715592\n",
      "\tspeed: 0.1317s/iter; left time: 2513.3104s\n",
      "3299it [07:12,  7.85it/s]\titers: 3300, epoch: 15 | loss: 0.2396106\n",
      "\tspeed: 0.1308s/iter; left time: 2482.6258s\n",
      "3399it [07:25,  7.80it/s]\titers: 3400, epoch: 15 | loss: 0.2126822\n",
      "\tspeed: 0.1298s/iter; left time: 2449.5793s\n",
      "3499it [07:38,  7.43it/s]\titers: 3500, epoch: 15 | loss: 0.1733334\n",
      "\tspeed: 0.1320s/iter; left time: 2479.1866s\n",
      "3599it [07:51,  6.86it/s]\titers: 3600, epoch: 15 | loss: 0.3623030\n",
      "\tspeed: 0.1296s/iter; left time: 2420.3746s\n",
      "3699it [08:04,  7.75it/s]\titers: 3700, epoch: 15 | loss: 0.2445326\n",
      "\tspeed: 0.1312s/iter; left time: 2438.1293s\n",
      "3713it [08:06,  7.63it/s]\n",
      "Epoch: 15 cost time: 486.7254321575165\n",
      "810it [00:48, 16.64it/s]\n",
      "807it [00:49, 16.28it/s]\n",
      "Epoch: 15 | Train Loss: 0.2904040 Vali Loss: 0.3497226 Test Loss: 0.4324299 MAE Loss: 0.4276436\n",
      "lr = 0.0001464551\n",
      "99it [00:13,  7.47it/s]\titers: 100, epoch: 16 | loss: 0.1861260\n",
      "\tspeed: 1.1669s/iter; left time: 21547.8971s\n",
      "199it [00:26,  7.77it/s]\titers: 200, epoch: 16 | loss: 0.1767844\n",
      "\tspeed: 0.1306s/iter; left time: 2398.8192s\n",
      "299it [00:40,  7.62it/s]\titers: 300, epoch: 16 | loss: 0.1695202\n",
      "\tspeed: 0.1361s/iter; left time: 2485.1061s\n",
      "399it [00:53,  7.89it/s]\titers: 400, epoch: 16 | loss: 0.1533292\n",
      "\tspeed: 0.1341s/iter; left time: 2436.6311s\n",
      "499it [01:06,  7.81it/s]\titers: 500, epoch: 16 | loss: 0.3388799\n",
      "\tspeed: 0.1320s/iter; left time: 2383.9700s\n",
      "599it [01:19,  7.89it/s]\titers: 600, epoch: 16 | loss: 0.3582064\n",
      "\tspeed: 0.1306s/iter; left time: 2346.8012s\n",
      "699it [01:33,  7.84it/s]\titers: 700, epoch: 16 | loss: 0.6211451\n",
      "\tspeed: 0.1340s/iter; left time: 2394.3304s\n",
      "799it [01:46,  7.82it/s]\titers: 800, epoch: 16 | loss: 0.4362165\n",
      "\tspeed: 0.1335s/iter; left time: 2371.2231s\n",
      "899it [01:59,  7.07it/s]\titers: 900, epoch: 16 | loss: 0.2294557\n",
      "\tspeed: 0.1310s/iter; left time: 2314.7693s\n",
      "999it [02:12,  7.75it/s]\titers: 1000, epoch: 16 | loss: 0.3457487\n",
      "\tspeed: 0.1333s/iter; left time: 2341.2381s\n",
      "1099it [02:26,  7.44it/s]\titers: 1100, epoch: 16 | loss: 0.2124871\n",
      "\tspeed: 0.1373s/iter; left time: 2397.9776s\n",
      "1199it [02:39,  7.78it/s]\titers: 1200, epoch: 16 | loss: 0.3403161\n",
      "\tspeed: 0.1293s/iter; left time: 2246.0756s\n",
      "1299it [02:52,  7.99it/s]\titers: 1300, epoch: 16 | loss: 0.1891805\n",
      "\tspeed: 0.1304s/iter; left time: 2251.1429s\n",
      "1399it [03:05,  8.02it/s]\titers: 1400, epoch: 16 | loss: 0.2910257\n",
      "\tspeed: 0.1286s/iter; left time: 2208.2694s\n",
      "1499it [03:18,  7.98it/s]\titers: 1500, epoch: 16 | loss: 0.3099553\n",
      "\tspeed: 0.1283s/iter; left time: 2189.0190s\n",
      "1599it [03:31,  7.92it/s]\titers: 1600, epoch: 16 | loss: 0.2545178\n",
      "\tspeed: 0.1298s/iter; left time: 2202.6214s\n",
      "1699it [03:44,  8.02it/s]\titers: 1700, epoch: 16 | loss: 0.5039687\n",
      "\tspeed: 0.1293s/iter; left time: 2180.2458s\n",
      "1799it [03:57,  7.51it/s]\titers: 1800, epoch: 16 | loss: 0.3732177\n",
      "\tspeed: 0.1294s/iter; left time: 2169.7061s\n",
      "1899it [04:09,  7.95it/s]\titers: 1900, epoch: 16 | loss: 0.1803452\n",
      "\tspeed: 0.1260s/iter; left time: 2099.2757s\n",
      "1999it [04:22,  7.95it/s]\titers: 2000, epoch: 16 | loss: 0.1640476\n",
      "\tspeed: 0.1305s/iter; left time: 2161.5992s\n",
      "2099it [04:35,  8.03it/s]\titers: 2100, epoch: 16 | loss: 0.2665240\n",
      "\tspeed: 0.1288s/iter; left time: 2121.1819s\n",
      "2199it [04:48,  7.79it/s]\titers: 2200, epoch: 16 | loss: 0.3570365\n",
      "\tspeed: 0.1277s/iter; left time: 2089.3825s\n",
      "2299it [05:01,  7.88it/s]\titers: 2300, epoch: 16 | loss: 0.4647745\n",
      "\tspeed: 0.1280s/iter; left time: 2081.2615s\n",
      "2399it [05:14,  7.78it/s]\titers: 2400, epoch: 16 | loss: 0.1857308\n",
      "\tspeed: 0.1287s/iter; left time: 2080.7052s\n",
      "2499it [05:27,  7.82it/s]\titers: 2500, epoch: 16 | loss: 0.2017089\n",
      "\tspeed: 0.1285s/iter; left time: 2063.7977s\n",
      "2599it [05:39,  7.91it/s]\titers: 2600, epoch: 16 | loss: 0.4566964\n",
      "\tspeed: 0.1271s/iter; left time: 2029.3354s\n",
      "2699it [05:52,  7.85it/s]\titers: 2700, epoch: 16 | loss: 0.2925663\n",
      "\tspeed: 0.1305s/iter; left time: 2070.5098s\n",
      "2799it [06:05,  7.95it/s]\titers: 2800, epoch: 16 | loss: 0.2202639\n",
      "\tspeed: 0.1303s/iter; left time: 2054.0940s\n",
      "2899it [06:18,  7.24it/s]\titers: 2900, epoch: 16 | loss: 0.3928232\n",
      "\tspeed: 0.1281s/iter; left time: 2006.9880s\n",
      "2999it [06:31,  7.94it/s]\titers: 3000, epoch: 16 | loss: 0.3039874\n",
      "\tspeed: 0.1284s/iter; left time: 1998.6201s\n",
      "3099it [06:44,  8.01it/s]\titers: 3100, epoch: 16 | loss: 0.2731483\n",
      "\tspeed: 0.1284s/iter; left time: 1985.6006s\n",
      "3199it [06:57,  7.85it/s]\titers: 3200, epoch: 16 | loss: 0.4619856\n",
      "\tspeed: 0.1270s/iter; left time: 1951.5617s\n",
      "3299it [07:09,  7.94it/s]\titers: 3300, epoch: 16 | loss: 0.1495067\n",
      "\tspeed: 0.1283s/iter; left time: 1959.3258s\n",
      "3399it [07:22,  8.01it/s]\titers: 3400, epoch: 16 | loss: 0.2597162\n",
      "\tspeed: 0.1305s/iter; left time: 1979.7944s\n",
      "3499it [07:35,  7.83it/s]\titers: 3500, epoch: 16 | loss: 0.2072920\n",
      "\tspeed: 0.1289s/iter; left time: 1942.2016s\n",
      "3599it [07:48,  7.06it/s]\titers: 3600, epoch: 16 | loss: 0.2320128\n",
      "\tspeed: 0.1274s/iter; left time: 1906.1780s\n",
      "3699it [08:01,  7.47it/s]\titers: 3700, epoch: 16 | loss: 0.2333990\n",
      "\tspeed: 0.1286s/iter; left time: 1911.5070s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 16 cost time: 483.26137375831604\n",
      "810it [00:48, 16.73it/s]\n",
      "807it [00:48, 16.69it/s]\n",
      "Epoch: 16 | Train Loss: 0.2896346 Vali Loss: 0.3507182 Test Loss: 0.4344943 MAE Loss: 0.4307301\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0000955005\n",
      "99it [00:13,  7.86it/s]\titers: 100, epoch: 17 | loss: 0.2886153\n",
      "\tspeed: 1.1176s/iter; left time: 16488.6253s\n",
      "199it [00:25,  7.91it/s]\titers: 200, epoch: 17 | loss: 0.1521192\n",
      "\tspeed: 0.1272s/iter; left time: 1864.0853s\n",
      "299it [00:38,  7.85it/s]\titers: 300, epoch: 17 | loss: 0.1269865\n",
      "\tspeed: 0.1306s/iter; left time: 1901.3037s\n",
      "399it [00:51,  7.95it/s]\titers: 400, epoch: 17 | loss: 0.3803651\n",
      "\tspeed: 0.1270s/iter; left time: 1836.1327s\n",
      "499it [01:04,  7.86it/s]\titers: 500, epoch: 17 | loss: 0.2037760\n",
      "\tspeed: 0.1274s/iter; left time: 1828.3165s\n",
      "599it [01:17,  7.61it/s]\titers: 600, epoch: 17 | loss: 0.3450657\n",
      "\tspeed: 0.1301s/iter; left time: 1853.7242s\n",
      "699it [01:30,  7.69it/s]\titers: 700, epoch: 17 | loss: 0.2402654\n",
      "\tspeed: 0.1290s/iter; left time: 1825.5258s\n",
      "799it [01:42,  7.58it/s]\titers: 800, epoch: 17 | loss: 0.2436413\n",
      "\tspeed: 0.1276s/iter; left time: 1792.6871s\n",
      "899it [01:55,  7.68it/s]\titers: 900, epoch: 17 | loss: 0.2765182\n",
      "\tspeed: 0.1301s/iter; left time: 1814.7131s\n",
      "999it [02:08,  7.98it/s]\titers: 1000, epoch: 17 | loss: 0.2652180\n",
      "\tspeed: 0.1298s/iter; left time: 1797.8715s\n",
      "1099it [02:21,  7.92it/s]\titers: 1100, epoch: 17 | loss: 0.3413520\n",
      "\tspeed: 0.1288s/iter; left time: 1771.8964s\n",
      "1199it [02:34,  7.95it/s]\titers: 1200, epoch: 17 | loss: 0.1930054\n",
      "\tspeed: 0.1280s/iter; left time: 1747.6868s\n",
      "1299it [02:47,  8.10it/s]\titers: 1300, epoch: 17 | loss: 0.4490595\n",
      "\tspeed: 0.1285s/iter; left time: 1741.6409s\n",
      "1399it [03:00,  7.86it/s]\titers: 1400, epoch: 17 | loss: 0.6068544\n",
      "\tspeed: 0.1292s/iter; left time: 1738.5577s\n",
      "1499it [03:13,  7.82it/s]\titers: 1500, epoch: 17 | loss: 0.2249237\n",
      "\tspeed: 0.1286s/iter; left time: 1717.4378s\n",
      "1599it [03:26,  7.84it/s]\titers: 1600, epoch: 17 | loss: 0.2344005\n",
      "\tspeed: 0.1294s/iter; left time: 1714.6548s\n",
      "1699it [03:39,  7.77it/s]\titers: 1700, epoch: 17 | loss: 0.2375891\n",
      "\tspeed: 0.1312s/iter; left time: 1725.0304s\n",
      "1799it [03:52,  7.77it/s]\titers: 1800, epoch: 17 | loss: 0.3281684\n",
      "\tspeed: 0.1279s/iter; left time: 1669.7394s\n",
      "1899it [04:05,  7.36it/s]\titers: 1900, epoch: 17 | loss: 0.3739150\n",
      "\tspeed: 0.1321s/iter; left time: 1711.4503s\n",
      "1999it [04:18,  7.97it/s]\titers: 2000, epoch: 17 | loss: 0.2851160\n",
      "\tspeed: 0.1299s/iter; left time: 1669.0053s\n",
      "2099it [04:31,  7.83it/s]\titers: 2100, epoch: 17 | loss: 0.3748374\n",
      "\tspeed: 0.1279s/iter; left time: 1631.2669s\n",
      "2199it [04:44,  7.62it/s]\titers: 2200, epoch: 17 | loss: 0.2040289\n",
      "\tspeed: 0.1301s/iter; left time: 1646.1764s\n",
      "2299it [04:56,  8.01it/s]\titers: 2300, epoch: 17 | loss: 0.2245248\n",
      "\tspeed: 0.1291s/iter; left time: 1620.8617s\n",
      "2399it [05:09,  7.94it/s]\titers: 2400, epoch: 17 | loss: 0.2705359\n",
      "\tspeed: 0.1280s/iter; left time: 1593.5619s\n",
      "2499it [05:22,  7.57it/s]\titers: 2500, epoch: 17 | loss: 0.3253122\n",
      "\tspeed: 0.1263s/iter; left time: 1560.1805s\n",
      "2599it [05:35,  7.56it/s]\titers: 2600, epoch: 17 | loss: 0.1431143\n",
      "\tspeed: 0.1289s/iter; left time: 1579.8357s\n",
      "2699it [05:48,  7.83it/s]\titers: 2700, epoch: 17 | loss: 0.1145093\n",
      "\tspeed: 0.1305s/iter; left time: 1586.2359s\n",
      "2799it [06:01,  7.64it/s]\titers: 2800, epoch: 17 | loss: 0.4969672\n",
      "\tspeed: 0.1283s/iter; left time: 1546.7589s\n",
      "2899it [06:13,  7.96it/s]\titers: 2900, epoch: 17 | loss: 0.5124037\n",
      "\tspeed: 0.1277s/iter; left time: 1526.5471s\n",
      "2999it [06:26,  8.04it/s]\titers: 3000, epoch: 17 | loss: 0.5197293\n",
      "\tspeed: 0.1287s/iter; left time: 1525.5053s\n",
      "3099it [06:39,  7.88it/s]\titers: 3100, epoch: 17 | loss: 0.2230427\n",
      "\tspeed: 0.1277s/iter; left time: 1500.4461s\n",
      "3199it [06:52,  8.00it/s]\titers: 3200, epoch: 17 | loss: 0.4513548\n",
      "\tspeed: 0.1284s/iter; left time: 1496.1837s\n",
      "3299it [07:05,  7.89it/s]\titers: 3300, epoch: 17 | loss: 0.3612390\n",
      "\tspeed: 0.1295s/iter; left time: 1496.5267s\n",
      "3399it [07:18,  7.79it/s]\titers: 3400, epoch: 17 | loss: 0.2907190\n",
      "\tspeed: 0.1295s/iter; left time: 1482.6471s\n",
      "3499it [07:31,  7.71it/s]\titers: 3500, epoch: 17 | loss: 0.2137356\n",
      "\tspeed: 0.1276s/iter; left time: 1448.2261s\n",
      "3599it [07:43,  7.76it/s]\titers: 3600, epoch: 17 | loss: 0.1934652\n",
      "\tspeed: 0.1279s/iter; left time: 1439.7937s\n",
      "3699it [07:56,  7.90it/s]\titers: 3700, epoch: 17 | loss: 0.4378054\n",
      "\tspeed: 0.1284s/iter; left time: 1431.7193s\n",
      "3713it [07:58,  7.76it/s]\n",
      "Epoch: 17 cost time: 478.550164937973\n",
      "810it [00:47, 16.89it/s]\n",
      "807it [00:48, 16.75it/s]\n",
      "Epoch: 17 | Train Loss: 0.2851446 Vali Loss: 0.3439783 Test Loss: 0.4263099 MAE Loss: 0.4231231\n",
      "lr = 0.0000545062\n",
      "99it [00:13,  7.82it/s]\titers: 100, epoch: 18 | loss: 0.3329677\n",
      "\tspeed: 1.1441s/iter; left time: 12630.8337s\n",
      "199it [00:25,  7.88it/s]\titers: 200, epoch: 18 | loss: 0.2575828\n",
      "\tspeed: 0.1286s/iter; left time: 1407.1362s\n",
      "299it [00:38,  7.88it/s]\titers: 300, epoch: 18 | loss: 0.1765651\n",
      "\tspeed: 0.1273s/iter; left time: 1379.4930s\n",
      "399it [00:51,  7.93it/s]\titers: 400, epoch: 18 | loss: 0.2640049\n",
      "\tspeed: 0.1278s/iter; left time: 1373.0121s\n",
      "499it [01:04,  7.86it/s]\titers: 500, epoch: 18 | loss: 0.3224196\n",
      "\tspeed: 0.1291s/iter; left time: 1373.8698s\n",
      "599it [01:17,  7.78it/s]\titers: 600, epoch: 18 | loss: 0.1794068\n",
      "\tspeed: 0.1281s/iter; left time: 1350.3175s\n",
      "699it [01:29,  7.60it/s]\titers: 700, epoch: 18 | loss: 0.3325299\n",
      "\tspeed: 0.1259s/iter; left time: 1314.5621s\n",
      "799it [01:42,  8.04it/s]\titers: 800, epoch: 18 | loss: 0.2906775\n",
      "\tspeed: 0.1290s/iter; left time: 1333.3985s\n",
      "899it [01:55,  7.83it/s]\titers: 900, epoch: 18 | loss: 0.4680055\n",
      "\tspeed: 0.1288s/iter; left time: 1318.9278s\n",
      "999it [02:08,  7.82it/s]\titers: 1000, epoch: 18 | loss: 0.2280695\n",
      "\tspeed: 0.1277s/iter; left time: 1295.1997s\n",
      "1099it [02:21,  7.73it/s]\titers: 1100, epoch: 18 | loss: 0.3151264\n",
      "\tspeed: 0.1283s/iter; left time: 1288.5462s\n",
      "1199it [02:33,  8.00it/s]\titers: 1200, epoch: 18 | loss: 0.1943336\n",
      "\tspeed: 0.1279s/iter; left time: 1271.1642s\n",
      "1299it [02:46,  6.42it/s]\titers: 1300, epoch: 18 | loss: 0.4807726\n",
      "\tspeed: 0.1280s/iter; left time: 1259.8359s\n",
      "1399it [02:59,  7.58it/s]\titers: 1400, epoch: 18 | loss: 0.1760294\n",
      "\tspeed: 0.1269s/iter; left time: 1235.8635s\n",
      "1499it [03:12,  7.99it/s]\titers: 1500, epoch: 18 | loss: 0.2912110\n",
      "\tspeed: 0.1282s/iter; left time: 1235.5841s\n",
      "1599it [03:25,  8.08it/s]\titers: 1600, epoch: 18 | loss: 0.4577796\n",
      "\tspeed: 0.1282s/iter; left time: 1222.9742s\n",
      "1699it [03:37,  7.68it/s]\titers: 1700, epoch: 18 | loss: 0.1651925\n",
      "\tspeed: 0.1273s/iter; left time: 1201.3672s\n",
      "1799it [03:50,  8.07it/s]\titers: 1800, epoch: 18 | loss: 0.1767547\n",
      "\tspeed: 0.1277s/iter; left time: 1192.8318s\n",
      "1899it [04:03,  8.00it/s]\titers: 1900, epoch: 18 | loss: 0.5720109\n",
      "\tspeed: 0.1293s/iter; left time: 1194.3509s\n",
      "1999it [04:16,  7.25it/s]\titers: 2000, epoch: 18 | loss: 0.2140196\n",
      "\tspeed: 0.1285s/iter; left time: 1174.5562s\n",
      "2099it [04:29,  7.82it/s]\titers: 2100, epoch: 18 | loss: 0.2658590\n",
      "\tspeed: 0.1279s/iter; left time: 1156.5780s\n",
      "2199it [04:42,  7.64it/s]\titers: 2200, epoch: 18 | loss: 0.3156388\n",
      "\tspeed: 0.1311s/iter; left time: 1171.7019s\n",
      "2299it [04:55,  7.97it/s]\titers: 2300, epoch: 18 | loss: 0.2038364\n",
      "\tspeed: 0.1295s/iter; left time: 1144.5797s\n",
      "2399it [05:07,  7.50it/s]\titers: 2400, epoch: 18 | loss: 0.2096113\n",
      "\tspeed: 0.1286s/iter; left time: 1123.5941s\n",
      "2499it [05:21,  7.58it/s]\titers: 2500, epoch: 18 | loss: 0.1682891\n",
      "\tspeed: 0.1314s/iter; left time: 1135.6233s\n",
      "2599it [05:34,  7.69it/s]\titers: 2600, epoch: 18 | loss: 0.4195050\n",
      "\tspeed: 0.1296s/iter; left time: 1106.5708s\n",
      "2699it [05:47,  7.32it/s]\titers: 2700, epoch: 18 | loss: 0.1885891\n",
      "\tspeed: 0.1309s/iter; left time: 1104.8437s\n",
      "2799it [05:59,  7.41it/s]\titers: 2800, epoch: 18 | loss: 0.2885799\n",
      "\tspeed: 0.1272s/iter; left time: 1060.9185s\n",
      "2899it [06:12,  7.97it/s]\titers: 2900, epoch: 18 | loss: 0.1885973\n",
      "\tspeed: 0.1292s/iter; left time: 1064.3687s\n",
      "2999it [06:25,  8.02it/s]\titers: 3000, epoch: 18 | loss: 0.3157410\n",
      "\tspeed: 0.1279s/iter; left time: 1040.9552s\n",
      "3099it [06:38,  7.81it/s]\titers: 3100, epoch: 18 | loss: 0.1815318\n",
      "\tspeed: 0.1281s/iter; left time: 1029.9836s\n",
      "3199it [06:51,  7.46it/s]\titers: 3200, epoch: 18 | loss: 0.2727541\n",
      "\tspeed: 0.1277s/iter; left time: 1014.2258s\n",
      "3299it [07:04,  8.01it/s]\titers: 3300, epoch: 18 | loss: 0.2843535\n",
      "\tspeed: 0.1295s/iter; left time: 1014.8999s\n",
      "3399it [07:17,  7.86it/s]\titers: 3400, epoch: 18 | loss: 0.1880093\n",
      "\tspeed: 0.1288s/iter; left time: 996.5449s\n",
      "3499it [07:29,  7.68it/s]\titers: 3500, epoch: 18 | loss: 0.2316481\n",
      "\tspeed: 0.1264s/iter; left time: 965.6923s\n",
      "3599it [07:42,  7.92it/s]\titers: 3600, epoch: 18 | loss: 0.2278130\n",
      "\tspeed: 0.1284s/iter; left time: 968.1911s\n",
      "3699it [07:55,  7.89it/s]\titers: 3700, epoch: 18 | loss: 0.3258895\n",
      "\tspeed: 0.1287s/iter; left time: 957.3414s\n",
      "3713it [07:57,  7.78it/s]\n",
      "Epoch: 18 cost time: 477.18381214141846\n",
      "810it [00:48, 16.79it/s]\n",
      "807it [00:47, 16.82it/s]\n",
      "Epoch: 18 | Train Loss: 0.2818938 Vali Loss: 0.3431476 Test Loss: 0.4251187 MAE Loss: 0.4230486\n",
      "lr = 0.0000244815\n",
      "99it [00:13,  7.96it/s]\titers: 100, epoch: 19 | loss: 0.3231862\n",
      "\tspeed: 1.1480s/iter; left time: 8411.2409s\n",
      "199it [00:25,  7.70it/s]\titers: 200, epoch: 19 | loss: 0.2902018\n",
      "\tspeed: 0.1287s/iter; left time: 929.9664s\n",
      "299it [00:38,  7.91it/s]\titers: 300, epoch: 19 | loss: 0.3231234\n",
      "\tspeed: 0.1285s/iter; left time: 916.0933s\n",
      "399it [00:51,  7.58it/s]\titers: 400, epoch: 19 | loss: 0.2864132\n",
      "\tspeed: 0.1259s/iter; left time: 884.3783s\n",
      "499it [01:04,  7.63it/s]\titers: 500, epoch: 19 | loss: 0.2952008\n",
      "\tspeed: 0.1289s/iter; left time: 892.8428s\n",
      "599it [01:17,  8.02it/s]\titers: 600, epoch: 19 | loss: 0.2018728\n",
      "\tspeed: 0.1335s/iter; left time: 911.5230s\n",
      "699it [01:30,  7.59it/s]\titers: 700, epoch: 19 | loss: 0.4377728\n",
      "\tspeed: 0.1274s/iter; left time: 857.0629s\n",
      "799it [01:43,  7.96it/s]\titers: 800, epoch: 19 | loss: 0.3378433\n",
      "\tspeed: 0.1276s/iter; left time: 845.9074s\n",
      "899it [01:56,  7.90it/s]\titers: 900, epoch: 19 | loss: 0.2063994\n",
      "\tspeed: 0.1287s/iter; left time: 839.7220s\n",
      "999it [02:08,  7.91it/s]\titers: 1000, epoch: 19 | loss: 0.3694931\n",
      "\tspeed: 0.1275s/iter; left time: 819.2119s\n",
      "1099it [02:21,  7.99it/s]\titers: 1100, epoch: 19 | loss: 0.3364376\n",
      "\tspeed: 0.1278s/iter; left time: 808.6942s\n",
      "1199it [02:34,  8.02it/s]\titers: 1200, epoch: 19 | loss: 0.3416563\n",
      "\tspeed: 0.1291s/iter; left time: 804.1307s\n",
      "1299it [02:47,  7.97it/s]\titers: 1300, epoch: 19 | loss: 0.1821789\n",
      "\tspeed: 0.1286s/iter; left time: 787.9134s\n",
      "1399it [03:00,  7.68it/s]\titers: 1400, epoch: 19 | loss: 0.2529828\n",
      "\tspeed: 0.1275s/iter; left time: 768.5814s\n",
      "1499it [03:12,  8.01it/s]\titers: 1500, epoch: 19 | loss: 0.3169283\n",
      "\tspeed: 0.1277s/iter; left time: 756.7978s\n",
      "1599it [03:25,  7.89it/s]\titers: 1600, epoch: 19 | loss: 0.4366460\n",
      "\tspeed: 0.1290s/iter; left time: 751.6298s\n",
      "1699it [03:38,  6.69it/s]\titers: 1700, epoch: 19 | loss: 0.2569892\n",
      "\tspeed: 0.1297s/iter; left time: 742.5425s\n",
      "1799it [03:51,  7.84it/s]\titers: 1800, epoch: 19 | loss: 0.2051529\n",
      "\tspeed: 0.1267s/iter; left time: 712.7902s\n",
      "1899it [04:04,  7.88it/s]\titers: 1900, epoch: 19 | loss: 0.3925875\n",
      "\tspeed: 0.1303s/iter; left time: 720.0739s\n",
      "1999it [04:17,  8.01it/s]\titers: 2000, epoch: 19 | loss: 0.2824491\n",
      "\tspeed: 0.1284s/iter; left time: 696.9412s\n",
      "2099it [04:30,  7.91it/s]\titers: 2100, epoch: 19 | loss: 0.1650740\n",
      "\tspeed: 0.1276s/iter; left time: 679.6337s\n",
      "2199it [04:42,  7.66it/s]\titers: 2200, epoch: 19 | loss: 0.2945198\n",
      "\tspeed: 0.1283s/iter; left time: 670.3964s\n",
      "2299it [04:55,  7.92it/s]\titers: 2300, epoch: 19 | loss: 0.5822414\n",
      "\tspeed: 0.1288s/iter; left time: 660.3531s\n",
      "2399it [05:08,  6.94it/s]\titers: 2400, epoch: 19 | loss: 0.2541802\n",
      "\tspeed: 0.1296s/iter; left time: 651.2677s\n",
      "2499it [05:21,  7.19it/s]\titers: 2500, epoch: 19 | loss: 0.3122996\n",
      "\tspeed: 0.1311s/iter; left time: 645.8778s\n",
      "2599it [05:34,  8.07it/s]\titers: 2600, epoch: 19 | loss: 0.3651050\n",
      "\tspeed: 0.1285s/iter; left time: 620.0868s\n",
      "2699it [05:47,  7.67it/s]\titers: 2700, epoch: 19 | loss: 0.1750141\n",
      "\tspeed: 0.1307s/iter; left time: 617.6676s\n",
      "2799it [06:00,  7.69it/s]\titers: 2800, epoch: 19 | loss: 0.3191998\n",
      "\tspeed: 0.1302s/iter; left time: 602.3877s\n",
      "2899it [06:13,  7.76it/s]\titers: 2900, epoch: 19 | loss: 0.2538366\n",
      "\tspeed: 0.1294s/iter; left time: 585.9877s\n",
      "2999it [06:26,  7.80it/s]\titers: 3000, epoch: 19 | loss: 0.2005800\n",
      "\tspeed: 0.1293s/iter; left time: 572.5579s\n",
      "3099it [06:39,  7.65it/s]\titers: 3100, epoch: 19 | loss: 0.2404605\n",
      "\tspeed: 0.1309s/iter; left time: 566.5372s\n",
      "3199it [06:52,  7.72it/s]\titers: 3200, epoch: 19 | loss: 0.3099367\n",
      "\tspeed: 0.1312s/iter; left time: 554.7385s\n",
      "3299it [07:05,  7.72it/s]\titers: 3300, epoch: 19 | loss: 0.5230960\n",
      "\tspeed: 0.1293s/iter; left time: 533.4299s\n",
      "3399it [07:18,  7.95it/s]\titers: 3400, epoch: 19 | loss: 0.3983754\n",
      "\tspeed: 0.1323s/iter; left time: 532.6848s\n",
      "3499it [07:31,  7.80it/s]\titers: 3500, epoch: 19 | loss: 0.3132668\n",
      "\tspeed: 0.1290s/iter; left time: 506.4156s\n",
      "3599it [07:44,  7.60it/s]\titers: 3600, epoch: 19 | loss: 0.2824549\n",
      "\tspeed: 0.1291s/iter; left time: 494.2350s\n",
      "3699it [07:57,  7.92it/s]\titers: 3700, epoch: 19 | loss: 0.3821140\n",
      "\tspeed: 0.1296s/iter; left time: 483.1581s\n",
      "3713it [07:59,  7.74it/s]\n",
      "Epoch: 19 cost time: 479.59899163246155\n",
      "810it [00:48, 16.73it/s]\n",
      "807it [00:48, 16.54it/s]\n",
      "Epoch: 19 | Train Loss: 0.2808887 Vali Loss: 0.3445619 Test Loss: 0.4261527 MAE Loss: 0.4264147\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0000061658\n",
      "99it [00:13,  7.70it/s]\titers: 100, epoch: 20 | loss: 0.2526909\n",
      "\tspeed: 1.1239s/iter; left time: 4061.5981s\n",
      "199it [00:26,  7.70it/s]\titers: 200, epoch: 20 | loss: 0.2030843\n",
      "\tspeed: 0.1307s/iter; left time: 459.1413s\n",
      "299it [00:39,  8.03it/s]\titers: 300, epoch: 20 | loss: 0.2638560\n",
      "\tspeed: 0.1314s/iter; left time: 448.4845s\n",
      "399it [00:52,  7.86it/s]\titers: 400, epoch: 20 | loss: 0.2450883\n",
      "\tspeed: 0.1300s/iter; left time: 430.9079s\n",
      "499it [01:05,  7.75it/s]\titers: 500, epoch: 20 | loss: 0.2361744\n",
      "\tspeed: 0.1282s/iter; left time: 412.1153s\n",
      "599it [01:18,  7.96it/s]\titers: 600, epoch: 20 | loss: 0.1980131\n",
      "\tspeed: 0.1292s/iter; left time: 402.3029s\n",
      "699it [01:31,  7.97it/s]\titers: 700, epoch: 20 | loss: 0.3825595\n",
      "\tspeed: 0.1289s/iter; left time: 388.5415s\n",
      "799it [01:43,  7.83it/s]\titers: 800, epoch: 20 | loss: 0.1336034\n",
      "\tspeed: 0.1277s/iter; left time: 372.1399s\n",
      "899it [01:56,  7.60it/s]\titers: 900, epoch: 20 | loss: 0.3303688\n",
      "\tspeed: 0.1287s/iter; left time: 362.0651s\n",
      "999it [02:09,  7.95it/s]\titers: 1000, epoch: 20 | loss: 0.2278752\n",
      "\tspeed: 0.1307s/iter; left time: 354.7756s\n",
      "1099it [02:22,  7.88it/s]\titers: 1100, epoch: 20 | loss: 0.1569596\n",
      "\tspeed: 0.1291s/iter; left time: 337.5476s\n",
      "1199it [02:35,  7.89it/s]\titers: 1200, epoch: 20 | loss: 0.2233342\n",
      "\tspeed: 0.1280s/iter; left time: 321.8290s\n",
      "1299it [02:48,  7.76it/s]\titers: 1300, epoch: 20 | loss: 0.3263616\n",
      "\tspeed: 0.1284s/iter; left time: 309.8561s\n",
      "1399it [03:01,  7.90it/s]\titers: 1400, epoch: 20 | loss: 0.3985030\n",
      "\tspeed: 0.1307s/iter; left time: 302.4910s\n",
      "1499it [03:14,  7.16it/s]\titers: 1500, epoch: 20 | loss: 0.2953323\n",
      "\tspeed: 0.1302s/iter; left time: 288.3417s\n",
      "1599it [03:27,  7.81it/s]\titers: 1600, epoch: 20 | loss: 0.4013351\n",
      "\tspeed: 0.1279s/iter; left time: 270.4134s\n",
      "1699it [03:40,  7.72it/s]\titers: 1700, epoch: 20 | loss: 0.1585270\n",
      "\tspeed: 0.1304s/iter; left time: 262.5846s\n",
      "1799it [03:53,  7.37it/s]\titers: 1800, epoch: 20 | loss: 0.2059319\n",
      "\tspeed: 0.1320s/iter; left time: 252.6315s\n",
      "1899it [04:06,  7.88it/s]\titers: 1900, epoch: 20 | loss: 0.1659470\n",
      "\tspeed: 0.1282s/iter; left time: 232.6291s\n",
      "1999it [04:19,  7.92it/s]\titers: 2000, epoch: 20 | loss: 0.3189528\n",
      "\tspeed: 0.1278s/iter; left time: 219.0644s\n",
      "2099it [04:31,  7.79it/s]\titers: 2100, epoch: 20 | loss: 0.3272199\n",
      "\tspeed: 0.1291s/iter; left time: 208.3164s\n",
      "2199it [04:44,  7.93it/s]\titers: 2200, epoch: 20 | loss: 0.1735636\n",
      "\tspeed: 0.1286s/iter; left time: 194.7156s\n",
      "2299it [04:57,  7.83it/s]\titers: 2300, epoch: 20 | loss: 0.2227974\n",
      "\tspeed: 0.1292s/iter; left time: 182.6533s\n",
      "2399it [05:10,  7.63it/s]\titers: 2400, epoch: 20 | loss: 0.2269403\n",
      "\tspeed: 0.1276s/iter; left time: 167.6395s\n",
      "2499it [05:23,  7.92it/s]\titers: 2500, epoch: 20 | loss: 0.3882084\n",
      "\tspeed: 0.1297s/iter; left time: 157.4350s\n",
      "2599it [05:36,  7.60it/s]\titers: 2600, epoch: 20 | loss: 0.2199817\n",
      "\tspeed: 0.1293s/iter; left time: 144.0565s\n",
      "2699it [05:49,  7.43it/s]\titers: 2700, epoch: 20 | loss: 0.2882137\n",
      "\tspeed: 0.1281s/iter; left time: 129.9079s\n",
      "2799it [06:02,  7.90it/s]\titers: 2800, epoch: 20 | loss: 0.2681598\n",
      "\tspeed: 0.1288s/iter; left time: 117.7404s\n",
      "2899it [06:15,  7.82it/s]\titers: 2900, epoch: 20 | loss: 0.2051983\n",
      "\tspeed: 0.1296s/iter; left time: 105.4827s\n",
      "2999it [06:27,  7.71it/s]\titers: 3000, epoch: 20 | loss: 0.2666871\n",
      "\tspeed: 0.1292s/iter; left time: 92.2643s\n",
      "3099it [06:40,  7.88it/s]\titers: 3100, epoch: 20 | loss: 0.1687871\n",
      "\tspeed: 0.1287s/iter; left time: 79.0008s\n",
      "3199it [06:53,  7.90it/s]\titers: 3200, epoch: 20 | loss: 0.2888637\n",
      "\tspeed: 0.1291s/iter; left time: 66.3527s\n",
      "3299it [07:06,  7.61it/s]\titers: 3300, epoch: 20 | loss: 0.2770034\n",
      "\tspeed: 0.1299s/iter; left time: 53.7666s\n",
      "3399it [07:19,  7.40it/s]\titers: 3400, epoch: 20 | loss: 0.1920416\n",
      "\tspeed: 0.1285s/iter; left time: 40.3379s\n",
      "3499it [07:32,  7.90it/s]\titers: 3500, epoch: 20 | loss: 0.2849917\n",
      "\tspeed: 0.1289s/iter; left time: 27.5749s\n",
      "3599it [07:45,  7.72it/s]\titers: 3600, epoch: 20 | loss: 0.4497917\n",
      "\tspeed: 0.1298s/iter; left time: 14.7965s\n",
      "3699it [07:58,  7.82it/s]\titers: 3700, epoch: 20 | loss: 0.3295776\n",
      "\tspeed: 0.1286s/iter; left time: 1.8002s\n",
      "3713it [08:00,  7.73it/s]\n",
      "Epoch: 20 cost time: 480.29611682891846\n",
      "810it [00:48, 16.77it/s]\n",
      "807it [00:48, 16.67it/s]\n",
      "Epoch: 20 | Train Loss: 0.2792270 Vali Loss: 0.3419906 Test Loss: 0.4223526 MAE Loss: 0.4208767\n",
      "lr = 0.0000000100\n",
      "Total time: 204.96061081091563 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small, 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-04 20:07:53,719] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-04 20:07:54,569] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-04 20:07:54,569] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-04 20:07:54,569] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-04 20:07:55,484] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-04 20:07:55,484] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-04 20:07:56,098] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-04 20:07:56,099] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-04 20:07:56,100] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-04 20:07:56,101] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-04 20:07:56,101] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-04 20:07:56,101] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-04 20:07:56,101] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-04 20:07:56,101] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-04 20:07:56,101] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-04 20:07:56,101] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-04 20:07:56,415] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-04 20:07:56,415] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-04 20:07:56,415] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.28 GB, percent = 16.1%\n",
      "[2024-05-04 20:07:56,525] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-04 20:07:56,525] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-04 20:07:56,525] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.32 GB, percent = 16.1%\n",
      "[2024-05-04 20:07:56,526] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-04 20:07:56,636] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-04 20:07:56,637] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-04 20:07:56,637] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 121.56 GB, percent = 16.1%\n",
      "[2024-05-04 20:07:56,637] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-04 20:07:56,637] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-04 20:07:56,637] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-04 20:07:56,637] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3fff48eb10>\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-04 20:07:56,638] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-04 20:07:56,639] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-04 20:07:56,640] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:08, 13.94it/s]\titers: 100, epoch: 1 | loss: 0.6932486\n",
      "\tspeed: 0.1181s/iter; left time: 8755.9334s\n",
      "199it [00:15, 13.86it/s]\titers: 200, epoch: 1 | loss: 0.2162637\n",
      "\tspeed: 0.0711s/iter; left time: 5264.7337s\n",
      "299it [00:23, 14.06it/s]\titers: 300, epoch: 1 | loss: 0.3769366\n",
      "\tspeed: 0.0778s/iter; left time: 5754.1582s\n",
      "399it [00:31, 13.91it/s]\titers: 400, epoch: 1 | loss: 0.2745434\n",
      "\tspeed: 0.0779s/iter; left time: 5750.2392s\n",
      "499it [00:38, 13.70it/s]\titers: 500, epoch: 1 | loss: 0.4847790\n",
      "\tspeed: 0.0724s/iter; left time: 5343.8528s\n",
      "599it [00:45, 14.14it/s]\titers: 600, epoch: 1 | loss: 0.4859864\n",
      "\tspeed: 0.0735s/iter; left time: 5411.7245s\n",
      "699it [00:52, 14.11it/s]\titers: 700, epoch: 1 | loss: 0.4851586\n",
      "\tspeed: 0.0715s/iter; left time: 5262.9484s\n",
      "799it [00:59, 14.26it/s]\titers: 800, epoch: 1 | loss: 0.4660286\n",
      "\tspeed: 0.0717s/iter; left time: 5263.6896s\n",
      "899it [01:07, 13.54it/s]\titers: 900, epoch: 1 | loss: 0.2512229\n",
      "\tspeed: 0.0728s/iter; left time: 5342.1663s\n",
      "999it [01:14, 13.10it/s]\titers: 1000, epoch: 1 | loss: 0.5408119\n",
      "\tspeed: 0.0719s/iter; left time: 5263.9904s\n",
      "1099it [01:21, 13.91it/s]\titers: 1100, epoch: 1 | loss: 0.4881727\n",
      "\tspeed: 0.0736s/iter; left time: 5387.0057s\n",
      "1199it [01:28, 13.44it/s]\titers: 1200, epoch: 1 | loss: 0.4563959\n",
      "\tspeed: 0.0714s/iter; left time: 5215.7678s\n",
      "1299it [01:36, 14.05it/s]\titers: 1300, epoch: 1 | loss: 0.2801948\n",
      "\tspeed: 0.0722s/iter; left time: 5266.4093s\n",
      "1399it [01:43, 13.21it/s]\titers: 1400, epoch: 1 | loss: 0.3749747\n",
      "\tspeed: 0.0731s/iter; left time: 5323.2823s\n",
      "1499it [01:50, 12.80it/s]\titers: 1500, epoch: 1 | loss: 0.1778722\n",
      "\tspeed: 0.0736s/iter; left time: 5357.3353s\n",
      "1599it [01:58, 13.53it/s]\titers: 1600, epoch: 1 | loss: 0.2050066\n",
      "\tspeed: 0.0728s/iter; left time: 5286.5128s\n",
      "1699it [02:05, 14.14it/s]\titers: 1700, epoch: 1 | loss: 0.4777356\n",
      "\tspeed: 0.0715s/iter; left time: 5185.1173s\n",
      "1799it [02:12, 13.94it/s]\titers: 1800, epoch: 1 | loss: 0.5995959\n",
      "\tspeed: 0.0735s/iter; left time: 5327.5210s\n",
      "1899it [02:19, 13.78it/s]\titers: 1900, epoch: 1 | loss: 0.3243000\n",
      "\tspeed: 0.0713s/iter; left time: 5157.0747s\n",
      "1999it [02:27, 13.52it/s]\titers: 2000, epoch: 1 | loss: 0.2054642\n",
      "\tspeed: 0.0726s/iter; left time: 5249.2268s\n",
      "2099it [02:34, 14.16it/s]\titers: 2100, epoch: 1 | loss: 0.7944400\n",
      "\tspeed: 0.0740s/iter; left time: 5339.1311s\n",
      "2199it [02:41, 11.54it/s]\titers: 2200, epoch: 1 | loss: 0.2168330\n",
      "\tspeed: 0.0743s/iter; left time: 5351.3410s\n",
      "2299it [02:49, 13.15it/s]\titers: 2300, epoch: 1 | loss: 0.2408096\n",
      "\tspeed: 0.0758s/iter; left time: 5452.7007s\n",
      "2399it [02:56, 14.19it/s]\titers: 2400, epoch: 1 | loss: 0.2905696\n",
      "\tspeed: 0.0711s/iter; left time: 5107.7679s\n",
      "2499it [03:03, 14.12it/s]\titers: 2500, epoch: 1 | loss: 0.2873078\n",
      "\tspeed: 0.0726s/iter; left time: 5210.1054s\n",
      "2599it [03:11, 14.15it/s]\titers: 2600, epoch: 1 | loss: 0.2829672\n",
      "\tspeed: 0.0725s/iter; left time: 5194.4198s\n",
      "2699it [03:18, 12.65it/s]\titers: 2700, epoch: 1 | loss: 0.3935815\n",
      "\tspeed: 0.0732s/iter; left time: 5239.4984s\n",
      "2799it [03:25, 14.06it/s]\titers: 2800, epoch: 1 | loss: 0.2103565\n",
      "\tspeed: 0.0736s/iter; left time: 5258.0972s\n",
      "2899it [03:32, 14.16it/s]\titers: 2900, epoch: 1 | loss: 0.3417163\n",
      "\tspeed: 0.0711s/iter; left time: 5075.5540s\n",
      "2999it [03:40, 12.34it/s]\titers: 3000, epoch: 1 | loss: 0.2578327\n",
      "\tspeed: 0.0737s/iter; left time: 5252.8160s\n",
      "3099it [03:47, 14.15it/s]\titers: 3100, epoch: 1 | loss: 0.3924931\n",
      "\tspeed: 0.0713s/iter; left time: 5074.5802s\n",
      "3199it [03:54, 13.48it/s]\titers: 3200, epoch: 1 | loss: 0.3727626\n",
      "\tspeed: 0.0736s/iter; left time: 5231.0557s\n",
      "3299it [04:01, 14.12it/s]\titers: 3300, epoch: 1 | loss: 0.4639084\n",
      "\tspeed: 0.0717s/iter; left time: 5088.2382s\n",
      "3399it [04:08, 14.02it/s]\titers: 3400, epoch: 1 | loss: 0.4539699\n",
      "\tspeed: 0.0705s/iter; left time: 4998.9704s\n",
      "3499it [04:16, 13.92it/s]\titers: 3500, epoch: 1 | loss: 0.3433972\n",
      "\tspeed: 0.0725s/iter; left time: 5130.9374s\n",
      "3599it [04:23, 13.73it/s]\titers: 3600, epoch: 1 | loss: 0.3567059\n",
      "\tspeed: 0.0719s/iter; left time: 5077.6738s\n",
      "3699it [04:30, 13.75it/s]\titers: 3700, epoch: 1 | loss: 0.4630506\n",
      "\tspeed: 0.0717s/iter; left time: 5062.1838s\n",
      "3713it [04:31, 13.67it/s]\n",
      "Epoch: 1 cost time: 271.54762840270996\n",
      "810it [00:30, 26.99it/s]\n",
      "807it [00:30, 26.66it/s]\n",
      "Epoch: 1 | Train Loss: 0.3603586 Vali Loss: 0.3968324 Test Loss: 0.4883537 MAE Loss: 0.4657121\n",
      "lr = 0.0009938442\n",
      "99it [00:07, 14.17it/s]\titers: 100, epoch: 2 | loss: 0.4103872\n",
      "\tspeed: 0.7068s/iter; left time: 49792.5831s\n",
      "199it [00:14, 13.89it/s]\titers: 200, epoch: 2 | loss: 0.2962865\n",
      "\tspeed: 0.0718s/iter; left time: 5049.1423s\n",
      "299it [00:21, 14.04it/s]\titers: 300, epoch: 2 | loss: 0.4552098\n",
      "\tspeed: 0.0706s/iter; left time: 4962.6590s\n",
      "399it [00:28, 15.58it/s]\titers: 400, epoch: 2 | loss: 0.1380480\n",
      "\tspeed: 0.0709s/iter; left time: 4972.7531s\n",
      "499it [00:35, 14.56it/s]\titers: 500, epoch: 2 | loss: 0.2856549\n",
      "\tspeed: 0.0701s/iter; left time: 4912.2785s\n",
      "599it [00:42, 14.17it/s]\titers: 600, epoch: 2 | loss: 0.3516709\n",
      "\tspeed: 0.0713s/iter; left time: 4987.1275s\n",
      "699it [00:50, 15.01it/s]\titers: 700, epoch: 2 | loss: 0.4588235\n",
      "\tspeed: 0.0709s/iter; left time: 4954.9512s\n",
      "799it [00:57, 12.75it/s]\titers: 800, epoch: 2 | loss: 0.3512471\n",
      "\tspeed: 0.0704s/iter; left time: 4912.5360s\n",
      "899it [01:04, 14.16it/s]\titers: 900, epoch: 2 | loss: 0.2884502\n",
      "\tspeed: 0.0728s/iter; left time: 5072.1880s\n",
      "999it [01:11, 15.03it/s]\titers: 1000, epoch: 2 | loss: 0.3002308\n",
      "\tspeed: 0.0701s/iter; left time: 4872.1912s\n",
      "1099it [01:18, 14.18it/s]\titers: 1100, epoch: 2 | loss: 0.1781139\n",
      "\tspeed: 0.0719s/iter; left time: 4992.2088s\n",
      "1199it [01:25, 14.21it/s]\titers: 1200, epoch: 2 | loss: 0.2972357\n",
      "\tspeed: 0.0720s/iter; left time: 4996.2337s\n",
      "1299it [01:32, 14.17it/s]\titers: 1300, epoch: 2 | loss: 0.3384142\n",
      "\tspeed: 0.0682s/iter; left time: 4720.1978s\n",
      "1399it [01:39, 14.33it/s]\titers: 1400, epoch: 2 | loss: 0.4042118\n",
      "\tspeed: 0.0714s/iter; left time: 4935.3640s\n",
      "1499it [01:46, 13.73it/s]\titers: 1500, epoch: 2 | loss: 0.2262840\n",
      "\tspeed: 0.0709s/iter; left time: 4894.4761s\n",
      "1599it [01:54, 13.49it/s]\titers: 1600, epoch: 2 | loss: 0.2712517\n",
      "\tspeed: 0.0735s/iter; left time: 5069.0067s\n",
      "1699it [02:01, 14.12it/s]\titers: 1700, epoch: 2 | loss: 0.3201418\n",
      "\tspeed: 0.0705s/iter; left time: 4855.0481s\n",
      "1799it [02:08, 15.04it/s]\titers: 1800, epoch: 2 | loss: 0.3149760\n",
      "\tspeed: 0.0710s/iter; left time: 4879.1876s\n",
      "1899it [02:15, 13.61it/s]\titers: 1900, epoch: 2 | loss: 0.3865437\n",
      "\tspeed: 0.0696s/iter; left time: 4774.6309s\n",
      "1999it [02:22, 13.86it/s]\titers: 2000, epoch: 2 | loss: 0.2544391\n",
      "\tspeed: 0.0710s/iter; left time: 4863.9549s\n",
      "2099it [02:29, 13.72it/s]\titers: 2100, epoch: 2 | loss: 0.5642318\n",
      "\tspeed: 0.0718s/iter; left time: 4914.0728s\n",
      "2199it [02:36, 14.34it/s]\titers: 2200, epoch: 2 | loss: 0.3639329\n",
      "\tspeed: 0.0706s/iter; left time: 4826.9559s\n",
      "2299it [02:43, 14.08it/s]\titers: 2300, epoch: 2 | loss: 0.3828222\n",
      "\tspeed: 0.0726s/iter; left time: 4957.6533s\n",
      "2399it [02:51, 14.17it/s]\titers: 2400, epoch: 2 | loss: 0.1834839\n",
      "\tspeed: 0.0718s/iter; left time: 4896.4174s\n",
      "2499it [02:58, 14.11it/s]\titers: 2500, epoch: 2 | loss: 0.3763536\n",
      "\tspeed: 0.0704s/iter; left time: 4793.7179s\n",
      "2599it [03:05, 14.05it/s]\titers: 2600, epoch: 2 | loss: 0.4121595\n",
      "\tspeed: 0.0730s/iter; left time: 4957.9522s\n",
      "2699it [03:12, 14.17it/s]\titers: 2700, epoch: 2 | loss: 0.5046951\n",
      "\tspeed: 0.0705s/iter; left time: 4780.9266s\n",
      "2799it [03:19, 14.19it/s]\titers: 2800, epoch: 2 | loss: 0.3165244\n",
      "\tspeed: 0.0729s/iter; left time: 4935.8615s\n",
      "2899it [03:26, 14.79it/s]\titers: 2900, epoch: 2 | loss: 0.5156003\n",
      "\tspeed: 0.0711s/iter; left time: 4808.6299s\n",
      "2999it [03:33, 14.14it/s]\titers: 3000, epoch: 2 | loss: 0.3766225\n",
      "\tspeed: 0.0712s/iter; left time: 4807.5557s\n",
      "3099it [03:41, 13.97it/s]\titers: 3100, epoch: 2 | loss: 0.2918439\n",
      "\tspeed: 0.0714s/iter; left time: 4812.4627s\n",
      "3199it [03:48, 14.14it/s]\titers: 3200, epoch: 2 | loss: 0.2761501\n",
      "\tspeed: 0.0704s/iter; left time: 4743.9385s\n",
      "3299it [03:55, 13.99it/s]\titers: 3300, epoch: 2 | loss: 0.3070646\n",
      "\tspeed: 0.0737s/iter; left time: 4955.4849s\n",
      "3399it [04:02, 14.23it/s]\titers: 3400, epoch: 2 | loss: 0.2999128\n",
      "\tspeed: 0.0698s/iter; left time: 4690.1686s\n",
      "3499it [04:09, 14.13it/s]\titers: 3500, epoch: 2 | loss: 0.3372339\n",
      "\tspeed: 0.0718s/iter; left time: 4814.2464s\n",
      "3599it [04:16, 14.14it/s]\titers: 3600, epoch: 2 | loss: 0.6030918\n",
      "\tspeed: 0.0716s/iter; left time: 4795.9377s\n",
      "3699it [04:23, 14.20it/s]\titers: 3700, epoch: 2 | loss: 0.2646025\n",
      "\tspeed: 0.0707s/iter; left time: 4723.7463s\n",
      "3713it [04:25, 14.01it/s]\n",
      "Epoch: 2 cost time: 265.0349464416504\n",
      "810it [00:27, 29.43it/s]\n",
      "807it [00:27, 29.71it/s]\n",
      "Epoch: 2 | Train Loss: 0.3255689 Vali Loss: 0.4044774 Test Loss: 0.4940924 MAE Loss: 0.4781854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0009755285\n",
      "99it [00:07, 14.27it/s]\titers: 100, epoch: 3 | loss: 0.2158741\n",
      "\tspeed: 0.6330s/iter; left time: 42244.4830s\n",
      "199it [00:14, 13.53it/s]\titers: 200, epoch: 3 | loss: 0.2994398\n",
      "\tspeed: 0.0705s/iter; left time: 4698.0326s\n",
      "299it [00:21, 14.14it/s]\titers: 300, epoch: 3 | loss: 0.2349110\n",
      "\tspeed: 0.0717s/iter; left time: 4768.9636s\n",
      "399it [00:28, 14.05it/s]\titers: 400, epoch: 3 | loss: 0.2036653\n",
      "\tspeed: 0.0706s/iter; left time: 4690.6742s\n",
      "499it [00:35, 14.13it/s]\titers: 500, epoch: 3 | loss: 0.2923087\n",
      "\tspeed: 0.0707s/iter; left time: 4690.2104s\n",
      "599it [00:42, 14.15it/s]\titers: 600, epoch: 3 | loss: 0.4084447\n",
      "\tspeed: 0.0712s/iter; left time: 4712.8124s\n",
      "699it [00:50, 12.74it/s]\titers: 700, epoch: 3 | loss: 0.2335312\n",
      "\tspeed: 0.0724s/iter; left time: 4788.3050s\n",
      "799it [00:57, 14.50it/s]\titers: 800, epoch: 3 | loss: 0.4835654\n",
      "\tspeed: 0.0722s/iter; left time: 4768.5624s\n",
      "899it [01:04, 14.12it/s]\titers: 900, epoch: 3 | loss: 0.2760869\n",
      "\tspeed: 0.0704s/iter; left time: 4642.4693s\n",
      "999it [01:11, 13.18it/s]\titers: 1000, epoch: 3 | loss: 0.3622765\n",
      "\tspeed: 0.0734s/iter; left time: 4830.9563s\n",
      "1099it [01:18, 16.18it/s]\titers: 1100, epoch: 3 | loss: 0.2895743\n",
      "\tspeed: 0.0665s/iter; left time: 4373.3885s\n",
      "1199it [01:25, 13.37it/s]\titers: 1200, epoch: 3 | loss: 0.2582735\n",
      "\tspeed: 0.0687s/iter; left time: 4506.4055s\n",
      "1299it [01:32, 14.18it/s]\titers: 1300, epoch: 3 | loss: 0.4120094\n",
      "\tspeed: 0.0713s/iter; left time: 4671.6275s\n",
      "1399it [01:39, 14.18it/s]\titers: 1400, epoch: 3 | loss: 0.2673759\n",
      "\tspeed: 0.0706s/iter; left time: 4620.8445s\n",
      "1499it [01:46, 13.65it/s]\titers: 1500, epoch: 3 | loss: 0.3413921\n",
      "\tspeed: 0.0709s/iter; left time: 4631.7181s\n",
      "1599it [01:53, 14.17it/s]\titers: 1600, epoch: 3 | loss: 0.5834995\n",
      "\tspeed: 0.0705s/iter; left time: 4601.8796s\n",
      "1699it [02:00, 13.88it/s]\titers: 1700, epoch: 3 | loss: 0.2681298\n",
      "\tspeed: 0.0740s/iter; left time: 4819.9182s\n",
      "1799it [02:07, 16.13it/s]\titers: 1800, epoch: 3 | loss: 0.3280468\n",
      "\tspeed: 0.0701s/iter; left time: 4557.3736s\n",
      "1899it [02:14, 14.26it/s]\titers: 1900, epoch: 3 | loss: 0.3379025\n",
      "\tspeed: 0.0676s/iter; left time: 4392.1088s\n",
      "1999it [02:21, 16.11it/s]\titers: 2000, epoch: 3 | loss: 0.2398708\n",
      "\tspeed: 0.0721s/iter; left time: 4673.8878s\n",
      "2099it [02:28, 13.96it/s]\titers: 2100, epoch: 3 | loss: 0.4052865\n",
      "\tspeed: 0.0700s/iter; left time: 4528.7827s\n",
      "2199it [02:36, 14.19it/s]\titers: 2200, epoch: 3 | loss: 0.4468919\n",
      "\tspeed: 0.0709s/iter; left time: 4585.3982s\n",
      "2299it [02:43, 13.72it/s]\titers: 2300, epoch: 3 | loss: 0.2328262\n",
      "\tspeed: 0.0717s/iter; left time: 4630.1345s\n",
      "2399it [02:50, 14.61it/s]\titers: 2400, epoch: 3 | loss: 0.4020664\n",
      "\tspeed: 0.0707s/iter; left time: 4558.1292s\n",
      "2499it [02:57, 13.58it/s]\titers: 2500, epoch: 3 | loss: 0.2348269\n",
      "\tspeed: 0.0713s/iter; left time: 4589.4890s\n",
      "2599it [03:04, 14.09it/s]\titers: 2600, epoch: 3 | loss: 0.1938243\n",
      "\tspeed: 0.0708s/iter; left time: 4550.5957s\n",
      "2699it [03:11, 13.46it/s]\titers: 2700, epoch: 3 | loss: 0.3673901\n",
      "\tspeed: 0.0721s/iter; left time: 4625.5976s\n",
      "2799it [03:18, 14.12it/s]\titers: 2800, epoch: 3 | loss: 0.2743841\n",
      "\tspeed: 0.0709s/iter; left time: 4542.2297s\n",
      "2899it [03:25, 14.06it/s]\titers: 2900, epoch: 3 | loss: 0.3674475\n",
      "\tspeed: 0.0705s/iter; left time: 4510.2430s\n",
      "2999it [03:33, 14.14it/s]\titers: 3000, epoch: 3 | loss: 0.4020359\n",
      "\tspeed: 0.0725s/iter; left time: 4628.6259s\n",
      "3099it [03:40, 14.18it/s]\titers: 3100, epoch: 3 | loss: 0.4316165\n",
      "\tspeed: 0.0704s/iter; left time: 4488.1587s\n",
      "3199it [03:47, 14.08it/s]\titers: 3200, epoch: 3 | loss: 0.2782803\n",
      "\tspeed: 0.0718s/iter; left time: 4566.5390s\n",
      "3299it [03:54, 13.96it/s]\titers: 3300, epoch: 3 | loss: 0.5212505\n",
      "\tspeed: 0.0716s/iter; left time: 4546.3564s\n",
      "3399it [04:01, 13.95it/s]\titers: 3400, epoch: 3 | loss: 0.4546598\n",
      "\tspeed: 0.0694s/iter; left time: 4401.6936s\n",
      "3499it [04:08, 14.20it/s]\titers: 3500, epoch: 3 | loss: 0.2816445\n",
      "\tspeed: 0.0742s/iter; left time: 4702.3578s\n",
      "3599it [04:15, 14.35it/s]\titers: 3600, epoch: 3 | loss: 0.3583716\n",
      "\tspeed: 0.0706s/iter; left time: 4467.0832s\n",
      "3699it [04:23, 12.67it/s]\titers: 3700, epoch: 3 | loss: 0.4355737\n",
      "\tspeed: 0.0743s/iter; left time: 4689.7929s\n",
      "3713it [04:24, 14.04it/s]\n",
      "Epoch: 3 cost time: 264.42951941490173\n",
      "810it [00:26, 30.54it/s]\n",
      "807it [00:27, 29.77it/s]\n",
      "Epoch: 3 | Train Loss: 0.3301399 Vali Loss: 0.4071151 Test Loss: 0.5216547 MAE Loss: 0.4878996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0009455038\n",
      "99it [00:06, 16.29it/s]\titers: 100, epoch: 4 | loss: 0.3422665\n",
      "\tspeed: 0.6166s/iter; left time: 38858.8373s\n",
      "199it [00:13, 14.23it/s]\titers: 200, epoch: 4 | loss: 0.3514585\n",
      "\tspeed: 0.0700s/iter; left time: 4402.7278s\n",
      "299it [00:21, 14.15it/s]\titers: 300, epoch: 4 | loss: 0.3818747\n",
      "\tspeed: 0.0716s/iter; left time: 4500.6906s\n",
      "399it [00:28, 13.77it/s]\titers: 400, epoch: 4 | loss: 0.2806220\n",
      "\tspeed: 0.0708s/iter; left time: 4442.0999s\n",
      "499it [00:35, 14.23it/s]\titers: 500, epoch: 4 | loss: 0.2576785\n",
      "\tspeed: 0.0729s/iter; left time: 4562.7243s\n",
      "599it [00:42, 14.16it/s]\titers: 600, epoch: 4 | loss: 0.3208332\n",
      "\tspeed: 0.0708s/iter; left time: 4424.0847s\n",
      "699it [00:49, 15.94it/s]\titers: 700, epoch: 4 | loss: 0.2212766\n",
      "\tspeed: 0.0687s/iter; left time: 4287.1163s\n",
      "799it [00:56, 14.16it/s]\titers: 800, epoch: 4 | loss: 0.4491027\n",
      "\tspeed: 0.0700s/iter; left time: 4363.6098s\n",
      "899it [01:03, 12.24it/s]\titers: 900, epoch: 4 | loss: 0.2682408\n",
      "\tspeed: 0.0728s/iter; left time: 4530.5636s\n",
      "999it [01:10, 14.11it/s]\titers: 1000, epoch: 4 | loss: 0.2410987\n",
      "\tspeed: 0.0723s/iter; left time: 4492.0098s\n",
      "1099it [01:17, 14.26it/s]\titers: 1100, epoch: 4 | loss: 0.3213558\n",
      "\tspeed: 0.0705s/iter; left time: 4375.5616s\n",
      "1199it [01:25, 13.83it/s]\titers: 1200, epoch: 4 | loss: 0.3673171\n",
      "\tspeed: 0.0739s/iter; left time: 4577.0001s\n",
      "1299it [01:32, 15.64it/s]\titers: 1300, epoch: 4 | loss: 0.4325978\n",
      "\tspeed: 0.0695s/iter; left time: 4297.8891s\n",
      "1399it [01:39, 14.11it/s]\titers: 1400, epoch: 4 | loss: 0.3647960\n",
      "\tspeed: 0.0731s/iter; left time: 4512.1389s\n",
      "1499it [01:46, 14.29it/s]\titers: 1500, epoch: 4 | loss: 0.3088050\n",
      "\tspeed: 0.0715s/iter; left time: 4408.7367s\n",
      "1599it [01:53, 14.59it/s]\titers: 1600, epoch: 4 | loss: 0.1894979\n",
      "\tspeed: 0.0702s/iter; left time: 4320.6656s\n",
      "1699it [02:01, 14.17it/s]\titers: 1700, epoch: 4 | loss: 0.3767528\n",
      "\tspeed: 0.0737s/iter; left time: 4526.6445s\n",
      "1799it [02:08, 14.11it/s]\titers: 1800, epoch: 4 | loss: 0.3783594\n",
      "\tspeed: 0.0705s/iter; left time: 4325.8765s\n",
      "1899it [02:15, 15.28it/s]\titers: 1900, epoch: 4 | loss: 0.2802714\n",
      "\tspeed: 0.0708s/iter; left time: 4335.7825s\n",
      "1999it [02:22, 14.18it/s]\titers: 2000, epoch: 4 | loss: 0.1866409\n",
      "\tspeed: 0.0711s/iter; left time: 4346.8655s\n",
      "2099it [02:29, 14.87it/s]\titers: 2100, epoch: 4 | loss: 0.2393479\n",
      "\tspeed: 0.0711s/iter; left time: 4338.5902s\n",
      "2199it [02:36, 14.33it/s]\titers: 2200, epoch: 4 | loss: 0.7834582\n",
      "\tspeed: 0.0740s/iter; left time: 4510.0663s\n",
      "2299it [02:43, 15.12it/s]\titers: 2300, epoch: 4 | loss: 0.3821228\n",
      "\tspeed: 0.0707s/iter; left time: 4300.8728s\n",
      "2399it [02:51, 14.14it/s]\titers: 2400, epoch: 4 | loss: 0.2741475\n",
      "\tspeed: 0.0709s/iter; left time: 4305.1271s\n",
      "2499it [02:58, 14.00it/s]\titers: 2500, epoch: 4 | loss: 0.1827663\n",
      "\tspeed: 0.0715s/iter; left time: 4331.6562s\n",
      "2599it [03:05, 14.15it/s]\titers: 2600, epoch: 4 | loss: 0.4768053\n",
      "\tspeed: 0.0692s/iter; left time: 4188.0802s\n",
      "2699it [03:12, 16.27it/s]\titers: 2700, epoch: 4 | loss: 0.5026925\n",
      "\tspeed: 0.0697s/iter; left time: 4213.0636s\n",
      "2799it [03:18, 14.12it/s]\titers: 2800, epoch: 4 | loss: 0.2714068\n",
      "\tspeed: 0.0688s/iter; left time: 4148.3590s\n",
      "2899it [03:26, 14.10it/s]\titers: 2900, epoch: 4 | loss: 0.3935429\n",
      "\tspeed: 0.0711s/iter; left time: 4279.8787s\n",
      "2999it [03:33, 14.07it/s]\titers: 3000, epoch: 4 | loss: 0.3613620\n",
      "\tspeed: 0.0755s/iter; left time: 4538.7040s\n",
      "3099it [03:40, 12.17it/s]\titers: 3100, epoch: 4 | loss: 0.2979709\n",
      "\tspeed: 0.0723s/iter; left time: 4338.7401s\n",
      "3199it [03:48, 14.10it/s]\titers: 3200, epoch: 4 | loss: 0.3801350\n",
      "\tspeed: 0.0756s/iter; left time: 4529.4220s\n",
      "3299it [03:55, 13.23it/s]\titers: 3300, epoch: 4 | loss: 0.1832873\n",
      "\tspeed: 0.0674s/iter; left time: 4033.1897s\n",
      "3399it [04:02, 12.51it/s]\titers: 3400, epoch: 4 | loss: 0.3181505\n",
      "\tspeed: 0.0745s/iter; left time: 4451.0548s\n",
      "3499it [04:09, 13.97it/s]\titers: 3500, epoch: 4 | loss: 0.2727686\n",
      "\tspeed: 0.0730s/iter; left time: 4351.9271s\n",
      "3599it [04:17, 14.25it/s]\titers: 3600, epoch: 4 | loss: 0.2692441\n",
      "\tspeed: 0.0718s/iter; left time: 4271.0512s\n",
      "3699it [04:24, 12.77it/s]\titers: 3700, epoch: 4 | loss: 0.3386483\n",
      "\tspeed: 0.0746s/iter; left time: 4433.0866s\n",
      "3713it [04:25, 13.98it/s]\n",
      "Epoch: 4 cost time: 265.6598780155182\n",
      "810it [00:26, 30.42it/s]\n",
      "807it [00:26, 29.99it/s]\n",
      "Epoch: 4 | Train Loss: 0.3307268 Vali Loss: 0.4089147 Test Loss: 0.5126240 MAE Loss: 0.4891933\n",
      "EarlyStopping counter: 3 out of 10\n",
      "lr = 0.0009045095\n",
      "99it [00:07, 13.38it/s]\titers: 100, epoch: 5 | loss: 0.2200186\n",
      "\tspeed: 0.6264s/iter; left time: 37151.5280s\n",
      "199it [00:15, 13.96it/s]\titers: 200, epoch: 5 | loss: 0.3128289\n",
      "\tspeed: 0.0759s/iter; left time: 4491.0090s\n",
      "299it [00:22, 14.11it/s]\titers: 300, epoch: 5 | loss: 0.3600637\n",
      "\tspeed: 0.0709s/iter; left time: 4193.7178s\n",
      "399it [00:29, 14.14it/s]\titers: 400, epoch: 5 | loss: 0.2711596\n",
      "\tspeed: 0.0716s/iter; left time: 4226.8659s\n",
      "499it [00:36, 14.06it/s]\titers: 500, epoch: 5 | loss: 0.3120309\n",
      "\tspeed: 0.0722s/iter; left time: 4251.9013s\n",
      "599it [00:44, 11.90it/s]\titers: 600, epoch: 5 | loss: 0.3725851\n",
      "\tspeed: 0.0736s/iter; left time: 4326.1998s\n",
      "699it [00:51, 13.34it/s]\titers: 700, epoch: 5 | loss: 0.2512808\n",
      "\tspeed: 0.0761s/iter; left time: 4465.3336s\n",
      "799it [00:59, 14.30it/s]\titers: 800, epoch: 5 | loss: 0.4038743\n",
      "\tspeed: 0.0725s/iter; left time: 4250.8212s\n",
      "899it [01:06, 13.15it/s]\titers: 900, epoch: 5 | loss: 0.2295453\n",
      "\tspeed: 0.0717s/iter; left time: 4194.2090s\n",
      "999it [01:13, 13.07it/s]\titers: 1000, epoch: 5 | loss: 0.2616349\n",
      "\tspeed: 0.0749s/iter; left time: 4377.5030s\n",
      "1099it [01:21, 14.08it/s]\titers: 1100, epoch: 5 | loss: 0.3075055\n",
      "\tspeed: 0.0731s/iter; left time: 4263.6396s\n",
      "1199it [01:28, 13.90it/s]\titers: 1200, epoch: 5 | loss: 0.2475507\n",
      "\tspeed: 0.0702s/iter; left time: 4085.7629s\n",
      "1299it [01:35, 14.09it/s]\titers: 1300, epoch: 5 | loss: 0.3084032\n",
      "\tspeed: 0.0730s/iter; left time: 4241.8795s\n",
      "1399it [01:42, 14.09it/s]\titers: 1400, epoch: 5 | loss: 0.3613304\n",
      "\tspeed: 0.0717s/iter; left time: 4160.3172s\n",
      "1499it [01:49, 15.05it/s]\titers: 1500, epoch: 5 | loss: 0.5281095\n",
      "\tspeed: 0.0700s/iter; left time: 4051.8204s\n",
      "1599it [01:56, 14.08it/s]\titers: 1600, epoch: 5 | loss: 0.3851665\n",
      "\tspeed: 0.0725s/iter; left time: 4190.1136s\n",
      "1699it [02:03, 14.12it/s]\titers: 1700, epoch: 5 | loss: 0.3251232\n",
      "\tspeed: 0.0705s/iter; left time: 4066.3305s\n",
      "1799it [02:11, 14.11it/s]\titers: 1800, epoch: 5 | loss: 0.3338038\n",
      "\tspeed: 0.0718s/iter; left time: 4138.6878s\n",
      "1899it [02:18, 14.19it/s]\titers: 1900, epoch: 5 | loss: 0.2854664\n",
      "\tspeed: 0.0719s/iter; left time: 4133.7278s\n",
      "1999it [02:25, 13.93it/s]\titers: 2000, epoch: 5 | loss: 0.3313590\n",
      "\tspeed: 0.0708s/iter; left time: 4065.8758s\n",
      "2099it [02:32, 14.69it/s]\titers: 2100, epoch: 5 | loss: 0.2955469\n",
      "\tspeed: 0.0719s/iter; left time: 4123.2720s\n",
      "2199it [02:39, 13.76it/s]\titers: 2200, epoch: 5 | loss: 0.2825411\n",
      "\tspeed: 0.0706s/iter; left time: 4036.2201s\n",
      "2299it [02:46, 11.50it/s]\titers: 2300, epoch: 5 | loss: 0.3070060\n",
      "\tspeed: 0.0702s/iter; left time: 4009.8286s\n",
      "2399it [02:53, 14.12it/s]\titers: 2400, epoch: 5 | loss: 0.3994337\n",
      "\tspeed: 0.0712s/iter; left time: 4056.6590s\n",
      "2499it [03:00, 13.57it/s]\titers: 2500, epoch: 5 | loss: 0.5860846\n",
      "\tspeed: 0.0714s/iter; left time: 4066.1314s\n",
      "2599it [03:08, 14.16it/s]\titers: 2600, epoch: 5 | loss: 0.2350308\n",
      "\tspeed: 0.0713s/iter; left time: 4052.0721s\n",
      "2699it [03:15, 14.20it/s]\titers: 2700, epoch: 5 | loss: 0.3490719\n",
      "\tspeed: 0.0702s/iter; left time: 3982.8872s\n",
      "2799it [03:22, 13.42it/s]\titers: 2800, epoch: 5 | loss: 0.1919007\n",
      "\tspeed: 0.0737s/iter; left time: 4174.8290s\n",
      "2899it [03:29, 14.04it/s]\titers: 2900, epoch: 5 | loss: 0.2227861\n",
      "\tspeed: 0.0690s/iter; left time: 3896.6402s\n",
      "2999it [03:36, 14.47it/s]\titers: 3000, epoch: 5 | loss: 0.6617911\n",
      "\tspeed: 0.0702s/iter; left time: 3959.7955s\n",
      "3099it [03:43, 13.89it/s]\titers: 3100, epoch: 5 | loss: 0.1727385\n",
      "\tspeed: 0.0718s/iter; left time: 4041.6040s\n",
      "3199it [03:50, 14.05it/s]\titers: 3200, epoch: 5 | loss: 0.5968987\n",
      "\tspeed: 0.0707s/iter; left time: 3973.5387s\n",
      "3299it [03:57, 15.94it/s]\titers: 3300, epoch: 5 | loss: 0.1983649\n",
      "\tspeed: 0.0713s/iter; left time: 3997.9511s\n",
      "3399it [04:04, 14.13it/s]\titers: 3400, epoch: 5 | loss: 0.2769464\n",
      "\tspeed: 0.0712s/iter; left time: 3989.1589s\n",
      "3499it [04:11, 13.16it/s]\titers: 3500, epoch: 5 | loss: 0.5170779\n",
      "\tspeed: 0.0716s/iter; left time: 4004.5365s\n",
      "3599it [04:19, 14.16it/s]\titers: 3600, epoch: 5 | loss: 0.3743671\n",
      "\tspeed: 0.0725s/iter; left time: 4043.8769s\n",
      "3699it [04:26, 14.10it/s]\titers: 3700, epoch: 5 | loss: 0.3560854\n",
      "\tspeed: 0.0701s/iter; left time: 3902.5343s\n",
      "3713it [04:27, 13.89it/s]\n",
      "Epoch: 5 cost time: 267.31482553482056\n",
      "810it [00:26, 30.03it/s]\n",
      "807it [00:26, 30.26it/s]\n",
      "Epoch: 5 | Train Loss: 0.3192967 Vali Loss: 0.3761173 Test Loss: 0.4595560 MAE Loss: 0.4551590\n",
      "lr = 0.0008535549\n",
      "99it [00:07, 14.19it/s]\titers: 100, epoch: 6 | loss: 0.1860293\n",
      "\tspeed: 0.6373s/iter; left time: 35429.9409s\n",
      "199it [00:14, 14.07it/s]\titers: 200, epoch: 6 | loss: 0.2454493\n",
      "\tspeed: 0.0705s/iter; left time: 3914.8299s\n",
      "299it [00:21, 14.16it/s]\titers: 300, epoch: 6 | loss: 0.3210287\n",
      "\tspeed: 0.0734s/iter; left time: 4066.0830s\n",
      "399it [00:28, 14.19it/s]\titers: 400, epoch: 6 | loss: 0.2927970\n",
      "\tspeed: 0.0699s/iter; left time: 3864.9611s\n",
      "499it [00:36, 14.13it/s]\titers: 500, epoch: 6 | loss: 0.2482518\n",
      "\tspeed: 0.0730s/iter; left time: 4029.6487s\n",
      "599it [00:43, 14.94it/s]\titers: 600, epoch: 6 | loss: 0.4101483\n",
      "\tspeed: 0.0712s/iter; left time: 3920.3870s\n",
      "699it [00:50, 12.12it/s]\titers: 700, epoch: 6 | loss: 0.3217023\n",
      "\tspeed: 0.0735s/iter; left time: 4039.7933s\n",
      "799it [00:57, 14.10it/s]\titers: 800, epoch: 6 | loss: 0.4144844\n",
      "\tspeed: 0.0725s/iter; left time: 3979.7865s\n",
      "899it [01:04, 14.10it/s]\titers: 900, epoch: 6 | loss: 0.2522916\n",
      "\tspeed: 0.0710s/iter; left time: 3891.6067s\n",
      "999it [01:12, 14.58it/s]\titers: 1000, epoch: 6 | loss: 0.4159895\n",
      "\tspeed: 0.0751s/iter; left time: 4107.3747s\n",
      "1099it [01:19, 14.03it/s]\titers: 1100, epoch: 6 | loss: 0.2766317\n",
      "\tspeed: 0.0702s/iter; left time: 3831.0945s\n",
      "1199it [01:26, 12.33it/s]\titers: 1200, epoch: 6 | loss: 0.2994572\n",
      "\tspeed: 0.0719s/iter; left time: 3919.0284s\n",
      "1299it [01:33, 14.14it/s]\titers: 1300, epoch: 6 | loss: 0.4543957\n",
      "\tspeed: 0.0718s/iter; left time: 3905.0724s\n",
      "1399it [01:40, 14.45it/s]\titers: 1400, epoch: 6 | loss: 0.2617683\n",
      "\tspeed: 0.0702s/iter; left time: 3812.9142s\n",
      "1499it [01:48, 14.19it/s]\titers: 1500, epoch: 6 | loss: 0.2228992\n",
      "\tspeed: 0.0735s/iter; left time: 3982.1452s\n",
      "1599it [01:55, 14.22it/s]\titers: 1600, epoch: 6 | loss: 0.1778523\n",
      "\tspeed: 0.0709s/iter; left time: 3833.4459s\n",
      "1699it [02:02, 13.00it/s]\titers: 1700, epoch: 6 | loss: 0.2138749\n",
      "\tspeed: 0.0733s/iter; left time: 3960.4102s\n",
      "1799it [02:10, 14.80it/s]\titers: 1800, epoch: 6 | loss: 0.2465591\n",
      "\tspeed: 0.0736s/iter; left time: 3968.9537s\n",
      "1899it [02:17, 13.15it/s]\titers: 1900, epoch: 6 | loss: 0.2328664\n",
      "\tspeed: 0.0726s/iter; left time: 3907.6928s\n",
      "1999it [02:25, 13.25it/s]\titers: 2000, epoch: 6 | loss: 0.2968273\n",
      "\tspeed: 0.0779s/iter; left time: 4181.1333s\n",
      "2099it [02:32, 14.12it/s]\titers: 2100, epoch: 6 | loss: 0.1951512\n",
      "\tspeed: 0.0745s/iter; left time: 3994.2988s\n",
      "2199it [02:40, 12.69it/s]\titers: 2200, epoch: 6 | loss: 0.4058631\n",
      "\tspeed: 0.0766s/iter; left time: 4099.4590s\n",
      "2299it [02:47, 14.11it/s]\titers: 2300, epoch: 6 | loss: 0.2320084\n",
      "\tspeed: 0.0708s/iter; left time: 3782.2742s\n",
      "2399it [02:54, 13.00it/s]\titers: 2400, epoch: 6 | loss: 0.2369453\n",
      "\tspeed: 0.0723s/iter; left time: 3855.8885s\n",
      "2499it [03:01, 14.31it/s]\titers: 2500, epoch: 6 | loss: 0.5147319\n",
      "\tspeed: 0.0717s/iter; left time: 3812.7344s\n",
      "2599it [03:08, 14.14it/s]\titers: 2600, epoch: 6 | loss: 0.4054409\n",
      "\tspeed: 0.0704s/iter; left time: 3735.4990s\n",
      "2699it [03:16, 14.14it/s]\titers: 2700, epoch: 6 | loss: 0.3702884\n",
      "\tspeed: 0.0735s/iter; left time: 3895.9390s\n",
      "2799it [03:23, 14.15it/s]\titers: 2800, epoch: 6 | loss: 0.1985116\n",
      "\tspeed: 0.0705s/iter; left time: 3731.3534s\n",
      "2899it [03:30, 14.07it/s]\titers: 2900, epoch: 6 | loss: 0.3785993\n",
      "\tspeed: 0.0725s/iter; left time: 3825.7130s\n",
      "2999it [03:37, 14.21it/s]\titers: 3000, epoch: 6 | loss: 0.3012078\n",
      "\tspeed: 0.0719s/iter; left time: 3786.9615s\n",
      "3099it [03:44, 12.83it/s]\titers: 3100, epoch: 6 | loss: 0.2047989\n",
      "\tspeed: 0.0711s/iter; left time: 3742.1866s\n",
      "3199it [03:51, 14.14it/s]\titers: 3200, epoch: 6 | loss: 0.2314112\n",
      "\tspeed: 0.0716s/iter; left time: 3757.7268s\n",
      "3299it [03:58, 14.12it/s]\titers: 3300, epoch: 6 | loss: 0.3803727\n",
      "\tspeed: 0.0701s/iter; left time: 3671.1715s\n",
      "3399it [04:06, 12.95it/s]\titers: 3400, epoch: 6 | loss: 0.3245858\n",
      "\tspeed: 0.0731s/iter; left time: 3824.8549s\n",
      "3499it [04:13, 14.37it/s]\titers: 3500, epoch: 6 | loss: 0.3491633\n",
      "\tspeed: 0.0705s/iter; left time: 3678.6578s\n",
      "3599it [04:20, 13.59it/s]\titers: 3600, epoch: 6 | loss: 0.2510218\n",
      "\tspeed: 0.0728s/iter; left time: 3792.3211s\n",
      "3699it [04:27, 14.76it/s]\titers: 3700, epoch: 6 | loss: 0.2699304\n",
      "\tspeed: 0.0715s/iter; left time: 3717.4258s\n",
      "3713it [04:28, 13.82it/s]\n",
      "Epoch: 6 cost time: 268.693071603775\n",
      "810it [00:26, 30.43it/s]\n",
      "807it [00:26, 30.25it/s]\n",
      "Epoch: 6 | Train Loss: 0.3218480 Vali Loss: 0.4051345 Test Loss: 0.5067619 MAE Loss: 0.4886023\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0007938947\n",
      "99it [00:07, 13.86it/s]\titers: 100, epoch: 7 | loss: 0.2478699\n",
      "\tspeed: 0.6198s/iter; left time: 32158.9321s\n",
      "199it [00:14, 14.10it/s]\titers: 200, epoch: 7 | loss: 0.4338553\n",
      "\tspeed: 0.0718s/iter; left time: 3719.3658s\n",
      "299it [00:21, 14.17it/s]\titers: 300, epoch: 7 | loss: 0.2661629\n",
      "\tspeed: 0.0705s/iter; left time: 3644.4657s\n",
      "399it [00:29, 13.76it/s]\titers: 400, epoch: 7 | loss: 0.3163179\n",
      "\tspeed: 0.0724s/iter; left time: 3733.0546s\n",
      "499it [00:36, 14.14it/s]\titers: 500, epoch: 7 | loss: 0.4007315\n",
      "\tspeed: 0.0712s/iter; left time: 3663.8397s\n",
      "599it [00:43, 14.00it/s]\titers: 600, epoch: 7 | loss: 0.2280969\n",
      "\tspeed: 0.0720s/iter; left time: 3699.5437s\n",
      "699it [00:50, 13.76it/s]\titers: 700, epoch: 7 | loss: 0.2925421\n",
      "\tspeed: 0.0718s/iter; left time: 3681.7702s\n",
      "799it [00:57, 15.59it/s]\titers: 800, epoch: 7 | loss: 0.2265948\n",
      "\tspeed: 0.0682s/iter; left time: 3489.6426s\n",
      "899it [01:04, 14.09it/s]\titers: 900, epoch: 7 | loss: 0.3741530\n",
      "\tspeed: 0.0719s/iter; left time: 3672.1621s\n",
      "999it [01:11, 14.14it/s]\titers: 1000, epoch: 7 | loss: 0.2658457\n",
      "\tspeed: 0.0702s/iter; left time: 3578.1585s\n",
      "1099it [01:18, 14.14it/s]\titers: 1100, epoch: 7 | loss: 0.3171934\n",
      "\tspeed: 0.0721s/iter; left time: 3667.3643s\n",
      "1199it [01:25, 14.33it/s]\titers: 1200, epoch: 7 | loss: 0.2551041\n",
      "\tspeed: 0.0703s/iter; left time: 3571.7648s\n",
      "1299it [01:32, 13.10it/s]\titers: 1300, epoch: 7 | loss: 0.5774506\n",
      "\tspeed: 0.0711s/iter; left time: 3604.6622s\n",
      "1399it [01:40, 14.09it/s]\titers: 1400, epoch: 7 | loss: 0.4140573\n",
      "\tspeed: 0.0731s/iter; left time: 3698.3644s\n",
      "1499it [01:47, 14.08it/s]\titers: 1500, epoch: 7 | loss: 0.4509597\n",
      "\tspeed: 0.0711s/iter; left time: 3589.5879s\n",
      "1599it [01:54, 14.60it/s]\titers: 1600, epoch: 7 | loss: 0.4527910\n",
      "\tspeed: 0.0693s/iter; left time: 3493.9320s\n",
      "1699it [02:01, 14.31it/s]\titers: 1700, epoch: 7 | loss: 0.2497097\n",
      "\tspeed: 0.0689s/iter; left time: 3466.6613s\n",
      "1799it [02:08, 11.98it/s]\titers: 1800, epoch: 7 | loss: 0.2073758\n",
      "\tspeed: 0.0725s/iter; left time: 3640.6730s\n",
      "1899it [02:15, 15.90it/s]\titers: 1900, epoch: 7 | loss: 0.3928856\n",
      "\tspeed: 0.0716s/iter; left time: 3588.0548s\n",
      "1999it [02:22, 14.40it/s]\titers: 2000, epoch: 7 | loss: 0.2590439\n",
      "\tspeed: 0.0646s/iter; left time: 3231.3398s\n",
      "2099it [02:28, 15.47it/s]\titers: 2100, epoch: 7 | loss: 0.2495854\n",
      "\tspeed: 0.0675s/iter; left time: 3366.2429s\n",
      "2199it [02:35, 14.14it/s]\titers: 2200, epoch: 7 | loss: 0.2702341\n",
      "\tspeed: 0.0707s/iter; left time: 3518.3920s\n",
      "2299it [02:42, 14.77it/s]\titers: 2300, epoch: 7 | loss: 0.3073743\n",
      "\tspeed: 0.0689s/iter; left time: 3420.9966s\n",
      "2399it [02:49, 14.12it/s]\titers: 2400, epoch: 7 | loss: 0.2895714\n",
      "\tspeed: 0.0724s/iter; left time: 3588.7822s\n",
      "2499it [02:56, 15.85it/s]\titers: 2500, epoch: 7 | loss: 0.3369277\n",
      "\tspeed: 0.0682s/iter; left time: 3375.1814s\n",
      "2599it [03:03, 15.99it/s]\titers: 2600, epoch: 7 | loss: 0.3677252\n",
      "\tspeed: 0.0701s/iter; left time: 3462.5944s\n",
      "2699it [03:10, 14.16it/s]\titers: 2700, epoch: 7 | loss: 0.1809392\n",
      "\tspeed: 0.0652s/iter; left time: 3213.1562s\n",
      "2799it [03:17, 14.01it/s]\titers: 2800, epoch: 7 | loss: 0.3356314\n",
      "\tspeed: 0.0712s/iter; left time: 3499.9747s\n",
      "2899it [03:24, 13.68it/s]\titers: 2900, epoch: 7 | loss: 0.2481166\n",
      "\tspeed: 0.0678s/iter; left time: 3328.5903s\n",
      "2999it [03:31, 14.56it/s]\titers: 3000, epoch: 7 | loss: 0.6404238\n",
      "\tspeed: 0.0680s/iter; left time: 3331.7002s\n",
      "3099it [03:38, 14.00it/s]\titers: 3100, epoch: 7 | loss: 0.2369842\n",
      "\tspeed: 0.0706s/iter; left time: 3450.9935s\n",
      "3199it [03:45, 14.30it/s]\titers: 3200, epoch: 7 | loss: 0.3639956\n",
      "\tspeed: 0.0714s/iter; left time: 3482.1464s\n",
      "3299it [03:52, 14.12it/s]\titers: 3300, epoch: 7 | loss: 0.5726178\n",
      "\tspeed: 0.0679s/iter; left time: 3305.6712s\n",
      "3399it [03:59, 13.59it/s]\titers: 3400, epoch: 7 | loss: 0.2654776\n",
      "\tspeed: 0.0730s/iter; left time: 3548.6674s\n",
      "3499it [04:06, 14.11it/s]\titers: 3500, epoch: 7 | loss: 0.4411390\n",
      "\tspeed: 0.0707s/iter; left time: 3429.8538s\n",
      "3599it [04:13, 14.10it/s]\titers: 3600, epoch: 7 | loss: 0.2713261\n",
      "\tspeed: 0.0711s/iter; left time: 3440.7764s\n",
      "3699it [04:20, 14.75it/s]\titers: 3700, epoch: 7 | loss: 0.2794026\n",
      "\tspeed: 0.0714s/iter; left time: 3449.5770s\n",
      "3713it [04:21, 14.19it/s]\n",
      "Epoch: 7 cost time: 261.6957426071167\n",
      "810it [00:26, 30.49it/s]\n",
      "807it [00:27, 29.89it/s]\n",
      "Epoch: 7 | Train Loss: 0.3176838 Vali Loss: 0.3900327 Test Loss: 0.4882854 MAE Loss: 0.4639982\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr = 0.0007269980\n",
      "99it [00:07, 12.64it/s]\titers: 100, epoch: 8 | loss: 0.5770047\n",
      "\tspeed: 0.6220s/iter; left time: 29959.8957s\n",
      "199it [00:14, 14.15it/s]\titers: 200, epoch: 8 | loss: 0.3267495\n",
      "\tspeed: 0.0707s/iter; left time: 3400.4030s\n",
      "299it [00:21, 14.22it/s]\titers: 300, epoch: 8 | loss: 0.1608692\n",
      "\tspeed: 0.0662s/iter; left time: 3176.8439s\n",
      "399it [00:28, 13.74it/s]\titers: 400, epoch: 8 | loss: 0.3844922\n",
      "\tspeed: 0.0727s/iter; left time: 3481.4675s\n",
      "499it [00:35, 14.03it/s]\titers: 500, epoch: 8 | loss: 0.2413089\n",
      "\tspeed: 0.0684s/iter; left time: 3268.0623s\n",
      "599it [00:42, 13.13it/s]\titers: 600, epoch: 8 | loss: 0.3362294\n",
      "\tspeed: 0.0715s/iter; left time: 3408.0008s\n",
      "699it [00:49, 13.21it/s]\titers: 700, epoch: 8 | loss: 0.1503156\n",
      "\tspeed: 0.0720s/iter; left time: 3427.1033s\n",
      "799it [00:56, 14.03it/s]\titers: 800, epoch: 8 | loss: 0.3333311\n",
      "\tspeed: 0.0692s/iter; left time: 3286.9807s\n",
      "899it [01:03, 14.17it/s]\titers: 900, epoch: 8 | loss: 0.4224862\n",
      "\tspeed: 0.0720s/iter; left time: 3411.0513s\n",
      "999it [01:11, 13.30it/s]\titers: 1000, epoch: 8 | loss: 0.3393056\n",
      "\tspeed: 0.0738s/iter; left time: 3488.9897s\n",
      "1099it [01:18, 14.07it/s]\titers: 1100, epoch: 8 | loss: 0.2967793\n",
      "\tspeed: 0.0721s/iter; left time: 3400.2359s\n",
      "1199it [01:25, 13.72it/s]\titers: 1200, epoch: 8 | loss: 0.6526562\n",
      "\tspeed: 0.0728s/iter; left time: 3428.6160s\n",
      "1299it [01:32, 14.10it/s]\titers: 1300, epoch: 8 | loss: 0.7756191\n",
      "\tspeed: 0.0720s/iter; left time: 3380.1344s\n",
      "1399it [01:40, 14.11it/s]\titers: 1400, epoch: 8 | loss: 0.2002395\n",
      "\tspeed: 0.0715s/iter; left time: 3351.6458s\n",
      "1499it [01:47, 15.62it/s]\titers: 1500, epoch: 8 | loss: 0.4000432\n",
      "\tspeed: 0.0711s/iter; left time: 3326.9779s\n",
      "1599it [01:54, 13.62it/s]\titers: 1600, epoch: 8 | loss: 0.2911925\n",
      "\tspeed: 0.0702s/iter; left time: 3278.4588s\n",
      "1699it [02:01, 14.02it/s]\titers: 1700, epoch: 8 | loss: 0.2495515\n",
      "\tspeed: 0.0720s/iter; left time: 3352.5311s\n",
      "1799it [02:08, 14.20it/s]\titers: 1800, epoch: 8 | loss: 0.2866145\n",
      "\tspeed: 0.0704s/iter; left time: 3270.4524s\n",
      "1899it [02:15, 14.06it/s]\titers: 1900, epoch: 8 | loss: 0.2690101\n",
      "\tspeed: 0.0716s/iter; left time: 3319.6581s\n",
      "1999it [02:22, 14.19it/s]\titers: 2000, epoch: 8 | loss: 0.2248492\n",
      "\tspeed: 0.0718s/iter; left time: 3320.2415s\n",
      "2099it [02:29, 14.52it/s]\titers: 2100, epoch: 8 | loss: 0.5944342\n",
      "\tspeed: 0.0699s/iter; left time: 3229.3515s\n",
      "2199it [02:36, 14.12it/s]\titers: 2200, epoch: 8 | loss: 0.2263105\n",
      "\tspeed: 0.0706s/iter; left time: 3251.6026s\n",
      "2299it [02:43, 14.16it/s]\titers: 2300, epoch: 8 | loss: 0.2574092\n",
      "\tspeed: 0.0700s/iter; left time: 3219.5631s\n",
      "2399it [02:50, 12.79it/s]\titers: 2400, epoch: 8 | loss: 0.3529392\n",
      "\tspeed: 0.0721s/iter; left time: 3305.0570s\n",
      "2499it [02:58, 14.12it/s]\titers: 2500, epoch: 8 | loss: 0.2122550\n",
      "\tspeed: 0.0711s/iter; left time: 3253.7079s\n",
      "2599it [03:05, 12.68it/s]\titers: 2600, epoch: 8 | loss: 0.2878301\n",
      "\tspeed: 0.0720s/iter; left time: 3290.1310s\n",
      "2699it [03:12, 14.10it/s]\titers: 2700, epoch: 8 | loss: 0.3256881\n",
      "\tspeed: 0.0719s/iter; left time: 3276.4107s\n",
      "2799it [03:19, 14.20it/s]\titers: 2800, epoch: 8 | loss: 0.2976313\n",
      "\tspeed: 0.0706s/iter; left time: 3208.3851s\n",
      "2899it [03:26, 13.34it/s]\titers: 2900, epoch: 8 | loss: 0.3020608\n",
      "\tspeed: 0.0726s/iter; left time: 3292.8836s\n",
      "2999it [03:33, 14.03it/s]\titers: 3000, epoch: 8 | loss: 0.6040528\n",
      "\tspeed: 0.0717s/iter; left time: 3244.1567s\n",
      "3099it [03:41, 13.97it/s]\titers: 3100, epoch: 8 | loss: 0.4602436\n",
      "\tspeed: 0.0710s/iter; left time: 3206.0016s\n",
      "3199it [03:48, 14.13it/s]\titers: 3200, epoch: 8 | loss: 0.2723779\n",
      "\tspeed: 0.0736s/iter; left time: 3318.8349s\n",
      "3299it [03:55, 14.38it/s]\titers: 3300, epoch: 8 | loss: 0.3347049\n",
      "\tspeed: 0.0704s/iter; left time: 3165.4586s\n",
      "3399it [04:02, 13.56it/s]\titers: 3400, epoch: 8 | loss: 0.3249944\n",
      "\tspeed: 0.0711s/iter; left time: 3188.7205s\n",
      "3499it [04:09, 14.12it/s]\titers: 3500, epoch: 8 | loss: 0.3546934\n",
      "\tspeed: 0.0725s/iter; left time: 3243.6312s\n",
      "3599it [04:16, 14.16it/s]\titers: 3600, epoch: 8 | loss: 0.2438684\n",
      "\tspeed: 0.0705s/iter; left time: 3149.8152s\n",
      "3699it [04:24, 14.18it/s]\titers: 3700, epoch: 8 | loss: 0.5086076\n",
      "\tspeed: 0.0724s/iter; left time: 3226.2807s\n",
      "3713it [04:25, 14.00it/s]\n",
      "Epoch: 8 cost time: 265.24969029426575\n",
      "810it [00:27, 29.85it/s]\n",
      "807it [00:26, 30.13it/s]\n",
      "Epoch: 8 | Train Loss: 0.3167600 Vali Loss: 0.3786555 Test Loss: 0.4712922 MAE Loss: 0.4615780\n",
      "EarlyStopping counter: 3 out of 10\n",
      "lr = 0.0006545120\n",
      "99it [00:07, 14.45it/s]\titers: 100, epoch: 9 | loss: 0.2055838\n",
      "\tspeed: 0.6250s/iter; left time: 27783.7068s\n",
      "199it [00:14, 14.00it/s]\titers: 200, epoch: 9 | loss: 0.4382360\n",
      "\tspeed: 0.0715s/iter; left time: 3172.5954s\n",
      "299it [00:21, 14.00it/s]\titers: 300, epoch: 9 | loss: 0.2477795\n",
      "\tspeed: 0.0713s/iter; left time: 3153.8063s\n",
      "399it [00:28, 14.39it/s]\titers: 400, epoch: 9 | loss: 0.2436704\n",
      "\tspeed: 0.0701s/iter; left time: 3094.1295s\n",
      "499it [00:35, 13.89it/s]\titers: 500, epoch: 9 | loss: 0.2715870\n",
      "\tspeed: 0.0726s/iter; left time: 3197.9471s\n",
      "599it [00:42, 14.09it/s]\titers: 600, epoch: 9 | loss: 0.2231630\n",
      "\tspeed: 0.0704s/iter; left time: 3093.7989s\n",
      "699it [00:50, 14.12it/s]\titers: 700, epoch: 9 | loss: 0.1860436\n",
      "\tspeed: 0.0719s/iter; left time: 3153.8865s\n",
      "799it [00:57, 14.24it/s]\titers: 800, epoch: 9 | loss: 0.3048641\n",
      "\tspeed: 0.0712s/iter; left time: 3113.5801s\n",
      "899it [01:04, 13.23it/s]\titers: 900, epoch: 9 | loss: 0.2116062\n",
      "\tspeed: 0.0710s/iter; left time: 3098.2645s\n",
      "999it [01:11, 14.11it/s]\titers: 1000, epoch: 9 | loss: 0.4252240\n",
      "\tspeed: 0.0726s/iter; left time: 3163.7562s\n",
      "1099it [01:18, 14.15it/s]\titers: 1100, epoch: 9 | loss: 0.3475896\n",
      "\tspeed: 0.0705s/iter; left time: 3064.3892s\n",
      "1199it [01:25, 12.35it/s]\titers: 1200, epoch: 9 | loss: 0.2482909\n",
      "\tspeed: 0.0729s/iter; left time: 3160.3898s\n",
      "1299it [01:33, 14.62it/s]\titers: 1300, epoch: 9 | loss: 0.3578586\n",
      "\tspeed: 0.0709s/iter; left time: 3067.9247s\n",
      "1399it [01:40, 14.09it/s]\titers: 1400, epoch: 9 | loss: 0.5017953\n",
      "\tspeed: 0.0724s/iter; left time: 3125.9325s\n",
      "1499it [01:47, 14.14it/s]\titers: 1500, epoch: 9 | loss: 0.2505350\n",
      "\tspeed: 0.0717s/iter; left time: 3086.7532s\n",
      "1599it [01:54, 13.19it/s]\titers: 1600, epoch: 9 | loss: 0.3136218\n",
      "\tspeed: 0.0713s/iter; left time: 3064.3773s\n",
      "1699it [02:02, 13.12it/s]\titers: 1700, epoch: 9 | loss: 0.2684740\n",
      "\tspeed: 0.0746s/iter; left time: 3197.8552s\n",
      "1799it [02:09, 14.09it/s]\titers: 1800, epoch: 9 | loss: 0.2982276\n",
      "\tspeed: 0.0706s/iter; left time: 3017.1105s\n",
      "1899it [02:16, 13.38it/s]\titers: 1900, epoch: 9 | loss: 0.6690124\n",
      "\tspeed: 0.0711s/iter; left time: 3030.8845s\n",
      "1999it [02:23, 13.25it/s]\titers: 2000, epoch: 9 | loss: 0.3351339\n",
      "\tspeed: 0.0705s/iter; left time: 2999.7427s\n",
      "2099it [02:30, 13.80it/s]\titers: 2100, epoch: 9 | loss: 0.2604609\n",
      "\tspeed: 0.0708s/iter; left time: 3004.0921s\n",
      "2199it [02:37, 13.60it/s]\titers: 2200, epoch: 9 | loss: 0.3689049\n",
      "\tspeed: 0.0727s/iter; left time: 3078.5910s\n",
      "2299it [02:44, 14.16it/s]\titers: 2300, epoch: 9 | loss: 0.3088582\n",
      "\tspeed: 0.0708s/iter; left time: 2993.2270s\n",
      "2399it [02:51, 13.38it/s]\titers: 2400, epoch: 9 | loss: 0.3777398\n",
      "\tspeed: 0.0716s/iter; left time: 3017.0458s\n",
      "2499it [02:59, 14.16it/s]\titers: 2500, epoch: 9 | loss: 0.2721376\n",
      "\tspeed: 0.0721s/iter; left time: 3033.5271s\n",
      "2599it [03:06, 13.89it/s]\titers: 2600, epoch: 9 | loss: 0.3252808\n",
      "\tspeed: 0.0709s/iter; left time: 2976.0346s\n",
      "2699it [03:13, 14.24it/s]\titers: 2700, epoch: 9 | loss: 0.3464783\n",
      "\tspeed: 0.0716s/iter; left time: 2995.9078s\n",
      "2799it [03:20, 14.17it/s]\titers: 2800, epoch: 9 | loss: 0.2026952\n",
      "\tspeed: 0.0715s/iter; left time: 2987.6863s\n",
      "2899it [03:27, 13.52it/s]\titers: 2900, epoch: 9 | loss: 0.3048419\n",
      "\tspeed: 0.0711s/iter; left time: 2961.1921s\n",
      "2999it [03:34, 14.10it/s]\titers: 3000, epoch: 9 | loss: 0.3719063\n",
      "\tspeed: 0.0731s/iter; left time: 3038.8357s\n",
      "3099it [03:42, 13.86it/s]\titers: 3100, epoch: 9 | loss: 0.6094643\n",
      "\tspeed: 0.0752s/iter; left time: 3117.3929s\n",
      "3199it [03:49, 14.16it/s]\titers: 3200, epoch: 9 | loss: 0.2338102\n",
      "\tspeed: 0.0713s/iter; left time: 2948.5991s\n",
      "3299it [03:56, 14.15it/s]\titers: 3300, epoch: 9 | loss: 0.3370678\n",
      "\tspeed: 0.0714s/iter; left time: 2946.8397s\n",
      "3399it [04:03, 13.65it/s]\titers: 3400, epoch: 9 | loss: 0.2784171\n",
      "\tspeed: 0.0708s/iter; left time: 2912.8042s\n",
      "3499it [04:10, 14.17it/s]\titers: 3500, epoch: 9 | loss: 0.4160938\n",
      "\tspeed: 0.0717s/iter; left time: 2944.9028s\n",
      "3599it [04:18, 14.12it/s]\titers: 3600, epoch: 9 | loss: 0.1992202\n",
      "\tspeed: 0.0709s/iter; left time: 2905.4227s\n",
      "3699it [04:25, 14.16it/s]\titers: 3700, epoch: 9 | loss: 0.1777645\n",
      "\tspeed: 0.0718s/iter; left time: 2934.4138s\n",
      "3713it [04:26, 13.94it/s]\n",
      "Epoch: 9 cost time: 266.3497133255005\n",
      "810it [00:26, 30.64it/s]\n",
      "807it [00:26, 30.14it/s]\n",
      "Epoch: 9 | Train Loss: 0.3193015 Vali Loss: 0.3908932 Test Loss: 0.4891208 MAE Loss: 0.4701705\n",
      "EarlyStopping counter: 4 out of 10\n",
      "lr = 0.0005782215\n",
      "99it [00:07, 14.83it/s]\titers: 100, epoch: 10 | loss: 0.6328828\n",
      "\tspeed: 0.6179s/iter; left time: 25176.3457s\n",
      "199it [00:14, 14.11it/s]\titers: 200, epoch: 10 | loss: 0.2557484\n",
      "\tspeed: 0.0715s/iter; left time: 2906.3487s\n",
      "299it [00:21, 14.13it/s]\titers: 300, epoch: 10 | loss: 0.3946822\n",
      "\tspeed: 0.0717s/iter; left time: 2908.3313s\n",
      "399it [00:28, 14.32it/s]\titers: 400, epoch: 10 | loss: 0.2857973\n",
      "\tspeed: 0.0705s/iter; left time: 2850.9153s\n",
      "499it [00:35, 14.05it/s]\titers: 500, epoch: 10 | loss: 0.2762298\n",
      "\tspeed: 0.0725s/iter; left time: 2924.3895s\n",
      "599it [00:43, 14.13it/s]\titers: 600, epoch: 10 | loss: 0.2609059\n",
      "\tspeed: 0.0707s/iter; left time: 2843.4045s\n",
      "699it [00:50, 14.23it/s]\titers: 700, epoch: 10 | loss: 0.5183377\n",
      "\tspeed: 0.0713s/iter; left time: 2862.1845s\n",
      "799it [00:57, 14.93it/s]\titers: 800, epoch: 10 | loss: 0.3327874\n",
      "\tspeed: 0.0700s/iter; left time: 2802.5244s\n",
      "899it [01:04, 14.09it/s]\titers: 900, epoch: 10 | loss: 0.2915243\n",
      "\tspeed: 0.0688s/iter; left time: 2747.7177s\n",
      "999it [01:11, 14.09it/s]\titers: 1000, epoch: 10 | loss: 0.4116774\n",
      "\tspeed: 0.0731s/iter; left time: 2913.7742s\n",
      "1099it [01:18, 14.77it/s]\titers: 1100, epoch: 10 | loss: 0.3381758\n",
      "\tspeed: 0.0701s/iter; left time: 2788.0224s\n",
      "1199it [01:25, 13.17it/s]\titers: 1200, epoch: 10 | loss: 0.4430414\n",
      "\tspeed: 0.0754s/iter; left time: 2990.5337s\n",
      "1299it [01:33, 13.36it/s]\titers: 1300, epoch: 10 | loss: 0.3568830\n",
      "\tspeed: 0.0726s/iter; left time: 2872.6648s\n",
      "1399it [01:41, 10.96it/s]\titers: 1400, epoch: 10 | loss: 0.3547076\n",
      "\tspeed: 0.0786s/iter; left time: 3099.6525s\n",
      "1499it [01:48, 14.06it/s]\titers: 1500, epoch: 10 | loss: 0.3370391\n",
      "\tspeed: 0.0720s/iter; left time: 2831.3749s\n",
      "1599it [01:55, 14.11it/s]\titers: 1600, epoch: 10 | loss: 0.5297878\n",
      "\tspeed: 0.0708s/iter; left time: 2778.9718s\n",
      "1699it [02:02, 13.25it/s]\titers: 1700, epoch: 10 | loss: 0.3545569\n",
      "\tspeed: 0.0763s/iter; left time: 2985.1371s\n",
      "1799it [02:10, 14.17it/s]\titers: 1800, epoch: 10 | loss: 0.3164133\n",
      "\tspeed: 0.0727s/iter; left time: 2840.0181s\n",
      "1899it [02:17, 13.23it/s]\titers: 1900, epoch: 10 | loss: 0.1621146\n",
      "\tspeed: 0.0752s/iter; left time: 2928.9422s\n",
      "1999it [02:25, 13.42it/s]\titers: 2000, epoch: 10 | loss: 0.3638330\n",
      "\tspeed: 0.0762s/iter; left time: 2959.0439s\n",
      "2099it [02:32, 11.10it/s]\titers: 2100, epoch: 10 | loss: 0.3622330\n",
      "\tspeed: 0.0729s/iter; left time: 2824.3133s\n",
      "2199it [02:40, 13.42it/s]\titers: 2200, epoch: 10 | loss: 0.3698464\n",
      "\tspeed: 0.0773s/iter; left time: 2987.4829s\n",
      "2299it [02:47, 13.21it/s]\titers: 2300, epoch: 10 | loss: 0.2250059\n",
      "\tspeed: 0.0684s/iter; left time: 2634.7856s\n",
      "2399it [02:54, 14.14it/s]\titers: 2400, epoch: 10 | loss: 0.2350701\n",
      "\tspeed: 0.0711s/iter; left time: 2732.8648s\n",
      "2499it [03:01, 14.17it/s]\titers: 2500, epoch: 10 | loss: 0.3937078\n",
      "\tspeed: 0.0718s/iter; left time: 2752.2378s\n",
      "2599it [03:08, 13.33it/s]\titers: 2600, epoch: 10 | loss: 0.2359046\n",
      "\tspeed: 0.0713s/iter; left time: 2724.9641s\n",
      "2699it [03:15, 14.42it/s]\titers: 2700, epoch: 10 | loss: 0.2048412\n",
      "\tspeed: 0.0714s/iter; left time: 2724.0245s\n",
      "2799it [03:22, 15.42it/s]\titers: 2800, epoch: 10 | loss: 0.2506647\n",
      "\tspeed: 0.0694s/iter; left time: 2642.0220s\n",
      "2899it [03:29, 12.13it/s]\titers: 2900, epoch: 10 | loss: 0.4791837\n",
      "\tspeed: 0.0723s/iter; left time: 2741.8931s\n",
      "2999it [03:37, 14.15it/s]\titers: 3000, epoch: 10 | loss: 0.4039135\n",
      "\tspeed: 0.0705s/iter; left time: 2668.5627s\n",
      "3099it [03:44, 13.08it/s]\titers: 3100, epoch: 10 | loss: 0.1761593\n",
      "\tspeed: 0.0714s/iter; left time: 2695.0147s\n",
      "3199it [03:51, 14.18it/s]\titers: 3200, epoch: 10 | loss: 0.1721474\n",
      "\tspeed: 0.0717s/iter; left time: 2700.8959s\n",
      "3299it [03:58, 14.16it/s]\titers: 3300, epoch: 10 | loss: 0.3097329\n",
      "\tspeed: 0.0707s/iter; left time: 2654.4925s\n",
      "3399it [04:05, 13.42it/s]\titers: 3400, epoch: 10 | loss: 0.5163501\n",
      "\tspeed: 0.0699s/iter; left time: 2617.2819s\n",
      "3499it [04:12, 14.15it/s]\titers: 3500, epoch: 10 | loss: 0.2257713\n",
      "\tspeed: 0.0699s/iter; left time: 2608.6481s\n",
      "3599it [04:19, 12.54it/s]\titers: 3600, epoch: 10 | loss: 0.3606421\n",
      "\tspeed: 0.0714s/iter; left time: 2658.4921s\n",
      "3699it [04:26, 13.97it/s]\titers: 3700, epoch: 10 | loss: 0.3611962\n",
      "\tspeed: 0.0747s/iter; left time: 2776.3617s\n",
      "3713it [04:28, 13.85it/s]\n",
      "Epoch: 10 cost time: 268.0211503505707\n",
      "810it [00:26, 30.14it/s]\n",
      "807it [00:26, 30.21it/s]\n",
      "Epoch: 10 | Train Loss: 0.3041269 Vali Loss: 0.3780959 Test Loss: 0.4662771 MAE Loss: 0.4537774\n",
      "EarlyStopping counter: 5 out of 10\n",
      "lr = 0.0005000050\n",
      "99it [00:07, 12.95it/s]\titers: 100, epoch: 11 | loss: 0.2315817\n",
      "\tspeed: 0.6202s/iter; left time: 22968.3211s\n",
      "199it [00:14, 14.25it/s]\titers: 200, epoch: 11 | loss: 0.3358840\n",
      "\tspeed: 0.0717s/iter; left time: 2649.3456s\n",
      "299it [00:21, 16.01it/s]\titers: 300, epoch: 11 | loss: 0.2364494\n",
      "\tspeed: 0.0663s/iter; left time: 2441.9352s\n",
      "399it [00:27, 14.18it/s]\titers: 400, epoch: 11 | loss: 0.4483358\n",
      "\tspeed: 0.0679s/iter; left time: 2494.9273s\n",
      "499it [00:34, 14.12it/s]\titers: 500, epoch: 11 | loss: 0.3491395\n",
      "\tspeed: 0.0703s/iter; left time: 2576.8821s\n",
      "599it [00:42, 14.16it/s]\titers: 600, epoch: 11 | loss: 0.2113983\n",
      "\tspeed: 0.0708s/iter; left time: 2584.9807s\n",
      "699it [00:49, 14.18it/s]\titers: 700, epoch: 11 | loss: 0.2449994\n",
      "\tspeed: 0.0735s/iter; left time: 2677.7167s\n",
      "799it [00:56, 14.20it/s]\titers: 800, epoch: 11 | loss: 0.4927401\n",
      "\tspeed: 0.0705s/iter; left time: 2563.1043s\n",
      "899it [01:03, 13.84it/s]\titers: 900, epoch: 11 | loss: 0.2359479\n",
      "\tspeed: 0.0715s/iter; left time: 2591.3214s\n",
      "999it [01:10, 13.97it/s]\titers: 1000, epoch: 11 | loss: 0.2809621\n",
      "\tspeed: 0.0711s/iter; left time: 2569.3585s\n",
      "1099it [01:17, 12.64it/s]\titers: 1100, epoch: 11 | loss: 0.2099049\n",
      "\tspeed: 0.0726s/iter; left time: 2614.8144s\n",
      "1199it [01:25, 14.26it/s]\titers: 1200, epoch: 11 | loss: 0.2824244\n",
      "\tspeed: 0.0721s/iter; left time: 2590.8751s\n",
      "1299it [01:32, 14.15it/s]\titers: 1300, epoch: 11 | loss: 0.1849677\n",
      "\tspeed: 0.0706s/iter; left time: 2529.4055s\n",
      "1399it [01:39, 14.38it/s]\titers: 1400, epoch: 11 | loss: 0.2756193\n",
      "\tspeed: 0.0713s/iter; left time: 2548.0961s\n",
      "1499it [01:46, 14.77it/s]\titers: 1500, epoch: 11 | loss: 0.2333716\n",
      "\tspeed: 0.0711s/iter; left time: 2534.4682s\n",
      "1599it [01:53, 13.04it/s]\titers: 1600, epoch: 11 | loss: 0.2342457\n",
      "\tspeed: 0.0704s/iter; left time: 2501.8235s\n",
      "1699it [02:00, 14.14it/s]\titers: 1700, epoch: 11 | loss: 0.4024353\n",
      "\tspeed: 0.0719s/iter; left time: 2546.4560s\n",
      "1799it [02:07, 14.12it/s]\titers: 1800, epoch: 11 | loss: 0.3037993\n",
      "\tspeed: 0.0709s/iter; left time: 2504.2494s\n",
      "1899it [02:14, 14.06it/s]\titers: 1900, epoch: 11 | loss: 0.3815071\n",
      "\tspeed: 0.0723s/iter; left time: 2547.8257s\n",
      "1999it [02:22, 14.12it/s]\titers: 2000, epoch: 11 | loss: 0.2112320\n",
      "\tspeed: 0.0715s/iter; left time: 2510.9753s\n",
      "2099it [02:29, 13.47it/s]\titers: 2100, epoch: 11 | loss: 0.1788025\n",
      "\tspeed: 0.0715s/iter; left time: 2506.0588s\n",
      "2199it [02:36, 13.84it/s]\titers: 2200, epoch: 11 | loss: 0.1849326\n",
      "\tspeed: 0.0717s/iter; left time: 2503.0087s\n",
      "2299it [02:43, 14.15it/s]\titers: 2300, epoch: 11 | loss: 0.3742796\n",
      "\tspeed: 0.0706s/iter; left time: 2459.7960s\n",
      "2399it [02:50, 13.52it/s]\titers: 2400, epoch: 11 | loss: 0.3149775\n",
      "\tspeed: 0.0735s/iter; left time: 2554.2686s\n",
      "2499it [02:57, 14.86it/s]\titers: 2500, epoch: 11 | loss: 0.1865861\n",
      "\tspeed: 0.0692s/iter; left time: 2398.1694s\n",
      "2599it [03:04, 13.85it/s]\titers: 2600, epoch: 11 | loss: 0.3147987\n",
      "\tspeed: 0.0695s/iter; left time: 2401.4450s\n",
      "2699it [03:11, 13.91it/s]\titers: 2700, epoch: 11 | loss: 0.2902370\n",
      "\tspeed: 0.0721s/iter; left time: 2483.6910s\n",
      "2799it [03:19, 14.15it/s]\titers: 2800, epoch: 11 | loss: 0.2377849\n",
      "\tspeed: 0.0703s/iter; left time: 2414.7641s\n",
      "2899it [03:26, 13.74it/s]\titers: 2900, epoch: 11 | loss: 0.2783045\n",
      "\tspeed: 0.0733s/iter; left time: 2509.6821s\n",
      "2999it [03:33, 14.54it/s]\titers: 3000, epoch: 11 | loss: 0.2602543\n",
      "\tspeed: 0.0702s/iter; left time: 2394.9345s\n",
      "3099it [03:40, 15.44it/s]\titers: 3100, epoch: 11 | loss: 0.2794184\n",
      "\tspeed: 0.0697s/iter; left time: 2372.8130s\n",
      "3199it [03:47, 15.45it/s]\titers: 3200, epoch: 11 | loss: 0.2061066\n",
      "\tspeed: 0.0692s/iter; left time: 2348.7258s\n",
      "3299it [03:53, 14.21it/s]\titers: 3300, epoch: 11 | loss: 0.2921207\n",
      "\tspeed: 0.0668s/iter; left time: 2260.5866s\n",
      "3399it [04:01, 13.58it/s]\titers: 3400, epoch: 11 | loss: 0.1485655\n",
      "\tspeed: 0.0721s/iter; left time: 2433.2517s\n",
      "3499it [04:08, 14.37it/s]\titers: 3500, epoch: 11 | loss: 0.2519857\n",
      "\tspeed: 0.0701s/iter; left time: 2357.0921s\n",
      "3599it [04:15, 13.69it/s]\titers: 3600, epoch: 11 | loss: 0.3005330\n",
      "\tspeed: 0.0691s/iter; left time: 2317.5827s\n",
      "3699it [04:22, 14.09it/s]\titers: 3700, epoch: 11 | loss: 0.3009367\n",
      "\tspeed: 0.0721s/iter; left time: 2411.6534s\n",
      "3713it [04:23, 14.10it/s]\n",
      "Epoch: 11 cost time: 263.3467803001404\n",
      "810it [00:26, 30.39it/s]\n",
      "807it [00:26, 30.25it/s]\n",
      "Epoch: 11 | Train Loss: 0.2995192 Vali Loss: 0.3645885 Test Loss: 0.4439737 MAE Loss: 0.4471173\n",
      "lr = 0.0004217885\n",
      "99it [00:07, 14.10it/s]\titers: 100, epoch: 12 | loss: 0.1509874\n",
      "\tspeed: 0.6444s/iter; left time: 21469.2977s\n",
      "199it [00:14, 14.44it/s]\titers: 200, epoch: 12 | loss: 0.3394450\n",
      "\tspeed: 0.0712s/iter; left time: 2366.5357s\n",
      "299it [00:21, 14.07it/s]\titers: 300, epoch: 12 | loss: 0.3195904\n",
      "\tspeed: 0.0707s/iter; left time: 2340.1540s\n",
      "399it [00:28, 13.78it/s]\titers: 400, epoch: 12 | loss: 0.2724038\n",
      "\tspeed: 0.0724s/iter; left time: 2390.1700s\n",
      "499it [00:35, 14.55it/s]\titers: 500, epoch: 12 | loss: 0.3184952\n",
      "\tspeed: 0.0701s/iter; left time: 2307.7439s\n",
      "599it [00:42, 14.45it/s]\titers: 600, epoch: 12 | loss: 0.2330701\n",
      "\tspeed: 0.0707s/iter; left time: 2321.4936s\n",
      "699it [00:50, 13.86it/s]\titers: 700, epoch: 12 | loss: 0.2266781\n",
      "\tspeed: 0.0717s/iter; left time: 2345.6875s\n",
      "799it [00:57, 14.13it/s]\titers: 800, epoch: 12 | loss: 0.5447848\n",
      "\tspeed: 0.0700s/iter; left time: 2284.0424s\n",
      "899it [01:04, 14.97it/s]\titers: 900, epoch: 12 | loss: 0.2503325\n",
      "\tspeed: 0.0717s/iter; left time: 2332.2793s\n",
      "999it [01:11, 14.92it/s]\titers: 1000, epoch: 12 | loss: 0.1742527\n",
      "\tspeed: 0.0710s/iter; left time: 2301.1240s\n",
      "1099it [01:18, 14.10it/s]\titers: 1100, epoch: 12 | loss: 0.5025838\n",
      "\tspeed: 0.0698s/iter; left time: 2256.8195s\n",
      "1199it [01:25, 14.12it/s]\titers: 1200, epoch: 12 | loss: 0.2415927\n",
      "\tspeed: 0.0726s/iter; left time: 2338.8603s\n",
      "1299it [01:32, 14.23it/s]\titers: 1300, epoch: 12 | loss: 0.2686547\n",
      "\tspeed: 0.0705s/iter; left time: 2264.4871s\n",
      "1399it [01:39, 14.03it/s]\titers: 1400, epoch: 12 | loss: 0.3864858\n",
      "\tspeed: 0.0728s/iter; left time: 2331.5438s\n",
      "1499it [01:47, 14.67it/s]\titers: 1500, epoch: 12 | loss: 0.2925336\n",
      "\tspeed: 0.0715s/iter; left time: 2281.1115s\n",
      "1599it [01:54, 13.88it/s]\titers: 1600, epoch: 12 | loss: 0.3702458\n",
      "\tspeed: 0.0706s/iter; left time: 2246.6705s\n",
      "1699it [02:01, 14.00it/s]\titers: 1700, epoch: 12 | loss: 0.3332889\n",
      "\tspeed: 0.0723s/iter; left time: 2293.3709s\n",
      "1799it [02:07, 14.20it/s]\titers: 1800, epoch: 12 | loss: 0.2772009\n",
      "\tspeed: 0.0670s/iter; left time: 2117.4783s\n",
      "1899it [02:15, 13.90it/s]\titers: 1900, epoch: 12 | loss: 0.1514916\n",
      "\tspeed: 0.0719s/iter; left time: 2264.8682s\n",
      "1999it [02:22, 14.12it/s]\titers: 2000, epoch: 12 | loss: 0.1765492\n",
      "\tspeed: 0.0716s/iter; left time: 2251.0956s\n",
      "2099it [02:29, 13.90it/s]\titers: 2100, epoch: 12 | loss: 0.2332756\n",
      "\tspeed: 0.0711s/iter; left time: 2228.1686s\n",
      "2199it [02:36, 14.23it/s]\titers: 2200, epoch: 12 | loss: 0.1891710\n",
      "\tspeed: 0.0708s/iter; left time: 2209.2309s\n",
      "2299it [02:43, 14.09it/s]\titers: 2300, epoch: 12 | loss: 0.2998321\n",
      "\tspeed: 0.0707s/iter; left time: 2201.1985s\n",
      "2399it [02:50, 14.63it/s]\titers: 2400, epoch: 12 | loss: 0.3815722\n",
      "\tspeed: 0.0708s/iter; left time: 2196.1653s\n",
      "2499it [02:57, 14.15it/s]\titers: 2500, epoch: 12 | loss: 0.4097457\n",
      "\tspeed: 0.0716s/iter; left time: 2213.0084s\n",
      "2599it [03:04, 13.77it/s]\titers: 2600, epoch: 12 | loss: 0.2603845\n",
      "\tspeed: 0.0698s/iter; left time: 2150.7414s\n",
      "2699it [03:12, 14.06it/s]\titers: 2700, epoch: 12 | loss: 0.2863677\n",
      "\tspeed: 0.0725s/iter; left time: 2225.9671s\n",
      "2799it [03:19, 14.13it/s]\titers: 2800, epoch: 12 | loss: 0.3533033\n",
      "\tspeed: 0.0709s/iter; left time: 2171.8869s\n",
      "2899it [03:26, 14.08it/s]\titers: 2900, epoch: 12 | loss: 0.2120877\n",
      "\tspeed: 0.0714s/iter; left time: 2180.4203s\n",
      "2999it [03:33, 14.18it/s]\titers: 3000, epoch: 12 | loss: 0.3545184\n",
      "\tspeed: 0.0720s/iter; left time: 2189.3695s\n",
      "3099it [03:40, 13.44it/s]\titers: 3100, epoch: 12 | loss: 0.3811266\n",
      "\tspeed: 0.0713s/iter; left time: 2162.5116s\n",
      "3199it [03:49, 14.04it/s]\titers: 3200, epoch: 12 | loss: 0.3707130\n",
      "\tspeed: 0.0866s/iter; left time: 2618.1840s\n",
      "3299it [03:56, 14.14it/s]\titers: 3300, epoch: 12 | loss: 0.2778952\n",
      "\tspeed: 0.0708s/iter; left time: 2133.8312s\n",
      "3399it [04:03, 14.20it/s]\titers: 3400, epoch: 12 | loss: 0.2310287\n",
      "\tspeed: 0.0709s/iter; left time: 2128.6905s\n",
      "3499it [04:11, 13.04it/s]\titers: 3500, epoch: 12 | loss: 0.2008852\n",
      "\tspeed: 0.0754s/iter; left time: 2255.2510s\n",
      "3599it [04:18, 14.10it/s]\titers: 3600, epoch: 12 | loss: 0.2930796\n",
      "\tspeed: 0.0718s/iter; left time: 2140.2136s\n",
      "3699it [04:25, 14.19it/s]\titers: 3700, epoch: 12 | loss: 0.3361859\n",
      "\tspeed: 0.0724s/iter; left time: 2150.6966s\n",
      "3713it [04:26, 13.93it/s]\n",
      "Epoch: 12 cost time: 266.4823911190033\n",
      "810it [00:27, 29.97it/s]\n",
      "807it [00:26, 30.06it/s]\n",
      "Epoch: 12 | Train Loss: 0.2928803 Vali Loss: 0.3491664 Test Loss: 0.4295338 MAE Loss: 0.4290132\n",
      "lr = 0.0003454980\n",
      "99it [00:07, 14.17it/s]\titers: 100, epoch: 13 | loss: 0.2500547\n",
      "\tspeed: 0.6383s/iter; left time: 18897.5582s\n",
      "199it [00:14, 14.14it/s]\titers: 200, epoch: 13 | loss: 0.3289737\n",
      "\tspeed: 0.0711s/iter; left time: 2096.7974s\n",
      "299it [00:21, 14.16it/s]\titers: 300, epoch: 13 | loss: 0.4403877\n",
      "\tspeed: 0.0715s/iter; left time: 2102.3192s\n",
      "399it [00:28, 14.13it/s]\titers: 400, epoch: 13 | loss: 0.3743571\n",
      "\tspeed: 0.0711s/iter; left time: 2083.5347s\n",
      "499it [00:35, 14.06it/s]\titers: 500, epoch: 13 | loss: 0.2266241\n",
      "\tspeed: 0.0677s/iter; left time: 1977.3900s\n",
      "599it [00:42, 14.01it/s]\titers: 600, epoch: 13 | loss: 0.2079357\n",
      "\tspeed: 0.0706s/iter; left time: 2054.5959s\n",
      "699it [00:49, 14.06it/s]\titers: 700, epoch: 13 | loss: 0.2082679\n",
      "\tspeed: 0.0717s/iter; left time: 2078.9222s\n",
      "799it [00:56, 15.24it/s]\titers: 800, epoch: 13 | loss: 0.2345156\n",
      "\tspeed: 0.0701s/iter; left time: 2027.0753s\n",
      "899it [01:03, 14.15it/s]\titers: 900, epoch: 13 | loss: 0.2828797\n",
      "\tspeed: 0.0686s/iter; left time: 1974.9482s\n",
      "999it [01:11, 13.24it/s]\titers: 1000, epoch: 13 | loss: 0.2040381\n",
      "\tspeed: 0.0758s/iter; left time: 2175.1066s\n",
      "1099it [01:18, 13.96it/s]\titers: 1100, epoch: 13 | loss: 0.1817234\n",
      "\tspeed: 0.0713s/iter; left time: 2038.2601s\n",
      "1199it [01:25, 14.23it/s]\titers: 1200, epoch: 13 | loss: 0.3184826\n",
      "\tspeed: 0.0714s/iter; left time: 2034.9236s\n",
      "1299it [01:32, 14.21it/s]\titers: 1300, epoch: 13 | loss: 0.3097099\n",
      "\tspeed: 0.0718s/iter; left time: 2040.3713s\n",
      "1399it [01:39, 14.19it/s]\titers: 1400, epoch: 13 | loss: 0.1641601\n",
      "\tspeed: 0.0704s/iter; left time: 1993.8599s\n",
      "1499it [01:46, 12.40it/s]\titers: 1500, epoch: 13 | loss: 0.1698398\n",
      "\tspeed: 0.0709s/iter; left time: 2000.3224s\n",
      "1599it [01:53, 14.14it/s]\titers: 1600, epoch: 13 | loss: 0.1701911\n",
      "\tspeed: 0.0706s/iter; left time: 1983.7027s\n",
      "1699it [02:00, 13.22it/s]\titers: 1700, epoch: 13 | loss: 0.3833731\n",
      "\tspeed: 0.0709s/iter; left time: 1986.9018s\n",
      "1799it [02:08, 14.63it/s]\titers: 1800, epoch: 13 | loss: 0.3531256\n",
      "\tspeed: 0.0715s/iter; left time: 1996.5815s\n",
      "1899it [02:15, 14.12it/s]\titers: 1900, epoch: 13 | loss: 0.3888091\n",
      "\tspeed: 0.0706s/iter; left time: 1961.7786s\n",
      "1999it [02:22, 14.13it/s]\titers: 2000, epoch: 13 | loss: 0.1712952\n",
      "\tspeed: 0.0713s/iter; left time: 1974.2570s\n",
      "2099it [02:29, 14.23it/s]\titers: 2100, epoch: 13 | loss: 0.3548581\n",
      "\tspeed: 0.0718s/iter; left time: 1981.9483s\n",
      "2199it [02:36, 12.55it/s]\titers: 2200, epoch: 13 | loss: 0.2814353\n",
      "\tspeed: 0.0702s/iter; left time: 1930.2656s\n",
      "2299it [02:43, 13.81it/s]\titers: 2300, epoch: 13 | loss: 0.2541613\n",
      "\tspeed: 0.0729s/iter; left time: 1997.0025s\n",
      "2399it [02:50, 13.61it/s]\titers: 2400, epoch: 13 | loss: 0.1366356\n",
      "\tspeed: 0.0727s/iter; left time: 1984.0631s\n",
      "2499it [02:58, 14.07it/s]\titers: 2500, epoch: 13 | loss: 0.4193524\n",
      "\tspeed: 0.0717s/iter; left time: 1950.1163s\n",
      "2599it [03:05, 14.30it/s]\titers: 2600, epoch: 13 | loss: 0.2318483\n",
      "\tspeed: 0.0716s/iter; left time: 1939.3724s\n",
      "2699it [03:12, 14.47it/s]\titers: 2700, epoch: 13 | loss: 0.3280040\n",
      "\tspeed: 0.0706s/iter; left time: 1905.3874s\n",
      "2799it [03:19, 14.33it/s]\titers: 2800, epoch: 13 | loss: 0.1456751\n",
      "\tspeed: 0.0731s/iter; left time: 1966.2104s\n",
      "2899it [03:26, 14.41it/s]\titers: 2900, epoch: 13 | loss: 0.5170210\n",
      "\tspeed: 0.0704s/iter; left time: 1888.1756s\n",
      "2999it [03:33, 14.10it/s]\titers: 3000, epoch: 13 | loss: 0.2727808\n",
      "\tspeed: 0.0707s/iter; left time: 1886.8994s\n",
      "3099it [03:40, 14.05it/s]\titers: 3100, epoch: 13 | loss: 0.3808917\n",
      "\tspeed: 0.0713s/iter; left time: 1895.6229s\n",
      "3199it [03:47, 13.84it/s]\titers: 3200, epoch: 13 | loss: 0.4237591\n",
      "\tspeed: 0.0703s/iter; left time: 1862.4158s\n",
      "3299it [03:55, 14.15it/s]\titers: 3300, epoch: 13 | loss: 0.3806382\n",
      "\tspeed: 0.0717s/iter; left time: 1893.1565s\n",
      "3399it [04:02, 14.16it/s]\titers: 3400, epoch: 13 | loss: 0.1700326\n",
      "\tspeed: 0.0707s/iter; left time: 1860.2651s\n",
      "3499it [04:09, 13.94it/s]\titers: 3500, epoch: 13 | loss: 0.1937704\n",
      "\tspeed: 0.0731s/iter; left time: 1914.9228s\n",
      "3599it [04:16, 13.81it/s]\titers: 3600, epoch: 13 | loss: 0.2143539\n",
      "\tspeed: 0.0726s/iter; left time: 1895.4044s\n",
      "3699it [04:24, 12.57it/s]\titers: 3700, epoch: 13 | loss: 0.1635020\n",
      "\tspeed: 0.0752s/iter; left time: 1956.2442s\n",
      "3713it [04:25, 13.98it/s]\n",
      "Epoch: 13 cost time: 265.5321087837219\n",
      "810it [00:27, 29.99it/s]\n",
      "807it [00:26, 30.27it/s]\n",
      "Epoch: 13 | Train Loss: 0.2857190 Vali Loss: 0.3522942 Test Loss: 0.4258270 MAE Loss: 0.4285729\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0002730120\n",
      "99it [00:07, 14.11it/s]\titers: 100, epoch: 14 | loss: 0.1415872\n",
      "\tspeed: 0.6247s/iter; left time: 16174.3113s\n",
      "199it [00:14, 12.09it/s]\titers: 200, epoch: 14 | loss: 0.3726557\n",
      "\tspeed: 0.0734s/iter; left time: 1892.5391s\n",
      "299it [00:22, 13.80it/s]\titers: 300, epoch: 14 | loss: 0.1997793\n",
      "\tspeed: 0.0766s/iter; left time: 1967.0124s\n",
      "399it [00:29, 14.16it/s]\titers: 400, epoch: 14 | loss: 0.2242292\n",
      "\tspeed: 0.0707s/iter; left time: 1809.9619s\n",
      "499it [00:37, 12.37it/s]\titers: 500, epoch: 14 | loss: 0.2321423\n",
      "\tspeed: 0.0759s/iter; left time: 1935.0658s\n",
      "599it [00:44, 14.28it/s]\titers: 600, epoch: 14 | loss: 0.2901591\n",
      "\tspeed: 0.0705s/iter; left time: 1790.7014s\n",
      "699it [00:51, 14.25it/s]\titers: 700, epoch: 14 | loss: 0.3365245\n",
      "\tspeed: 0.0716s/iter; left time: 1812.1030s\n",
      "799it [00:58, 14.21it/s]\titers: 800, epoch: 14 | loss: 0.2503560\n",
      "\tspeed: 0.0716s/iter; left time: 1804.9550s\n",
      "899it [01:05, 14.12it/s]\titers: 900, epoch: 14 | loss: 0.1625718\n",
      "\tspeed: 0.0716s/iter; left time: 1795.5543s\n",
      "999it [01:12, 13.74it/s]\titers: 1000, epoch: 14 | loss: 0.3779067\n",
      "\tspeed: 0.0727s/iter; left time: 1817.0992s\n",
      "1099it [01:20, 14.15it/s]\titers: 1100, epoch: 14 | loss: 0.4091911\n",
      "\tspeed: 0.0710s/iter; left time: 1766.9448s\n",
      "1199it [01:27, 14.33it/s]\titers: 1200, epoch: 14 | loss: 0.3242282\n",
      "\tspeed: 0.0709s/iter; left time: 1756.9423s\n",
      "1299it [01:33, 14.10it/s]\titers: 1300, epoch: 14 | loss: 0.1593705\n",
      "\tspeed: 0.0660s/iter; left time: 1629.8097s\n",
      "1399it [01:40, 14.18it/s]\titers: 1400, epoch: 14 | loss: 0.2169230\n",
      "\tspeed: 0.0675s/iter; left time: 1659.0202s\n",
      "1499it [01:47, 11.75it/s]\titers: 1500, epoch: 14 | loss: 0.1868869\n",
      "\tspeed: 0.0730s/iter; left time: 1788.4081s\n",
      "1599it [01:54, 14.12it/s]\titers: 1600, epoch: 14 | loss: 0.2463919\n",
      "\tspeed: 0.0649s/iter; left time: 1583.6194s\n",
      "1699it [02:01, 12.35it/s]\titers: 1700, epoch: 14 | loss: 0.2685658\n",
      "\tspeed: 0.0750s/iter; left time: 1822.1770s\n",
      "1799it [02:08, 14.72it/s]\titers: 1800, epoch: 14 | loss: 0.3146133\n",
      "\tspeed: 0.0717s/iter; left time: 1733.9604s\n",
      "1899it [02:15, 14.11it/s]\titers: 1900, epoch: 14 | loss: 0.2438359\n",
      "\tspeed: 0.0705s/iter; left time: 1698.7160s\n",
      "1999it [02:23, 13.49it/s]\titers: 2000, epoch: 14 | loss: 0.3774941\n",
      "\tspeed: 0.0724s/iter; left time: 1737.4126s\n",
      "2099it [02:30, 14.16it/s]\titers: 2100, epoch: 14 | loss: 0.1291581\n",
      "\tspeed: 0.0708s/iter; left time: 1692.1527s\n",
      "2199it [02:37, 13.83it/s]\titers: 2200, epoch: 14 | loss: 0.1385535\n",
      "\tspeed: 0.0720s/iter; left time: 1713.2081s\n",
      "2299it [02:44, 14.20it/s]\titers: 2300, epoch: 14 | loss: 0.3594226\n",
      "\tspeed: 0.0713s/iter; left time: 1690.1842s\n",
      "2399it [02:52, 14.10it/s]\titers: 2400, epoch: 14 | loss: 0.1384499\n",
      "\tspeed: 0.0756s/iter; left time: 1782.9678s\n",
      "2499it [02:59, 14.13it/s]\titers: 2500, epoch: 14 | loss: 0.2154482\n",
      "\tspeed: 0.0708s/iter; left time: 1662.1393s\n",
      "2599it [03:06, 14.12it/s]\titers: 2600, epoch: 14 | loss: 0.2900347\n",
      "\tspeed: 0.0718s/iter; left time: 1680.0744s\n",
      "2699it [03:13, 14.37it/s]\titers: 2700, epoch: 14 | loss: 0.3648814\n",
      "\tspeed: 0.0708s/iter; left time: 1650.0492s\n",
      "2799it [03:20, 14.17it/s]\titers: 2800, epoch: 14 | loss: 0.2247330\n",
      "\tspeed: 0.0726s/iter; left time: 1684.1493s\n",
      "2899it [03:27, 14.46it/s]\titers: 2900, epoch: 14 | loss: 0.1582369\n",
      "\tspeed: 0.0706s/iter; left time: 1631.4358s\n",
      "2999it [03:35, 14.16it/s]\titers: 3000, epoch: 14 | loss: 0.2606623\n",
      "\tspeed: 0.0718s/iter; left time: 1650.0448s\n",
      "3099it [03:42, 14.15it/s]\titers: 3100, epoch: 14 | loss: 0.1796550\n",
      "\tspeed: 0.0714s/iter; left time: 1633.4689s\n",
      "3199it [03:49, 14.24it/s]\titers: 3200, epoch: 14 | loss: 0.1905132\n",
      "\tspeed: 0.0703s/iter; left time: 1602.1653s\n",
      "3299it [03:56, 14.38it/s]\titers: 3300, epoch: 14 | loss: 0.2390756\n",
      "\tspeed: 0.0731s/iter; left time: 1658.3199s\n",
      "3399it [04:03, 13.84it/s]\titers: 3400, epoch: 14 | loss: 0.2047181\n",
      "\tspeed: 0.0710s/iter; left time: 1604.9379s\n",
      "3499it [04:10, 14.38it/s]\titers: 3500, epoch: 14 | loss: 0.4570910\n",
      "\tspeed: 0.0713s/iter; left time: 1603.5419s\n",
      "3599it [04:17, 14.44it/s]\titers: 3600, epoch: 14 | loss: 0.3326656\n",
      "\tspeed: 0.0695s/iter; left time: 1555.8251s\n",
      "3699it [04:24, 14.16it/s]\titers: 3700, epoch: 14 | loss: 0.4978660\n",
      "\tspeed: 0.0709s/iter; left time: 1579.7417s\n",
      "3713it [04:25, 13.97it/s]\n",
      "Epoch: 14 cost time: 265.8192241191864\n",
      "810it [00:30, 26.49it/s]\n",
      "807it [00:26, 30.05it/s]\n",
      "Epoch: 14 | Train Loss: 0.2815254 Vali Loss: 0.3473715 Test Loss: 0.4298393 MAE Loss: 0.4306547\n",
      "lr = 0.0002061153\n",
      "99it [00:07, 12.51it/s]\titers: 100, epoch: 15 | loss: 0.2852388\n",
      "\tspeed: 0.6820s/iter; left time: 15126.4852s\n",
      "199it [00:14, 14.35it/s]\titers: 200, epoch: 15 | loss: 0.2945589\n",
      "\tspeed: 0.0706s/iter; left time: 1557.8939s\n",
      "299it [00:21, 14.29it/s]\titers: 300, epoch: 15 | loss: 0.3102703\n",
      "\tspeed: 0.0705s/iter; left time: 1549.4757s\n",
      "399it [00:28, 14.01it/s]\titers: 400, epoch: 15 | loss: 0.2265408\n",
      "\tspeed: 0.0712s/iter; left time: 1557.9586s\n",
      "499it [00:35, 13.93it/s]\titers: 500, epoch: 15 | loss: 0.2774400\n",
      "\tspeed: 0.0716s/iter; left time: 1558.3881s\n",
      "599it [00:42, 14.14it/s]\titers: 600, epoch: 15 | loss: 0.2331572\n",
      "\tspeed: 0.0704s/iter; left time: 1525.9834s\n",
      "699it [00:50, 14.15it/s]\titers: 700, epoch: 15 | loss: 0.3521843\n",
      "\tspeed: 0.0715s/iter; left time: 1542.2400s\n",
      "799it [00:57, 14.13it/s]\titers: 800, epoch: 15 | loss: 0.2242591\n",
      "\tspeed: 0.0717s/iter; left time: 1539.2591s\n",
      "899it [01:04, 14.34it/s]\titers: 900, epoch: 15 | loss: 0.3982336\n",
      "\tspeed: 0.0697s/iter; left time: 1490.2392s\n",
      "999it [01:11, 14.18it/s]\titers: 1000, epoch: 15 | loss: 0.1443637\n",
      "\tspeed: 0.0723s/iter; left time: 1538.0897s\n",
      "1099it [01:18, 14.01it/s]\titers: 1100, epoch: 15 | loss: 0.4453093\n",
      "\tspeed: 0.0712s/iter; left time: 1507.8481s\n",
      "1199it [01:25, 14.19it/s]\titers: 1200, epoch: 15 | loss: 0.2708587\n",
      "\tspeed: 0.0709s/iter; left time: 1495.1990s\n",
      "1299it [01:32, 13.86it/s]\titers: 1300, epoch: 15 | loss: 0.1108242\n",
      "\tspeed: 0.0740s/iter; left time: 1553.2372s\n",
      "1399it [01:40, 13.79it/s]\titers: 1400, epoch: 15 | loss: 0.1267032\n",
      "\tspeed: 0.0715s/iter; left time: 1493.2097s\n",
      "1499it [01:47, 13.08it/s]\titers: 1500, epoch: 15 | loss: 0.4226899\n",
      "\tspeed: 0.0710s/iter; left time: 1474.7860s\n",
      "1599it [01:54, 14.15it/s]\titers: 1600, epoch: 15 | loss: 0.2651436\n",
      "\tspeed: 0.0720s/iter; left time: 1489.1996s\n",
      "1699it [02:01, 14.16it/s]\titers: 1700, epoch: 15 | loss: 0.6496507\n",
      "\tspeed: 0.0703s/iter; left time: 1445.9538s\n",
      "1799it [02:08, 14.03it/s]\titers: 1800, epoch: 15 | loss: 0.2868510\n",
      "\tspeed: 0.0717s/iter; left time: 1468.2332s\n",
      "1899it [02:15, 13.73it/s]\titers: 1900, epoch: 15 | loss: 0.1607992\n",
      "\tspeed: 0.0720s/iter; left time: 1466.6574s\n",
      "1999it [02:22, 14.01it/s]\titers: 2000, epoch: 15 | loss: 0.2209032\n",
      "\tspeed: 0.0672s/iter; left time: 1362.8965s\n",
      "2099it [02:29, 14.17it/s]\titers: 2100, epoch: 15 | loss: 0.2851955\n",
      "\tspeed: 0.0741s/iter; left time: 1494.2890s\n",
      "2199it [02:37, 14.18it/s]\titers: 2200, epoch: 15 | loss: 0.2628145\n",
      "\tspeed: 0.0719s/iter; left time: 1442.8267s\n",
      "2299it [02:44, 14.13it/s]\titers: 2300, epoch: 15 | loss: 0.1971958\n",
      "\tspeed: 0.0708s/iter; left time: 1413.5740s\n",
      "2399it [02:51, 12.78it/s]\titers: 2400, epoch: 15 | loss: 0.2070485\n",
      "\tspeed: 0.0727s/iter; left time: 1445.9400s\n",
      "2499it [02:58, 14.69it/s]\titers: 2500, epoch: 15 | loss: 0.2627920\n",
      "\tspeed: 0.0702s/iter; left time: 1388.2625s\n",
      "2599it [03:05, 14.20it/s]\titers: 2600, epoch: 15 | loss: 0.2176888\n",
      "\tspeed: 0.0705s/iter; left time: 1387.7861s\n",
      "2699it [03:12, 13.90it/s]\titers: 2700, epoch: 15 | loss: 0.2749127\n",
      "\tspeed: 0.0728s/iter; left time: 1424.9465s\n",
      "2799it [03:19, 14.13it/s]\titers: 2800, epoch: 15 | loss: 0.2533981\n",
      "\tspeed: 0.0705s/iter; left time: 1372.4999s\n",
      "2899it [03:27, 14.07it/s]\titers: 2900, epoch: 15 | loss: 0.4910263\n",
      "\tspeed: 0.0714s/iter; left time: 1383.0317s\n",
      "2999it [03:34, 13.87it/s]\titers: 3000, epoch: 15 | loss: 0.4446198\n",
      "\tspeed: 0.0721s/iter; left time: 1389.5355s\n",
      "3099it [03:41, 13.38it/s]\titers: 3100, epoch: 15 | loss: 0.1879049\n",
      "\tspeed: 0.0695s/iter; left time: 1333.0306s\n",
      "3199it [03:48, 14.07it/s]\titers: 3200, epoch: 15 | loss: 0.2714720\n",
      "\tspeed: 0.0722s/iter; left time: 1376.9614s\n",
      "3299it [03:55, 13.52it/s]\titers: 3300, epoch: 15 | loss: 0.2499533\n",
      "\tspeed: 0.0750s/iter; left time: 1423.3510s\n",
      "3399it [04:03, 12.08it/s]\titers: 3400, epoch: 15 | loss: 0.3669249\n",
      "\tspeed: 0.0734s/iter; left time: 1386.5623s\n",
      "3499it [04:10, 15.92it/s]\titers: 3500, epoch: 15 | loss: 0.2670145\n",
      "\tspeed: 0.0736s/iter; left time: 1382.9946s\n",
      "3599it [04:17, 13.71it/s]\titers: 3600, epoch: 15 | loss: 0.2108040\n",
      "\tspeed: 0.0733s/iter; left time: 1369.9499s\n",
      "3699it [04:25, 12.14it/s]\titers: 3700, epoch: 15 | loss: 0.3302063\n",
      "\tspeed: 0.0726s/iter; left time: 1349.6748s\n",
      "3713it [04:26, 13.94it/s]\n",
      "Epoch: 15 cost time: 266.32483172416687\n",
      "810it [00:28, 28.69it/s]\n",
      "807it [00:27, 28.84it/s]\n",
      "Epoch: 15 | Train Loss: 0.2765293 Vali Loss: 0.3472695 Test Loss: 0.4232479 MAE Loss: 0.4269224\n",
      "lr = 0.0001464551\n",
      "99it [00:07, 13.22it/s]\titers: 100, epoch: 16 | loss: 0.2020161\n",
      "\tspeed: 0.6677s/iter; left time: 12329.2829s\n",
      "199it [00:14, 14.28it/s]\titers: 200, epoch: 16 | loss: 0.2949465\n",
      "\tspeed: 0.0720s/iter; left time: 1322.1263s\n",
      "299it [00:21, 14.28it/s]\titers: 300, epoch: 16 | loss: 0.1851370\n",
      "\tspeed: 0.0708s/iter; left time: 1294.0234s\n",
      "399it [00:29, 14.21it/s]\titers: 400, epoch: 16 | loss: 0.1348809\n",
      "\tspeed: 0.0736s/iter; left time: 1337.0965s\n",
      "499it [00:36, 14.05it/s]\titers: 500, epoch: 16 | loss: 0.2194290\n",
      "\tspeed: 0.0708s/iter; left time: 1279.9519s\n",
      "599it [00:43, 12.26it/s]\titers: 600, epoch: 16 | loss: 0.1609053\n",
      "\tspeed: 0.0758s/iter; left time: 1362.1767s\n",
      "699it [00:50, 16.04it/s]\titers: 700, epoch: 16 | loss: 0.2201415\n",
      "\tspeed: 0.0671s/iter; left time: 1199.4789s\n",
      "799it [00:57, 11.22it/s]\titers: 800, epoch: 16 | loss: 0.1854500\n",
      "\tspeed: 0.0705s/iter; left time: 1252.7707s\n",
      "899it [01:04, 15.61it/s]\titers: 900, epoch: 16 | loss: 0.3085216\n",
      "\tspeed: 0.0717s/iter; left time: 1266.8955s\n",
      "999it [01:11, 14.16it/s]\titers: 1000, epoch: 16 | loss: 0.1788992\n",
      "\tspeed: 0.0694s/iter; left time: 1219.5491s\n",
      "1099it [01:18, 14.45it/s]\titers: 1100, epoch: 16 | loss: 0.1909116\n",
      "\tspeed: 0.0678s/iter; left time: 1183.6383s\n",
      "1199it [01:25, 14.09it/s]\titers: 1200, epoch: 16 | loss: 0.4690150\n",
      "\tspeed: 0.0719s/iter; left time: 1247.7998s\n",
      "1299it [01:32, 11.88it/s]\titers: 1300, epoch: 16 | loss: 0.1999692\n",
      "\tspeed: 0.0721s/iter; left time: 1245.6674s\n",
      "1399it [01:40, 14.26it/s]\titers: 1400, epoch: 16 | loss: 0.2140208\n",
      "\tspeed: 0.0717s/iter; left time: 1230.5630s\n",
      "1499it [01:47, 15.23it/s]\titers: 1500, epoch: 16 | loss: 0.2056334\n",
      "\tspeed: 0.0698s/iter; left time: 1190.7839s\n",
      "1599it [01:54, 11.54it/s]\titers: 1600, epoch: 16 | loss: 0.1058935\n",
      "\tspeed: 0.0729s/iter; left time: 1236.2800s\n",
      "1699it [02:01, 14.36it/s]\titers: 1700, epoch: 16 | loss: 0.3025618\n",
      "\tspeed: 0.0706s/iter; left time: 1191.5024s\n",
      "1799it [02:08, 13.56it/s]\titers: 1800, epoch: 16 | loss: 0.2963597\n",
      "\tspeed: 0.0737s/iter; left time: 1235.8914s\n",
      "1899it [02:16, 14.18it/s]\titers: 1900, epoch: 16 | loss: 0.2280244\n",
      "\tspeed: 0.0719s/iter; left time: 1197.9145s\n",
      "1999it [02:23, 14.15it/s]\titers: 2000, epoch: 16 | loss: 0.2398469\n",
      "\tspeed: 0.0703s/iter; left time: 1164.7272s\n",
      "2099it [02:30, 13.94it/s]\titers: 2100, epoch: 16 | loss: 0.2779323\n",
      "\tspeed: 0.0714s/iter; left time: 1176.0180s\n",
      "2199it [02:37, 14.11it/s]\titers: 2200, epoch: 16 | loss: 0.2129690\n",
      "\tspeed: 0.0707s/iter; left time: 1157.7480s\n",
      "2299it [02:44, 15.68it/s]\titers: 2300, epoch: 16 | loss: 0.2281235\n",
      "\tspeed: 0.0699s/iter; left time: 1136.9740s\n",
      "2399it [02:50, 14.19it/s]\titers: 2400, epoch: 16 | loss: 0.2684809\n",
      "\tspeed: 0.0662s/iter; left time: 1069.8623s\n",
      "2499it [02:57, 14.18it/s]\titers: 2500, epoch: 16 | loss: 0.3272431\n",
      "\tspeed: 0.0707s/iter; left time: 1136.2152s\n",
      "2599it [03:05, 12.62it/s]\titers: 2600, epoch: 16 | loss: 0.3226390\n",
      "\tspeed: 0.0750s/iter; left time: 1197.5399s\n",
      "2699it [03:12, 12.85it/s]\titers: 2700, epoch: 16 | loss: 0.3296982\n",
      "\tspeed: 0.0729s/iter; left time: 1156.8568s\n",
      "2799it [03:20, 11.95it/s]\titers: 2800, epoch: 16 | loss: 0.1943063\n",
      "\tspeed: 0.0733s/iter; left time: 1156.1464s\n",
      "2899it [03:27, 14.19it/s]\titers: 2900, epoch: 16 | loss: 0.3767173\n",
      "\tspeed: 0.0739s/iter; left time: 1157.5080s\n",
      "2999it [03:34, 13.71it/s]\titers: 3000, epoch: 16 | loss: 0.1849061\n",
      "\tspeed: 0.0745s/iter; left time: 1159.6154s\n",
      "3099it [03:42, 14.12it/s]\titers: 3100, epoch: 16 | loss: 0.2574348\n",
      "\tspeed: 0.0725s/iter; left time: 1120.9268s\n",
      "3199it [03:49, 14.10it/s]\titers: 3200, epoch: 16 | loss: 0.6203088\n",
      "\tspeed: 0.0717s/iter; left time: 1102.2683s\n",
      "3299it [03:56, 12.09it/s]\titers: 3300, epoch: 16 | loss: 0.1819046\n",
      "\tspeed: 0.0731s/iter; left time: 1115.4952s\n",
      "3399it [04:03, 14.15it/s]\titers: 3400, epoch: 16 | loss: 0.2000389\n",
      "\tspeed: 0.0723s/iter; left time: 1096.1722s\n",
      "3499it [04:10, 14.09it/s]\titers: 3500, epoch: 16 | loss: 0.3431151\n",
      "\tspeed: 0.0708s/iter; left time: 1066.0556s\n",
      "3599it [04:18, 13.64it/s]\titers: 3600, epoch: 16 | loss: 0.3790014\n",
      "\tspeed: 0.0731s/iter; left time: 1093.6068s\n",
      "3699it [04:25, 14.08it/s]\titers: 3700, epoch: 16 | loss: 0.2359140\n",
      "\tspeed: 0.0709s/iter; left time: 1053.5201s\n",
      "3713it [04:26, 13.94it/s]\n",
      "Epoch: 16 cost time: 266.38344049453735\n",
      "810it [00:27, 29.91it/s]\n",
      "807it [00:26, 30.10it/s]\n",
      "Epoch: 16 | Train Loss: 0.2730362 Vali Loss: 0.3435258 Test Loss: 0.4203814 MAE Loss: 0.4198538\n",
      "lr = 0.0000955005\n",
      "99it [00:07, 13.89it/s]\titers: 100, epoch: 17 | loss: 0.1640527\n",
      "\tspeed: 0.6434s/iter; left time: 9492.2560s\n",
      "199it [00:14, 13.94it/s]\titers: 200, epoch: 17 | loss: 0.2565632\n",
      "\tspeed: 0.0710s/iter; left time: 1039.7335s\n",
      "299it [00:21, 12.61it/s]\titers: 300, epoch: 17 | loss: 0.2054514\n",
      "\tspeed: 0.0721s/iter; left time: 1049.3338s\n",
      "399it [00:28, 14.15it/s]\titers: 400, epoch: 17 | loss: 0.2421706\n",
      "\tspeed: 0.0719s/iter; left time: 1038.8073s\n",
      "499it [00:35, 15.75it/s]\titers: 500, epoch: 17 | loss: 0.2484227\n",
      "\tspeed: 0.0692s/iter; left time: 992.7476s\n",
      "599it [00:43, 13.47it/s]\titers: 600, epoch: 17 | loss: 0.3249735\n",
      "\tspeed: 0.0710s/iter; left time: 1012.2464s\n",
      "699it [00:50, 14.27it/s]\titers: 700, epoch: 17 | loss: 0.3014257\n",
      "\tspeed: 0.0704s/iter; left time: 996.5399s\n",
      "799it [00:57, 15.74it/s]\titers: 800, epoch: 17 | loss: 0.4434174\n",
      "\tspeed: 0.0697s/iter; left time: 979.6321s\n",
      "899it [01:03, 14.09it/s]\titers: 900, epoch: 17 | loss: 0.2459723\n",
      "\tspeed: 0.0668s/iter; left time: 931.8527s\n",
      "999it [01:10, 13.82it/s]\titers: 1000, epoch: 17 | loss: 0.2611732\n",
      "\tspeed: 0.0707s/iter; left time: 979.8444s\n",
      "1099it [01:17, 14.15it/s]\titers: 1100, epoch: 17 | loss: 0.3641392\n",
      "\tspeed: 0.0719s/iter; left time: 988.6241s\n",
      "1199it [01:25, 13.95it/s]\titers: 1200, epoch: 17 | loss: 0.5401652\n",
      "\tspeed: 0.0717s/iter; left time: 979.5378s\n",
      "1299it [01:32, 14.15it/s]\titers: 1300, epoch: 17 | loss: 0.2258662\n",
      "\tspeed: 0.0706s/iter; left time: 956.2947s\n",
      "1399it [01:39, 14.09it/s]\titers: 1400, epoch: 17 | loss: 0.4497410\n",
      "\tspeed: 0.0732s/iter; left time: 984.3799s\n",
      "1499it [01:46, 14.07it/s]\titers: 1500, epoch: 17 | loss: 0.1883235\n",
      "\tspeed: 0.0711s/iter; left time: 949.4421s\n",
      "1599it [01:53, 14.20it/s]\titers: 1600, epoch: 17 | loss: 0.1766431\n",
      "\tspeed: 0.0731s/iter; left time: 969.1876s\n",
      "1699it [02:01, 14.00it/s]\titers: 1700, epoch: 17 | loss: 0.2800076\n",
      "\tspeed: 0.0720s/iter; left time: 947.3799s\n",
      "1799it [02:08, 14.09it/s]\titers: 1800, epoch: 17 | loss: 0.2221693\n",
      "\tspeed: 0.0713s/iter; left time: 930.6308s\n",
      "1899it [02:15, 13.98it/s]\titers: 1900, epoch: 17 | loss: 0.2821738\n",
      "\tspeed: 0.0726s/iter; left time: 940.8874s\n",
      "1999it [02:22, 14.18it/s]\titers: 2000, epoch: 17 | loss: 0.1933572\n",
      "\tspeed: 0.0706s/iter; left time: 907.1788s\n",
      "2099it [02:29, 14.95it/s]\titers: 2100, epoch: 17 | loss: 0.2550882\n",
      "\tspeed: 0.0724s/iter; left time: 923.8579s\n",
      "2199it [02:37, 14.27it/s]\titers: 2200, epoch: 17 | loss: 0.3099648\n",
      "\tspeed: 0.0718s/iter; left time: 908.9712s\n",
      "2299it [02:44, 14.18it/s]\titers: 2300, epoch: 17 | loss: 0.2622376\n",
      "\tspeed: 0.0747s/iter; left time: 937.9557s\n",
      "2399it [02:51, 14.34it/s]\titers: 2400, epoch: 17 | loss: 0.2911693\n",
      "\tspeed: 0.0721s/iter; left time: 897.9677s\n",
      "2499it [02:58, 14.14it/s]\titers: 2500, epoch: 17 | loss: 0.2848457\n",
      "\tspeed: 0.0705s/iter; left time: 871.4083s\n",
      "2599it [03:05, 12.59it/s]\titers: 2600, epoch: 17 | loss: 0.1373540\n",
      "\tspeed: 0.0724s/iter; left time: 887.5626s\n",
      "2699it [03:15, 10.27it/s]\titers: 2700, epoch: 17 | loss: 0.3808969\n",
      "\tspeed: 0.0967s/iter; left time: 1175.5653s\n",
      "2799it [03:23, 13.30it/s]\titers: 2800, epoch: 17 | loss: 0.3286078\n",
      "\tspeed: 0.0763s/iter; left time: 919.4191s\n",
      "2899it [03:30, 14.26it/s]\titers: 2900, epoch: 17 | loss: 0.2710432\n",
      "\tspeed: 0.0725s/iter; left time: 866.6581s\n",
      "2999it [03:37, 14.13it/s]\titers: 3000, epoch: 17 | loss: 0.2120618\n",
      "\tspeed: 0.0705s/iter; left time: 836.0145s\n",
      "3099it [03:44, 13.79it/s]\titers: 3100, epoch: 17 | loss: 0.2421237\n",
      "\tspeed: 0.0716s/iter; left time: 841.5532s\n",
      "3199it [03:51, 13.44it/s]\titers: 3200, epoch: 17 | loss: 0.3240352\n",
      "\tspeed: 0.0718s/iter; left time: 836.2547s\n",
      "3299it [03:58, 14.08it/s]\titers: 3300, epoch: 17 | loss: 0.2677674\n",
      "\tspeed: 0.0703s/iter; left time: 812.6366s\n",
      "3399it [04:05, 14.82it/s]\titers: 3400, epoch: 17 | loss: 0.2419178\n",
      "\tspeed: 0.0699s/iter; left time: 800.6305s\n",
      "3499it [04:13, 14.03it/s]\titers: 3500, epoch: 17 | loss: 0.3133871\n",
      "\tspeed: 0.0725s/iter; left time: 823.3669s\n",
      "3599it [04:20, 14.32it/s]\titers: 3600, epoch: 17 | loss: 0.5323966\n",
      "\tspeed: 0.0710s/iter; left time: 798.9455s\n",
      "3699it [04:27, 14.51it/s]\titers: 3700, epoch: 17 | loss: 0.3406528\n",
      "\tspeed: 0.0712s/iter; left time: 793.8341s\n",
      "3713it [04:28, 13.83it/s]\n",
      "Epoch: 17 cost time: 268.47436451911926\n",
      "810it [00:26, 30.05it/s]\n",
      "807it [00:26, 30.44it/s]\n",
      "Epoch: 17 | Train Loss: 0.2700421 Vali Loss: 0.3400391 Test Loss: 0.4160352 MAE Loss: 0.4166830\n",
      "lr = 0.0000545062\n",
      "99it [00:07, 14.12it/s]\titers: 100, epoch: 18 | loss: 0.3171934\n",
      "\tspeed: 0.6371s/iter; left time: 7033.9441s\n",
      "199it [00:14, 14.15it/s]\titers: 200, epoch: 18 | loss: 0.1833807\n",
      "\tspeed: 0.0714s/iter; left time: 780.9932s\n",
      "299it [00:22, 14.08it/s]\titers: 300, epoch: 18 | loss: 0.1346787\n",
      "\tspeed: 0.0742s/iter; left time: 804.2939s\n",
      "399it [00:29, 14.28it/s]\titers: 400, epoch: 18 | loss: 0.3923603\n",
      "\tspeed: 0.0709s/iter; left time: 761.8342s\n",
      "499it [00:36, 14.02it/s]\titers: 500, epoch: 18 | loss: 0.1583522\n",
      "\tspeed: 0.0733s/iter; left time: 780.1489s\n",
      "599it [00:43, 14.58it/s]\titers: 600, epoch: 18 | loss: 0.3503875\n",
      "\tspeed: 0.0718s/iter; left time: 756.4285s\n",
      "699it [00:50, 13.21it/s]\titers: 700, epoch: 18 | loss: 0.3783064\n",
      "\tspeed: 0.0711s/iter; left time: 742.7562s\n",
      "799it [00:58, 12.68it/s]\titers: 800, epoch: 18 | loss: 0.2059459\n",
      "\tspeed: 0.0743s/iter; left time: 768.5243s\n",
      "898it [01:07, 11.37it/s]\titers: 900, epoch: 18 | loss: 0.2104725\n",
      "\tspeed: 0.0934s/iter; left time: 956.6168s\n",
      "998it [01:15, 14.12it/s]\titers: 1000, epoch: 18 | loss: 0.2512944\n",
      "\tspeed: 0.0808s/iter; left time: 819.4730s\n",
      "1098it [01:22, 14.02it/s]\titers: 1100, epoch: 18 | loss: 0.4875512\n",
      "\tspeed: 0.0717s/iter; left time: 719.4262s\n",
      "1199it [01:30, 14.05it/s]\titers: 1200, epoch: 18 | loss: 0.3160571\n",
      "\tspeed: 0.0752s/iter; left time: 747.0066s\n",
      "1299it [01:37, 14.29it/s]\titers: 1300, epoch: 18 | loss: 0.4352148\n",
      "\tspeed: 0.0721s/iter; left time: 709.2237s\n",
      "1399it [01:44, 14.48it/s]\titers: 1400, epoch: 18 | loss: 0.2360902\n",
      "\tspeed: 0.0710s/iter; left time: 691.9889s\n",
      "1499it [01:51, 12.18it/s]\titers: 1500, epoch: 18 | loss: 0.2842156\n",
      "\tspeed: 0.0735s/iter; left time: 708.7495s\n",
      "1599it [01:59, 14.12it/s]\titers: 1600, epoch: 18 | loss: 0.3081040\n",
      "\tspeed: 0.0707s/iter; left time: 674.1794s\n",
      "1699it [02:06, 14.07it/s]\titers: 1700, epoch: 18 | loss: 0.1965987\n",
      "\tspeed: 0.0714s/iter; left time: 673.9922s\n",
      "1799it [02:13, 14.13it/s]\titers: 1800, epoch: 18 | loss: 0.3155457\n",
      "\tspeed: 0.0733s/iter; left time: 684.2618s\n",
      "1899it [02:20, 14.78it/s]\titers: 1900, epoch: 18 | loss: 0.2459525\n",
      "\tspeed: 0.0709s/iter; left time: 654.8524s\n",
      "1999it [02:27, 13.56it/s]\titers: 2000, epoch: 18 | loss: 0.2038857\n",
      "\tspeed: 0.0728s/iter; left time: 665.7990s\n",
      "2099it [02:35, 14.19it/s]\titers: 2100, epoch: 18 | loss: 0.1858789\n",
      "\tspeed: 0.0727s/iter; left time: 657.2816s\n",
      "2199it [02:42, 14.07it/s]\titers: 2200, epoch: 18 | loss: 0.3386445\n",
      "\tspeed: 0.0715s/iter; left time: 639.1112s\n",
      "2299it [02:49, 14.13it/s]\titers: 2300, epoch: 18 | loss: 0.2114703\n",
      "\tspeed: 0.0725s/iter; left time: 640.5781s\n",
      "2399it [02:57, 12.99it/s]\titers: 2400, epoch: 18 | loss: 0.3746703\n",
      "\tspeed: 0.0774s/iter; left time: 676.5977s\n",
      "2499it [03:04, 14.33it/s]\titers: 2500, epoch: 18 | loss: 0.1676080\n",
      "\tspeed: 0.0711s/iter; left time: 614.2327s\n",
      "2599it [03:11, 14.51it/s]\titers: 2600, epoch: 18 | loss: 0.1944087\n",
      "\tspeed: 0.0686s/iter; left time: 586.0570s\n",
      "2699it [03:18, 14.08it/s]\titers: 2700, epoch: 18 | loss: 0.4498771\n",
      "\tspeed: 0.0748s/iter; left time: 631.4720s\n",
      "2799it [03:26, 13.92it/s]\titers: 2800, epoch: 18 | loss: 0.1481468\n",
      "\tspeed: 0.0753s/iter; left time: 627.8141s\n",
      "2899it [03:34, 13.62it/s]\titers: 2900, epoch: 18 | loss: 0.2155235\n",
      "\tspeed: 0.0791s/iter; left time: 652.1688s\n",
      "2999it [03:41, 15.09it/s]\titers: 3000, epoch: 18 | loss: 0.2635684\n",
      "\tspeed: 0.0705s/iter; left time: 574.1496s\n",
      "3099it [03:48, 12.87it/s]\titers: 3100, epoch: 18 | loss: 0.3060077\n",
      "\tspeed: 0.0775s/iter; left time: 622.8654s\n",
      "3199it [03:56, 14.11it/s]\titers: 3200, epoch: 18 | loss: 0.1600410\n",
      "\tspeed: 0.0708s/iter; left time: 562.3723s\n",
      "3299it [04:03, 14.01it/s]\titers: 3300, epoch: 18 | loss: 0.1447030\n",
      "\tspeed: 0.0720s/iter; left time: 564.3887s\n",
      "3399it [04:11, 13.13it/s]\titers: 3400, epoch: 18 | loss: 0.3035178\n",
      "\tspeed: 0.0792s/iter; left time: 613.2628s\n",
      "3499it [04:18, 14.22it/s]\titers: 3500, epoch: 18 | loss: 0.2496608\n",
      "\tspeed: 0.0717s/iter; left time: 547.9156s\n",
      "3599it [04:25, 14.11it/s]\titers: 3600, epoch: 18 | loss: 0.4928241\n",
      "\tspeed: 0.0751s/iter; left time: 566.1162s\n",
      "3699it [04:32, 14.18it/s]\titers: 3700, epoch: 18 | loss: 0.3123909\n",
      "\tspeed: 0.0685s/iter; left time: 509.4965s\n",
      "3713it [04:33, 13.56it/s]\n",
      "Epoch: 18 cost time: 273.76011872291565\n",
      "810it [00:28, 28.50it/s]\n",
      "807it [00:28, 28.68it/s]\n",
      "Epoch: 18 | Train Loss: 0.2671667 Vali Loss: 0.3431970 Test Loss: 0.4182879 MAE Loss: 0.4214019\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr = 0.0000244815\n",
      "99it [00:07, 14.14it/s]\titers: 100, epoch: 19 | loss: 0.2765492\n",
      "\tspeed: 0.6512s/iter; left time: 4771.3491s\n",
      "198it [00:15, 14.27it/s]\titers: 200, epoch: 19 | loss: 0.2169117\n",
      "\tspeed: 0.0768s/iter; left time: 554.7980s\n",
      "298it [00:22, 13.84it/s]\titers: 300, epoch: 19 | loss: 0.2999817\n",
      "\tspeed: 0.0710s/iter; left time: 506.1294s\n",
      "399it [00:29, 14.09it/s]\titers: 400, epoch: 19 | loss: 0.1898630\n",
      "\tspeed: 0.0770s/iter; left time: 541.3909s\n",
      "499it [00:37, 14.25it/s]\titers: 500, epoch: 19 | loss: 0.3765214\n",
      "\tspeed: 0.0708s/iter; left time: 490.3359s\n",
      "599it [00:44, 14.25it/s]\titers: 600, epoch: 19 | loss: 0.2427113\n",
      "\tspeed: 0.0745s/iter; left time: 508.3603s\n",
      "699it [00:51, 15.65it/s]\titers: 700, epoch: 19 | loss: 0.2246418\n",
      "\tspeed: 0.0698s/iter; left time: 469.5133s\n",
      "799it [00:58, 13.93it/s]\titers: 800, epoch: 19 | loss: 0.5571246\n",
      "\tspeed: 0.0741s/iter; left time: 491.2941s\n",
      "899it [01:06, 13.99it/s]\titers: 900, epoch: 19 | loss: 0.1534219\n",
      "\tspeed: 0.0732s/iter; left time: 477.7612s\n",
      "999it [01:13, 14.15it/s]\titers: 1000, epoch: 19 | loss: 0.3163153\n",
      "\tspeed: 0.0748s/iter; left time: 480.5569s\n",
      "1099it [01:20, 13.49it/s]\titers: 1100, epoch: 19 | loss: 0.3593818\n",
      "\tspeed: 0.0716s/iter; left time: 452.7463s\n",
      "1199it [01:28, 14.09it/s]\titers: 1200, epoch: 19 | loss: 0.2577397\n",
      "\tspeed: 0.0756s/iter; left time: 470.8791s\n",
      "1299it [01:35, 14.42it/s]\titers: 1300, epoch: 19 | loss: 0.3132360\n",
      "\tspeed: 0.0708s/iter; left time: 434.0518s\n",
      "1399it [01:43, 11.84it/s]\titers: 1400, epoch: 19 | loss: 0.3073771\n",
      "\tspeed: 0.0769s/iter; left time: 463.6571s\n",
      "1499it [01:50, 13.81it/s]\titers: 1500, epoch: 19 | loss: 0.1983021\n",
      "\tspeed: 0.0711s/iter; left time: 421.4856s\n",
      "1599it [01:57, 11.82it/s]\titers: 1600, epoch: 19 | loss: 0.1767408\n",
      "\tspeed: 0.0755s/iter; left time: 439.8685s\n",
      "1699it [02:04, 14.11it/s]\titers: 1700, epoch: 19 | loss: 0.1988638\n",
      "\tspeed: 0.0719s/iter; left time: 411.5204s\n",
      "1798it [02:12, 11.99it/s]\titers: 1800, epoch: 19 | loss: 0.2384618\n",
      "\tspeed: 0.0756s/iter; left time: 425.5778s\n",
      "1898it [02:20, 13.03it/s]\titers: 1900, epoch: 19 | loss: 0.3995284\n",
      "\tspeed: 0.0752s/iter; left time: 415.7409s\n",
      "1998it [02:27, 14.09it/s]\titers: 2000, epoch: 19 | loss: 0.2984046\n",
      "\tspeed: 0.0709s/iter; left time: 384.6563s\n",
      "2098it [02:34, 14.35it/s]\titers: 2100, epoch: 19 | loss: 0.3472441\n",
      "\tspeed: 0.0754s/iter; left time: 401.5361s\n",
      "2198it [02:41, 14.57it/s]\titers: 2200, epoch: 19 | loss: 0.1168213\n",
      "\tspeed: 0.0713s/iter; left time: 372.6271s\n",
      "2298it [02:49, 14.10it/s]\titers: 2300, epoch: 19 | loss: 0.1935789\n",
      "\tspeed: 0.0742s/iter; left time: 380.5897s\n",
      "2398it [02:56, 13.87it/s]\titers: 2400, epoch: 19 | loss: 0.1908798\n",
      "\tspeed: 0.0734s/iter; left time: 368.8829s\n",
      "2498it [03:03, 10.96it/s]\titers: 2500, epoch: 19 | loss: 0.3685527\n",
      "\tspeed: 0.0733s/iter; left time: 361.0765s\n",
      "2598it [03:11, 14.08it/s]\titers: 2600, epoch: 19 | loss: 0.1834503\n",
      "\tspeed: 0.0719s/iter; left time: 346.8741s\n",
      "2698it [03:18, 13.74it/s]\titers: 2700, epoch: 19 | loss: 0.2304170\n",
      "\tspeed: 0.0736s/iter; left time: 348.1322s\n",
      "2798it [03:25, 14.43it/s]\titers: 2800, epoch: 19 | loss: 0.4333939\n",
      "\tspeed: 0.0725s/iter; left time: 335.4842s\n",
      "2898it [03:32, 14.29it/s]\titers: 2900, epoch: 19 | loss: 0.2429963\n",
      "\tspeed: 0.0727s/iter; left time: 329.1005s\n",
      "2998it [03:40, 13.89it/s]\titers: 3000, epoch: 19 | loss: 0.2365280\n",
      "\tspeed: 0.0749s/iter; left time: 331.4123s\n",
      "3098it [03:47, 13.97it/s]\titers: 3100, epoch: 19 | loss: 0.1644711\n",
      "\tspeed: 0.0726s/iter; left time: 313.9583s\n",
      "3198it [03:55, 14.28it/s]\titers: 3200, epoch: 19 | loss: 0.1599708\n",
      "\tspeed: 0.0754s/iter; left time: 318.6220s\n",
      "3298it [04:02, 14.20it/s]\titers: 3300, epoch: 19 | loss: 0.2976720\n",
      "\tspeed: 0.0705s/iter; left time: 290.9809s\n",
      "3398it [04:09, 13.27it/s]\titers: 3400, epoch: 19 | loss: 0.3369531\n",
      "\tspeed: 0.0769s/iter; left time: 309.7013s\n",
      "3498it [04:17, 14.10it/s]\titers: 3500, epoch: 19 | loss: 0.1798500\n",
      "\tspeed: 0.0710s/iter; left time: 278.7136s\n",
      "3598it [04:24, 14.00it/s]\titers: 3600, epoch: 19 | loss: 0.3012286\n",
      "\tspeed: 0.0725s/iter; left time: 277.2695s\n",
      "3698it [04:31, 14.02it/s]\titers: 3700, epoch: 19 | loss: 0.1916632\n",
      "\tspeed: 0.0743s/iter; left time: 276.9338s\n",
      "3713it [04:32, 13.61it/s]\n",
      "Epoch: 19 cost time: 272.845965385437\n",
      "810it [00:27, 29.03it/s]\n",
      "807it [00:27, 29.58it/s]\n",
      "Epoch: 19 | Train Loss: 0.2659731 Vali Loss: 0.3390222 Test Loss: 0.4134638 MAE Loss: 0.4165031\n",
      "lr = 0.0000061658\n",
      "99it [00:07, 14.18it/s]\titers: 100, epoch: 20 | loss: 0.2028809\n",
      "\tspeed: 0.6568s/iter; left time: 2373.6171s\n",
      "199it [00:14, 14.04it/s]\titers: 200, epoch: 20 | loss: 0.2550098\n",
      "\tspeed: 0.0718s/iter; left time: 252.4395s\n",
      "299it [00:22, 13.52it/s]\titers: 300, epoch: 20 | loss: 0.3964863\n",
      "\tspeed: 0.0720s/iter; left time: 245.8937s\n",
      "399it [00:29, 14.08it/s]\titers: 400, epoch: 20 | loss: 0.2367971\n",
      "\tspeed: 0.0746s/iter; left time: 247.1169s\n",
      "499it [00:37, 14.13it/s]\titers: 500, epoch: 20 | loss: 0.1902281\n",
      "\tspeed: 0.0753s/iter; left time: 242.0656s\n",
      "599it [00:44, 14.10it/s]\titers: 600, epoch: 20 | loss: 0.3067628\n",
      "\tspeed: 0.0723s/iter; left time: 224.9950s\n",
      "699it [00:51, 14.10it/s]\titers: 700, epoch: 20 | loss: 0.4380533\n",
      "\tspeed: 0.0756s/iter; left time: 227.9318s\n",
      "799it [00:58, 14.22it/s]\titers: 800, epoch: 20 | loss: 0.2823110\n",
      "\tspeed: 0.0707s/iter; left time: 206.0789s\n",
      "899it [01:06, 11.94it/s]\titers: 900, epoch: 20 | loss: 0.1910501\n",
      "\tspeed: 0.0746s/iter; left time: 209.9286s\n",
      "999it [01:13, 14.08it/s]\titers: 1000, epoch: 20 | loss: 0.1359421\n",
      "\tspeed: 0.0723s/iter; left time: 196.3057s\n",
      "1099it [01:20, 14.19it/s]\titers: 1100, epoch: 20 | loss: 0.2254554\n",
      "\tspeed: 0.0718s/iter; left time: 187.7094s\n",
      "1199it [01:28, 14.11it/s]\titers: 1200, epoch: 20 | loss: 0.2320993\n",
      "\tspeed: 0.0758s/iter; left time: 190.4880s\n",
      "1299it [01:35, 14.10it/s]\titers: 1300, epoch: 20 | loss: 0.2081875\n",
      "\tspeed: 0.0706s/iter; left time: 170.3367s\n",
      "1399it [01:42, 12.83it/s]\titers: 1400, epoch: 20 | loss: 0.2950242\n",
      "\tspeed: 0.0727s/iter; left time: 168.2256s\n",
      "1499it [01:50, 15.84it/s]\titers: 1500, epoch: 20 | loss: 0.3131588\n",
      "\tspeed: 0.0732s/iter; left time: 162.1144s\n",
      "1599it [01:57, 14.25it/s]\titers: 1600, epoch: 20 | loss: 0.2728341\n",
      "\tspeed: 0.0693s/iter; left time: 146.5281s\n",
      "1699it [02:04, 12.25it/s]\titers: 1700, epoch: 20 | loss: 0.2262768\n",
      "\tspeed: 0.0735s/iter; left time: 148.0730s\n",
      "1799it [02:11, 14.00it/s]\titers: 1800, epoch: 20 | loss: 0.3804431\n",
      "\tspeed: 0.0742s/iter; left time: 142.0803s\n",
      "1899it [02:19, 14.04it/s]\titers: 1900, epoch: 20 | loss: 0.3351625\n",
      "\tspeed: 0.0728s/iter; left time: 132.1080s\n",
      "1999it [02:26, 14.13it/s]\titers: 2000, epoch: 20 | loss: 0.1908536\n",
      "\tspeed: 0.0728s/iter; left time: 124.7771s\n",
      "2099it [02:33, 14.04it/s]\titers: 2100, epoch: 20 | loss: 0.1543461\n",
      "\tspeed: 0.0741s/iter; left time: 119.6177s\n",
      "2199it [02:40, 13.95it/s]\titers: 2200, epoch: 20 | loss: 0.2040936\n",
      "\tspeed: 0.0714s/iter; left time: 108.1165s\n",
      "2299it [02:48,  9.30it/s]\titers: 2300, epoch: 20 | loss: 0.5196315\n",
      "\tspeed: 0.0747s/iter; left time: 105.6437s\n",
      "2399it [02:55, 14.04it/s]\titers: 2400, epoch: 20 | loss: 0.3994785\n",
      "\tspeed: 0.0718s/iter; left time: 94.3495s\n",
      "2499it [03:02, 14.20it/s]\titers: 2500, epoch: 20 | loss: 0.3272019\n",
      "\tspeed: 0.0719s/iter; left time: 87.2352s\n",
      "2599it [03:10, 13.76it/s]\titers: 2600, epoch: 20 | loss: 0.2275440\n",
      "\tspeed: 0.0755s/iter; left time: 84.0681s\n",
      "2699it [03:17, 13.18it/s]\titers: 2700, epoch: 20 | loss: 0.3621648\n",
      "\tspeed: 0.0716s/iter; left time: 72.5927s\n",
      "2799it [03:24, 13.16it/s]\titers: 2800, epoch: 20 | loss: 0.2244433\n",
      "\tspeed: 0.0684s/iter; left time: 62.5500s\n",
      "2899it [03:31, 14.11it/s]\titers: 2900, epoch: 20 | loss: 0.1791323\n",
      "\tspeed: 0.0741s/iter; left time: 60.2810s\n",
      "2999it [03:38, 14.09it/s]\titers: 3000, epoch: 20 | loss: 0.3702236\n",
      "\tspeed: 0.0717s/iter; left time: 51.1586s\n",
      "3099it [03:46, 14.32it/s]\titers: 3100, epoch: 20 | loss: 0.2150385\n",
      "\tspeed: 0.0736s/iter; left time: 45.2068s\n",
      "3199it [03:53, 15.08it/s]\titers: 3200, epoch: 20 | loss: 0.2343135\n",
      "\tspeed: 0.0712s/iter; left time: 36.5863s\n",
      "3299it [04:00, 14.13it/s]\titers: 3300, epoch: 20 | loss: 0.2327813\n",
      "\tspeed: 0.0753s/iter; left time: 31.1713s\n",
      "3399it [04:07, 13.40it/s]\titers: 3400, epoch: 20 | loss: 0.2484347\n",
      "\tspeed: 0.0712s/iter; left time: 22.3719s\n",
      "3499it [04:14, 12.40it/s]\titers: 3500, epoch: 20 | loss: 0.4114945\n",
      "\tspeed: 0.0694s/iter; left time: 14.8462s\n",
      "3599it [04:21, 15.97it/s]\titers: 3600, epoch: 20 | loss: 0.4327282\n",
      "\tspeed: 0.0663s/iter; left time: 7.5538s\n",
      "3699it [04:28, 13.91it/s]\titers: 3700, epoch: 20 | loss: 0.1714645\n",
      "\tspeed: 0.0684s/iter; left time: 0.9580s\n",
      "3713it [04:29, 13.78it/s]\n",
      "Epoch: 20 cost time: 269.4710817337036\n",
      "810it [00:27, 29.07it/s]\n",
      "807it [00:27, 28.82it/s]\n",
      "Epoch: 20 | Train Loss: 0.2655603 Vali Loss: 0.3383641 Test Loss: 0.4129862 MAE Loss: 0.4151682\n",
      "lr = 0.0000000100\n",
      "Total time: 107.90661646922429 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=12\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --lradj 'COS' \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "[2024-05-03 15:44:30,610] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 15:44:31,493] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 15:44:31,493] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 15:44:31,493] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 15:44:32,485] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-03 15:44:32,486] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 15:44:33,736] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 15:44:33,738] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 15:44:33,738] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 15:44:33,740] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 15:44:33,740] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 15:44:33,740] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 15:44:33,740] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 15:44:33,740] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 15:44:33,740] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 15:44:33,740] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 15:44:34,329] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 15:44:34,331] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:44:34,331] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.33 GB, percent = 12.2%\n",
      "[2024-05-03 15:44:34,569] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 15:44:34,570] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:44:34,571] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.34 GB, percent = 12.2%\n",
      "[2024-05-03 15:44:34,571] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 15:44:34,813] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 15:44:34,814] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-03 15:44:34,815] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.33 GB, percent = 12.2%\n",
      "[2024-05-03 15:44:34,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 15:44:34,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 15:44:34,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 15:44:34,816] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 15:44:34,817] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 15:44:34,818] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 15:44:34,818] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 15:44:34,818] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 15:44:34,818] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5903c8c6d0>\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 15:44:34,819] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 15:44:34,820] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 15:44:34,821] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 15:44:34,822] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:24,  4.19it/s]\titers: 100, epoch: 1 | loss: 0.7356012\n",
      "\tspeed: 0.2908s/iter; left time: 1066.1519s\n",
      "199it [00:58,  3.10it/s]\titers: 200, epoch: 1 | loss: 0.5691991\n",
      "\tspeed: 0.3444s/iter; left time: 1228.1985s\n",
      "299it [01:32,  2.10it/s]\titers: 300, epoch: 1 | loss: 0.4520031\n",
      "\tspeed: 0.3429s/iter; left time: 1188.5837s\n",
      "399it [02:06,  2.39it/s]\titers: 400, epoch: 1 | loss: 0.6152174\n",
      "\tspeed: 0.3344s/iter; left time: 1125.4562s\n",
      "499it [02:39,  3.45it/s]\titers: 500, epoch: 1 | loss: 0.4286653\n",
      "\tspeed: 0.3363s/iter; left time: 1098.4060s\n",
      "599it [03:12,  3.34it/s]\titers: 600, epoch: 1 | loss: 0.2725918\n",
      "\tspeed: 0.3255s/iter; left time: 1030.4073s\n",
      "699it [03:46,  2.90it/s]\titers: 700, epoch: 1 | loss: 0.3188488\n",
      "\tspeed: 0.3411s/iter; left time: 1045.8324s\n",
      "799it [04:17,  3.43it/s]\titers: 800, epoch: 1 | loss: 0.5181361\n",
      "\tspeed: 0.3103s/iter; left time: 920.4743s\n",
      "899it [04:49,  3.36it/s]\titers: 900, epoch: 1 | loss: 0.1869062\n",
      "\tspeed: 0.3193s/iter; left time: 914.9958s\n",
      "999it [05:21,  2.09it/s]\titers: 1000, epoch: 1 | loss: 0.2172682\n",
      "\tspeed: 0.3165s/iter; left time: 875.3748s\n",
      "1099it [05:55,  3.02it/s]\titers: 1100, epoch: 1 | loss: 0.2820303\n",
      "\tspeed: 0.3483s/iter; left time: 928.5558s\n",
      "1199it [06:27,  2.91it/s]\titers: 1200, epoch: 1 | loss: 0.4319468\n",
      "\tspeed: 0.3125s/iter; left time: 801.8844s\n",
      "1299it [07:02,  2.85it/s]\titers: 1300, epoch: 1 | loss: 0.3310315\n",
      "\tspeed: 0.3570s/iter; left time: 880.3170s\n",
      "1399it [07:35,  2.92it/s]\titers: 1400, epoch: 1 | loss: 0.3464009\n",
      "\tspeed: 0.3294s/iter; left time: 779.4637s\n",
      "1499it [08:07,  3.00it/s]\titers: 1500, epoch: 1 | loss: 0.2595419\n",
      "\tspeed: 0.3195s/iter; left time: 724.0822s\n",
      "1599it [08:44,  2.77it/s]\titers: 1600, epoch: 1 | loss: 0.3122485\n",
      "\tspeed: 0.3714s/iter; left time: 804.4426s\n",
      "1699it [09:18,  2.33it/s]\titers: 1700, epoch: 1 | loss: 0.3014346\n",
      "\tspeed: 0.3356s/iter; left time: 693.3138s\n",
      "1799it [09:50,  3.38it/s]\titers: 1800, epoch: 1 | loss: 0.3493429\n",
      "\tspeed: 0.3214s/iter; left time: 631.9039s\n",
      "1899it [10:20,  3.62it/s]\titers: 1900, epoch: 1 | loss: 0.3084237\n",
      "\tspeed: 0.3020s/iter; left time: 563.6075s\n",
      "1999it [10:49,  3.60it/s]\titers: 2000, epoch: 1 | loss: 0.2826749\n",
      "\tspeed: 0.2837s/iter; left time: 500.9693s\n",
      "2099it [11:18,  3.05it/s]\titers: 2100, epoch: 1 | loss: 0.4879281\n",
      "\tspeed: 0.2969s/iter; left time: 494.6857s\n",
      "2199it [11:47,  3.41it/s]\titers: 2200, epoch: 1 | loss: 0.2046579\n",
      "\tspeed: 0.2897s/iter; left time: 453.7468s\n",
      "2299it [12:16,  4.14it/s]\titers: 2300, epoch: 1 | loss: 0.1233690\n",
      "\tspeed: 0.2890s/iter; left time: 423.7306s\n",
      "2399it [12:51,  3.40it/s]\titers: 2400, epoch: 1 | loss: 0.2604498\n",
      "\tspeed: 0.3438s/iter; left time: 469.6103s\n",
      "2499it [13:25,  3.11it/s]\titers: 2500, epoch: 1 | loss: 0.2310107\n",
      "\tspeed: 0.3405s/iter; left time: 431.0967s\n",
      "2599it [13:58,  2.98it/s]\titers: 2600, epoch: 1 | loss: 0.2021242\n",
      "\tspeed: 0.3349s/iter; left time: 390.4528s\n",
      "2699it [14:29,  3.37it/s]\titers: 2700, epoch: 1 | loss: 0.1879779\n",
      "\tspeed: 0.3108s/iter; left time: 331.2782s\n",
      "2799it [15:00,  3.76it/s]\titers: 2800, epoch: 1 | loss: 0.4332197\n",
      "\tspeed: 0.3074s/iter; left time: 296.9775s\n",
      "2899it [15:31,  3.10it/s]\titers: 2900, epoch: 1 | loss: 0.1966374\n",
      "\tspeed: 0.3056s/iter; left time: 264.6117s\n",
      "2999it [16:01,  2.53it/s]\titers: 3000, epoch: 1 | loss: 0.1856316\n",
      "\tspeed: 0.3012s/iter; left time: 230.6993s\n",
      "3099it [16:35,  3.33it/s]\titers: 3100, epoch: 1 | loss: 0.3469718\n",
      "\tspeed: 0.3414s/iter; left time: 227.3795s\n",
      "3199it [17:11,  3.12it/s]\titers: 3200, epoch: 1 | loss: 0.5812799\n",
      "\tspeed: 0.3665s/iter; left time: 207.4195s\n",
      "3299it [17:46,  3.17it/s]\titers: 3300, epoch: 1 | loss: 0.2726511\n",
      "\tspeed: 0.3405s/iter; left time: 158.6874s\n",
      "3399it [18:18,  3.11it/s]\titers: 3400, epoch: 1 | loss: 0.5794476\n",
      "\tspeed: 0.3238s/iter; left time: 118.5144s\n",
      "3499it [18:49,  3.54it/s]\titers: 3500, epoch: 1 | loss: 0.3040229\n",
      "\tspeed: 0.3134s/iter; left time: 83.3695s\n",
      "3599it [19:22,  2.81it/s]\titers: 3600, epoch: 1 | loss: 0.3292978\n",
      "\tspeed: 0.3332s/iter; left time: 55.3053s\n",
      "3699it [19:57,  2.28it/s]\titers: 3700, epoch: 1 | loss: 0.2165164\n",
      "\tspeed: 0.3475s/iter; left time: 22.9338s\n",
      "3765it [20:18,  3.09it/s]\n",
      "Epoch: 1 cost time: 1218.1102845668793\n",
      "810it [02:00,  6.70it/s]\n",
      "807it [02:14,  6.00it/s]\n",
      "Epoch: 1 | Train Loss: 0.3600279 Vali Loss: 0.3258024 Test Loss: 0.3997062 MAE Loss: 0.4031630\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "Total time: 25.003564433256784 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.001\n",
    "llama_layers=12\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A100 80GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-03 18:41:03,815] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 18:41:04,703] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 18:41:04,703] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 18:41:04,703] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 18:41:05,580] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-03 18:41:05,580] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 18:41:06,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 18:41:06,480] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 18:41:06,480] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 18:41:06,481] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 18:41:06,481] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 18:41:06,482] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 18:41:06,482] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 18:41:06,482] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 18:41:06,482] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 18:41:06,482] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 18:41:06,753] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 18:41:06,753] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.65 GB         CA 0.66 GB         Max_CA 1 GB \n",
      "[2024-05-03 18:41:06,754] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 375.06 GB, percent = 49.7%\n",
      "[2024-05-03 18:41:06,877] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 18:41:06,878] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.74 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-03 18:41:06,878] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 375.1 GB, percent = 49.7%\n",
      "[2024-05-03 18:41:06,878] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 18:41:06,994] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 18:41:06,995] [INFO] [utils.py:801:see_memory_usage] MA 0.55 GB         Max_MA 0.55 GB         CA 0.86 GB         Max_CA 1 GB \n",
      "[2024-05-03 18:41:06,995] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 375.1 GB, percent = 49.7%\n",
      "[2024-05-03 18:41:06,996] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 18:41:06,996] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 18:41:06,996] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 18:41:06,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 18:41:06,996] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbb408b32d0>\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 18:41:06,997] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 18:41:06,998] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:08, 12.12it/s]\titers: 100, epoch: 1 | loss: 0.7344609\n",
      "\tspeed: 0.1206s/iter; left time: 9068.2232s\n",
      "199it [00:15, 13.18it/s]\titers: 200, epoch: 1 | loss: 0.5534266\n",
      "\tspeed: 0.0735s/iter; left time: 5521.3202s\n",
      "299it [00:23, 12.82it/s]\titers: 300, epoch: 1 | loss: 0.3374816\n",
      "\tspeed: 0.0777s/iter; left time: 5827.0684s\n",
      "399it [00:31, 13.43it/s]\titers: 400, epoch: 1 | loss: 0.5920237\n",
      "\tspeed: 0.0780s/iter; left time: 5843.9775s\n",
      "498it [00:39, 13.87it/s]\titers: 500, epoch: 1 | loss: 0.3636857\n",
      "\tspeed: 0.0794s/iter; left time: 5935.7716s\n",
      "598it [00:46, 12.71it/s]\titers: 600, epoch: 1 | loss: 0.2869768\n",
      "\tspeed: 0.0736s/iter; left time: 5500.4722s\n",
      "698it [00:54, 13.53it/s]\titers: 700, epoch: 1 | loss: 0.2821769\n",
      "\tspeed: 0.0765s/iter; left time: 5703.9659s\n",
      "798it [01:01, 14.61it/s]\titers: 800, epoch: 1 | loss: 0.4466472\n",
      "\tspeed: 0.0697s/iter; left time: 5191.4872s\n",
      "898it [01:08, 15.17it/s]\titers: 900, epoch: 1 | loss: 0.1720697\n",
      "\tspeed: 0.0700s/iter; left time: 5206.3678s\n",
      "998it [01:15, 14.37it/s]\titers: 1000, epoch: 1 | loss: 0.2217325\n",
      "\tspeed: 0.0726s/iter; left time: 5391.9281s\n",
      "1098it [01:22, 14.70it/s]\titers: 1100, epoch: 1 | loss: 0.2706838\n",
      "\tspeed: 0.0701s/iter; left time: 5197.9634s\n",
      "1198it [01:29, 12.70it/s]\titers: 1200, epoch: 1 | loss: 0.4562358\n",
      "\tspeed: 0.0743s/iter; left time: 5504.2786s\n",
      "1298it [01:37, 12.66it/s]\titers: 1300, epoch: 1 | loss: 0.3683525\n",
      "\tspeed: 0.0810s/iter; left time: 5991.9219s\n",
      "1398it [01:45, 13.17it/s]\titers: 1400, epoch: 1 | loss: 0.3831846\n",
      "\tspeed: 0.0760s/iter; left time: 5614.9376s\n",
      "1498it [01:53, 12.52it/s]\titers: 1500, epoch: 1 | loss: 0.2239503\n",
      "\tspeed: 0.0791s/iter; left time: 5836.1271s\n",
      "1598it [02:01, 13.40it/s]\titers: 1600, epoch: 1 | loss: 0.3337799\n",
      "\tspeed: 0.0780s/iter; left time: 5747.6152s\n",
      "1698it [02:08, 12.99it/s]\titers: 1700, epoch: 1 | loss: 0.2691672\n",
      "\tspeed: 0.0748s/iter; left time: 5505.1997s\n",
      "1798it [02:16, 13.31it/s]\titers: 1800, epoch: 1 | loss: 0.3767647\n",
      "\tspeed: 0.0792s/iter; left time: 5823.2407s\n",
      "1898it [02:24, 12.68it/s]\titers: 1900, epoch: 1 | loss: 0.3214819\n",
      "\tspeed: 0.0743s/iter; left time: 5455.7107s\n",
      "1998it [02:31, 13.07it/s]\titers: 2000, epoch: 1 | loss: 0.3014286\n",
      "\tspeed: 0.0773s/iter; left time: 5663.9153s\n",
      "2098it [02:39, 14.14it/s]\titers: 2100, epoch: 1 | loss: 0.4911543\n",
      "\tspeed: 0.0783s/iter; left time: 5734.0535s\n",
      "2198it [02:46, 15.47it/s]\titers: 2200, epoch: 1 | loss: 0.2055287\n",
      "\tspeed: 0.0673s/iter; left time: 4922.6746s\n",
      "2298it [02:53, 10.47it/s]\titers: 2300, epoch: 1 | loss: 0.1426944\n",
      "\tspeed: 0.0738s/iter; left time: 5387.3839s\n",
      "2398it [03:00, 14.54it/s]\titers: 2400, epoch: 1 | loss: 0.2317778\n",
      "\tspeed: 0.0676s/iter; left time: 4924.8447s\n",
      "2498it [03:07, 15.03it/s]\titers: 2500, epoch: 1 | loss: 0.2468895\n",
      "\tspeed: 0.0686s/iter; left time: 4995.6702s\n",
      "2598it [03:14, 14.17it/s]\titers: 2600, epoch: 1 | loss: 0.2311681\n",
      "\tspeed: 0.0706s/iter; left time: 5135.9480s\n",
      "2698it [03:21, 14.30it/s]\titers: 2700, epoch: 1 | loss: 0.1829604\n",
      "\tspeed: 0.0669s/iter; left time: 4857.7140s\n",
      "2798it [03:28, 15.19it/s]\titers: 2800, epoch: 1 | loss: 0.4374384\n",
      "\tspeed: 0.0705s/iter; left time: 5114.5406s\n",
      "2898it [03:35, 14.98it/s]\titers: 2900, epoch: 1 | loss: 0.2059190\n",
      "\tspeed: 0.0753s/iter; left time: 5454.7268s\n",
      "2998it [03:42, 14.35it/s]\titers: 3000, epoch: 1 | loss: 0.2148284\n",
      "\tspeed: 0.0686s/iter; left time: 4961.4937s\n",
      "3098it [03:49, 15.10it/s]\titers: 3100, epoch: 1 | loss: 0.3376509\n",
      "\tspeed: 0.0660s/iter; left time: 4762.4497s\n",
      "3198it [03:56, 14.17it/s]\titers: 3200, epoch: 1 | loss: 0.5711665\n",
      "\tspeed: 0.0744s/iter; left time: 5360.8125s\n",
      "3298it [04:03, 16.24it/s]\titers: 3300, epoch: 1 | loss: 0.2519772\n",
      "\tspeed: 0.0663s/iter; left time: 4772.4071s\n",
      "3398it [04:10, 13.77it/s]\titers: 3400, epoch: 1 | loss: 0.5514895\n",
      "\tspeed: 0.0735s/iter; left time: 5286.6557s\n",
      "3498it [04:17, 14.17it/s]\titers: 3500, epoch: 1 | loss: 0.3255207\n",
      "\tspeed: 0.0695s/iter; left time: 4987.5832s\n",
      "3598it [04:24, 14.36it/s]\titers: 3600, epoch: 1 | loss: 0.3368211\n",
      "\tspeed: 0.0677s/iter; left time: 4855.0338s\n",
      "3698it [04:31, 14.05it/s]\titers: 3700, epoch: 1 | loss: 0.2395910\n",
      "\tspeed: 0.0752s/iter; left time: 5386.6931s\n",
      "3765it [04:36, 13.61it/s]\n",
      "Epoch: 1 cost time: 276.5777759552002\n",
      "810it [00:26, 30.82it/s]\n",
      "807it [00:26, 30.58it/s]\n",
      "Epoch: 1 | Train Loss: 0.3455458 Vali Loss: 0.3314827 Test Loss: 0.4090656 MAE Loss: 0.4084324\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "99it [00:06, 15.31it/s]\titers: 100, epoch: 2 | loss: 0.2133331\n",
      "\tspeed: 0.6680s/iter; left time: 47722.7565s\n",
      "199it [00:13, 14.86it/s]\titers: 200, epoch: 2 | loss: 0.3633168\n",
      "\tspeed: 0.0684s/iter; left time: 4878.6151s\n",
      "299it [00:20, 16.78it/s]\titers: 300, epoch: 2 | loss: 0.2297406\n",
      "\tspeed: 0.0682s/iter; left time: 4855.7457s\n",
      "399it [00:26, 14.99it/s]\titers: 400, epoch: 2 | loss: 0.2786470\n",
      "\tspeed: 0.0633s/iter; left time: 4506.1030s\n",
      "499it [00:33, 15.79it/s]\titers: 500, epoch: 2 | loss: 0.1391118\n",
      "\tspeed: 0.0654s/iter; left time: 4643.3850s\n",
      "599it [00:40, 14.26it/s]\titers: 600, epoch: 2 | loss: 0.2329213\n",
      "\tspeed: 0.0696s/iter; left time: 4934.1914s\n",
      "698it [00:46, 19.73it/s]\titers: 700, epoch: 2 | loss: 0.3461939\n",
      "\tspeed: 0.0646s/iter; left time: 4577.8259s\n",
      "799it [00:51, 19.57it/s]\titers: 800, epoch: 2 | loss: 0.4934967\n",
      "\tspeed: 0.0510s/iter; left time: 3604.6537s\n",
      "899it [00:58, 16.36it/s]\titers: 900, epoch: 2 | loss: 0.2556140\n",
      "\tspeed: 0.0614s/iter; left time: 4335.2765s\n",
      "999it [01:04, 19.71it/s]\titers: 1000, epoch: 2 | loss: 0.2170373\n",
      "\tspeed: 0.0598s/iter; left time: 4218.7536s\n",
      "1099it [01:09, 19.59it/s]\titers: 1100, epoch: 2 | loss: 0.1909031\n",
      "\tspeed: 0.0507s/iter; left time: 3571.8803s\n",
      "1199it [01:16, 10.68it/s]\titers: 1200, epoch: 2 | loss: 0.3276211\n",
      "\tspeed: 0.0694s/iter; left time: 4881.9351s\n",
      "1299it [01:22, 16.40it/s]\titers: 1300, epoch: 2 | loss: 0.6224858\n",
      "\tspeed: 0.0633s/iter; left time: 4447.6846s\n",
      "1399it [01:28, 15.88it/s]\titers: 1400, epoch: 2 | loss: 0.3547138\n",
      "\tspeed: 0.0650s/iter; left time: 4561.6783s\n",
      "1499it [01:34, 15.80it/s]\titers: 1500, epoch: 2 | loss: 0.2847526\n",
      "\tspeed: 0.0573s/iter; left time: 4009.9011s\n",
      "1599it [01:41, 15.53it/s]\titers: 1600, epoch: 2 | loss: 0.1720620\n",
      "\tspeed: 0.0663s/iter; left time: 4633.9506s\n",
      "1699it [01:47, 15.20it/s]\titers: 1700, epoch: 2 | loss: 0.2632230\n",
      "\tspeed: 0.0657s/iter; left time: 4586.9384s\n",
      "1799it [01:54, 14.44it/s]\titers: 1800, epoch: 2 | loss: 0.2095311\n",
      "\tspeed: 0.0676s/iter; left time: 4714.7681s\n",
      "1899it [02:01, 14.20it/s]\titers: 1900, epoch: 2 | loss: 0.2062538\n",
      "\tspeed: 0.0718s/iter; left time: 5000.3535s\n",
      "1999it [02:08, 15.12it/s]\titers: 2000, epoch: 2 | loss: 0.1903376\n",
      "\tspeed: 0.0687s/iter; left time: 4779.3092s\n",
      "2099it [02:15, 10.60it/s]\titers: 2100, epoch: 2 | loss: 0.3051968\n",
      "\tspeed: 0.0693s/iter; left time: 4811.1060s\n",
      "2199it [02:22, 15.05it/s]\titers: 2200, epoch: 2 | loss: 0.2243668\n",
      "\tspeed: 0.0677s/iter; left time: 4696.3468s\n",
      "2299it [02:28, 15.54it/s]\titers: 2300, epoch: 2 | loss: 0.2801064\n",
      "\tspeed: 0.0656s/iter; left time: 4544.0293s\n",
      "2399it [02:34, 17.37it/s]\titers: 2400, epoch: 2 | loss: 0.1785705\n",
      "\tspeed: 0.0518s/iter; left time: 3582.5709s\n",
      "2499it [02:41, 15.06it/s]\titers: 2500, epoch: 2 | loss: 0.4827907\n",
      "\tspeed: 0.0701s/iter; left time: 4838.7578s\n",
      "2599it [02:47, 15.65it/s]\titers: 2600, epoch: 2 | loss: 0.1959589\n",
      "\tspeed: 0.0622s/iter; left time: 4286.1951s\n",
      "2699it [02:54, 11.96it/s]\titers: 2700, epoch: 2 | loss: 0.2637077\n",
      "\tspeed: 0.0678s/iter; left time: 4669.8012s\n",
      "2799it [03:00, 15.49it/s]\titers: 2800, epoch: 2 | loss: 0.4255023\n",
      "\tspeed: 0.0652s/iter; left time: 4480.5772s\n",
      "2899it [03:07, 16.34it/s]\titers: 2900, epoch: 2 | loss: 0.3513686\n",
      "\tspeed: 0.0646s/iter; left time: 4430.6122s\n",
      "2999it [03:13, 14.43it/s]\titers: 3000, epoch: 2 | loss: 0.1681190\n",
      "\tspeed: 0.0649s/iter; left time: 4444.7811s\n",
      "3099it [03:20, 15.79it/s]\titers: 3100, epoch: 2 | loss: 0.1524097\n",
      "\tspeed: 0.0646s/iter; left time: 4418.4245s\n",
      "3199it [03:26, 16.37it/s]\titers: 3200, epoch: 2 | loss: 0.2961035\n",
      "\tspeed: 0.0619s/iter; left time: 4233.2126s\n",
      "3299it [03:32, 15.42it/s]\titers: 3300, epoch: 2 | loss: 0.1931553\n",
      "\tspeed: 0.0646s/iter; left time: 4409.4368s\n",
      "3399it [03:39, 14.49it/s]\titers: 3400, epoch: 2 | loss: 0.2171213\n",
      "\tspeed: 0.0698s/iter; left time: 4755.0487s\n",
      "3497it [03:46, 16.57it/s]\titers: 3500, epoch: 2 | loss: 0.4232988\n",
      "\tspeed: 0.0653s/iter; left time: 4442.7707s\n",
      "3598it [03:51, 19.67it/s]\titers: 3600, epoch: 2 | loss: 0.1783781\n",
      "\tspeed: 0.0508s/iter; left time: 3454.1217s\n",
      "3699it [03:57, 15.94it/s]\titers: 3700, epoch: 2 | loss: 0.2112690\n",
      "\tspeed: 0.0605s/iter; left time: 4105.3207s\n",
      "3765it [04:01, 15.59it/s]\n",
      "Epoch: 2 cost time: 241.5614116191864\n",
      "810it [00:23, 34.53it/s]\n",
      "807it [00:23, 34.31it/s]\n",
      "Epoch: 2 | Train Loss: 0.2716841 Vali Loss: 0.3368949 Test Loss: 0.4269623 MAE Loss: 0.4148688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "99it [00:07, 16.41it/s]\titers: 100, epoch: 3 | loss: 0.2494262\n",
      "\tspeed: 0.5860s/iter; left time: 39653.4451s\n",
      "199it [00:13, 15.50it/s]\titers: 200, epoch: 3 | loss: 0.4260388\n",
      "\tspeed: 0.0637s/iter; left time: 4306.1997s\n",
      "299it [00:19, 15.33it/s]\titers: 300, epoch: 3 | loss: 0.1500765\n",
      "\tspeed: 0.0629s/iter; left time: 4245.3254s\n",
      "399it [00:26, 17.07it/s]\titers: 400, epoch: 3 | loss: 0.3129734\n",
      "\tspeed: 0.0668s/iter; left time: 4498.2295s\n",
      "499it [00:33, 13.81it/s]\titers: 500, epoch: 3 | loss: 0.1419590\n",
      "\tspeed: 0.0651s/iter; left time: 4378.1604s\n",
      "599it [00:39, 16.76it/s]\titers: 600, epoch: 3 | loss: 0.1678801\n",
      "\tspeed: 0.0649s/iter; left time: 4361.9441s\n",
      "699it [00:46, 15.84it/s]\titers: 700, epoch: 3 | loss: 0.2609751\n",
      "\tspeed: 0.0711s/iter; left time: 4770.2796s\n",
      "799it [00:53, 15.60it/s]\titers: 800, epoch: 3 | loss: 0.3131287\n",
      "\tspeed: 0.0647s/iter; left time: 4330.0893s\n",
      "899it [00:59, 13.96it/s]\titers: 900, epoch: 3 | loss: 0.2596065\n",
      "\tspeed: 0.0650s/iter; left time: 4343.3395s\n",
      "999it [01:06, 14.10it/s]\titers: 1000, epoch: 3 | loss: 0.4696178\n",
      "\tspeed: 0.0725s/iter; left time: 4839.0961s\n",
      "1099it [01:14, 13.48it/s]\titers: 1100, epoch: 3 | loss: 0.1118183\n",
      "\tspeed: 0.0709s/iter; left time: 4727.5424s\n",
      "1199it [01:21, 13.66it/s]\titers: 1200, epoch: 3 | loss: 0.1599149\n",
      "\tspeed: 0.0695s/iter; left time: 4625.8446s\n",
      "1299it [01:28, 16.09it/s]\titers: 1300, epoch: 3 | loss: 0.2614858\n",
      "\tspeed: 0.0711s/iter; left time: 4727.6956s\n",
      "1399it [01:34, 15.24it/s]\titers: 1400, epoch: 3 | loss: 0.3105979\n",
      "\tspeed: 0.0657s/iter; left time: 4362.4998s\n",
      "1499it [01:41, 18.21it/s]\titers: 1500, epoch: 3 | loss: 0.1588375\n",
      "\tspeed: 0.0629s/iter; left time: 4167.9447s\n",
      "1598it [01:46, 15.91it/s]\titers: 1600, epoch: 3 | loss: 0.2056118\n",
      "\tspeed: 0.0533s/iter; left time: 3528.8559s\n",
      "1699it [01:52, 16.02it/s]\titers: 1700, epoch: 3 | loss: 0.1775197\n",
      "\tspeed: 0.0635s/iter; left time: 4198.6742s\n",
      "1799it [01:59, 15.21it/s]\titers: 1800, epoch: 3 | loss: 0.3883937\n",
      "\tspeed: 0.0653s/iter; left time: 4309.7467s\n",
      "1899it [02:05, 15.02it/s]\titers: 1900, epoch: 3 | loss: 0.1765780\n",
      "\tspeed: 0.0652s/iter; left time: 4295.7623s\n",
      "1999it [02:12, 13.50it/s]\titers: 2000, epoch: 3 | loss: 0.3559508\n",
      "\tspeed: 0.0710s/iter; left time: 4668.2619s\n",
      "2099it [02:18, 18.56it/s]\titers: 2100, epoch: 3 | loss: 0.2184572\n",
      "\tspeed: 0.0595s/iter; left time: 3909.5610s\n",
      "2199it [02:25, 14.88it/s]\titers: 2200, epoch: 3 | loss: 0.2784693\n",
      "\tspeed: 0.0643s/iter; left time: 4214.5104s\n",
      "2299it [02:32, 15.98it/s]\titers: 2300, epoch: 3 | loss: 0.3075760\n",
      "\tspeed: 0.0680s/iter; left time: 4449.3812s\n",
      "2399it [02:38, 14.67it/s]\titers: 2400, epoch: 3 | loss: 0.4369825\n",
      "\tspeed: 0.0678s/iter; left time: 4433.3824s\n",
      "2499it [02:45, 14.99it/s]\titers: 2500, epoch: 3 | loss: 0.2119672\n",
      "\tspeed: 0.0660s/iter; left time: 4307.3455s\n",
      "2599it [02:52, 14.88it/s]\titers: 2600, epoch: 3 | loss: 0.2304634\n",
      "\tspeed: 0.0704s/iter; left time: 4588.5023s\n",
      "2699it [02:59, 15.20it/s]\titers: 2700, epoch: 3 | loss: 0.1034780\n",
      "\tspeed: 0.0660s/iter; left time: 4293.1820s\n",
      "2799it [03:05, 16.31it/s]\titers: 2800, epoch: 3 | loss: 0.1633217\n",
      "\tspeed: 0.0635s/iter; left time: 4128.3998s\n",
      "2899it [03:11, 14.01it/s]\titers: 2900, epoch: 3 | loss: 0.2074667\n",
      "\tspeed: 0.0654s/iter; left time: 4243.4041s\n",
      "2999it [03:18, 17.22it/s]\titers: 3000, epoch: 3 | loss: 0.1936255\n",
      "\tspeed: 0.0632s/iter; left time: 4095.9958s\n",
      "3099it [03:24, 15.94it/s]\titers: 3100, epoch: 3 | loss: 0.3537498\n",
      "\tspeed: 0.0617s/iter; left time: 3989.7609s\n",
      "3199it [03:30, 15.09it/s]\titers: 3200, epoch: 3 | loss: 0.2398289\n",
      "\tspeed: 0.0620s/iter; left time: 4003.6273s\n",
      "3299it [03:36, 17.54it/s]\titers: 3300, epoch: 3 | loss: 0.2424933\n",
      "\tspeed: 0.0567s/iter; left time: 3654.9959s\n",
      "3399it [03:42, 16.26it/s]\titers: 3400, epoch: 3 | loss: 0.2064747\n",
      "\tspeed: 0.0616s/iter; left time: 3965.0968s\n",
      "3499it [03:48, 15.55it/s]\titers: 3500, epoch: 3 | loss: 0.2138335\n",
      "\tspeed: 0.0626s/iter; left time: 4024.4716s\n",
      "3599it [03:55, 14.83it/s]\titers: 3600, epoch: 3 | loss: 0.1495813\n",
      "\tspeed: 0.0660s/iter; left time: 4234.8543s\n",
      "3699it [04:01, 15.43it/s]\titers: 3700, epoch: 3 | loss: 0.1738549\n",
      "\tspeed: 0.0654s/iter; left time: 4188.2539s\n",
      "3765it [04:06, 15.30it/s]\n",
      "Epoch: 3 cost time: 246.12982082366943\n",
      "810it [00:23, 34.64it/s]\n",
      "807it [00:23, 34.87it/s]\n",
      "Epoch: 3 | Train Loss: 0.2576268 Vali Loss: 0.2999316 Test Loss: 0.3649445 MAE Loss: 0.3680021\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "99it [00:06, 16.54it/s]\titers: 100, epoch: 4 | loss: 0.1314902\n",
      "\tspeed: 0.5937s/iter; left time: 37940.5125s\n",
      "199it [00:12, 15.41it/s]\titers: 200, epoch: 4 | loss: 0.2942722\n",
      "\tspeed: 0.0640s/iter; left time: 4084.9053s\n",
      "299it [00:19, 15.91it/s]\titers: 300, epoch: 4 | loss: 0.2316074\n",
      "\tspeed: 0.0664s/iter; left time: 4228.6559s\n",
      "399it [00:26, 16.07it/s]\titers: 400, epoch: 4 | loss: 0.1880004\n",
      "\tspeed: 0.0651s/iter; left time: 4139.9121s\n",
      "499it [00:32, 19.49it/s]\titers: 500, epoch: 4 | loss: 0.2408332\n",
      "\tspeed: 0.0591s/iter; left time: 3755.1291s\n",
      "599it [00:38, 15.82it/s]\titers: 600, epoch: 4 | loss: 0.2508964\n",
      "\tspeed: 0.0666s/iter; left time: 4220.4954s\n",
      "699it [00:45, 16.33it/s]\titers: 700, epoch: 4 | loss: 0.1975549\n",
      "\tspeed: 0.0639s/iter; left time: 4045.0349s\n",
      "799it [00:51, 15.88it/s]\titers: 800, epoch: 4 | loss: 0.2421163\n",
      "\tspeed: 0.0633s/iter; left time: 4004.0765s\n",
      "899it [00:58, 15.64it/s]\titers: 900, epoch: 4 | loss: 0.2278664\n",
      "\tspeed: 0.0674s/iter; left time: 4252.3354s\n",
      "999it [01:04, 15.14it/s]\titers: 1000, epoch: 4 | loss: 0.2228788\n",
      "\tspeed: 0.0637s/iter; left time: 4013.4850s\n",
      "1099it [01:11, 15.79it/s]\titers: 1100, epoch: 4 | loss: 0.1800691\n",
      "\tspeed: 0.0653s/iter; left time: 4105.5595s\n",
      "1199it [01:17, 13.53it/s]\titers: 1200, epoch: 4 | loss: 0.1924494\n",
      "\tspeed: 0.0665s/iter; left time: 4178.0438s\n",
      "1299it [01:24, 15.72it/s]\titers: 1300, epoch: 4 | loss: 0.3029090\n",
      "\tspeed: 0.0642s/iter; left time: 4027.5513s\n",
      "1399it [01:30, 15.26it/s]\titers: 1400, epoch: 4 | loss: 0.2870390\n",
      "\tspeed: 0.0648s/iter; left time: 4059.2200s\n",
      "1499it [01:37, 14.41it/s]\titers: 1500, epoch: 4 | loss: 0.3282450\n",
      "\tspeed: 0.0659s/iter; left time: 4116.6629s\n",
      "1599it [01:44, 14.14it/s]\titers: 1600, epoch: 4 | loss: 0.2599825\n",
      "\tspeed: 0.0757s/iter; left time: 4724.4752s\n",
      "1699it [01:51, 15.58it/s]\titers: 1700, epoch: 4 | loss: 0.2064519\n",
      "\tspeed: 0.0682s/iter; left time: 4250.7221s\n",
      "1799it [01:58, 15.20it/s]\titers: 1800, epoch: 4 | loss: 0.2098617\n",
      "\tspeed: 0.0679s/iter; left time: 4225.7750s\n",
      "1899it [02:04, 16.10it/s]\titers: 1900, epoch: 4 | loss: 0.2606903\n",
      "\tspeed: 0.0629s/iter; left time: 3903.7190s\n",
      "1999it [02:11, 16.06it/s]\titers: 2000, epoch: 4 | loss: 0.2206062\n",
      "\tspeed: 0.0640s/iter; left time: 3971.1712s\n",
      "2099it [02:17, 16.15it/s]\titers: 2100, epoch: 4 | loss: 0.2280117\n",
      "\tspeed: 0.0667s/iter; left time: 4130.7004s\n",
      "2199it [02:24, 15.78it/s]\titers: 2200, epoch: 4 | loss: 0.2723797\n",
      "\tspeed: 0.0630s/iter; left time: 3891.6316s\n",
      "2299it [02:30, 15.35it/s]\titers: 2300, epoch: 4 | loss: 0.1497230\n",
      "\tspeed: 0.0637s/iter; left time: 3931.9107s\n",
      "2399it [02:37, 15.06it/s]\titers: 2400, epoch: 4 | loss: 0.1706560\n",
      "\tspeed: 0.0663s/iter; left time: 4084.4851s\n",
      "2499it [02:43, 15.64it/s]\titers: 2500, epoch: 4 | loss: 0.1892076\n",
      "\tspeed: 0.0636s/iter; left time: 3909.9513s\n",
      "2599it [02:49, 15.88it/s]\titers: 2600, epoch: 4 | loss: 0.2370274\n",
      "\tspeed: 0.0641s/iter; left time: 3938.8264s\n",
      "2699it [02:56, 12.37it/s]\titers: 2700, epoch: 4 | loss: 0.2875415\n",
      "\tspeed: 0.0679s/iter; left time: 4165.3309s\n",
      "2799it [03:02, 15.29it/s]\titers: 2800, epoch: 4 | loss: 0.2479535\n",
      "\tspeed: 0.0621s/iter; left time: 3798.7946s\n",
      "2899it [03:09, 14.78it/s]\titers: 2900, epoch: 4 | loss: 0.2013184\n",
      "\tspeed: 0.0637s/iter; left time: 3892.7349s\n",
      "2999it [03:15, 13.07it/s]\titers: 3000, epoch: 4 | loss: 0.1513206\n",
      "\tspeed: 0.0671s/iter; left time: 4092.1526s\n",
      "3099it [03:22, 14.97it/s]\titers: 3100, epoch: 4 | loss: 0.3568746\n",
      "\tspeed: 0.0691s/iter; left time: 4206.1438s\n",
      "3199it [03:29, 13.66it/s]\titers: 3200, epoch: 4 | loss: 0.1830495\n",
      "\tspeed: 0.0672s/iter; left time: 4083.2868s\n",
      "3299it [03:36, 15.14it/s]\titers: 3300, epoch: 4 | loss: 0.3516821\n",
      "\tspeed: 0.0656s/iter; left time: 3979.9890s\n",
      "3399it [03:42, 15.11it/s]\titers: 3400, epoch: 4 | loss: 0.5220647\n",
      "\tspeed: 0.0659s/iter; left time: 3992.2192s\n",
      "3499it [03:49, 15.42it/s]\titers: 3500, epoch: 4 | loss: 0.2608746\n",
      "\tspeed: 0.0651s/iter; left time: 3935.9462s\n",
      "3599it [03:55, 14.04it/s]\titers: 3600, epoch: 4 | loss: 0.2053786\n",
      "\tspeed: 0.0658s/iter; left time: 3977.1193s\n",
      "3699it [04:01, 16.45it/s]\titers: 3700, epoch: 4 | loss: 0.1342290\n",
      "\tspeed: 0.0626s/iter; left time: 3773.4069s\n",
      "3765it [04:06, 15.29it/s]\n",
      "Epoch: 4 cost time: 246.20728754997253\n",
      "810it [00:22, 35.51it/s]\n",
      "807it [00:23, 34.74it/s]\n",
      "Epoch: 4 | Train Loss: 0.2499129 Vali Loss: 0.2966581 Test Loss: 0.3651407 MAE Loss: 0.3743777\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "99it [00:06, 15.01it/s]\titers: 100, epoch: 5 | loss: 0.1123981\n",
      "\tspeed: 0.6003s/iter; left time: 36102.1822s\n",
      "199it [00:13, 15.01it/s]\titers: 200, epoch: 5 | loss: 0.2107955\n",
      "\tspeed: 0.0664s/iter; left time: 3985.2155s\n",
      "299it [00:20, 16.05it/s]\titers: 300, epoch: 5 | loss: 0.1289533\n",
      "\tspeed: 0.0662s/iter; left time: 3966.7769s\n",
      "399it [00:26, 16.10it/s]\titers: 400, epoch: 5 | loss: 0.3781210\n",
      "\tspeed: 0.0637s/iter; left time: 3812.7839s\n",
      "499it [00:32, 15.53it/s]\titers: 500, epoch: 5 | loss: 0.1776559\n",
      "\tspeed: 0.0644s/iter; left time: 3846.8740s\n",
      "599it [00:39, 14.91it/s]\titers: 600, epoch: 5 | loss: 0.2202805\n",
      "\tspeed: 0.0664s/iter; left time: 3960.3258s\n",
      "699it [00:45, 15.75it/s]\titers: 700, epoch: 5 | loss: 0.2922030\n",
      "\tspeed: 0.0596s/iter; left time: 3546.9424s\n",
      "799it [00:53, 15.40it/s]\titers: 800, epoch: 5 | loss: 0.2109923\n",
      "\tspeed: 0.0846s/iter; left time: 5031.2240s\n",
      "899it [01:00, 14.63it/s]\titers: 900, epoch: 5 | loss: 0.4018222\n",
      "\tspeed: 0.0700s/iter; left time: 4152.5433s\n",
      "999it [01:07, 15.47it/s]\titers: 1000, epoch: 5 | loss: 0.2406776\n",
      "\tspeed: 0.0657s/iter; left time: 3890.9067s\n",
      "1099it [01:14, 15.13it/s]\titers: 1100, epoch: 5 | loss: 0.2309297\n",
      "\tspeed: 0.0665s/iter; left time: 3934.6147s\n",
      "1199it [01:21, 15.59it/s]\titers: 1200, epoch: 5 | loss: 0.3776409\n",
      "\tspeed: 0.0701s/iter; left time: 4139.0200s\n",
      "1299it [01:27, 15.24it/s]\titers: 1300, epoch: 5 | loss: 0.2000230\n",
      "\tspeed: 0.0653s/iter; left time: 3846.7009s\n",
      "1399it [01:34, 15.08it/s]\titers: 1400, epoch: 5 | loss: 0.2622741\n",
      "\tspeed: 0.0661s/iter; left time: 3886.5529s\n",
      "1499it [01:41, 14.77it/s]\titers: 1500, epoch: 5 | loss: 0.2484586\n",
      "\tspeed: 0.0682s/iter; left time: 4003.3188s\n",
      "1599it [01:47, 15.26it/s]\titers: 1600, epoch: 5 | loss: 0.2005717\n",
      "\tspeed: 0.0651s/iter; left time: 3817.8295s\n",
      "1699it [01:54, 15.16it/s]\titers: 1700, epoch: 5 | loss: 0.2261216\n",
      "\tspeed: 0.0657s/iter; left time: 3845.4225s\n",
      "1799it [02:00, 13.32it/s]\titers: 1800, epoch: 5 | loss: 0.2542133\n",
      "\tspeed: 0.0684s/iter; left time: 3997.0259s\n",
      "1899it [02:07, 14.86it/s]\titers: 1900, epoch: 5 | loss: 0.1634717\n",
      "\tspeed: 0.0641s/iter; left time: 3739.2104s\n",
      "1999it [02:13, 15.08it/s]\titers: 2000, epoch: 5 | loss: 0.3553766\n",
      "\tspeed: 0.0660s/iter; left time: 3842.4089s\n",
      "2099it [02:20, 16.35it/s]\titers: 2100, epoch: 5 | loss: 0.1943088\n",
      "\tspeed: 0.0669s/iter; left time: 3889.5072s\n",
      "2199it [02:26, 15.22it/s]\titers: 2200, epoch: 5 | loss: 0.1610091\n",
      "\tspeed: 0.0630s/iter; left time: 3657.9664s\n",
      "2299it [02:33, 15.63it/s]\titers: 2300, epoch: 5 | loss: 0.1404839\n",
      "\tspeed: 0.0632s/iter; left time: 3661.9216s\n",
      "2399it [02:40, 13.98it/s]\titers: 2400, epoch: 5 | loss: 0.2060732\n",
      "\tspeed: 0.0716s/iter; left time: 4140.8351s\n",
      "2499it [02:47, 14.63it/s]\titers: 2500, epoch: 5 | loss: 0.3878875\n",
      "\tspeed: 0.0688s/iter; left time: 3972.9248s\n",
      "2598it [02:54, 12.67it/s]\titers: 2600, epoch: 5 | loss: 0.2119254\n",
      "\tspeed: 0.0741s/iter; left time: 4273.9516s\n",
      "2698it [03:01, 14.03it/s]\titers: 2700, epoch: 5 | loss: 0.2229400\n",
      "\tspeed: 0.0703s/iter; left time: 4043.4403s\n",
      "2798it [03:08, 15.16it/s]\titers: 2800, epoch: 5 | loss: 0.3755247\n",
      "\tspeed: 0.0646s/iter; left time: 3710.9907s\n",
      "2898it [03:14, 15.79it/s]\titers: 2900, epoch: 5 | loss: 0.1882057\n",
      "\tspeed: 0.0678s/iter; left time: 3885.1253s\n",
      "2998it [03:21, 15.44it/s]\titers: 3000, epoch: 5 | loss: 0.2404755\n",
      "\tspeed: 0.0647s/iter; left time: 3705.8081s\n",
      "3098it [03:27, 15.21it/s]\titers: 3100, epoch: 5 | loss: 0.1888831\n",
      "\tspeed: 0.0646s/iter; left time: 3692.9255s\n",
      "3198it [03:34, 13.36it/s]\titers: 3200, epoch: 5 | loss: 0.2706753\n",
      "\tspeed: 0.0644s/iter; left time: 3672.8977s\n",
      "3298it [03:40, 15.88it/s]\titers: 3300, epoch: 5 | loss: 0.3557244\n",
      "\tspeed: 0.0640s/iter; left time: 3643.3547s\n",
      "3398it [03:47, 15.77it/s]\titers: 3400, epoch: 5 | loss: 0.4302408\n",
      "\tspeed: 0.0636s/iter; left time: 3613.8811s\n",
      "3498it [03:53, 12.40it/s]\titers: 3500, epoch: 5 | loss: 0.3061902\n",
      "\tspeed: 0.0667s/iter; left time: 3783.3020s\n",
      "3598it [04:00, 15.12it/s]\titers: 3600, epoch: 5 | loss: 0.2078661\n",
      "\tspeed: 0.0649s/iter; left time: 3673.4077s\n",
      "3698it [04:06, 17.15it/s]\titers: 3700, epoch: 5 | loss: 0.2266775\n",
      "\tspeed: 0.0630s/iter; left time: 3560.1871s\n",
      "3765it [04:10, 15.02it/s]\n",
      "Epoch: 5 cost time: 250.65710639953613\n",
      "810it [00:23, 34.37it/s]\n",
      "807it [00:23, 33.99it/s]\n",
      "Epoch: 5 | Train Loss: 0.2455455 Vali Loss: 0.2894572 Test Loss: 0.3574075 MAE Loss: 0.3616647\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "99it [00:06, 15.29it/s]\titers: 100, epoch: 6 | loss: 0.4155045\n",
      "\tspeed: 0.6014s/iter; left time: 33903.4173s\n",
      "199it [00:13, 15.43it/s]\titers: 200, epoch: 6 | loss: 0.2151375\n",
      "\tspeed: 0.0682s/iter; left time: 3837.9299s\n",
      "299it [00:19, 15.99it/s]\titers: 300, epoch: 6 | loss: 0.2233660\n",
      "\tspeed: 0.0655s/iter; left time: 3679.2937s\n",
      "399it [00:26, 16.29it/s]\titers: 400, epoch: 6 | loss: 0.2370272\n",
      "\tspeed: 0.0633s/iter; left time: 3551.9772s\n",
      "499it [00:32, 15.14it/s]\titers: 500, epoch: 6 | loss: 0.3249427\n",
      "\tspeed: 0.0669s/iter; left time: 3743.2322s\n",
      "599it [00:39, 15.20it/s]\titers: 600, epoch: 6 | loss: 0.2057504\n",
      "\tspeed: 0.0668s/iter; left time: 3730.7064s\n",
      "699it [00:46, 15.13it/s]\titers: 700, epoch: 6 | loss: 0.2245868\n",
      "\tspeed: 0.0649s/iter; left time: 3621.5401s\n",
      "799it [00:53, 15.18it/s]\titers: 800, epoch: 6 | loss: 0.2150132\n",
      "\tspeed: 0.0714s/iter; left time: 3976.6183s\n",
      "899it [00:59, 14.95it/s]\titers: 900, epoch: 6 | loss: 0.2049391\n",
      "\tspeed: 0.0628s/iter; left time: 3492.0743s\n",
      "999it [01:05, 14.91it/s]\titers: 1000, epoch: 6 | loss: 0.2362233\n",
      "\tspeed: 0.0629s/iter; left time: 3486.7621s\n",
      "1099it [01:12, 16.07it/s]\titers: 1100, epoch: 6 | loss: 0.3349630\n",
      "\tspeed: 0.0661s/iter; left time: 3661.8807s\n",
      "1199it [01:19, 15.26it/s]\titers: 1200, epoch: 6 | loss: 0.2291597\n",
      "\tspeed: 0.0667s/iter; left time: 3689.0608s\n",
      "1299it [01:25, 15.16it/s]\titers: 1300, epoch: 6 | loss: 0.2673230\n",
      "\tspeed: 0.0649s/iter; left time: 3580.7492s\n",
      "1399it [01:32, 14.20it/s]\titers: 1400, epoch: 6 | loss: 0.4808021\n",
      "\tspeed: 0.0706s/iter; left time: 3889.1142s\n",
      "1499it [01:39, 14.34it/s]\titers: 1500, epoch: 6 | loss: 0.2465804\n",
      "\tspeed: 0.0685s/iter; left time: 3767.6201s\n",
      "1599it [01:46, 15.97it/s]\titers: 1600, epoch: 6 | loss: 0.2136759\n",
      "\tspeed: 0.0664s/iter; left time: 3641.5649s\n",
      "1699it [01:53, 14.10it/s]\titers: 1700, epoch: 6 | loss: 0.2059775\n",
      "\tspeed: 0.0704s/iter; left time: 3853.7615s\n",
      "1799it [01:59, 15.14it/s]\titers: 1800, epoch: 6 | loss: 0.2031878\n",
      "\tspeed: 0.0639s/iter; left time: 3494.8315s\n",
      "1899it [02:06, 15.29it/s]\titers: 1900, epoch: 6 | loss: 0.2569441\n",
      "\tspeed: 0.0656s/iter; left time: 3578.3720s\n",
      "1999it [02:12, 15.88it/s]\titers: 2000, epoch: 6 | loss: 0.2712336\n",
      "\tspeed: 0.0683s/iter; left time: 3720.0949s\n",
      "2099it [02:19, 15.25it/s]\titers: 2100, epoch: 6 | loss: 0.2789578\n",
      "\tspeed: 0.0651s/iter; left time: 3538.8900s\n",
      "2199it [02:25, 15.45it/s]\titers: 2200, epoch: 6 | loss: 0.4470836\n",
      "\tspeed: 0.0642s/iter; left time: 3485.7095s\n",
      "2299it [02:32, 15.94it/s]\titers: 2300, epoch: 6 | loss: 0.2961437\n",
      "\tspeed: 0.0702s/iter; left time: 3801.6925s\n",
      "2399it [02:39, 15.79it/s]\titers: 2400, epoch: 6 | loss: 0.2287057\n",
      "\tspeed: 0.0624s/iter; left time: 3374.0040s\n",
      "2499it [02:45, 15.36it/s]\titers: 2500, epoch: 6 | loss: 0.2533989\n",
      "\tspeed: 0.0651s/iter; left time: 3513.4286s\n",
      "2599it [02:52, 15.87it/s]\titers: 2600, epoch: 6 | loss: 0.3319125\n",
      "\tspeed: 0.0690s/iter; left time: 3717.7609s\n",
      "2699it [02:58, 15.86it/s]\titers: 2700, epoch: 6 | loss: 0.2754551\n",
      "\tspeed: 0.0640s/iter; left time: 3442.4326s\n",
      "2799it [03:05, 15.55it/s]\titers: 2800, epoch: 6 | loss: 0.2759766\n",
      "\tspeed: 0.0656s/iter; left time: 3518.8770s\n",
      "2899it [03:12, 15.89it/s]\titers: 2900, epoch: 6 | loss: 0.2929042\n",
      "\tspeed: 0.0691s/iter; left time: 3700.2190s\n",
      "2999it [03:18, 15.44it/s]\titers: 3000, epoch: 6 | loss: 0.2592451\n",
      "\tspeed: 0.0642s/iter; left time: 3431.4171s\n",
      "3099it [03:25, 15.54it/s]\titers: 3100, epoch: 6 | loss: 0.1958182\n",
      "\tspeed: 0.0647s/iter; left time: 3452.6918s\n",
      "3199it [03:31, 15.16it/s]\titers: 3200, epoch: 6 | loss: 0.2920388\n",
      "\tspeed: 0.0645s/iter; left time: 3436.8226s\n",
      "3299it [03:38, 15.59it/s]\titers: 3300, epoch: 6 | loss: 0.2211662\n",
      "\tspeed: 0.0638s/iter; left time: 3394.6524s\n",
      "3399it [03:44, 15.59it/s]\titers: 3400, epoch: 6 | loss: 0.1265130\n",
      "\tspeed: 0.0629s/iter; left time: 3339.1285s\n",
      "3499it [03:51, 10.86it/s]\titers: 3500, epoch: 6 | loss: 0.2550684\n",
      "\tspeed: 0.0693s/iter; left time: 3670.6221s\n",
      "3599it [03:58, 14.62it/s]\titers: 3600, epoch: 6 | loss: 0.1757974\n",
      "\tspeed: 0.0679s/iter; left time: 3589.4018s\n",
      "3699it [04:04, 15.36it/s]\titers: 3700, epoch: 6 | loss: 0.1225053\n",
      "\tspeed: 0.0682s/iter; left time: 3600.8768s\n",
      "3765it [04:09, 15.09it/s]\n",
      "Epoch: 6 cost time: 249.46359276771545\n",
      "810it [00:23, 34.96it/s]\n",
      "807it [00:23, 34.98it/s]\n",
      "Epoch: 6 | Train Loss: 0.2419333 Vali Loss: 0.2892111 Test Loss: 0.3571283 MAE Loss: 0.3614434\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "99it [00:06, 15.13it/s]\titers: 100, epoch: 7 | loss: 0.3755708\n",
      "\tspeed: 0.5990s/iter; left time: 31515.4167s\n",
      "199it [00:13, 15.25it/s]\titers: 200, epoch: 7 | loss: 0.1756885\n",
      "\tspeed: 0.0632s/iter; left time: 3316.6107s\n",
      "299it [00:19, 15.38it/s]\titers: 300, epoch: 7 | loss: 0.2545287\n",
      "\tspeed: 0.0659s/iter; left time: 3456.3325s\n",
      "399it [00:26, 15.17it/s]\titers: 400, epoch: 7 | loss: 0.2934910\n",
      "\tspeed: 0.0660s/iter; left time: 3452.4453s\n",
      "499it [00:33, 14.13it/s]\titers: 500, epoch: 7 | loss: 0.1888867\n",
      "\tspeed: 0.0705s/iter; left time: 3679.6623s\n",
      "599it [00:40, 13.69it/s]\titers: 600, epoch: 7 | loss: 0.3608443\n",
      "\tspeed: 0.0704s/iter; left time: 3669.3634s\n",
      "699it [00:47, 16.61it/s]\titers: 700, epoch: 7 | loss: 0.2574110\n",
      "\tspeed: 0.0684s/iter; left time: 3555.0965s\n",
      "799it [00:54, 13.97it/s]\titers: 800, epoch: 7 | loss: 0.1950595\n",
      "\tspeed: 0.0695s/iter; left time: 3606.5328s\n",
      "899it [01:00, 15.78it/s]\titers: 900, epoch: 7 | loss: 0.2976969\n",
      "\tspeed: 0.0663s/iter; left time: 3435.4333s\n",
      "999it [01:07, 13.90it/s]\titers: 1000, epoch: 7 | loss: 0.1752623\n",
      "\tspeed: 0.0694s/iter; left time: 3591.1877s\n",
      "1099it [01:14, 15.67it/s]\titers: 1100, epoch: 7 | loss: 0.1814448\n",
      "\tspeed: 0.0712s/iter; left time: 3676.8496s\n",
      "1199it [01:21, 15.52it/s]\titers: 1200, epoch: 7 | loss: 0.1131182\n",
      "\tspeed: 0.0647s/iter; left time: 3332.7229s\n",
      "1299it [01:27, 15.87it/s]\titers: 1300, epoch: 7 | loss: 0.1894270\n",
      "\tspeed: 0.0635s/iter; left time: 3263.9715s\n",
      "1399it [01:34, 15.71it/s]\titers: 1400, epoch: 7 | loss: 0.1981000\n",
      "\tspeed: 0.0641s/iter; left time: 3290.7053s\n",
      "1499it [01:40, 16.30it/s]\titers: 1500, epoch: 7 | loss: 0.1791575\n",
      "\tspeed: 0.0630s/iter; left time: 3226.8126s\n",
      "1599it [01:46, 15.78it/s]\titers: 1600, epoch: 7 | loss: 0.1704624\n",
      "\tspeed: 0.0621s/iter; left time: 3173.2277s\n",
      "1699it [01:53, 16.18it/s]\titers: 1700, epoch: 7 | loss: 0.2538942\n",
      "\tspeed: 0.0661s/iter; left time: 3374.1756s\n",
      "1799it [01:59, 15.66it/s]\titers: 1800, epoch: 7 | loss: 0.1871732\n",
      "\tspeed: 0.0644s/iter; left time: 3276.2959s\n",
      "1899it [02:06, 15.22it/s]\titers: 1900, epoch: 7 | loss: 0.2823605\n",
      "\tspeed: 0.0644s/iter; left time: 3272.0371s\n",
      "1999it [02:12, 16.10it/s]\titers: 2000, epoch: 7 | loss: 0.4445322\n",
      "\tspeed: 0.0678s/iter; left time: 3439.4261s\n",
      "2099it [02:19, 15.72it/s]\titers: 2100, epoch: 7 | loss: 0.2962854\n",
      "\tspeed: 0.0631s/iter; left time: 3192.1028s\n",
      "2199it [02:25, 15.41it/s]\titers: 2200, epoch: 7 | loss: 0.2771426\n",
      "\tspeed: 0.0621s/iter; left time: 3136.5327s\n",
      "2299it [02:31, 16.05it/s]\titers: 2300, epoch: 7 | loss: 0.2426527\n",
      "\tspeed: 0.0650s/iter; left time: 3278.3331s\n",
      "2399it [02:38, 15.64it/s]\titers: 2400, epoch: 7 | loss: 0.3367086\n",
      "\tspeed: 0.0641s/iter; left time: 3223.0074s\n",
      "2499it [02:44, 15.41it/s]\titers: 2500, epoch: 7 | loss: 0.1935951\n",
      "\tspeed: 0.0640s/iter; left time: 3215.3658s\n",
      "2599it [02:51, 16.03it/s]\titers: 2600, epoch: 7 | loss: 0.1862796\n",
      "\tspeed: 0.0678s/iter; left time: 3398.5853s\n",
      "2699it [02:57, 15.53it/s]\titers: 2700, epoch: 7 | loss: 0.2568911\n",
      "\tspeed: 0.0631s/iter; left time: 3155.0619s\n",
      "2799it [03:04, 15.47it/s]\titers: 2800, epoch: 7 | loss: 0.3016179\n",
      "\tspeed: 0.0631s/iter; left time: 3147.5495s\n",
      "2899it [03:10, 15.38it/s]\titers: 2900, epoch: 7 | loss: 0.2567457\n",
      "\tspeed: 0.0677s/iter; left time: 3369.7859s\n",
      "2999it [03:17, 15.66it/s]\titers: 3000, epoch: 7 | loss: 0.2577315\n",
      "\tspeed: 0.0652s/iter; left time: 3240.7088s\n",
      "3099it [03:23, 15.49it/s]\titers: 3100, epoch: 7 | loss: 0.1764490\n",
      "\tspeed: 0.0631s/iter; left time: 3129.2517s\n",
      "3199it [03:30, 16.10it/s]\titers: 3200, epoch: 7 | loss: 0.2115007\n",
      "\tspeed: 0.0691s/iter; left time: 3421.9284s\n",
      "3299it [03:37, 15.35it/s]\titers: 3300, epoch: 7 | loss: 0.2941763\n",
      "\tspeed: 0.0644s/iter; left time: 3181.0613s\n",
      "3399it [03:43, 15.03it/s]\titers: 3400, epoch: 7 | loss: 0.1953549\n",
      "\tspeed: 0.0657s/iter; left time: 3240.0570s\n",
      "3499it [03:50, 15.65it/s]\titers: 3500, epoch: 7 | loss: 0.3348430\n",
      "\tspeed: 0.0690s/iter; left time: 3397.8274s\n",
      "3599it [03:56, 16.21it/s]\titers: 3600, epoch: 7 | loss: 0.2835595\n",
      "\tspeed: 0.0613s/iter; left time: 3010.4840s\n",
      "3699it [04:03, 15.29it/s]\titers: 3700, epoch: 7 | loss: 0.2593045\n",
      "\tspeed: 0.0643s/iter; left time: 3152.1821s\n",
      "3765it [04:07, 15.23it/s]\n",
      "Epoch: 7 cost time: 247.17385578155518\n",
      "810it [00:23, 34.50it/s]\n",
      "807it [00:22, 35.32it/s]\n",
      "Epoch: 7 | Train Loss: 0.2412956 Vali Loss: 0.2868791 Test Loss: 0.3543772 MAE Loss: 0.3594986\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "99it [00:06, 19.83it/s]\titers: 100, epoch: 8 | loss: 0.2224935\n",
      "\tspeed: 0.5864s/iter; left time: 28642.0468s\n",
      "198it [00:11, 16.17it/s]\titers: 200, epoch: 8 | loss: 0.2044067\n",
      "\tspeed: 0.0590s/iter; left time: 2875.7838s\n",
      "298it [00:18, 15.66it/s]\titers: 300, epoch: 8 | loss: 0.1038597\n",
      "\tspeed: 0.0625s/iter; left time: 3040.1208s\n",
      "398it [00:24, 15.14it/s]\titers: 400, epoch: 8 | loss: 0.1543410\n",
      "\tspeed: 0.0647s/iter; left time: 3139.2949s\n",
      "497it [00:31, 19.39it/s]\titers: 500, epoch: 8 | loss: 0.2309961\n",
      "\tspeed: 0.0652s/iter; left time: 3160.0353s\n",
      "599it [00:36, 20.15it/s]\titers: 600, epoch: 8 | loss: 0.2914826\n",
      "\tspeed: 0.0505s/iter; left time: 2442.3531s\n",
      "698it [00:41, 20.09it/s]\titers: 700, epoch: 8 | loss: 0.3107494\n",
      "\tspeed: 0.0494s/iter; left time: 2384.7821s\n",
      "797it [00:46, 20.05it/s]\titers: 800, epoch: 8 | loss: 0.1408462\n",
      "\tspeed: 0.0499s/iter; left time: 2403.4868s\n",
      "899it [00:51, 17.64it/s]\titers: 900, epoch: 8 | loss: 0.2760729\n",
      "\tspeed: 0.0541s/iter; left time: 2600.2087s\n",
      "998it [00:57, 15.60it/s]\titers: 1000, epoch: 8 | loss: 0.1479827\n",
      "\tspeed: 0.0602s/iter; left time: 2886.6740s\n",
      "1098it [01:03, 15.73it/s]\titers: 1100, epoch: 8 | loss: 0.1647125\n",
      "\tspeed: 0.0629s/iter; left time: 3007.1734s\n",
      "1198it [01:10, 15.46it/s]\titers: 1200, epoch: 8 | loss: 0.3855052\n",
      "\tspeed: 0.0655s/iter; left time: 3127.0189s\n",
      "1298it [01:16, 16.37it/s]\titers: 1300, epoch: 8 | loss: 0.2248528\n",
      "\tspeed: 0.0619s/iter; left time: 2947.3665s\n",
      "1398it [01:22, 15.31it/s]\titers: 1400, epoch: 8 | loss: 0.1797119\n",
      "\tspeed: 0.0626s/iter; left time: 2978.6863s\n",
      "1498it [01:29, 16.02it/s]\titers: 1500, epoch: 8 | loss: 0.2034261\n",
      "\tspeed: 0.0649s/iter; left time: 3078.2126s\n",
      "1598it [01:35, 15.64it/s]\titers: 1600, epoch: 8 | loss: 0.3035041\n",
      "\tspeed: 0.0625s/iter; left time: 2958.9167s\n",
      "1698it [01:42, 15.56it/s]\titers: 1700, epoch: 8 | loss: 0.1762127\n",
      "\tspeed: 0.0640s/iter; left time: 3021.8044s\n",
      "1798it [01:48, 16.20it/s]\titers: 1800, epoch: 8 | loss: 0.3360490\n",
      "\tspeed: 0.0660s/iter; left time: 3112.5039s\n",
      "1898it [01:55, 15.63it/s]\titers: 1900, epoch: 8 | loss: 0.1874921\n",
      "\tspeed: 0.0636s/iter; left time: 2992.9954s\n",
      "1998it [02:01, 15.43it/s]\titers: 2000, epoch: 8 | loss: 0.1278186\n",
      "\tspeed: 0.0651s/iter; left time: 3056.1974s\n",
      "2098it [02:08, 16.54it/s]\titers: 2100, epoch: 8 | loss: 0.1297460\n",
      "\tspeed: 0.0684s/iter; left time: 3204.8639s\n",
      "2198it [02:14, 15.59it/s]\titers: 2200, epoch: 8 | loss: 0.2459786\n",
      "\tspeed: 0.0622s/iter; left time: 2908.9094s\n",
      "2298it [02:21, 15.54it/s]\titers: 2300, epoch: 8 | loss: 0.1471041\n",
      "\tspeed: 0.0642s/iter; left time: 2996.0878s\n",
      "2398it [02:27, 16.47it/s]\titers: 2400, epoch: 8 | loss: 0.4369275\n",
      "\tspeed: 0.0682s/iter; left time: 3173.0920s\n",
      "2498it [02:33, 16.49it/s]\titers: 2500, epoch: 8 | loss: 0.2633002\n",
      "\tspeed: 0.0607s/iter; left time: 2818.3451s\n",
      "2598it [02:40, 10.31it/s]\titers: 2600, epoch: 8 | loss: 0.3233567\n",
      "\tspeed: 0.0680s/iter; left time: 3153.3242s\n",
      "2698it [02:47, 16.02it/s]\titers: 2700, epoch: 8 | loss: 0.2161634\n",
      "\tspeed: 0.0629s/iter; left time: 2910.8849s\n",
      "2798it [02:53, 15.97it/s]\titers: 2800, epoch: 8 | loss: 0.2650145\n",
      "\tspeed: 0.0630s/iter; left time: 2906.1978s\n",
      "2898it [03:00, 10.23it/s]\titers: 2900, epoch: 8 | loss: 0.1921072\n",
      "\tspeed: 0.0694s/iter; left time: 3197.0158s\n",
      "2998it [03:06, 15.80it/s]\titers: 3000, epoch: 8 | loss: 0.1592651\n",
      "\tspeed: 0.0621s/iter; left time: 2853.0081s\n",
      "3098it [03:12, 15.57it/s]\titers: 3100, epoch: 8 | loss: 0.1788701\n",
      "\tspeed: 0.0633s/iter; left time: 2904.0992s\n",
      "3198it [03:19, 14.03it/s]\titers: 3200, epoch: 8 | loss: 0.3043209\n",
      "\tspeed: 0.0671s/iter; left time: 3070.9920s\n",
      "3298it [03:25, 15.57it/s]\titers: 3300, epoch: 8 | loss: 0.2385036\n",
      "\tspeed: 0.0640s/iter; left time: 2919.4134s\n",
      "3398it [03:32, 15.47it/s]\titers: 3400, epoch: 8 | loss: 0.1678842\n",
      "\tspeed: 0.0634s/iter; left time: 2888.2669s\n",
      "3499it [03:38, 19.65it/s]\titers: 3500, epoch: 8 | loss: 0.2638773\n",
      "\tspeed: 0.0575s/iter; left time: 2614.5690s\n",
      "3598it [03:43, 15.96it/s]\titers: 3600, epoch: 8 | loss: 0.2820717\n",
      "\tspeed: 0.0587s/iter; left time: 2659.7423s\n",
      "3698it [03:50, 15.55it/s]\titers: 3700, epoch: 8 | loss: 0.0960728\n",
      "\tspeed: 0.0631s/iter; left time: 2854.2053s\n",
      "3765it [03:54, 16.07it/s]\n",
      "Epoch: 8 cost time: 234.2793345451355\n",
      "810it [00:23, 34.72it/s]\n",
      "807it [00:23, 34.92it/s]\n",
      "Epoch: 8 | Train Loss: 0.2410483 Vali Loss: 0.2871329 Test Loss: 0.3549889 MAE Loss: 0.3607748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "99it [00:06, 15.46it/s]\titers: 100, epoch: 9 | loss: 0.1438134\n",
      "\tspeed: 0.5739s/iter; left time: 25871.6682s\n",
      "199it [00:13, 15.25it/s]\titers: 200, epoch: 9 | loss: 0.3153541\n",
      "\tspeed: 0.0650s/iter; left time: 2925.7174s\n",
      "299it [00:19, 16.07it/s]\titers: 300, epoch: 9 | loss: 0.4425206\n",
      "\tspeed: 0.0665s/iter; left time: 2982.6772s\n",
      "399it [00:26, 15.60it/s]\titers: 400, epoch: 9 | loss: 0.1034750\n",
      "\tspeed: 0.0638s/iter; left time: 2857.0393s\n",
      "499it [00:32, 15.25it/s]\titers: 500, epoch: 9 | loss: 0.2935615\n",
      "\tspeed: 0.0647s/iter; left time: 2892.1706s\n",
      "599it [00:39, 14.23it/s]\titers: 600, epoch: 9 | loss: 0.2302960\n",
      "\tspeed: 0.0651s/iter; left time: 2902.7581s\n",
      "699it [00:45, 15.15it/s]\titers: 700, epoch: 9 | loss: 0.1624193\n",
      "\tspeed: 0.0639s/iter; left time: 2843.5966s\n",
      "799it [00:52, 15.12it/s]\titers: 800, epoch: 9 | loss: 0.1916170\n",
      "\tspeed: 0.0662s/iter; left time: 2936.2389s\n",
      "899it [00:59, 16.98it/s]\titers: 900, epoch: 9 | loss: 0.2105528\n",
      "\tspeed: 0.0680s/iter; left time: 3009.0126s\n",
      "999it [01:05, 16.76it/s]\titers: 1000, epoch: 9 | loss: 0.2711023\n",
      "\tspeed: 0.0618s/iter; left time: 2729.6510s\n",
      "1099it [01:11, 18.49it/s]\titers: 1100, epoch: 9 | loss: 0.2673998\n",
      "\tspeed: 0.0649s/iter; left time: 2859.5405s\n",
      "1198it [01:17, 19.43it/s]\titers: 1200, epoch: 9 | loss: 0.1544502\n",
      "\tspeed: 0.0606s/iter; left time: 2663.3371s\n",
      "1299it [01:23, 16.44it/s]\titers: 1300, epoch: 9 | loss: 0.1365122\n",
      "\tspeed: 0.0583s/iter; left time: 2559.8882s\n",
      "1399it [01:29, 14.89it/s]\titers: 1400, epoch: 9 | loss: 0.1936604\n",
      "\tspeed: 0.0626s/iter; left time: 2740.6103s\n",
      "1499it [01:37, 16.03it/s]\titers: 1500, epoch: 9 | loss: 0.2028575\n",
      "\tspeed: 0.0711s/iter; left time: 3106.3337s\n",
      "1599it [01:43, 15.04it/s]\titers: 1600, epoch: 9 | loss: 0.1639494\n",
      "\tspeed: 0.0692s/iter; left time: 3014.7167s\n",
      "1699it [01:50, 13.89it/s]\titers: 1700, epoch: 9 | loss: 0.5783395\n",
      "\tspeed: 0.0669s/iter; left time: 2907.8190s\n",
      "1799it [01:58, 13.65it/s]\titers: 1800, epoch: 9 | loss: 0.2934180\n",
      "\tspeed: 0.0750s/iter; left time: 3254.2576s\n",
      "1899it [02:04, 15.38it/s]\titers: 1900, epoch: 9 | loss: 0.1467383\n",
      "\tspeed: 0.0653s/iter; left time: 2824.6697s\n",
      "1999it [02:12, 14.26it/s]\titers: 2000, epoch: 9 | loss: 0.2441390\n",
      "\tspeed: 0.0744s/iter; left time: 3210.7164s\n",
      "2099it [02:18, 14.10it/s]\titers: 2100, epoch: 9 | loss: 0.1274403\n",
      "\tspeed: 0.0678s/iter; left time: 2923.0002s\n",
      "2199it [02:25, 15.28it/s]\titers: 2200, epoch: 9 | loss: 0.2353911\n",
      "\tspeed: 0.0660s/iter; left time: 2834.8758s\n",
      "2299it [02:32, 16.37it/s]\titers: 2300, epoch: 9 | loss: 0.1641532\n",
      "\tspeed: 0.0659s/iter; left time: 2827.1198s\n",
      "2399it [02:38, 15.62it/s]\titers: 2400, epoch: 9 | loss: 0.1710678\n",
      "\tspeed: 0.0639s/iter; left time: 2734.5670s\n",
      "2499it [02:44, 15.61it/s]\titers: 2500, epoch: 9 | loss: 0.1746087\n",
      "\tspeed: 0.0644s/iter; left time: 2747.0585s\n",
      "2599it [02:51, 13.59it/s]\titers: 2600, epoch: 9 | loss: 0.1394702\n",
      "\tspeed: 0.0693s/iter; left time: 2952.7911s\n",
      "2699it [02:58, 16.33it/s]\titers: 2700, epoch: 9 | loss: 0.1887179\n",
      "\tspeed: 0.0622s/iter; left time: 2643.9687s\n",
      "2799it [03:04, 15.59it/s]\titers: 2800, epoch: 9 | loss: 0.2198702\n",
      "\tspeed: 0.0597s/iter; left time: 2529.6325s\n",
      "2899it [03:10, 11.08it/s]\titers: 2900, epoch: 9 | loss: 0.3595637\n",
      "\tspeed: 0.0677s/iter; left time: 2860.7049s\n",
      "2999it [03:17, 16.45it/s]\titers: 3000, epoch: 9 | loss: 0.1445765\n",
      "\tspeed: 0.0629s/iter; left time: 2651.1238s\n",
      "3099it [03:23, 15.94it/s]\titers: 3100, epoch: 9 | loss: 0.3077244\n",
      "\tspeed: 0.0614s/iter; left time: 2585.7387s\n",
      "3199it [03:30, 14.99it/s]\titers: 3200, epoch: 9 | loss: 0.2367380\n",
      "\tspeed: 0.0690s/iter; left time: 2897.5253s\n",
      "3299it [03:36, 15.91it/s]\titers: 3300, epoch: 9 | loss: 0.1797716\n",
      "\tspeed: 0.0630s/iter; left time: 2640.2563s\n",
      "3399it [03:43, 15.26it/s]\titers: 3400, epoch: 9 | loss: 0.1403939\n",
      "\tspeed: 0.0664s/iter; left time: 2774.1000s\n",
      "3499it [03:50, 13.96it/s]\titers: 3500, epoch: 9 | loss: 0.2329953\n",
      "\tspeed: 0.0716s/iter; left time: 2983.4741s\n",
      "3599it [03:56, 15.57it/s]\titers: 3600, epoch: 9 | loss: 0.2639203\n",
      "\tspeed: 0.0630s/iter; left time: 2619.2415s\n",
      "3699it [04:02, 15.29it/s]\titers: 3700, epoch: 9 | loss: 0.1373141\n",
      "\tspeed: 0.0640s/iter; left time: 2654.0059s\n",
      "3765it [04:07, 15.23it/s]\n",
      "Epoch: 9 cost time: 247.23481607437134\n",
      "810it [00:22, 35.61it/s]\n",
      "807it [00:22, 35.51it/s]\n",
      "Epoch: 9 | Train Loss: 0.2405042 Vali Loss: 0.2867072 Test Loss: 0.3545933 MAE Loss: 0.3590756\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "99it [00:06, 15.63it/s]\titers: 100, epoch: 10 | loss: 0.3972464\n",
      "\tspeed: 0.5851s/iter; left time: 24174.4506s\n",
      "199it [00:13, 15.66it/s]\titers: 200, epoch: 10 | loss: 0.2279532\n",
      "\tspeed: 0.0655s/iter; left time: 2698.5396s\n",
      "299it [00:19, 15.70it/s]\titers: 300, epoch: 10 | loss: 0.2912650\n",
      "\tspeed: 0.0632s/iter; left time: 2597.8381s\n",
      "398it [00:25, 15.24it/s]\titers: 400, epoch: 10 | loss: 0.1637478\n",
      "\tspeed: 0.0621s/iter; left time: 2548.1802s\n",
      "498it [00:32, 14.73it/s]\titers: 500, epoch: 10 | loss: 0.2050238\n",
      "\tspeed: 0.0670s/iter; left time: 2740.2560s\n",
      "598it [00:38, 14.92it/s]\titers: 600, epoch: 10 | loss: 0.1919203\n",
      "\tspeed: 0.0641s/iter; left time: 2616.1766s\n",
      "698it [00:45, 17.34it/s]\titers: 700, epoch: 10 | loss: 0.3335089\n",
      "\tspeed: 0.0634s/iter; left time: 2582.2856s\n",
      "798it [00:51, 15.70it/s]\titers: 800, epoch: 10 | loss: 0.1561195\n",
      "\tspeed: 0.0653s/iter; left time: 2652.2917s\n",
      "898it [00:58, 14.63it/s]\titers: 900, epoch: 10 | loss: 0.1851393\n",
      "\tspeed: 0.0665s/iter; left time: 2693.1382s\n",
      "998it [01:04, 15.18it/s]\titers: 1000, epoch: 10 | loss: 0.2193477\n",
      "\tspeed: 0.0614s/iter; left time: 2481.6750s\n",
      "1098it [01:11, 15.09it/s]\titers: 1100, epoch: 10 | loss: 0.1650451\n",
      "\tspeed: 0.0666s/iter; left time: 2686.8983s\n",
      "1198it [01:17, 15.77it/s]\titers: 1200, epoch: 10 | loss: 0.3965899\n",
      "\tspeed: 0.0636s/iter; left time: 2558.2610s\n",
      "1298it [01:23, 15.47it/s]\titers: 1300, epoch: 10 | loss: 0.1840114\n",
      "\tspeed: 0.0642s/iter; left time: 2574.8144s\n",
      "1398it [01:30, 14.18it/s]\titers: 1400, epoch: 10 | loss: 0.2338235\n",
      "\tspeed: 0.0653s/iter; left time: 2613.0050s\n",
      "1498it [01:36, 15.54it/s]\titers: 1500, epoch: 10 | loss: 0.2544596\n",
      "\tspeed: 0.0626s/iter; left time: 2496.8462s\n",
      "1598it [01:43, 15.77it/s]\titers: 1600, epoch: 10 | loss: 0.1930967\n",
      "\tspeed: 0.0643s/iter; left time: 2558.7457s\n",
      "1698it [01:49, 15.69it/s]\titers: 1700, epoch: 10 | loss: 0.1582661\n",
      "\tspeed: 0.0660s/iter; left time: 2622.6278s\n",
      "1798it [01:56, 16.29it/s]\titers: 1800, epoch: 10 | loss: 0.2678743\n",
      "\tspeed: 0.0641s/iter; left time: 2538.1102s\n",
      "1899it [02:02, 19.55it/s]\titers: 1900, epoch: 10 | loss: 0.2291739\n",
      "\tspeed: 0.0618s/iter; left time: 2440.9093s\n",
      "1997it [02:07, 19.57it/s]\titers: 2000, epoch: 10 | loss: 0.2255884\n",
      "\tspeed: 0.0539s/iter; left time: 2126.3717s\n",
      "2098it [02:13, 16.39it/s]\titers: 2100, epoch: 10 | loss: 0.4371972\n",
      "\tspeed: 0.0602s/iter; left time: 2368.4840s\n",
      "2198it [02:20, 14.71it/s]\titers: 2200, epoch: 10 | loss: 0.2235700\n",
      "\tspeed: 0.0641s/iter; left time: 2512.6893s\n",
      "2298it [02:26, 15.73it/s]\titers: 2300, epoch: 10 | loss: 0.5989801\n",
      "\tspeed: 0.0653s/iter; left time: 2555.5105s\n",
      "2398it [02:33, 15.67it/s]\titers: 2400, epoch: 10 | loss: 0.1996730\n",
      "\tspeed: 0.0685s/iter; left time: 2671.3600s\n",
      "2498it [02:40, 14.54it/s]\titers: 2500, epoch: 10 | loss: 0.1260048\n",
      "\tspeed: 0.0657s/iter; left time: 2558.4502s\n",
      "2598it [02:46, 15.26it/s]\titers: 2600, epoch: 10 | loss: 0.2941970\n",
      "\tspeed: 0.0657s/iter; left time: 2548.8015s\n",
      "2698it [02:53, 15.86it/s]\titers: 2700, epoch: 10 | loss: 0.2032500\n",
      "\tspeed: 0.0656s/iter; left time: 2538.8135s\n",
      "2798it [02:59, 15.72it/s]\titers: 2800, epoch: 10 | loss: 0.3878573\n",
      "\tspeed: 0.0631s/iter; left time: 2438.5119s\n",
      "2898it [03:06, 15.34it/s]\titers: 2900, epoch: 10 | loss: 0.3162101\n",
      "\tspeed: 0.0660s/iter; left time: 2542.5424s\n",
      "2998it [03:12, 16.01it/s]\titers: 3000, epoch: 10 | loss: 0.1755231\n",
      "\tspeed: 0.0684s/iter; left time: 2629.3100s\n",
      "3098it [03:19, 15.72it/s]\titers: 3100, epoch: 10 | loss: 0.5846490\n",
      "\tspeed: 0.0638s/iter; left time: 2444.5801s\n",
      "3198it [03:25, 15.15it/s]\titers: 3200, epoch: 10 | loss: 0.3587353\n",
      "\tspeed: 0.0652s/iter; left time: 2491.1610s\n",
      "3298it [03:32, 16.47it/s]\titers: 3300, epoch: 10 | loss: 0.3651359\n",
      "\tspeed: 0.0655s/iter; left time: 2496.0994s\n",
      "3398it [03:38, 16.39it/s]\titers: 3400, epoch: 10 | loss: 0.2639170\n",
      "\tspeed: 0.0617s/iter; left time: 2347.1396s\n",
      "3498it [03:44, 15.59it/s]\titers: 3500, epoch: 10 | loss: 0.1750275\n",
      "\tspeed: 0.0618s/iter; left time: 2342.6821s\n",
      "3598it [03:51, 14.97it/s]\titers: 3600, epoch: 10 | loss: 0.2482153\n",
      "\tspeed: 0.0676s/iter; left time: 2557.6929s\n",
      "3698it [03:57, 15.87it/s]\titers: 3700, epoch: 10 | loss: 0.3747338\n",
      "\tspeed: 0.0634s/iter; left time: 2392.0804s\n",
      "3765it [04:02, 15.54it/s]\n",
      "Epoch: 10 cost time: 242.3334138393402\n",
      "810it [00:23, 34.06it/s]\n",
      "807it [00:23, 34.65it/s]\n",
      "Epoch: 10 | Train Loss: 0.2407713 Vali Loss: 0.2868628 Test Loss: 0.3545096 MAE Loss: 0.3595430\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "99it [00:07, 14.97it/s]\titers: 100, epoch: 11 | loss: 0.1523518\n",
      "\tspeed: 0.5877s/iter; left time: 22066.9629s\n",
      "199it [00:13, 15.41it/s]\titers: 200, epoch: 11 | loss: 0.1788480\n",
      "\tspeed: 0.0675s/iter; left time: 2527.8263s\n",
      "299it [00:20, 15.28it/s]\titers: 300, epoch: 11 | loss: 0.1941694\n",
      "\tspeed: 0.0676s/iter; left time: 2526.2513s\n",
      "399it [00:27, 13.98it/s]\titers: 400, epoch: 11 | loss: 0.2509474\n",
      "\tspeed: 0.0707s/iter; left time: 2632.8470s\n",
      "499it [00:34, 13.34it/s]\titers: 500, epoch: 11 | loss: 0.1987103\n",
      "\tspeed: 0.0689s/iter; left time: 2561.1591s\n",
      "599it [00:41, 15.92it/s]\titers: 600, epoch: 11 | loss: 0.2572412\n",
      "\tspeed: 0.0682s/iter; left time: 2525.7669s\n",
      "699it [00:48, 15.67it/s]\titers: 700, epoch: 11 | loss: 0.2392495\n",
      "\tspeed: 0.0721s/iter; left time: 2663.8116s\n",
      "799it [00:55, 15.00it/s]\titers: 800, epoch: 11 | loss: 0.1718923\n",
      "\tspeed: 0.0648s/iter; left time: 2386.9926s\n",
      "899it [01:01, 15.61it/s]\titers: 900, epoch: 11 | loss: 0.3663811\n",
      "\tspeed: 0.0650s/iter; left time: 2390.1987s\n",
      "999it [01:07, 19.64it/s]\titers: 1000, epoch: 11 | loss: 0.1906657\n",
      "\tspeed: 0.0630s/iter; left time: 2310.0655s\n",
      "1099it [01:14, 15.60it/s]\titers: 1100, epoch: 11 | loss: 0.1568315\n",
      "\tspeed: 0.0625s/iter; left time: 2283.6844s\n",
      "1199it [01:20, 15.72it/s]\titers: 1200, epoch: 11 | loss: 0.1380863\n",
      "\tspeed: 0.0656s/iter; left time: 2390.7856s\n",
      "1299it [01:27, 14.33it/s]\titers: 1300, epoch: 11 | loss: 0.3951476\n",
      "\tspeed: 0.0663s/iter; left time: 2408.4098s\n",
      "1399it [01:34, 15.32it/s]\titers: 1400, epoch: 11 | loss: 0.1509212\n",
      "\tspeed: 0.0668s/iter; left time: 2422.5927s\n",
      "1499it [01:40, 15.18it/s]\titers: 1500, epoch: 11 | loss: 0.2031958\n",
      "\tspeed: 0.0657s/iter; left time: 2374.9672s\n",
      "1599it [01:47, 15.31it/s]\titers: 1600, epoch: 11 | loss: 0.3048785\n",
      "\tspeed: 0.0696s/iter; left time: 2510.3946s\n",
      "1699it [01:54, 13.20it/s]\titers: 1700, epoch: 11 | loss: 0.2224412\n",
      "\tspeed: 0.0676s/iter; left time: 2431.9201s\n",
      "1799it [02:02, 11.70it/s]\titers: 1800, epoch: 11 | loss: 0.1976964\n",
      "\tspeed: 0.0780s/iter; left time: 2795.7843s\n",
      "1899it [02:08, 14.84it/s]\titers: 1900, epoch: 11 | loss: 0.2001353\n",
      "\tspeed: 0.0682s/iter; left time: 2438.6166s\n",
      "1999it [02:15, 15.55it/s]\titers: 2000, epoch: 11 | loss: 0.2133107\n",
      "\tspeed: 0.0642s/iter; left time: 2287.0985s\n",
      "2099it [02:22, 15.95it/s]\titers: 2100, epoch: 11 | loss: 0.3001105\n",
      "\tspeed: 0.0672s/iter; left time: 2388.9025s\n",
      "2199it [02:28, 19.35it/s]\titers: 2200, epoch: 11 | loss: 0.2117094\n",
      "\tspeed: 0.0614s/iter; left time: 2177.0739s\n",
      "2299it [02:33, 19.65it/s]\titers: 2300, epoch: 11 | loss: 0.1308386\n",
      "\tspeed: 0.0508s/iter; left time: 1796.1041s\n",
      "2399it [02:39, 14.85it/s]\titers: 2400, epoch: 11 | loss: 0.2182207\n",
      "\tspeed: 0.0617s/iter; left time: 2175.1240s\n",
      "2498it [02:45, 16.10it/s]\titers: 2500, epoch: 11 | loss: 0.2155576\n",
      "\tspeed: 0.0591s/iter; left time: 2078.1343s\n",
      "2598it [02:51, 15.52it/s]\titers: 2600, epoch: 11 | loss: 0.2568840\n",
      "\tspeed: 0.0638s/iter; left time: 2235.8221s\n",
      "2698it [02:58, 11.13it/s]\titers: 2700, epoch: 11 | loss: 0.1326563\n",
      "\tspeed: 0.0694s/iter; left time: 2424.6734s\n",
      "2798it [03:04, 16.19it/s]\titers: 2800, epoch: 11 | loss: 0.1121421\n",
      "\tspeed: 0.0626s/iter; left time: 2181.8454s\n",
      "2898it [03:11, 15.42it/s]\titers: 2900, epoch: 11 | loss: 0.1698917\n",
      "\tspeed: 0.0639s/iter; left time: 2219.6599s\n",
      "2998it [03:18, 13.92it/s]\titers: 3000, epoch: 11 | loss: 0.2847153\n",
      "\tspeed: 0.0697s/iter; left time: 2413.5913s\n",
      "3098it [03:24, 16.27it/s]\titers: 3100, epoch: 11 | loss: 0.2408329\n",
      "\tspeed: 0.0622s/iter; left time: 2147.3729s\n",
      "3198it [03:30, 15.70it/s]\titers: 3200, epoch: 11 | loss: 0.2004641\n",
      "\tspeed: 0.0636s/iter; left time: 2192.1488s\n",
      "3298it [03:37, 13.01it/s]\titers: 3300, epoch: 11 | loss: 0.3276578\n",
      "\tspeed: 0.0705s/iter; left time: 2421.8977s\n",
      "3398it [03:44, 16.37it/s]\titers: 3400, epoch: 11 | loss: 0.3011216\n",
      "\tspeed: 0.0621s/iter; left time: 2125.9751s\n",
      "3498it [03:50, 15.88it/s]\titers: 3500, epoch: 11 | loss: 0.3440614\n",
      "\tspeed: 0.0631s/iter; left time: 2156.3648s\n",
      "3598it [03:57, 15.49it/s]\titers: 3600, epoch: 11 | loss: 0.2644449\n",
      "\tspeed: 0.0686s/iter; left time: 2335.4309s\n",
      "3698it [04:04, 16.86it/s]\titers: 3700, epoch: 11 | loss: 0.1537652\n",
      "\tspeed: 0.0761s/iter; left time: 2582.4418s\n",
      "3765it [04:09, 15.11it/s]\n",
      "Epoch: 11 cost time: 249.10235953330994\n",
      "810it [00:22, 35.89it/s]\n",
      "807it [00:23, 34.86it/s]\n",
      "Epoch: 11 | Train Loss: 0.2403472 Vali Loss: 0.2866376 Test Loss: 0.3537605 MAE Loss: 0.3585937\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "99it [00:06, 17.46it/s]\titers: 100, epoch: 12 | loss: 0.3085007\n",
      "\tspeed: 0.5891s/iter; left time: 19904.7016s\n",
      "199it [00:13, 15.57it/s]\titers: 200, epoch: 12 | loss: 0.1332655\n",
      "\tspeed: 0.0639s/iter; left time: 2153.3090s\n",
      "299it [00:19, 15.22it/s]\titers: 300, epoch: 12 | loss: 0.1796459\n",
      "\tspeed: 0.0652s/iter; left time: 2188.2247s\n",
      "399it [00:26, 16.25it/s]\titers: 400, epoch: 12 | loss: 0.1470300\n",
      "\tspeed: 0.0632s/iter; left time: 2117.7317s\n",
      "499it [00:32, 15.79it/s]\titers: 500, epoch: 12 | loss: 0.2110700\n",
      "\tspeed: 0.0629s/iter; left time: 2100.0498s\n",
      "599it [00:39, 11.83it/s]\titers: 600, epoch: 12 | loss: 0.3484653\n",
      "\tspeed: 0.0667s/iter; left time: 2220.0102s\n",
      "699it [00:45, 16.48it/s]\titers: 700, epoch: 12 | loss: 0.1754405\n",
      "\tspeed: 0.0631s/iter; left time: 2093.6678s\n",
      "799it [00:51, 16.23it/s]\titers: 800, epoch: 12 | loss: 0.3128537\n",
      "\tspeed: 0.0617s/iter; left time: 2043.0322s\n",
      "899it [00:57, 15.86it/s]\titers: 900, epoch: 12 | loss: 0.2986689\n",
      "\tspeed: 0.0643s/iter; left time: 2120.2816s\n",
      "999it [01:04, 16.44it/s]\titers: 1000, epoch: 12 | loss: 0.1743185\n",
      "\tspeed: 0.0623s/iter; left time: 2049.9975s\n",
      "1099it [01:10, 15.84it/s]\titers: 1100, epoch: 12 | loss: 0.1906256\n",
      "\tspeed: 0.0626s/iter; left time: 2053.6793s\n",
      "1199it [01:16, 16.05it/s]\titers: 1200, epoch: 12 | loss: 0.2786244\n",
      "\tspeed: 0.0633s/iter; left time: 2070.4755s\n",
      "1299it [01:23, 14.73it/s]\titers: 1300, epoch: 12 | loss: 0.3473099\n",
      "\tspeed: 0.0653s/iter; left time: 2129.3729s\n",
      "1399it [01:30, 14.55it/s]\titers: 1400, epoch: 12 | loss: 0.2028490\n",
      "\tspeed: 0.0681s/iter; left time: 2213.5010s\n",
      "1499it [01:36, 15.55it/s]\titers: 1500, epoch: 12 | loss: 0.1583905\n",
      "\tspeed: 0.0677s/iter; left time: 2191.8800s\n",
      "1599it [01:43, 16.10it/s]\titers: 1600, epoch: 12 | loss: 0.2504120\n",
      "\tspeed: 0.0621s/iter; left time: 2003.3803s\n",
      "1699it [01:49, 15.25it/s]\titers: 1700, epoch: 12 | loss: 0.1546139\n",
      "\tspeed: 0.0635s/iter; left time: 2043.0444s\n",
      "1799it [01:55, 15.93it/s]\titers: 1800, epoch: 12 | loss: 0.1471218\n",
      "\tspeed: 0.0652s/iter; left time: 2091.2437s\n",
      "1899it [02:02, 15.04it/s]\titers: 1900, epoch: 12 | loss: 0.2878406\n",
      "\tspeed: 0.0632s/iter; left time: 2021.2574s\n",
      "1999it [02:08, 15.21it/s]\titers: 2000, epoch: 12 | loss: 0.1285395\n",
      "\tspeed: 0.0647s/iter; left time: 2063.3056s\n",
      "2099it [02:15, 14.82it/s]\titers: 2100, epoch: 12 | loss: 0.1859432\n",
      "\tspeed: 0.0654s/iter; left time: 2077.6319s\n",
      "2199it [02:21, 16.44it/s]\titers: 2200, epoch: 12 | loss: 0.2538866\n",
      "\tspeed: 0.0628s/iter; left time: 1989.7613s\n",
      "2299it [02:27, 14.00it/s]\titers: 2300, epoch: 12 | loss: 0.2070795\n",
      "\tspeed: 0.0640s/iter; left time: 2020.8613s\n",
      "2399it [02:34, 15.96it/s]\titers: 2400, epoch: 12 | loss: 0.3111381\n",
      "\tspeed: 0.0639s/iter; left time: 2012.2453s\n",
      "2499it [02:40, 15.54it/s]\titers: 2500, epoch: 12 | loss: 0.4293250\n",
      "\tspeed: 0.0629s/iter; left time: 1973.9704s\n",
      "2599it [02:47, 13.61it/s]\titers: 2600, epoch: 12 | loss: 0.2364888\n",
      "\tspeed: 0.0643s/iter; left time: 2012.3983s\n",
      "2699it [02:53, 16.04it/s]\titers: 2700, epoch: 12 | loss: 0.2943379\n",
      "\tspeed: 0.0638s/iter; left time: 1991.0521s\n",
      "2799it [02:59, 15.60it/s]\titers: 2800, epoch: 12 | loss: 0.2269082\n",
      "\tspeed: 0.0627s/iter; left time: 1947.5488s\n",
      "2899it [03:06, 14.71it/s]\titers: 2900, epoch: 12 | loss: 0.2235478\n",
      "\tspeed: 0.0635s/iter; left time: 1966.2835s\n",
      "2999it [03:12, 17.86it/s]\titers: 3000, epoch: 12 | loss: 0.5443007\n",
      "\tspeed: 0.0645s/iter; left time: 1993.5566s\n",
      "3099it [03:18, 15.50it/s]\titers: 3100, epoch: 12 | loss: 0.1725603\n",
      "\tspeed: 0.0608s/iter; left time: 1872.8980s\n",
      "3199it [03:25, 15.10it/s]\titers: 3200, epoch: 12 | loss: 0.2618819\n",
      "\tspeed: 0.0650s/iter; left time: 1993.1833s\n",
      "3299it [03:31, 16.47it/s]\titers: 3300, epoch: 12 | loss: 0.3100971\n",
      "\tspeed: 0.0660s/iter; left time: 2018.0569s\n",
      "3399it [03:37, 15.67it/s]\titers: 3400, epoch: 12 | loss: 0.2671025\n",
      "\tspeed: 0.0608s/iter; left time: 1853.8412s\n",
      "3499it [03:44, 14.79it/s]\titers: 3500, epoch: 12 | loss: 0.1404945\n",
      "\tspeed: 0.0630s/iter; left time: 1915.5331s\n",
      "3599it [03:50, 15.95it/s]\titers: 3600, epoch: 12 | loss: 0.2807010\n",
      "\tspeed: 0.0651s/iter; left time: 1971.7177s\n",
      "3698it [03:56, 16.29it/s]\titers: 3700, epoch: 12 | loss: 0.2870910\n",
      "\tspeed: 0.0564s/iter; left time: 1702.2502s\n",
      "3765it [03:59, 15.69it/s]\n",
      "Epoch: 12 cost time: 239.98393058776855\n",
      "810it [00:23, 33.94it/s]\n",
      "807it [00:22, 35.16it/s]\n",
      "Epoch: 12 | Train Loss: 0.2403952 Vali Loss: 0.2869440 Test Loss: 0.3544106 MAE Loss: 0.3595624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "99it [00:06, 16.04it/s]\titers: 100, epoch: 13 | loss: 0.2628521\n",
      "\tspeed: 0.5721s/iter; left time: 17174.1669s\n",
      "199it [00:12, 16.67it/s]\titers: 200, epoch: 13 | loss: 0.1684883\n",
      "\tspeed: 0.0640s/iter; left time: 1914.4460s\n",
      "298it [00:18, 15.98it/s]\titers: 300, epoch: 13 | loss: 0.3153008\n",
      "\tspeed: 0.0584s/iter; left time: 1741.9203s\n",
      "398it [00:24, 15.68it/s]\titers: 400, epoch: 13 | loss: 0.1417075\n",
      "\tspeed: 0.0613s/iter; left time: 1822.9501s\n",
      "498it [00:31, 15.95it/s]\titers: 500, epoch: 13 | loss: 0.1456744\n",
      "\tspeed: 0.0645s/iter; left time: 1911.0956s\n",
      "598it [00:37, 15.49it/s]\titers: 600, epoch: 13 | loss: 0.1803585\n",
      "\tspeed: 0.0636s/iter; left time: 1876.6041s\n",
      "698it [00:43, 15.70it/s]\titers: 700, epoch: 13 | loss: 0.3078794\n",
      "\tspeed: 0.0610s/iter; left time: 1795.8805s\n",
      "798it [00:50, 15.91it/s]\titers: 800, epoch: 13 | loss: 0.2227665\n",
      "\tspeed: 0.0652s/iter; left time: 1913.0315s\n",
      "898it [00:56, 15.93it/s]\titers: 900, epoch: 13 | loss: 0.2230606\n",
      "\tspeed: 0.0634s/iter; left time: 1853.5320s\n",
      "998it [01:03, 15.46it/s]\titers: 1000, epoch: 13 | loss: 0.1995756\n",
      "\tspeed: 0.0639s/iter; left time: 1859.9926s\n",
      "1098it [01:09, 15.62it/s]\titers: 1100, epoch: 13 | loss: 0.2893338\n",
      "\tspeed: 0.0665s/iter; left time: 1929.9095s\n",
      "1198it [01:15, 15.81it/s]\titers: 1200, epoch: 13 | loss: 0.2073116\n",
      "\tspeed: 0.0629s/iter; left time: 1818.6719s\n",
      "1298it [01:22, 16.46it/s]\titers: 1300, epoch: 13 | loss: 0.2569440\n",
      "\tspeed: 0.0621s/iter; left time: 1788.9370s\n",
      "1398it [01:28, 16.08it/s]\titers: 1400, epoch: 13 | loss: 0.2835281\n",
      "\tspeed: 0.0653s/iter; left time: 1875.7184s\n",
      "1498it [01:34, 19.56it/s]\titers: 1500, epoch: 13 | loss: 0.1431955\n",
      "\tspeed: 0.0559s/iter; left time: 1598.9745s\n",
      "1599it [01:39, 19.63it/s]\titers: 1600, epoch: 13 | loss: 0.1538688\n",
      "\tspeed: 0.0510s/iter; left time: 1453.2541s\n",
      "1698it [01:44, 19.38it/s]\titers: 1700, epoch: 13 | loss: 0.3327123\n",
      "\tspeed: 0.0532s/iter; left time: 1512.3464s\n",
      "1798it [01:49, 20.12it/s]\titers: 1800, epoch: 13 | loss: 0.2021110\n",
      "\tspeed: 0.0524s/iter; left time: 1484.4561s\n",
      "1899it [01:55, 16.25it/s]\titers: 1900, epoch: 13 | loss: 0.4123766\n",
      "\tspeed: 0.0589s/iter; left time: 1660.9804s\n",
      "1999it [02:02, 16.01it/s]\titers: 2000, epoch: 13 | loss: 0.2209519\n",
      "\tspeed: 0.0626s/iter; left time: 1759.4440s\n",
      "2099it [02:08, 16.20it/s]\titers: 2100, epoch: 13 | loss: 0.2995470\n",
      "\tspeed: 0.0682s/iter; left time: 1911.9626s\n",
      "2199it [02:15, 15.61it/s]\titers: 2200, epoch: 13 | loss: 0.1898121\n",
      "\tspeed: 0.0620s/iter; left time: 1729.9893s\n",
      "2299it [02:21, 15.50it/s]\titers: 2300, epoch: 13 | loss: 0.1993044\n",
      "\tspeed: 0.0635s/iter; left time: 1767.4364s\n",
      "2399it [02:28, 14.55it/s]\titers: 2400, epoch: 13 | loss: 0.2087336\n",
      "\tspeed: 0.0732s/iter; left time: 2028.3172s\n",
      "2499it [02:35, 16.07it/s]\titers: 2500, epoch: 13 | loss: 0.2090921\n",
      "\tspeed: 0.0679s/iter; left time: 1874.4330s\n",
      "2599it [02:42, 12.22it/s]\titers: 2600, epoch: 13 | loss: 0.2740145\n",
      "\tspeed: 0.0689s/iter; left time: 1895.8986s\n",
      "2699it [02:49, 14.11it/s]\titers: 2700, epoch: 13 | loss: 0.1732064\n",
      "\tspeed: 0.0722s/iter; left time: 1979.3265s\n",
      "2799it [02:56, 14.55it/s]\titers: 2800, epoch: 13 | loss: 0.1894887\n",
      "\tspeed: 0.0636s/iter; left time: 1737.1593s\n",
      "2899it [03:02, 17.15it/s]\titers: 2900, epoch: 13 | loss: 0.1692419\n",
      "\tspeed: 0.0684s/iter; left time: 1862.0000s\n",
      "2999it [03:09, 14.07it/s]\titers: 3000, epoch: 13 | loss: 0.2913737\n",
      "\tspeed: 0.0654s/iter; left time: 1773.4403s\n",
      "3099it [03:16, 13.51it/s]\titers: 3100, epoch: 13 | loss: 0.2039373\n",
      "\tspeed: 0.0683s/iter; left time: 1845.8429s\n",
      "3199it [03:23, 16.49it/s]\titers: 3200, epoch: 13 | loss: 0.4868638\n",
      "\tspeed: 0.0690s/iter; left time: 1856.8779s\n",
      "3299it [03:29, 16.48it/s]\titers: 3300, epoch: 13 | loss: 0.2281553\n",
      "\tspeed: 0.0622s/iter; left time: 1667.9792s\n",
      "3399it [03:35, 16.03it/s]\titers: 3400, epoch: 13 | loss: 0.2060827\n",
      "\tspeed: 0.0611s/iter; left time: 1631.9816s\n",
      "3499it [03:42, 15.61it/s]\titers: 3500, epoch: 13 | loss: 0.1951438\n",
      "\tspeed: 0.0670s/iter; left time: 1784.5781s\n",
      "3598it [03:47, 20.24it/s]\titers: 3600, epoch: 13 | loss: 0.1788611\n",
      "\tspeed: 0.0561s/iter; left time: 1486.6080s\n",
      "3699it [03:54, 15.17it/s]\titers: 3700, epoch: 13 | loss: 0.2662455\n",
      "\tspeed: 0.0641s/iter; left time: 1693.8779s\n",
      "3765it [03:58, 15.76it/s]\n",
      "Epoch: 13 cost time: 238.86319088935852\n",
      "810it [00:23, 34.80it/s]\n",
      "807it [00:22, 35.30it/s]\n",
      "Epoch: 13 | Train Loss: 0.2408106 Vali Loss: 0.2869270 Test Loss: 0.3545165 MAE Loss: 0.3596092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.765624999999999e-09\n",
      "99it [00:06, 15.38it/s]\titers: 100, epoch: 14 | loss: 0.2766951\n",
      "\tspeed: 0.5765s/iter; left time: 15136.1426s\n",
      "199it [00:12, 19.89it/s]\titers: 200, epoch: 14 | loss: 0.2088864\n",
      "\tspeed: 0.0601s/iter; left time: 1571.5559s\n",
      "298it [00:17, 19.79it/s]\titers: 300, epoch: 14 | loss: 0.2911074\n",
      "\tspeed: 0.0511s/iter; left time: 1330.1929s\n",
      "398it [00:22, 20.04it/s]\titers: 400, epoch: 14 | loss: 0.1669109\n",
      "\tspeed: 0.0503s/iter; left time: 1304.4077s\n",
      "498it [00:27, 19.60it/s]\titers: 500, epoch: 14 | loss: 0.2670271\n",
      "\tspeed: 0.0510s/iter; left time: 1318.0768s\n",
      "599it [00:35, 15.36it/s]\titers: 600, epoch: 14 | loss: 0.4604237\n",
      "\tspeed: 0.0711s/iter; left time: 1831.8506s\n",
      "699it [00:41, 16.26it/s]\titers: 700, epoch: 14 | loss: 0.3117603\n",
      "\tspeed: 0.0616s/iter; left time: 1580.0993s\n",
      "799it [00:48, 13.75it/s]\titers: 800, epoch: 14 | loss: 0.2060950\n",
      "\tspeed: 0.0669s/iter; left time: 1710.6157s\n",
      "899it [00:54, 15.88it/s]\titers: 900, epoch: 14 | loss: 0.3709309\n",
      "\tspeed: 0.0637s/iter; left time: 1621.2778s\n",
      "999it [00:59, 19.71it/s]\titers: 1000, epoch: 14 | loss: 0.2843518\n",
      "\tspeed: 0.0554s/iter; left time: 1404.5230s\n",
      "1099it [01:05, 16.33it/s]\titers: 1100, epoch: 14 | loss: 0.1702826\n",
      "\tspeed: 0.0518s/iter; left time: 1308.2513s\n",
      "1199it [01:11, 13.67it/s]\titers: 1200, epoch: 14 | loss: 0.2288027\n",
      "\tspeed: 0.0642s/iter; left time: 1615.4597s\n",
      "1299it [01:17, 16.41it/s]\titers: 1300, epoch: 14 | loss: 0.2078893\n",
      "\tspeed: 0.0609s/iter; left time: 1527.1616s\n",
      "1399it [01:23, 15.40it/s]\titers: 1400, epoch: 14 | loss: 0.1316809\n",
      "\tspeed: 0.0626s/iter; left time: 1562.6970s\n",
      "1499it [01:29, 18.29it/s]\titers: 1500, epoch: 14 | loss: 0.3166687\n",
      "\tspeed: 0.0584s/iter; left time: 1452.0059s\n",
      "1599it [01:34, 17.02it/s]\titers: 1600, epoch: 14 | loss: 0.1217285\n",
      "\tspeed: 0.0506s/iter; left time: 1252.8158s\n",
      "1699it [01:41, 15.75it/s]\titers: 1700, epoch: 14 | loss: 0.1879709\n",
      "\tspeed: 0.0631s/iter; left time: 1555.9349s\n",
      "1799it [01:47, 14.33it/s]\titers: 1800, epoch: 14 | loss: 0.2517678\n",
      "\tspeed: 0.0669s/iter; left time: 1643.2588s\n",
      "1899it [01:54, 15.62it/s]\titers: 1900, epoch: 14 | loss: 0.1492695\n",
      "\tspeed: 0.0623s/iter; left time: 1523.2686s\n",
      "1999it [02:00, 18.25it/s]\titers: 2000, epoch: 14 | loss: 0.1484565\n",
      "\tspeed: 0.0619s/iter; left time: 1506.7768s\n",
      "2099it [02:06, 18.92it/s]\titers: 2100, epoch: 14 | loss: 0.2174385\n",
      "\tspeed: 0.0600s/iter; left time: 1456.3091s\n",
      "2198it [02:11, 16.15it/s]\titers: 2200, epoch: 14 | loss: 0.2208518\n",
      "\tspeed: 0.0526s/iter; left time: 1271.4137s\n",
      "2298it [02:17, 19.80it/s]\titers: 2300, epoch: 14 | loss: 0.1313207\n",
      "\tspeed: 0.0584s/iter; left time: 1403.8238s\n",
      "2399it [02:22, 20.10it/s]\titers: 2400, epoch: 14 | loss: 0.1164559\n",
      "\tspeed: 0.0523s/iter; left time: 1253.0773s\n",
      "2497it [02:27, 20.38it/s]\titers: 2500, epoch: 14 | loss: 0.2819122\n",
      "\tspeed: 0.0504s/iter; left time: 1203.3475s\n",
      "2599it [02:32, 20.36it/s]\titers: 2600, epoch: 14 | loss: 0.2359000\n",
      "\tspeed: 0.0494s/iter; left time: 1172.4804s\n",
      "2698it [02:37, 15.49it/s]\titers: 2700, epoch: 14 | loss: 0.1793555\n",
      "\tspeed: 0.0521s/iter; left time: 1231.9161s\n",
      "2798it [02:44, 16.57it/s]\titers: 2800, epoch: 14 | loss: 0.5488445\n",
      "\tspeed: 0.0661s/iter; left time: 1555.9646s\n",
      "2898it [02:50, 15.57it/s]\titers: 2900, epoch: 14 | loss: 0.2586073\n",
      "\tspeed: 0.0634s/iter; left time: 1486.2684s\n",
      "2998it [02:57, 12.77it/s]\titers: 3000, epoch: 14 | loss: 0.3459770\n",
      "\tspeed: 0.0665s/iter; left time: 1554.0302s\n",
      "3098it [03:03, 15.87it/s]\titers: 3100, epoch: 14 | loss: 0.1972141\n",
      "\tspeed: 0.0633s/iter; left time: 1472.6145s\n",
      "3198it [03:09, 15.67it/s]\titers: 3200, epoch: 14 | loss: 0.2222412\n",
      "\tspeed: 0.0636s/iter; left time: 1472.4765s\n",
      "3298it [03:16, 14.12it/s]\titers: 3300, epoch: 14 | loss: 0.2366683\n",
      "\tspeed: 0.0654s/iter; left time: 1507.7605s\n",
      "3398it [03:22, 16.49it/s]\titers: 3400, epoch: 14 | loss: 0.5761340\n",
      "\tspeed: 0.0627s/iter; left time: 1438.7323s\n",
      "3498it [03:28, 16.48it/s]\titers: 3500, epoch: 14 | loss: 0.2705685\n",
      "\tspeed: 0.0608s/iter; left time: 1389.4950s\n",
      "3598it [03:35, 16.07it/s]\titers: 3600, epoch: 14 | loss: 0.3616163\n",
      "\tspeed: 0.0631s/iter; left time: 1434.9999s\n",
      "3698it [03:41, 16.28it/s]\titers: 3700, epoch: 14 | loss: 0.1656536\n",
      "\tspeed: 0.0630s/iter; left time: 1426.4998s\n",
      "3765it [03:45, 16.67it/s]\n",
      "Epoch: 14 cost time: 225.79718136787415\n",
      "810it [00:23, 34.61it/s]\n",
      "807it [00:23, 34.86it/s]\n",
      "Epoch: 14 | Train Loss: 0.2405387 Vali Loss: 0.2868419 Test Loss: 0.3544639 MAE Loss: 0.3595170\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.8828124999999996e-09\n",
      "99it [00:06, 15.75it/s]\titers: 100, epoch: 15 | loss: 0.1462605\n",
      "\tspeed: 0.5774s/iter; left time: 12986.6269s\n",
      "199it [00:13, 15.68it/s]\titers: 200, epoch: 15 | loss: 0.5276050\n",
      "\tspeed: 0.0637s/iter; left time: 1426.3613s\n",
      "299it [00:19, 19.72it/s]\titers: 300, epoch: 15 | loss: 0.1919925\n",
      "\tspeed: 0.0623s/iter; left time: 1388.9755s\n",
      "398it [00:24, 16.40it/s]\titers: 400, epoch: 15 | loss: 0.1474142\n",
      "\tspeed: 0.0572s/iter; left time: 1268.9503s\n",
      "498it [00:31, 16.12it/s]\titers: 500, epoch: 15 | loss: 0.2179147\n",
      "\tspeed: 0.0609s/iter; left time: 1345.3732s\n",
      "598it [00:37, 16.41it/s]\titers: 600, epoch: 15 | loss: 0.1850785\n",
      "\tspeed: 0.0638s/iter; left time: 1402.7690s\n",
      "698it [00:43, 15.54it/s]\titers: 700, epoch: 15 | loss: 0.1606525\n",
      "\tspeed: 0.0628s/iter; left time: 1373.6975s\n",
      "798it [00:50, 15.67it/s]\titers: 800, epoch: 15 | loss: 0.3099542\n",
      "\tspeed: 0.0636s/iter; left time: 1385.2253s\n",
      "898it [00:56, 16.30it/s]\titers: 900, epoch: 15 | loss: 0.1873751\n",
      "\tspeed: 0.0644s/iter; left time: 1396.4146s\n",
      "998it [01:02, 15.70it/s]\titers: 1000, epoch: 15 | loss: 0.2166293\n",
      "\tspeed: 0.0639s/iter; left time: 1379.0261s\n",
      "1098it [01:09, 15.66it/s]\titers: 1100, epoch: 15 | loss: 0.3537371\n",
      "\tspeed: 0.0640s/iter; left time: 1374.7457s\n",
      "1198it [01:16, 14.52it/s]\titers: 1200, epoch: 15 | loss: 0.4045269\n",
      "\tspeed: 0.0674s/iter; left time: 1440.9448s\n",
      "1298it [01:21, 20.12it/s]\titers: 1300, epoch: 15 | loss: 0.2008556\n",
      "\tspeed: 0.0582s/iter; left time: 1239.4644s\n",
      "1398it [01:27, 15.77it/s]\titers: 1400, epoch: 15 | loss: 0.1684144\n",
      "\tspeed: 0.0599s/iter; left time: 1268.4408s\n",
      "1498it [01:34, 16.48it/s]\titers: 1500, epoch: 15 | loss: 0.1317047\n",
      "\tspeed: 0.0680s/iter; left time: 1433.4027s\n",
      "1598it [01:40, 15.32it/s]\titers: 1600, epoch: 15 | loss: 0.1608481\n",
      "\tspeed: 0.0623s/iter; left time: 1307.4586s\n",
      "1698it [01:47, 15.55it/s]\titers: 1700, epoch: 15 | loss: 0.1544187\n",
      "\tspeed: 0.0647s/iter; left time: 1351.1819s\n",
      "1798it [01:53, 16.51it/s]\titers: 1800, epoch: 15 | loss: 0.2390110\n",
      "\tspeed: 0.0660s/iter; left time: 1372.2738s\n",
      "1898it [02:00, 15.30it/s]\titers: 1900, epoch: 15 | loss: 0.2357488\n",
      "\tspeed: 0.0645s/iter; left time: 1333.9436s\n",
      "1998it [02:06, 15.12it/s]\titers: 2000, epoch: 15 | loss: 0.1244796\n",
      "\tspeed: 0.0625s/iter; left time: 1286.2211s\n",
      "2098it [02:12, 19.48it/s]\titers: 2100, epoch: 15 | loss: 0.5285318\n",
      "\tspeed: 0.0604s/iter; left time: 1237.6179s\n",
      "2199it [02:17, 19.67it/s]\titers: 2200, epoch: 15 | loss: 0.2301651\n",
      "\tspeed: 0.0523s/iter; left time: 1067.0166s\n",
      "2298it [02:23, 19.85it/s]\titers: 2300, epoch: 15 | loss: 0.2886354\n",
      "\tspeed: 0.0508s/iter; left time: 1030.3732s\n",
      "2399it [02:28, 16.71it/s]\titers: 2400, epoch: 15 | loss: 0.3394863\n",
      "\tspeed: 0.0573s/iter; left time: 1156.9102s\n",
      "2499it [02:35, 16.10it/s]\titers: 2500, epoch: 15 | loss: 0.1666542\n",
      "\tspeed: 0.0704s/iter; left time: 1414.0004s\n",
      "2599it [02:42, 15.88it/s]\titers: 2600, epoch: 15 | loss: 0.2026832\n",
      "\tspeed: 0.0633s/iter; left time: 1265.8226s\n",
      "2699it [02:48, 14.21it/s]\titers: 2700, epoch: 15 | loss: 0.2042899\n",
      "\tspeed: 0.0647s/iter; left time: 1287.3573s\n",
      "2799it [02:55, 15.71it/s]\titers: 2800, epoch: 15 | loss: 0.1342990\n",
      "\tspeed: 0.0682s/iter; left time: 1350.3095s\n",
      "2899it [03:02, 15.49it/s]\titers: 2900, epoch: 15 | loss: 0.2600103\n",
      "\tspeed: 0.0669s/iter; left time: 1317.2145s\n",
      "2999it [03:08, 16.00it/s]\titers: 3000, epoch: 15 | loss: 0.1590758\n",
      "\tspeed: 0.0627s/iter; left time: 1227.6285s\n",
      "3099it [03:14, 16.46it/s]\titers: 3100, epoch: 15 | loss: 0.1108824\n",
      "\tspeed: 0.0651s/iter; left time: 1268.2421s\n",
      "3199it [03:21, 16.07it/s]\titers: 3200, epoch: 15 | loss: 0.5454468\n",
      "\tspeed: 0.0609s/iter; left time: 1181.7447s\n",
      "3299it [03:27, 14.78it/s]\titers: 3300, epoch: 15 | loss: 0.2585146\n",
      "\tspeed: 0.0653s/iter; left time: 1260.1964s\n",
      "3399it [03:34, 15.98it/s]\titers: 3400, epoch: 15 | loss: 0.1515789\n",
      "\tspeed: 0.0672s/iter; left time: 1289.4534s\n",
      "3499it [03:40, 15.76it/s]\titers: 3500, epoch: 15 | loss: 0.2614948\n",
      "\tspeed: 0.0628s/iter; left time: 1198.9763s\n",
      "3599it [03:46, 15.54it/s]\titers: 3600, epoch: 15 | loss: 0.1294327\n",
      "\tspeed: 0.0637s/iter; left time: 1209.2498s\n",
      "3699it [03:53, 15.55it/s]\titers: 3700, epoch: 15 | loss: 0.2644349\n",
      "\tspeed: 0.0663s/iter; left time: 1253.1052s\n",
      "3765it [03:57, 15.83it/s]\n",
      "Epoch: 15 cost time: 237.804429769516\n",
      "810it [00:22, 35.45it/s]\n",
      "807it [00:22, 35.15it/s]\n",
      "Epoch: 15 | Train Loss: 0.2401748 Vali Loss: 0.2868109 Test Loss: 0.3544210 MAE Loss: 0.3594698\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.4414062499999998e-09\n",
      "99it [00:07, 14.13it/s]\titers: 100, epoch: 16 | loss: 0.1313339\n",
      "\tspeed: 0.5758s/iter; left time: 10782.0462s\n",
      "199it [00:14, 15.09it/s]\titers: 200, epoch: 16 | loss: 0.3213878\n",
      "\tspeed: 0.0737s/iter; left time: 1373.3754s\n",
      "299it [00:21, 15.32it/s]\titers: 300, epoch: 16 | loss: 0.1721865\n",
      "\tspeed: 0.0642s/iter; left time: 1189.5845s\n",
      "399it [00:27, 15.39it/s]\titers: 400, epoch: 16 | loss: 0.1876957\n",
      "\tspeed: 0.0657s/iter; left time: 1210.9384s\n",
      "499it [00:34, 16.09it/s]\titers: 500, epoch: 16 | loss: 0.1850105\n",
      "\tspeed: 0.0701s/iter; left time: 1284.4668s\n",
      "599it [00:41, 15.57it/s]\titers: 600, epoch: 16 | loss: 0.3622075\n",
      "\tspeed: 0.0647s/iter; left time: 1179.1533s\n",
      "699it [00:47, 10.32it/s]\titers: 700, epoch: 16 | loss: 0.2453377\n",
      "\tspeed: 0.0668s/iter; left time: 1211.5515s\n",
      "799it [00:54, 16.01it/s]\titers: 800, epoch: 16 | loss: 0.2593257\n",
      "\tspeed: 0.0680s/iter; left time: 1225.1445s\n",
      "899it [01:01, 15.45it/s]\titers: 900, epoch: 16 | loss: 0.2161812\n",
      "\tspeed: 0.0640s/iter; left time: 1146.7692s\n",
      "999it [01:07, 12.11it/s]\titers: 1000, epoch: 16 | loss: 0.2872171\n",
      "\tspeed: 0.0676s/iter; left time: 1205.1291s\n",
      "1099it [01:14, 16.11it/s]\titers: 1100, epoch: 16 | loss: 0.4407399\n",
      "\tspeed: 0.0620s/iter; left time: 1098.5607s\n",
      "1199it [01:20, 14.62it/s]\titers: 1200, epoch: 16 | loss: 0.5879644\n",
      "\tspeed: 0.0652s/iter; left time: 1148.8315s\n",
      "1299it [01:27, 13.95it/s]\titers: 1300, epoch: 16 | loss: 0.1737542\n",
      "\tspeed: 0.0720s/iter; left time: 1262.5919s\n",
      "1399it [01:34, 15.41it/s]\titers: 1400, epoch: 16 | loss: 0.2089980\n",
      "\tspeed: 0.0663s/iter; left time: 1155.6179s\n",
      "1499it [01:40, 15.34it/s]\titers: 1500, epoch: 16 | loss: 0.3415230\n",
      "\tspeed: 0.0623s/iter; left time: 1079.0407s\n",
      "1599it [01:47, 14.99it/s]\titers: 1600, epoch: 16 | loss: 0.3892488\n",
      "\tspeed: 0.0668s/iter; left time: 1150.0274s\n",
      "1699it [01:54, 14.51it/s]\titers: 1700, epoch: 16 | loss: 0.1921915\n",
      "\tspeed: 0.0716s/iter; left time: 1226.7704s\n",
      "1799it [02:00, 14.12it/s]\titers: 1800, epoch: 16 | loss: 0.2437634\n",
      "\tspeed: 0.0645s/iter; left time: 1098.3814s\n",
      "1898it [02:08, 13.78it/s]\titers: 1900, epoch: 16 | loss: 0.3115801\n",
      "\tspeed: 0.0755s/iter; left time: 1278.7168s\n",
      "1998it [02:15, 15.83it/s]\titers: 2000, epoch: 16 | loss: 0.2143061\n",
      "\tspeed: 0.0677s/iter; left time: 1139.5607s\n",
      "2098it [02:21, 14.98it/s]\titers: 2100, epoch: 16 | loss: 0.1305671\n",
      "\tspeed: 0.0671s/iter; left time: 1122.4326s\n",
      "2198it [02:28, 16.11it/s]\titers: 2200, epoch: 16 | loss: 0.2081653\n",
      "\tspeed: 0.0672s/iter; left time: 1116.5650s\n",
      "2298it [02:34, 17.39it/s]\titers: 2300, epoch: 16 | loss: 0.1036527\n",
      "\tspeed: 0.0627s/iter; left time: 1035.5890s\n",
      "2398it [02:41, 15.56it/s]\titers: 2400, epoch: 16 | loss: 0.2199027\n",
      "\tspeed: 0.0630s/iter; left time: 1035.4282s\n",
      "2498it [02:47, 14.32it/s]\titers: 2500, epoch: 16 | loss: 0.3010949\n",
      "\tspeed: 0.0658s/iter; left time: 1074.1468s\n",
      "2598it [02:54, 15.56it/s]\titers: 2600, epoch: 16 | loss: 0.1576370\n",
      "\tspeed: 0.0632s/iter; left time: 1024.6723s\n",
      "2698it [03:00, 17.16it/s]\titers: 2700, epoch: 16 | loss: 0.5059547\n",
      "\tspeed: 0.0614s/iter; left time: 990.4463s\n",
      "2798it [03:06, 16.48it/s]\titers: 2800, epoch: 16 | loss: 0.1300958\n",
      "\tspeed: 0.0652s/iter; left time: 1044.7375s\n",
      "2898it [03:12, 16.16it/s]\titers: 2900, epoch: 16 | loss: 0.2122274\n",
      "\tspeed: 0.0614s/iter; left time: 977.3613s\n",
      "2998it [03:19, 15.60it/s]\titers: 3000, epoch: 16 | loss: 0.2932600\n",
      "\tspeed: 0.0643s/iter; left time: 1017.0681s\n",
      "3098it [03:26, 15.86it/s]\titers: 3100, epoch: 16 | loss: 0.2845843\n",
      "\tspeed: 0.0682s/iter; left time: 1071.8985s\n",
      "3198it [03:32, 15.49it/s]\titers: 3200, epoch: 16 | loss: 0.3261687\n",
      "\tspeed: 0.0637s/iter; left time: 994.6048s\n",
      "3298it [03:39, 15.10it/s]\titers: 3300, epoch: 16 | loss: 0.2563445\n",
      "\tspeed: 0.0650s/iter; left time: 1009.3910s\n",
      "3398it [03:45, 16.09it/s]\titers: 3400, epoch: 16 | loss: 0.2358372\n",
      "\tspeed: 0.0659s/iter; left time: 1016.0734s\n",
      "3498it [03:51, 15.74it/s]\titers: 3500, epoch: 16 | loss: 0.3046217\n",
      "\tspeed: 0.0632s/iter; left time: 968.2229s\n",
      "3598it [03:58, 15.36it/s]\titers: 3600, epoch: 16 | loss: 0.2316809\n",
      "\tspeed: 0.0652s/iter; left time: 993.3186s\n",
      "3699it [04:04, 19.89it/s]\titers: 3700, epoch: 16 | loss: 0.1820514\n",
      "\tspeed: 0.0613s/iter; left time: 927.2645s\n",
      "3765it [04:08, 15.17it/s]\n",
      "Epoch: 16 cost time: 248.12830567359924\n",
      "810it [00:22, 35.67it/s]\n",
      "807it [00:23, 34.70it/s]\n",
      "Epoch: 16 | Train Loss: 0.2403181 Vali Loss: 0.2868069 Test Loss: 0.3544185 MAE Loss: 0.3594624\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2207031249999999e-09\n",
      "99it [00:06, 13.65it/s]\titers: 100, epoch: 17 | loss: 0.1790431\n",
      "\tspeed: 0.5634s/iter; left time: 8428.9578s\n",
      "199it [00:13, 15.31it/s]\titers: 200, epoch: 17 | loss: 0.1973538\n",
      "\tspeed: 0.0635s/iter; left time: 943.7103s\n",
      "299it [00:19, 15.38it/s]\titers: 300, epoch: 17 | loss: 0.4148529\n",
      "\tspeed: 0.0658s/iter; left time: 971.7853s\n",
      "399it [00:25, 14.94it/s]\titers: 400, epoch: 17 | loss: 0.1595646\n",
      "\tspeed: 0.0633s/iter; left time: 927.7740s\n",
      "499it [00:32, 15.80it/s]\titers: 500, epoch: 17 | loss: 0.1112918\n",
      "\tspeed: 0.0677s/iter; left time: 986.2298s\n",
      "599it [00:38, 17.73it/s]\titers: 600, epoch: 17 | loss: 0.2874404\n",
      "\tspeed: 0.0569s/iter; left time: 823.4884s\n",
      "699it [00:44, 15.62it/s]\titers: 700, epoch: 17 | loss: 0.2976929\n",
      "\tspeed: 0.0638s/iter; left time: 916.5789s\n",
      "799it [00:51, 15.31it/s]\titers: 800, epoch: 17 | loss: 0.1485269\n",
      "\tspeed: 0.0666s/iter; left time: 949.6336s\n",
      "899it [00:57, 15.27it/s]\titers: 900, epoch: 17 | loss: 0.3525675\n",
      "\tspeed: 0.0647s/iter; left time: 916.6081s\n",
      "999it [01:04, 15.19it/s]\titers: 1000, epoch: 17 | loss: 0.4449722\n",
      "\tspeed: 0.0652s/iter; left time: 917.4601s\n",
      "1099it [01:11, 13.45it/s]\titers: 1100, epoch: 17 | loss: 0.2085751\n",
      "\tspeed: 0.0704s/iter; left time: 982.3371s\n",
      "1199it [01:17, 15.52it/s]\titers: 1200, epoch: 17 | loss: 0.2100131\n",
      "\tspeed: 0.0641s/iter; left time: 887.9361s\n",
      "1299it [01:24, 15.22it/s]\titers: 1300, epoch: 17 | loss: 0.1045809\n",
      "\tspeed: 0.0632s/iter; left time: 869.7244s\n",
      "1399it [01:30, 16.44it/s]\titers: 1400, epoch: 17 | loss: 0.2002374\n",
      "\tspeed: 0.0677s/iter; left time: 924.5435s\n",
      "1499it [01:37, 15.82it/s]\titers: 1500, epoch: 17 | loss: 0.2632557\n",
      "\tspeed: 0.0619s/iter; left time: 839.9856s\n",
      "1599it [01:43, 15.40it/s]\titers: 1600, epoch: 17 | loss: 0.3127479\n",
      "\tspeed: 0.0640s/iter; left time: 861.1251s\n",
      "1699it [01:50, 16.49it/s]\titers: 1700, epoch: 17 | loss: 0.1668860\n",
      "\tspeed: 0.0685s/iter; left time: 914.6919s\n",
      "1799it [01:56, 16.18it/s]\titers: 1800, epoch: 17 | loss: 0.6033255\n",
      "\tspeed: 0.0623s/iter; left time: 825.8519s\n",
      "1899it [02:03, 15.53it/s]\titers: 1900, epoch: 17 | loss: 0.1473853\n",
      "\tspeed: 0.0671s/iter; left time: 883.4749s\n",
      "1999it [02:10, 15.77it/s]\titers: 2000, epoch: 17 | loss: 0.1158464\n",
      "\tspeed: 0.0674s/iter; left time: 880.5383s\n",
      "2099it [02:16, 15.23it/s]\titers: 2100, epoch: 17 | loss: 0.2927096\n",
      "\tspeed: 0.0655s/iter; left time: 848.3202s\n",
      "2199it [02:23, 15.18it/s]\titers: 2200, epoch: 17 | loss: 0.3607923\n",
      "\tspeed: 0.0644s/iter; left time: 827.8231s\n",
      "2299it [02:29, 16.09it/s]\titers: 2300, epoch: 17 | loss: 0.1311593\n",
      "\tspeed: 0.0685s/iter; left time: 873.9121s\n",
      "2399it [02:36, 15.62it/s]\titers: 2400, epoch: 17 | loss: 0.1660731\n",
      "\tspeed: 0.0631s/iter; left time: 799.2774s\n",
      "2499it [02:43, 14.23it/s]\titers: 2500, epoch: 17 | loss: 0.3768957\n",
      "\tspeed: 0.0678s/iter; left time: 851.3255s\n",
      "2599it [02:49, 15.86it/s]\titers: 2600, epoch: 17 | loss: 0.2001093\n",
      "\tspeed: 0.0697s/iter; left time: 868.3254s\n",
      "2699it [02:56, 15.52it/s]\titers: 2700, epoch: 17 | loss: 0.2122296\n",
      "\tspeed: 0.0637s/iter; left time: 787.4555s\n",
      "2799it [03:02, 15.31it/s]\titers: 2800, epoch: 17 | loss: 0.3149003\n",
      "\tspeed: 0.0645s/iter; left time: 790.2580s\n",
      "2899it [03:09, 11.93it/s]\titers: 2900, epoch: 17 | loss: 0.2745255\n",
      "\tspeed: 0.0680s/iter; left time: 827.3266s\n",
      "2999it [03:16, 16.07it/s]\titers: 3000, epoch: 17 | loss: 0.2805024\n",
      "\tspeed: 0.0643s/iter; left time: 775.4582s\n",
      "3099it [03:22, 15.32it/s]\titers: 3100, epoch: 17 | loss: 0.2975344\n",
      "\tspeed: 0.0667s/iter; left time: 797.7861s\n",
      "3199it [03:29, 14.65it/s]\titers: 3200, epoch: 17 | loss: 0.6362581\n",
      "\tspeed: 0.0683s/iter; left time: 809.9340s\n",
      "3299it [03:35, 16.31it/s]\titers: 3300, epoch: 17 | loss: 0.1771577\n",
      "\tspeed: 0.0630s/iter; left time: 740.9614s\n",
      "3399it [03:42, 14.84it/s]\titers: 3400, epoch: 17 | loss: 0.2837758\n",
      "\tspeed: 0.0630s/iter; left time: 734.6957s\n",
      "3499it [03:48, 16.48it/s]\titers: 3500, epoch: 17 | loss: 0.2836261\n",
      "\tspeed: 0.0648s/iter; left time: 749.6250s\n",
      "3599it [03:55, 15.89it/s]\titers: 3600, epoch: 17 | loss: 0.2247824\n",
      "\tspeed: 0.0654s/iter; left time: 749.8967s\n",
      "3699it [04:01, 15.76it/s]\titers: 3700, epoch: 17 | loss: 0.1264317\n",
      "\tspeed: 0.0614s/iter; left time: 697.6756s\n",
      "3765it [04:05, 15.32it/s]\n",
      "Epoch: 17 cost time: 245.74307823181152\n",
      "810it [00:23, 34.59it/s]\n",
      "807it [00:23, 34.92it/s]\n",
      "Epoch: 17 | Train Loss: 0.2405716 Vali Loss: 0.2868028 Test Loss: 0.3544032 MAE Loss: 0.3594499\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.103515624999999e-10\n",
      "99it [00:06, 16.05it/s]\titers: 100, epoch: 18 | loss: 0.1149401\n",
      "\tspeed: 0.5788s/iter; left time: 6480.0069s\n",
      "199it [00:13, 15.56it/s]\titers: 200, epoch: 18 | loss: 0.1628300\n",
      "\tspeed: 0.0632s/iter; left time: 701.7674s\n",
      "299it [00:19, 15.59it/s]\titers: 300, epoch: 18 | loss: 0.2268005\n",
      "\tspeed: 0.0653s/iter; left time: 718.4291s\n",
      "399it [00:25, 15.89it/s]\titers: 400, epoch: 18 | loss: 0.2319918\n",
      "\tspeed: 0.0630s/iter; left time: 686.5188s\n",
      "499it [00:32, 15.48it/s]\titers: 500, epoch: 18 | loss: 0.1197591\n",
      "\tspeed: 0.0638s/iter; left time: 688.7452s\n",
      "599it [00:39, 16.17it/s]\titers: 600, epoch: 18 | loss: 0.2221109\n",
      "\tspeed: 0.0683s/iter; left time: 731.0703s\n",
      "699it [00:45, 16.05it/s]\titers: 700, epoch: 18 | loss: 0.2205137\n",
      "\tspeed: 0.0619s/iter; left time: 655.8369s\n",
      "799it [00:51, 16.85it/s]\titers: 800, epoch: 18 | loss: 0.1459414\n",
      "\tspeed: 0.0629s/iter; left time: 660.5701s\n",
      "899it [00:57, 16.67it/s]\titers: 900, epoch: 18 | loss: 0.2054292\n",
      "\tspeed: 0.0630s/iter; left time: 655.3911s\n",
      "999it [01:04, 17.18it/s]\titers: 1000, epoch: 18 | loss: 0.2089355\n",
      "\tspeed: 0.0607s/iter; left time: 624.9189s\n",
      "1099it [01:10, 12.72it/s]\titers: 1100, epoch: 18 | loss: 0.1713609\n",
      "\tspeed: 0.0678s/iter; left time: 691.4805s\n",
      "1199it [01:17, 15.98it/s]\titers: 1200, epoch: 18 | loss: 0.4682534\n",
      "\tspeed: 0.0631s/iter; left time: 636.8155s\n",
      "1299it [01:23, 16.66it/s]\titers: 1300, epoch: 18 | loss: 0.2941119\n",
      "\tspeed: 0.0625s/iter; left time: 624.9661s\n",
      "1399it [01:29, 16.12it/s]\titers: 1400, epoch: 18 | loss: 0.1942298\n",
      "\tspeed: 0.0642s/iter; left time: 635.3361s\n",
      "1499it [01:36, 16.11it/s]\titers: 1500, epoch: 18 | loss: 0.1866525\n",
      "\tspeed: 0.0625s/iter; left time: 612.0513s\n",
      "1599it [01:42, 15.60it/s]\titers: 1600, epoch: 18 | loss: 0.3768480\n",
      "\tspeed: 0.0648s/iter; left time: 628.2806s\n",
      "1699it [01:49, 15.91it/s]\titers: 1700, epoch: 18 | loss: 0.1606815\n",
      "\tspeed: 0.0701s/iter; left time: 673.1404s\n",
      "1799it [01:55, 15.34it/s]\titers: 1800, epoch: 18 | loss: 0.3521737\n",
      "\tspeed: 0.0641s/iter; left time: 608.4239s\n",
      "1899it [02:02, 15.58it/s]\titers: 1900, epoch: 18 | loss: 0.3089982\n",
      "\tspeed: 0.0634s/iter; left time: 595.3571s\n",
      "1999it [02:09, 15.83it/s]\titers: 2000, epoch: 18 | loss: 0.1460445\n",
      "\tspeed: 0.0678s/iter; left time: 630.2742s\n",
      "2099it [02:15, 16.69it/s]\titers: 2100, epoch: 18 | loss: 0.5405850\n",
      "\tspeed: 0.0611s/iter; left time: 562.2953s\n",
      "2199it [02:21, 16.07it/s]\titers: 2200, epoch: 18 | loss: 0.2307949\n",
      "\tspeed: 0.0609s/iter; left time: 553.9159s\n",
      "2299it [02:28, 16.26it/s]\titers: 2300, epoch: 18 | loss: 0.2217308\n",
      "\tspeed: 0.0682s/iter; left time: 613.5980s\n",
      "2399it [02:34, 16.01it/s]\titers: 2400, epoch: 18 | loss: 0.2220411\n",
      "\tspeed: 0.0624s/iter; left time: 554.9882s\n",
      "2499it [02:40, 15.60it/s]\titers: 2500, epoch: 18 | loss: 0.2467567\n",
      "\tspeed: 0.0632s/iter; left time: 555.9493s\n",
      "2599it [02:47, 14.47it/s]\titers: 2600, epoch: 18 | loss: 0.1691185\n",
      "\tspeed: 0.0695s/iter; left time: 604.6580s\n",
      "2699it [02:53, 15.52it/s]\titers: 2700, epoch: 18 | loss: 0.1348142\n",
      "\tspeed: 0.0633s/iter; left time: 544.5244s\n",
      "2799it [03:00, 15.60it/s]\titers: 2800, epoch: 18 | loss: 0.2349158\n",
      "\tspeed: 0.0653s/iter; left time: 554.9023s\n",
      "2899it [03:07, 16.48it/s]\titers: 2900, epoch: 18 | loss: 0.1483360\n",
      "\tspeed: 0.0681s/iter; left time: 571.3621s\n",
      "2999it [03:13, 17.40it/s]\titers: 3000, epoch: 18 | loss: 0.1397166\n",
      "\tspeed: 0.0589s/iter; left time: 488.5158s\n",
      "3099it [03:19, 15.56it/s]\titers: 3100, epoch: 18 | loss: 0.3029978\n",
      "\tspeed: 0.0594s/iter; left time: 487.2321s\n",
      "3199it [03:25, 16.47it/s]\titers: 3200, epoch: 18 | loss: 0.1750781\n",
      "\tspeed: 0.0680s/iter; left time: 550.4932s\n",
      "3299it [03:32, 15.40it/s]\titers: 3300, epoch: 18 | loss: 0.4172933\n",
      "\tspeed: 0.0645s/iter; left time: 515.4113s\n",
      "3399it [03:38, 15.44it/s]\titers: 3400, epoch: 18 | loss: 0.1971476\n",
      "\tspeed: 0.0633s/iter; left time: 499.9471s\n",
      "3499it [03:45, 16.13it/s]\titers: 3500, epoch: 18 | loss: 0.2929800\n",
      "\tspeed: 0.0651s/iter; left time: 507.4652s\n",
      "3599it [03:51, 16.15it/s]\titers: 3600, epoch: 18 | loss: 0.1714748\n",
      "\tspeed: 0.0623s/iter; left time: 479.1743s\n",
      "3699it [03:57, 15.81it/s]\titers: 3700, epoch: 18 | loss: 0.1868517\n",
      "\tspeed: 0.0625s/iter; left time: 475.0227s\n",
      "3765it [04:02, 15.54it/s]\n",
      "Epoch: 18 cost time: 242.26519632339478\n",
      "810it [00:22, 35.51it/s]\n",
      "807it [00:23, 34.72it/s]\n",
      "Epoch: 18 | Train Loss: 0.2406514 Vali Loss: 0.2868585 Test Loss: 0.3544081 MAE Loss: 0.3594481\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.0517578124999997e-10\n",
      "99it [00:05, 19.87it/s]\titers: 100, epoch: 19 | loss: 0.2090819\n",
      "\tspeed: 0.5626s/iter; left time: 4180.6301s\n",
      "199it [00:11, 15.94it/s]\titers: 200, epoch: 19 | loss: 0.2616295\n",
      "\tspeed: 0.0630s/iter; left time: 461.8594s\n",
      "299it [00:18, 16.05it/s]\titers: 300, epoch: 19 | loss: 0.2658483\n",
      "\tspeed: 0.0627s/iter; left time: 453.4350s\n",
      "399it [00:24, 15.32it/s]\titers: 400, epoch: 19 | loss: 0.2658174\n",
      "\tspeed: 0.0641s/iter; left time: 456.7571s\n",
      "499it [00:30, 16.33it/s]\titers: 500, epoch: 19 | loss: 0.2875904\n",
      "\tspeed: 0.0639s/iter; left time: 449.5418s\n",
      "599it [00:37, 16.25it/s]\titers: 600, epoch: 19 | loss: 0.2721080\n",
      "\tspeed: 0.0624s/iter; left time: 432.4793s\n",
      "699it [00:43, 17.22it/s]\titers: 700, epoch: 19 | loss: 0.2358391\n",
      "\tspeed: 0.0599s/iter; left time: 409.2900s\n",
      "799it [00:49, 13.34it/s]\titers: 800, epoch: 19 | loss: 0.1202363\n",
      "\tspeed: 0.0618s/iter; left time: 416.0281s\n",
      "899it [00:55, 16.46it/s]\titers: 900, epoch: 19 | loss: 0.2020888\n",
      "\tspeed: 0.0625s/iter; left time: 414.1282s\n",
      "999it [01:01, 16.87it/s]\titers: 1000, epoch: 19 | loss: 0.2006921\n",
      "\tspeed: 0.0621s/iter; left time: 405.4709s\n",
      "1098it [01:07, 16.16it/s]\titers: 1100, epoch: 19 | loss: 0.3915307\n",
      "\tspeed: 0.0593s/iter; left time: 381.0447s\n",
      "1198it [01:13, 20.05it/s]\titers: 1200, epoch: 19 | loss: 0.3757917\n",
      "\tspeed: 0.0572s/iter; left time: 362.0411s\n",
      "1298it [01:18, 19.71it/s]\titers: 1300, epoch: 19 | loss: 0.1456084\n",
      "\tspeed: 0.0502s/iter; left time: 313.0388s\n",
      "1398it [01:23, 19.64it/s]\titers: 1400, epoch: 19 | loss: 0.1724416\n",
      "\tspeed: 0.0505s/iter; left time: 309.5885s\n",
      "1498it [01:28, 17.59it/s]\titers: 1500, epoch: 19 | loss: 0.1761060\n",
      "\tspeed: 0.0520s/iter; left time: 313.5855s\n",
      "1598it [01:34, 16.21it/s]\titers: 1600, epoch: 19 | loss: 0.2777399\n",
      "\tspeed: 0.0631s/iter; left time: 374.2022s\n",
      "1698it [01:41, 16.14it/s]\titers: 1700, epoch: 19 | loss: 0.2387632\n",
      "\tspeed: 0.0630s/iter; left time: 367.1734s\n",
      "1798it [01:47, 15.66it/s]\titers: 1800, epoch: 19 | loss: 0.2864440\n",
      "\tspeed: 0.0654s/iter; left time: 374.6850s\n",
      "1899it [01:53, 16.35it/s]\titers: 1900, epoch: 19 | loss: 0.1623599\n",
      "\tspeed: 0.0570s/iter; left time: 320.9203s\n",
      "1998it [01:58, 20.29it/s]\titers: 2000, epoch: 19 | loss: 0.3337181\n",
      "\tspeed: 0.0525s/iter; left time: 290.2373s\n",
      "2099it [02:03, 19.70it/s]\titers: 2100, epoch: 19 | loss: 0.6763064\n",
      "\tspeed: 0.0496s/iter; left time: 269.6358s\n",
      "2199it [02:10, 16.16it/s]\titers: 2200, epoch: 19 | loss: 0.1896386\n",
      "\tspeed: 0.0650s/iter; left time: 346.2746s\n",
      "2299it [02:16, 15.90it/s]\titers: 2300, epoch: 19 | loss: 0.4624285\n",
      "\tspeed: 0.0632s/iter; left time: 330.3554s\n",
      "2399it [02:23, 12.07it/s]\titers: 2400, epoch: 19 | loss: 0.2505639\n",
      "\tspeed: 0.0674s/iter; left time: 345.8125s\n",
      "2499it [02:29, 16.16it/s]\titers: 2500, epoch: 19 | loss: 0.2530861\n",
      "\tspeed: 0.0626s/iter; left time: 314.7892s\n",
      "2599it [02:36, 15.22it/s]\titers: 2600, epoch: 19 | loss: 0.1167460\n",
      "\tspeed: 0.0652s/iter; left time: 321.5864s\n",
      "2699it [02:42, 16.38it/s]\titers: 2700, epoch: 19 | loss: 0.1652538\n",
      "\tspeed: 0.0683s/iter; left time: 329.9452s\n",
      "2799it [02:49, 16.20it/s]\titers: 2800, epoch: 19 | loss: 0.3055148\n",
      "\tspeed: 0.0624s/iter; left time: 295.3427s\n",
      "2899it [02:55, 15.73it/s]\titers: 2900, epoch: 19 | loss: 0.2628029\n",
      "\tspeed: 0.0629s/iter; left time: 291.1325s\n",
      "2999it [03:01, 15.76it/s]\titers: 3000, epoch: 19 | loss: 0.3317397\n",
      "\tspeed: 0.0651s/iter; left time: 294.9468s\n",
      "3099it [03:08, 16.35it/s]\titers: 3100, epoch: 19 | loss: 0.1404723\n",
      "\tspeed: 0.0627s/iter; left time: 277.8383s\n",
      "3199it [03:14, 15.82it/s]\titers: 3200, epoch: 19 | loss: 0.1137830\n",
      "\tspeed: 0.0621s/iter; left time: 268.9004s\n",
      "3299it [03:20, 14.26it/s]\titers: 3300, epoch: 19 | loss: 0.1915501\n",
      "\tspeed: 0.0645s/iter; left time: 272.7928s\n",
      "3399it [03:26, 16.21it/s]\titers: 3400, epoch: 19 | loss: 0.2559881\n",
      "\tspeed: 0.0573s/iter; left time: 236.5577s\n",
      "3499it [03:32, 15.56it/s]\titers: 3500, epoch: 19 | loss: 0.1756145\n",
      "\tspeed: 0.0635s/iter; left time: 255.9236s\n",
      "3599it [03:39, 16.43it/s]\titers: 3600, epoch: 19 | loss: 0.1698450\n",
      "\tspeed: 0.0651s/iter; left time: 255.9606s\n",
      "3699it [03:45, 16.10it/s]\titers: 3700, epoch: 19 | loss: 0.2651412\n",
      "\tspeed: 0.0632s/iter; left time: 242.1870s\n",
      "3765it [03:49, 16.37it/s]\n",
      "Epoch: 19 cost time: 229.98932886123657\n",
      "810it [00:23, 34.75it/s]\n",
      "807it [00:23, 34.62it/s]\n",
      "Epoch: 19 | Train Loss: 0.2403287 Vali Loss: 0.2866571 Test Loss: 0.3543888 MAE Loss: 0.3594454\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5258789062499999e-10\n",
      "99it [00:06, 15.48it/s]\titers: 100, epoch: 20 | loss: 0.2254924\n",
      "\tspeed: 0.5777s/iter; left time: 2117.8446s\n",
      "199it [00:13, 14.75it/s]\titers: 200, epoch: 20 | loss: 0.3145793\n",
      "\tspeed: 0.0658s/iter; left time: 234.8082s\n",
      "299it [00:20, 14.12it/s]\titers: 300, epoch: 20 | loss: 0.1694066\n",
      "\tspeed: 0.0696s/iter; left time: 241.3214s\n",
      "399it [00:27, 15.50it/s]\titers: 400, epoch: 20 | loss: 0.4031621\n",
      "\tspeed: 0.0667s/iter; left time: 224.4888s\n",
      "499it [00:33, 16.38it/s]\titers: 500, epoch: 20 | loss: 0.1989420\n",
      "\tspeed: 0.0633s/iter; left time: 206.8768s\n",
      "599it [00:39, 16.00it/s]\titers: 600, epoch: 20 | loss: 0.1349097\n",
      "\tspeed: 0.0658s/iter; left time: 208.2322s\n",
      "699it [00:46, 17.15it/s]\titers: 700, epoch: 20 | loss: 0.2714568\n",
      "\tspeed: 0.0632s/iter; left time: 193.7351s\n",
      "799it [00:51, 17.52it/s]\titers: 800, epoch: 20 | loss: 0.2522634\n",
      "\tspeed: 0.0562s/iter; left time: 166.8249s\n",
      "899it [00:57, 20.17it/s]\titers: 900, epoch: 20 | loss: 0.1381346\n",
      "\tspeed: 0.0602s/iter; left time: 172.6660s\n",
      "997it [01:02, 20.38it/s]\titers: 1000, epoch: 20 | loss: 0.1926743\n",
      "\tspeed: 0.0503s/iter; left time: 139.0471s\n",
      "1099it [01:09, 15.26it/s]\titers: 1100, epoch: 20 | loss: 0.2487187\n",
      "\tspeed: 0.0635s/iter; left time: 169.1609s\n",
      "1199it [01:15, 15.66it/s]\titers: 1200, epoch: 20 | loss: 0.2510842\n",
      "\tspeed: 0.0668s/iter; left time: 171.4627s\n",
      "1299it [01:22, 16.16it/s]\titers: 1300, epoch: 20 | loss: 0.2946405\n",
      "\tspeed: 0.0631s/iter; left time: 155.5705s\n",
      "1399it [01:28, 15.71it/s]\titers: 1400, epoch: 20 | loss: 0.2021894\n",
      "\tspeed: 0.0632s/iter; left time: 149.4617s\n",
      "1498it [01:33, 14.76it/s]\titers: 1500, epoch: 20 | loss: 0.1626229\n",
      "\tspeed: 0.0548s/iter; left time: 124.0858s\n",
      "1598it [01:40, 15.21it/s]\titers: 1600, epoch: 20 | loss: 0.1667224\n",
      "\tspeed: 0.0634s/iter; left time: 137.3377s\n",
      "1698it [01:46, 16.21it/s]\titers: 1700, epoch: 20 | loss: 0.2986733\n",
      "\tspeed: 0.0591s/iter; left time: 122.1851s\n",
      "1798it [01:52, 15.98it/s]\titers: 1800, epoch: 20 | loss: 0.1473860\n",
      "\tspeed: 0.0658s/iter; left time: 129.3856s\n",
      "1898it [01:58, 18.14it/s]\titers: 1900, epoch: 20 | loss: 0.3267851\n",
      "\tspeed: 0.0606s/iter; left time: 112.9957s\n",
      "1998it [02:05, 15.24it/s]\titers: 2000, epoch: 20 | loss: 0.2409165\n",
      "\tspeed: 0.0614s/iter; left time: 108.3525s\n",
      "2098it [02:11, 15.79it/s]\titers: 2100, epoch: 20 | loss: 0.1143558\n",
      "\tspeed: 0.0652s/iter; left time: 108.6543s\n",
      "2198it [02:17, 15.77it/s]\titers: 2200, epoch: 20 | loss: 0.1900837\n",
      "\tspeed: 0.0632s/iter; left time: 99.0324s\n",
      "2298it [02:23, 15.60it/s]\titers: 2300, epoch: 20 | loss: 0.2480171\n",
      "\tspeed: 0.0602s/iter; left time: 88.2750s\n",
      "2398it [02:30, 16.00it/s]\titers: 2400, epoch: 20 | loss: 0.1445971\n",
      "\tspeed: 0.0646s/iter; left time: 88.1914s\n",
      "2498it [02:36, 16.40it/s]\titers: 2500, epoch: 20 | loss: 0.1870067\n",
      "\tspeed: 0.0623s/iter; left time: 78.8780s\n",
      "2598it [02:43, 15.23it/s]\titers: 2600, epoch: 20 | loss: 0.3986656\n",
      "\tspeed: 0.0657s/iter; left time: 76.6020s\n",
      "2698it [02:49, 13.92it/s]\titers: 2700, epoch: 20 | loss: 0.1321919\n",
      "\tspeed: 0.0659s/iter; left time: 70.2678s\n",
      "2798it [02:55, 16.19it/s]\titers: 2800, epoch: 20 | loss: 0.1658623\n",
      "\tspeed: 0.0621s/iter; left time: 60.0198s\n",
      "2898it [03:02, 16.02it/s]\titers: 2900, epoch: 20 | loss: 0.2688126\n",
      "\tspeed: 0.0625s/iter; left time: 54.1385s\n",
      "2998it [03:08, 15.91it/s]\titers: 3000, epoch: 20 | loss: 0.2802991\n",
      "\tspeed: 0.0680s/iter; left time: 52.0939s\n",
      "3098it [03:15, 15.98it/s]\titers: 3100, epoch: 20 | loss: 0.1629362\n",
      "\tspeed: 0.0631s/iter; left time: 42.0151s\n",
      "3198it [03:21, 15.73it/s]\titers: 3200, epoch: 20 | loss: 0.2844540\n",
      "\tspeed: 0.0643s/iter; left time: 36.4033s\n",
      "3298it [03:28, 15.29it/s]\titers: 3300, epoch: 20 | loss: 0.2217215\n",
      "\tspeed: 0.0663s/iter; left time: 30.8727s\n",
      "3398it [03:34, 16.11it/s]\titers: 3400, epoch: 20 | loss: 0.1736506\n",
      "\tspeed: 0.0630s/iter; left time: 23.0407s\n",
      "3498it [03:41, 15.60it/s]\titers: 3500, epoch: 20 | loss: 0.2384140\n",
      "\tspeed: 0.0636s/iter; left time: 16.9199s\n",
      "3598it [03:47, 11.66it/s]\titers: 3600, epoch: 20 | loss: 0.2056171\n",
      "\tspeed: 0.0684s/iter; left time: 11.3563s\n",
      "3698it [03:54, 15.64it/s]\titers: 3700, epoch: 20 | loss: 0.2011973\n",
      "\tspeed: 0.0629s/iter; left time: 4.1513s\n",
      "3765it [03:58, 15.79it/s]\n",
      "Epoch: 20 cost time: 238.41683316230774\n",
      "810it [00:25, 32.12it/s]\n",
      "807it [00:24, 32.92it/s]\n",
      "Epoch: 20 | Train Loss: 0.2400190 Vali Loss: 0.2867778 Test Loss: 0.3544127 MAE Loss: 0.3594607\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.629394531249999e-11\n",
      "Total time: 97.56099663972854 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=12\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-03 20:30:22,622] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 20:30:23,465] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 20:30:23,466] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 20:30:23,466] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 20:30:24,380] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-03 20:30:24,380] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 20:30:25,635] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 20:30:25,636] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 20:30:25,636] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 20:30:25,637] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 20:30:25,637] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 20:30:25,638] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 20:30:25,638] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 20:30:25,638] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 20:30:25,638] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 20:30:25,638] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 20:30:25,906] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 20:30:25,907] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-03 20:30:25,907] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 194.74 GB, percent = 25.8%\n",
      "[2024-05-03 20:30:26,038] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 20:30:26,039] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-03 20:30:26,039] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 194.9 GB, percent = 25.8%\n",
      "[2024-05-03 20:30:26,039] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 20:30:26,158] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 20:30:26,158] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-03 20:30:26,158] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 195.03 GB, percent = 25.8%\n",
      "[2024-05-03 20:30:26,159] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 20:30:26,159] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 20:30:26,159] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 20:30:26,159] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8634786510>\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 20:30:26,160] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 20:30:26,161] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:12,  9.46it/s]\titers: 100, epoch: 1 | loss: 0.8720683\n",
      "\tspeed: 0.1636s/iter; left time: 12303.4216s\n",
      "199it [00:23,  8.97it/s]\titers: 200, epoch: 1 | loss: 0.5065026\n",
      "\tspeed: 0.1135s/iter; left time: 8524.8961s\n",
      "299it [00:34,  9.26it/s]\titers: 300, epoch: 1 | loss: 0.3391798\n",
      "\tspeed: 0.1091s/iter; left time: 8183.7724s\n",
      "399it [00:45,  9.33it/s]\titers: 400, epoch: 1 | loss: 0.3010673\n",
      "\tspeed: 0.1132s/iter; left time: 8479.5291s\n",
      "499it [00:56,  9.37it/s]\titers: 500, epoch: 1 | loss: 0.4299749\n",
      "\tspeed: 0.1078s/iter; left time: 8065.9695s\n",
      "599it [01:07,  8.89it/s]\titers: 600, epoch: 1 | loss: 0.3507005\n",
      "\tspeed: 0.1134s/iter; left time: 8469.3930s\n",
      "699it [01:18,  9.08it/s]\titers: 700, epoch: 1 | loss: 0.2531307\n",
      "\tspeed: 0.1095s/iter; left time: 8172.4255s\n",
      "799it [01:30,  8.72it/s]\titers: 800, epoch: 1 | loss: 0.2008217\n",
      "\tspeed: 0.1141s/iter; left time: 8502.8012s\n",
      "899it [01:41,  8.21it/s]\titers: 900, epoch: 1 | loss: 0.2658834\n",
      "\tspeed: 0.1124s/iter; left time: 8363.7715s\n",
      "999it [01:52,  8.97it/s]\titers: 1000, epoch: 1 | loss: 0.1754939\n",
      "\tspeed: 0.1115s/iter; left time: 8282.2753s\n",
      "1099it [02:04,  8.21it/s]\titers: 1100, epoch: 1 | loss: 0.1986075\n",
      "\tspeed: 0.1182s/iter; left time: 8772.2648s\n",
      "1199it [02:16,  9.00it/s]\titers: 1200, epoch: 1 | loss: 0.2600406\n",
      "\tspeed: 0.1180s/iter; left time: 8747.3023s\n",
      "1299it [02:27,  8.95it/s]\titers: 1300, epoch: 1 | loss: 0.2458196\n",
      "\tspeed: 0.1152s/iter; left time: 8528.0479s\n",
      "1399it [02:39,  8.41it/s]\titers: 1400, epoch: 1 | loss: 0.3013499\n",
      "\tspeed: 0.1122s/iter; left time: 8288.2482s\n",
      "1499it [02:51,  8.84it/s]\titers: 1500, epoch: 1 | loss: 0.4926764\n",
      "\tspeed: 0.1225s/iter; left time: 9039.4693s\n",
      "1599it [03:02,  8.28it/s]\titers: 1600, epoch: 1 | loss: 0.3098283\n",
      "\tspeed: 0.1134s/iter; left time: 8356.2305s\n",
      "1699it [03:13,  9.03it/s]\titers: 1700, epoch: 1 | loss: 0.2061113\n",
      "\tspeed: 0.1132s/iter; left time: 8330.0179s\n",
      "1799it [03:25,  9.18it/s]\titers: 1800, epoch: 1 | loss: 0.3247851\n",
      "\tspeed: 0.1162s/iter; left time: 8542.2291s\n",
      "1899it [03:36,  9.03it/s]\titers: 1900, epoch: 1 | loss: 0.3004698\n",
      "\tspeed: 0.1084s/iter; left time: 7957.6212s\n",
      "1999it [03:47,  8.83it/s]\titers: 2000, epoch: 1 | loss: 0.1845030\n",
      "\tspeed: 0.1138s/iter; left time: 8343.2680s\n",
      "2099it [03:59,  8.81it/s]\titers: 2100, epoch: 1 | loss: 0.3011261\n",
      "\tspeed: 0.1138s/iter; left time: 8328.5447s\n",
      "2199it [04:10,  9.10it/s]\titers: 2200, epoch: 1 | loss: 0.1491057\n",
      "\tspeed: 0.1111s/iter; left time: 8122.0984s\n",
      "2299it [04:21,  9.24it/s]\titers: 2300, epoch: 1 | loss: 0.2294417\n",
      "\tspeed: 0.1140s/iter; left time: 8323.7917s\n",
      "2399it [04:32,  9.12it/s]\titers: 2400, epoch: 1 | loss: 0.2654189\n",
      "\tspeed: 0.1083s/iter; left time: 7892.9086s\n",
      "2499it [04:43,  9.18it/s]\titers: 2500, epoch: 1 | loss: 0.2196381\n",
      "\tspeed: 0.1144s/iter; left time: 8329.2417s\n",
      "2599it [04:54,  8.94it/s]\titers: 2600, epoch: 1 | loss: 0.1637122\n",
      "\tspeed: 0.1089s/iter; left time: 7920.6450s\n",
      "2699it [05:05,  9.07it/s]\titers: 2700, epoch: 1 | loss: 0.1458107\n",
      "\tspeed: 0.1101s/iter; left time: 7995.7889s\n",
      "2799it [05:17,  8.89it/s]\titers: 2800, epoch: 1 | loss: 0.1363378\n",
      "\tspeed: 0.1120s/iter; left time: 8120.2840s\n",
      "2899it [05:28,  9.11it/s]\titers: 2900, epoch: 1 | loss: 0.2458407\n",
      "\tspeed: 0.1110s/iter; left time: 8038.7909s\n",
      "2999it [05:39,  9.23it/s]\titers: 3000, epoch: 1 | loss: 0.2506288\n",
      "\tspeed: 0.1136s/iter; left time: 8214.3023s\n",
      "3099it [05:50,  9.02it/s]\titers: 3100, epoch: 1 | loss: 0.2206718\n",
      "\tspeed: 0.1091s/iter; left time: 7877.9553s\n",
      "3199it [06:01,  9.42it/s]\titers: 3200, epoch: 1 | loss: 0.4658456\n",
      "\tspeed: 0.1131s/iter; left time: 8153.4297s\n",
      "3299it [06:12,  7.55it/s]\titers: 3300, epoch: 1 | loss: 0.3971891\n",
      "\tspeed: 0.1118s/iter; left time: 8051.2942s\n",
      "3399it [06:23,  9.34it/s]\titers: 3400, epoch: 1 | loss: 0.2191683\n",
      "\tspeed: 0.1087s/iter; left time: 7817.4710s\n",
      "3499it [06:35,  9.14it/s]\titers: 3500, epoch: 1 | loss: 0.2384708\n",
      "\tspeed: 0.1123s/iter; left time: 8062.8384s\n",
      "3599it [06:45,  9.18it/s]\titers: 3600, epoch: 1 | loss: 0.3434020\n",
      "\tspeed: 0.1080s/iter; left time: 7747.1486s\n",
      "3699it [06:57,  9.21it/s]\titers: 3700, epoch: 1 | loss: 0.1852512\n",
      "\tspeed: 0.1128s/iter; left time: 8074.5361s\n",
      "3765it [07:04,  8.87it/s]\n",
      "Epoch: 1 cost time: 424.3217496871948\n",
      "810it [00:42, 18.99it/s]\n",
      "807it [00:42, 18.84it/s]\n",
      "Epoch: 1 | Train Loss: 0.3143477 Vali Loss: 0.3187971 Test Loss: 0.3921895 MAE Loss: 0.3947553\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "99it [00:11,  7.92it/s]\titers: 100, epoch: 2 | loss: 0.3257698\n",
      "\tspeed: 1.0843s/iter; left time: 77454.8621s\n",
      "199it [00:22,  9.32it/s]\titers: 200, epoch: 2 | loss: 0.5429347\n",
      "\tspeed: 0.1107s/iter; left time: 7895.1104s\n",
      "299it [00:34,  8.85it/s]\titers: 300, epoch: 2 | loss: 0.2926316\n",
      "\tspeed: 0.1130s/iter; left time: 8046.6881s\n",
      "399it [00:45,  9.20it/s]\titers: 400, epoch: 2 | loss: 0.1785531\n",
      "\tspeed: 0.1083s/iter; left time: 7705.4235s\n",
      "499it [00:56,  9.06it/s]\titers: 500, epoch: 2 | loss: 0.1654402\n",
      "\tspeed: 0.1122s/iter; left time: 7967.8893s\n",
      "599it [01:07,  8.92it/s]\titers: 600, epoch: 2 | loss: 0.4490877\n",
      "\tspeed: 0.1097s/iter; left time: 7782.5756s\n",
      "699it [01:18,  9.10it/s]\titers: 700, epoch: 2 | loss: 0.4413053\n",
      "\tspeed: 0.1089s/iter; left time: 7715.0955s\n",
      "799it [01:29,  9.10it/s]\titers: 800, epoch: 2 | loss: 0.2705620\n",
      "\tspeed: 0.1113s/iter; left time: 7870.3453s\n",
      "899it [01:40,  9.34it/s]\titers: 900, epoch: 2 | loss: 0.1858509\n",
      "\tspeed: 0.1088s/iter; left time: 7686.6553s\n",
      "999it [01:51,  9.20it/s]\titers: 1000, epoch: 2 | loss: 0.2500934\n",
      "\tspeed: 0.1122s/iter; left time: 7913.1936s\n",
      "1099it [02:02,  7.76it/s]\titers: 1100, epoch: 2 | loss: 0.2143093\n",
      "\tspeed: 0.1071s/iter; left time: 7540.2643s\n",
      "1199it [02:13,  9.09it/s]\titers: 1200, epoch: 2 | loss: 0.2532977\n",
      "\tspeed: 0.1109s/iter; left time: 7800.8538s\n",
      "1299it [02:24,  9.09it/s]\titers: 1300, epoch: 2 | loss: 0.1322539\n",
      "\tspeed: 0.1106s/iter; left time: 7769.8485s\n",
      "1399it [02:35,  9.59it/s]\titers: 1400, epoch: 2 | loss: 0.2507161\n",
      "\tspeed: 0.1092s/iter; left time: 7659.0549s\n",
      "1499it [02:46,  9.09it/s]\titers: 1500, epoch: 2 | loss: 0.3585689\n",
      "\tspeed: 0.1120s/iter; left time: 7844.4061s\n",
      "1599it [02:57,  9.25it/s]\titers: 1600, epoch: 2 | loss: 0.2483891\n",
      "\tspeed: 0.1067s/iter; left time: 7463.3288s\n",
      "1699it [03:08,  9.49it/s]\titers: 1700, epoch: 2 | loss: 0.1066617\n",
      "\tspeed: 0.1110s/iter; left time: 7754.5798s\n",
      "1799it [03:18,  9.23it/s]\titers: 1800, epoch: 2 | loss: 0.2496381\n",
      "\tspeed: 0.1071s/iter; left time: 7471.7465s\n",
      "1898it [03:30,  9.17it/s]\titers: 1900, epoch: 2 | loss: 0.4604181\n",
      "\tspeed: 0.1138s/iter; left time: 7924.5950s\n",
      "1999it [03:41,  8.26it/s]\titers: 2000, epoch: 2 | loss: 0.1519645\n",
      "\tspeed: 0.1113s/iter; left time: 7739.3280s\n",
      "2099it [03:52,  9.31it/s]\titers: 2100, epoch: 2 | loss: 0.3148130\n",
      "\tspeed: 0.1083s/iter; left time: 7518.1242s\n",
      "2199it [04:03,  9.30it/s]\titers: 2200, epoch: 2 | loss: 0.1887021\n",
      "\tspeed: 0.1111s/iter; left time: 7701.2827s\n",
      "2299it [04:14,  9.37it/s]\titers: 2300, epoch: 2 | loss: 0.3369347\n",
      "\tspeed: 0.1125s/iter; left time: 7786.1778s\n",
      "2399it [04:25,  9.32it/s]\titers: 2400, epoch: 2 | loss: 0.1767766\n",
      "\tspeed: 0.1087s/iter; left time: 7512.7573s\n",
      "2499it [04:36,  8.88it/s]\titers: 2500, epoch: 2 | loss: 0.2903088\n",
      "\tspeed: 0.1111s/iter; left time: 7672.8268s\n",
      "2599it [04:47,  9.62it/s]\titers: 2600, epoch: 2 | loss: 0.3526972\n",
      "\tspeed: 0.1055s/iter; left time: 7274.9783s\n",
      "2699it [04:58,  9.47it/s]\titers: 2700, epoch: 2 | loss: 0.1873801\n",
      "\tspeed: 0.1102s/iter; left time: 7588.7844s\n",
      "2799it [05:08,  9.45it/s]\titers: 2800, epoch: 2 | loss: 0.2074384\n",
      "\tspeed: 0.1056s/iter; left time: 7257.9629s\n",
      "2899it [05:20,  9.36it/s]\titers: 2900, epoch: 2 | loss: 0.2050084\n",
      "\tspeed: 0.1141s/iter; left time: 7829.3259s\n",
      "2999it [05:31,  9.38it/s]\titers: 3000, epoch: 2 | loss: 0.2550214\n",
      "\tspeed: 0.1097s/iter; left time: 7520.7710s\n",
      "3099it [05:41,  9.35it/s]\titers: 3100, epoch: 2 | loss: 0.3198403\n",
      "\tspeed: 0.1066s/iter; left time: 7294.6622s\n",
      "3199it [05:52,  9.66it/s]\titers: 3200, epoch: 2 | loss: 0.2663392\n",
      "\tspeed: 0.1085s/iter; left time: 7416.7765s\n",
      "3299it [06:03,  9.36it/s]\titers: 3300, epoch: 2 | loss: 0.3405620\n",
      "\tspeed: 0.1074s/iter; left time: 7331.7076s\n",
      "3398it [06:14,  9.73it/s]\titers: 3400, epoch: 2 | loss: 0.3583790\n",
      "\tspeed: 0.1110s/iter; left time: 7564.1220s\n",
      "3499it [06:24,  9.44it/s]\titers: 3500, epoch: 2 | loss: 0.2920292\n",
      "\tspeed: 0.1043s/iter; left time: 7098.0126s\n",
      "3599it [06:35,  9.72it/s]\titers: 3600, epoch: 2 | loss: 0.2104270\n",
      "\tspeed: 0.1097s/iter; left time: 7450.4318s\n",
      "3699it [06:46,  7.73it/s]\titers: 3700, epoch: 2 | loss: 0.3792321\n",
      "\tspeed: 0.1083s/iter; left time: 7349.7581s\n",
      "3765it [06:53,  9.10it/s]\n",
      "Epoch: 2 cost time: 413.9427099227905\n",
      "810it [00:39, 20.51it/s]\n",
      "807it [00:39, 20.41it/s]\n",
      "Epoch: 2 | Train Loss: 0.2646172 Vali Loss: 0.3105387 Test Loss: 0.3764460 MAE Loss: 0.3837782\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "99it [00:11,  9.39it/s]\titers: 100, epoch: 3 | loss: 0.2978648\n",
      "\tspeed: 1.0150s/iter; left time: 68684.4952s\n",
      "198it [00:21,  9.29it/s]\titers: 200, epoch: 3 | loss: 0.2218207\n",
      "\tspeed: 0.1061s/iter; left time: 7167.2868s\n",
      "299it [00:32,  9.08it/s]\titers: 300, epoch: 3 | loss: 0.3516690\n",
      "\tspeed: 0.1105s/iter; left time: 7452.5027s\n",
      "399it [00:43,  7.90it/s]\titers: 400, epoch: 3 | loss: 0.2343934\n",
      "\tspeed: 0.1090s/iter; left time: 7341.7735s\n",
      "499it [00:54,  9.19it/s]\titers: 500, epoch: 3 | loss: 0.2358997\n",
      "\tspeed: 0.1056s/iter; left time: 7107.1061s\n",
      "599it [01:05,  8.76it/s]\titers: 600, epoch: 3 | loss: 0.3204251\n",
      "\tspeed: 0.1109s/iter; left time: 7451.1469s\n",
      "698it [01:15,  9.72it/s]\titers: 700, epoch: 3 | loss: 0.3975033\n",
      "\tspeed: 0.1051s/iter; left time: 7047.9663s\n",
      "799it [01:26,  9.77it/s]\titers: 800, epoch: 3 | loss: 0.3985476\n",
      "\tspeed: 0.1085s/iter; left time: 7264.2833s\n",
      "899it [01:37,  9.46it/s]\titers: 900, epoch: 3 | loss: 0.1841005\n",
      "\tspeed: 0.1056s/iter; left time: 7060.2783s\n",
      "999it [01:48,  9.67it/s]\titers: 1000, epoch: 3 | loss: 0.1552988\n",
      "\tspeed: 0.1081s/iter; left time: 7220.4931s\n",
      "1099it [01:58,  9.47it/s]\titers: 1100, epoch: 3 | loss: 0.4149681\n",
      "\tspeed: 0.1076s/iter; left time: 7171.3652s\n",
      "1199it [02:10,  9.38it/s]\titers: 1200, epoch: 3 | loss: 0.3466677\n",
      "\tspeed: 0.1154s/iter; left time: 7679.4795s\n",
      "1299it [02:21,  9.48it/s]\titers: 1300, epoch: 3 | loss: 0.2948653\n",
      "\tspeed: 0.1073s/iter; left time: 7129.8301s\n",
      "1399it [02:31,  8.94it/s]\titers: 1400, epoch: 3 | loss: 0.2601008\n",
      "\tspeed: 0.1084s/iter; left time: 7194.1815s\n",
      "1499it [02:42,  9.45it/s]\titers: 1500, epoch: 3 | loss: 0.1333135\n",
      "\tspeed: 0.1098s/iter; left time: 7275.1436s\n",
      "1599it [02:53,  9.38it/s]\titers: 1600, epoch: 3 | loss: 0.2863780\n",
      "\tspeed: 0.1098s/iter; left time: 7267.0489s\n",
      "1699it [03:04,  9.66it/s]\titers: 1700, epoch: 3 | loss: 0.2553263\n",
      "\tspeed: 0.1083s/iter; left time: 7156.7137s\n",
      "1798it [03:14,  9.49it/s]\titers: 1800, epoch: 3 | loss: 0.1366695\n",
      "\tspeed: 0.1042s/iter; left time: 6872.1585s\n",
      "1899it [03:25,  9.81it/s]\titers: 1900, epoch: 3 | loss: 0.3149875\n",
      "\tspeed: 0.1079s/iter; left time: 7104.7834s\n",
      "1999it [03:36, 10.20it/s]\titers: 2000, epoch: 3 | loss: 0.3165818\n",
      "\tspeed: 0.1023s/iter; left time: 6725.1720s\n",
      "2098it [03:46,  9.50it/s]\titers: 2100, epoch: 3 | loss: 0.2897106\n",
      "\tspeed: 0.1076s/iter; left time: 7064.9561s\n",
      "2198it [03:57,  9.60it/s]\titers: 2200, epoch: 3 | loss: 0.1993236\n",
      "\tspeed: 0.1045s/iter; left time: 6852.6157s\n",
      "2299it [04:08,  9.51it/s]\titers: 2300, epoch: 3 | loss: 0.1569899\n",
      "\tspeed: 0.1071s/iter; left time: 7013.1114s\n",
      "2399it [04:18,  9.56it/s]\titers: 2400, epoch: 3 | loss: 0.3033898\n",
      "\tspeed: 0.1048s/iter; left time: 6847.9465s\n",
      "2499it [04:29,  9.59it/s]\titers: 2500, epoch: 3 | loss: 0.1715891\n",
      "\tspeed: 0.1058s/iter; left time: 6904.3870s\n",
      "2599it [04:39,  9.52it/s]\titers: 2600, epoch: 3 | loss: 0.3647809\n",
      "\tspeed: 0.1035s/iter; left time: 6743.5573s\n",
      "2699it [04:50,  9.99it/s]\titers: 2700, epoch: 3 | loss: 0.3418826\n",
      "\tspeed: 0.1062s/iter; left time: 6911.5091s\n",
      "2799it [05:00,  7.71it/s]\titers: 2800, epoch: 3 | loss: 0.2294641\n",
      "\tspeed: 0.1065s/iter; left time: 6919.1507s\n",
      "2898it [05:11,  9.77it/s]\titers: 2900, epoch: 3 | loss: 0.2157331\n",
      "\tspeed: 0.1051s/iter; left time: 6817.3043s\n",
      "2999it [05:21,  9.45it/s]\titers: 3000, epoch: 3 | loss: 0.2310529\n",
      "\tspeed: 0.1068s/iter; left time: 6914.6336s\n",
      "3099it [05:32,  9.64it/s]\titers: 3100, epoch: 3 | loss: 0.1768773\n",
      "\tspeed: 0.1037s/iter; left time: 6707.1661s\n",
      "3199it [05:42, 10.08it/s]\titers: 3200, epoch: 3 | loss: 0.3301882\n",
      "\tspeed: 0.1035s/iter; left time: 6682.5204s\n",
      "3298it [05:52, 10.22it/s]\titers: 3300, epoch: 3 | loss: 0.1547895\n",
      "\tspeed: 0.1004s/iter; left time: 6473.2023s\n",
      "3399it [06:03,  9.70it/s]\titers: 3400, epoch: 3 | loss: 0.4457112\n",
      "\tspeed: 0.1095s/iter; left time: 7051.1109s\n",
      "3499it [06:14,  9.57it/s]\titers: 3500, epoch: 3 | loss: 0.1522036\n",
      "\tspeed: 0.1043s/iter; left time: 6705.0328s\n",
      "3599it [06:24,  9.18it/s]\titers: 3600, epoch: 3 | loss: 0.1718226\n",
      "\tspeed: 0.1093s/iter; left time: 7015.4024s\n",
      "3698it [06:35,  9.90it/s]\titers: 3700, epoch: 3 | loss: 0.1879304\n",
      "\tspeed: 0.1087s/iter; left time: 6965.1792s\n",
      "3765it [06:42,  9.35it/s]\n",
      "Epoch: 3 cost time: 402.868435382843\n",
      "810it [00:40, 20.09it/s]\n",
      "807it [00:38, 21.11it/s]\n",
      "Epoch: 3 | Train Loss: 0.2491981 Vali Loss: 0.2902947 Test Loss: 0.3629373 MAE Loss: 0.3664696\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "99it [00:10, 10.09it/s]\titers: 100, epoch: 4 | loss: 0.2327871\n",
      "\tspeed: 0.9913s/iter; left time: 63349.0618s\n",
      "199it [00:21,  9.11it/s]\titers: 200, epoch: 4 | loss: 0.1827734\n",
      "\tspeed: 0.1115s/iter; left time: 7116.5084s\n",
      "299it [00:32,  9.54it/s]\titers: 300, epoch: 4 | loss: 0.3517460\n",
      "\tspeed: 0.1069s/iter; left time: 6810.1985s\n",
      "399it [00:43,  9.48it/s]\titers: 400, epoch: 4 | loss: 0.4774743\n",
      "\tspeed: 0.1098s/iter; left time: 6983.9928s\n",
      "499it [00:53,  9.62it/s]\titers: 500, epoch: 4 | loss: 0.2738291\n",
      "\tspeed: 0.1036s/iter; left time: 6580.8852s\n",
      "599it [01:04,  9.97it/s]\titers: 600, epoch: 4 | loss: 0.1376224\n",
      "\tspeed: 0.1049s/iter; left time: 6654.4427s\n",
      "699it [01:14,  8.21it/s]\titers: 700, epoch: 4 | loss: 0.1827113\n",
      "\tspeed: 0.1062s/iter; left time: 6720.2033s\n",
      "798it [01:25,  9.98it/s]\titers: 800, epoch: 4 | loss: 0.1716439\n",
      "\tspeed: 0.1072s/iter; left time: 6777.4699s\n",
      "899it [01:35,  8.65it/s]\titers: 900, epoch: 4 | loss: 0.2336449\n",
      "\tspeed: 0.1060s/iter; left time: 6686.3741s\n",
      "999it [01:46,  9.76it/s]\titers: 1000, epoch: 4 | loss: 0.2158545\n",
      "\tspeed: 0.1030s/iter; left time: 6489.3115s\n",
      "1099it [01:56,  9.23it/s]\titers: 1100, epoch: 4 | loss: 0.1309988\n",
      "\tspeed: 0.1064s/iter; left time: 6692.3619s\n",
      "1199it [02:07,  9.50it/s]\titers: 1200, epoch: 4 | loss: 0.1824656\n",
      "\tspeed: 0.1053s/iter; left time: 6616.2456s\n",
      "1299it [02:18,  9.54it/s]\titers: 1300, epoch: 4 | loss: 0.1274952\n",
      "\tspeed: 0.1070s/iter; left time: 6708.3829s\n",
      "1398it [02:28,  9.60it/s]\titers: 1400, epoch: 4 | loss: 0.2485512\n",
      "\tspeed: 0.1045s/iter; left time: 6542.6056s\n",
      "1499it [02:39,  9.46it/s]\titers: 1500, epoch: 4 | loss: 0.2532129\n",
      "\tspeed: 0.1078s/iter; left time: 6736.6199s\n",
      "1599it [02:49,  9.81it/s]\titers: 1600, epoch: 4 | loss: 0.2630502\n",
      "\tspeed: 0.1059s/iter; left time: 6609.9535s\n",
      "1698it [03:00,  9.90it/s]\titers: 1700, epoch: 4 | loss: 0.1064853\n",
      "\tspeed: 0.1090s/iter; left time: 6790.6147s\n",
      "1799it [03:11,  9.55it/s]\titers: 1800, epoch: 4 | loss: 0.2026107\n",
      "\tspeed: 0.1022s/iter; left time: 6355.0358s\n",
      "1899it [03:21,  9.45it/s]\titers: 1900, epoch: 4 | loss: 0.1402255\n",
      "\tspeed: 0.1085s/iter; left time: 6740.9178s\n",
      "1999it [03:32,  9.44it/s]\titers: 2000, epoch: 4 | loss: 0.2274337\n",
      "\tspeed: 0.1044s/iter; left time: 6475.5181s\n",
      "2099it [03:43,  9.64it/s]\titers: 2100, epoch: 4 | loss: 0.1340142\n",
      "\tspeed: 0.1078s/iter; left time: 6675.6959s\n",
      "2199it [03:53,  7.49it/s]\titers: 2200, epoch: 4 | loss: 0.1894352\n",
      "\tspeed: 0.1058s/iter; left time: 6539.2721s\n",
      "2299it [04:04,  9.68it/s]\titers: 2300, epoch: 4 | loss: 0.2004484\n",
      "\tspeed: 0.1069s/iter; left time: 6597.4261s\n",
      "2399it [04:14,  9.72it/s]\titers: 2400, epoch: 4 | loss: 0.5271217\n",
      "\tspeed: 0.1037s/iter; left time: 6390.3673s\n",
      "2499it [04:25,  9.54it/s]\titers: 2500, epoch: 4 | loss: 0.3280498\n",
      "\tspeed: 0.1050s/iter; left time: 6458.0568s\n",
      "2598it [04:35,  9.72it/s]\titers: 2600, epoch: 4 | loss: 0.1119976\n",
      "\tspeed: 0.1073s/iter; left time: 6591.5923s\n",
      "2699it [04:46,  9.19it/s]\titers: 2700, epoch: 4 | loss: 0.1604813\n",
      "\tspeed: 0.1054s/iter; left time: 6463.2969s\n",
      "2799it [04:57,  9.45it/s]\titers: 2800, epoch: 4 | loss: 0.4198509\n",
      "\tspeed: 0.1103s/iter; left time: 6753.6667s\n",
      "2899it [05:08,  9.69it/s]\titers: 2900, epoch: 4 | loss: 0.1755294\n",
      "\tspeed: 0.1057s/iter; left time: 6456.7716s\n",
      "2999it [05:18,  9.49it/s]\titers: 3000, epoch: 4 | loss: 0.3166817\n",
      "\tspeed: 0.1078s/iter; left time: 6574.4215s\n",
      "3099it [05:29,  9.31it/s]\titers: 3100, epoch: 4 | loss: 0.1173963\n",
      "\tspeed: 0.1039s/iter; left time: 6327.6517s\n",
      "3198it [05:40,  9.49it/s]\titers: 3200, epoch: 4 | loss: 0.1401283\n",
      "\tspeed: 0.1084s/iter; left time: 6591.3018s\n",
      "3299it [05:50,  8.94it/s]\titers: 3300, epoch: 4 | loss: 0.2136915\n",
      "\tspeed: 0.1049s/iter; left time: 6369.0707s\n",
      "3399it [06:01,  9.33it/s]\titers: 3400, epoch: 4 | loss: 0.1206224\n",
      "\tspeed: 0.1086s/iter; left time: 6584.1245s\n",
      "3499it [06:12,  8.36it/s]\titers: 3500, epoch: 4 | loss: 0.1457095\n",
      "\tspeed: 0.1140s/iter; left time: 6898.2944s\n",
      "3599it [06:23,  9.52it/s]\titers: 3600, epoch: 4 | loss: 0.3187863\n",
      "\tspeed: 0.1094s/iter; left time: 6608.7313s\n",
      "3699it [06:34,  9.15it/s]\titers: 3700, epoch: 4 | loss: 0.2756296\n",
      "\tspeed: 0.1102s/iter; left time: 6646.0507s\n",
      "3765it [06:42,  9.36it/s]\n",
      "Epoch: 4 cost time: 402.28674483299255\n",
      "810it [00:39, 20.40it/s]\n",
      "807it [00:38, 20.97it/s]\n",
      "Epoch: 4 | Train Loss: 0.2416328 Vali Loss: 0.2884408 Test Loss: 0.3517958 MAE Loss: 0.3653238\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "98it [00:11,  9.64it/s]\titers: 100, epoch: 5 | loss: 0.2478547\n",
      "\tspeed: 1.0030s/iter; left time: 60320.3544s\n",
      "199it [00:21,  9.19it/s]\titers: 200, epoch: 5 | loss: 0.1383682\n",
      "\tspeed: 0.1060s/iter; left time: 6364.5058s\n",
      "299it [00:33,  9.47it/s]\titers: 300, epoch: 5 | loss: 0.1529171\n",
      "\tspeed: 0.1160s/iter; left time: 6952.4690s\n",
      "399it [00:44,  8.23it/s]\titers: 400, epoch: 5 | loss: 0.1276615\n",
      "\tspeed: 0.1072s/iter; left time: 6415.3112s\n",
      "499it [00:54,  9.54it/s]\titers: 500, epoch: 5 | loss: 0.2939120\n",
      "\tspeed: 0.1049s/iter; left time: 6266.6093s\n",
      "599it [01:05,  9.66it/s]\titers: 600, epoch: 5 | loss: 0.1669849\n",
      "\tspeed: 0.1074s/iter; left time: 6404.3057s\n",
      "699it [01:15,  9.04it/s]\titers: 700, epoch: 5 | loss: 0.2098992\n",
      "\tspeed: 0.1051s/iter; left time: 6256.3082s\n",
      "799it [01:27,  8.07it/s]\titers: 800, epoch: 5 | loss: 0.1521538\n",
      "\tspeed: 0.1166s/iter; left time: 6928.7065s\n",
      "899it [01:38,  9.54it/s]\titers: 900, epoch: 5 | loss: 0.3411751\n",
      "\tspeed: 0.1080s/iter; left time: 6411.6337s\n",
      "999it [01:49,  9.42it/s]\titers: 1000, epoch: 5 | loss: 0.2953703\n",
      "\tspeed: 0.1089s/iter; left time: 6448.9994s\n",
      "1099it [01:59,  9.31it/s]\titers: 1100, epoch: 5 | loss: 0.1461303\n",
      "\tspeed: 0.1050s/iter; left time: 6209.9935s\n",
      "1199it [02:10,  9.26it/s]\titers: 1200, epoch: 5 | loss: 0.2113649\n",
      "\tspeed: 0.1089s/iter; left time: 6430.9100s\n",
      "1298it [02:21,  9.27it/s]\titers: 1300, epoch: 5 | loss: 0.1441561\n",
      "\tspeed: 0.1053s/iter; left time: 6208.3072s\n",
      "1399it [02:32,  9.44it/s]\titers: 1400, epoch: 5 | loss: 0.2450217\n",
      "\tspeed: 0.1117s/iter; left time: 6569.6076s\n",
      "1499it [02:43,  9.54it/s]\titers: 1500, epoch: 5 | loss: 0.2191112\n",
      "\tspeed: 0.1065s/iter; left time: 6256.0241s\n",
      "1599it [02:53,  9.62it/s]\titers: 1600, epoch: 5 | loss: 0.1568705\n",
      "\tspeed: 0.1064s/iter; left time: 6238.9224s\n",
      "1699it [03:04,  9.64it/s]\titers: 1700, epoch: 5 | loss: 0.0926042\n",
      "\tspeed: 0.1049s/iter; left time: 6140.2863s\n",
      "1798it [03:14,  9.66it/s]\titers: 1800, epoch: 5 | loss: 0.1626513\n",
      "\tspeed: 0.1071s/iter; left time: 6260.1090s\n",
      "1899it [03:25,  9.68it/s]\titers: 1900, epoch: 5 | loss: 0.1184558\n",
      "\tspeed: 0.1051s/iter; left time: 6133.3035s\n",
      "1998it [03:36,  9.38it/s]\titers: 2000, epoch: 5 | loss: 0.1913441\n",
      "\tspeed: 0.1087s/iter; left time: 6327.9669s\n",
      "2099it [03:46,  9.17it/s]\titers: 2100, epoch: 5 | loss: 0.0798915\n",
      "\tspeed: 0.1054s/iter; left time: 6129.9605s\n",
      "2199it [03:57,  9.54it/s]\titers: 2200, epoch: 5 | loss: 0.1707447\n",
      "\tspeed: 0.1064s/iter; left time: 6173.9485s\n",
      "2299it [04:08,  9.22it/s]\titers: 2300, epoch: 5 | loss: 0.1905618\n",
      "\tspeed: 0.1065s/iter; left time: 6171.9079s\n",
      "2398it [04:18,  9.59it/s]\titers: 2400, epoch: 5 | loss: 0.1451156\n",
      "\tspeed: 0.1069s/iter; left time: 6183.3265s\n",
      "2499it [04:29,  9.49it/s]\titers: 2500, epoch: 5 | loss: 0.1663814\n",
      "\tspeed: 0.1054s/iter; left time: 6085.9398s\n",
      "2598it [04:39,  9.46it/s]\titers: 2600, epoch: 5 | loss: 0.1278661\n",
      "\tspeed: 0.1070s/iter; left time: 6168.3899s\n",
      "2698it [04:50,  9.58it/s]\titers: 2700, epoch: 5 | loss: 0.1764272\n",
      "\tspeed: 0.1081s/iter; left time: 6218.2579s\n",
      "2799it [05:01,  9.60it/s]\titers: 2800, epoch: 5 | loss: 0.1719727\n",
      "\tspeed: 0.1038s/iter; left time: 5961.1469s\n",
      "2899it [05:12,  9.29it/s]\titers: 2900, epoch: 5 | loss: 0.4123531\n",
      "\tspeed: 0.1083s/iter; left time: 6209.4678s\n",
      "2999it [05:22,  9.50it/s]\titers: 3000, epoch: 5 | loss: 0.1176015\n",
      "\tspeed: 0.1043s/iter; left time: 5970.1939s\n",
      "3099it [05:33,  9.33it/s]\titers: 3100, epoch: 5 | loss: 0.6524203\n",
      "\tspeed: 0.1110s/iter; left time: 6341.6547s\n",
      "3199it [05:44,  9.13it/s]\titers: 3200, epoch: 5 | loss: 0.2427421\n",
      "\tspeed: 0.1084s/iter; left time: 6181.1839s\n",
      "3299it [05:55,  9.61it/s]\titers: 3300, epoch: 5 | loss: 0.4476039\n",
      "\tspeed: 0.1062s/iter; left time: 6047.3804s\n",
      "3399it [06:05,  9.23it/s]\titers: 3400, epoch: 5 | loss: 0.1180677\n",
      "\tspeed: 0.1046s/iter; left time: 5946.9910s\n",
      "3499it [06:16,  9.01it/s]\titers: 3500, epoch: 5 | loss: 0.2994959\n",
      "\tspeed: 0.1091s/iter; left time: 6191.3284s\n",
      "3599it [06:27,  7.67it/s]\titers: 3600, epoch: 5 | loss: 0.1675474\n",
      "\tspeed: 0.1107s/iter; left time: 6272.6382s\n",
      "3698it [06:38,  9.52it/s]\titers: 3700, epoch: 5 | loss: 0.2383050\n",
      "\tspeed: 0.1086s/iter; left time: 6140.0379s\n",
      "3765it [06:45,  9.28it/s]\n",
      "Epoch: 5 cost time: 405.56024527549744\n",
      "810it [00:39, 20.37it/s]\n",
      "807it [00:37, 21.25it/s]\n",
      "Epoch: 5 | Train Loss: 0.2372901 Vali Loss: 0.2835108 Test Loss: 0.3499868 MAE Loss: 0.3575151\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "99it [00:10, 10.22it/s]\titers: 100, epoch: 6 | loss: 0.2878288\n",
      "\tspeed: 0.9848s/iter; left time: 55517.7716s\n",
      "199it [00:20,  9.53it/s]\titers: 200, epoch: 6 | loss: 0.4961921\n",
      "\tspeed: 0.1049s/iter; left time: 5903.4541s\n",
      "299it [00:30,  9.66it/s]\titers: 300, epoch: 6 | loss: 0.2105422\n",
      "\tspeed: 0.1025s/iter; left time: 5755.2556s\n",
      "399it [00:40, 10.07it/s]\titers: 400, epoch: 6 | loss: 0.1743765\n",
      "\tspeed: 0.0991s/iter; left time: 5559.0680s\n",
      "499it [00:51,  9.84it/s]\titers: 500, epoch: 6 | loss: 0.1949147\n",
      "\tspeed: 0.1042s/iter; left time: 5833.4118s\n",
      "599it [01:01,  9.42it/s]\titers: 600, epoch: 6 | loss: 0.1083930\n",
      "\tspeed: 0.1053s/iter; left time: 5882.0827s\n",
      "699it [01:12,  9.80it/s]\titers: 700, epoch: 6 | loss: 0.1878314\n",
      "\tspeed: 0.1090s/iter; left time: 6079.1164s\n",
      "799it [01:23,  9.68it/s]\titers: 800, epoch: 6 | loss: 0.1152903\n",
      "\tspeed: 0.1039s/iter; left time: 5786.1455s\n",
      "899it [01:34,  9.53it/s]\titers: 900, epoch: 6 | loss: 0.2227674\n",
      "\tspeed: 0.1097s/iter; left time: 6098.2023s\n",
      "999it [01:44,  9.29it/s]\titers: 1000, epoch: 6 | loss: 0.1907932\n",
      "\tspeed: 0.1039s/iter; left time: 5765.7965s\n",
      "1099it [01:54,  9.81it/s]\titers: 1100, epoch: 6 | loss: 0.1790158\n",
      "\tspeed: 0.1055s/iter; left time: 5840.9169s\n",
      "1199it [02:05,  8.85it/s]\titers: 1200, epoch: 6 | loss: 0.2772488\n",
      "\tspeed: 0.1060s/iter; left time: 5860.4896s\n",
      "1298it [02:16,  9.32it/s]\titers: 1300, epoch: 6 | loss: 0.2489044\n",
      "\tspeed: 0.1060s/iter; left time: 5846.5409s\n",
      "1399it [02:26,  9.51it/s]\titers: 1400, epoch: 6 | loss: 0.2973155\n",
      "\tspeed: 0.1062s/iter; left time: 5849.7735s\n",
      "1499it [02:37,  9.35it/s]\titers: 1500, epoch: 6 | loss: 0.2260058\n",
      "\tspeed: 0.1083s/iter; left time: 5951.9936s\n",
      "1599it [02:48,  8.99it/s]\titers: 1600, epoch: 6 | loss: 0.2973276\n",
      "\tspeed: 0.1105s/iter; left time: 6066.3321s\n",
      "1699it [02:59,  9.32it/s]\titers: 1700, epoch: 6 | loss: 0.1307759\n",
      "\tspeed: 0.1083s/iter; left time: 5932.2078s\n",
      "1799it [03:10,  8.97it/s]\titers: 1800, epoch: 6 | loss: 0.1549767\n",
      "\tspeed: 0.1108s/iter; left time: 6057.4518s\n",
      "1899it [03:21,  8.59it/s]\titers: 1900, epoch: 6 | loss: 0.1688714\n",
      "\tspeed: 0.1101s/iter; left time: 6009.3486s\n",
      "1999it [03:32,  9.58it/s]\titers: 2000, epoch: 6 | loss: 0.3452678\n",
      "\tspeed: 0.1054s/iter; left time: 5743.6534s\n",
      "2099it [03:42,  9.69it/s]\titers: 2100, epoch: 6 | loss: 0.2638007\n",
      "\tspeed: 0.1065s/iter; left time: 5792.2436s\n",
      "2199it [03:53,  9.76it/s]\titers: 2200, epoch: 6 | loss: 0.2849278\n",
      "\tspeed: 0.1046s/iter; left time: 5678.8956s\n",
      "2299it [04:03,  9.69it/s]\titers: 2300, epoch: 6 | loss: 0.1462020\n",
      "\tspeed: 0.1063s/iter; left time: 5761.6097s\n",
      "2399it [04:14,  9.46it/s]\titers: 2400, epoch: 6 | loss: 0.3516234\n",
      "\tspeed: 0.1039s/iter; left time: 5616.7188s\n",
      "2499it [04:25,  9.70it/s]\titers: 2500, epoch: 6 | loss: 0.2124246\n",
      "\tspeed: 0.1073s/iter; left time: 5790.1146s\n",
      "2599it [04:35,  9.61it/s]\titers: 2600, epoch: 6 | loss: 0.1399324\n",
      "\tspeed: 0.1035s/iter; left time: 5574.6019s\n",
      "2698it [04:46,  9.81it/s]\titers: 2700, epoch: 6 | loss: 0.2741902\n",
      "\tspeed: 0.1075s/iter; left time: 5782.2493s\n",
      "2798it [04:56,  9.44it/s]\titers: 2800, epoch: 6 | loss: 0.2097877\n",
      "\tspeed: 0.1071s/iter; left time: 5748.2906s\n",
      "2899it [05:07,  9.72it/s]\titers: 2900, epoch: 6 | loss: 0.2950759\n",
      "\tspeed: 0.1043s/iter; left time: 5586.0248s\n",
      "2999it [05:18,  9.78it/s]\titers: 3000, epoch: 6 | loss: 0.2340228\n",
      "\tspeed: 0.1084s/iter; left time: 5796.8100s\n",
      "3099it [05:28,  9.66it/s]\titers: 3100, epoch: 6 | loss: 0.2753986\n",
      "\tspeed: 0.1048s/iter; left time: 5595.4622s\n",
      "3199it [05:39,  9.59it/s]\titers: 3200, epoch: 6 | loss: 0.2271931\n",
      "\tspeed: 0.1084s/iter; left time: 5777.4290s\n",
      "3299it [05:49,  9.63it/s]\titers: 3300, epoch: 6 | loss: 0.2401093\n",
      "\tspeed: 0.1024s/iter; left time: 5443.6759s\n",
      "3398it [06:00,  9.56it/s]\titers: 3400, epoch: 6 | loss: 0.2277089\n",
      "\tspeed: 0.1082s/iter; left time: 5741.6426s\n",
      "3499it [06:11,  7.59it/s]\titers: 3500, epoch: 6 | loss: 0.1773320\n",
      "\tspeed: 0.1071s/iter; left time: 5674.4784s\n",
      "3599it [06:21,  9.72it/s]\titers: 3600, epoch: 6 | loss: 0.2196590\n",
      "\tspeed: 0.1047s/iter; left time: 5537.1965s\n",
      "3699it [06:32,  9.51it/s]\titers: 3700, epoch: 6 | loss: 0.3850082\n",
      "\tspeed: 0.1075s/iter; left time: 5670.8963s\n",
      "3765it [06:39,  9.43it/s]\n",
      "Epoch: 6 cost time: 399.38268995285034\n",
      "810it [00:38, 21.01it/s]\n",
      "807it [00:38, 21.18it/s]\n",
      "Epoch: 6 | Train Loss: 0.2355063 Vali Loss: 0.2831480 Test Loss: 0.3547814 MAE Loss: 0.3591193\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "99it [00:11,  9.69it/s]\titers: 100, epoch: 7 | loss: 0.1825873\n",
      "\tspeed: 0.9871s/iter; left time: 51930.6914s\n",
      "198it [00:21,  9.57it/s]\titers: 200, epoch: 7 | loss: 0.1787469\n",
      "\tspeed: 0.1028s/iter; left time: 5398.3621s\n",
      "299it [00:32,  9.53it/s]\titers: 300, epoch: 7 | loss: 0.2098895\n",
      "\tspeed: 0.1078s/iter; left time: 5650.0891s\n",
      "399it [00:42,  7.07it/s]\titers: 400, epoch: 7 | loss: 0.2005446\n",
      "\tspeed: 0.1072s/iter; left time: 5608.4776s\n",
      "499it [00:53,  9.69it/s]\titers: 500, epoch: 7 | loss: 0.2577834\n",
      "\tspeed: 0.1046s/iter; left time: 5460.6343s\n",
      "599it [01:04,  9.61it/s]\titers: 600, epoch: 7 | loss: 0.4209492\n",
      "\tspeed: 0.1078s/iter; left time: 5617.2098s\n",
      "699it [01:14,  9.76it/s]\titers: 700, epoch: 7 | loss: 0.2408255\n",
      "\tspeed: 0.1046s/iter; left time: 5441.2551s\n",
      "799it [01:25,  9.63it/s]\titers: 800, epoch: 7 | loss: 0.1835321\n",
      "\tspeed: 0.1086s/iter; left time: 5636.5820s\n",
      "899it [01:35,  9.69it/s]\titers: 900, epoch: 7 | loss: 0.1966216\n",
      "\tspeed: 0.1033s/iter; left time: 5354.4035s\n",
      "999it [01:46,  9.54it/s]\titers: 1000, epoch: 7 | loss: 0.2130457\n",
      "\tspeed: 0.1084s/iter; left time: 5605.6590s\n",
      "1099it [01:57,  7.20it/s]\titers: 1100, epoch: 7 | loss: 0.2298835\n",
      "\tspeed: 0.1059s/iter; left time: 5467.5402s\n",
      "1199it [02:07,  9.78it/s]\titers: 1200, epoch: 7 | loss: 0.1886945\n",
      "\tspeed: 0.1053s/iter; left time: 5425.1909s\n",
      "1298it [02:18,  9.56it/s]\titers: 1300, epoch: 7 | loss: 0.5007377\n",
      "\tspeed: 0.1068s/iter; left time: 5492.8980s\n",
      "1399it [02:28,  9.48it/s]\titers: 1400, epoch: 7 | loss: 0.1594545\n",
      "\tspeed: 0.1045s/iter; left time: 5362.8243s\n",
      "1499it [02:39,  9.51it/s]\titers: 1500, epoch: 7 | loss: 0.1172540\n",
      "\tspeed: 0.1068s/iter; left time: 5468.0775s\n",
      "1598it [02:50,  9.62it/s]\titers: 1600, epoch: 7 | loss: 0.1343378\n",
      "\tspeed: 0.1050s/iter; left time: 5366.5141s\n",
      "1699it [03:00,  9.41it/s]\titers: 1700, epoch: 7 | loss: 0.3640646\n",
      "\tspeed: 0.1081s/iter; left time: 5513.4884s\n",
      "1799it [03:11,  9.52it/s]\titers: 1800, epoch: 7 | loss: 0.2789223\n",
      "\tspeed: 0.1027s/iter; left time: 5228.5404s\n",
      "1899it [03:22,  9.44it/s]\titers: 1900, epoch: 7 | loss: 0.2838268\n",
      "\tspeed: 0.1091s/iter; left time: 5544.3078s\n",
      "1999it [03:32,  9.10it/s]\titers: 2000, epoch: 7 | loss: 0.2160061\n",
      "\tspeed: 0.1071s/iter; left time: 5432.2292s\n",
      "2099it [03:43, 10.22it/s]\titers: 2100, epoch: 7 | loss: 0.1511686\n",
      "\tspeed: 0.1094s/iter; left time: 5539.3656s\n",
      "2199it [03:54,  7.75it/s]\titers: 2200, epoch: 7 | loss: 0.2368914\n",
      "\tspeed: 0.1073s/iter; left time: 5419.2347s\n",
      "2299it [04:05,  8.97it/s]\titers: 2300, epoch: 7 | loss: 0.1790831\n",
      "\tspeed: 0.1113s/iter; left time: 5612.8662s\n",
      "2399it [04:16,  7.03it/s]\titers: 2400, epoch: 7 | loss: 0.0987818\n",
      "\tspeed: 0.1135s/iter; left time: 5708.8493s\n",
      "2499it [04:27,  9.43it/s]\titers: 2500, epoch: 7 | loss: 0.2260060\n",
      "\tspeed: 0.1045s/iter; left time: 5244.9195s\n",
      "2599it [04:38,  9.70it/s]\titers: 2600, epoch: 7 | loss: 0.2190440\n",
      "\tspeed: 0.1097s/iter; left time: 5497.8238s\n",
      "2699it [04:48,  9.49it/s]\titers: 2700, epoch: 7 | loss: 0.1700542\n",
      "\tspeed: 0.1038s/iter; left time: 5190.4737s\n",
      "2798it [04:59,  9.70it/s]\titers: 2800, epoch: 7 | loss: 0.1898256\n",
      "\tspeed: 0.1091s/iter; left time: 5445.3317s\n",
      "2899it [05:10,  9.45it/s]\titers: 2900, epoch: 7 | loss: 0.2612721\n",
      "\tspeed: 0.1048s/iter; left time: 5217.9305s\n",
      "2998it [05:20,  9.02it/s]\titers: 3000, epoch: 7 | loss: 0.1626969\n",
      "\tspeed: 0.1092s/iter; left time: 5426.8441s\n",
      "3099it [05:31,  8.28it/s]\titers: 3100, epoch: 7 | loss: 0.1865934\n",
      "\tspeed: 0.1081s/iter; left time: 5364.7979s\n",
      "3199it [05:42,  9.52it/s]\titers: 3200, epoch: 7 | loss: 0.1596189\n",
      "\tspeed: 0.1049s/iter; left time: 5192.9703s\n",
      "3299it [05:53,  9.56it/s]\titers: 3300, epoch: 7 | loss: 0.1887575\n",
      "\tspeed: 0.1074s/iter; left time: 5304.5052s\n",
      "3399it [06:03,  9.48it/s]\titers: 3400, epoch: 7 | loss: 0.2988138\n",
      "\tspeed: 0.1072s/iter; left time: 5286.4007s\n",
      "3499it [06:14,  9.03it/s]\titers: 3500, epoch: 7 | loss: 0.2396412\n",
      "\tspeed: 0.1084s/iter; left time: 5335.1119s\n",
      "3599it [06:25,  9.76it/s]\titers: 3600, epoch: 7 | loss: 0.2243811\n",
      "\tspeed: 0.1051s/iter; left time: 5163.3953s\n",
      "3699it [06:36,  9.47it/s]\titers: 3700, epoch: 7 | loss: 0.1390385\n",
      "\tspeed: 0.1097s/iter; left time: 5378.1704s\n",
      "3765it [06:43,  9.34it/s]\n",
      "Epoch: 7 cost time: 403.27958273887634\n",
      "810it [00:38, 21.09it/s]\n",
      "807it [00:37, 21.26it/s]\n",
      "Epoch: 7 | Train Loss: 0.2349653 Vali Loss: 0.2790892 Test Loss: 0.3470574 MAE Loss: 0.3519578\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "99it [00:10,  9.60it/s]\titers: 100, epoch: 8 | loss: 0.3506989\n",
      "\tspeed: 0.9742s/iter; left time: 47584.9162s\n",
      "199it [00:21,  9.28it/s]\titers: 200, epoch: 8 | loss: 0.1436247\n",
      "\tspeed: 0.1035s/iter; left time: 5047.3099s\n",
      "299it [00:31,  9.74it/s]\titers: 300, epoch: 8 | loss: 0.2360088\n",
      "\tspeed: 0.1051s/iter; left time: 5111.3325s\n",
      "399it [00:42,  9.74it/s]\titers: 400, epoch: 8 | loss: 0.2246222\n",
      "\tspeed: 0.1070s/iter; left time: 5193.1261s\n",
      "499it [00:52,  9.68it/s]\titers: 500, epoch: 8 | loss: 0.2638862\n",
      "\tspeed: 0.1043s/iter; left time: 5053.3993s\n",
      "598it [01:03,  9.68it/s]\titers: 600, epoch: 8 | loss: 0.2370474\n",
      "\tspeed: 0.1064s/iter; left time: 5141.9360s\n",
      "699it [01:13,  9.59it/s]\titers: 700, epoch: 8 | loss: 0.1567954\n",
      "\tspeed: 0.1031s/iter; left time: 4974.2034s\n",
      "799it [01:24,  9.45it/s]\titers: 800, epoch: 8 | loss: 0.1541171\n",
      "\tspeed: 0.1078s/iter; left time: 5192.3821s\n",
      "899it [01:35,  8.13it/s]\titers: 900, epoch: 8 | loss: 0.2944638\n",
      "\tspeed: 0.1063s/iter; left time: 5106.9767s\n",
      "999it [01:46,  9.52it/s]\titers: 1000, epoch: 8 | loss: 0.2044097\n",
      "\tspeed: 0.1086s/iter; left time: 5206.5203s\n",
      "1098it [01:56,  9.54it/s]\titers: 1100, epoch: 8 | loss: 0.1035955\n",
      "\tspeed: 0.1065s/iter; left time: 5095.2613s\n",
      "1199it [02:07,  9.87it/s]\titers: 1200, epoch: 8 | loss: 0.1289895\n",
      "\tspeed: 0.1049s/iter; left time: 5007.2069s\n",
      "1299it [02:18,  9.42it/s]\titers: 1300, epoch: 8 | loss: 0.1314626\n",
      "\tspeed: 0.1090s/iter; left time: 5193.0044s\n",
      "1399it [02:28,  9.51it/s]\titers: 1400, epoch: 8 | loss: 0.1493650\n",
      "\tspeed: 0.1034s/iter; left time: 4914.2520s\n",
      "1499it [02:39,  9.52it/s]\titers: 1500, epoch: 8 | loss: 0.2853166\n",
      "\tspeed: 0.1090s/iter; left time: 5169.8122s\n",
      "1599it [02:49,  9.52it/s]\titers: 1600, epoch: 8 | loss: 0.2085637\n",
      "\tspeed: 0.1031s/iter; left time: 4882.1221s\n",
      "1698it [03:00,  9.66it/s]\titers: 1700, epoch: 8 | loss: 0.3593288\n",
      "\tspeed: 0.1084s/iter; left time: 5122.4889s\n",
      "1799it [03:11,  7.35it/s]\titers: 1800, epoch: 8 | loss: 0.1689215\n",
      "\tspeed: 0.1094s/iter; left time: 5158.1945s\n",
      "1898it [03:21,  9.66it/s]\titers: 1900, epoch: 8 | loss: 0.3364297\n",
      "\tspeed: 0.1037s/iter; left time: 4880.7255s\n",
      "1999it [03:32,  7.52it/s]\titers: 2000, epoch: 8 | loss: 0.1890083\n",
      "\tspeed: 0.1063s/iter; left time: 4989.8657s\n",
      "2099it [03:42,  9.71it/s]\titers: 2100, epoch: 8 | loss: 0.1462867\n",
      "\tspeed: 0.1032s/iter; left time: 4833.4673s\n",
      "2199it [03:53,  9.79it/s]\titers: 2200, epoch: 8 | loss: 0.2131882\n",
      "\tspeed: 0.1068s/iter; left time: 4993.0659s\n",
      "2299it [04:03,  9.54it/s]\titers: 2300, epoch: 8 | loss: 0.3391059\n",
      "\tspeed: 0.1035s/iter; left time: 4826.4876s\n",
      "2399it [04:14,  9.76it/s]\titers: 2400, epoch: 8 | loss: 0.1930247\n",
      "\tspeed: 0.1077s/iter; left time: 5011.2657s\n",
      "2499it [04:25,  9.50it/s]\titers: 2500, epoch: 8 | loss: 0.1811646\n",
      "\tspeed: 0.1075s/iter; left time: 4991.2171s\n",
      "2599it [04:35,  9.55it/s]\titers: 2600, epoch: 8 | loss: 0.3426889\n",
      "\tspeed: 0.1048s/iter; left time: 4855.5459s\n",
      "2698it [04:46,  7.59it/s]\titers: 2700, epoch: 8 | loss: 0.2884260\n",
      "\tspeed: 0.1099s/iter; left time: 5081.8339s\n",
      "2799it [04:57,  9.52it/s]\titers: 2800, epoch: 8 | loss: 0.2787545\n",
      "\tspeed: 0.1035s/iter; left time: 4778.2179s\n",
      "2899it [05:07,  9.69it/s]\titers: 2900, epoch: 8 | loss: 0.2385738\n",
      "\tspeed: 0.1066s/iter; left time: 4906.6784s\n",
      "2999it [05:18,  8.76it/s]\titers: 3000, epoch: 8 | loss: 0.2332280\n",
      "\tspeed: 0.1059s/iter; left time: 4863.4971s\n",
      "3098it [05:28, 10.17it/s]\titers: 3100, epoch: 8 | loss: 0.4117592\n",
      "\tspeed: 0.1050s/iter; left time: 4815.2151s\n",
      "3199it [05:39,  8.99it/s]\titers: 3200, epoch: 8 | loss: 0.2709180\n",
      "\tspeed: 0.1024s/iter; left time: 4686.6122s\n",
      "3299it [05:49,  9.49it/s]\titers: 3300, epoch: 8 | loss: 0.1573088\n",
      "\tspeed: 0.1047s/iter; left time: 4779.3078s\n",
      "3399it [05:59,  9.69it/s]\titers: 3400, epoch: 8 | loss: 0.2022467\n",
      "\tspeed: 0.1009s/iter; left time: 4597.5796s\n",
      "3498it [06:10,  9.52it/s]\titers: 3500, epoch: 8 | loss: 0.2233892\n",
      "\tspeed: 0.1040s/iter; left time: 4725.3009s\n",
      "3599it [06:20,  9.68it/s]\titers: 3600, epoch: 8 | loss: 0.2437603\n",
      "\tspeed: 0.1066s/iter; left time: 4835.5807s\n",
      "3699it [06:31,  9.61it/s]\titers: 3700, epoch: 8 | loss: 0.1701473\n",
      "\tspeed: 0.1034s/iter; left time: 4679.0393s\n",
      "3765it [06:38,  9.45it/s]\n",
      "Epoch: 8 cost time: 398.3803572654724\n",
      "810it [00:38, 20.96it/s]\n",
      "807it [00:38, 20.96it/s]\n",
      "Epoch: 8 | Train Loss: 0.2336885 Vali Loss: 0.2808471 Test Loss: 0.3495025 MAE Loss: 0.3542536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "99it [00:10,  9.35it/s]\titers: 100, epoch: 9 | loss: 0.3825790\n",
      "\tspeed: 0.9531s/iter; left time: 42968.6418s\n",
      "198it [00:21,  9.54it/s]\titers: 200, epoch: 9 | loss: 0.1725433\n",
      "\tspeed: 0.1077s/iter; left time: 4843.8722s\n",
      "299it [00:32,  7.87it/s]\titers: 300, epoch: 9 | loss: 0.4980379\n",
      "\tspeed: 0.1066s/iter; left time: 4783.7567s\n",
      "399it [00:42,  9.77it/s]\titers: 400, epoch: 9 | loss: 0.2820833\n",
      "\tspeed: 0.1046s/iter; left time: 4685.0990s\n",
      "499it [00:53,  8.60it/s]\titers: 500, epoch: 9 | loss: 0.1706389\n",
      "\tspeed: 0.1064s/iter; left time: 4752.4898s\n",
      "599it [01:03,  9.55it/s]\titers: 600, epoch: 9 | loss: 0.1779170\n",
      "\tspeed: 0.1037s/iter; left time: 4621.9437s\n",
      "699it [01:14,  9.67it/s]\titers: 700, epoch: 9 | loss: 0.2595640\n",
      "\tspeed: 0.1077s/iter; left time: 4788.6863s\n",
      "799it [01:25,  9.48it/s]\titers: 800, epoch: 9 | loss: 0.2967034\n",
      "\tspeed: 0.1057s/iter; left time: 4692.0544s\n",
      "899it [01:36,  9.60it/s]\titers: 900, epoch: 9 | loss: 0.2537479\n",
      "\tspeed: 0.1112s/iter; left time: 4924.3820s\n",
      "999it [01:46,  9.54it/s]\titers: 1000, epoch: 9 | loss: 0.3987970\n",
      "\tspeed: 0.1059s/iter; left time: 4677.3088s\n",
      "1099it [01:57,  9.76it/s]\titers: 1100, epoch: 9 | loss: 0.1572018\n",
      "\tspeed: 0.1073s/iter; left time: 4728.3657s\n",
      "1198it [02:07,  9.26it/s]\titers: 1200, epoch: 9 | loss: 0.1536233\n",
      "\tspeed: 0.1054s/iter; left time: 4633.7065s\n",
      "1299it [02:18, 10.02it/s]\titers: 1300, epoch: 9 | loss: 0.2235825\n",
      "\tspeed: 0.1057s/iter; left time: 4636.7308s\n",
      "1399it [02:28,  9.51it/s]\titers: 1400, epoch: 9 | loss: 0.3382436\n",
      "\tspeed: 0.1038s/iter; left time: 4542.8797s\n",
      "1499it [02:39,  9.61it/s]\titers: 1500, epoch: 9 | loss: 0.5567049\n",
      "\tspeed: 0.1065s/iter; left time: 4651.1950s\n",
      "1599it [02:49,  8.47it/s]\titers: 1600, epoch: 9 | loss: 0.2711269\n",
      "\tspeed: 0.1011s/iter; left time: 4406.6254s\n",
      "1699it [03:00,  9.43it/s]\titers: 1700, epoch: 9 | loss: 0.1396367\n",
      "\tspeed: 0.1089s/iter; left time: 4737.0533s\n",
      "1798it [03:11,  7.94it/s]\titers: 1800, epoch: 9 | loss: 0.0876262\n",
      "\tspeed: 0.1094s/iter; left time: 4745.9913s\n",
      "1899it [03:22,  9.80it/s]\titers: 1900, epoch: 9 | loss: 0.1658398\n",
      "\tspeed: 0.1048s/iter; left time: 4537.2197s\n",
      "1999it [03:32,  9.84it/s]\titers: 2000, epoch: 9 | loss: 0.1741202\n",
      "\tspeed: 0.1045s/iter; left time: 4514.2938s\n",
      "2099it [03:42,  9.57it/s]\titers: 2100, epoch: 9 | loss: 0.2029316\n",
      "\tspeed: 0.1050s/iter; left time: 4523.7842s\n",
      "2199it [03:53,  8.32it/s]\titers: 2200, epoch: 9 | loss: 0.2443927\n",
      "\tspeed: 0.1069s/iter; left time: 4593.1132s\n",
      "2299it [04:04,  9.51it/s]\titers: 2300, epoch: 9 | loss: 0.1655963\n",
      "\tspeed: 0.1045s/iter; left time: 4479.8366s\n",
      "2399it [04:14,  9.56it/s]\titers: 2400, epoch: 9 | loss: 0.1731331\n",
      "\tspeed: 0.1065s/iter; left time: 4554.6750s\n",
      "2498it [04:25,  9.53it/s]\titers: 2500, epoch: 9 | loss: 0.1904792\n",
      "\tspeed: 0.1044s/iter; left time: 4454.2786s\n",
      "2599it [04:36,  8.83it/s]\titers: 2600, epoch: 9 | loss: 0.2654003\n",
      "\tspeed: 0.1118s/iter; left time: 4759.0654s\n",
      "2699it [04:47,  7.47it/s]\titers: 2700, epoch: 9 | loss: 0.1814935\n",
      "\tspeed: 0.1093s/iter; left time: 4642.8090s\n",
      "2799it [04:58,  8.91it/s]\titers: 2800, epoch: 9 | loss: 0.1873304\n",
      "\tspeed: 0.1094s/iter; left time: 4634.6139s\n",
      "2899it [05:09,  9.48it/s]\titers: 2900, epoch: 9 | loss: 0.4009605\n",
      "\tspeed: 0.1107s/iter; left time: 4681.5403s\n",
      "2999it [05:20,  9.22it/s]\titers: 3000, epoch: 9 | loss: 0.2766252\n",
      "\tspeed: 0.1096s/iter; left time: 4622.5977s\n",
      "3099it [05:31,  9.45it/s]\titers: 3100, epoch: 9 | loss: 0.0845561\n",
      "\tspeed: 0.1105s/iter; left time: 4651.5161s\n",
      "3199it [05:42,  7.68it/s]\titers: 3200, epoch: 9 | loss: 0.1238977\n",
      "\tspeed: 0.1076s/iter; left time: 4518.3938s\n",
      "3299it [05:52,  9.66it/s]\titers: 3300, epoch: 9 | loss: 0.3404590\n",
      "\tspeed: 0.1046s/iter; left time: 4381.1668s\n",
      "3399it [06:03,  9.67it/s]\titers: 3400, epoch: 9 | loss: 0.2350450\n",
      "\tspeed: 0.1065s/iter; left time: 4449.9174s\n",
      "3499it [06:13,  9.90it/s]\titers: 3500, epoch: 9 | loss: 0.1866093\n",
      "\tspeed: 0.1051s/iter; left time: 4381.2601s\n",
      "3598it [06:23,  9.95it/s]\titers: 3600, epoch: 9 | loss: 0.1902752\n",
      "\tspeed: 0.1036s/iter; left time: 4306.3117s\n",
      "3699it [06:34,  9.33it/s]\titers: 3700, epoch: 9 | loss: 0.2562085\n",
      "\tspeed: 0.1085s/iter; left time: 4501.6013s\n",
      "3765it [06:42,  9.35it/s]\n",
      "Epoch: 9 cost time: 402.5866334438324\n",
      "810it [00:38, 21.19it/s]\n",
      "807it [00:37, 21.27it/s]\n",
      "Epoch: 9 | Train Loss: 0.2341588 Vali Loss: 0.2810043 Test Loss: 0.3491890 MAE Loss: 0.3547902\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "99it [00:11,  9.68it/s]\titers: 100, epoch: 10 | loss: 0.1723268\n",
      "\tspeed: 0.9517s/iter; left time: 39321.8994s\n",
      "199it [00:22,  8.76it/s]\titers: 200, epoch: 10 | loss: 0.2208683\n",
      "\tspeed: 0.1088s/iter; left time: 4482.7890s\n",
      "299it [00:32,  9.92it/s]\titers: 300, epoch: 10 | loss: 0.4449243\n",
      "\tspeed: 0.1082s/iter; left time: 4450.5838s\n",
      "399it [00:43,  9.68it/s]\titers: 400, epoch: 10 | loss: 0.2609064\n",
      "\tspeed: 0.1033s/iter; left time: 4236.9209s\n",
      "499it [00:54,  9.71it/s]\titers: 500, epoch: 10 | loss: 0.0984240\n",
      "\tspeed: 0.1088s/iter; left time: 4453.5563s\n",
      "598it [01:04,  9.22it/s]\titers: 600, epoch: 10 | loss: 0.1044388\n",
      "\tspeed: 0.1019s/iter; left time: 4159.3155s\n",
      "698it [01:14, 10.20it/s]\titers: 700, epoch: 10 | loss: 0.2919191\n",
      "\tspeed: 0.1034s/iter; left time: 4208.6553s\n",
      "799it [01:25,  8.82it/s]\titers: 800, epoch: 10 | loss: 0.2367166\n",
      "\tspeed: 0.1048s/iter; left time: 4257.2800s\n",
      "899it [01:35,  9.85it/s]\titers: 900, epoch: 10 | loss: 0.2438001\n",
      "\tspeed: 0.1053s/iter; left time: 4266.9489s\n",
      "999it [01:46,  9.49it/s]\titers: 1000, epoch: 10 | loss: 0.3405101\n",
      "\tspeed: 0.1098s/iter; left time: 4436.0965s\n",
      "1099it [01:57,  9.67it/s]\titers: 1100, epoch: 10 | loss: 0.1387934\n",
      "\tspeed: 0.1059s/iter; left time: 4268.2194s\n",
      "1199it [02:08,  9.45it/s]\titers: 1200, epoch: 10 | loss: 0.1498981\n",
      "\tspeed: 0.1113s/iter; left time: 4474.5353s\n",
      "1299it [02:19,  8.93it/s]\titers: 1300, epoch: 10 | loss: 0.2480242\n",
      "\tspeed: 0.1108s/iter; left time: 4445.2533s\n",
      "1399it [02:30,  9.52it/s]\titers: 1400, epoch: 10 | loss: 0.2578139\n",
      "\tspeed: 0.1065s/iter; left time: 4259.9175s\n",
      "1499it [02:40,  9.46it/s]\titers: 1500, epoch: 10 | loss: 0.1467920\n",
      "\tspeed: 0.1087s/iter; left time: 4338.6808s\n",
      "1599it [02:51,  9.51it/s]\titers: 1600, epoch: 10 | loss: 0.1537020\n",
      "\tspeed: 0.1038s/iter; left time: 4132.1258s\n",
      "1699it [03:02,  9.80it/s]\titers: 1700, epoch: 10 | loss: 0.1890868\n",
      "\tspeed: 0.1070s/iter; left time: 4248.8094s\n",
      "1799it [03:12,  9.41it/s]\titers: 1800, epoch: 10 | loss: 0.2270114\n",
      "\tspeed: 0.1038s/iter; left time: 4112.1507s\n",
      "1898it [03:23,  9.83it/s]\titers: 1900, epoch: 10 | loss: 0.2309489\n",
      "\tspeed: 0.1070s/iter; left time: 4227.3148s\n",
      "1999it [03:33,  9.42it/s]\titers: 2000, epoch: 10 | loss: 0.2096069\n",
      "\tspeed: 0.1067s/iter; left time: 4205.5740s\n",
      "2099it [03:44,  9.60it/s]\titers: 2100, epoch: 10 | loss: 0.1128602\n",
      "\tspeed: 0.1050s/iter; left time: 4126.9486s\n",
      "2199it [03:55,  9.55it/s]\titers: 2200, epoch: 10 | loss: 0.1700975\n",
      "\tspeed: 0.1091s/iter; left time: 4277.7295s\n",
      "2299it [04:05,  9.41it/s]\titers: 2300, epoch: 10 | loss: 0.1551427\n",
      "\tspeed: 0.1043s/iter; left time: 4080.1898s\n",
      "2399it [04:16,  9.52it/s]\titers: 2400, epoch: 10 | loss: 0.2703189\n",
      "\tspeed: 0.1081s/iter; left time: 4216.4743s\n",
      "2499it [04:26,  9.00it/s]\titers: 2500, epoch: 10 | loss: 0.2492352\n",
      "\tspeed: 0.1041s/iter; left time: 4051.7476s\n",
      "2599it [04:37,  9.81it/s]\titers: 2600, epoch: 10 | loss: 0.2253091\n",
      "\tspeed: 0.1055s/iter; left time: 4095.9945s\n",
      "2699it [04:48,  9.67it/s]\titers: 2700, epoch: 10 | loss: 0.2914334\n",
      "\tspeed: 0.1062s/iter; left time: 4110.9622s\n",
      "2799it [04:58,  9.80it/s]\titers: 2800, epoch: 10 | loss: 0.1950349\n",
      "\tspeed: 0.1047s/iter; left time: 4042.6593s\n",
      "2899it [05:09,  9.55it/s]\titers: 2900, epoch: 10 | loss: 0.1068291\n",
      "\tspeed: 0.1061s/iter; left time: 4086.8210s\n",
      "2999it [05:19,  9.64it/s]\titers: 3000, epoch: 10 | loss: 0.1239468\n",
      "\tspeed: 0.1036s/iter; left time: 3979.3154s\n",
      "3098it [05:29,  9.81it/s]\titers: 3100, epoch: 10 | loss: 0.2012846\n",
      "\tspeed: 0.1062s/iter; left time: 4068.1682s\n",
      "3199it [05:40,  9.38it/s]\titers: 3200, epoch: 10 | loss: 0.4415931\n",
      "\tspeed: 0.1053s/iter; left time: 4026.0304s\n",
      "3299it [05:51,  9.86it/s]\titers: 3300, epoch: 10 | loss: 0.1700503\n",
      "\tspeed: 0.1049s/iter; left time: 3998.3357s\n",
      "3399it [06:01,  9.37it/s]\titers: 3400, epoch: 10 | loss: 0.2265361\n",
      "\tspeed: 0.1041s/iter; left time: 3958.5381s\n",
      "3498it [06:11, 10.23it/s]\titers: 3500, epoch: 10 | loss: 0.1616457\n",
      "\tspeed: 0.0986s/iter; left time: 3738.1490s\n",
      "3599it [06:21,  9.99it/s]\titers: 3600, epoch: 10 | loss: 0.4349119\n",
      "\tspeed: 0.1006s/iter; left time: 3802.6790s\n",
      "3699it [06:31,  9.48it/s]\titers: 3700, epoch: 10 | loss: 0.1088503\n",
      "\tspeed: 0.1008s/iter; left time: 3803.5302s\n",
      "3765it [06:38,  9.45it/s]\n",
      "Epoch: 10 cost time: 398.6025242805481\n",
      "810it [00:38, 21.14it/s]\n",
      "807it [00:38, 21.20it/s]\n",
      "Epoch: 10 | Train Loss: 0.2338287 Vali Loss: 0.2807260 Test Loss: 0.3485084 MAE Loss: 0.3539550\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.812499999999999e-08\n",
      "99it [00:10,  9.27it/s]\titers: 100, epoch: 11 | loss: 0.4864461\n",
      "\tspeed: 0.9445s/iter; left time: 35466.8045s\n",
      "199it [00:21,  9.20it/s]\titers: 200, epoch: 11 | loss: 0.1635980\n",
      "\tspeed: 0.1084s/iter; left time: 4059.2845s\n",
      "299it [00:32,  9.42it/s]\titers: 300, epoch: 11 | loss: 0.2338124\n",
      "\tspeed: 0.1069s/iter; left time: 3993.4392s\n",
      "399it [00:43,  8.97it/s]\titers: 400, epoch: 11 | loss: 0.2477203\n",
      "\tspeed: 0.1143s/iter; left time: 4258.3263s\n",
      "499it [00:55,  7.72it/s]\titers: 500, epoch: 11 | loss: 0.2224052\n",
      "\tspeed: 0.1121s/iter; left time: 4163.3418s\n",
      "599it [01:06,  8.96it/s]\titers: 600, epoch: 11 | loss: 0.1731232\n",
      "\tspeed: 0.1117s/iter; left time: 4139.7487s\n",
      "699it [01:17,  9.19it/s]\titers: 700, epoch: 11 | loss: 0.3543292\n",
      "\tspeed: 0.1104s/iter; left time: 4079.2972s\n",
      "799it [01:28,  9.11it/s]\titers: 800, epoch: 11 | loss: 0.1423600\n",
      "\tspeed: 0.1097s/iter; left time: 4042.9890s\n",
      "899it [01:39,  9.92it/s]\titers: 900, epoch: 11 | loss: 0.2840686\n",
      "\tspeed: 0.1095s/iter; left time: 4023.8818s\n",
      "998it [01:49, 10.21it/s]\titers: 1000, epoch: 11 | loss: 0.3593785\n",
      "\tspeed: 0.0997s/iter; left time: 3654.8080s\n",
      "1099it [01:59, 10.35it/s]\titers: 1100, epoch: 11 | loss: 0.2088745\n",
      "\tspeed: 0.1049s/iter; left time: 3833.9230s\n",
      "1198it [02:09, 10.01it/s]\titers: 1200, epoch: 11 | loss: 0.2125911\n",
      "\tspeed: 0.0989s/iter; left time: 3605.3922s\n",
      "1299it [02:19, 10.15it/s]\titers: 1300, epoch: 11 | loss: 0.2791885\n",
      "\tspeed: 0.1023s/iter; left time: 3717.6079s\n",
      "1399it [02:29,  9.91it/s]\titers: 1400, epoch: 11 | loss: 0.3497153\n",
      "\tspeed: 0.0994s/iter; left time: 3604.9283s\n",
      "1499it [02:40,  9.50it/s]\titers: 1500, epoch: 11 | loss: 0.2165293\n",
      "\tspeed: 0.1058s/iter; left time: 3826.1153s\n",
      "1599it [02:51,  9.51it/s]\titers: 1600, epoch: 11 | loss: 0.1766350\n",
      "\tspeed: 0.1078s/iter; left time: 3884.6602s\n",
      "1699it [03:02,  9.07it/s]\titers: 1700, epoch: 11 | loss: 0.2907978\n",
      "\tspeed: 0.1116s/iter; left time: 4010.7409s\n",
      "1799it [03:13,  9.32it/s]\titers: 1800, epoch: 11 | loss: 0.2214073\n",
      "\tspeed: 0.1125s/iter; left time: 4033.9085s\n",
      "1899it [03:24,  9.33it/s]\titers: 1900, epoch: 11 | loss: 0.2165587\n",
      "\tspeed: 0.1073s/iter; left time: 3834.4568s\n",
      "1999it [03:35,  7.66it/s]\titers: 2000, epoch: 11 | loss: 0.2333512\n",
      "\tspeed: 0.1106s/iter; left time: 3941.4764s\n",
      "2099it [03:45,  9.52it/s]\titers: 2100, epoch: 11 | loss: 0.1813310\n",
      "\tspeed: 0.1046s/iter; left time: 3718.4351s\n",
      "2199it [03:56,  9.52it/s]\titers: 2200, epoch: 11 | loss: 0.1433497\n",
      "\tspeed: 0.1111s/iter; left time: 3938.7020s\n",
      "2299it [04:07,  8.93it/s]\titers: 2300, epoch: 11 | loss: 0.1124350\n",
      "\tspeed: 0.1082s/iter; left time: 3825.0113s\n",
      "2399it [04:18,  9.61it/s]\titers: 2400, epoch: 11 | loss: 0.3049277\n",
      "\tspeed: 0.1120s/iter; left time: 3948.6067s\n",
      "2499it [04:29,  9.42it/s]\titers: 2500, epoch: 11 | loss: 0.1442997\n",
      "\tspeed: 0.1083s/iter; left time: 3806.8467s\n",
      "2599it [04:40,  9.62it/s]\titers: 2600, epoch: 11 | loss: 0.1332534\n",
      "\tspeed: 0.1047s/iter; left time: 3668.7147s\n",
      "2699it [04:50,  9.67it/s]\titers: 2700, epoch: 11 | loss: 0.6135613\n",
      "\tspeed: 0.1054s/iter; left time: 3682.9050s\n",
      "2799it [05:01,  9.69it/s]\titers: 2800, epoch: 11 | loss: 0.3236788\n",
      "\tspeed: 0.1042s/iter; left time: 3632.3348s\n",
      "2899it [05:11,  9.50it/s]\titers: 2900, epoch: 11 | loss: 0.3091466\n",
      "\tspeed: 0.1066s/iter; left time: 3705.7011s\n",
      "2998it [05:22,  9.60it/s]\titers: 3000, epoch: 11 | loss: 0.4900548\n",
      "\tspeed: 0.1037s/iter; left time: 3593.3714s\n",
      "3099it [05:32,  9.72it/s]\titers: 3100, epoch: 11 | loss: 0.2280794\n",
      "\tspeed: 0.1066s/iter; left time: 3682.2397s\n",
      "3199it [05:43,  9.51it/s]\titers: 3200, epoch: 11 | loss: 0.1335958\n",
      "\tspeed: 0.1053s/iter; left time: 3626.3814s\n",
      "3299it [05:53, 10.20it/s]\titers: 3300, epoch: 11 | loss: 0.1745294\n",
      "\tspeed: 0.1036s/iter; left time: 3560.2857s\n",
      "3398it [06:03,  9.80it/s]\titers: 3400, epoch: 11 | loss: 0.3373220\n",
      "\tspeed: 0.0985s/iter; left time: 3373.7783s\n",
      "3499it [06:13,  9.64it/s]\titers: 3500, epoch: 11 | loss: 0.1952699\n",
      "\tspeed: 0.1034s/iter; left time: 3532.2673s\n",
      "3599it [06:24,  8.86it/s]\titers: 3600, epoch: 11 | loss: 0.2437931\n",
      "\tspeed: 0.1073s/iter; left time: 3654.0190s\n",
      "3699it [06:35,  9.66it/s]\titers: 3700, epoch: 11 | loss: 0.1880078\n",
      "\tspeed: 0.1043s/iter; left time: 3541.6672s\n",
      "3765it [06:42,  9.36it/s]\n",
      "Epoch: 11 cost time: 402.2965576648712\n",
      "810it [00:38, 21.03it/s]\n",
      "807it [00:38, 20.84it/s]\n",
      "Epoch: 11 | Train Loss: 0.2340201 Vali Loss: 0.2806249 Test Loss: 0.3491499 MAE Loss: 0.3542873\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.9062499999999997e-08\n",
      "99it [00:11,  9.05it/s]\titers: 100, epoch: 12 | loss: 0.2215275\n",
      "\tspeed: 0.9579s/iter; left time: 32363.9318s\n",
      "198it [00:21,  9.70it/s]\titers: 200, epoch: 12 | loss: 0.2778927\n",
      "\tspeed: 0.1075s/iter; left time: 3619.7474s\n",
      "299it [00:32,  8.84it/s]\titers: 300, epoch: 12 | loss: 0.2482912\n",
      "\tspeed: 0.1079s/iter; left time: 3624.9242s\n",
      "399it [00:43,  9.72it/s]\titers: 400, epoch: 12 | loss: 0.1680039\n",
      "\tspeed: 0.1073s/iter; left time: 3592.1223s\n",
      "499it [00:54,  9.55it/s]\titers: 500, epoch: 12 | loss: 0.1615561\n",
      "\tspeed: 0.1073s/iter; left time: 3581.4129s\n",
      "599it [01:04,  9.51it/s]\titers: 600, epoch: 12 | loss: 0.1828732\n",
      "\tspeed: 0.1049s/iter; left time: 3490.4000s\n",
      "699it [01:15,  9.56it/s]\titers: 700, epoch: 12 | loss: 0.1864735\n",
      "\tspeed: 0.1098s/iter; left time: 3643.7965s\n",
      "798it [01:25,  9.60it/s]\titers: 800, epoch: 12 | loss: 0.2307299\n",
      "\tspeed: 0.1035s/iter; left time: 3425.3803s\n",
      "899it [01:36,  9.96it/s]\titers: 900, epoch: 12 | loss: 0.3113188\n",
      "\tspeed: 0.1079s/iter; left time: 3557.9079s\n",
      "999it [01:47,  9.80it/s]\titers: 1000, epoch: 12 | loss: 0.2383570\n",
      "\tspeed: 0.1044s/iter; left time: 3432.8477s\n",
      "1099it [01:58,  9.37it/s]\titers: 1100, epoch: 12 | loss: 0.1591633\n",
      "\tspeed: 0.1085s/iter; left time: 3557.9697s\n",
      "1199it [02:09,  9.30it/s]\titers: 1200, epoch: 12 | loss: 0.4656069\n",
      "\tspeed: 0.1119s/iter; left time: 3658.5057s\n",
      "1299it [02:20,  9.22it/s]\titers: 1300, epoch: 12 | loss: 0.1292953\n",
      "\tspeed: 0.1093s/iter; left time: 3560.7673s\n",
      "1399it [02:31,  8.59it/s]\titers: 1400, epoch: 12 | loss: 0.1644338\n",
      "\tspeed: 0.1138s/iter; left time: 3697.3480s\n",
      "1499it [02:42,  9.05it/s]\titers: 1500, epoch: 12 | loss: 0.3327014\n",
      "\tspeed: 0.1096s/iter; left time: 3550.5242s\n",
      "1599it [02:53,  8.96it/s]\titers: 1600, epoch: 12 | loss: 0.4618825\n",
      "\tspeed: 0.1117s/iter; left time: 3605.0499s\n",
      "1699it [03:04,  9.17it/s]\titers: 1700, epoch: 12 | loss: 0.2019073\n",
      "\tspeed: 0.1090s/iter; left time: 3509.3451s\n",
      "1798it [03:15,  9.45it/s]\titers: 1800, epoch: 12 | loss: 0.5016454\n",
      "\tspeed: 0.1125s/iter; left time: 3609.6365s\n",
      "1899it [03:26,  8.68it/s]\titers: 1900, epoch: 12 | loss: 0.1364064\n",
      "\tspeed: 0.1089s/iter; left time: 3484.3390s\n",
      "1999it [03:37,  9.32it/s]\titers: 2000, epoch: 12 | loss: 0.2250724\n",
      "\tspeed: 0.1112s/iter; left time: 3546.3642s\n",
      "2099it [03:48,  8.60it/s]\titers: 2100, epoch: 12 | loss: 0.1591920\n",
      "\tspeed: 0.1080s/iter; left time: 3433.0556s\n",
      "2199it [03:59,  9.33it/s]\titers: 2200, epoch: 12 | loss: 0.2809311\n",
      "\tspeed: 0.1082s/iter; left time: 3427.1437s\n",
      "2299it [04:10,  9.18it/s]\titers: 2300, epoch: 12 | loss: 0.1750271\n",
      "\tspeed: 0.1106s/iter; left time: 3493.2171s\n",
      "2399it [04:21,  9.14it/s]\titers: 2400, epoch: 12 | loss: 0.0954402\n",
      "\tspeed: 0.1066s/iter; left time: 3356.3451s\n",
      "2499it [04:32,  9.18it/s]\titers: 2500, epoch: 12 | loss: 0.1508003\n",
      "\tspeed: 0.1106s/iter; left time: 3472.5678s\n",
      "2599it [04:43,  9.14it/s]\titers: 2600, epoch: 12 | loss: 0.1688677\n",
      "\tspeed: 0.1077s/iter; left time: 3369.4372s\n",
      "2699it [04:54,  8.34it/s]\titers: 2700, epoch: 12 | loss: 0.3628941\n",
      "\tspeed: 0.1116s/iter; left time: 3480.0537s\n",
      "2799it [05:04,  9.30it/s]\titers: 2800, epoch: 12 | loss: 0.1929711\n",
      "\tspeed: 0.1074s/iter; left time: 3337.3173s\n",
      "2899it [05:16,  9.12it/s]\titers: 2900, epoch: 12 | loss: 0.1826122\n",
      "\tspeed: 0.1128s/iter; left time: 3496.1765s\n",
      "2999it [05:27,  8.81it/s]\titers: 3000, epoch: 12 | loss: 0.3986395\n",
      "\tspeed: 0.1085s/iter; left time: 3351.2216s\n",
      "3099it [05:38,  9.56it/s]\titers: 3100, epoch: 12 | loss: 0.3112746\n",
      "\tspeed: 0.1134s/iter; left time: 3489.6549s\n",
      "3199it [05:49,  9.35it/s]\titers: 3200, epoch: 12 | loss: 0.2156391\n",
      "\tspeed: 0.1109s/iter; left time: 3402.8943s\n",
      "3299it [06:00,  9.35it/s]\titers: 3300, epoch: 12 | loss: 0.2692370\n",
      "\tspeed: 0.1072s/iter; left time: 3279.1939s\n",
      "3399it [06:11,  9.42it/s]\titers: 3400, epoch: 12 | loss: 0.1785697\n",
      "\tspeed: 0.1096s/iter; left time: 3339.9097s\n",
      "3499it [06:22,  9.23it/s]\titers: 3500, epoch: 12 | loss: 0.2638203\n",
      "\tspeed: 0.1091s/iter; left time: 3314.3730s\n",
      "3599it [06:33,  9.32it/s]\titers: 3600, epoch: 12 | loss: 0.3289876\n",
      "\tspeed: 0.1122s/iter; left time: 3398.2805s\n",
      "3699it [06:43,  9.43it/s]\titers: 3700, epoch: 12 | loss: 0.2729000\n",
      "\tspeed: 0.1048s/iter; left time: 3162.8303s\n",
      "3765it [06:51,  9.16it/s]\n",
      "Epoch: 12 cost time: 411.1880190372467\n",
      "810it [00:39, 20.45it/s]\n",
      "807it [00:39, 20.66it/s]\n",
      "Epoch: 12 | Train Loss: 0.2337841 Vali Loss: 0.2808911 Test Loss: 0.3492676 MAE Loss: 0.3543388\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9531249999999998e-08\n",
      "98it [00:11,  9.47it/s]\titers: 100, epoch: 13 | loss: 0.3362105\n",
      "\tspeed: 0.9760s/iter; left time: 29300.1547s\n",
      "199it [00:22,  9.65it/s]\titers: 200, epoch: 13 | loss: 0.1477616\n",
      "\tspeed: 0.1111s/iter; left time: 3324.5997s\n",
      "299it [00:33,  9.69it/s]\titers: 300, epoch: 13 | loss: 0.1589456\n",
      "\tspeed: 0.1066s/iter; left time: 3178.4128s\n",
      "399it [00:44,  9.35it/s]\titers: 400, epoch: 13 | loss: 0.1681641\n",
      "\tspeed: 0.1111s/iter; left time: 3303.1864s\n",
      "499it [00:54,  9.33it/s]\titers: 500, epoch: 13 | loss: 0.2840580\n",
      "\tspeed: 0.1055s/iter; left time: 3125.8846s\n",
      "599it [01:06,  9.15it/s]\titers: 600, epoch: 13 | loss: 0.1988679\n",
      "\tspeed: 0.1129s/iter; left time: 3333.3480s\n",
      "698it [01:16,  9.26it/s]\titers: 700, epoch: 13 | loss: 0.1428153\n",
      "\tspeed: 0.1062s/iter; left time: 3124.4401s\n",
      "799it [01:27,  9.48it/s]\titers: 800, epoch: 13 | loss: 0.2407028\n",
      "\tspeed: 0.1062s/iter; left time: 3115.2895s\n",
      "899it [01:38,  9.95it/s]\titers: 900, epoch: 13 | loss: 0.2220701\n",
      "\tspeed: 0.1078s/iter; left time: 3149.3804s\n",
      "999it [01:48,  9.64it/s]\titers: 1000, epoch: 13 | loss: 0.2569728\n",
      "\tspeed: 0.1068s/iter; left time: 3108.8771s\n",
      "1099it [01:59,  9.62it/s]\titers: 1100, epoch: 13 | loss: 0.2117180\n",
      "\tspeed: 0.1082s/iter; left time: 3138.8706s\n",
      "1199it [02:10,  9.46it/s]\titers: 1200, epoch: 13 | loss: 0.2115802\n",
      "\tspeed: 0.1047s/iter; left time: 3029.1695s\n",
      "1299it [02:20,  9.66it/s]\titers: 1300, epoch: 13 | loss: 0.2062632\n",
      "\tspeed: 0.1074s/iter; left time: 3096.6749s\n",
      "1399it [02:31,  9.82it/s]\titers: 1400, epoch: 13 | loss: 0.2595464\n",
      "\tspeed: 0.1075s/iter; left time: 3087.3412s\n",
      "1499it [02:42,  9.68it/s]\titers: 1500, epoch: 13 | loss: 0.4534394\n",
      "\tspeed: 0.1121s/iter; left time: 3209.2824s\n",
      "1599it [02:53,  9.25it/s]\titers: 1600, epoch: 13 | loss: 0.1993464\n",
      "\tspeed: 0.1071s/iter; left time: 3054.8149s\n",
      "1699it [03:04,  9.17it/s]\titers: 1700, epoch: 13 | loss: 0.2447704\n",
      "\tspeed: 0.1099s/iter; left time: 3123.6623s\n",
      "1799it [03:15,  9.31it/s]\titers: 1800, epoch: 13 | loss: 0.1824096\n",
      "\tspeed: 0.1073s/iter; left time: 3038.8471s\n",
      "1899it [03:26,  9.39it/s]\titers: 1900, epoch: 13 | loss: 0.3147148\n",
      "\tspeed: 0.1087s/iter; left time: 3068.4556s\n",
      "1999it [03:36,  8.39it/s]\titers: 2000, epoch: 13 | loss: 0.1745521\n",
      "\tspeed: 0.1078s/iter; left time: 3031.4979s\n",
      "2099it [03:47,  9.49it/s]\titers: 2100, epoch: 13 | loss: 0.1882442\n",
      "\tspeed: 0.1062s/iter; left time: 2975.5280s\n",
      "2199it [03:58,  9.51it/s]\titers: 2200, epoch: 13 | loss: 0.2789165\n",
      "\tspeed: 0.1059s/iter; left time: 2956.1652s\n",
      "2299it [04:08,  9.64it/s]\titers: 2300, epoch: 13 | loss: 0.1682907\n",
      "\tspeed: 0.1045s/iter; left time: 2907.7091s\n",
      "2399it [04:19,  9.79it/s]\titers: 2400, epoch: 13 | loss: 0.2113981\n",
      "\tspeed: 0.1063s/iter; left time: 2945.7863s\n",
      "2499it [04:30,  9.21it/s]\titers: 2500, epoch: 13 | loss: 0.2018636\n",
      "\tspeed: 0.1079s/iter; left time: 2978.9841s\n",
      "2599it [04:40,  9.64it/s]\titers: 2600, epoch: 13 | loss: 0.2715619\n",
      "\tspeed: 0.1088s/iter; left time: 2994.2637s\n",
      "2699it [04:51,  9.38it/s]\titers: 2700, epoch: 13 | loss: 0.1428440\n",
      "\tspeed: 0.1034s/iter; left time: 2836.2552s\n",
      "2799it [05:02,  9.05it/s]\titers: 2800, epoch: 13 | loss: 0.2531872\n",
      "\tspeed: 0.1091s/iter; left time: 2980.7858s\n",
      "2899it [05:13,  8.96it/s]\titers: 2900, epoch: 13 | loss: 0.1315245\n",
      "\tspeed: 0.1092s/iter; left time: 2972.8619s\n",
      "2999it [05:23, 10.18it/s]\titers: 3000, epoch: 13 | loss: 0.2280157\n",
      "\tspeed: 0.1077s/iter; left time: 2920.1001s\n",
      "3099it [05:34,  9.47it/s]\titers: 3100, epoch: 13 | loss: 0.2598972\n",
      "\tspeed: 0.1038s/iter; left time: 2803.9943s\n",
      "3199it [05:44,  9.61it/s]\titers: 3200, epoch: 13 | loss: 0.1496727\n",
      "\tspeed: 0.1051s/iter; left time: 2828.6015s\n",
      "3299it [05:55,  8.90it/s]\titers: 3300, epoch: 13 | loss: 0.3098501\n",
      "\tspeed: 0.1122s/iter; left time: 3010.1053s\n",
      "3399it [06:06,  9.61it/s]\titers: 3400, epoch: 13 | loss: 0.1922676\n",
      "\tspeed: 0.1046s/iter; left time: 2795.1129s\n",
      "3499it [06:17,  9.61it/s]\titers: 3500, epoch: 13 | loss: 0.1808806\n",
      "\tspeed: 0.1090s/iter; left time: 2900.9773s\n",
      "3598it [06:27,  9.31it/s]\titers: 3600, epoch: 13 | loss: 0.2485105\n",
      "\tspeed: 0.1047s/iter; left time: 2777.4688s\n",
      "3699it [06:38,  9.46it/s]\titers: 3700, epoch: 13 | loss: 0.3037823\n",
      "\tspeed: 0.1080s/iter; left time: 2852.2894s\n",
      "3765it [06:45,  9.28it/s]\n",
      "Epoch: 13 cost time: 405.6518449783325\n",
      "810it [00:43, 18.80it/s]\n",
      "807it [00:51, 15.73it/s]\n",
      "Epoch: 13 | Train Loss: 0.2333985 Vali Loss: 0.2808090 Test Loss: 0.3491333 MAE Loss: 0.3541619\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.765624999999999e-09\n",
      "99it [00:13,  9.66it/s]\titers: 100, epoch: 14 | loss: 0.3863677\n",
      "\tspeed: 1.1532s/iter; left time: 30279.2464s\n",
      "199it [00:28,  3.94it/s]\titers: 200, epoch: 14 | loss: 0.1034165\n",
      "\tspeed: 0.1451s/iter; left time: 3795.6949s\n",
      "299it [00:42,  9.06it/s]\titers: 300, epoch: 14 | loss: 0.3730589\n",
      "\tspeed: 0.1400s/iter; left time: 3648.4481s\n",
      "399it [00:55,  4.13it/s]\titers: 400, epoch: 14 | loss: 0.1873746\n",
      "\tspeed: 0.1285s/iter; left time: 3335.6276s\n",
      "499it [01:09,  3.66it/s]\titers: 500, epoch: 14 | loss: 0.1666247\n",
      "\tspeed: 0.1417s/iter; left time: 3663.8050s\n",
      "599it [01:22,  4.89it/s]\titers: 600, epoch: 14 | loss: 0.3071131\n",
      "\tspeed: 0.1359s/iter; left time: 3499.6694s\n",
      "699it [01:36,  9.39it/s]\titers: 700, epoch: 14 | loss: 0.1818582\n",
      "\tspeed: 0.1342s/iter; left time: 3442.3860s\n",
      "799it [01:49,  9.73it/s]\titers: 800, epoch: 14 | loss: 0.1756371\n",
      "\tspeed: 0.1355s/iter; left time: 3463.8570s\n",
      "899it [02:03,  9.71it/s]\titers: 900, epoch: 14 | loss: 0.3430182\n",
      "\tspeed: 0.1358s/iter; left time: 3456.9154s\n",
      "998it [02:16,  9.67it/s]\titers: 1000, epoch: 14 | loss: 0.3203391\n",
      "\tspeed: 0.1359s/iter; left time: 3445.3859s\n",
      "1099it [02:30,  9.62it/s]\titers: 1100, epoch: 14 | loss: 0.3448130\n",
      "\tspeed: 0.1354s/iter; left time: 3420.1075s\n",
      "1199it [02:45,  6.00it/s]\titers: 1200, epoch: 14 | loss: 0.1542165\n",
      "\tspeed: 0.1512s/iter; left time: 3804.2230s\n",
      "1298it [02:59,  9.69it/s]\titers: 1300, epoch: 14 | loss: 0.1624537\n",
      "\tspeed: 0.1353s/iter; left time: 3390.8495s\n",
      "1399it [03:12,  9.50it/s]\titers: 1400, epoch: 14 | loss: 0.3461871\n",
      "\tspeed: 0.1350s/iter; left time: 3369.2321s\n",
      "1499it [03:26,  9.51it/s]\titers: 1500, epoch: 14 | loss: 0.1170795\n",
      "\tspeed: 0.1355s/iter; left time: 3366.9063s\n",
      "1599it [03:39,  7.01it/s]\titers: 1600, epoch: 14 | loss: 0.1710199\n",
      "\tspeed: 0.1347s/iter; left time: 3333.7117s\n",
      "1698it [03:53,  9.55it/s]\titers: 1700, epoch: 14 | loss: 0.1746632\n",
      "\tspeed: 0.1347s/iter; left time: 3321.3781s\n",
      "1799it [04:06,  7.11it/s]\titers: 1800, epoch: 14 | loss: 0.3030184\n",
      "\tspeed: 0.1377s/iter; left time: 3381.9123s\n",
      "1899it [04:20,  9.54it/s]\titers: 1900, epoch: 14 | loss: 0.1916448\n",
      "\tspeed: 0.1330s/iter; left time: 3252.3349s\n",
      "1998it [04:33,  9.57it/s]\titers: 2000, epoch: 14 | loss: 0.2229933\n",
      "\tspeed: 0.1354s/iter; left time: 3298.0918s\n",
      "2099it [04:47,  9.79it/s]\titers: 2100, epoch: 14 | loss: 0.4312854\n",
      "\tspeed: 0.1355s/iter; left time: 3285.8830s\n",
      "2199it [05:00,  9.65it/s]\titers: 2200, epoch: 14 | loss: 0.2023392\n",
      "\tspeed: 0.1351s/iter; left time: 3263.6609s\n",
      "2299it [05:14,  6.63it/s]\titers: 2300, epoch: 14 | loss: 0.1697642\n",
      "\tspeed: 0.1379s/iter; left time: 3318.3009s\n",
      "2399it [05:28,  5.12it/s]\titers: 2400, epoch: 14 | loss: 0.4923284\n",
      "\tspeed: 0.1380s/iter; left time: 3305.4953s\n",
      "2498it [05:41,  9.69it/s]\titers: 2500, epoch: 14 | loss: 0.2669123\n",
      "\tspeed: 0.1300s/iter; left time: 3100.2532s\n",
      "2599it [05:55,  9.65it/s]\titers: 2600, epoch: 14 | loss: 0.2077136\n",
      "\tspeed: 0.1353s/iter; left time: 3215.1306s\n",
      "2699it [06:08,  9.54it/s]\titers: 2700, epoch: 14 | loss: 0.2082514\n",
      "\tspeed: 0.1352s/iter; left time: 3198.3769s\n",
      "2799it [06:22,  9.62it/s]\titers: 2800, epoch: 14 | loss: 0.1641709\n",
      "\tspeed: 0.1351s/iter; left time: 3183.1441s\n",
      "2899it [06:37,  7.71it/s]\titers: 2900, epoch: 14 | loss: 0.2350979\n",
      "\tspeed: 0.1513s/iter; left time: 3548.8944s\n",
      "2999it [06:50,  6.73it/s]\titers: 3000, epoch: 14 | loss: 0.1336308\n",
      "\tspeed: 0.1358s/iter; left time: 3171.0746s\n",
      "3098it [07:04,  6.86it/s]\titers: 3100, epoch: 14 | loss: 0.3312708\n",
      "\tspeed: 0.1357s/iter; left time: 3155.8169s\n",
      "3199it [07:17,  9.67it/s]\titers: 3200, epoch: 14 | loss: 0.1275646\n",
      "\tspeed: 0.1353s/iter; left time: 3133.0079s\n",
      "3298it [07:31,  9.76it/s]\titers: 3300, epoch: 14 | loss: 0.1126211\n",
      "\tspeed: 0.1346s/iter; left time: 3104.2625s\n",
      "3399it [07:44,  9.68it/s]\titers: 3400, epoch: 14 | loss: 0.3241873\n",
      "\tspeed: 0.1352s/iter; left time: 3102.8873s\n",
      "3499it [07:58,  9.67it/s]\titers: 3500, epoch: 14 | loss: 0.2679831\n",
      "\tspeed: 0.1349s/iter; left time: 3082.8838s\n",
      "3599it [08:11,  8.71it/s]\titers: 3600, epoch: 14 | loss: 0.0938485\n",
      "\tspeed: 0.1357s/iter; left time: 3087.7131s\n",
      "3698it [08:25,  9.37it/s]\titers: 3700, epoch: 14 | loss: 0.2314561\n",
      "\tspeed: 0.1356s/iter; left time: 3073.2758s\n",
      "3765it [08:33,  7.33it/s]\n",
      "Epoch: 14 cost time: 513.9695999622345\n",
      "810it [00:50, 16.16it/s]\n",
      "807it [00:49, 16.15it/s]\n",
      "Epoch: 14 | Train Loss: 0.2333696 Vali Loss: 0.2807267 Test Loss: 0.3491375 MAE Loss: 0.3542327\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.8828124999999996e-09\n",
      "99it [00:13,  9.51it/s]\titers: 100, epoch: 15 | loss: 0.1975555\n",
      "\tspeed: 1.2253s/iter; left time: 27558.0101s\n",
      "199it [00:27,  9.78it/s]\titers: 200, epoch: 15 | loss: 0.4405577\n",
      "\tspeed: 0.1354s/iter; left time: 3030.7954s\n",
      "299it [00:40,  9.73it/s]\titers: 300, epoch: 15 | loss: 0.2479765\n",
      "\tspeed: 0.1347s/iter; left time: 3001.5713s\n",
      "399it [00:54,  9.65it/s]\titers: 400, epoch: 15 | loss: 0.2251632\n",
      "\tspeed: 0.1346s/iter; left time: 2986.8998s\n",
      "499it [01:07,  9.87it/s]\titers: 500, epoch: 15 | loss: 0.3850349\n",
      "\tspeed: 0.1348s/iter; left time: 2977.2059s\n",
      "599it [01:21,  9.63it/s]\titers: 600, epoch: 15 | loss: 0.1419098\n",
      "\tspeed: 0.1354s/iter; left time: 2976.9891s\n",
      "699it [01:34,  9.76it/s]\titers: 700, epoch: 15 | loss: 0.2665705\n",
      "\tspeed: 0.1351s/iter; left time: 2956.6515s\n",
      "798it [01:48,  9.72it/s]\titers: 800, epoch: 15 | loss: 0.2190610\n",
      "\tspeed: 0.1352s/iter; left time: 2945.2745s\n",
      "899it [02:01,  9.74it/s]\titers: 900, epoch: 15 | loss: 0.3130034\n",
      "\tspeed: 0.1357s/iter; left time: 2942.5844s\n",
      "999it [02:15,  9.64it/s]\titers: 1000, epoch: 15 | loss: 0.2516190\n",
      "\tspeed: 0.1353s/iter; left time: 2921.3778s\n",
      "1099it [02:29,  9.55it/s]\titers: 1100, epoch: 15 | loss: 0.2180743\n",
      "\tspeed: 0.1355s/iter; left time: 2911.1892s\n",
      "1199it [02:42,  9.73it/s]\titers: 1200, epoch: 15 | loss: 0.2685801\n",
      "\tspeed: 0.1356s/iter; left time: 2900.0863s\n",
      "1299it [02:56,  9.74it/s]\titers: 1300, epoch: 15 | loss: 0.1720230\n",
      "\tspeed: 0.1345s/iter; left time: 2863.4469s\n",
      "1399it [03:09,  9.41it/s]\titers: 1400, epoch: 15 | loss: 0.1908010\n",
      "\tspeed: 0.1362s/iter; left time: 2885.7574s\n",
      "1498it [03:23,  9.61it/s]\titers: 1500, epoch: 15 | loss: 0.3134522\n",
      "\tspeed: 0.1356s/iter; left time: 2860.3944s\n",
      "1599it [03:36,  9.73it/s]\titers: 1600, epoch: 15 | loss: 0.1826265\n",
      "\tspeed: 0.1344s/iter; left time: 2820.1739s\n",
      "1698it [03:50,  9.39it/s]\titers: 1700, epoch: 15 | loss: 0.1812316\n",
      "\tspeed: 0.1351s/iter; left time: 2822.0234s\n",
      "1798it [04:03,  6.17it/s]\titers: 1800, epoch: 15 | loss: 0.2817172\n",
      "\tspeed: 0.1373s/iter; left time: 2854.2767s\n",
      "1899it [04:17,  9.16it/s]\titers: 1900, epoch: 15 | loss: 0.3217671\n",
      "\tspeed: 0.1380s/iter; left time: 2855.0721s\n",
      "1999it [04:31,  9.48it/s]\titers: 2000, epoch: 15 | loss: 0.2408595\n",
      "\tspeed: 0.1371s/iter; left time: 2822.2509s\n",
      "2099it [04:45,  9.62it/s]\titers: 2100, epoch: 15 | loss: 0.2187961\n",
      "\tspeed: 0.1377s/iter; left time: 2820.7026s\n",
      "2199it [04:58,  9.67it/s]\titers: 2200, epoch: 15 | loss: 0.2327244\n",
      "\tspeed: 0.1372s/iter; left time: 2797.5762s\n",
      "2299it [05:12,  9.70it/s]\titers: 2300, epoch: 15 | loss: 0.1658186\n",
      "\tspeed: 0.1349s/iter; left time: 2736.3037s\n",
      "2399it [05:25,  9.77it/s]\titers: 2400, epoch: 15 | loss: 0.2931226\n",
      "\tspeed: 0.1349s/iter; left time: 2724.6072s\n",
      "2499it [05:39,  9.64it/s]\titers: 2500, epoch: 15 | loss: 0.3092394\n",
      "\tspeed: 0.1356s/iter; left time: 2723.9997s\n",
      "2599it [05:53,  6.70it/s]\titers: 2600, epoch: 15 | loss: 0.2860564\n",
      "\tspeed: 0.1390s/iter; left time: 2777.8900s\n",
      "2698it [06:06,  9.78it/s]\titers: 2700, epoch: 15 | loss: 0.1876989\n",
      "\tspeed: 0.1341s/iter; left time: 2667.5611s\n",
      "2799it [06:20,  9.75it/s]\titers: 2800, epoch: 15 | loss: 0.2462531\n",
      "\tspeed: 0.1353s/iter; left time: 2678.5323s\n",
      "2899it [06:33,  9.56it/s]\titers: 2900, epoch: 15 | loss: 0.3218998\n",
      "\tspeed: 0.1353s/iter; left time: 2663.6630s\n",
      "2999it [06:47,  9.45it/s]\titers: 3000, epoch: 15 | loss: 0.1877180\n",
      "\tspeed: 0.1389s/iter; left time: 2721.1926s\n",
      "3099it [07:01,  9.76it/s]\titers: 3100, epoch: 15 | loss: 0.2781151\n",
      "\tspeed: 0.1358s/iter; left time: 2647.5784s\n",
      "3199it [07:14,  9.12it/s]\titers: 3200, epoch: 15 | loss: 0.3083299\n",
      "\tspeed: 0.1354s/iter; left time: 2624.7191s\n",
      "3299it [07:28,  9.50it/s]\titers: 3300, epoch: 15 | loss: 0.1406376\n",
      "\tspeed: 0.1390s/iter; left time: 2681.1792s\n",
      "3399it [07:42,  9.48it/s]\titers: 3400, epoch: 15 | loss: 0.1498336\n",
      "\tspeed: 0.1383s/iter; left time: 2653.8699s\n",
      "3499it [07:56,  9.42it/s]\titers: 3500, epoch: 15 | loss: 0.1887756\n",
      "\tspeed: 0.1377s/iter; left time: 2629.0422s\n",
      "3599it [08:10,  9.41it/s]\titers: 3600, epoch: 15 | loss: 0.2406267\n",
      "\tspeed: 0.1382s/iter; left time: 2625.4771s\n",
      "3699it [08:23,  9.39it/s]\titers: 3700, epoch: 15 | loss: 0.1049828\n",
      "\tspeed: 0.1377s/iter; left time: 2601.2466s\n",
      "3765it [08:34,  7.32it/s]\n",
      "Epoch: 15 cost time: 514.0326642990112\n",
      "810it [00:48, 16.66it/s]\n",
      "807it [00:48, 16.71it/s]\n",
      "Epoch: 15 | Train Loss: 0.2335377 Vali Loss: 0.2807547 Test Loss: 0.3491512 MAE Loss: 0.3542560\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.4414062499999998e-09\n",
      "99it [00:13,  7.34it/s]\titers: 100, epoch: 16 | loss: 0.2052431\n",
      "\tspeed: 1.2101s/iter; left time: 22660.5528s\n",
      "199it [00:27, 10.03it/s]\titers: 200, epoch: 16 | loss: 0.1398610\n",
      "\tspeed: 0.1330s/iter; left time: 2477.8740s\n",
      "299it [00:40,  9.82it/s]\titers: 300, epoch: 16 | loss: 0.2716383\n",
      "\tspeed: 0.1358s/iter; left time: 2516.0479s\n",
      "399it [00:54,  9.88it/s]\titers: 400, epoch: 16 | loss: 0.1362100\n",
      "\tspeed: 0.1352s/iter; left time: 2490.5631s\n",
      "499it [01:07,  9.69it/s]\titers: 500, epoch: 16 | loss: 0.1250075\n",
      "\tspeed: 0.1346s/iter; left time: 2466.0865s\n",
      "599it [01:21,  9.19it/s]\titers: 600, epoch: 16 | loss: 0.3821145\n",
      "\tspeed: 0.1364s/iter; left time: 2486.5961s\n",
      "699it [01:35,  4.71it/s]\titers: 700, epoch: 16 | loss: 0.1484954\n",
      "\tspeed: 0.1476s/iter; left time: 2676.0752s\n",
      "799it [01:50,  3.86it/s]\titers: 800, epoch: 16 | loss: 0.2339084\n",
      "\tspeed: 0.1437s/iter; left time: 2590.1252s\n",
      "899it [02:02,  8.97it/s]\titers: 900, epoch: 16 | loss: 0.2846689\n",
      "\tspeed: 0.1240s/iter; left time: 2222.8790s\n",
      "998it [02:16,  9.64it/s]\titers: 1000, epoch: 16 | loss: 0.2870998\n",
      "\tspeed: 0.1344s/iter; left time: 2396.0349s\n",
      "1099it [02:29,  9.80it/s]\titers: 1100, epoch: 16 | loss: 0.1882836\n",
      "\tspeed: 0.1344s/iter; left time: 2381.8871s\n",
      "1199it [02:43,  9.60it/s]\titers: 1200, epoch: 16 | loss: 0.4896719\n",
      "\tspeed: 0.1348s/iter; left time: 2376.3598s\n",
      "1299it [02:56,  8.54it/s]\titers: 1300, epoch: 16 | loss: 0.1874782\n",
      "\tspeed: 0.1374s/iter; left time: 2407.9122s\n",
      "1399it [03:11,  3.97it/s]\titers: 1400, epoch: 16 | loss: 0.2069475\n",
      "\tspeed: 0.1452s/iter; left time: 2530.7711s\n",
      "1499it [03:23,  9.02it/s]\titers: 1500, epoch: 16 | loss: 0.1760991\n",
      "\tspeed: 0.1243s/iter; left time: 2153.3870s\n",
      "1599it [03:37,  9.34it/s]\titers: 1600, epoch: 16 | loss: 0.3296472\n",
      "\tspeed: 0.1337s/iter; left time: 2303.6156s\n",
      "1699it [03:51,  9.72it/s]\titers: 1700, epoch: 16 | loss: 0.1719277\n",
      "\tspeed: 0.1397s/iter; left time: 2392.4259s\n",
      "1799it [04:04,  9.75it/s]\titers: 1800, epoch: 16 | loss: 0.1191543\n",
      "\tspeed: 0.1356s/iter; left time: 2308.0709s\n",
      "1899it [04:18,  9.79it/s]\titers: 1900, epoch: 16 | loss: 0.1440190\n",
      "\tspeed: 0.1353s/iter; left time: 2289.9408s\n",
      "1999it [04:31,  9.89it/s]\titers: 2000, epoch: 16 | loss: 0.1751920\n",
      "\tspeed: 0.1348s/iter; left time: 2267.9932s\n",
      "2098it [04:45,  9.81it/s]\titers: 2100, epoch: 16 | loss: 0.1687019\n",
      "\tspeed: 0.1356s/iter; left time: 2268.6394s\n",
      "2198it [04:58,  6.33it/s]\titers: 2200, epoch: 16 | loss: 0.1841564\n",
      "\tspeed: 0.1353s/iter; left time: 2250.0900s\n",
      "2299it [05:12,  9.28it/s]\titers: 2300, epoch: 16 | loss: 0.2242603\n",
      "\tspeed: 0.1378s/iter; left time: 2277.9856s\n",
      "2399it [05:26,  7.91it/s]\titers: 2400, epoch: 16 | loss: 0.1329996\n",
      "\tspeed: 0.1363s/iter; left time: 2238.2521s\n",
      "2499it [05:39,  9.08it/s]\titers: 2500, epoch: 16 | loss: 0.2083606\n",
      "\tspeed: 0.1354s/iter; left time: 2211.1553s\n",
      "2599it [05:53,  9.57it/s]\titers: 2600, epoch: 16 | loss: 0.1550801\n",
      "\tspeed: 0.1352s/iter; left time: 2194.3410s\n",
      "2699it [06:06,  6.55it/s]\titers: 2700, epoch: 16 | loss: 0.2257742\n",
      "\tspeed: 0.1363s/iter; left time: 2197.9111s\n",
      "2799it [06:18,  6.91it/s]\titers: 2800, epoch: 16 | loss: 0.2924374\n",
      "\tspeed: 0.1203s/iter; left time: 1927.5931s\n",
      "2899it [06:33,  4.52it/s]\titers: 2900, epoch: 16 | loss: 0.2393765\n",
      "\tspeed: 0.1487s/iter; left time: 2367.8732s\n",
      "2999it [06:46,  5.05it/s]\titers: 3000, epoch: 16 | loss: 0.1276661\n",
      "\tspeed: 0.1251s/iter; left time: 1979.7278s\n",
      "3099it [07:00,  4.56it/s]\titers: 3100, epoch: 16 | loss: 0.2254440\n",
      "\tspeed: 0.1447s/iter; left time: 2275.0899s\n",
      "3199it [07:12, 10.09it/s]\titers: 3200, epoch: 16 | loss: 0.1343989\n",
      "\tspeed: 0.1191s/iter; left time: 1860.7809s\n",
      "3299it [07:26,  9.59it/s]\titers: 3300, epoch: 16 | loss: 0.4312514\n",
      "\tspeed: 0.1364s/iter; left time: 2117.9060s\n",
      "3399it [07:39,  9.62it/s]\titers: 3400, epoch: 16 | loss: 0.3534585\n",
      "\tspeed: 0.1348s/iter; left time: 2079.8800s\n",
      "3499it [07:53,  9.83it/s]\titers: 3500, epoch: 16 | loss: 0.3077425\n",
      "\tspeed: 0.1351s/iter; left time: 2071.2471s\n",
      "3599it [08:06,  9.45it/s]\titers: 3600, epoch: 16 | loss: 0.1545011\n",
      "\tspeed: 0.1358s/iter; left time: 2068.1232s\n",
      "3699it [08:20,  9.78it/s]\titers: 3700, epoch: 16 | loss: 0.4054082\n",
      "\tspeed: 0.1354s/iter; left time: 2048.3328s\n",
      "3765it [08:28,  7.40it/s]\n",
      "Epoch: 16 cost time: 508.87806272506714\n",
      "810it [00:50, 16.13it/s]\n",
      "807it [00:49, 16.25it/s]\n",
      "Epoch: 16 | Train Loss: 0.2334517 Vali Loss: 0.2807871 Test Loss: 0.3491733 MAE Loss: 0.3542686\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2207031249999999e-09\n",
      "99it [00:13,  9.81it/s]\titers: 100, epoch: 17 | loss: 0.1608212\n",
      "\tspeed: 1.2217s/iter; left time: 18278.1997s\n",
      "199it [00:27,  9.74it/s]\titers: 200, epoch: 17 | loss: 0.2550369\n",
      "\tspeed: 0.1352s/iter; left time: 2009.1105s\n",
      "299it [00:40,  9.55it/s]\titers: 300, epoch: 17 | loss: 0.1719689\n",
      "\tspeed: 0.1354s/iter; left time: 1998.2270s\n",
      "399it [00:54,  8.80it/s]\titers: 400, epoch: 17 | loss: 0.1944816\n",
      "\tspeed: 0.1349s/iter; left time: 1977.5843s\n",
      "499it [01:06,  5.77it/s]\titers: 500, epoch: 17 | loss: 0.2919102\n",
      "\tspeed: 0.1219s/iter; left time: 1774.3476s\n",
      "599it [01:21,  9.42it/s]\titers: 600, epoch: 17 | loss: 0.1946203\n",
      "\tspeed: 0.1470s/iter; left time: 2126.4269s\n",
      "699it [01:34,  8.15it/s]\titers: 700, epoch: 17 | loss: 0.3219073\n",
      "\tspeed: 0.1361s/iter; left time: 1953.8758s\n",
      "798it [01:48,  9.45it/s]\titers: 800, epoch: 17 | loss: 0.2349289\n",
      "\tspeed: 0.1351s/iter; left time: 1925.9545s\n",
      "899it [02:01,  8.00it/s]\titers: 900, epoch: 17 | loss: 0.4002778\n",
      "\tspeed: 0.1357s/iter; left time: 1922.2242s\n",
      "999it [02:13,  9.73it/s]\titers: 1000, epoch: 17 | loss: 0.2985493\n",
      "\tspeed: 0.1195s/iter; left time: 1679.9261s\n",
      "1099it [02:28,  6.95it/s]\titers: 1100, epoch: 17 | loss: 0.3871070\n",
      "\tspeed: 0.1510s/iter; left time: 2107.8553s\n",
      "1199it [02:42,  3.84it/s]\titers: 1200, epoch: 17 | loss: 0.2572240\n",
      "\tspeed: 0.1348s/iter; left time: 1867.9419s\n",
      "1299it [02:56,  5.64it/s]\titers: 1300, epoch: 17 | loss: 0.2535135\n",
      "\tspeed: 0.1357s/iter; left time: 1866.8248s\n",
      "1399it [03:09,  7.62it/s]\titers: 1400, epoch: 17 | loss: 0.2375524\n",
      "\tspeed: 0.1350s/iter; left time: 1843.9154s\n",
      "1499it [03:22,  4.28it/s]\titers: 1500, epoch: 17 | loss: 0.2001255\n",
      "\tspeed: 0.1273s/iter; left time: 1725.6899s\n",
      "1599it [03:34,  9.70it/s]\titers: 1600, epoch: 17 | loss: 0.2111700\n",
      "\tspeed: 0.1262s/iter; left time: 1698.4306s\n",
      "1699it [03:49,  4.27it/s]\titers: 1700, epoch: 17 | loss: 0.1585602\n",
      "\tspeed: 0.1511s/iter; left time: 2018.1972s\n",
      "1799it [04:02,  4.57it/s]\titers: 1800, epoch: 17 | loss: 0.2108273\n",
      "\tspeed: 0.1261s/iter; left time: 1672.2431s\n",
      "1899it [04:17,  6.63it/s]\titers: 1900, epoch: 17 | loss: 0.1510955\n",
      "\tspeed: 0.1449s/iter; left time: 1906.7937s\n",
      "1999it [04:29,  6.09it/s]\titers: 2000, epoch: 17 | loss: 0.2025328\n",
      "\tspeed: 0.1224s/iter; left time: 1598.7982s\n",
      "2099it [04:42,  9.88it/s]\titers: 2100, epoch: 17 | loss: 0.1961629\n",
      "\tspeed: 0.1323s/iter; left time: 1715.2052s\n",
      "2199it [04:57,  3.81it/s]\titers: 2200, epoch: 17 | loss: 0.4592136\n",
      "\tspeed: 0.1504s/iter; left time: 1934.8702s\n",
      "2298it [05:09,  9.75it/s]\titers: 2300, epoch: 17 | loss: 0.4834341\n",
      "\tspeed: 0.1192s/iter; left time: 1520.5181s\n",
      "2399it [05:23,  9.84it/s]\titers: 2400, epoch: 17 | loss: 0.2778184\n",
      "\tspeed: 0.1355s/iter; left time: 1716.0941s\n",
      "2498it [05:36,  9.82it/s]\titers: 2500, epoch: 17 | loss: 0.1481767\n",
      "\tspeed: 0.1353s/iter; left time: 1699.5720s\n",
      "2599it [05:50,  9.57it/s]\titers: 2600, epoch: 17 | loss: 0.1716279\n",
      "\tspeed: 0.1347s/iter; left time: 1679.0167s\n",
      "2699it [06:03,  9.58it/s]\titers: 2700, epoch: 17 | loss: 0.1564758\n",
      "\tspeed: 0.1338s/iter; left time: 1653.4616s\n",
      "2799it [06:16,  9.78it/s]\titers: 2800, epoch: 17 | loss: 0.1929457\n",
      "\tspeed: 0.1349s/iter; left time: 1654.5342s\n",
      "2899it [06:30,  9.82it/s]\titers: 2900, epoch: 17 | loss: 0.1140169\n",
      "\tspeed: 0.1352s/iter; left time: 1643.5850s\n",
      "2999it [06:44,  9.83it/s]\titers: 3000, epoch: 17 | loss: 0.3556680\n",
      "\tspeed: 0.1354s/iter; left time: 1633.6300s\n",
      "3099it [06:57,  9.79it/s]\titers: 3100, epoch: 17 | loss: 0.1539478\n",
      "\tspeed: 0.1345s/iter; left time: 1608.8967s\n",
      "3198it [07:10,  9.66it/s]\titers: 3200, epoch: 17 | loss: 0.3540530\n",
      "\tspeed: 0.1352s/iter; left time: 1603.9134s\n",
      "3299it [07:24,  9.41it/s]\titers: 3300, epoch: 17 | loss: 0.3375691\n",
      "\tspeed: 0.1343s/iter; left time: 1579.3432s\n",
      "3399it [07:37,  9.61it/s]\titers: 3400, epoch: 17 | loss: 0.2333136\n",
      "\tspeed: 0.1355s/iter; left time: 1579.8022s\n",
      "3498it [07:51,  9.67it/s]\titers: 3500, epoch: 17 | loss: 0.2489024\n",
      "\tspeed: 0.1360s/iter; left time: 1571.9402s\n",
      "3599it [08:05,  9.98it/s]\titers: 3600, epoch: 17 | loss: 0.5496481\n",
      "\tspeed: 0.1356s/iter; left time: 1554.3997s\n",
      "3699it [08:18,  9.79it/s]\titers: 3700, epoch: 17 | loss: 0.2607773\n",
      "\tspeed: 0.1343s/iter; left time: 1525.5402s\n",
      "3765it [08:26,  7.43it/s]\n",
      "Epoch: 17 cost time: 506.9613764286041\n",
      "810it [00:51, 15.66it/s]\n",
      "807it [00:49, 16.21it/s]\n",
      "Epoch: 17 | Train Loss: 0.2337719 Vali Loss: 0.2808656 Test Loss: 0.3491645 MAE Loss: 0.3542609\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Total time: 146.53452744086584 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --num_machines=1 --dynamo_backend \"no\" --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 89115\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 1024\n",
      "[2024-05-03 23:16:03,402] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 23:16:04,246] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-03 23:16:04,246] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 23:16:04,246] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-03 23:16:05,159] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.44, master_port=29500\n",
      "[2024-05-03 23:16:05,159] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-03 23:16:06,308] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 23:16:06,309] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 23:16:06,309] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 23:16:06,311] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 23:16:06,311] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 23:16:06,311] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 23:16:06,311] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 23:16:06,311] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 23:16:06,311] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 23:16:06,311] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-03 23:16:06,568] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 23:16:06,569] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.09 GB         CA 1.13 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:16:06,569] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 209.92 GB, percent = 27.8%\n",
      "[2024-05-03 23:16:06,875] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 23:16:06,875] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 1.19 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:16:06,875] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 210.56 GB, percent = 27.9%\n",
      "[2024-05-03 23:16:06,875] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 23:16:06,990] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 23:16:06,991] [INFO] [utils.py:801:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.33 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:16:06,991] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 210.8 GB, percent = 27.9%\n",
      "[2024-05-03 23:16:06,991] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 23:16:06,991] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 23:16:06,991] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 23:16:06,991] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 23:16:06,992] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2b91a64410>\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 23:16:06,993] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 23:16:06,994] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:14,  7.90it/s]\titers: 100, epoch: 1 | loss: 0.9641595\n",
      "\tspeed: 0.1901s/iter; left time: 14096.9636s\n",
      "199it [00:28,  7.61it/s]\titers: 200, epoch: 1 | loss: 0.5187201\n",
      "\tspeed: 0.1342s/iter; left time: 9941.6416s\n",
      "299it [00:41,  7.69it/s]\titers: 300, epoch: 1 | loss: 0.4029001\n",
      "\tspeed: 0.1327s/iter; left time: 9815.0356s\n",
      "399it [00:54,  6.88it/s]\titers: 400, epoch: 1 | loss: 0.2808163\n",
      "\tspeed: 0.1322s/iter; left time: 9761.5748s\n",
      "499it [01:08,  7.58it/s]\titers: 500, epoch: 1 | loss: 0.1841253\n",
      "\tspeed: 0.1341s/iter; left time: 9890.6729s\n",
      "599it [01:21,  7.18it/s]\titers: 600, epoch: 1 | loss: 0.2845896\n",
      "\tspeed: 0.1355s/iter; left time: 9980.9429s\n",
      "699it [01:35,  7.15it/s]\titers: 700, epoch: 1 | loss: 0.3291208\n",
      "\tspeed: 0.1328s/iter; left time: 9766.7432s\n",
      "799it [01:48,  7.52it/s]\titers: 800, epoch: 1 | loss: 0.2157963\n",
      "\tspeed: 0.1338s/iter; left time: 9826.3813s\n",
      "899it [02:02,  7.14it/s]\titers: 900, epoch: 1 | loss: 0.3774287\n",
      "\tspeed: 0.1377s/iter; left time: 10098.9919s\n",
      "999it [02:15,  6.42it/s]\titers: 1000, epoch: 1 | loss: 0.2994530\n",
      "\tspeed: 0.1348s/iter; left time: 9878.4683s\n",
      "1099it [02:29,  7.42it/s]\titers: 1100, epoch: 1 | loss: 0.2394145\n",
      "\tspeed: 0.1343s/iter; left time: 9823.6066s\n",
      "1199it [02:42,  7.54it/s]\titers: 1200, epoch: 1 | loss: 0.2472853\n",
      "\tspeed: 0.1367s/iter; left time: 9989.1850s\n",
      "1299it [02:56,  7.48it/s]\titers: 1300, epoch: 1 | loss: 0.2571820\n",
      "\tspeed: 0.1353s/iter; left time: 9869.7256s\n",
      "1399it [03:09,  7.13it/s]\titers: 1400, epoch: 1 | loss: 0.2126374\n",
      "\tspeed: 0.1330s/iter; left time: 9688.5399s\n",
      "1499it [03:22,  7.56it/s]\titers: 1500, epoch: 1 | loss: 0.2242659\n",
      "\tspeed: 0.1323s/iter; left time: 9623.3073s\n",
      "1599it [03:36,  7.51it/s]\titers: 1600, epoch: 1 | loss: 0.3551038\n",
      "\tspeed: 0.1342s/iter; left time: 9754.2883s\n",
      "1699it [03:49,  7.33it/s]\titers: 1700, epoch: 1 | loss: 0.2962065\n",
      "\tspeed: 0.1332s/iter; left time: 9662.3525s\n",
      "1799it [04:02,  7.54it/s]\titers: 1800, epoch: 1 | loss: 0.3189642\n",
      "\tspeed: 0.1326s/iter; left time: 9606.1630s\n",
      "1899it [04:16,  7.62it/s]\titers: 1900, epoch: 1 | loss: 0.2609983\n",
      "\tspeed: 0.1335s/iter; left time: 9662.1350s\n",
      "1999it [04:29,  7.56it/s]\titers: 2000, epoch: 1 | loss: 0.3362970\n",
      "\tspeed: 0.1359s/iter; left time: 9823.6383s\n",
      "2099it [04:42,  7.63it/s]\titers: 2100, epoch: 1 | loss: 0.1997824\n",
      "\tspeed: 0.1317s/iter; left time: 9505.2096s\n",
      "2199it [04:56,  7.63it/s]\titers: 2200, epoch: 1 | loss: 0.2255914\n",
      "\tspeed: 0.1364s/iter; left time: 9832.5489s\n",
      "2299it [05:10,  7.73it/s]\titers: 2300, epoch: 1 | loss: 0.3413877\n",
      "\tspeed: 0.1358s/iter; left time: 9769.7333s\n",
      "2399it [05:23,  7.59it/s]\titers: 2400, epoch: 1 | loss: 0.2875497\n",
      "\tspeed: 0.1342s/iter; left time: 9640.8782s\n",
      "2499it [05:36,  7.62it/s]\titers: 2500, epoch: 1 | loss: 0.3320526\n",
      "\tspeed: 0.1317s/iter; left time: 9448.9760s\n",
      "2599it [05:50,  7.46it/s]\titers: 2600, epoch: 1 | loss: 0.1992021\n",
      "\tspeed: 0.1361s/iter; left time: 9754.5541s\n",
      "2699it [06:03,  7.74it/s]\titers: 2700, epoch: 1 | loss: 0.2342773\n",
      "\tspeed: 0.1354s/iter; left time: 9692.0353s\n",
      "2799it [06:17,  7.51it/s]\titers: 2800, epoch: 1 | loss: 0.1815586\n",
      "\tspeed: 0.1335s/iter; left time: 9537.4159s\n",
      "2899it [06:30,  7.63it/s]\titers: 2900, epoch: 1 | loss: 0.2151070\n",
      "\tspeed: 0.1326s/iter; left time: 9462.8863s\n",
      "2999it [06:44,  7.66it/s]\titers: 3000, epoch: 1 | loss: 0.2274868\n",
      "\tspeed: 0.1358s/iter; left time: 9680.2054s\n",
      "3099it [06:57,  6.48it/s]\titers: 3100, epoch: 1 | loss: 0.1735005\n",
      "\tspeed: 0.1362s/iter; left time: 9692.7038s\n",
      "3199it [07:10,  7.65it/s]\titers: 3200, epoch: 1 | loss: 0.1491423\n",
      "\tspeed: 0.1303s/iter; left time: 9260.9430s\n",
      "3299it [07:24,  7.32it/s]\titers: 3300, epoch: 1 | loss: 0.2412028\n",
      "\tspeed: 0.1351s/iter; left time: 9587.4681s\n",
      "3399it [07:37,  7.14it/s]\titers: 3400, epoch: 1 | loss: 0.3968665\n",
      "\tspeed: 0.1354s/iter; left time: 9594.9798s\n",
      "3499it [07:51,  7.65it/s]\titers: 3500, epoch: 1 | loss: 0.2387104\n",
      "\tspeed: 0.1334s/iter; left time: 9437.6668s\n",
      "3599it [08:04,  7.23it/s]\titers: 3600, epoch: 1 | loss: 0.2146533\n",
      "\tspeed: 0.1349s/iter; left time: 9535.3530s\n",
      "3699it [08:18,  7.44it/s]\titers: 3700, epoch: 1 | loss: 0.1906886\n",
      "\tspeed: 0.1360s/iter; left time: 9596.9117s\n",
      "3713it [08:20,  7.42it/s]\n",
      "Epoch: 1 cost time: 500.14733815193176\n",
      "810it [00:51, 15.65it/s]\n",
      "807it [00:51, 15.62it/s]\n",
      "Epoch: 1 | Train Loss: 0.2935759 Vali Loss: 0.3151243 Test Loss: 0.3966921 MAE Loss: 0.4009331\n",
      "lr = 0.0000400000\n",
      "Updating learning rate to 3.9999999999999996e-05\n",
      "99it [00:13,  7.67it/s]\titers: 100, epoch: 2 | loss: 0.2668546\n",
      "\tspeed: 1.2391s/iter; left time: 87289.6703s\n",
      "199it [00:26,  7.42it/s]\titers: 200, epoch: 2 | loss: 0.3243296\n",
      "\tspeed: 0.1322s/iter; left time: 9302.8708s\n",
      "299it [00:39,  7.56it/s]\titers: 300, epoch: 2 | loss: 0.2878442\n",
      "\tspeed: 0.1302s/iter; left time: 9144.6476s\n",
      "399it [00:53,  7.79it/s]\titers: 400, epoch: 2 | loss: 0.3907331\n",
      "\tspeed: 0.1324s/iter; left time: 9289.5052s\n",
      "499it [01:06,  7.84it/s]\titers: 500, epoch: 2 | loss: 0.2069688\n",
      "\tspeed: 0.1343s/iter; left time: 9407.2661s\n",
      "599it [01:19,  7.29it/s]\titers: 600, epoch: 2 | loss: 0.2945153\n",
      "\tspeed: 0.1307s/iter; left time: 9141.1951s\n",
      "699it [01:32,  7.60it/s]\titers: 700, epoch: 2 | loss: 0.2082459\n",
      "\tspeed: 0.1323s/iter; left time: 9238.9507s\n",
      "799it [01:46,  7.98it/s]\titers: 800, epoch: 2 | loss: 0.3093166\n",
      "\tspeed: 0.1330s/iter; left time: 9275.4029s\n",
      "899it [01:59,  7.73it/s]\titers: 900, epoch: 2 | loss: 0.1970092\n",
      "\tspeed: 0.1301s/iter; left time: 9061.1613s\n",
      "999it [02:12,  7.67it/s]\titers: 1000, epoch: 2 | loss: 0.3330566\n",
      "\tspeed: 0.1288s/iter; left time: 8957.2229s\n",
      "1099it [02:25,  7.75it/s]\titers: 1100, epoch: 2 | loss: 0.1897289\n",
      "\tspeed: 0.1330s/iter; left time: 9237.5728s\n",
      "1199it [02:38,  7.76it/s]\titers: 1200, epoch: 2 | loss: 0.4427165\n",
      "\tspeed: 0.1298s/iter; left time: 8999.9445s\n",
      "1299it [02:51,  7.72it/s]\titers: 1300, epoch: 2 | loss: 0.2237228\n",
      "\tspeed: 0.1300s/iter; left time: 9004.1973s\n",
      "1399it [03:04,  7.71it/s]\titers: 1400, epoch: 2 | loss: 0.1716717\n",
      "\tspeed: 0.1315s/iter; left time: 9094.9401s\n",
      "1499it [03:17,  7.72it/s]\titers: 1500, epoch: 2 | loss: 0.5217724\n",
      "\tspeed: 0.1303s/iter; left time: 8995.5274s\n",
      "1599it [03:30,  7.86it/s]\titers: 1600, epoch: 2 | loss: 0.2182254\n",
      "\tspeed: 0.1283s/iter; left time: 8847.8451s\n",
      "1699it [03:43,  8.01it/s]\titers: 1700, epoch: 2 | loss: 0.2576517\n",
      "\tspeed: 0.1322s/iter; left time: 9102.7865s\n",
      "1799it [03:56,  7.45it/s]\titers: 1800, epoch: 2 | loss: 0.1207245\n",
      "\tspeed: 0.1297s/iter; left time: 8914.8277s\n",
      "1899it [04:09,  7.73it/s]\titers: 1900, epoch: 2 | loss: 0.2838496\n",
      "\tspeed: 0.1308s/iter; left time: 8978.4981s\n",
      "1999it [04:22,  7.83it/s]\titers: 2000, epoch: 2 | loss: 0.2352560\n",
      "\tspeed: 0.1326s/iter; left time: 9089.6573s\n",
      "2099it [04:35,  7.77it/s]\titers: 2100, epoch: 2 | loss: 0.2004760\n",
      "\tspeed: 0.1296s/iter; left time: 8874.0426s\n",
      "2199it [04:48,  7.98it/s]\titers: 2200, epoch: 2 | loss: 0.3143178\n",
      "\tspeed: 0.1290s/iter; left time: 8817.1081s\n",
      "2299it [05:02,  7.93it/s]\titers: 2300, epoch: 2 | loss: 0.2416739\n",
      "\tspeed: 0.1338s/iter; left time: 9128.8448s\n",
      "2399it [05:15,  7.74it/s]\titers: 2400, epoch: 2 | loss: 0.4222754\n",
      "\tspeed: 0.1310s/iter; left time: 8929.5252s\n",
      "2499it [05:28,  7.69it/s]\titers: 2500, epoch: 2 | loss: 0.1435327\n",
      "\tspeed: 0.1305s/iter; left time: 8878.6645s\n",
      "2599it [05:41,  7.63it/s]\titers: 2600, epoch: 2 | loss: 0.2831287\n",
      "\tspeed: 0.1341s/iter; left time: 9110.4733s\n",
      "2699it [05:55,  7.34it/s]\titers: 2700, epoch: 2 | loss: 0.2098521\n",
      "\tspeed: 0.1337s/iter; left time: 9068.2377s\n",
      "2799it [06:08,  7.65it/s]\titers: 2800, epoch: 2 | loss: 0.2984158\n",
      "\tspeed: 0.1311s/iter; left time: 8883.9049s\n",
      "2899it [06:21,  7.83it/s]\titers: 2900, epoch: 2 | loss: 0.2197979\n",
      "\tspeed: 0.1353s/iter; left time: 9153.0203s\n",
      "2999it [06:35,  6.34it/s]\titers: 3000, epoch: 2 | loss: 0.1694328\n",
      "\tspeed: 0.1346s/iter; left time: 9090.2800s\n",
      "3099it [06:48,  7.80it/s]\titers: 3100, epoch: 2 | loss: 0.2197636\n",
      "\tspeed: 0.1301s/iter; left time: 8772.4604s\n",
      "3199it [07:01,  7.44it/s]\titers: 3200, epoch: 2 | loss: 0.2478591\n",
      "\tspeed: 0.1330s/iter; left time: 8957.9047s\n",
      "3299it [07:14,  6.86it/s]\titers: 3300, epoch: 2 | loss: 0.1612138\n",
      "\tspeed: 0.1338s/iter; left time: 8996.9980s\n",
      "3399it [07:28,  7.68it/s]\titers: 3400, epoch: 2 | loss: 0.1399053\n",
      "\tspeed: 0.1316s/iter; left time: 8838.2709s\n",
      "3499it [07:41,  7.69it/s]\titers: 3500, epoch: 2 | loss: 0.1988449\n",
      "\tspeed: 0.1349s/iter; left time: 9042.2084s\n",
      "3599it [07:54,  7.79it/s]\titers: 3600, epoch: 2 | loss: 0.1694340\n",
      "\tspeed: 0.1325s/iter; left time: 8872.4572s\n",
      "3699it [08:07,  7.64it/s]\titers: 3700, epoch: 2 | loss: 0.1109314\n",
      "\tspeed: 0.1295s/iter; left time: 8658.8483s\n",
      "3713it [08:09,  7.58it/s]\n",
      "Epoch: 2 cost time: 489.6390595436096\n",
      "810it [00:48, 16.55it/s]\n",
      "807it [00:48, 16.60it/s]\n",
      "Epoch: 2 | Train Loss: 0.2395417 Vali Loss: 0.2934191 Test Loss: 0.3401946 MAE Loss: 0.3558949\n",
      "Updating learning rate to 1.9999999999999998e-05\n",
      "99it [00:13,  7.76it/s]\titers: 100, epoch: 3 | loss: 0.2172087\n",
      "\tspeed: 1.1628s/iter; left time: 77599.2643s\n",
      "199it [00:26,  7.82it/s]\titers: 200, epoch: 3 | loss: 0.1346914\n",
      "\tspeed: 0.1311s/iter; left time: 8732.9475s\n",
      "299it [00:39,  7.66it/s]\titers: 300, epoch: 3 | loss: 0.2193775\n",
      "\tspeed: 0.1307s/iter; left time: 8693.5844s\n",
      "399it [00:52,  7.76it/s]\titers: 400, epoch: 3 | loss: 0.4463703\n",
      "\tspeed: 0.1304s/iter; left time: 8660.1707s\n",
      "499it [01:05,  7.78it/s]\titers: 500, epoch: 3 | loss: 0.1829557\n",
      "\tspeed: 0.1334s/iter; left time: 8849.0088s\n",
      "599it [01:18,  7.71it/s]\titers: 600, epoch: 3 | loss: 0.2435770\n",
      "\tspeed: 0.1295s/iter; left time: 8577.6722s\n",
      "699it [01:31,  7.80it/s]\titers: 700, epoch: 3 | loss: 0.2425336\n",
      "\tspeed: 0.1303s/iter; left time: 8617.8318s\n",
      "799it [01:44,  7.85it/s]\titers: 800, epoch: 3 | loss: 0.4156528\n",
      "\tspeed: 0.1299s/iter; left time: 8580.8410s\n",
      "899it [01:57,  7.72it/s]\titers: 900, epoch: 3 | loss: 0.4306667\n",
      "\tspeed: 0.1289s/iter; left time: 8500.6631s\n",
      "999it [02:10,  7.85it/s]\titers: 1000, epoch: 3 | loss: 0.2407355\n",
      "\tspeed: 0.1288s/iter; left time: 8479.3888s\n",
      "1099it [02:23,  7.86it/s]\titers: 1100, epoch: 3 | loss: 0.2281860\n",
      "\tspeed: 0.1312s/iter; left time: 8627.5827s\n",
      "1199it [02:36,  7.14it/s]\titers: 1200, epoch: 3 | loss: 0.1639353\n",
      "\tspeed: 0.1294s/iter; left time: 8494.9647s\n",
      "1299it [02:49,  7.72it/s]\titers: 1300, epoch: 3 | loss: 0.2385784\n",
      "\tspeed: 0.1297s/iter; left time: 8497.8942s\n",
      "1399it [03:02,  7.58it/s]\titers: 1400, epoch: 3 | loss: 0.3162254\n",
      "\tspeed: 0.1325s/iter; left time: 8670.8155s\n",
      "1499it [03:15,  7.03it/s]\titers: 1500, epoch: 3 | loss: 0.1490571\n",
      "\tspeed: 0.1297s/iter; left time: 8475.7814s\n",
      "1599it [03:29,  7.73it/s]\titers: 1600, epoch: 3 | loss: 0.3864870\n",
      "\tspeed: 0.1307s/iter; left time: 8524.3812s\n",
      "1699it [03:42,  7.97it/s]\titers: 1700, epoch: 3 | loss: 0.3177374\n",
      "\tspeed: 0.1322s/iter; left time: 8613.8330s\n",
      "1799it [03:55,  7.64it/s]\titers: 1800, epoch: 3 | loss: 0.1520831\n",
      "\tspeed: 0.1288s/iter; left time: 8373.8813s\n",
      "1899it [04:08,  7.91it/s]\titers: 1900, epoch: 3 | loss: 0.2257083\n",
      "\tspeed: 0.1304s/iter; left time: 8467.0423s\n",
      "1999it [04:21,  7.77it/s]\titers: 2000, epoch: 3 | loss: 0.2256435\n",
      "\tspeed: 0.1295s/iter; left time: 8394.7477s\n",
      "2099it [04:33,  7.81it/s]\titers: 2100, epoch: 3 | loss: 0.2019173\n",
      "\tspeed: 0.1281s/iter; left time: 8289.6898s\n",
      "2199it [04:47,  7.88it/s]\titers: 2200, epoch: 3 | loss: 0.1541355\n",
      "\tspeed: 0.1316s/iter; left time: 8502.7703s\n",
      "2299it [05:00,  7.85it/s]\titers: 2300, epoch: 3 | loss: 0.1263089\n",
      "\tspeed: 0.1310s/iter; left time: 8451.2051s\n",
      "2399it [05:12,  7.87it/s]\titers: 2400, epoch: 3 | loss: 0.2702385\n",
      "\tspeed: 0.1264s/iter; left time: 8144.7847s\n",
      "2499it [05:25,  7.90it/s]\titers: 2500, epoch: 3 | loss: 0.2562164\n",
      "\tspeed: 0.1294s/iter; left time: 8327.7767s\n",
      "2599it [05:38,  7.08it/s]\titers: 2600, epoch: 3 | loss: 0.2490318\n",
      "\tspeed: 0.1290s/iter; left time: 8284.2528s\n",
      "2699it [05:51,  7.91it/s]\titers: 2700, epoch: 3 | loss: 0.1571666\n",
      "\tspeed: 0.1272s/iter; left time: 8155.6866s\n",
      "2799it [06:04,  7.79it/s]\titers: 2800, epoch: 3 | loss: 0.1761787\n",
      "\tspeed: 0.1289s/iter; left time: 8254.6760s\n",
      "2899it [06:17,  7.80it/s]\titers: 2900, epoch: 3 | loss: 0.1350867\n",
      "\tspeed: 0.1277s/iter; left time: 8165.8856s\n",
      "2999it [06:29,  7.71it/s]\titers: 3000, epoch: 3 | loss: 0.2478373\n",
      "\tspeed: 0.1287s/iter; left time: 8217.4150s\n",
      "3099it [06:42,  7.83it/s]\titers: 3100, epoch: 3 | loss: 0.2496981\n",
      "\tspeed: 0.1299s/iter; left time: 8281.7341s\n",
      "3199it [06:55,  7.50it/s]\titers: 3200, epoch: 3 | loss: 0.1517304\n",
      "\tspeed: 0.1306s/iter; left time: 8307.6520s\n",
      "3299it [07:08,  7.81it/s]\titers: 3300, epoch: 3 | loss: 0.1905589\n",
      "\tspeed: 0.1299s/iter; left time: 8255.4373s\n",
      "3399it [07:22,  7.73it/s]\titers: 3400, epoch: 3 | loss: 0.2230773\n",
      "\tspeed: 0.1323s/iter; left time: 8391.9180s\n",
      "3499it [07:35,  7.68it/s]\titers: 3500, epoch: 3 | loss: 0.2365967\n",
      "\tspeed: 0.1298s/iter; left time: 8220.1556s\n",
      "3599it [07:48,  7.77it/s]\titers: 3600, epoch: 3 | loss: 0.1072769\n",
      "\tspeed: 0.1312s/iter; left time: 8293.7054s\n",
      "3699it [08:01,  7.69it/s]\titers: 3700, epoch: 3 | loss: 0.2879986\n",
      "\tspeed: 0.1332s/iter; left time: 8407.6610s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 3 cost time: 483.4823913574219\n",
      "810it [00:49, 16.20it/s]\n",
      "807it [00:49, 16.35it/s]\n",
      "Epoch: 3 | Train Loss: 0.2212686 Vali Loss: 0.2801371 Test Loss: 0.3329907 MAE Loss: 0.3440673\n",
      "Updating learning rate to 9.999999999999999e-06\n",
      "99it [00:13,  7.80it/s]\titers: 100, epoch: 4 | loss: 0.2128312\n",
      "\tspeed: 1.1825s/iter; left time: 74524.6950s\n",
      "199it [00:27,  7.58it/s]\titers: 200, epoch: 4 | loss: 0.2195538\n",
      "\tspeed: 0.1340s/iter; left time: 8429.7965s\n",
      "299it [00:40,  7.67it/s]\titers: 300, epoch: 4 | loss: 0.3302707\n",
      "\tspeed: 0.1299s/iter; left time: 8160.0765s\n",
      "399it [00:53,  7.60it/s]\titers: 400, epoch: 4 | loss: 0.4481091\n",
      "\tspeed: 0.1335s/iter; left time: 8374.7982s\n",
      "499it [01:06,  7.59it/s]\titers: 500, epoch: 4 | loss: 0.0987328\n",
      "\tspeed: 0.1336s/iter; left time: 8367.1181s\n",
      "599it [01:20,  7.55it/s]\titers: 600, epoch: 4 | loss: 0.2090068\n",
      "\tspeed: 0.1312s/iter; left time: 8202.8580s\n",
      "699it [01:33,  7.78it/s]\titers: 700, epoch: 4 | loss: 0.3150179\n",
      "\tspeed: 0.1336s/iter; left time: 8340.5657s\n",
      "799it [01:46,  7.87it/s]\titers: 800, epoch: 4 | loss: 0.1733373\n",
      "\tspeed: 0.1308s/iter; left time: 8149.8054s\n",
      "899it [01:59,  7.23it/s]\titers: 900, epoch: 4 | loss: 0.2353803\n",
      "\tspeed: 0.1289s/iter; left time: 8022.7098s\n",
      "999it [02:12,  7.65it/s]\titers: 1000, epoch: 4 | loss: 0.2693732\n",
      "\tspeed: 0.1300s/iter; left time: 8075.5701s\n",
      "1099it [02:25,  7.44it/s]\titers: 1100, epoch: 4 | loss: 0.2488151\n",
      "\tspeed: 0.1336s/iter; left time: 8289.2193s\n",
      "1199it [02:38,  7.15it/s]\titers: 1200, epoch: 4 | loss: 0.3202523\n",
      "\tspeed: 0.1286s/iter; left time: 7961.3516s\n",
      "1299it [02:51,  7.60it/s]\titers: 1300, epoch: 4 | loss: 0.2792143\n",
      "\tspeed: 0.1321s/iter; left time: 8164.7204s\n",
      "1399it [03:05,  7.90it/s]\titers: 1400, epoch: 4 | loss: 0.3689791\n",
      "\tspeed: 0.1329s/iter; left time: 8202.8967s\n",
      "1499it [03:18,  6.92it/s]\titers: 1500, epoch: 4 | loss: 0.1964427\n",
      "\tspeed: 0.1306s/iter; left time: 8045.7311s\n",
      "1599it [03:31,  7.97it/s]\titers: 1600, epoch: 4 | loss: 0.1753232\n",
      "\tspeed: 0.1294s/iter; left time: 7958.8608s\n",
      "1699it [03:44,  7.76it/s]\titers: 1700, epoch: 4 | loss: 0.1751649\n",
      "\tspeed: 0.1298s/iter; left time: 7975.3103s\n",
      "1799it [03:57,  6.89it/s]\titers: 1800, epoch: 4 | loss: 0.1906732\n",
      "\tspeed: 0.1301s/iter; left time: 7980.8608s\n",
      "1899it [04:10,  7.47it/s]\titers: 1900, epoch: 4 | loss: 0.1933302\n",
      "\tspeed: 0.1315s/iter; left time: 8053.5229s\n",
      "1999it [04:23,  7.76it/s]\titers: 2000, epoch: 4 | loss: 0.1602807\n",
      "\tspeed: 0.1344s/iter; left time: 8217.4018s\n",
      "2099it [04:36,  7.31it/s]\titers: 2100, epoch: 4 | loss: 0.2727919\n",
      "\tspeed: 0.1297s/iter; left time: 7915.0626s\n",
      "2199it [04:49,  7.77it/s]\titers: 2200, epoch: 4 | loss: 0.1243803\n",
      "\tspeed: 0.1329s/iter; left time: 8097.4275s\n",
      "2299it [05:03,  7.47it/s]\titers: 2300, epoch: 4 | loss: 0.2286512\n",
      "\tspeed: 0.1337s/iter; left time: 8133.1621s\n",
      "2399it [05:16,  7.36it/s]\titers: 2400, epoch: 4 | loss: 0.1426104\n",
      "\tspeed: 0.1308s/iter; left time: 7941.0021s\n",
      "2499it [05:29,  7.81it/s]\titers: 2500, epoch: 4 | loss: 0.1815710\n",
      "\tspeed: 0.1308s/iter; left time: 7927.6447s\n",
      "2599it [05:42,  7.68it/s]\titers: 2600, epoch: 4 | loss: 0.2303303\n",
      "\tspeed: 0.1339s/iter; left time: 8103.9024s\n",
      "2699it [05:56,  6.83it/s]\titers: 2700, epoch: 4 | loss: 0.1436880\n",
      "\tspeed: 0.1353s/iter; left time: 8172.1888s\n",
      "2799it [06:09,  7.74it/s]\titers: 2800, epoch: 4 | loss: 0.3447067\n",
      "\tspeed: 0.1300s/iter; left time: 7844.7544s\n",
      "2899it [06:22,  7.73it/s]\titers: 2900, epoch: 4 | loss: 0.1544191\n",
      "\tspeed: 0.1320s/iter; left time: 7949.0549s\n",
      "2999it [06:35,  7.71it/s]\titers: 3000, epoch: 4 | loss: 0.2189909\n",
      "\tspeed: 0.1336s/iter; left time: 8031.9786s\n",
      "3099it [06:48,  7.78it/s]\titers: 3100, epoch: 4 | loss: 0.1446553\n",
      "\tspeed: 0.1291s/iter; left time: 7748.3308s\n",
      "3199it [07:02,  7.76it/s]\titers: 3200, epoch: 4 | loss: 0.2125824\n",
      "\tspeed: 0.1327s/iter; left time: 7951.4862s\n",
      "3299it [07:15,  7.65it/s]\titers: 3300, epoch: 4 | loss: 0.1498930\n",
      "\tspeed: 0.1321s/iter; left time: 7900.0393s\n",
      "3399it [07:28,  7.75it/s]\titers: 3400, epoch: 4 | loss: 0.1350155\n",
      "\tspeed: 0.1286s/iter; left time: 7681.1129s\n",
      "3499it [07:41,  7.78it/s]\titers: 3500, epoch: 4 | loss: 0.2077062\n",
      "\tspeed: 0.1315s/iter; left time: 7842.8196s\n",
      "3599it [07:54,  7.75it/s]\titers: 3600, epoch: 4 | loss: 0.1565008\n",
      "\tspeed: 0.1318s/iter; left time: 7843.6119s\n",
      "3699it [08:08,  5.53it/s]\titers: 3700, epoch: 4 | loss: 0.1517958\n",
      "\tspeed: 0.1360s/iter; left time: 8084.1826s\n",
      "3713it [08:10,  7.57it/s]\n",
      "Epoch: 4 cost time: 490.21391320228577\n",
      "810it [00:49, 16.42it/s]\n",
      "807it [00:49, 16.41it/s]\n",
      "Epoch: 4 | Train Loss: 0.2116419 Vali Loss: 0.2813208 Test Loss: 0.3359991 MAE Loss: 0.3474960\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.9999999999999996e-06\n",
      "99it [00:13,  7.81it/s]\titers: 100, epoch: 5 | loss: 0.1215705\n",
      "\tspeed: 1.1374s/iter; left time: 67456.5391s\n",
      "199it [00:26,  7.62it/s]\titers: 200, epoch: 5 | loss: 0.1519264\n",
      "\tspeed: 0.1343s/iter; left time: 7952.3108s\n",
      "299it [00:39,  6.67it/s]\titers: 300, epoch: 5 | loss: 0.1742376\n",
      "\tspeed: 0.1327s/iter; left time: 7846.5699s\n",
      "399it [00:52,  7.80it/s]\titers: 400, epoch: 5 | loss: 0.2460077\n",
      "\tspeed: 0.1290s/iter; left time: 7614.7672s\n",
      "499it [01:05,  7.83it/s]\titers: 500, epoch: 5 | loss: 0.0752749\n",
      "\tspeed: 0.1306s/iter; left time: 7691.3824s\n",
      "599it [01:18,  7.71it/s]\titers: 600, epoch: 5 | loss: 0.1421984\n",
      "\tspeed: 0.1309s/iter; left time: 7699.5268s\n",
      "699it [01:31,  7.82it/s]\titers: 700, epoch: 5 | loss: 0.2719428\n",
      "\tspeed: 0.1293s/iter; left time: 7592.8828s\n",
      "799it [01:44,  7.78it/s]\titers: 800, epoch: 5 | loss: 0.2143029\n",
      "\tspeed: 0.1309s/iter; left time: 7670.1602s\n",
      "899it [01:57,  7.60it/s]\titers: 900, epoch: 5 | loss: 0.2020324\n",
      "\tspeed: 0.1304s/iter; left time: 7627.3199s\n",
      "999it [02:10,  7.74it/s]\titers: 1000, epoch: 5 | loss: 0.2187834\n",
      "\tspeed: 0.1294s/iter; left time: 7558.2192s\n",
      "1099it [02:24,  7.91it/s]\titers: 1100, epoch: 5 | loss: 0.2859931\n",
      "\tspeed: 0.1322s/iter; left time: 7708.0266s\n",
      "1199it [02:37,  7.25it/s]\titers: 1200, epoch: 5 | loss: 0.1921416\n",
      "\tspeed: 0.1303s/iter; left time: 7585.8764s\n",
      "1299it [02:50,  7.66it/s]\titers: 1300, epoch: 5 | loss: 0.1542293\n",
      "\tspeed: 0.1297s/iter; left time: 7536.3844s\n",
      "1399it [03:03,  7.71it/s]\titers: 1400, epoch: 5 | loss: 0.1083390\n",
      "\tspeed: 0.1314s/iter; left time: 7620.9577s\n",
      "1499it [03:16,  7.77it/s]\titers: 1500, epoch: 5 | loss: 0.1162234\n",
      "\tspeed: 0.1289s/iter; left time: 7463.0696s\n",
      "1599it [03:29,  7.91it/s]\titers: 1600, epoch: 5 | loss: 0.2247154\n",
      "\tspeed: 0.1293s/iter; left time: 7475.0828s\n",
      "1699it [03:42,  7.86it/s]\titers: 1700, epoch: 5 | loss: 0.2029028\n",
      "\tspeed: 0.1314s/iter; left time: 7583.7786s\n",
      "1799it [03:55,  6.92it/s]\titers: 1800, epoch: 5 | loss: 0.2313351\n",
      "\tspeed: 0.1288s/iter; left time: 7418.2420s\n",
      "1899it [04:08,  7.73it/s]\titers: 1900, epoch: 5 | loss: 0.2222791\n",
      "\tspeed: 0.1301s/iter; left time: 7483.4158s\n",
      "1999it [04:21,  7.71it/s]\titers: 2000, epoch: 5 | loss: 0.1447722\n",
      "\tspeed: 0.1308s/iter; left time: 7508.8304s\n",
      "2099it [04:34,  7.03it/s]\titers: 2100, epoch: 5 | loss: 0.2559798\n",
      "\tspeed: 0.1292s/iter; left time: 7403.3624s\n",
      "2199it [04:47,  7.92it/s]\titers: 2200, epoch: 5 | loss: 0.1325725\n",
      "\tspeed: 0.1293s/iter; left time: 7396.7396s\n",
      "2299it [05:00,  7.84it/s]\titers: 2300, epoch: 5 | loss: 0.2350173\n",
      "\tspeed: 0.1303s/iter; left time: 7442.6577s\n",
      "2399it [05:12,  7.13it/s]\titers: 2400, epoch: 5 | loss: 0.1642561\n",
      "\tspeed: 0.1295s/iter; left time: 7384.2219s\n",
      "2499it [05:25,  7.82it/s]\titers: 2500, epoch: 5 | loss: 0.1604826\n",
      "\tspeed: 0.1289s/iter; left time: 7334.3306s\n",
      "2599it [05:38,  7.71it/s]\titers: 2600, epoch: 5 | loss: 0.2684038\n",
      "\tspeed: 0.1304s/iter; left time: 7406.8786s\n",
      "2699it [05:51,  7.62it/s]\titers: 2700, epoch: 5 | loss: 0.1760338\n",
      "\tspeed: 0.1288s/iter; left time: 7304.9225s\n",
      "2799it [06:04,  7.75it/s]\titers: 2800, epoch: 5 | loss: 0.1796928\n",
      "\tspeed: 0.1314s/iter; left time: 7439.0862s\n",
      "2899it [06:18,  7.79it/s]\titers: 2900, epoch: 5 | loss: 0.2157445\n",
      "\tspeed: 0.1317s/iter; left time: 7442.3547s\n",
      "2999it [06:31,  7.42it/s]\titers: 3000, epoch: 5 | loss: 0.1468672\n",
      "\tspeed: 0.1291s/iter; left time: 7281.7606s\n",
      "3099it [06:43,  7.76it/s]\titers: 3100, epoch: 5 | loss: 0.2015075\n",
      "\tspeed: 0.1297s/iter; left time: 7306.0170s\n",
      "3199it [06:57,  7.83it/s]\titers: 3200, epoch: 5 | loss: 0.1676449\n",
      "\tspeed: 0.1308s/iter; left time: 7351.4428s\n",
      "3299it [07:10,  6.05it/s]\titers: 3300, epoch: 5 | loss: 0.1916084\n",
      "\tspeed: 0.1313s/iter; left time: 7366.8941s\n",
      "3399it [07:23,  7.74it/s]\titers: 3400, epoch: 5 | loss: 0.2393851\n",
      "\tspeed: 0.1295s/iter; left time: 7250.4324s\n",
      "3499it [07:36,  7.58it/s]\titers: 3500, epoch: 5 | loss: 0.3022619\n",
      "\tspeed: 0.1309s/iter; left time: 7317.2789s\n",
      "3599it [07:49,  7.44it/s]\titers: 3600, epoch: 5 | loss: 0.2383408\n",
      "\tspeed: 0.1295s/iter; left time: 7224.5517s\n",
      "3699it [08:02,  7.90it/s]\titers: 3700, epoch: 5 | loss: 0.1483875\n",
      "\tspeed: 0.1311s/iter; left time: 7305.3372s\n",
      "3713it [08:04,  7.67it/s]\n",
      "Epoch: 5 cost time: 484.16480469703674\n",
      "810it [00:49, 16.52it/s]\n",
      "807it [00:48, 16.71it/s]\n",
      "Epoch: 5 | Train Loss: 0.2056262 Vali Loss: 0.2857605 Test Loss: 0.3462862 MAE Loss: 0.3538258\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.4999999999999998e-06\n",
      "99it [00:13,  8.03it/s]\titers: 100, epoch: 6 | loss: 0.2537978\n",
      "\tspeed: 1.1249s/iter; left time: 62537.8014s\n",
      "199it [00:26,  6.99it/s]\titers: 200, epoch: 6 | loss: 0.1386817\n",
      "\tspeed: 0.1305s/iter; left time: 7244.6451s\n",
      "299it [00:39,  6.41it/s]\titers: 300, epoch: 6 | loss: 0.2591326\n",
      "\tspeed: 0.1285s/iter; left time: 7117.1344s\n",
      "399it [00:52,  7.92it/s]\titers: 400, epoch: 6 | loss: 0.1535020\n",
      "\tspeed: 0.1293s/iter; left time: 7151.4746s\n",
      "499it [01:05,  8.01it/s]\titers: 500, epoch: 6 | loss: 0.2082774\n",
      "\tspeed: 0.1315s/iter; left time: 7259.8823s\n",
      "599it [01:18,  7.92it/s]\titers: 600, epoch: 6 | loss: 0.2359465\n",
      "\tspeed: 0.1296s/iter; left time: 7143.1575s\n",
      "699it [01:30,  7.98it/s]\titers: 700, epoch: 6 | loss: 0.3018428\n",
      "\tspeed: 0.1280s/iter; left time: 7039.6886s\n",
      "799it [01:43,  7.88it/s]\titers: 800, epoch: 6 | loss: 0.2652551\n",
      "\tspeed: 0.1287s/iter; left time: 7067.5588s\n",
      "899it [01:56,  6.72it/s]\titers: 900, epoch: 6 | loss: 0.2376828\n",
      "\tspeed: 0.1302s/iter; left time: 7136.6489s\n",
      "999it [02:09,  7.49it/s]\titers: 1000, epoch: 6 | loss: 0.1226375\n",
      "\tspeed: 0.1309s/iter; left time: 7157.0021s\n",
      "1099it [02:23,  7.41it/s]\titers: 1100, epoch: 6 | loss: 0.1675810\n",
      "\tspeed: 0.1347s/iter; left time: 7355.2663s\n",
      "1199it [02:36,  7.71it/s]\titers: 1200, epoch: 6 | loss: 0.2391902\n",
      "\tspeed: 0.1313s/iter; left time: 7154.5023s\n",
      "1299it [02:49,  7.95it/s]\titers: 1300, epoch: 6 | loss: 0.1843557\n",
      "\tspeed: 0.1277s/iter; left time: 6946.1290s\n",
      "1399it [03:02,  7.90it/s]\titers: 1400, epoch: 6 | loss: 0.1571867\n",
      "\tspeed: 0.1292s/iter; left time: 7016.0276s\n",
      "1499it [03:15,  7.71it/s]\titers: 1500, epoch: 6 | loss: 0.1495090\n",
      "\tspeed: 0.1307s/iter; left time: 7084.4020s\n",
      "1599it [03:28,  7.65it/s]\titers: 1600, epoch: 6 | loss: 0.0854176\n",
      "\tspeed: 0.1276s/iter; left time: 6900.6249s\n",
      "1699it [03:41,  7.71it/s]\titers: 1700, epoch: 6 | loss: 0.2547580\n",
      "\tspeed: 0.1306s/iter; left time: 7051.3996s\n",
      "1799it [03:54,  7.89it/s]\titers: 1800, epoch: 6 | loss: 0.1928886\n",
      "\tspeed: 0.1302s/iter; left time: 7014.8396s\n",
      "1899it [04:06,  7.88it/s]\titers: 1900, epoch: 6 | loss: 0.2520036\n",
      "\tspeed: 0.1277s/iter; left time: 6871.5270s\n",
      "1999it [04:20,  7.90it/s]\titers: 2000, epoch: 6 | loss: 0.1259657\n",
      "\tspeed: 0.1309s/iter; left time: 7030.8391s\n",
      "2099it [04:32,  7.87it/s]\titers: 2100, epoch: 6 | loss: 0.2468439\n",
      "\tspeed: 0.1295s/iter; left time: 6939.2114s\n",
      "2199it [04:45,  7.86it/s]\titers: 2200, epoch: 6 | loss: 0.1148948\n",
      "\tspeed: 0.1270s/iter; left time: 6793.3687s\n",
      "2299it [04:58,  7.72it/s]\titers: 2300, epoch: 6 | loss: 0.1980886\n",
      "\tspeed: 0.1313s/iter; left time: 7010.9937s\n",
      "2399it [05:12,  7.72it/s]\titers: 2400, epoch: 6 | loss: 0.1522728\n",
      "\tspeed: 0.1357s/iter; left time: 7230.5244s\n",
      "2499it [05:25,  5.93it/s]\titers: 2500, epoch: 6 | loss: 0.3693871\n",
      "\tspeed: 0.1330s/iter; left time: 7073.8179s\n",
      "2599it [05:39,  7.69it/s]\titers: 2600, epoch: 6 | loss: 0.1994973\n",
      "\tspeed: 0.1345s/iter; left time: 7141.0385s\n",
      "2699it [05:52,  7.64it/s]\titers: 2700, epoch: 6 | loss: 0.2647148\n",
      "\tspeed: 0.1345s/iter; left time: 7126.2563s\n",
      "2799it [06:05,  7.14it/s]\titers: 2800, epoch: 6 | loss: 0.2415183\n",
      "\tspeed: 0.1294s/iter; left time: 6847.0898s\n",
      "2899it [06:18,  7.87it/s]\titers: 2900, epoch: 6 | loss: 0.2359923\n",
      "\tspeed: 0.1291s/iter; left time: 6814.9882s\n",
      "2999it [06:31,  7.74it/s]\titers: 3000, epoch: 6 | loss: 0.1775244\n",
      "\tspeed: 0.1300s/iter; left time: 6849.0749s\n",
      "3099it [06:44,  7.71it/s]\titers: 3100, epoch: 6 | loss: 0.1864435\n",
      "\tspeed: 0.1316s/iter; left time: 6920.6569s\n",
      "3199it [06:57,  7.68it/s]\titers: 3200, epoch: 6 | loss: 0.1932236\n",
      "\tspeed: 0.1301s/iter; left time: 6830.5767s\n",
      "3299it [07:10,  7.87it/s]\titers: 3300, epoch: 6 | loss: 0.1104027\n",
      "\tspeed: 0.1323s/iter; left time: 6931.2826s\n",
      "3399it [07:23,  7.75it/s]\titers: 3400, epoch: 6 | loss: 0.2285420\n",
      "\tspeed: 0.1315s/iter; left time: 6877.3935s\n",
      "3499it [07:36,  7.84it/s]\titers: 3500, epoch: 6 | loss: 0.1582985\n",
      "\tspeed: 0.1289s/iter; left time: 6728.0666s\n",
      "3599it [07:50,  7.73it/s]\titers: 3600, epoch: 6 | loss: 0.2720512\n",
      "\tspeed: 0.1318s/iter; left time: 6867.0234s\n",
      "3699it [08:03,  7.80it/s]\titers: 3700, epoch: 6 | loss: 0.3566822\n",
      "\tspeed: 0.1297s/iter; left time: 6744.8405s\n",
      "3713it [08:04,  7.66it/s]\n",
      "Epoch: 6 cost time: 484.9444179534912\n",
      "810it [00:48, 16.70it/s]\n",
      "807it [00:48, 16.60it/s]\n",
      "Epoch: 6 | Train Loss: 0.2030284 Vali Loss: 0.2816860 Test Loss: 0.3389031 MAE Loss: 0.3452845\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2499999999999999e-06\n",
      "99it [00:13,  7.80it/s]\titers: 100, epoch: 7 | loss: 0.1816242\n",
      "\tspeed: 1.1272s/iter; left time: 58480.9936s\n",
      "199it [00:26,  7.71it/s]\titers: 200, epoch: 7 | loss: 0.1633084\n",
      "\tspeed: 0.1325s/iter; left time: 6861.9220s\n",
      "299it [00:39,  6.62it/s]\titers: 300, epoch: 7 | loss: 0.4109701\n",
      "\tspeed: 0.1303s/iter; left time: 6732.9699s\n",
      "399it [00:52,  7.70it/s]\titers: 400, epoch: 7 | loss: 0.1848504\n",
      "\tspeed: 0.1319s/iter; left time: 6801.2247s\n",
      "499it [01:06,  7.82it/s]\titers: 500, epoch: 7 | loss: 0.1937406\n",
      "\tspeed: 0.1319s/iter; left time: 6792.5681s\n",
      "599it [01:19,  7.74it/s]\titers: 600, epoch: 7 | loss: 0.0962959\n",
      "\tspeed: 0.1294s/iter; left time: 6649.4411s\n",
      "699it [01:32,  7.74it/s]\titers: 700, epoch: 7 | loss: 0.1348601\n",
      "\tspeed: 0.1327s/iter; left time: 6805.7421s\n",
      "799it [01:45,  7.12it/s]\titers: 800, epoch: 7 | loss: 0.2012894\n",
      "\tspeed: 0.1339s/iter; left time: 6852.5888s\n",
      "899it [01:58,  7.69it/s]\titers: 900, epoch: 7 | loss: 0.1680372\n",
      "\tspeed: 0.1284s/iter; left time: 6560.7507s\n",
      "999it [02:11,  7.83it/s]\titers: 1000, epoch: 7 | loss: 0.1848904\n",
      "\tspeed: 0.1324s/iter; left time: 6752.3672s\n",
      "1099it [02:24,  7.76it/s]\titers: 1100, epoch: 7 | loss: 0.2683204\n",
      "\tspeed: 0.1306s/iter; left time: 6644.5460s\n",
      "1199it [02:37,  7.81it/s]\titers: 1200, epoch: 7 | loss: 0.1783266\n",
      "\tspeed: 0.1307s/iter; left time: 6635.1892s\n",
      "1299it [02:51,  7.81it/s]\titers: 1300, epoch: 7 | loss: 0.2116267\n",
      "\tspeed: 0.1316s/iter; left time: 6672.1216s\n",
      "1399it [03:04,  7.88it/s]\titers: 1400, epoch: 7 | loss: 0.4300954\n",
      "\tspeed: 0.1296s/iter; left time: 6554.1266s\n",
      "1499it [03:16,  7.76it/s]\titers: 1500, epoch: 7 | loss: 0.0957096\n",
      "\tspeed: 0.1279s/iter; left time: 6455.3211s\n",
      "1599it [03:29,  8.00it/s]\titers: 1600, epoch: 7 | loss: 0.4175620\n",
      "\tspeed: 0.1294s/iter; left time: 6520.7315s\n",
      "1699it [03:42,  7.43it/s]\titers: 1700, epoch: 7 | loss: 0.2002852\n",
      "\tspeed: 0.1288s/iter; left time: 6477.2554s\n",
      "1799it [03:55,  7.83it/s]\titers: 1800, epoch: 7 | loss: 0.2869585\n",
      "\tspeed: 0.1286s/iter; left time: 6455.9009s\n",
      "1899it [04:08,  7.75it/s]\titers: 1900, epoch: 7 | loss: 0.1711172\n",
      "\tspeed: 0.1300s/iter; left time: 6509.2525s\n",
      "1999it [04:21,  7.80it/s]\titers: 2000, epoch: 7 | loss: 0.3147885\n",
      "\tspeed: 0.1288s/iter; left time: 6437.5564s\n",
      "2099it [04:35,  7.93it/s]\titers: 2100, epoch: 7 | loss: 0.1433862\n",
      "\tspeed: 0.1450s/iter; left time: 7235.4068s\n",
      "2199it [04:48,  7.88it/s]\titers: 2200, epoch: 7 | loss: 0.1799153\n",
      "\tspeed: 0.1296s/iter; left time: 6449.9507s\n",
      "2299it [05:01,  7.53it/s]\titers: 2300, epoch: 7 | loss: 0.1999256\n",
      "\tspeed: 0.1305s/iter; left time: 6482.0212s\n",
      "2399it [05:15,  7.93it/s]\titers: 2400, epoch: 7 | loss: 0.1239488\n",
      "\tspeed: 0.1312s/iter; left time: 6503.9396s\n",
      "2499it [05:28,  7.69it/s]\titers: 2500, epoch: 7 | loss: 0.1484330\n",
      "\tspeed: 0.1319s/iter; left time: 6528.7910s\n",
      "2599it [05:41,  7.67it/s]\titers: 2600, epoch: 7 | loss: 0.1561098\n",
      "\tspeed: 0.1312s/iter; left time: 6480.4592s\n",
      "2699it [05:54,  7.61it/s]\titers: 2700, epoch: 7 | loss: 0.1467226\n",
      "\tspeed: 0.1342s/iter; left time: 6612.1262s\n",
      "2799it [06:08,  7.45it/s]\titers: 2800, epoch: 7 | loss: 0.1576784\n",
      "\tspeed: 0.1333s/iter; left time: 6553.8863s\n",
      "2899it [06:20,  7.85it/s]\titers: 2900, epoch: 7 | loss: 0.1832876\n",
      "\tspeed: 0.1283s/iter; left time: 6298.7057s\n",
      "2999it [06:34,  7.72it/s]\titers: 3000, epoch: 7 | loss: 0.3054015\n",
      "\tspeed: 0.1317s/iter; left time: 6452.3426s\n",
      "3099it [06:47,  6.88it/s]\titers: 3100, epoch: 7 | loss: 0.1696397\n",
      "\tspeed: 0.1321s/iter; left time: 6456.8004s\n",
      "3199it [07:00,  7.83it/s]\titers: 3200, epoch: 7 | loss: 0.2006701\n",
      "\tspeed: 0.1279s/iter; left time: 6237.4040s\n",
      "3299it [07:13,  7.78it/s]\titers: 3300, epoch: 7 | loss: 0.2382244\n",
      "\tspeed: 0.1339s/iter; left time: 6516.2320s\n",
      "3399it [07:26,  8.01it/s]\titers: 3400, epoch: 7 | loss: 0.1469581\n",
      "\tspeed: 0.1312s/iter; left time: 6373.5756s\n",
      "3499it [07:39,  7.43it/s]\titers: 3500, epoch: 7 | loss: 0.1741498\n",
      "\tspeed: 0.1296s/iter; left time: 6284.3976s\n",
      "3599it [07:52,  7.50it/s]\titers: 3600, epoch: 7 | loss: 0.1849421\n",
      "\tspeed: 0.1312s/iter; left time: 6349.1515s\n",
      "3699it [08:05,  7.76it/s]\titers: 3700, epoch: 7 | loss: 0.1843563\n",
      "\tspeed: 0.1320s/iter; left time: 6373.8388s\n",
      "3713it [08:07,  7.61it/s]\n",
      "Epoch: 7 cost time: 487.79139137268066\n",
      "810it [00:48, 16.80it/s]\n",
      "807it [00:48, 16.67it/s]\n",
      "Epoch: 7 | Train Loss: 0.2013410 Vali Loss: 0.2826792 Test Loss: 0.3383601 MAE Loss: 0.3447699\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.249999999999999e-07\n",
      "99it [00:13,  7.61it/s]\titers: 100, epoch: 8 | loss: 0.1279582\n",
      "\tspeed: 1.1217s/iter; left time: 54032.8632s\n",
      "199it [00:26,  7.67it/s]\titers: 200, epoch: 8 | loss: 0.2164734\n",
      "\tspeed: 0.1313s/iter; left time: 6312.1012s\n",
      "299it [00:39,  7.58it/s]\titers: 300, epoch: 8 | loss: 0.1220205\n",
      "\tspeed: 0.1306s/iter; left time: 6264.8663s\n",
      "399it [00:53,  7.77it/s]\titers: 400, epoch: 8 | loss: 0.2323599\n",
      "\tspeed: 0.1332s/iter; left time: 6375.1941s\n",
      "499it [01:06,  6.51it/s]\titers: 500, epoch: 8 | loss: 0.1516758\n",
      "\tspeed: 0.1335s/iter; left time: 6379.6197s\n",
      "599it [01:19,  7.56it/s]\titers: 600, epoch: 8 | loss: 0.2472006\n",
      "\tspeed: 0.1297s/iter; left time: 6185.1197s\n",
      "699it [01:32,  7.70it/s]\titers: 700, epoch: 8 | loss: 0.3572842\n",
      "\tspeed: 0.1317s/iter; left time: 6264.4968s\n",
      "799it [01:45,  6.39it/s]\titers: 800, epoch: 8 | loss: 0.2375330\n",
      "\tspeed: 0.1309s/iter; left time: 6214.5150s\n",
      "899it [01:58,  7.84it/s]\titers: 900, epoch: 8 | loss: 0.1513738\n",
      "\tspeed: 0.1276s/iter; left time: 6045.1114s\n",
      "999it [02:11,  7.81it/s]\titers: 1000, epoch: 8 | loss: 0.2617031\n",
      "\tspeed: 0.1335s/iter; left time: 6311.8158s\n",
      "1099it [02:24,  7.81it/s]\titers: 1100, epoch: 8 | loss: 0.1723645\n",
      "\tspeed: 0.1315s/iter; left time: 6201.8919s\n",
      "1199it [02:37,  7.50it/s]\titers: 1200, epoch: 8 | loss: 0.2137951\n",
      "\tspeed: 0.1289s/iter; left time: 6067.7133s\n",
      "1299it [02:50,  7.82it/s]\titers: 1300, epoch: 8 | loss: 0.3421403\n",
      "\tspeed: 0.1281s/iter; left time: 6016.7453s\n",
      "1399it [03:03,  7.76it/s]\titers: 1400, epoch: 8 | loss: 0.2555632\n",
      "\tspeed: 0.1320s/iter; left time: 6188.1950s\n",
      "1499it [03:16,  7.19it/s]\titers: 1500, epoch: 8 | loss: 0.1085190\n",
      "\tspeed: 0.1298s/iter; left time: 6072.6476s\n",
      "1599it [03:29,  7.78it/s]\titers: 1600, epoch: 8 | loss: 0.2211587\n",
      "\tspeed: 0.1300s/iter; left time: 6066.0828s\n",
      "1699it [03:42,  7.77it/s]\titers: 1700, epoch: 8 | loss: 0.2141633\n",
      "\tspeed: 0.1314s/iter; left time: 6121.5817s\n",
      "1799it [03:55,  7.86it/s]\titers: 1800, epoch: 8 | loss: 0.1186428\n",
      "\tspeed: 0.1304s/iter; left time: 6059.8979s\n",
      "1899it [04:08,  7.69it/s]\titers: 1900, epoch: 8 | loss: 0.1627512\n",
      "\tspeed: 0.1292s/iter; left time: 5991.3989s\n",
      "1999it [04:22,  7.61it/s]\titers: 2000, epoch: 8 | loss: 0.2959258\n",
      "\tspeed: 0.1339s/iter; left time: 6193.7442s\n",
      "2099it [04:35,  6.55it/s]\titers: 2100, epoch: 8 | loss: 0.2173650\n",
      "\tspeed: 0.1332s/iter; left time: 6150.1055s\n",
      "2199it [04:48,  7.42it/s]\titers: 2200, epoch: 8 | loss: 0.2223504\n",
      "\tspeed: 0.1291s/iter; left time: 5947.2999s\n",
      "2299it [05:01,  7.96it/s]\titers: 2300, epoch: 8 | loss: 0.2041960\n",
      "\tspeed: 0.1307s/iter; left time: 6007.4042s\n",
      "2399it [05:14,  7.93it/s]\titers: 2400, epoch: 8 | loss: 0.2009455\n",
      "\tspeed: 0.1287s/iter; left time: 5901.4440s\n",
      "2499it [05:27,  7.69it/s]\titers: 2500, epoch: 8 | loss: 0.2436721\n",
      "\tspeed: 0.1268s/iter; left time: 5802.1276s\n",
      "2599it [05:39,  7.79it/s]\titers: 2600, epoch: 8 | loss: 0.1071552\n",
      "\tspeed: 0.1284s/iter; left time: 5863.6868s\n",
      "2699it [05:52,  7.87it/s]\titers: 2700, epoch: 8 | loss: 0.2414134\n",
      "\tspeed: 0.1288s/iter; left time: 5870.4132s\n",
      "2799it [06:05,  7.30it/s]\titers: 2800, epoch: 8 | loss: 0.1024023\n",
      "\tspeed: 0.1283s/iter; left time: 5832.5339s\n",
      "2899it [06:18,  7.78it/s]\titers: 2900, epoch: 8 | loss: 0.2330065\n",
      "\tspeed: 0.1286s/iter; left time: 5834.4799s\n",
      "2999it [06:31,  7.83it/s]\titers: 3000, epoch: 8 | loss: 0.1946887\n",
      "\tspeed: 0.1304s/iter; left time: 5904.6926s\n",
      "3099it [06:44,  7.95it/s]\titers: 3100, epoch: 8 | loss: 0.3304685\n",
      "\tspeed: 0.1280s/iter; left time: 5780.3157s\n",
      "3199it [06:57,  7.89it/s]\titers: 3200, epoch: 8 | loss: 0.1626873\n",
      "\tspeed: 0.1278s/iter; left time: 5761.1602s\n",
      "3299it [07:10,  7.92it/s]\titers: 3300, epoch: 8 | loss: 0.2423405\n",
      "\tspeed: 0.1289s/iter; left time: 5797.7545s\n",
      "3399it [07:22,  7.11it/s]\titers: 3400, epoch: 8 | loss: 0.1369114\n",
      "\tspeed: 0.1284s/iter; left time: 5763.3125s\n",
      "3499it [07:35,  7.85it/s]\titers: 3500, epoch: 8 | loss: 0.2636695\n",
      "\tspeed: 0.1270s/iter; left time: 5685.8544s\n",
      "3599it [07:48,  7.82it/s]\titers: 3600, epoch: 8 | loss: 0.1168666\n",
      "\tspeed: 0.1300s/iter; left time: 5806.8647s\n",
      "3699it [08:01,  7.88it/s]\titers: 3700, epoch: 8 | loss: 0.2894470\n",
      "\tspeed: 0.1322s/iter; left time: 5892.7150s\n",
      "3713it [08:03,  7.68it/s]\n",
      "Epoch: 8 cost time: 483.6595969200134\n",
      "810it [00:48, 16.70it/s]\n",
      "807it [00:48, 16.60it/s]\n",
      "Epoch: 8 | Train Loss: 0.2007458 Vali Loss: 0.2816134 Test Loss: 0.3387974 MAE Loss: 0.3444809\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.1249999999999997e-07\n",
      "99it [00:13,  7.88it/s]\titers: 100, epoch: 9 | loss: 0.2003011\n",
      "\tspeed: 1.1243s/iter; left time: 49983.0702s\n",
      "199it [00:26,  6.40it/s]\titers: 200, epoch: 9 | loss: 0.1307631\n",
      "\tspeed: 0.1314s/iter; left time: 5828.2518s\n",
      "299it [00:39,  7.77it/s]\titers: 300, epoch: 9 | loss: 0.1951911\n",
      "\tspeed: 0.1266s/iter; left time: 5601.8584s\n",
      "399it [00:52,  7.63it/s]\titers: 400, epoch: 9 | loss: 0.1443585\n",
      "\tspeed: 0.1310s/iter; left time: 5786.4324s\n",
      "499it [01:05,  7.77it/s]\titers: 500, epoch: 9 | loss: 0.1766445\n",
      "\tspeed: 0.1335s/iter; left time: 5882.2023s\n",
      "599it [01:18,  6.87it/s]\titers: 600, epoch: 9 | loss: 0.1759405\n",
      "\tspeed: 0.1306s/iter; left time: 5741.5441s\n",
      "699it [01:31,  7.57it/s]\titers: 700, epoch: 9 | loss: 0.1444973\n",
      "\tspeed: 0.1298s/iter; left time: 5691.3585s\n",
      "799it [01:45,  7.95it/s]\titers: 800, epoch: 9 | loss: 0.2164062\n",
      "\tspeed: 0.1331s/iter; left time: 5825.1980s\n",
      "899it [01:57,  7.83it/s]\titers: 900, epoch: 9 | loss: 0.1583990\n",
      "\tspeed: 0.1294s/iter; left time: 5650.7521s\n",
      "999it [02:10,  7.59it/s]\titers: 1000, epoch: 9 | loss: 0.2654483\n",
      "\tspeed: 0.1297s/iter; left time: 5648.9689s\n",
      "1099it [02:23,  7.86it/s]\titers: 1100, epoch: 9 | loss: 0.2316056\n",
      "\tspeed: 0.1305s/iter; left time: 5672.6459s\n",
      "1199it [02:36,  7.93it/s]\titers: 1200, epoch: 9 | loss: 0.1286955\n",
      "\tspeed: 0.1289s/iter; left time: 5587.1203s\n",
      "1299it [02:49,  7.67it/s]\titers: 1300, epoch: 9 | loss: 0.1373106\n",
      "\tspeed: 0.1284s/iter; left time: 5554.4789s\n",
      "1399it [03:02,  7.70it/s]\titers: 1400, epoch: 9 | loss: 0.2391982\n",
      "\tspeed: 0.1314s/iter; left time: 5671.0211s\n",
      "1499it [03:15,  7.88it/s]\titers: 1500, epoch: 9 | loss: 0.3220335\n",
      "\tspeed: 0.1288s/iter; left time: 5546.5328s\n",
      "1599it [03:28,  7.77it/s]\titers: 1600, epoch: 9 | loss: 0.1655974\n",
      "\tspeed: 0.1283s/iter; left time: 5512.2614s\n",
      "1699it [03:41,  7.86it/s]\titers: 1700, epoch: 9 | loss: 0.2797700\n",
      "\tspeed: 0.1315s/iter; left time: 5633.9515s\n",
      "1799it [03:54,  7.75it/s]\titers: 1800, epoch: 9 | loss: 0.1983084\n",
      "\tspeed: 0.1306s/iter; left time: 5584.8375s\n",
      "1899it [04:07,  6.38it/s]\titers: 1900, epoch: 9 | loss: 0.1109257\n",
      "\tspeed: 0.1297s/iter; left time: 5533.2509s\n",
      "1999it [04:20,  7.83it/s]\titers: 2000, epoch: 9 | loss: 0.1946364\n",
      "\tspeed: 0.1299s/iter; left time: 5528.4719s\n",
      "2099it [04:33,  7.82it/s]\titers: 2100, epoch: 9 | loss: 0.1541816\n",
      "\tspeed: 0.1308s/iter; left time: 5551.3477s\n",
      "2199it [04:46,  7.72it/s]\titers: 2200, epoch: 9 | loss: 0.1911540\n",
      "\tspeed: 0.1284s/iter; left time: 5439.7692s\n",
      "2299it [04:59,  7.88it/s]\titers: 2300, epoch: 9 | loss: 0.2803768\n",
      "\tspeed: 0.1279s/iter; left time: 5403.8932s\n",
      "2399it [05:12,  7.79it/s]\titers: 2400, epoch: 9 | loss: 0.2161340\n",
      "\tspeed: 0.1297s/iter; left time: 5467.3670s\n",
      "2499it [05:25,  7.83it/s]\titers: 2500, epoch: 9 | loss: 0.1608322\n",
      "\tspeed: 0.1297s/iter; left time: 5455.5505s\n",
      "2599it [05:38,  7.84it/s]\titers: 2600, epoch: 9 | loss: 0.1170731\n",
      "\tspeed: 0.1276s/iter; left time: 5354.3577s\n",
      "2699it [05:51,  7.86it/s]\titers: 2700, epoch: 9 | loss: 0.1482374\n",
      "\tspeed: 0.1318s/iter; left time: 5517.3851s\n",
      "2799it [06:04,  7.87it/s]\titers: 2800, epoch: 9 | loss: 0.2600410\n",
      "\tspeed: 0.1296s/iter; left time: 5410.1335s\n",
      "2899it [06:17,  7.42it/s]\titers: 2900, epoch: 9 | loss: 0.2394323\n",
      "\tspeed: 0.1295s/iter; left time: 5393.1266s\n",
      "2999it [06:29,  7.99it/s]\titers: 3000, epoch: 9 | loss: 0.1812843\n",
      "\tspeed: 0.1276s/iter; left time: 5303.7687s\n",
      "3099it [06:42,  7.88it/s]\titers: 3100, epoch: 9 | loss: 0.2702093\n",
      "\tspeed: 0.1299s/iter; left time: 5387.1313s\n",
      "3199it [06:55,  7.84it/s]\titers: 3200, epoch: 9 | loss: 0.2112910\n",
      "\tspeed: 0.1270s/iter; left time: 5253.5577s\n",
      "3299it [07:08,  7.86it/s]\titers: 3300, epoch: 9 | loss: 0.1367011\n",
      "\tspeed: 0.1280s/iter; left time: 5279.4883s\n",
      "3399it [07:21,  7.88it/s]\titers: 3400, epoch: 9 | loss: 0.1591177\n",
      "\tspeed: 0.1286s/iter; left time: 5292.4345s\n",
      "3499it [07:34,  7.99it/s]\titers: 3500, epoch: 9 | loss: 0.1455339\n",
      "\tspeed: 0.1270s/iter; left time: 5212.6109s\n",
      "3599it [07:46,  7.83it/s]\titers: 3600, epoch: 9 | loss: 0.1673865\n",
      "\tspeed: 0.1271s/iter; left time: 5207.4104s\n",
      "3699it [07:59,  7.85it/s]\titers: 3700, epoch: 9 | loss: 0.1879564\n",
      "\tspeed: 0.1306s/iter; left time: 5336.2904s\n",
      "3713it [08:01,  7.71it/s]\n",
      "Epoch: 9 cost time: 481.6420624256134\n",
      "810it [00:48, 16.75it/s]\n",
      "807it [00:48, 16.78it/s]\n",
      "Epoch: 9 | Train Loss: 0.2000246 Vali Loss: 0.2808785 Test Loss: 0.3386556 MAE Loss: 0.3452881\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5624999999999999e-07\n",
      "99it [00:13,  7.82it/s]\titers: 100, epoch: 10 | loss: 0.1908673\n",
      "\tspeed: 1.1199s/iter; left time: 45628.1615s\n",
      "199it [00:26,  7.96it/s]\titers: 200, epoch: 10 | loss: 0.1978689\n",
      "\tspeed: 0.1302s/iter; left time: 5293.0266s\n",
      "299it [00:39,  7.74it/s]\titers: 300, epoch: 10 | loss: 0.1750423\n",
      "\tspeed: 0.1282s/iter; left time: 5197.4612s\n",
      "399it [00:52,  7.82it/s]\titers: 400, epoch: 10 | loss: 0.2005215\n",
      "\tspeed: 0.1287s/iter; left time: 5204.7362s\n",
      "499it [01:04,  7.85it/s]\titers: 500, epoch: 10 | loss: 0.1575629\n",
      "\tspeed: 0.1291s/iter; left time: 5207.0451s\n",
      "599it [01:17,  7.89it/s]\titers: 600, epoch: 10 | loss: 0.1473856\n",
      "\tspeed: 0.1276s/iter; left time: 5136.4176s\n",
      "699it [01:30,  7.82it/s]\titers: 700, epoch: 10 | loss: 0.1861153\n",
      "\tspeed: 0.1282s/iter; left time: 5146.3839s\n",
      "799it [01:43,  7.72it/s]\titers: 800, epoch: 10 | loss: 0.2066590\n",
      "\tspeed: 0.1309s/iter; left time: 5243.5751s\n",
      "899it [01:56,  7.84it/s]\titers: 900, epoch: 10 | loss: 0.1746807\n",
      "\tspeed: 0.1294s/iter; left time: 5168.2416s\n",
      "999it [02:09,  7.64it/s]\titers: 1000, epoch: 10 | loss: 0.1866677\n",
      "\tspeed: 0.1284s/iter; left time: 5115.1388s\n",
      "1099it [02:22,  7.85it/s]\titers: 1100, epoch: 10 | loss: 0.1075767\n",
      "\tspeed: 0.1301s/iter; left time: 5170.8340s\n",
      "1199it [02:35,  7.81it/s]\titers: 1200, epoch: 10 | loss: 0.1957726\n",
      "\tspeed: 0.1301s/iter; left time: 5157.6115s\n",
      "1299it [02:48,  7.68it/s]\titers: 1300, epoch: 10 | loss: 0.1697790\n",
      "\tspeed: 0.1292s/iter; left time: 5107.9951s\n",
      "1399it [03:01,  7.85it/s]\titers: 1400, epoch: 10 | loss: 0.2389533\n",
      "\tspeed: 0.1280s/iter; left time: 5047.3476s\n",
      "1499it [03:14,  7.74it/s]\titers: 1500, epoch: 10 | loss: 0.3297002\n",
      "\tspeed: 0.1303s/iter; left time: 5125.3429s\n",
      "1599it [03:27,  7.69it/s]\titers: 1600, epoch: 10 | loss: 0.2177351\n",
      "\tspeed: 0.1314s/iter; left time: 5158.6034s\n",
      "1699it [03:40,  7.04it/s]\titers: 1700, epoch: 10 | loss: 0.1073710\n",
      "\tspeed: 0.1296s/iter; left time: 5074.4227s\n",
      "1799it [03:53,  7.79it/s]\titers: 1800, epoch: 10 | loss: 0.3009464\n",
      "\tspeed: 0.1311s/iter; left time: 5120.0122s\n",
      "1899it [04:06,  7.81it/s]\titers: 1900, epoch: 10 | loss: 0.3686776\n",
      "\tspeed: 0.1312s/iter; left time: 5110.3391s\n",
      "1999it [04:19,  7.10it/s]\titers: 2000, epoch: 10 | loss: 0.1824735\n",
      "\tspeed: 0.1305s/iter; left time: 5069.4684s\n",
      "2058it [04:27,  7.85it/s]^C\n",
      "2058it [04:27,  7.70it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py\", line 237, in <module>\n",
      "    accelerator.backward(loss)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/accelerator.py\", line 1995, in backward\n",
      "    self.deepspeed_engine_wrapped.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/utils/deepspeed.py\", line 166, in backward\n",
      "    self.engine.backward(loss, **kwargs)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 2002, in backward\n",
      "    self.allreduce_gradients()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1918, in allreduce_gradients\n",
      "    self.optimizer.overlapping_partition_gradients_reduce_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 859, in overlapping_partition_gradients_reduce_epilogue\n",
      "    self.independent_gradient_partition_epilogue()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 760, in independent_gradient_partition_epilogue\n",
      "    get_accelerator().synchronize()\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/accelerator/cuda_accelerator.py\", line 77, in synchronize\n",
      "    return torch.cuda.synchronize(device_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 801, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Total time: 92.78709202210108 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --num_machines=1 --dynamo_backend \"no\" --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning rate 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=20\n",
    "learning_rate=0.001\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --num_machines=1 --dynamo_backend \"no\" --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 512 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2-medium\" \\\n",
    "  --llm_dim 1024 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2024-05-03 23:11:43,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 23:11:43,917] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-03 23:11:44,837] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 23:11:44,837] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-03 23:11:44,837] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "d_llm 768\n",
      "[2024-05-03 23:11:46,684] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "d_llm 768\n",
      "[2024-05-03 23:11:47,587] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-03 23:11:47,588] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-03 23:11:47,588] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-03 23:11:47,589] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-03 23:11:47,589] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-03 23:11:47,589] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-03 23:11:47,589] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-03 23:11:47,589] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-03 23:11:47,589] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-03 23:11:47,589] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "0it [00:00, ?it/s][2024-05-03 23:11:47,892] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-03 23:11:47,893] [INFO] [utils.py:801:see_memory_usage] MA 0.45 GB         Max_MA 0.5 GB         CA 0.51 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:11:47,893] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 204.92 GB, percent = 27.2%\n",
      "[2024-05-03 23:11:48,183] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-03 23:11:48,183] [INFO] [utils.py:801:see_memory_usage] MA 0.45 GB         Max_MA 0.55 GB         CA 0.61 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:11:48,183] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 204.96 GB, percent = 27.2%\n",
      "[2024-05-03 23:11:48,183] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-03 23:11:48,312] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-03 23:11:48,313] [INFO] [utils.py:801:see_memory_usage] MA 0.45 GB         Max_MA 0.45 GB         CA 0.61 GB         Max_CA 1 GB \n",
      "[2024-05-03 23:11:48,313] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 205.09 GB, percent = 27.2%\n",
      "[2024-05-03 23:11:48,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-03 23:11:48,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-03 23:11:48,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-03 23:11:48,313] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0040000000000000036], mom=[(0.95, 0.999)]\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe8c48dbb10>\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-03 23:11:48,314] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   train_batch_size ............. 48\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   world_size ................... 2\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-03 23:11:48,315] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-03 23:11:48,316] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 48, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "0it [00:00, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py\", line 215, in <module>\n",
      "    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1852, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/models/TimeLLM.py\", line 238, in forward\n",
      "    dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/models/TimeLLM.py\", line 285, in forecast\n",
      "    dec_out = self.llm_model(inputs_embeds=llama_enc_out).last_hidden_state\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 900, in forward\n",
      "    outputs = block(\n",
      "              ^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 391, in forward\n",
      "    attn_outputs = self.attn(\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 332, in forward\n",
      "    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 213, in _attn\n",
      "    attn_weights = self.attn_dropout(attn_weights)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 59, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1268, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 1 has a total capacity of 79.32 GiB of which 2.50 MiB is free. Process 26038 has 77.25 GiB memory in use. Including non-PyTorch memory, this process has 2.04 GiB memory in use. Of the allocated memory 1.30 GiB is allocated by PyTorch, and 86.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[2024-05-03 23:11:53,794] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 65363 closing signal SIGTERM\n",
      "[2024-05-03 23:11:54,009] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 1 (pid: 65364) of binary: /usr/local/anaconda3-2023.03/envs/python311/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/.local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1048, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 702, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 803, in run\n",
      "    elastic_launch(\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 135, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 268, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "/vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-05-03_23:11:53\n",
      "  host      : gruenau10.informatik.hu-berlin.de\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 65364)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "Total time: 0.3587648391723633 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=1\n",
    "learning_rate=0.1\n",
    "llama_layers=24\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1, 2\"\n",
    "\n",
    "\n",
    "!accelerate launch --multi_gpu --mixed_precision bf16 --num_processes=2 --main_process_port \"01025\" /vol/cs-hu/riabchuv/hu-home/my_work/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
