{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No Patching](#3-no-patching)\n",
    "- [4. Time series decomposition](#4-ts-decomposition)\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_lens = [512, 512, 336, 168, 168]\n",
    "\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2566070\n",
      "\tspeed: 0.0697s/iter; left time: 1554.3492s\n",
      "\titers: 200, epoch: 1 | loss: 0.2419528\n",
      "\tspeed: 0.0297s/iter; left time: 660.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 224 | Train Loss: 0.2636380 Vali Loss: 0.2222575 Test Loss: 0.2204070\n",
      "Validation loss decreased (inf --> 0.222257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1490381\n",
      "\tspeed: 0.0510s/iter; left time: 1125.5861s\n",
      "\titers: 200, epoch: 2 | loss: 0.1197937\n",
      "\tspeed: 0.0264s/iter; left time: 580.1624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.1535841 Vali Loss: 0.1151092 Test Loss: 0.1171536\n",
      "Validation loss decreased (0.222257 --> 0.115109).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1010839\n",
      "\tspeed: 0.0513s/iter; left time: 1121.7780s\n",
      "\titers: 200, epoch: 3 | loss: 0.0979355\n",
      "\tspeed: 0.0264s/iter; left time: 574.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.1034884 Vali Loss: 0.1062425 Test Loss: 0.1076204\n",
      "Validation loss decreased (0.115109 --> 0.106242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0974420\n",
      "\tspeed: 0.0515s/iter; left time: 1113.9680s\n",
      "\titers: 200, epoch: 4 | loss: 0.0977694\n",
      "\tspeed: 0.0264s/iter; left time: 567.9155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0933482 Vali Loss: 0.0992072 Test Loss: 0.1010505\n",
      "Validation loss decreased (0.106242 --> 0.099207).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0909457\n",
      "\tspeed: 0.0512s/iter; left time: 1095.1722s\n",
      "\titers: 200, epoch: 5 | loss: 0.0860357\n",
      "\tspeed: 0.0263s/iter; left time: 560.0035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0887532 Vali Loss: 0.0971549 Test Loss: 0.0991021\n",
      "Validation loss decreased (0.099207 --> 0.097155).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0950104\n",
      "\tspeed: 0.0511s/iter; left time: 1082.2264s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841039\n",
      "\tspeed: 0.0263s/iter; left time: 553.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0859246 Vali Loss: 0.0970220 Test Loss: 0.0979300\n",
      "Validation loss decreased (0.097155 --> 0.097022).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830651\n",
      "\tspeed: 0.0514s/iter; left time: 1077.2520s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861730\n",
      "\tspeed: 0.0266s/iter; left time: 554.7573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0841975 Vali Loss: 0.0949431 Test Loss: 0.0963822\n",
      "Validation loss decreased (0.097022 --> 0.094943).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834699\n",
      "\tspeed: 0.0515s/iter; left time: 1067.3835s\n",
      "\titers: 200, epoch: 8 | loss: 0.0826666\n",
      "\tspeed: 0.0262s/iter; left time: 541.5249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0832470 Vali Loss: 0.0940332 Test Loss: 0.0951022\n",
      "Validation loss decreased (0.094943 --> 0.094033).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0867406\n",
      "\tspeed: 0.0513s/iter; left time: 1051.3144s\n",
      "\titers: 200, epoch: 9 | loss: 0.0859180\n",
      "\tspeed: 0.0265s/iter; left time: 541.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0822038 Vali Loss: 0.0939286 Test Loss: 0.0947163\n",
      "Validation loss decreased (0.094033 --> 0.093929).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0839390\n",
      "\tspeed: 0.0520s/iter; left time: 1055.6915s\n",
      "\titers: 200, epoch: 10 | loss: 0.0786523\n",
      "\tspeed: 0.0266s/iter; left time: 536.4196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0808735 Vali Loss: 0.0932474 Test Loss: 0.0947599\n",
      "Validation loss decreased (0.093929 --> 0.093247).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754465\n",
      "\tspeed: 0.0518s/iter; left time: 1038.5746s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798902\n",
      "\tspeed: 0.0265s/iter; left time: 528.4970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0805028 Vali Loss: 0.0930160 Test Loss: 0.0942361\n",
      "Validation loss decreased (0.093247 --> 0.093016).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0777061\n",
      "\tspeed: 0.0517s/iter; left time: 1025.7292s\n",
      "\titers: 200, epoch: 12 | loss: 0.0808789\n",
      "\tspeed: 0.0264s/iter; left time: 520.3353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0801001 Vali Loss: 0.0921757 Test Loss: 0.0932652\n",
      "Validation loss decreased (0.093016 --> 0.092176).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0751510\n",
      "\tspeed: 0.0514s/iter; left time: 1008.7788s\n",
      "\titers: 200, epoch: 13 | loss: 0.0770847\n",
      "\tspeed: 0.0264s/iter; left time: 514.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0791738 Vali Loss: 0.0924514 Test Loss: 0.0932204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0782727\n",
      "\tspeed: 0.0512s/iter; left time: 992.9978s\n",
      "\titers: 200, epoch: 14 | loss: 0.0786983\n",
      "\tspeed: 0.0264s/iter; left time: 509.4893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0787759 Vali Loss: 0.0920219 Test Loss: 0.0935162\n",
      "Validation loss decreased (0.092176 --> 0.092022).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0777310\n",
      "\tspeed: 0.0522s/iter; left time: 999.8995s\n",
      "\titers: 200, epoch: 15 | loss: 0.0735414\n",
      "\tspeed: 0.0266s/iter; left time: 506.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0786300 Vali Loss: 0.0917478 Test Loss: 0.0926336\n",
      "Validation loss decreased (0.092022 --> 0.091748).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785231\n",
      "\tspeed: 0.0512s/iter; left time: 970.0143s\n",
      "\titers: 200, epoch: 16 | loss: 0.0768834\n",
      "\tspeed: 0.0265s/iter; left time: 499.4976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0784725 Vali Loss: 0.0918264 Test Loss: 0.0926172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0798664\n",
      "\tspeed: 0.0514s/iter; left time: 962.0186s\n",
      "\titers: 200, epoch: 17 | loss: 0.0797044\n",
      "\tspeed: 0.0264s/iter; left time: 491.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0783037 Vali Loss: 0.0910420 Test Loss: 0.0925358\n",
      "Validation loss decreased (0.091748 --> 0.091042).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781114\n",
      "\tspeed: 0.0513s/iter; left time: 948.8579s\n",
      "\titers: 200, epoch: 18 | loss: 0.0855012\n",
      "\tspeed: 0.0266s/iter; left time: 489.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0779318 Vali Loss: 0.0907866 Test Loss: 0.0921505\n",
      "Validation loss decreased (0.091042 --> 0.090787).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0735422\n",
      "\tspeed: 0.0517s/iter; left time: 944.8442s\n",
      "\titers: 200, epoch: 19 | loss: 0.0740805\n",
      "\tspeed: 0.0264s/iter; left time: 479.6136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0774609 Vali Loss: 0.0919343 Test Loss: 0.0928579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0746833\n",
      "\tspeed: 0.0504s/iter; left time: 908.8097s\n",
      "\titers: 200, epoch: 20 | loss: 0.0807188\n",
      "\tspeed: 0.0267s/iter; left time: 478.4274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0773912 Vali Loss: 0.0916482 Test Loss: 0.0923388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0721470\n",
      "\tspeed: 0.0508s/iter; left time: 904.9998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779014\n",
      "\tspeed: 0.0264s/iter; left time: 466.9820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0773700 Vali Loss: 0.0906744 Test Loss: 0.0923040\n",
      "Validation loss decreased (0.090787 --> 0.090674).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0702513\n",
      "\tspeed: 0.0510s/iter; left time: 897.7170s\n",
      "\titers: 200, epoch: 22 | loss: 0.0733673\n",
      "\tspeed: 0.0269s/iter; left time: 470.6345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0772820 Vali Loss: 0.0907303 Test Loss: 0.0918452\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767162\n",
      "\tspeed: 0.0518s/iter; left time: 900.4560s\n",
      "\titers: 200, epoch: 23 | loss: 0.0720851\n",
      "\tspeed: 0.0265s/iter; left time: 458.5923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0770278 Vali Loss: 0.0907926 Test Loss: 0.0918527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0754888\n",
      "\tspeed: 0.0509s/iter; left time: 873.5967s\n",
      "\titers: 200, epoch: 24 | loss: 0.0748333\n",
      "\tspeed: 0.0264s/iter; left time: 449.9587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0768529 Vali Loss: 0.0908272 Test Loss: 0.0918088\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0754161\n",
      "\tspeed: 0.0504s/iter; left time: 853.8475s\n",
      "\titers: 200, epoch: 25 | loss: 0.0849064\n",
      "\tspeed: 0.0267s/iter; left time: 449.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0768403 Vali Loss: 0.0907090 Test Loss: 0.0916022\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0744077\n",
      "\tspeed: 0.0511s/iter; left time: 854.0449s\n",
      "\titers: 200, epoch: 26 | loss: 0.0762815\n",
      "\tspeed: 0.0264s/iter; left time: 437.7518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0767571 Vali Loss: 0.0906516 Test Loss: 0.0917031\n",
      "Validation loss decreased (0.090674 --> 0.090652).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0812616\n",
      "\tspeed: 0.0513s/iter; left time: 845.1961s\n",
      "\titers: 200, epoch: 27 | loss: 0.0799414\n",
      "\tspeed: 0.0263s/iter; left time: 430.9567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0765723 Vali Loss: 0.0903748 Test Loss: 0.0915898\n",
      "Validation loss decreased (0.090652 --> 0.090375).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0726214\n",
      "\tspeed: 0.0510s/iter; left time: 828.6620s\n",
      "\titers: 200, epoch: 28 | loss: 0.0789795\n",
      "\tspeed: 0.0264s/iter; left time: 426.4562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0765280 Vali Loss: 0.0905175 Test Loss: 0.0916367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0772127\n",
      "\tspeed: 0.0507s/iter; left time: 812.8412s\n",
      "\titers: 200, epoch: 29 | loss: 0.0697870\n",
      "\tspeed: 0.0263s/iter; left time: 419.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0765321 Vali Loss: 0.0904983 Test Loss: 0.0915829\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0811062\n",
      "\tspeed: 0.0508s/iter; left time: 802.3043s\n",
      "\titers: 200, epoch: 30 | loss: 0.0780678\n",
      "\tspeed: 0.0265s/iter; left time: 416.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0765154 Vali Loss: 0.0902160 Test Loss: 0.0915959\n",
      "Validation loss decreased (0.090375 --> 0.090216).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0766579\n",
      "\tspeed: 0.0522s/iter; left time: 812.7127s\n",
      "\titers: 200, epoch: 31 | loss: 0.0730054\n",
      "\tspeed: 0.0264s/iter; left time: 409.0530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0764262 Vali Loss: 0.0905278 Test Loss: 0.0917065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0711051\n",
      "\tspeed: 0.0509s/iter; left time: 782.1983s\n",
      "\titers: 200, epoch: 32 | loss: 0.0803683\n",
      "\tspeed: 0.0263s/iter; left time: 401.6960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0763533 Vali Loss: 0.0901207 Test Loss: 0.0914401\n",
      "Validation loss decreased (0.090216 --> 0.090121).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0823469\n",
      "\tspeed: 0.0515s/iter; left time: 779.3056s\n",
      "\titers: 200, epoch: 33 | loss: 0.0713614\n",
      "\tspeed: 0.0264s/iter; left time: 396.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0763147 Vali Loss: 0.0905146 Test Loss: 0.0916492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0752804\n",
      "\tspeed: 0.0506s/iter; left time: 755.0867s\n",
      "\titers: 200, epoch: 34 | loss: 0.0791326\n",
      "\tspeed: 0.0265s/iter; left time: 392.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0762617 Vali Loss: 0.0903647 Test Loss: 0.0914449\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0792777\n",
      "\tspeed: 0.0513s/iter; left time: 753.7300s\n",
      "\titers: 200, epoch: 35 | loss: 0.0719633\n",
      "\tspeed: 0.0263s/iter; left time: 382.9059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0761660 Vali Loss: 0.0903345 Test Loss: 0.0914848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0769392\n",
      "\tspeed: 0.0504s/iter; left time: 728.1795s\n",
      "\titers: 200, epoch: 36 | loss: 0.0812033\n",
      "\tspeed: 0.0263s/iter; left time: 377.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0762252 Vali Loss: 0.0910000 Test Loss: 0.0918637\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0839674\n",
      "\tspeed: 0.0506s/iter; left time: 720.8292s\n",
      "\titers: 200, epoch: 37 | loss: 0.0782146\n",
      "\tspeed: 0.0265s/iter; left time: 374.3928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0761717 Vali Loss: 0.0904660 Test Loss: 0.0915176\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0749981\n",
      "\tspeed: 0.0510s/iter; left time: 714.8634s\n",
      "\titers: 200, epoch: 38 | loss: 0.0715419\n",
      "\tspeed: 0.0263s/iter; left time: 365.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0761763 Vali Loss: 0.0906010 Test Loss: 0.0916540\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0792945\n",
      "\tspeed: 0.0514s/iter; left time: 708.8584s\n",
      "\titers: 200, epoch: 39 | loss: 0.0729343\n",
      "\tspeed: 0.0263s/iter; left time: 360.4861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0762594 Vali Loss: 0.0901306 Test Loss: 0.0913918\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0725834\n",
      "\tspeed: 0.0507s/iter; left time: 687.9009s\n",
      "\titers: 200, epoch: 40 | loss: 0.0821638\n",
      "\tspeed: 0.0264s/iter; left time: 355.7920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0761080 Vali Loss: 0.0901505 Test Loss: 0.0913605\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0714317\n",
      "\tspeed: 0.0503s/iter; left time: 671.1363s\n",
      "\titers: 200, epoch: 41 | loss: 0.0747623\n",
      "\tspeed: 0.0263s/iter; left time: 348.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0761157 Vali Loss: 0.0900619 Test Loss: 0.0915041\n",
      "Validation loss decreased (0.090121 --> 0.090062).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0739755\n",
      "\tspeed: 0.0511s/iter; left time: 669.7266s\n",
      "\titers: 200, epoch: 42 | loss: 0.0810414\n",
      "\tspeed: 0.0262s/iter; left time: 341.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0761380 Vali Loss: 0.0903147 Test Loss: 0.0914038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0811172\n",
      "\tspeed: 0.0505s/iter; left time: 651.0997s\n",
      "\titers: 200, epoch: 43 | loss: 0.0779029\n",
      "\tspeed: 0.0263s/iter; left time: 336.3816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0760796 Vali Loss: 0.0902422 Test Loss: 0.0914716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0723317\n",
      "\tspeed: 0.0510s/iter; left time: 645.5269s\n",
      "\titers: 200, epoch: 44 | loss: 0.0762026\n",
      "\tspeed: 0.0263s/iter; left time: 330.3537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0759945 Vali Loss: 0.0902213 Test Loss: 0.0914703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0768227\n",
      "\tspeed: 0.0506s/iter; left time: 629.5039s\n",
      "\titers: 200, epoch: 45 | loss: 0.0778465\n",
      "\tspeed: 0.0263s/iter; left time: 324.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0760749 Vali Loss: 0.0902847 Test Loss: 0.0914034\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0757674\n",
      "\tspeed: 0.0508s/iter; left time: 620.4236s\n",
      "\titers: 200, epoch: 46 | loss: 0.0817664\n",
      "\tspeed: 0.0264s/iter; left time: 320.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0760586 Vali Loss: 0.0901711 Test Loss: 0.0912951\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0757344\n",
      "\tspeed: 0.0512s/iter; left time: 614.4499s\n",
      "\titers: 200, epoch: 47 | loss: 0.0739751\n",
      "\tspeed: 0.0263s/iter; left time: 312.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0760620 Vali Loss: 0.0903189 Test Loss: 0.0914689\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0769868\n",
      "\tspeed: 0.0510s/iter; left time: 600.1422s\n",
      "\titers: 200, epoch: 48 | loss: 0.0761500\n",
      "\tspeed: 0.0264s/iter; left time: 308.1459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0760214 Vali Loss: 0.0901692 Test Loss: 0.0913794\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0779364\n",
      "\tspeed: 0.0504s/iter; left time: 581.5220s\n",
      "\titers: 200, epoch: 49 | loss: 0.0800145\n",
      "\tspeed: 0.0263s/iter; left time: 301.3702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0760802 Vali Loss: 0.0900943 Test Loss: 0.0913661\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0724418\n",
      "\tspeed: 0.0503s/iter; left time: 570.1542s\n",
      "\titers: 200, epoch: 50 | loss: 0.0738002\n",
      "\tspeed: 0.0263s/iter; left time: 294.9540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 224 | Train Loss: 0.0759310 Vali Loss: 0.0905732 Test Loss: 0.0915211\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0714924\n",
      "\tspeed: 0.0504s/iter; left time: 559.1858s\n",
      "\titers: 200, epoch: 51 | loss: 0.0791853\n",
      "\tspeed: 0.0265s/iter; left time: 291.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0759803 Vali Loss: 0.0902920 Test Loss: 0.0913586\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021748371422290802, rmse:0.1474732905626297, mae:0.0915040671825409, rse:0.5204536318778992\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2623934\n",
      "\tspeed: 0.0283s/iter; left time: 631.1664s\n",
      "\titers: 200, epoch: 1 | loss: 0.2396158\n",
      "\tspeed: 0.0264s/iter; left time: 585.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.2633231 Vali Loss: 0.2145368 Test Loss: 0.2137502\n",
      "Validation loss decreased (inf --> 0.214537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1374790\n",
      "\tspeed: 0.0518s/iter; left time: 1143.5152s\n",
      "\titers: 200, epoch: 2 | loss: 0.1093387\n",
      "\tspeed: 0.0264s/iter; left time: 580.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.1501679 Vali Loss: 0.1194519 Test Loss: 0.1199035\n",
      "Validation loss decreased (0.214537 --> 0.119452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0990194\n",
      "\tspeed: 0.0530s/iter; left time: 1157.8753s\n",
      "\titers: 200, epoch: 3 | loss: 0.1039781\n",
      "\tspeed: 0.0264s/iter; left time: 573.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.1039293 Vali Loss: 0.1051352 Test Loss: 0.1071176\n",
      "Validation loss decreased (0.119452 --> 0.105135).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944413\n",
      "\tspeed: 0.0521s/iter; left time: 1127.6466s\n",
      "\titers: 200, epoch: 4 | loss: 0.0901303\n",
      "\tspeed: 0.0266s/iter; left time: 572.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0936006 Vali Loss: 0.0998318 Test Loss: 0.1013047\n",
      "Validation loss decreased (0.105135 --> 0.099832).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0877668\n",
      "\tspeed: 0.0516s/iter; left time: 1103.8633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0928216\n",
      "\tspeed: 0.0264s/iter; left time: 562.6199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0888237 Vali Loss: 0.0964812 Test Loss: 0.0980058\n",
      "Validation loss decreased (0.099832 --> 0.096481).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0847580\n",
      "\tspeed: 0.0515s/iter; left time: 1089.9201s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826628\n",
      "\tspeed: 0.0263s/iter; left time: 554.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0858948 Vali Loss: 0.0959795 Test Loss: 0.0970195\n",
      "Validation loss decreased (0.096481 --> 0.095980).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0905109\n",
      "\tspeed: 0.0516s/iter; left time: 1080.8875s\n",
      "\titers: 200, epoch: 7 | loss: 0.0828156\n",
      "\tspeed: 0.0263s/iter; left time: 548.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0842266 Vali Loss: 0.0946363 Test Loss: 0.0962865\n",
      "Validation loss decreased (0.095980 --> 0.094636).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0775391\n",
      "\tspeed: 0.0517s/iter; left time: 1071.6379s\n",
      "\titers: 200, epoch: 8 | loss: 0.0855141\n",
      "\tspeed: 0.0268s/iter; left time: 552.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0828761 Vali Loss: 0.0938537 Test Loss: 0.0953314\n",
      "Validation loss decreased (0.094636 --> 0.093854).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0816690\n",
      "\tspeed: 0.0520s/iter; left time: 1067.0735s\n",
      "\titers: 200, epoch: 9 | loss: 0.0851879\n",
      "\tspeed: 0.0264s/iter; left time: 539.0021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0829858 Vali Loss: 0.0947143 Test Loss: 0.0958647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0823175\n",
      "\tspeed: 0.0512s/iter; left time: 1039.1988s\n",
      "\titers: 200, epoch: 10 | loss: 0.0796459\n",
      "\tspeed: 0.0263s/iter; left time: 531.3518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0809271 Vali Loss: 0.0935037 Test Loss: 0.0946443\n",
      "Validation loss decreased (0.093854 --> 0.093504).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0768127\n",
      "\tspeed: 0.0528s/iter; left time: 1058.8666s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761531\n",
      "\tspeed: 0.0265s/iter; left time: 528.0351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0801934 Vali Loss: 0.0916781 Test Loss: 0.0932157\n",
      "Validation loss decreased (0.093504 --> 0.091678).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837837\n",
      "\tspeed: 0.0515s/iter; left time: 1022.5853s\n",
      "\titers: 200, epoch: 12 | loss: 0.0775089\n",
      "\tspeed: 0.0265s/iter; left time: 522.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0802700 Vali Loss: 0.0934207 Test Loss: 0.0943639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0784073\n",
      "\tspeed: 0.0511s/iter; left time: 1003.1424s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782698\n",
      "\tspeed: 0.0264s/iter; left time: 515.5103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0792549 Vali Loss: 0.0911230 Test Loss: 0.0926930\n",
      "Validation loss decreased (0.091678 --> 0.091123).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0733982\n",
      "\tspeed: 0.0512s/iter; left time: 993.5707s\n",
      "\titers: 200, epoch: 14 | loss: 0.0791362\n",
      "\tspeed: 0.0263s/iter; left time: 506.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0786626 Vali Loss: 0.0918051 Test Loss: 0.0929869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0759531\n",
      "\tspeed: 0.0514s/iter; left time: 984.9887s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776807\n",
      "\tspeed: 0.0263s/iter; left time: 501.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0783810 Vali Loss: 0.0908538 Test Loss: 0.0923476\n",
      "Validation loss decreased (0.091123 --> 0.090854).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0793302\n",
      "\tspeed: 0.0515s/iter; left time: 975.4116s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803491\n",
      "\tspeed: 0.0265s/iter; left time: 498.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0782527 Vali Loss: 0.0906397 Test Loss: 0.0923295\n",
      "Validation loss decreased (0.090854 --> 0.090640).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0744852\n",
      "\tspeed: 0.0522s/iter; left time: 976.6843s\n",
      "\titers: 200, epoch: 17 | loss: 0.0786489\n",
      "\tspeed: 0.0265s/iter; left time: 492.4357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0779015 Vali Loss: 0.0903674 Test Loss: 0.0920459\n",
      "Validation loss decreased (0.090640 --> 0.090367).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0812337\n",
      "\tspeed: 0.0523s/iter; left time: 966.3005s\n",
      "\titers: 200, epoch: 18 | loss: 0.0783246\n",
      "\tspeed: 0.0267s/iter; left time: 490.5978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0775950 Vali Loss: 0.0926962 Test Loss: 0.0936254\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784258\n",
      "\tspeed: 0.0514s/iter; left time: 938.3536s\n",
      "\titers: 200, epoch: 19 | loss: 0.0762034\n",
      "\tspeed: 0.0263s/iter; left time: 478.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0777468 Vali Loss: 0.0910056 Test Loss: 0.0922556\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0757184\n",
      "\tspeed: 0.0521s/iter; left time: 939.6522s\n",
      "\titers: 200, epoch: 20 | loss: 0.0782048\n",
      "\tspeed: 0.0265s/iter; left time: 475.0869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0774940 Vali Loss: 0.0901802 Test Loss: 0.0919014\n",
      "Validation loss decreased (0.090367 --> 0.090180).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752977\n",
      "\tspeed: 0.0520s/iter; left time: 926.6258s\n",
      "\titers: 200, epoch: 21 | loss: 0.0739630\n",
      "\tspeed: 0.0264s/iter; left time: 468.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0772572 Vali Loss: 0.0915566 Test Loss: 0.0928652\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0792587\n",
      "\tspeed: 0.0516s/iter; left time: 907.9606s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784705\n",
      "\tspeed: 0.0264s/iter; left time: 461.4505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0769730 Vali Loss: 0.0908989 Test Loss: 0.0921991\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772055\n",
      "\tspeed: 0.0514s/iter; left time: 893.6607s\n",
      "\titers: 200, epoch: 23 | loss: 0.0812640\n",
      "\tspeed: 0.0263s/iter; left time: 454.8712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0770093 Vali Loss: 0.0900116 Test Loss: 0.0918345\n",
      "Validation loss decreased (0.090180 --> 0.090012).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0803091\n",
      "\tspeed: 0.0524s/iter; left time: 897.8110s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759364\n",
      "\tspeed: 0.0262s/iter; left time: 447.2752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0770596 Vali Loss: 0.0899609 Test Loss: 0.0916573\n",
      "Validation loss decreased (0.090012 --> 0.089961).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0758617\n",
      "\tspeed: 0.0518s/iter; left time: 876.7166s\n",
      "\titers: 200, epoch: 25 | loss: 0.0737996\n",
      "\tspeed: 0.0264s/iter; left time: 443.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0769033 Vali Loss: 0.0899511 Test Loss: 0.0915681\n",
      "Validation loss decreased (0.089961 --> 0.089951).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0765661\n",
      "\tspeed: 0.0519s/iter; left time: 866.3557s\n",
      "\titers: 200, epoch: 26 | loss: 0.0763971\n",
      "\tspeed: 0.0263s/iter; left time: 437.3978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0765872 Vali Loss: 0.0900413 Test Loss: 0.0916204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0758144\n",
      "\tspeed: 0.0510s/iter; left time: 839.5982s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757976\n",
      "\tspeed: 0.0264s/iter; left time: 432.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0764685 Vali Loss: 0.0906311 Test Loss: 0.0921329\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0758253\n",
      "\tspeed: 0.0519s/iter; left time: 843.7484s\n",
      "\titers: 200, epoch: 28 | loss: 0.0753282\n",
      "\tspeed: 0.0263s/iter; left time: 424.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0765909 Vali Loss: 0.0898152 Test Loss: 0.0914769\n",
      "Validation loss decreased (0.089951 --> 0.089815).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0749874\n",
      "\tspeed: 0.0517s/iter; left time: 829.3648s\n",
      "\titers: 200, epoch: 29 | loss: 0.0735045\n",
      "\tspeed: 0.0265s/iter; left time: 422.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0764512 Vali Loss: 0.0897418 Test Loss: 0.0915002\n",
      "Validation loss decreased (0.089815 --> 0.089742).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0812473\n",
      "\tspeed: 0.0523s/iter; left time: 826.7454s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751119\n",
      "\tspeed: 0.0264s/iter; left time: 415.2961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0764347 Vali Loss: 0.0904919 Test Loss: 0.0919945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0783717\n",
      "\tspeed: 0.0513s/iter; left time: 798.7433s\n",
      "\titers: 200, epoch: 31 | loss: 0.0838023\n",
      "\tspeed: 0.0265s/iter; left time: 410.9278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0763518 Vali Loss: 0.0900647 Test Loss: 0.0916321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0714996\n",
      "\tspeed: 0.0524s/iter; left time: 805.4191s\n",
      "\titers: 200, epoch: 32 | loss: 0.0752642\n",
      "\tspeed: 0.0265s/iter; left time: 404.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0763182 Vali Loss: 0.0899387 Test Loss: 0.0916039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0770082\n",
      "\tspeed: 0.0509s/iter; left time: 770.3764s\n",
      "\titers: 200, epoch: 33 | loss: 0.0753402\n",
      "\tspeed: 0.0266s/iter; left time: 400.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0896231 Test Loss: 0.0914508\n",
      "Validation loss decreased (0.089742 --> 0.089623).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0725115\n",
      "\tspeed: 0.0526s/iter; left time: 783.9538s\n",
      "\titers: 200, epoch: 34 | loss: 0.0776233\n",
      "\tspeed: 0.0263s/iter; left time: 389.1455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0762119 Vali Loss: 0.0895975 Test Loss: 0.0913485\n",
      "Validation loss decreased (0.089623 --> 0.089597).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0771235\n",
      "\tspeed: 0.0517s/iter; left time: 759.8852s\n",
      "\titers: 200, epoch: 35 | loss: 0.0781061\n",
      "\tspeed: 0.0263s/iter; left time: 383.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0761741 Vali Loss: 0.0895915 Test Loss: 0.0913442\n",
      "Validation loss decreased (0.089597 --> 0.089591).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0696032\n",
      "\tspeed: 0.0517s/iter; left time: 748.2079s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770035\n",
      "\tspeed: 0.0263s/iter; left time: 377.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0760867 Vali Loss: 0.0900567 Test Loss: 0.0917049\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0778791\n",
      "\tspeed: 0.0509s/iter; left time: 724.6042s\n",
      "\titers: 200, epoch: 37 | loss: 0.0745140\n",
      "\tspeed: 0.0263s/iter; left time: 371.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0762562 Vali Loss: 0.0897121 Test Loss: 0.0913620\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0783371\n",
      "\tspeed: 0.0509s/iter; left time: 713.1096s\n",
      "\titers: 200, epoch: 38 | loss: 0.0818648\n",
      "\tspeed: 0.0263s/iter; left time: 365.7976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0761213 Vali Loss: 0.0900666 Test Loss: 0.0917065\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0803079\n",
      "\tspeed: 0.0513s/iter; left time: 706.7780s\n",
      "\titers: 200, epoch: 39 | loss: 0.0745575\n",
      "\tspeed: 0.0265s/iter; left time: 363.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0760805 Vali Loss: 0.0901203 Test Loss: 0.0916768\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0744408\n",
      "\tspeed: 0.0508s/iter; left time: 689.1131s\n",
      "\titers: 200, epoch: 40 | loss: 0.0698902\n",
      "\tspeed: 0.0263s/iter; left time: 354.3091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0760944 Vali Loss: 0.0897818 Test Loss: 0.0915024\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0756303\n",
      "\tspeed: 0.0513s/iter; left time: 683.9743s\n",
      "\titers: 200, epoch: 41 | loss: 0.0757952\n",
      "\tspeed: 0.0263s/iter; left time: 348.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0760046 Vali Loss: 0.0898426 Test Loss: 0.0915377\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0779208\n",
      "\tspeed: 0.0514s/iter; left time: 674.5092s\n",
      "\titers: 200, epoch: 42 | loss: 0.0747404\n",
      "\tspeed: 0.0265s/iter; left time: 345.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0761344 Vali Loss: 0.0901287 Test Loss: 0.0917811\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0771934\n",
      "\tspeed: 0.0514s/iter; left time: 662.9252s\n",
      "\titers: 200, epoch: 43 | loss: 0.0749607\n",
      "\tspeed: 0.0264s/iter; left time: 337.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0759900 Vali Loss: 0.0897255 Test Loss: 0.0914727\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0743435\n",
      "\tspeed: 0.0513s/iter; left time: 649.7218s\n",
      "\titers: 200, epoch: 44 | loss: 0.0800619\n",
      "\tspeed: 0.0263s/iter; left time: 330.9807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0760069 Vali Loss: 0.0894995 Test Loss: 0.0912929\n",
      "Validation loss decreased (0.089591 --> 0.089500).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0732608\n",
      "\tspeed: 0.0516s/iter; left time: 641.8608s\n",
      "\titers: 200, epoch: 45 | loss: 0.0766907\n",
      "\tspeed: 0.0265s/iter; left time: 327.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0759964 Vali Loss: 0.0898933 Test Loss: 0.0914188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0741571\n",
      "\tspeed: 0.0509s/iter; left time: 622.2045s\n",
      "\titers: 200, epoch: 46 | loss: 0.0754467\n",
      "\tspeed: 0.0264s/iter; left time: 319.9092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0760600 Vali Loss: 0.0897355 Test Loss: 0.0913146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0713772\n",
      "\tspeed: 0.0510s/iter; left time: 612.1991s\n",
      "\titers: 200, epoch: 47 | loss: 0.0743333\n",
      "\tspeed: 0.0262s/iter; left time: 312.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0758811 Vali Loss: 0.0899609 Test Loss: 0.0915293\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0764152\n",
      "\tspeed: 0.0509s/iter; left time: 599.2296s\n",
      "\titers: 200, epoch: 48 | loss: 0.0770819\n",
      "\tspeed: 0.0263s/iter; left time: 307.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0759072 Vali Loss: 0.0899988 Test Loss: 0.0916863\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0743392\n",
      "\tspeed: 0.0508s/iter; left time: 586.3439s\n",
      "\titers: 200, epoch: 49 | loss: 0.0781718\n",
      "\tspeed: 0.0267s/iter; left time: 305.1282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0759080 Vali Loss: 0.0899594 Test Loss: 0.0915774\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0756658\n",
      "\tspeed: 0.0511s/iter; left time: 578.9039s\n",
      "\titers: 200, epoch: 50 | loss: 0.0756160\n",
      "\tspeed: 0.0263s/iter; left time: 295.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 224 | Train Loss: 0.0759219 Vali Loss: 0.0898047 Test Loss: 0.0914517\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0815681\n",
      "\tspeed: 0.0512s/iter; left time: 568.4181s\n",
      "\titers: 200, epoch: 51 | loss: 0.0765514\n",
      "\tspeed: 0.0263s/iter; left time: 289.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0759615 Vali Loss: 0.0896021 Test Loss: 0.0913982\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0764843\n",
      "\tspeed: 0.0511s/iter; left time: 555.8316s\n",
      "\titers: 200, epoch: 52 | loss: 0.0764052\n",
      "\tspeed: 0.0264s/iter; left time: 283.9931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0758922 Vali Loss: 0.0901767 Test Loss: 0.0917404\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0747740\n",
      "\tspeed: 0.0513s/iter; left time: 546.0956s\n",
      "\titers: 200, epoch: 53 | loss: 0.0760180\n",
      "\tspeed: 0.0263s/iter; left time: 277.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0758861 Vali Loss: 0.0898443 Test Loss: 0.0914755\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0749051\n",
      "\tspeed: 0.0510s/iter; left time: 532.3610s\n",
      "\titers: 200, epoch: 54 | loss: 0.0723748\n",
      "\tspeed: 0.0263s/iter; left time: 271.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 224 | Train Loss: 0.0758602 Vali Loss: 0.0899249 Test Loss: 0.0915471\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021651936694979668, rmse:0.14714597165584564, mae:0.09129294008016586, rse:0.5192984938621521\n",
      "Intermediate time for DE and pred_len 24: 00h:13m:50.19s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2567174\n",
      "\tspeed: 0.0628s/iter; left time: 1388.0100s\n",
      "\titers: 200, epoch: 1 | loss: 0.2369715\n",
      "\tspeed: 0.0412s/iter; left time: 906.9908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.2615639 Vali Loss: 0.2209979 Test Loss: 0.2222324\n",
      "Validation loss decreased (inf --> 0.220998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1564926\n",
      "\tspeed: 0.0754s/iter; left time: 1649.4417s\n",
      "\titers: 200, epoch: 2 | loss: 0.1341260\n",
      "\tspeed: 0.0410s/iter; left time: 893.7510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1608338 Vali Loss: 0.1363482 Test Loss: 0.1418259\n",
      "Validation loss decreased (0.220998 --> 0.136348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1162611\n",
      "\tspeed: 0.0761s/iter; left time: 1649.0645s\n",
      "\titers: 200, epoch: 3 | loss: 0.1177480\n",
      "\tspeed: 0.0409s/iter; left time: 880.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1208445 Vali Loss: 0.1277944 Test Loss: 0.1374204\n",
      "Validation loss decreased (0.136348 --> 0.127794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1102845\n",
      "\tspeed: 0.0763s/iter; left time: 1636.2639s\n",
      "\titers: 200, epoch: 4 | loss: 0.1140750\n",
      "\tspeed: 0.0409s/iter; left time: 873.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1129174 Vali Loss: 0.1251605 Test Loss: 0.1341668\n",
      "Validation loss decreased (0.127794 --> 0.125161).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1166949\n",
      "\tspeed: 0.0760s/iter; left time: 1611.2576s\n",
      "\titers: 200, epoch: 5 | loss: 0.1081393\n",
      "\tspeed: 0.0407s/iter; left time: 859.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1103549 Vali Loss: 0.1227886 Test Loss: 0.1303220\n",
      "Validation loss decreased (0.125161 --> 0.122789).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062442\n",
      "\tspeed: 0.0756s/iter; left time: 1586.8452s\n",
      "\titers: 200, epoch: 6 | loss: 0.1072186\n",
      "\tspeed: 0.0409s/iter; left time: 855.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1078670 Vali Loss: 0.1219471 Test Loss: 0.1291881\n",
      "Validation loss decreased (0.122789 --> 0.121947).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1061169\n",
      "\tspeed: 0.0762s/iter; left time: 1583.3644s\n",
      "\titers: 200, epoch: 7 | loss: 0.1112051\n",
      "\tspeed: 0.0407s/iter; left time: 841.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1068713 Vali Loss: 0.1213121 Test Loss: 0.1290444\n",
      "Validation loss decreased (0.121947 --> 0.121312).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1057692\n",
      "\tspeed: 0.0757s/iter; left time: 1555.9161s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068326\n",
      "\tspeed: 0.0408s/iter; left time: 833.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1059914 Vali Loss: 0.1224635 Test Loss: 0.1298995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1034219\n",
      "\tspeed: 0.0754s/iter; left time: 1532.3575s\n",
      "\titers: 200, epoch: 9 | loss: 0.0999100\n",
      "\tspeed: 0.0408s/iter; left time: 825.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1050044 Vali Loss: 0.1230605 Test Loss: 0.1317926\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1093468\n",
      "\tspeed: 0.0748s/iter; left time: 1504.2936s\n",
      "\titers: 200, epoch: 10 | loss: 0.1081782\n",
      "\tspeed: 0.0411s/iter; left time: 821.1721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1045642 Vali Loss: 0.1219349 Test Loss: 0.1301681\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1027195\n",
      "\tspeed: 0.0743s/iter; left time: 1477.2936s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048118\n",
      "\tspeed: 0.0407s/iter; left time: 805.3636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1038951 Vali Loss: 0.1220826 Test Loss: 0.1309490\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1036500\n",
      "\tspeed: 0.0756s/iter; left time: 1486.8648s\n",
      "\titers: 200, epoch: 12 | loss: 0.0967905\n",
      "\tspeed: 0.0407s/iter; left time: 795.0850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1036535 Vali Loss: 0.1236033 Test Loss: 0.1331385\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1004048\n",
      "\tspeed: 0.0750s/iter; left time: 1457.8008s\n",
      "\titers: 200, epoch: 13 | loss: 0.0993740\n",
      "\tspeed: 0.0409s/iter; left time: 790.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1033556 Vali Loss: 0.1226675 Test Loss: 0.1322711\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1005409\n",
      "\tspeed: 0.0760s/iter; left time: 1459.5280s\n",
      "\titers: 200, epoch: 14 | loss: 0.1024006\n",
      "\tspeed: 0.0409s/iter; left time: 780.9383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1029066 Vali Loss: 0.1230128 Test Loss: 0.1320505\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1068955\n",
      "\tspeed: 0.0756s/iter; left time: 1435.2907s\n",
      "\titers: 200, epoch: 15 | loss: 0.1093898\n",
      "\tspeed: 0.0410s/iter; left time: 773.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1028959 Vali Loss: 0.1227752 Test Loss: 0.1326943\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1076504\n",
      "\tspeed: 0.0754s/iter; left time: 1416.2298s\n",
      "\titers: 200, epoch: 16 | loss: 0.0938831\n",
      "\tspeed: 0.0408s/iter; left time: 760.8655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1022091 Vali Loss: 0.1224919 Test Loss: 0.1329917\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1013022\n",
      "\tspeed: 0.0748s/iter; left time: 1387.4968s\n",
      "\titers: 200, epoch: 17 | loss: 0.1030388\n",
      "\tspeed: 0.0409s/iter; left time: 754.5603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1022000 Vali Loss: 0.1220423 Test Loss: 0.1307992\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03688869625329971, rmse:0.1920643001794815, mae:0.12904435396194458, rse:0.6801385283470154\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2674383\n",
      "\tspeed: 0.0430s/iter; left time: 951.1925s\n",
      "\titers: 200, epoch: 1 | loss: 0.2461667\n",
      "\tspeed: 0.0409s/iter; left time: 899.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.2638501 Vali Loss: 0.2226131 Test Loss: 0.2216158\n",
      "Validation loss decreased (inf --> 0.222613).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543895\n",
      "\tspeed: 0.0770s/iter; left time: 1684.2141s\n",
      "\titers: 200, epoch: 2 | loss: 0.1398169\n",
      "\tspeed: 0.0410s/iter; left time: 892.0417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1605066 Vali Loss: 0.1367813 Test Loss: 0.1428790\n",
      "Validation loss decreased (0.222613 --> 0.136781).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1166887\n",
      "\tspeed: 0.0773s/iter; left time: 1673.4618s\n",
      "\titers: 200, epoch: 3 | loss: 0.1116634\n",
      "\tspeed: 0.0410s/iter; left time: 884.7100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1194075 Vali Loss: 0.1278751 Test Loss: 0.1380406\n",
      "Validation loss decreased (0.136781 --> 0.127875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1114147\n",
      "\tspeed: 0.0766s/iter; left time: 1641.8385s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107357\n",
      "\tspeed: 0.0407s/iter; left time: 869.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1119658 Vali Loss: 0.1239229 Test Loss: 0.1325669\n",
      "Validation loss decreased (0.127875 --> 0.123923).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1104820\n",
      "\tspeed: 0.0773s/iter; left time: 1640.6833s\n",
      "\titers: 200, epoch: 5 | loss: 0.1076826\n",
      "\tspeed: 0.0410s/iter; left time: 864.8064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1088037 Vali Loss: 0.1234485 Test Loss: 0.1317335\n",
      "Validation loss decreased (0.123923 --> 0.123449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1043967\n",
      "\tspeed: 0.0769s/iter; left time: 1613.9428s\n",
      "\titers: 200, epoch: 6 | loss: 0.1043626\n",
      "\tspeed: 0.0408s/iter; left time: 853.3950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1072132 Vali Loss: 0.1251106 Test Loss: 0.1335774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1115653\n",
      "\tspeed: 0.0757s/iter; left time: 1572.3607s\n",
      "\titers: 200, epoch: 7 | loss: 0.1044515\n",
      "\tspeed: 0.0408s/iter; left time: 843.3674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1065478 Vali Loss: 0.1222214 Test Loss: 0.1305019\n",
      "Validation loss decreased (0.123449 --> 0.122221).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1077851\n",
      "\tspeed: 0.0769s/iter; left time: 1579.9063s\n",
      "\titers: 200, epoch: 8 | loss: 0.1084414\n",
      "\tspeed: 0.0410s/iter; left time: 837.7699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1052958 Vali Loss: 0.1238670 Test Loss: 0.1318427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1064024\n",
      "\tspeed: 0.0757s/iter; left time: 1538.7054s\n",
      "\titers: 200, epoch: 9 | loss: 0.1059458\n",
      "\tspeed: 0.0407s/iter; left time: 823.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1049578 Vali Loss: 0.1226378 Test Loss: 0.1321362\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1027817\n",
      "\tspeed: 0.0758s/iter; left time: 1523.4538s\n",
      "\titers: 200, epoch: 10 | loss: 0.1018352\n",
      "\tspeed: 0.0409s/iter; left time: 817.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1040832 Vali Loss: 0.1221598 Test Loss: 0.1312657\n",
      "Validation loss decreased (0.122221 --> 0.122160).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1044997\n",
      "\tspeed: 0.0763s/iter; left time: 1516.9135s\n",
      "\titers: 200, epoch: 11 | loss: 0.1089497\n",
      "\tspeed: 0.0407s/iter; left time: 804.8415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1037177 Vali Loss: 0.1224726 Test Loss: 0.1325074\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011573\n",
      "\tspeed: 0.0753s/iter; left time: 1480.9254s\n",
      "\titers: 200, epoch: 12 | loss: 0.1064023\n",
      "\tspeed: 0.0408s/iter; left time: 798.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1033040 Vali Loss: 0.1231317 Test Loss: 0.1332391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020794\n",
      "\tspeed: 0.0763s/iter; left time: 1483.3208s\n",
      "\titers: 200, epoch: 13 | loss: 0.1041973\n",
      "\tspeed: 0.0408s/iter; left time: 788.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1027258 Vali Loss: 0.1206543 Test Loss: 0.1306935\n",
      "Validation loss decreased (0.122160 --> 0.120654).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1010036\n",
      "\tspeed: 0.0767s/iter; left time: 1473.0943s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005691\n",
      "\tspeed: 0.0407s/iter; left time: 777.9007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1023238 Vali Loss: 0.1209531 Test Loss: 0.1310647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1021855\n",
      "\tspeed: 0.0757s/iter; left time: 1437.1194s\n",
      "\titers: 200, epoch: 15 | loss: 0.1030579\n",
      "\tspeed: 0.0409s/iter; left time: 773.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1019652 Vali Loss: 0.1216964 Test Loss: 0.1336367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990499\n",
      "\tspeed: 0.0751s/iter; left time: 1409.2914s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013082\n",
      "\tspeed: 0.0409s/iter; left time: 762.7429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1017566 Vali Loss: 0.1207150 Test Loss: 0.1311256\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0989789\n",
      "\tspeed: 0.0764s/iter; left time: 1417.7488s\n",
      "\titers: 200, epoch: 17 | loss: 0.1032420\n",
      "\tspeed: 0.0409s/iter; left time: 755.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1016855 Vali Loss: 0.1216641 Test Loss: 0.1335739\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1009876\n",
      "\tspeed: 0.0755s/iter; left time: 1383.5795s\n",
      "\titers: 200, epoch: 18 | loss: 0.0992788\n",
      "\tspeed: 0.0407s/iter; left time: 741.6790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1016551 Vali Loss: 0.1225416 Test Loss: 0.1356461\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0994656\n",
      "\tspeed: 0.0761s/iter; left time: 1376.9440s\n",
      "\titers: 200, epoch: 19 | loss: 0.1023100\n",
      "\tspeed: 0.0406s/iter; left time: 731.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1011918 Vali Loss: 0.1226855 Test Loss: 0.1347964\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1051435\n",
      "\tspeed: 0.0755s/iter; left time: 1350.2551s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025466\n",
      "\tspeed: 0.0409s/iter; left time: 727.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1011156 Vali Loss: 0.1218346 Test Loss: 0.1332678\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033999\n",
      "\tspeed: 0.0756s/iter; left time: 1336.0540s\n",
      "\titers: 200, epoch: 21 | loss: 0.1037384\n",
      "\tspeed: 0.0407s/iter; left time: 715.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1009183 Vali Loss: 0.1211568 Test Loss: 0.1323556\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1021763\n",
      "\tspeed: 0.0763s/iter; left time: 1331.2421s\n",
      "\titers: 200, epoch: 22 | loss: 0.0984414\n",
      "\tspeed: 0.0406s/iter; left time: 704.7040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1006230 Vali Loss: 0.1213428 Test Loss: 0.1328119\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0972030\n",
      "\tspeed: 0.0760s/iter; left time: 1308.8892s\n",
      "\titers: 200, epoch: 23 | loss: 0.0972501\n",
      "\tspeed: 0.0408s/iter; left time: 698.3746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1005551 Vali Loss: 0.1217129 Test Loss: 0.1332923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03879741579294205, rmse:0.196970596909523, mae:0.1306934952735901, rse:0.6975127458572388\n",
      "Intermediate time for DE and pred_len 96: 00h:07m:59.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2547011\n",
      "\tspeed: 0.0659s/iter; left time: 1455.6398s\n",
      "\titers: 200, epoch: 1 | loss: 0.2446538\n",
      "\tspeed: 0.0413s/iter; left time: 908.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 222 | Train Loss: 0.2621706 Vali Loss: 0.2210747 Test Loss: 0.2229995\n",
      "Validation loss decreased (inf --> 0.221075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1477357\n",
      "\tspeed: 0.0766s/iter; left time: 1676.1026s\n",
      "\titers: 200, epoch: 2 | loss: 0.1341442\n",
      "\tspeed: 0.0412s/iter; left time: 898.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1630918 Vali Loss: 0.1387679 Test Loss: 0.1472351\n",
      "Validation loss decreased (0.221075 --> 0.138768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1283511\n",
      "\tspeed: 0.0767s/iter; left time: 1660.0239s\n",
      "\titers: 200, epoch: 3 | loss: 0.1233076\n",
      "\tspeed: 0.0414s/iter; left time: 891.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1242776 Vali Loss: 0.1343270 Test Loss: 0.1477458\n",
      "Validation loss decreased (0.138768 --> 0.134327).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1228040\n",
      "\tspeed: 0.0773s/iter; left time: 1656.7594s\n",
      "\titers: 200, epoch: 4 | loss: 0.1145430\n",
      "\tspeed: 0.0412s/iter; left time: 879.8497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1177692 Vali Loss: 0.1332793 Test Loss: 0.1471356\n",
      "Validation loss decreased (0.134327 --> 0.133279).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1108847\n",
      "\tspeed: 0.0781s/iter; left time: 1656.7242s\n",
      "\titers: 200, epoch: 5 | loss: 0.1184591\n",
      "\tspeed: 0.0411s/iter; left time: 868.7648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1150895 Vali Loss: 0.1292599 Test Loss: 0.1394582\n",
      "Validation loss decreased (0.133279 --> 0.129260).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1109404\n",
      "\tspeed: 0.0758s/iter; left time: 1590.2715s\n",
      "\titers: 200, epoch: 6 | loss: 0.1151391\n",
      "\tspeed: 0.0412s/iter; left time: 860.7552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1130198 Vali Loss: 0.1282362 Test Loss: 0.1374332\n",
      "Validation loss decreased (0.129260 --> 0.128236).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1107276\n",
      "\tspeed: 0.0768s/iter; left time: 1594.0727s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117783\n",
      "\tspeed: 0.0412s/iter; left time: 851.7463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1117408 Vali Loss: 0.1297795 Test Loss: 0.1401883\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1098032\n",
      "\tspeed: 0.0762s/iter; left time: 1566.2717s\n",
      "\titers: 200, epoch: 8 | loss: 0.1121785\n",
      "\tspeed: 0.0411s/iter; left time: 840.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1110236 Vali Loss: 0.1291916 Test Loss: 0.1372601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1095344\n",
      "\tspeed: 0.0760s/iter; left time: 1544.2785s\n",
      "\titers: 200, epoch: 9 | loss: 0.1124224\n",
      "\tspeed: 0.0411s/iter; left time: 831.4406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1099584 Vali Loss: 0.1276474 Test Loss: 0.1373459\n",
      "Validation loss decreased (0.128236 --> 0.127647).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1069649\n",
      "\tspeed: 0.0765s/iter; left time: 1538.7754s\n",
      "\titers: 200, epoch: 10 | loss: 0.1128789\n",
      "\tspeed: 0.0412s/iter; left time: 824.2495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1094869 Vali Loss: 0.1279376 Test Loss: 0.1391968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1130599\n",
      "\tspeed: 0.0768s/iter; left time: 1527.6429s\n",
      "\titers: 200, epoch: 11 | loss: 0.1103044\n",
      "\tspeed: 0.0411s/iter; left time: 813.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1087799 Vali Loss: 0.1274702 Test Loss: 0.1376306\n",
      "Validation loss decreased (0.127647 --> 0.127470).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1128469\n",
      "\tspeed: 0.0771s/iter; left time: 1514.9593s\n",
      "\titers: 200, epoch: 12 | loss: 0.1105351\n",
      "\tspeed: 0.0413s/iter; left time: 808.1190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1082214 Vali Loss: 0.1273075 Test Loss: 0.1389605\n",
      "Validation loss decreased (0.127470 --> 0.127308).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1044768\n",
      "\tspeed: 0.0771s/iter; left time: 1499.1437s\n",
      "\titers: 200, epoch: 13 | loss: 0.1075517\n",
      "\tspeed: 0.0411s/iter; left time: 794.5731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1078091 Vali Loss: 0.1270512 Test Loss: 0.1373295\n",
      "Validation loss decreased (0.127308 --> 0.127051).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1049805\n",
      "\tspeed: 0.0777s/iter; left time: 1492.5376s\n",
      "\titers: 200, epoch: 14 | loss: 0.1062305\n",
      "\tspeed: 0.0411s/iter; left time: 786.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1075614 Vali Loss: 0.1272584 Test Loss: 0.1405276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1024106\n",
      "\tspeed: 0.0761s/iter; left time: 1444.7472s\n",
      "\titers: 200, epoch: 15 | loss: 0.1068587\n",
      "\tspeed: 0.0412s/iter; left time: 778.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1072686 Vali Loss: 0.1271282 Test Loss: 0.1395907\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1049831\n",
      "\tspeed: 0.0761s/iter; left time: 1428.1250s\n",
      "\titers: 200, epoch: 16 | loss: 0.1086448\n",
      "\tspeed: 0.0411s/iter; left time: 766.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1069641 Vali Loss: 0.1280589 Test Loss: 0.1429418\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1084256\n",
      "\tspeed: 0.0753s/iter; left time: 1396.3966s\n",
      "\titers: 200, epoch: 17 | loss: 0.1095028\n",
      "\tspeed: 0.0411s/iter; left time: 757.4327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1066884 Vali Loss: 0.1263519 Test Loss: 0.1385314\n",
      "Validation loss decreased (0.127051 --> 0.126352).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1123055\n",
      "\tspeed: 0.0773s/iter; left time: 1416.9853s\n",
      "\titers: 200, epoch: 18 | loss: 0.1091762\n",
      "\tspeed: 0.0411s/iter; left time: 749.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1065208 Vali Loss: 0.1267130 Test Loss: 0.1371872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1051615\n",
      "\tspeed: 0.0758s/iter; left time: 1373.1484s\n",
      "\titers: 200, epoch: 19 | loss: 0.1084474\n",
      "\tspeed: 0.0411s/iter; left time: 739.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1062202 Vali Loss: 0.1266989 Test Loss: 0.1404610\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1065915\n",
      "\tspeed: 0.0763s/iter; left time: 1365.3596s\n",
      "\titers: 200, epoch: 20 | loss: 0.1041478\n",
      "\tspeed: 0.0411s/iter; left time: 730.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1061190 Vali Loss: 0.1269398 Test Loss: 0.1404824\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1061094\n",
      "\tspeed: 0.0755s/iter; left time: 1334.2136s\n",
      "\titers: 200, epoch: 21 | loss: 0.1058959\n",
      "\tspeed: 0.0415s/iter; left time: 728.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1059716 Vali Loss: 0.1267279 Test Loss: 0.1402840\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1044017\n",
      "\tspeed: 0.0755s/iter; left time: 1316.3296s\n",
      "\titers: 200, epoch: 22 | loss: 0.1075009\n",
      "\tspeed: 0.0414s/iter; left time: 718.3517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1057801 Vali Loss: 0.1281811 Test Loss: 0.1419328\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1047539\n",
      "\tspeed: 0.0758s/iter; left time: 1305.3737s\n",
      "\titers: 200, epoch: 23 | loss: 0.1052754\n",
      "\tspeed: 0.0410s/iter; left time: 701.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1056472 Vali Loss: 0.1271066 Test Loss: 0.1417327\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1032366\n",
      "\tspeed: 0.0759s/iter; left time: 1289.4818s\n",
      "\titers: 200, epoch: 24 | loss: 0.1044951\n",
      "\tspeed: 0.0411s/iter; left time: 693.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1055431 Vali Loss: 0.1264203 Test Loss: 0.1404810\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1115490\n",
      "\tspeed: 0.0749s/iter; left time: 1256.6678s\n",
      "\titers: 200, epoch: 25 | loss: 0.1035964\n",
      "\tspeed: 0.0411s/iter; left time: 686.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1053842 Vali Loss: 0.1263358 Test Loss: 0.1400815\n",
      "Validation loss decreased (0.126352 --> 0.126336).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1036159\n",
      "\tspeed: 0.0761s/iter; left time: 1259.7895s\n",
      "\titers: 200, epoch: 26 | loss: 0.1037731\n",
      "\tspeed: 0.0411s/iter; left time: 675.4162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1051834 Vali Loss: 0.1265433 Test Loss: 0.1410923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1022529\n",
      "\tspeed: 0.0753s/iter; left time: 1229.3054s\n",
      "\titers: 200, epoch: 27 | loss: 0.1063197\n",
      "\tspeed: 0.0412s/iter; left time: 667.9426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1051369 Vali Loss: 0.1266984 Test Loss: 0.1409570\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1050435\n",
      "\tspeed: 0.0764s/iter; left time: 1231.3200s\n",
      "\titers: 200, epoch: 28 | loss: 0.1088132\n",
      "\tspeed: 0.0411s/iter; left time: 658.0444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1050999 Vali Loss: 0.1260449 Test Loss: 0.1398182\n",
      "Validation loss decreased (0.126336 --> 0.126045).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1074791\n",
      "\tspeed: 0.0766s/iter; left time: 1216.7442s\n",
      "\titers: 200, epoch: 29 | loss: 0.1086402\n",
      "\tspeed: 0.0412s/iter; left time: 650.8129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1049540 Vali Loss: 0.1264877 Test Loss: 0.1398621\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1017556\n",
      "\tspeed: 0.0749s/iter; left time: 1173.1060s\n",
      "\titers: 200, epoch: 30 | loss: 0.1018851\n",
      "\tspeed: 0.0412s/iter; left time: 640.5907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1050275 Vali Loss: 0.1266508 Test Loss: 0.1413750\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1069471\n",
      "\tspeed: 0.0754s/iter; left time: 1163.7781s\n",
      "\titers: 200, epoch: 31 | loss: 0.1028269\n",
      "\tspeed: 0.0411s/iter; left time: 630.5249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1049095 Vali Loss: 0.1261828 Test Loss: 0.1394460\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1106816\n",
      "\tspeed: 0.0761s/iter; left time: 1157.5232s\n",
      "\titers: 200, epoch: 32 | loss: 0.1046448\n",
      "\tspeed: 0.0412s/iter; left time: 622.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1047826 Vali Loss: 0.1264209 Test Loss: 0.1406406\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1042348\n",
      "\tspeed: 0.0758s/iter; left time: 1136.8372s\n",
      "\titers: 200, epoch: 33 | loss: 0.1059592\n",
      "\tspeed: 0.0411s/iter; left time: 612.9490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1047775 Vali Loss: 0.1266658 Test Loss: 0.1412112\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1083043\n",
      "\tspeed: 0.0753s/iter; left time: 1113.1941s\n",
      "\titers: 200, epoch: 34 | loss: 0.1091277\n",
      "\tspeed: 0.0410s/iter; left time: 601.9288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1047314 Vali Loss: 0.1269310 Test Loss: 0.1415482\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1050427\n",
      "\tspeed: 0.0746s/iter; left time: 1085.8634s\n",
      "\titers: 200, epoch: 35 | loss: 0.1053451\n",
      "\tspeed: 0.0411s/iter; left time: 593.8324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1046090 Vali Loss: 0.1260353 Test Loss: 0.1401784\n",
      "Validation loss decreased (0.126045 --> 0.126035).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1072772\n",
      "\tspeed: 0.0758s/iter; left time: 1086.7973s\n",
      "\titers: 200, epoch: 36 | loss: 0.1069313\n",
      "\tspeed: 0.0410s/iter; left time: 584.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1046577 Vali Loss: 0.1265546 Test Loss: 0.1414028\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1073018\n",
      "\tspeed: 0.0749s/iter; left time: 1056.0987s\n",
      "\titers: 200, epoch: 37 | loss: 0.1043714\n",
      "\tspeed: 0.0410s/iter; left time: 574.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1046224 Vali Loss: 0.1261640 Test Loss: 0.1402127\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1110265\n",
      "\tspeed: 0.0759s/iter; left time: 1053.3801s\n",
      "\titers: 200, epoch: 38 | loss: 0.1001320\n",
      "\tspeed: 0.0410s/iter; left time: 565.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1045099 Vali Loss: 0.1261084 Test Loss: 0.1405019\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1004808\n",
      "\tspeed: 0.0753s/iter; left time: 1028.4516s\n",
      "\titers: 200, epoch: 39 | loss: 0.1060599\n",
      "\tspeed: 0.0411s/iter; left time: 558.1876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1045482 Vali Loss: 0.1261528 Test Loss: 0.1404652\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1076685\n",
      "\tspeed: 0.0749s/iter; left time: 1007.5148s\n",
      "\titers: 200, epoch: 40 | loss: 0.1019712\n",
      "\tspeed: 0.0411s/iter; left time: 548.3667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1044784 Vali Loss: 0.1262912 Test Loss: 0.1407943\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1066837\n",
      "\tspeed: 0.0756s/iter; left time: 999.6501s\n",
      "\titers: 200, epoch: 41 | loss: 0.1006510\n",
      "\tspeed: 0.0413s/iter; left time: 541.9486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1045106 Vali Loss: 0.1259988 Test Loss: 0.1401316\n",
      "Validation loss decreased (0.126035 --> 0.125999).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1069852\n",
      "\tspeed: 0.0774s/iter; left time: 1006.1285s\n",
      "\titers: 200, epoch: 42 | loss: 0.1012278\n",
      "\tspeed: 0.0411s/iter; left time: 529.9154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1044709 Vali Loss: 0.1263843 Test Loss: 0.1406530\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1050513\n",
      "\tspeed: 0.0751s/iter; left time: 958.9403s\n",
      "\titers: 200, epoch: 43 | loss: 0.1035220\n",
      "\tspeed: 0.0412s/iter; left time: 521.8023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1044019 Vali Loss: 0.1262721 Test Loss: 0.1411214\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1099950\n",
      "\tspeed: 0.0762s/iter; left time: 956.2018s\n",
      "\titers: 200, epoch: 44 | loss: 0.1008029\n",
      "\tspeed: 0.0413s/iter; left time: 514.0173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1043530 Vali Loss: 0.1268223 Test Loss: 0.1418868\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1062310\n",
      "\tspeed: 0.0748s/iter; left time: 922.6622s\n",
      "\titers: 200, epoch: 45 | loss: 0.0978017\n",
      "\tspeed: 0.0411s/iter; left time: 502.9413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1043717 Vali Loss: 0.1263294 Test Loss: 0.1411482\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1073297\n",
      "\tspeed: 0.0739s/iter; left time: 895.3941s\n",
      "\titers: 200, epoch: 46 | loss: 0.1029892\n",
      "\tspeed: 0.0411s/iter; left time: 493.3324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1043665 Vali Loss: 0.1261325 Test Loss: 0.1409885\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1039653\n",
      "\tspeed: 0.0761s/iter; left time: 905.1491s\n",
      "\titers: 200, epoch: 47 | loss: 0.1021439\n",
      "\tspeed: 0.0411s/iter; left time: 484.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1044277 Vali Loss: 0.1264205 Test Loss: 0.1413692\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1047657\n",
      "\tspeed: 0.0753s/iter; left time: 879.0226s\n",
      "\titers: 200, epoch: 48 | loss: 0.1039199\n",
      "\tspeed: 0.0410s/iter; left time: 474.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1043820 Vali Loss: 0.1264119 Test Loss: 0.1411667\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1022447\n",
      "\tspeed: 0.0757s/iter; left time: 866.2159s\n",
      "\titers: 200, epoch: 49 | loss: 0.1015952\n",
      "\tspeed: 0.0412s/iter; left time: 467.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1043758 Vali Loss: 0.1260933 Test Loss: 0.1404598\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1026140\n",
      "\tspeed: 0.0743s/iter; left time: 834.1814s\n",
      "\titers: 200, epoch: 50 | loss: 0.0980135\n",
      "\tspeed: 0.0412s/iter; left time: 457.9941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1043637 Vali Loss: 0.1261517 Test Loss: 0.1409613\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.1067247\n",
      "\tspeed: 0.0754s/iter; left time: 829.5468s\n",
      "\titers: 200, epoch: 51 | loss: 0.1038287\n",
      "\tspeed: 0.0412s/iter; left time: 449.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1043192 Vali Loss: 0.1263004 Test Loss: 0.1410258\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04456966370344162, rmse:0.2111152857542038, mae:0.14013166725635529, rse:0.747787356376648\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2695983\n",
      "\tspeed: 0.0435s/iter; left time: 960.9874s\n",
      "\titers: 200, epoch: 1 | loss: 0.2458136\n",
      "\tspeed: 0.0412s/iter; left time: 905.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.2653355 Vali Loss: 0.2224486 Test Loss: 0.2230866\n",
      "Validation loss decreased (inf --> 0.222449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1459184\n",
      "\tspeed: 0.0775s/iter; left time: 1695.2316s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344317\n",
      "\tspeed: 0.0411s/iter; left time: 894.6112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1615751 Vali Loss: 0.1398708 Test Loss: 0.1480999\n",
      "Validation loss decreased (0.222449 --> 0.139871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1242755\n",
      "\tspeed: 0.0788s/iter; left time: 1705.8541s\n",
      "\titers: 200, epoch: 3 | loss: 0.1158472\n",
      "\tspeed: 0.0413s/iter; left time: 889.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1242331 Vali Loss: 0.1310286 Test Loss: 0.1426450\n",
      "Validation loss decreased (0.139871 --> 0.131029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1153544\n",
      "\tspeed: 0.0851s/iter; left time: 1824.0587s\n",
      "\titers: 200, epoch: 4 | loss: 0.1145391\n",
      "\tspeed: 0.0412s/iter; left time: 878.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1171351 Vali Loss: 0.1277771 Test Loss: 0.1371709\n",
      "Validation loss decreased (0.131029 --> 0.127777).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1219279\n",
      "\tspeed: 0.0780s/iter; left time: 1653.8863s\n",
      "\titers: 200, epoch: 5 | loss: 0.1114400\n",
      "\tspeed: 0.0411s/iter; left time: 867.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1141187 Vali Loss: 0.1312206 Test Loss: 0.1432557\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1113654\n",
      "\tspeed: 0.0761s/iter; left time: 1596.7595s\n",
      "\titers: 200, epoch: 6 | loss: 0.1110327\n",
      "\tspeed: 0.0410s/iter; left time: 857.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1122951 Vali Loss: 0.1279132 Test Loss: 0.1393908\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1125884\n",
      "\tspeed: 0.0772s/iter; left time: 1602.6943s\n",
      "\titers: 200, epoch: 7 | loss: 0.1114042\n",
      "\tspeed: 0.0410s/iter; left time: 848.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1113330 Vali Loss: 0.1264910 Test Loss: 0.1378686\n",
      "Validation loss decreased (0.127777 --> 0.126491).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1113305\n",
      "\tspeed: 0.0778s/iter; left time: 1598.4130s\n",
      "\titers: 200, epoch: 8 | loss: 0.1078927\n",
      "\tspeed: 0.0410s/iter; left time: 839.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1103155 Vali Loss: 0.1271214 Test Loss: 0.1400218\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1121107\n",
      "\tspeed: 0.0766s/iter; left time: 1556.5739s\n",
      "\titers: 200, epoch: 9 | loss: 0.1082017\n",
      "\tspeed: 0.0413s/iter; left time: 836.0363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1099665 Vali Loss: 0.1268901 Test Loss: 0.1410304\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1071596\n",
      "\tspeed: 0.0771s/iter; left time: 1549.6833s\n",
      "\titers: 200, epoch: 10 | loss: 0.1088479\n",
      "\tspeed: 0.0411s/iter; left time: 822.6311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1091042 Vali Loss: 0.1271832 Test Loss: 0.1428634\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1068706\n",
      "\tspeed: 0.0762s/iter; left time: 1515.5644s\n",
      "\titers: 200, epoch: 11 | loss: 0.1111364\n",
      "\tspeed: 0.0413s/iter; left time: 816.2670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1084925 Vali Loss: 0.1307015 Test Loss: 0.1492935\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1100810\n",
      "\tspeed: 0.0774s/iter; left time: 1520.8222s\n",
      "\titers: 200, epoch: 12 | loss: 0.1114843\n",
      "\tspeed: 0.0412s/iter; left time: 805.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.1080450 Vali Loss: 0.1283088 Test Loss: 0.1461065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1144699\n",
      "\tspeed: 0.0764s/iter; left time: 1484.2761s\n",
      "\titers: 200, epoch: 13 | loss: 0.1059909\n",
      "\tspeed: 0.0411s/iter; left time: 794.5458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1073719 Vali Loss: 0.1269572 Test Loss: 0.1428572\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083283\n",
      "\tspeed: 0.0763s/iter; left time: 1466.8498s\n",
      "\titers: 200, epoch: 14 | loss: 0.1086156\n",
      "\tspeed: 0.0411s/iter; left time: 786.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1069796 Vali Loss: 0.1259924 Test Loss: 0.1436143\n",
      "Validation loss decreased (0.126491 --> 0.125992).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1066480\n",
      "\tspeed: 0.0780s/iter; left time: 1482.3102s\n",
      "\titers: 200, epoch: 15 | loss: 0.1062846\n",
      "\tspeed: 0.0411s/iter; left time: 777.0487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1068378 Vali Loss: 0.1262309 Test Loss: 0.1440513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067633\n",
      "\tspeed: 0.0765s/iter; left time: 1435.6313s\n",
      "\titers: 200, epoch: 16 | loss: 0.1104817\n",
      "\tspeed: 0.0412s/iter; left time: 769.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1063836 Vali Loss: 0.1261759 Test Loss: 0.1427229\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1053825\n",
      "\tspeed: 0.0766s/iter; left time: 1420.5417s\n",
      "\titers: 200, epoch: 17 | loss: 0.1034071\n",
      "\tspeed: 0.0410s/iter; left time: 756.5807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1059606 Vali Loss: 0.1266880 Test Loss: 0.1433154\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1074457\n",
      "\tspeed: 0.0763s/iter; left time: 1398.0312s\n",
      "\titers: 200, epoch: 18 | loss: 0.1025829\n",
      "\tspeed: 0.0411s/iter; left time: 748.5073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1056170 Vali Loss: 0.1255190 Test Loss: 0.1441649\n",
      "Validation loss decreased (0.125992 --> 0.125519).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1041701\n",
      "\tspeed: 0.0774s/iter; left time: 1401.8615s\n",
      "\titers: 200, epoch: 19 | loss: 0.1018132\n",
      "\tspeed: 0.0412s/iter; left time: 740.9868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1052355 Vali Loss: 0.1258863 Test Loss: 0.1445787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1048761\n",
      "\tspeed: 0.0761s/iter; left time: 1360.8724s\n",
      "\titers: 200, epoch: 20 | loss: 0.1065127\n",
      "\tspeed: 0.0412s/iter; left time: 732.6337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1051658 Vali Loss: 0.1252106 Test Loss: 0.1429672\n",
      "Validation loss decreased (0.125519 --> 0.125211).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1035283\n",
      "\tspeed: 0.0769s/iter; left time: 1357.3456s\n",
      "\titers: 200, epoch: 21 | loss: 0.1084166\n",
      "\tspeed: 0.0411s/iter; left time: 721.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1050887 Vali Loss: 0.1262848 Test Loss: 0.1436059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1018366\n",
      "\tspeed: 0.0779s/iter; left time: 1359.2956s\n",
      "\titers: 200, epoch: 22 | loss: 0.1031664\n",
      "\tspeed: 0.0411s/iter; left time: 712.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.1047694 Vali Loss: 0.1251836 Test Loss: 0.1430537\n",
      "Validation loss decreased (0.125211 --> 0.125184).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1010575\n",
      "\tspeed: 0.0776s/iter; left time: 1335.4983s\n",
      "\titers: 200, epoch: 23 | loss: 0.1016529\n",
      "\tspeed: 0.0410s/iter; left time: 701.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1047283 Vali Loss: 0.1250855 Test Loss: 0.1421348\n",
      "Validation loss decreased (0.125184 --> 0.125085).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1066785\n",
      "\tspeed: 0.0774s/iter; left time: 1316.1817s\n",
      "\titers: 200, epoch: 24 | loss: 0.1021970\n",
      "\tspeed: 0.0411s/iter; left time: 694.2526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1045605 Vali Loss: 0.1252609 Test Loss: 0.1430158\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1062797\n",
      "\tspeed: 0.0768s/iter; left time: 1288.2655s\n",
      "\titers: 200, epoch: 25 | loss: 0.1052838\n",
      "\tspeed: 0.0412s/iter; left time: 687.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1042314 Vali Loss: 0.1257189 Test Loss: 0.1448543\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1088224\n",
      "\tspeed: 0.0765s/iter; left time: 1266.0218s\n",
      "\titers: 200, epoch: 26 | loss: 0.1028319\n",
      "\tspeed: 0.0411s/iter; left time: 676.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1042463 Vali Loss: 0.1254094 Test Loss: 0.1445392\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1050898\n",
      "\tspeed: 0.0764s/iter; left time: 1248.0756s\n",
      "\titers: 200, epoch: 27 | loss: 0.1036657\n",
      "\tspeed: 0.0411s/iter; left time: 667.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1041168 Vali Loss: 0.1252972 Test Loss: 0.1431515\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1059706\n",
      "\tspeed: 0.0763s/iter; left time: 1229.3850s\n",
      "\titers: 200, epoch: 28 | loss: 0.1038235\n",
      "\tspeed: 0.0410s/iter; left time: 656.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1038388 Vali Loss: 0.1252899 Test Loss: 0.1423092\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1048199\n",
      "\tspeed: 0.0766s/iter; left time: 1217.3585s\n",
      "\titers: 200, epoch: 29 | loss: 0.1049025\n",
      "\tspeed: 0.0412s/iter; left time: 650.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1037922 Vali Loss: 0.1254297 Test Loss: 0.1428744\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1042742\n",
      "\tspeed: 0.0760s/iter; left time: 1190.2551s\n",
      "\titers: 200, epoch: 30 | loss: 0.1088455\n",
      "\tspeed: 0.0414s/iter; left time: 643.9882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1037990 Vali Loss: 0.1253161 Test Loss: 0.1436195\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1021391\n",
      "\tspeed: 0.0767s/iter; left time: 1184.9977s\n",
      "\titers: 200, epoch: 31 | loss: 0.1076526\n",
      "\tspeed: 0.0411s/iter; left time: 629.8870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1036785 Vali Loss: 0.1253694 Test Loss: 0.1436673\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0983822\n",
      "\tspeed: 0.0762s/iter; left time: 1159.9313s\n",
      "\titers: 200, epoch: 32 | loss: 0.1030093\n",
      "\tspeed: 0.0411s/iter; left time: 621.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1036134 Vali Loss: 0.1252570 Test Loss: 0.1444752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1020824\n",
      "\tspeed: 0.0768s/iter; left time: 1152.4882s\n",
      "\titers: 200, epoch: 33 | loss: 0.1070113\n",
      "\tspeed: 0.0412s/iter; left time: 614.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1035500 Vali Loss: 0.1254304 Test Loss: 0.1442089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04730448126792908, rmse:0.21749593317508698, mae:0.14213477075099945, rse:0.770388126373291\n",
      "Intermediate time for DE and pred_len 168: 00h:16m:40.88s\n",
      "Intermediate time for DE: 00h:38m:30.83s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2713369\n",
      "\tspeed: 0.0642s/iter; left time: 1426.1914s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666838\n",
      "\tspeed: 0.0406s/iter; left time: 896.4586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.2775031 Vali Loss: 0.2227723 Test Loss: 0.2392421\n",
      "Validation loss decreased (inf --> 0.222772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1425531\n",
      "\tspeed: 0.0736s/iter; left time: 1618.4386s\n",
      "\titers: 200, epoch: 2 | loss: 0.1142946\n",
      "\tspeed: 0.0404s/iter; left time: 883.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 223 | Train Loss: 0.1516249 Vali Loss: 0.1061840 Test Loss: 0.1243391\n",
      "Validation loss decreased (0.222772 --> 0.106184).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1043676\n",
      "\tspeed: 0.0740s/iter; left time: 1608.9193s\n",
      "\titers: 200, epoch: 3 | loss: 0.0964127\n",
      "\tspeed: 0.0405s/iter; left time: 876.3062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.1000793 Vali Loss: 0.0966325 Test Loss: 0.1096701\n",
      "Validation loss decreased (0.106184 --> 0.096632).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971016\n",
      "\tspeed: 0.0745s/iter; left time: 1604.4450s\n",
      "\titers: 200, epoch: 4 | loss: 0.0946171\n",
      "\tspeed: 0.0404s/iter; left time: 866.2746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0896545 Vali Loss: 0.0937908 Test Loss: 0.1082869\n",
      "Validation loss decreased (0.096632 --> 0.093791).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815196\n",
      "\tspeed: 0.0736s/iter; left time: 1567.2898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0840815\n",
      "\tspeed: 0.0404s/iter; left time: 856.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0858922 Vali Loss: 0.0940853 Test Loss: 0.1072255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0800261\n",
      "\tspeed: 0.0738s/iter; left time: 1556.8144s\n",
      "\titers: 200, epoch: 6 | loss: 0.0847688\n",
      "\tspeed: 0.0404s/iter; left time: 848.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0843575 Vali Loss: 0.0934700 Test Loss: 0.1070231\n",
      "Validation loss decreased (0.093791 --> 0.093470).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830629\n",
      "\tspeed: 0.0735s/iter; left time: 1532.6763s\n",
      "\titers: 200, epoch: 7 | loss: 0.0818849\n",
      "\tspeed: 0.0405s/iter; left time: 840.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0830517 Vali Loss: 0.0935562 Test Loss: 0.1062768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0861846\n",
      "\tspeed: 0.0726s/iter; left time: 1498.8984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820004\n",
      "\tspeed: 0.0405s/iter; left time: 831.0199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0825876 Vali Loss: 0.0935195 Test Loss: 0.1072546\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0820624\n",
      "\tspeed: 0.0733s/iter; left time: 1496.6125s\n",
      "\titers: 200, epoch: 9 | loss: 0.0781329\n",
      "\tspeed: 0.0404s/iter; left time: 821.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0817799 Vali Loss: 0.0945552 Test Loss: 0.1062779\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0802087\n",
      "\tspeed: 0.0729s/iter; left time: 1472.0468s\n",
      "\titers: 200, epoch: 10 | loss: 0.0832409\n",
      "\tspeed: 0.0407s/iter; left time: 818.2452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0810398 Vali Loss: 0.0922729 Test Loss: 0.1053363\n",
      "Validation loss decreased (0.093470 --> 0.092273).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0854504\n",
      "\tspeed: 0.0736s/iter; left time: 1470.1661s\n",
      "\titers: 200, epoch: 11 | loss: 0.0827603\n",
      "\tspeed: 0.0405s/iter; left time: 804.0218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0806057 Vali Loss: 0.0923044 Test Loss: 0.1049127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715239\n",
      "\tspeed: 0.0728s/iter; left time: 1437.5269s\n",
      "\titers: 200, epoch: 12 | loss: 0.0846490\n",
      "\tspeed: 0.0406s/iter; left time: 798.0289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0804665 Vali Loss: 0.0916704 Test Loss: 0.1046567\n",
      "Validation loss decreased (0.092273 --> 0.091670).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0789320\n",
      "\tspeed: 0.0735s/iter; left time: 1435.9416s\n",
      "\titers: 200, epoch: 13 | loss: 0.0801651\n",
      "\tspeed: 0.0404s/iter; left time: 784.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0798680 Vali Loss: 0.0913420 Test Loss: 0.1045888\n",
      "Validation loss decreased (0.091670 --> 0.091342).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795190\n",
      "\tspeed: 0.0740s/iter; left time: 1427.8847s\n",
      "\titers: 200, epoch: 14 | loss: 0.0791162\n",
      "\tspeed: 0.0405s/iter; left time: 777.1902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0797841 Vali Loss: 0.0914175 Test Loss: 0.1047300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0785403\n",
      "\tspeed: 0.0732s/iter; left time: 1396.1154s\n",
      "\titers: 200, epoch: 15 | loss: 0.0783143\n",
      "\tspeed: 0.0404s/iter; left time: 766.6822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0794608 Vali Loss: 0.0913306 Test Loss: 0.1041831\n",
      "Validation loss decreased (0.091342 --> 0.091331).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0761678\n",
      "\tspeed: 0.0737s/iter; left time: 1389.3648s\n",
      "\titers: 200, epoch: 16 | loss: 0.0737287\n",
      "\tspeed: 0.0404s/iter; left time: 758.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0792677 Vali Loss: 0.0918222 Test Loss: 0.1056311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0833909\n",
      "\tspeed: 0.0731s/iter; left time: 1361.4509s\n",
      "\titers: 200, epoch: 17 | loss: 0.0813364\n",
      "\tspeed: 0.0406s/iter; left time: 751.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0788700 Vali Loss: 0.0909332 Test Loss: 0.1044233\n",
      "Validation loss decreased (0.091331 --> 0.090933).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0786313\n",
      "\tspeed: 0.0738s/iter; left time: 1358.7282s\n",
      "\titers: 200, epoch: 18 | loss: 0.0771805\n",
      "\tspeed: 0.0404s/iter; left time: 740.1378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0787176 Vali Loss: 0.0909456 Test Loss: 0.1046183\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0785226\n",
      "\tspeed: 0.0728s/iter; left time: 1323.6296s\n",
      "\titers: 200, epoch: 19 | loss: 0.0825728\n",
      "\tspeed: 0.0408s/iter; left time: 738.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0784871 Vali Loss: 0.0913229 Test Loss: 0.1046131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0773899\n",
      "\tspeed: 0.0730s/iter; left time: 1312.1622s\n",
      "\titers: 200, epoch: 20 | loss: 0.0719374\n",
      "\tspeed: 0.0406s/iter; left time: 724.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0783474 Vali Loss: 0.0913036 Test Loss: 0.1047586\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0767777\n",
      "\tspeed: 0.0737s/iter; left time: 1306.6265s\n",
      "\titers: 200, epoch: 21 | loss: 0.0832794\n",
      "\tspeed: 0.0405s/iter; left time: 713.7119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0781011 Vali Loss: 0.0910498 Test Loss: 0.1046779\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0779329\n",
      "\tspeed: 0.0732s/iter; left time: 1282.5354s\n",
      "\titers: 200, epoch: 22 | loss: 0.0787014\n",
      "\tspeed: 0.0404s/iter; left time: 704.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0782003 Vali Loss: 0.0910638 Test Loss: 0.1044707\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0808069\n",
      "\tspeed: 0.0743s/iter; left time: 1284.7940s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714334\n",
      "\tspeed: 0.0404s/iter; left time: 695.0588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0781985 Vali Loss: 0.0906492 Test Loss: 0.1044392\n",
      "Validation loss decreased (0.090933 --> 0.090649).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0796330\n",
      "\tspeed: 0.0730s/iter; left time: 1246.6551s\n",
      "\titers: 200, epoch: 24 | loss: 0.0792855\n",
      "\tspeed: 0.0404s/iter; left time: 685.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0781420 Vali Loss: 0.0928221 Test Loss: 0.1059146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0789801\n",
      "\tspeed: 0.0738s/iter; left time: 1242.9445s\n",
      "\titers: 200, epoch: 25 | loss: 0.0770648\n",
      "\tspeed: 0.0405s/iter; left time: 678.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0778025 Vali Loss: 0.0910814 Test Loss: 0.1047692\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0750756\n",
      "\tspeed: 0.0735s/iter; left time: 1222.6360s\n",
      "\titers: 200, epoch: 26 | loss: 0.0734449\n",
      "\tspeed: 0.0405s/iter; left time: 668.7703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0777318 Vali Loss: 0.0906680 Test Loss: 0.1045140\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0786629\n",
      "\tspeed: 0.0731s/iter; left time: 1199.1492s\n",
      "\titers: 200, epoch: 27 | loss: 0.0804909\n",
      "\tspeed: 0.0404s/iter; left time: 659.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0775561 Vali Loss: 0.0909488 Test Loss: 0.1053258\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0729849\n",
      "\tspeed: 0.0735s/iter; left time: 1188.6991s\n",
      "\titers: 200, epoch: 28 | loss: 0.0823348\n",
      "\tspeed: 0.0406s/iter; left time: 652.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0775038 Vali Loss: 0.0906877 Test Loss: 0.1043712\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0803065\n",
      "\tspeed: 0.0728s/iter; left time: 1161.3404s\n",
      "\titers: 200, epoch: 29 | loss: 0.0776471\n",
      "\tspeed: 0.0404s/iter; left time: 641.1638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0775364 Vali Loss: 0.0904995 Test Loss: 0.1043667\n",
      "Validation loss decreased (0.090649 --> 0.090499).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0795126\n",
      "\tspeed: 0.0740s/iter; left time: 1164.1134s\n",
      "\titers: 200, epoch: 30 | loss: 0.0834667\n",
      "\tspeed: 0.0405s/iter; left time: 632.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0774307 Vali Loss: 0.0906215 Test Loss: 0.1045543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0763445\n",
      "\tspeed: 0.0729s/iter; left time: 1131.1346s\n",
      "\titers: 200, epoch: 31 | loss: 0.0814237\n",
      "\tspeed: 0.0404s/iter; left time: 622.7547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0773705 Vali Loss: 0.0906609 Test Loss: 0.1045952\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0799850\n",
      "\tspeed: 0.0731s/iter; left time: 1117.6484s\n",
      "\titers: 200, epoch: 32 | loss: 0.0796433\n",
      "\tspeed: 0.0405s/iter; left time: 614.7204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0773739 Vali Loss: 0.0906913 Test Loss: 0.1047461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0764047\n",
      "\tspeed: 0.0733s/iter; left time: 1103.7078s\n",
      "\titers: 200, epoch: 33 | loss: 0.0748812\n",
      "\tspeed: 0.0404s/iter; left time: 605.2630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0772914 Vali Loss: 0.0904291 Test Loss: 0.1046706\n",
      "Validation loss decreased (0.090499 --> 0.090429).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0757065\n",
      "\tspeed: 0.0744s/iter; left time: 1104.3862s\n",
      "\titers: 200, epoch: 34 | loss: 0.0784300\n",
      "\tspeed: 0.0404s/iter; left time: 595.8476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0774925 Vali Loss: 0.0904285 Test Loss: 0.1045240\n",
      "Validation loss decreased (0.090429 --> 0.090428).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0789417\n",
      "\tspeed: 0.0737s/iter; left time: 1077.2250s\n",
      "\titers: 200, epoch: 35 | loss: 0.0795636\n",
      "\tspeed: 0.0404s/iter; left time: 587.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0772180 Vali Loss: 0.0903595 Test Loss: 0.1044108\n",
      "Validation loss decreased (0.090428 --> 0.090360).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0779223\n",
      "\tspeed: 0.0741s/iter; left time: 1067.2375s\n",
      "\titers: 200, epoch: 36 | loss: 0.0729762\n",
      "\tspeed: 0.0405s/iter; left time: 578.6734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0771922 Vali Loss: 0.0907313 Test Loss: 0.1047319\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0809649\n",
      "\tspeed: 0.0729s/iter; left time: 1032.8605s\n",
      "\titers: 200, epoch: 37 | loss: 0.0781822\n",
      "\tspeed: 0.0404s/iter; left time: 568.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0771938 Vali Loss: 0.0908119 Test Loss: 0.1048842\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0790581\n",
      "\tspeed: 0.0730s/iter; left time: 1018.4860s\n",
      "\titers: 200, epoch: 38 | loss: 0.0769915\n",
      "\tspeed: 0.0405s/iter; left time: 560.7515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0771616 Vali Loss: 0.0907066 Test Loss: 0.1046624\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0794891\n",
      "\tspeed: 0.0736s/iter; left time: 1010.2209s\n",
      "\titers: 200, epoch: 39 | loss: 0.0770491\n",
      "\tspeed: 0.0405s/iter; left time: 551.6163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0770720 Vali Loss: 0.0905792 Test Loss: 0.1047044\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0841586\n",
      "\tspeed: 0.0729s/iter; left time: 984.7676s\n",
      "\titers: 200, epoch: 40 | loss: 0.0748983\n",
      "\tspeed: 0.0409s/iter; left time: 547.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0771946 Vali Loss: 0.0904707 Test Loss: 0.1045962\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0774204\n",
      "\tspeed: 0.0731s/iter; left time: 970.2207s\n",
      "\titers: 200, epoch: 41 | loss: 0.0755066\n",
      "\tspeed: 0.0405s/iter; left time: 533.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0771183 Vali Loss: 0.0908790 Test Loss: 0.1048907\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0775084\n",
      "\tspeed: 0.0732s/iter; left time: 956.0669s\n",
      "\titers: 200, epoch: 42 | loss: 0.0691002\n",
      "\tspeed: 0.0404s/iter; left time: 524.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0771249 Vali Loss: 0.0906246 Test Loss: 0.1047030\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0784101\n",
      "\tspeed: 0.0732s/iter; left time: 940.1250s\n",
      "\titers: 200, epoch: 43 | loss: 0.0804814\n",
      "\tspeed: 0.0404s/iter; left time: 514.9575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0770689 Vali Loss: 0.0905814 Test Loss: 0.1046426\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0731711\n",
      "\tspeed: 0.0733s/iter; left time: 924.2530s\n",
      "\titers: 200, epoch: 44 | loss: 0.0752849\n",
      "\tspeed: 0.0406s/iter; left time: 508.3404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0769947 Vali Loss: 0.0905712 Test Loss: 0.1047970\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0773128\n",
      "\tspeed: 0.0739s/iter; left time: 915.1414s\n",
      "\titers: 200, epoch: 45 | loss: 0.0740729\n",
      "\tspeed: 0.0407s/iter; left time: 500.0395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0770263 Vali Loss: 0.0906391 Test Loss: 0.1048571\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026252198964357376, rmse:0.1620253026485443, mae:0.10441073030233383, rse:0.5589413642883301\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2769710\n",
      "\tspeed: 0.0422s/iter; left time: 936.9427s\n",
      "\titers: 200, epoch: 1 | loss: 0.2703775\n",
      "\tspeed: 0.0404s/iter; left time: 893.2489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.2823273 Vali Loss: 0.2324963 Test Loss: 0.2465261\n",
      "Validation loss decreased (inf --> 0.232496).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1442659\n",
      "\tspeed: 0.0752s/iter; left time: 1653.5216s\n",
      "\titers: 200, epoch: 2 | loss: 0.1169949\n",
      "\tspeed: 0.0405s/iter; left time: 887.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.1555963 Vali Loss: 0.1053269 Test Loss: 0.1230106\n",
      "Validation loss decreased (0.232496 --> 0.105327).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0988071\n",
      "\tspeed: 0.0756s/iter; left time: 1644.9951s\n",
      "\titers: 200, epoch: 3 | loss: 0.0924419\n",
      "\tspeed: 0.0405s/iter; left time: 877.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0987847 Vali Loss: 0.0956057 Test Loss: 0.1094963\n",
      "Validation loss decreased (0.105327 --> 0.095606).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0906304\n",
      "\tspeed: 0.0741s/iter; left time: 1595.9171s\n",
      "\titers: 200, epoch: 4 | loss: 0.0859146\n",
      "\tspeed: 0.0406s/iter; left time: 870.8884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0896020 Vali Loss: 0.0942191 Test Loss: 0.1084674\n",
      "Validation loss decreased (0.095606 --> 0.094219).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0833325\n",
      "\tspeed: 0.0744s/iter; left time: 1586.0871s\n",
      "\titers: 200, epoch: 5 | loss: 0.0874665\n",
      "\tspeed: 0.0404s/iter; left time: 857.5373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0865134 Vali Loss: 0.0941752 Test Loss: 0.1083765\n",
      "Validation loss decreased (0.094219 --> 0.094175).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809869\n",
      "\tspeed: 0.0748s/iter; left time: 1577.3494s\n",
      "\titers: 200, epoch: 6 | loss: 0.0877753\n",
      "\tspeed: 0.0404s/iter; left time: 848.5874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0840436 Vali Loss: 0.0927668 Test Loss: 0.1062152\n",
      "Validation loss decreased (0.094175 --> 0.092767).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832490\n",
      "\tspeed: 0.0747s/iter; left time: 1558.7404s\n",
      "\titers: 200, epoch: 7 | loss: 0.0829870\n",
      "\tspeed: 0.0405s/iter; left time: 839.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0835418 Vali Loss: 0.0924259 Test Loss: 0.1067966\n",
      "Validation loss decreased (0.092767 --> 0.092426).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0888897\n",
      "\tspeed: 0.0747s/iter; left time: 1542.5103s\n",
      "\titers: 200, epoch: 8 | loss: 0.0776150\n",
      "\tspeed: 0.0405s/iter; left time: 832.2374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0817162 Vali Loss: 0.0922475 Test Loss: 0.1054070\n",
      "Validation loss decreased (0.092426 --> 0.092248).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843962\n",
      "\tspeed: 0.0742s/iter; left time: 1514.0752s\n",
      "\titers: 200, epoch: 9 | loss: 0.0838336\n",
      "\tspeed: 0.0405s/iter; left time: 821.9022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0816821 Vali Loss: 0.0933507 Test Loss: 0.1062168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0810641\n",
      "\tspeed: 0.0744s/iter; left time: 1502.5885s\n",
      "\titers: 200, epoch: 10 | loss: 0.0758244\n",
      "\tspeed: 0.0405s/iter; left time: 813.9880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0805795 Vali Loss: 0.0916511 Test Loss: 0.1045354\n",
      "Validation loss decreased (0.092248 --> 0.091651).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0785524\n",
      "\tspeed: 0.0747s/iter; left time: 1492.0473s\n",
      "\titers: 200, epoch: 11 | loss: 0.0734199\n",
      "\tspeed: 0.0404s/iter; left time: 802.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0804764 Vali Loss: 0.0922665 Test Loss: 0.1044703\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0815930\n",
      "\tspeed: 0.0741s/iter; left time: 1463.5480s\n",
      "\titers: 200, epoch: 12 | loss: 0.0852654\n",
      "\tspeed: 0.0405s/iter; left time: 796.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0801125 Vali Loss: 0.0941295 Test Loss: 0.1052972\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0784688\n",
      "\tspeed: 0.0745s/iter; left time: 1455.5487s\n",
      "\titers: 200, epoch: 13 | loss: 0.0802191\n",
      "\tspeed: 0.0405s/iter; left time: 786.6449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0796360 Vali Loss: 0.0911914 Test Loss: 0.1038486\n",
      "Validation loss decreased (0.091651 --> 0.091191).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0795192\n",
      "\tspeed: 0.0744s/iter; left time: 1436.1961s\n",
      "\titers: 200, epoch: 14 | loss: 0.0730847\n",
      "\tspeed: 0.0405s/iter; left time: 776.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0789982 Vali Loss: 0.0926355 Test Loss: 0.1048882\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0796765\n",
      "\tspeed: 0.0743s/iter; left time: 1417.1129s\n",
      "\titers: 200, epoch: 15 | loss: 0.0771256\n",
      "\tspeed: 0.0404s/iter; left time: 767.4386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0790234 Vali Loss: 0.0907969 Test Loss: 0.1034538\n",
      "Validation loss decreased (0.091191 --> 0.090797).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0818546\n",
      "\tspeed: 0.0750s/iter; left time: 1413.9264s\n",
      "\titers: 200, epoch: 16 | loss: 0.0809140\n",
      "\tspeed: 0.0405s/iter; left time: 760.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0784743 Vali Loss: 0.0916429 Test Loss: 0.1039903\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0794071\n",
      "\tspeed: 0.0747s/iter; left time: 1392.2929s\n",
      "\titers: 200, epoch: 17 | loss: 0.0774146\n",
      "\tspeed: 0.0405s/iter; left time: 750.5844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0785013 Vali Loss: 0.0909371 Test Loss: 0.1035683\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0766296\n",
      "\tspeed: 0.0744s/iter; left time: 1369.0815s\n",
      "\titers: 200, epoch: 18 | loss: 0.0832104\n",
      "\tspeed: 0.0405s/iter; left time: 741.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0784101 Vali Loss: 0.0908933 Test Loss: 0.1042490\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0762396\n",
      "\tspeed: 0.0737s/iter; left time: 1341.2443s\n",
      "\titers: 200, epoch: 19 | loss: 0.0799202\n",
      "\tspeed: 0.0405s/iter; left time: 732.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0783316 Vali Loss: 0.0916444 Test Loss: 0.1038889\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802529\n",
      "\tspeed: 0.0745s/iter; left time: 1337.9869s\n",
      "\titers: 200, epoch: 20 | loss: 0.0766167\n",
      "\tspeed: 0.0404s/iter; left time: 722.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0781671 Vali Loss: 0.0909578 Test Loss: 0.1033743\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0780121\n",
      "\tspeed: 0.0742s/iter; left time: 1315.8856s\n",
      "\titers: 200, epoch: 21 | loss: 0.0757186\n",
      "\tspeed: 0.0411s/iter; left time: 725.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0778531 Vali Loss: 0.0906028 Test Loss: 0.1035582\n",
      "Validation loss decreased (0.090797 --> 0.090603).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0755088\n",
      "\tspeed: 0.0748s/iter; left time: 1310.5108s\n",
      "\titers: 200, epoch: 22 | loss: 0.0724161\n",
      "\tspeed: 0.0406s/iter; left time: 706.5124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0779181 Vali Loss: 0.0907662 Test Loss: 0.1033700\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0793474\n",
      "\tspeed: 0.0742s/iter; left time: 1283.5519s\n",
      "\titers: 200, epoch: 23 | loss: 0.0752869\n",
      "\tspeed: 0.0405s/iter; left time: 696.5507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0778138 Vali Loss: 0.0906027 Test Loss: 0.1033847\n",
      "Validation loss decreased (0.090603 --> 0.090603).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0718337\n",
      "\tspeed: 0.0744s/iter; left time: 1270.7808s\n",
      "\titers: 200, epoch: 24 | loss: 0.0822986\n",
      "\tspeed: 0.0406s/iter; left time: 688.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0774387 Vali Loss: 0.0905964 Test Loss: 0.1033350\n",
      "Validation loss decreased (0.090603 --> 0.090596).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0781854\n",
      "\tspeed: 0.0745s/iter; left time: 1254.6554s\n",
      "\titers: 200, epoch: 25 | loss: 0.0776588\n",
      "\tspeed: 0.0405s/iter; left time: 678.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0773905 Vali Loss: 0.0911812 Test Loss: 0.1039794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0843180\n",
      "\tspeed: 0.0743s/iter; left time: 1234.5543s\n",
      "\titers: 200, epoch: 26 | loss: 0.0786229\n",
      "\tspeed: 0.0405s/iter; left time: 669.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0774403 Vali Loss: 0.0905203 Test Loss: 0.1033267\n",
      "Validation loss decreased (0.090596 --> 0.090520).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0778569\n",
      "\tspeed: 0.0743s/iter; left time: 1219.0835s\n",
      "\titers: 200, epoch: 27 | loss: 0.0760914\n",
      "\tspeed: 0.0404s/iter; left time: 659.4523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0773498 Vali Loss: 0.0905446 Test Loss: 0.1034297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0765770\n",
      "\tspeed: 0.0744s/iter; left time: 1203.1410s\n",
      "\titers: 200, epoch: 28 | loss: 0.0764705\n",
      "\tspeed: 0.0406s/iter; left time: 652.0977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0774625 Vali Loss: 0.0907428 Test Loss: 0.1031926\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0801089\n",
      "\tspeed: 0.0742s/iter; left time: 1184.2724s\n",
      "\titers: 200, epoch: 29 | loss: 0.0829091\n",
      "\tspeed: 0.0405s/iter; left time: 641.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0771658 Vali Loss: 0.0908485 Test Loss: 0.1035190\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0761231\n",
      "\tspeed: 0.0744s/iter; left time: 1171.0462s\n",
      "\titers: 200, epoch: 30 | loss: 0.0838616\n",
      "\tspeed: 0.0405s/iter; left time: 632.4530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0771273 Vali Loss: 0.0904082 Test Loss: 0.1034668\n",
      "Validation loss decreased (0.090520 --> 0.090408).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0791246\n",
      "\tspeed: 0.0746s/iter; left time: 1156.6156s\n",
      "\titers: 200, epoch: 31 | loss: 0.0760335\n",
      "\tspeed: 0.0404s/iter; left time: 622.7406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0771556 Vali Loss: 0.0904834 Test Loss: 0.1033723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0727148\n",
      "\tspeed: 0.0739s/iter; left time: 1129.9757s\n",
      "\titers: 200, epoch: 32 | loss: 0.0771118\n",
      "\tspeed: 0.0405s/iter; left time: 615.4426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0770119 Vali Loss: 0.0905958 Test Loss: 0.1032845\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0780054\n",
      "\tspeed: 0.0745s/iter; left time: 1122.0629s\n",
      "\titers: 200, epoch: 33 | loss: 0.0763030\n",
      "\tspeed: 0.0404s/iter; left time: 604.9782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0770482 Vali Loss: 0.0905138 Test Loss: 0.1034147\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0723855\n",
      "\tspeed: 0.0740s/iter; left time: 1098.3092s\n",
      "\titers: 200, epoch: 34 | loss: 0.0809077\n",
      "\tspeed: 0.0405s/iter; left time: 597.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0769784 Vali Loss: 0.0901652 Test Loss: 0.1032317\n",
      "Validation loss decreased (0.090408 --> 0.090165).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0753601\n",
      "\tspeed: 0.0743s/iter; left time: 1085.6582s\n",
      "\titers: 200, epoch: 35 | loss: 0.0833676\n",
      "\tspeed: 0.0404s/iter; left time: 586.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0770012 Vali Loss: 0.0904131 Test Loss: 0.1032534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0741394\n",
      "\tspeed: 0.0736s/iter; left time: 1059.4413s\n",
      "\titers: 200, epoch: 36 | loss: 0.0772207\n",
      "\tspeed: 0.0404s/iter; left time: 578.1975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0768503 Vali Loss: 0.0902097 Test Loss: 0.1032458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0748613\n",
      "\tspeed: 0.0738s/iter; left time: 1045.4778s\n",
      "\titers: 200, epoch: 37 | loss: 0.0764078\n",
      "\tspeed: 0.0404s/iter; left time: 569.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0768296 Vali Loss: 0.0906790 Test Loss: 0.1035006\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0836533\n",
      "\tspeed: 0.0739s/iter; left time: 1030.3494s\n",
      "\titers: 200, epoch: 38 | loss: 0.0738607\n",
      "\tspeed: 0.0405s/iter; left time: 561.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0768080 Vali Loss: 0.0905389 Test Loss: 0.1032715\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0852324\n",
      "\tspeed: 0.0734s/iter; left time: 1008.1749s\n",
      "\titers: 200, epoch: 39 | loss: 0.0836052\n",
      "\tspeed: 0.0404s/iter; left time: 551.1308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0769123 Vali Loss: 0.0903165 Test Loss: 0.1031685\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0723093\n",
      "\tspeed: 0.0737s/iter; left time: 995.6857s\n",
      "\titers: 200, epoch: 40 | loss: 0.0770771\n",
      "\tspeed: 0.0405s/iter; left time: 542.2184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0767563 Vali Loss: 0.0902461 Test Loss: 0.1032339\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0769785\n",
      "\tspeed: 0.0738s/iter; left time: 979.6360s\n",
      "\titers: 200, epoch: 41 | loss: 0.0785568\n",
      "\tspeed: 0.0404s/iter; left time: 532.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0768789 Vali Loss: 0.0903825 Test Loss: 0.1032286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0765508\n",
      "\tspeed: 0.0740s/iter; left time: 966.8555s\n",
      "\titers: 200, epoch: 42 | loss: 0.0757153\n",
      "\tspeed: 0.0407s/iter; left time: 526.8323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0767883 Vali Loss: 0.0905485 Test Loss: 0.1033848\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0777456\n",
      "\tspeed: 0.0736s/iter; left time: 944.6847s\n",
      "\titers: 200, epoch: 43 | loss: 0.0803093\n",
      "\tspeed: 0.0404s/iter; left time: 514.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0768418 Vali Loss: 0.0903485 Test Loss: 0.1032215\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0777099\n",
      "\tspeed: 0.0737s/iter; left time: 929.3859s\n",
      "\titers: 200, epoch: 44 | loss: 0.0776393\n",
      "\tspeed: 0.0404s/iter; left time: 505.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0767603 Vali Loss: 0.0905746 Test Loss: 0.1033903\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02546694502234459, rmse:0.1595836579799652, mae:0.10323171317577362, rse:0.5505183935165405\n",
      "Intermediate time for GB and pred_len 24: 00h:17m:10.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2754908\n",
      "\tspeed: 0.0654s/iter; left time: 1445.2351s\n",
      "\titers: 200, epoch: 1 | loss: 0.2565268\n",
      "\tspeed: 0.0408s/iter; left time: 896.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 222 | Train Loss: 0.2785139 Vali Loss: 0.2301577 Test Loss: 0.2489777\n",
      "Validation loss decreased (inf --> 0.230158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1454410\n",
      "\tspeed: 0.0743s/iter; left time: 1626.4319s\n",
      "\titers: 200, epoch: 2 | loss: 0.1294792\n",
      "\tspeed: 0.0408s/iter; left time: 889.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1582182 Vali Loss: 0.1259280 Test Loss: 0.1505259\n",
      "Validation loss decreased (0.230158 --> 0.125928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1139631\n",
      "\tspeed: 0.0758s/iter; left time: 1642.2493s\n",
      "\titers: 200, epoch: 3 | loss: 0.1146949\n",
      "\tspeed: 0.0407s/iter; left time: 876.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1160379 Vali Loss: 0.1217796 Test Loss: 0.1469357\n",
      "Validation loss decreased (0.125928 --> 0.121780).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1060906\n",
      "\tspeed: 0.0755s/iter; left time: 1618.8844s\n",
      "\titers: 200, epoch: 4 | loss: 0.1110405\n",
      "\tspeed: 0.0407s/iter; left time: 869.0712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1105263 Vali Loss: 0.1205399 Test Loss: 0.1479875\n",
      "Validation loss decreased (0.121780 --> 0.120540).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1105473\n",
      "\tspeed: 0.0755s/iter; left time: 1600.8842s\n",
      "\titers: 200, epoch: 5 | loss: 0.1073875\n",
      "\tspeed: 0.0408s/iter; left time: 860.5413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1084831 Vali Loss: 0.1211721 Test Loss: 0.1462333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1060356\n",
      "\tspeed: 0.0748s/iter; left time: 1570.8243s\n",
      "\titers: 200, epoch: 6 | loss: 0.1084735\n",
      "\tspeed: 0.0409s/iter; left time: 855.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1067980 Vali Loss: 0.1211017 Test Loss: 0.1448717\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1049255\n",
      "\tspeed: 0.0742s/iter; left time: 1540.1646s\n",
      "\titers: 200, epoch: 7 | loss: 0.1024340\n",
      "\tspeed: 0.0408s/iter; left time: 843.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1059185 Vali Loss: 0.1197927 Test Loss: 0.1431326\n",
      "Validation loss decreased (0.120540 --> 0.119793).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1077000\n",
      "\tspeed: 0.0756s/iter; left time: 1552.6685s\n",
      "\titers: 200, epoch: 8 | loss: 0.1062740\n",
      "\tspeed: 0.0408s/iter; left time: 833.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1051765 Vali Loss: 0.1208388 Test Loss: 0.1449344\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1044981\n",
      "\tspeed: 0.0745s/iter; left time: 1514.6372s\n",
      "\titers: 200, epoch: 9 | loss: 0.1011425\n",
      "\tspeed: 0.0409s/iter; left time: 827.9057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1047338 Vali Loss: 0.1204256 Test Loss: 0.1450119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024128\n",
      "\tspeed: 0.0751s/iter; left time: 1509.6850s\n",
      "\titers: 200, epoch: 10 | loss: 0.1052173\n",
      "\tspeed: 0.0407s/iter; left time: 813.6001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1041979 Vali Loss: 0.1203746 Test Loss: 0.1434776\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1026772\n",
      "\tspeed: 0.0750s/iter; left time: 1491.2236s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031066\n",
      "\tspeed: 0.0408s/iter; left time: 806.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1035710 Vali Loss: 0.1205041 Test Loss: 0.1424923\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1012086\n",
      "\tspeed: 0.0746s/iter; left time: 1466.9986s\n",
      "\titers: 200, epoch: 12 | loss: 0.1012537\n",
      "\tspeed: 0.0407s/iter; left time: 796.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1031444 Vali Loss: 0.1206255 Test Loss: 0.1456862\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0988313\n",
      "\tspeed: 0.0750s/iter; left time: 1458.6676s\n",
      "\titers: 200, epoch: 13 | loss: 0.1054351\n",
      "\tspeed: 0.0407s/iter; left time: 787.2148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1028723 Vali Loss: 0.1207204 Test Loss: 0.1443202\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1001708\n",
      "\tspeed: 0.0750s/iter; left time: 1440.9286s\n",
      "\titers: 200, epoch: 14 | loss: 0.1036020\n",
      "\tspeed: 0.0407s/iter; left time: 778.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1025796 Vali Loss: 0.1213824 Test Loss: 0.1413605\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1079437\n",
      "\tspeed: 0.0744s/iter; left time: 1412.1922s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065903\n",
      "\tspeed: 0.0407s/iter; left time: 768.8275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1024036 Vali Loss: 0.1207993 Test Loss: 0.1439709\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1031587\n",
      "\tspeed: 0.0742s/iter; left time: 1393.1864s\n",
      "\titers: 200, epoch: 16 | loss: 0.0969950\n",
      "\tspeed: 0.0407s/iter; left time: 760.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1019742 Vali Loss: 0.1192834 Test Loss: 0.1435636\n",
      "Validation loss decreased (0.119793 --> 0.119283).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1015605\n",
      "\tspeed: 0.0743s/iter; left time: 1377.5497s\n",
      "\titers: 200, epoch: 17 | loss: 0.1000266\n",
      "\tspeed: 0.0407s/iter; left time: 751.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1017171 Vali Loss: 0.1209069 Test Loss: 0.1445591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1034859\n",
      "\tspeed: 0.0737s/iter; left time: 1349.9659s\n",
      "\titers: 200, epoch: 18 | loss: 0.1006415\n",
      "\tspeed: 0.0408s/iter; left time: 743.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1016131 Vali Loss: 0.1202661 Test Loss: 0.1447202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0975137\n",
      "\tspeed: 0.0741s/iter; left time: 1341.5279s\n",
      "\titers: 200, epoch: 19 | loss: 0.1048678\n",
      "\tspeed: 0.0408s/iter; left time: 734.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1013461 Vali Loss: 0.1196784 Test Loss: 0.1444775\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0967539\n",
      "\tspeed: 0.0740s/iter; left time: 1323.4880s\n",
      "\titers: 200, epoch: 20 | loss: 0.1014193\n",
      "\tspeed: 0.0408s/iter; left time: 725.7344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1012372 Vali Loss: 0.1201976 Test Loss: 0.1447031\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1000276\n",
      "\tspeed: 0.0744s/iter; left time: 1314.8539s\n",
      "\titers: 200, epoch: 21 | loss: 0.1064060\n",
      "\tspeed: 0.0407s/iter; left time: 714.7966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1009980 Vali Loss: 0.1195866 Test Loss: 0.1452566\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0979460\n",
      "\tspeed: 0.0738s/iter; left time: 1286.8706s\n",
      "\titers: 200, epoch: 22 | loss: 0.0992387\n",
      "\tspeed: 0.0408s/iter; left time: 708.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1010185 Vali Loss: 0.1197461 Test Loss: 0.1442865\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0942505\n",
      "\tspeed: 0.0739s/iter; left time: 1271.8307s\n",
      "\titers: 200, epoch: 23 | loss: 0.0990180\n",
      "\tspeed: 0.0410s/iter; left time: 702.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1007635 Vali Loss: 0.1201730 Test Loss: 0.1457032\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0997986\n",
      "\tspeed: 0.0738s/iter; left time: 1254.8725s\n",
      "\titers: 200, epoch: 24 | loss: 0.1051661\n",
      "\tspeed: 0.0407s/iter; left time: 687.4366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1006523 Vali Loss: 0.1204499 Test Loss: 0.1449772\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0943325\n",
      "\tspeed: 0.0744s/iter; left time: 1248.4015s\n",
      "\titers: 200, epoch: 25 | loss: 0.1028278\n",
      "\tspeed: 0.0408s/iter; left time: 679.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1005114 Vali Loss: 0.1195987 Test Loss: 0.1457044\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0993995\n",
      "\tspeed: 0.0738s/iter; left time: 1221.8400s\n",
      "\titers: 200, epoch: 26 | loss: 0.1025434\n",
      "\tspeed: 0.0407s/iter; left time: 669.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1004969 Vali Loss: 0.1198426 Test Loss: 0.1459493\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04348594695329666, rmse:0.20853284001350403, mae:0.14356358349323273, rse:0.7211356163024902\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2774166\n",
      "\tspeed: 0.0426s/iter; left time: 942.1830s\n",
      "\titers: 200, epoch: 1 | loss: 0.2675685\n",
      "\tspeed: 0.0408s/iter; left time: 898.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.2809886 Vali Loss: 0.2336099 Test Loss: 0.2500508\n",
      "Validation loss decreased (inf --> 0.233610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1459654\n",
      "\tspeed: 0.0762s/iter; left time: 1667.1326s\n",
      "\titers: 200, epoch: 2 | loss: 0.1273764\n",
      "\tspeed: 0.0411s/iter; left time: 896.1594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1587790 Vali Loss: 0.1263587 Test Loss: 0.1510657\n",
      "Validation loss decreased (0.233610 --> 0.126359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1151451\n",
      "\tspeed: 0.0761s/iter; left time: 1648.5984s\n",
      "\titers: 200, epoch: 3 | loss: 0.1132580\n",
      "\tspeed: 0.0407s/iter; left time: 876.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1159257 Vali Loss: 0.1221918 Test Loss: 0.1485164\n",
      "Validation loss decreased (0.126359 --> 0.122192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1162400\n",
      "\tspeed: 0.0761s/iter; left time: 1630.1607s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102432\n",
      "\tspeed: 0.0408s/iter; left time: 870.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1102180 Vali Loss: 0.1223790 Test Loss: 0.1495408\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053681\n",
      "\tspeed: 0.0759s/iter; left time: 1610.8944s\n",
      "\titers: 200, epoch: 5 | loss: 0.1080542\n",
      "\tspeed: 0.0408s/iter; left time: 861.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1080120 Vali Loss: 0.1205955 Test Loss: 0.1468638\n",
      "Validation loss decreased (0.122192 --> 0.120595).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1048465\n",
      "\tspeed: 0.0758s/iter; left time: 1592.0341s\n",
      "\titers: 200, epoch: 6 | loss: 0.1037291\n",
      "\tspeed: 0.0408s/iter; left time: 852.3388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1066948 Vali Loss: 0.1201176 Test Loss: 0.1445497\n",
      "Validation loss decreased (0.120595 --> 0.120118).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1026185\n",
      "\tspeed: 0.0759s/iter; left time: 1577.0352s\n",
      "\titers: 200, epoch: 7 | loss: 0.1106706\n",
      "\tspeed: 0.0408s/iter; left time: 842.5379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1056956 Vali Loss: 0.1220439 Test Loss: 0.1470570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1022454\n",
      "\tspeed: 0.0753s/iter; left time: 1546.2830s\n",
      "\titers: 200, epoch: 8 | loss: 0.1057987\n",
      "\tspeed: 0.0408s/iter; left time: 833.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1047436 Vali Loss: 0.1197518 Test Loss: 0.1431227\n",
      "Validation loss decreased (0.120118 --> 0.119752).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0995139\n",
      "\tspeed: 0.0760s/iter; left time: 1543.9720s\n",
      "\titers: 200, epoch: 9 | loss: 0.1068991\n",
      "\tspeed: 0.0407s/iter; left time: 823.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1040069 Vali Loss: 0.1207591 Test Loss: 0.1448716\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0977267\n",
      "\tspeed: 0.0754s/iter; left time: 1515.2548s\n",
      "\titers: 200, epoch: 10 | loss: 0.1050342\n",
      "\tspeed: 0.0407s/iter; left time: 813.6096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1034888 Vali Loss: 0.1209808 Test Loss: 0.1457036\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1062801\n",
      "\tspeed: 0.0751s/iter; left time: 1492.5965s\n",
      "\titers: 200, epoch: 11 | loss: 0.1037657\n",
      "\tspeed: 0.0408s/iter; left time: 806.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1032361 Vali Loss: 0.1218010 Test Loss: 0.1467660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1031072\n",
      "\tspeed: 0.0764s/iter; left time: 1502.4624s\n",
      "\titers: 200, epoch: 12 | loss: 0.1042846\n",
      "\tspeed: 0.0408s/iter; left time: 797.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1025889 Vali Loss: 0.1222248 Test Loss: 0.1471041\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1004958\n",
      "\tspeed: 0.0760s/iter; left time: 1478.1091s\n",
      "\titers: 200, epoch: 13 | loss: 0.1037003\n",
      "\tspeed: 0.0407s/iter; left time: 787.8146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1026253 Vali Loss: 0.1218507 Test Loss: 0.1469564\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0960027\n",
      "\tspeed: 0.0748s/iter; left time: 1437.5752s\n",
      "\titers: 200, epoch: 14 | loss: 0.1035357\n",
      "\tspeed: 0.0407s/iter; left time: 778.1344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1021841 Vali Loss: 0.1208755 Test Loss: 0.1459521\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1015870\n",
      "\tspeed: 0.0750s/iter; left time: 1424.3674s\n",
      "\titers: 200, epoch: 15 | loss: 0.1023352\n",
      "\tspeed: 0.0408s/iter; left time: 770.9132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1016365 Vali Loss: 0.1208185 Test Loss: 0.1465824\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990154\n",
      "\tspeed: 0.0753s/iter; left time: 1414.3787s\n",
      "\titers: 200, epoch: 16 | loss: 0.1074008\n",
      "\tspeed: 0.0407s/iter; left time: 760.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.1014939 Vali Loss: 0.1214339 Test Loss: 0.1468978\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1053690\n",
      "\tspeed: 0.0750s/iter; left time: 1392.0747s\n",
      "\titers: 200, epoch: 17 | loss: 0.1010550\n",
      "\tspeed: 0.0408s/iter; left time: 752.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1012388 Vali Loss: 0.1209148 Test Loss: 0.1468553\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0994772\n",
      "\tspeed: 0.0755s/iter; left time: 1383.4358s\n",
      "\titers: 200, epoch: 18 | loss: 0.0990921\n",
      "\tspeed: 0.0407s/iter; left time: 742.2632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1008607 Vali Loss: 0.1210824 Test Loss: 0.1476732\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042964570224285126, rmse:0.20727896690368652, mae:0.14312276244163513, rse:0.7167995572090149\n",
      "Intermediate time for GB and pred_len 96: 00h:08m:42.42s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2716153\n",
      "\tspeed: 0.0660s/iter; left time: 1459.4963s\n",
      "\titers: 200, epoch: 1 | loss: 0.2638517\n",
      "\tspeed: 0.0412s/iter; left time: 907.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.2787672 Vali Loss: 0.2309910 Test Loss: 0.2493199\n",
      "Validation loss decreased (inf --> 0.230991).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1443525\n",
      "\tspeed: 0.0764s/iter; left time: 1672.1266s\n",
      "\titers: 200, epoch: 2 | loss: 0.1273726\n",
      "\tspeed: 0.0413s/iter; left time: 898.8461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1594456 Vali Loss: 0.1297770 Test Loss: 0.1556951\n",
      "Validation loss decreased (0.230991 --> 0.129777).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1201734\n",
      "\tspeed: 0.0771s/iter; left time: 1669.4693s\n",
      "\titers: 200, epoch: 3 | loss: 0.1219832\n",
      "\tspeed: 0.0413s/iter; left time: 890.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1194605 Vali Loss: 0.1255238 Test Loss: 0.1545679\n",
      "Validation loss decreased (0.129777 --> 0.125524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1181283\n",
      "\tspeed: 0.0761s/iter; left time: 1632.1475s\n",
      "\titers: 200, epoch: 4 | loss: 0.1108795\n",
      "\tspeed: 0.0413s/iter; left time: 881.0762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1145101 Vali Loss: 0.1246590 Test Loss: 0.1540057\n",
      "Validation loss decreased (0.125524 --> 0.124659).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1092665\n",
      "\tspeed: 0.0760s/iter; left time: 1612.9568s\n",
      "\titers: 200, epoch: 5 | loss: 0.1132531\n",
      "\tspeed: 0.0412s/iter; left time: 870.4696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1123378 Vali Loss: 0.1265095 Test Loss: 0.1549340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1059428\n",
      "\tspeed: 0.0755s/iter; left time: 1584.5224s\n",
      "\titers: 200, epoch: 6 | loss: 0.1128200\n",
      "\tspeed: 0.0412s/iter; left time: 859.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1113528 Vali Loss: 0.1253730 Test Loss: 0.1533087\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1118887\n",
      "\tspeed: 0.0756s/iter; left time: 1569.2793s\n",
      "\titers: 200, epoch: 7 | loss: 0.1120432\n",
      "\tspeed: 0.0412s/iter; left time: 852.2228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1100923 Vali Loss: 0.1250416 Test Loss: 0.1485461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1090592\n",
      "\tspeed: 0.0747s/iter; left time: 1534.7930s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068995\n",
      "\tspeed: 0.0414s/iter; left time: 847.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1091959 Vali Loss: 0.1256379 Test Loss: 0.1487788\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1106925\n",
      "\tspeed: 0.0754s/iter; left time: 1531.5013s\n",
      "\titers: 200, epoch: 9 | loss: 0.1068321\n",
      "\tspeed: 0.0414s/iter; left time: 836.8368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1085150 Vali Loss: 0.1243162 Test Loss: 0.1471283\n",
      "Validation loss decreased (0.124659 --> 0.124316).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1067732\n",
      "\tspeed: 0.0772s/iter; left time: 1552.5604s\n",
      "\titers: 200, epoch: 10 | loss: 0.1087037\n",
      "\tspeed: 0.0412s/iter; left time: 824.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1080044 Vali Loss: 0.1248898 Test Loss: 0.1474849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1124478\n",
      "\tspeed: 0.0755s/iter; left time: 1501.3308s\n",
      "\titers: 200, epoch: 11 | loss: 0.1083871\n",
      "\tspeed: 0.0413s/iter; left time: 816.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1076199 Vali Loss: 0.1253187 Test Loss: 0.1480367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1098340\n",
      "\tspeed: 0.0750s/iter; left time: 1473.6767s\n",
      "\titers: 200, epoch: 12 | loss: 0.1065531\n",
      "\tspeed: 0.0413s/iter; left time: 807.0006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1070364 Vali Loss: 0.1242883 Test Loss: 0.1481413\n",
      "Validation loss decreased (0.124316 --> 0.124288).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1028681\n",
      "\tspeed: 0.0763s/iter; left time: 1482.8800s\n",
      "\titers: 200, epoch: 13 | loss: 0.1073965\n",
      "\tspeed: 0.0413s/iter; left time: 798.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1067161 Vali Loss: 0.1250881 Test Loss: 0.1485085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1018266\n",
      "\tspeed: 0.0753s/iter; left time: 1447.5265s\n",
      "\titers: 200, epoch: 14 | loss: 0.1055653\n",
      "\tspeed: 0.0416s/iter; left time: 796.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1065856 Vali Loss: 0.1251107 Test Loss: 0.1492371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1073245\n",
      "\tspeed: 0.0753s/iter; left time: 1430.5092s\n",
      "\titers: 200, epoch: 15 | loss: 0.1032797\n",
      "\tspeed: 0.0413s/iter; left time: 780.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1062499 Vali Loss: 0.1251109 Test Loss: 0.1481002\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1035097\n",
      "\tspeed: 0.0758s/iter; left time: 1423.5704s\n",
      "\titers: 200, epoch: 16 | loss: 0.1055012\n",
      "\tspeed: 0.0413s/iter; left time: 771.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1059731 Vali Loss: 0.1256487 Test Loss: 0.1495054\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1115270\n",
      "\tspeed: 0.0757s/iter; left time: 1404.3685s\n",
      "\titers: 200, epoch: 17 | loss: 0.1086517\n",
      "\tspeed: 0.0413s/iter; left time: 761.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1058377 Vali Loss: 0.1241639 Test Loss: 0.1486776\n",
      "Validation loss decreased (0.124288 --> 0.124164).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1087099\n",
      "\tspeed: 0.0764s/iter; left time: 1400.1928s\n",
      "\titers: 200, epoch: 18 | loss: 0.1050047\n",
      "\tspeed: 0.0412s/iter; left time: 751.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1054555 Vali Loss: 0.1247823 Test Loss: 0.1497302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1028927\n",
      "\tspeed: 0.0755s/iter; left time: 1366.3546s\n",
      "\titers: 200, epoch: 19 | loss: 0.1060708\n",
      "\tspeed: 0.0414s/iter; left time: 745.0348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.1052858 Vali Loss: 0.1249171 Test Loss: 0.1500403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1049049\n",
      "\tspeed: 0.0759s/iter; left time: 1358.1418s\n",
      "\titers: 200, epoch: 20 | loss: 0.1012393\n",
      "\tspeed: 0.0412s/iter; left time: 733.2661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1053540 Vali Loss: 0.1261377 Test Loss: 0.1504158\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1063648\n",
      "\tspeed: 0.0754s/iter; left time: 1331.4070s\n",
      "\titers: 200, epoch: 21 | loss: 0.1047757\n",
      "\tspeed: 0.0413s/iter; left time: 725.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1052722 Vali Loss: 0.1249897 Test Loss: 0.1501012\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1041152\n",
      "\tspeed: 0.0755s/iter; left time: 1315.8241s\n",
      "\titers: 200, epoch: 22 | loss: 0.1084766\n",
      "\tspeed: 0.0413s/iter; left time: 716.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1049150 Vali Loss: 0.1259064 Test Loss: 0.1513341\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1038138\n",
      "\tspeed: 0.0753s/iter; left time: 1295.6782s\n",
      "\titers: 200, epoch: 23 | loss: 0.1041932\n",
      "\tspeed: 0.0412s/iter; left time: 706.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1048258 Vali Loss: 0.1255358 Test Loss: 0.1509897\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1022567\n",
      "\tspeed: 0.0755s/iter; left time: 1282.2932s\n",
      "\titers: 200, epoch: 24 | loss: 0.1052244\n",
      "\tspeed: 0.0412s/iter; left time: 696.8547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1046484 Vali Loss: 0.1249385 Test Loss: 0.1507090\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1076378\n",
      "\tspeed: 0.0756s/iter; left time: 1267.7721s\n",
      "\titers: 200, epoch: 25 | loss: 0.1043807\n",
      "\tspeed: 0.0411s/iter; left time: 684.6567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1046707 Vali Loss: 0.1248684 Test Loss: 0.1510690\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1014151\n",
      "\tspeed: 0.0754s/iter; left time: 1248.1725s\n",
      "\titers: 200, epoch: 26 | loss: 0.1049445\n",
      "\tspeed: 0.0410s/iter; left time: 675.0621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1045685 Vali Loss: 0.1245818 Test Loss: 0.1509740\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1041414\n",
      "\tspeed: 0.0753s/iter; left time: 1229.0372s\n",
      "\titers: 200, epoch: 27 | loss: 0.1036496\n",
      "\tspeed: 0.0412s/iter; left time: 668.2746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1043760 Vali Loss: 0.1253036 Test Loss: 0.1515556\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04521861672401428, rmse:0.2126466929912567, mae:0.14867757260799408, rse:0.7372766137123108\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2812609\n",
      "\tspeed: 0.0430s/iter; left time: 950.3421s\n",
      "\titers: 200, epoch: 1 | loss: 0.2743198\n",
      "\tspeed: 0.0411s/iter; left time: 903.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.2822524 Vali Loss: 0.2363064 Test Loss: 0.2515047\n",
      "Validation loss decreased (inf --> 0.236306).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1393131\n",
      "\tspeed: 0.0779s/iter; left time: 1704.9258s\n",
      "\titers: 200, epoch: 2 | loss: 0.1262606\n",
      "\tspeed: 0.0410s/iter; left time: 893.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1575504 Vali Loss: 0.1273091 Test Loss: 0.1528630\n",
      "Validation loss decreased (0.236306 --> 0.127309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138505\n",
      "\tspeed: 0.0777s/iter; left time: 1682.9884s\n",
      "\titers: 200, epoch: 3 | loss: 0.1161965\n",
      "\tspeed: 0.0412s/iter; left time: 887.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1181751 Vali Loss: 0.1289422 Test Loss: 0.1709879\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1163539\n",
      "\tspeed: 0.0759s/iter; left time: 1626.9556s\n",
      "\titers: 200, epoch: 4 | loss: 0.1155107\n",
      "\tspeed: 0.0410s/iter; left time: 874.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1139019 Vali Loss: 0.1297381 Test Loss: 0.1703210\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1137907\n",
      "\tspeed: 0.0755s/iter; left time: 1602.5071s\n",
      "\titers: 200, epoch: 5 | loss: 0.1132444\n",
      "\tspeed: 0.0412s/iter; left time: 868.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1125670 Vali Loss: 0.1281471 Test Loss: 0.1688897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1104800\n",
      "\tspeed: 0.0765s/iter; left time: 1606.2500s\n",
      "\titers: 200, epoch: 6 | loss: 0.1097190\n",
      "\tspeed: 0.0410s/iter; left time: 857.2504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1108655 Vali Loss: 0.1258683 Test Loss: 0.1585473\n",
      "Validation loss decreased (0.127309 --> 0.125868).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1140727\n",
      "\tspeed: 0.0764s/iter; left time: 1587.1705s\n",
      "\titers: 200, epoch: 7 | loss: 0.1073268\n",
      "\tspeed: 0.0410s/iter; left time: 847.6236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1100208 Vali Loss: 0.1245751 Test Loss: 0.1522525\n",
      "Validation loss decreased (0.125868 --> 0.124575).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1089322\n",
      "\tspeed: 0.0769s/iter; left time: 1579.9834s\n",
      "\titers: 200, epoch: 8 | loss: 0.1053236\n",
      "\tspeed: 0.0411s/iter; left time: 841.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1093476 Vali Loss: 0.1262100 Test Loss: 0.1514145\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1051588\n",
      "\tspeed: 0.0755s/iter; left time: 1534.4033s\n",
      "\titers: 200, epoch: 9 | loss: 0.1080333\n",
      "\tspeed: 0.0410s/iter; left time: 828.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1085658 Vali Loss: 0.1274492 Test Loss: 0.1521188\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1053995\n",
      "\tspeed: 0.0756s/iter; left time: 1519.5446s\n",
      "\titers: 200, epoch: 10 | loss: 0.1076154\n",
      "\tspeed: 0.0412s/iter; left time: 823.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1079732 Vali Loss: 0.1264845 Test Loss: 0.1513946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071782\n",
      "\tspeed: 0.0760s/iter; left time: 1510.1994s\n",
      "\titers: 200, epoch: 11 | loss: 0.1097906\n",
      "\tspeed: 0.0410s/iter; left time: 810.3533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 222 | Train Loss: 0.1073974 Vali Loss: 0.1266323 Test Loss: 0.1527154\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1083495\n",
      "\tspeed: 0.0760s/iter; left time: 1494.2791s\n",
      "\titers: 200, epoch: 12 | loss: 0.1082444\n",
      "\tspeed: 0.0410s/iter; left time: 802.4627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1070229 Vali Loss: 0.1274204 Test Loss: 0.1519750\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1112958\n",
      "\tspeed: 0.0756s/iter; left time: 1470.2463s\n",
      "\titers: 200, epoch: 13 | loss: 0.1051681\n",
      "\tspeed: 0.0411s/iter; left time: 794.1927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1067402 Vali Loss: 0.1246966 Test Loss: 0.1504878\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1047404\n",
      "\tspeed: 0.0759s/iter; left time: 1458.2581s\n",
      "\titers: 200, epoch: 14 | loss: 0.1110080\n",
      "\tspeed: 0.0411s/iter; left time: 785.2555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1063147 Vali Loss: 0.1260417 Test Loss: 0.1516709\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1065945\n",
      "\tspeed: 0.0759s/iter; left time: 1441.5429s\n",
      "\titers: 200, epoch: 15 | loss: 0.1034605\n",
      "\tspeed: 0.0410s/iter; left time: 775.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1061472 Vali Loss: 0.1259253 Test Loss: 0.1521753\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1045114\n",
      "\tspeed: 0.0758s/iter; left time: 1423.7237s\n",
      "\titers: 200, epoch: 16 | loss: 0.1061935\n",
      "\tspeed: 0.0410s/iter; left time: 766.4260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1057498 Vali Loss: 0.1266438 Test Loss: 0.1531464\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1039447\n",
      "\tspeed: 0.0756s/iter; left time: 1402.3167s\n",
      "\titers: 200, epoch: 17 | loss: 0.1046212\n",
      "\tspeed: 0.0410s/iter; left time: 756.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1054660 Vali Loss: 0.1257910 Test Loss: 0.1528551\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05040593817830086, rmse:0.22451266646385193, mae:0.1522524505853653, rse:0.7784176468849182\n",
      "Intermediate time for GB and pred_len 168: 00h:08m:49.69s\n",
      "Intermediate time for GB: 00h:34m:42.33s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2708257\n",
      "\tspeed: 0.0412s/iter; left time: 919.6909s\n",
      "\titers: 200, epoch: 1 | loss: 0.2622724\n",
      "\tspeed: 0.0173s/iter; left time: 382.9868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.2779982 Vali Loss: 0.2074505 Test Loss: 0.2332473\n",
      "Validation loss decreased (inf --> 0.207451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1510847\n",
      "\tspeed: 0.0382s/iter; left time: 843.2884s\n",
      "\titers: 200, epoch: 2 | loss: 0.1117425\n",
      "\tspeed: 0.0192s/iter; left time: 422.6661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1574519 Vali Loss: 0.0915035 Test Loss: 0.0991069\n",
      "Validation loss decreased (0.207451 --> 0.091504).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1003834\n",
      "\tspeed: 0.0364s/iter; left time: 794.6604s\n",
      "\titers: 200, epoch: 3 | loss: 0.0931744\n",
      "\tspeed: 0.0172s/iter; left time: 374.5618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1002942 Vali Loss: 0.0830410 Test Loss: 0.0912976\n",
      "Validation loss decreased (0.091504 --> 0.083041).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863603\n",
      "\tspeed: 0.0357s/iter; left time: 771.4233s\n",
      "\titers: 200, epoch: 4 | loss: 0.0836940\n",
      "\tspeed: 0.0176s/iter; left time: 378.6460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0864073 Vali Loss: 0.0718561 Test Loss: 0.0806061\n",
      "Validation loss decreased (0.083041 --> 0.071856).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0736417\n",
      "\tspeed: 0.0358s/iter; left time: 766.0545s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762774\n",
      "\tspeed: 0.0175s/iter; left time: 372.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0774616 Vali Loss: 0.0680598 Test Loss: 0.0780765\n",
      "Validation loss decreased (0.071856 --> 0.068060).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711824\n",
      "\tspeed: 0.0359s/iter; left time: 761.4207s\n",
      "\titers: 200, epoch: 6 | loss: 0.0742073\n",
      "\tspeed: 0.0172s/iter; left time: 363.5269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0727056 Vali Loss: 0.0657509 Test Loss: 0.0764956\n",
      "Validation loss decreased (0.068060 --> 0.065751).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0758830\n",
      "\tspeed: 0.0357s/iter; left time: 748.3752s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721870\n",
      "\tspeed: 0.0172s/iter; left time: 358.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0708751 Vali Loss: 0.0660416 Test Loss: 0.0778710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0714698\n",
      "\tspeed: 0.0356s/iter; left time: 737.0937s\n",
      "\titers: 200, epoch: 8 | loss: 0.0658485\n",
      "\tspeed: 0.0174s/iter; left time: 358.1808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0689583 Vali Loss: 0.0642446 Test Loss: 0.0767666\n",
      "Validation loss decreased (0.065751 --> 0.064245).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0694290\n",
      "\tspeed: 0.0362s/iter; left time: 743.3197s\n",
      "\titers: 200, epoch: 9 | loss: 0.0644000\n",
      "\tspeed: 0.0175s/iter; left time: 356.2119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0676455 Vali Loss: 0.0636601 Test Loss: 0.0770834\n",
      "Validation loss decreased (0.064245 --> 0.063660).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700247\n",
      "\tspeed: 0.0376s/iter; left time: 761.9303s\n",
      "\titers: 200, epoch: 10 | loss: 0.0655249\n",
      "\tspeed: 0.0174s/iter; left time: 351.4206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0667840 Vali Loss: 0.0626065 Test Loss: 0.0754004\n",
      "Validation loss decreased (0.063660 --> 0.062607).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672422\n",
      "\tspeed: 0.0377s/iter; left time: 756.5545s\n",
      "\titers: 200, epoch: 11 | loss: 0.0646161\n",
      "\tspeed: 0.0173s/iter; left time: 345.6716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0662278 Vali Loss: 0.0625945 Test Loss: 0.0761153\n",
      "Validation loss decreased (0.062607 --> 0.062595).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0648139\n",
      "\tspeed: 0.0356s/iter; left time: 707.1482s\n",
      "\titers: 200, epoch: 12 | loss: 0.0664951\n",
      "\tspeed: 0.0172s/iter; left time: 339.6006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0654111 Vali Loss: 0.0617924 Test Loss: 0.0757005\n",
      "Validation loss decreased (0.062595 --> 0.061792).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0622444\n",
      "\tspeed: 0.0356s/iter; left time: 698.7937s\n",
      "\titers: 200, epoch: 13 | loss: 0.0599254\n",
      "\tspeed: 0.0203s/iter; left time: 396.4701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0647105 Vali Loss: 0.0609597 Test Loss: 0.0746203\n",
      "Validation loss decreased (0.061792 --> 0.060960).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0647993\n",
      "\tspeed: 0.0372s/iter; left time: 721.4152s\n",
      "\titers: 200, epoch: 14 | loss: 0.0610652\n",
      "\tspeed: 0.0174s/iter; left time: 336.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0643186 Vali Loss: 0.0609952 Test Loss: 0.0744172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0624425\n",
      "\tspeed: 0.0353s/iter; left time: 676.6652s\n",
      "\titers: 200, epoch: 15 | loss: 0.0644481\n",
      "\tspeed: 0.0172s/iter; left time: 328.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0640143 Vali Loss: 0.0605438 Test Loss: 0.0741187\n",
      "Validation loss decreased (0.060960 --> 0.060544).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0600056\n",
      "\tspeed: 0.0354s/iter; left time: 670.0495s\n",
      "\titers: 200, epoch: 16 | loss: 0.0635128\n",
      "\tspeed: 0.0191s/iter; left time: 359.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0634908 Vali Loss: 0.0608249 Test Loss: 0.0749933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0606074\n",
      "\tspeed: 0.0360s/iter; left time: 673.3462s\n",
      "\titers: 200, epoch: 17 | loss: 0.0622914\n",
      "\tspeed: 0.0176s/iter; left time: 327.2015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0630818 Vali Loss: 0.0603432 Test Loss: 0.0748148\n",
      "Validation loss decreased (0.060544 --> 0.060343).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0615552\n",
      "\tspeed: 0.0364s/iter; left time: 673.3772s\n",
      "\titers: 200, epoch: 18 | loss: 0.0634372\n",
      "\tspeed: 0.0175s/iter; left time: 321.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0628284 Vali Loss: 0.0602996 Test Loss: 0.0743554\n",
      "Validation loss decreased (0.060343 --> 0.060300).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0640946\n",
      "\tspeed: 0.0366s/iter; left time: 668.3454s\n",
      "\titers: 200, epoch: 19 | loss: 0.0632057\n",
      "\tspeed: 0.0173s/iter; left time: 314.2733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0628115 Vali Loss: 0.0604891 Test Loss: 0.0746229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0630374\n",
      "\tspeed: 0.0354s/iter; left time: 639.4019s\n",
      "\titers: 200, epoch: 20 | loss: 0.0633529\n",
      "\tspeed: 0.0172s/iter; left time: 307.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0625326 Vali Loss: 0.0596575 Test Loss: 0.0737812\n",
      "Validation loss decreased (0.060300 --> 0.059657).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0616223\n",
      "\tspeed: 0.0395s/iter; left time: 703.1604s\n",
      "\titers: 200, epoch: 21 | loss: 0.0649464\n",
      "\tspeed: 0.0183s/iter; left time: 323.6225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0621714 Vali Loss: 0.0597556 Test Loss: 0.0742557\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0627824\n",
      "\tspeed: 0.0371s/iter; left time: 652.2355s\n",
      "\titers: 200, epoch: 22 | loss: 0.0598262\n",
      "\tspeed: 0.0174s/iter; left time: 303.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0622700 Vali Loss: 0.0598124 Test Loss: 0.0740635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0619051\n",
      "\tspeed: 0.0357s/iter; left time: 620.7394s\n",
      "\titers: 200, epoch: 23 | loss: 0.0605921\n",
      "\tspeed: 0.0179s/iter; left time: 308.9577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0617665 Vali Loss: 0.0594863 Test Loss: 0.0737347\n",
      "Validation loss decreased (0.059657 --> 0.059486).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0607017\n",
      "\tspeed: 0.0388s/iter; left time: 664.6397s\n",
      "\titers: 200, epoch: 24 | loss: 0.0636367\n",
      "\tspeed: 0.0174s/iter; left time: 297.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0617854 Vali Loss: 0.0594426 Test Loss: 0.0740125\n",
      "Validation loss decreased (0.059486 --> 0.059443).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0673195\n",
      "\tspeed: 0.0362s/iter; left time: 612.4036s\n",
      "\titers: 200, epoch: 25 | loss: 0.0601358\n",
      "\tspeed: 0.0177s/iter; left time: 298.2107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0616259 Vali Loss: 0.0594604 Test Loss: 0.0745333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0618991\n",
      "\tspeed: 0.0358s/iter; left time: 597.6044s\n",
      "\titers: 200, epoch: 26 | loss: 0.0608135\n",
      "\tspeed: 0.0174s/iter; left time: 289.5797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0614542 Vali Loss: 0.0593405 Test Loss: 0.0739550\n",
      "Validation loss decreased (0.059443 --> 0.059341).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0631193\n",
      "\tspeed: 0.0369s/iter; left time: 607.5670s\n",
      "\titers: 200, epoch: 27 | loss: 0.0657145\n",
      "\tspeed: 0.0176s/iter; left time: 287.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0616794 Vali Loss: 0.0594699 Test Loss: 0.0737223\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0565359\n",
      "\tspeed: 0.0397s/iter; left time: 645.6885s\n",
      "\titers: 200, epoch: 28 | loss: 0.0595181\n",
      "\tspeed: 0.0173s/iter; left time: 279.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0612757 Vali Loss: 0.0591323 Test Loss: 0.0734891\n",
      "Validation loss decreased (0.059341 --> 0.059132).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0586638\n",
      "\tspeed: 0.0367s/iter; left time: 587.9162s\n",
      "\titers: 200, epoch: 29 | loss: 0.0608017\n",
      "\tspeed: 0.0192s/iter; left time: 306.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0612530 Vali Loss: 0.0590975 Test Loss: 0.0735919\n",
      "Validation loss decreased (0.059132 --> 0.059097).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0592039\n",
      "\tspeed: 0.0412s/iter; left time: 650.7961s\n",
      "\titers: 200, epoch: 30 | loss: 0.0614624\n",
      "\tspeed: 0.0184s/iter; left time: 288.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0612326 Vali Loss: 0.0595413 Test Loss: 0.0739768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0617800\n",
      "\tspeed: 0.0358s/iter; left time: 557.7919s\n",
      "\titers: 200, epoch: 31 | loss: 0.0633619\n",
      "\tspeed: 0.0172s/iter; left time: 266.4169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0611033 Vali Loss: 0.0588847 Test Loss: 0.0730694\n",
      "Validation loss decreased (0.059097 --> 0.058885).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0632723\n",
      "\tspeed: 0.0374s/iter; left time: 574.4131s\n",
      "\titers: 200, epoch: 32 | loss: 0.0576704\n",
      "\tspeed: 0.0175s/iter; left time: 266.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0609722 Vali Loss: 0.0589661 Test Loss: 0.0733982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0627338\n",
      "\tspeed: 0.0354s/iter; left time: 535.9954s\n",
      "\titers: 200, epoch: 33 | loss: 0.0608308\n",
      "\tspeed: 0.0172s/iter; left time: 258.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0609542 Vali Loss: 0.0587706 Test Loss: 0.0731882\n",
      "Validation loss decreased (0.058885 --> 0.058771).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0627589\n",
      "\tspeed: 0.0394s/iter; left time: 587.7688s\n",
      "\titers: 200, epoch: 34 | loss: 0.0576832\n",
      "\tspeed: 0.0176s/iter; left time: 260.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0610260 Vali Loss: 0.0588217 Test Loss: 0.0729814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0592602\n",
      "\tspeed: 0.0362s/iter; left time: 531.4638s\n",
      "\titers: 200, epoch: 35 | loss: 0.0609397\n",
      "\tspeed: 0.0172s/iter; left time: 250.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0608695 Vali Loss: 0.0589980 Test Loss: 0.0734148\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0628913\n",
      "\tspeed: 0.0357s/iter; left time: 516.5297s\n",
      "\titers: 200, epoch: 36 | loss: 0.0595104\n",
      "\tspeed: 0.0178s/iter; left time: 255.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0607886 Vali Loss: 0.0588238 Test Loss: 0.0731824\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0592520\n",
      "\tspeed: 0.0359s/iter; left time: 510.4757s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619801\n",
      "\tspeed: 0.0173s/iter; left time: 243.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0608522 Vali Loss: 0.0588781 Test Loss: 0.0733389\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0571876\n",
      "\tspeed: 0.0355s/iter; left time: 496.8229s\n",
      "\titers: 200, epoch: 38 | loss: 0.0626874\n",
      "\tspeed: 0.0172s/iter; left time: 238.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0609661 Vali Loss: 0.0588733 Test Loss: 0.0733372\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0603451\n",
      "\tspeed: 0.0355s/iter; left time: 489.3631s\n",
      "\titers: 200, epoch: 39 | loss: 0.0607890\n",
      "\tspeed: 0.0173s/iter; left time: 236.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0607698 Vali Loss: 0.0588193 Test Loss: 0.0732570\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0569031\n",
      "\tspeed: 0.0356s/iter; left time: 482.7168s\n",
      "\titers: 200, epoch: 40 | loss: 0.0604230\n",
      "\tspeed: 0.0172s/iter; left time: 231.7892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0607826 Vali Loss: 0.0588016 Test Loss: 0.0730469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0587654\n",
      "\tspeed: 0.0367s/iter; left time: 490.2749s\n",
      "\titers: 200, epoch: 41 | loss: 0.0610591\n",
      "\tspeed: 0.0172s/iter; left time: 228.1223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0606978 Vali Loss: 0.0587396 Test Loss: 0.0732739\n",
      "Validation loss decreased (0.058771 --> 0.058740).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0635448\n",
      "\tspeed: 0.0367s/iter; left time: 481.0085s\n",
      "\titers: 200, epoch: 42 | loss: 0.0613662\n",
      "\tspeed: 0.0184s/iter; left time: 239.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0607116 Vali Loss: 0.0586978 Test Loss: 0.0730936\n",
      "Validation loss decreased (0.058740 --> 0.058698).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0577063\n",
      "\tspeed: 0.0380s/iter; left time: 490.5650s\n",
      "\titers: 200, epoch: 43 | loss: 0.0591121\n",
      "\tspeed: 0.0179s/iter; left time: 228.5114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0606261 Vali Loss: 0.0589224 Test Loss: 0.0736936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0624545\n",
      "\tspeed: 0.0374s/iter; left time: 473.3641s\n",
      "\titers: 200, epoch: 44 | loss: 0.0616844\n",
      "\tspeed: 0.0187s/iter; left time: 235.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0611692 Vali Loss: 0.0586782 Test Loss: 0.0729012\n",
      "Validation loss decreased (0.058698 --> 0.058678).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0593653\n",
      "\tspeed: 0.0372s/iter; left time: 463.2030s\n",
      "\titers: 200, epoch: 45 | loss: 0.0636859\n",
      "\tspeed: 0.0177s/iter; left time: 218.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0605644 Vali Loss: 0.0586519 Test Loss: 0.0729312\n",
      "Validation loss decreased (0.058678 --> 0.058652).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0588403\n",
      "\tspeed: 0.0369s/iter; left time: 450.9684s\n",
      "\titers: 200, epoch: 46 | loss: 0.0612193\n",
      "\tspeed: 0.0174s/iter; left time: 210.6585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0606294 Vali Loss: 0.0587211 Test Loss: 0.0729838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0612823\n",
      "\tspeed: 0.0361s/iter; left time: 433.0083s\n",
      "\titers: 200, epoch: 47 | loss: 0.0574999\n",
      "\tspeed: 0.0180s/iter; left time: 213.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0608826 Vali Loss: 0.0586566 Test Loss: 0.0730382\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0617604\n",
      "\tspeed: 0.0386s/iter; left time: 454.8398s\n",
      "\titers: 200, epoch: 48 | loss: 0.0574106\n",
      "\tspeed: 0.0190s/iter; left time: 221.8804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0606421 Vali Loss: 0.0585935 Test Loss: 0.0729641\n",
      "Validation loss decreased (0.058652 --> 0.058594).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0595661\n",
      "\tspeed: 0.0365s/iter; left time: 421.1314s\n",
      "\titers: 200, epoch: 49 | loss: 0.0651810\n",
      "\tspeed: 0.0174s/iter; left time: 198.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0605826 Vali Loss: 0.0586438 Test Loss: 0.0729285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0635316\n",
      "\tspeed: 0.0359s/iter; left time: 406.5635s\n",
      "\titers: 200, epoch: 50 | loss: 0.0610907\n",
      "\tspeed: 0.0171s/iter; left time: 192.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0609660 Vali Loss: 0.0588212 Test Loss: 0.0732808\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0592435\n",
      "\tspeed: 0.0365s/iter; left time: 404.7395s\n",
      "\titers: 200, epoch: 51 | loss: 0.0632765\n",
      "\tspeed: 0.0175s/iter; left time: 192.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0606898 Vali Loss: 0.0586598 Test Loss: 0.0730526\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0635184\n",
      "\tspeed: 0.0361s/iter; left time: 392.6319s\n",
      "\titers: 200, epoch: 52 | loss: 0.0610863\n",
      "\tspeed: 0.0218s/iter; left time: 234.8409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0605371 Vali Loss: 0.0588704 Test Loss: 0.0736128\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0603129\n",
      "\tspeed: 0.0369s/iter; left time: 392.8355s\n",
      "\titers: 200, epoch: 53 | loss: 0.0641348\n",
      "\tspeed: 0.0172s/iter; left time: 181.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0606629 Vali Loss: 0.0587345 Test Loss: 0.0732306\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0610451\n",
      "\tspeed: 0.0368s/iter; left time: 384.1182s\n",
      "\titers: 200, epoch: 54 | loss: 0.0583071\n",
      "\tspeed: 0.0192s/iter; left time: 197.9427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0608471 Vali Loss: 0.0588552 Test Loss: 0.0735912\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0600205\n",
      "\tspeed: 0.0374s/iter; left time: 381.5183s\n",
      "\titers: 200, epoch: 55 | loss: 0.0605740\n",
      "\tspeed: 0.0173s/iter; left time: 174.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0605078 Vali Loss: 0.0587326 Test Loss: 0.0732537\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0583362\n",
      "\tspeed: 0.0361s/iter; left time: 360.7633s\n",
      "\titers: 200, epoch: 56 | loss: 0.0632899\n",
      "\tspeed: 0.0174s/iter; left time: 171.6435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0607032 Vali Loss: 0.0586046 Test Loss: 0.0729888\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0592648\n",
      "\tspeed: 0.0367s/iter; left time: 357.6104s\n",
      "\titers: 200, epoch: 57 | loss: 0.0603010\n",
      "\tspeed: 0.0174s/iter; left time: 168.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0605897 Vali Loss: 0.0587299 Test Loss: 0.0734092\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0576204\n",
      "\tspeed: 0.0360s/iter; left time: 342.8372s\n",
      "\titers: 200, epoch: 58 | loss: 0.0604421\n",
      "\tspeed: 0.0174s/iter; left time: 164.2530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0606295 Vali Loss: 0.0587746 Test Loss: 0.0731275\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012697300873696804, rmse:0.1126822978258133, mae:0.07296409457921982, rse:0.33161038160324097\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2723186\n",
      "\tspeed: 0.0221s/iter; left time: 492.7511s\n",
      "\titers: 200, epoch: 1 | loss: 0.2594370\n",
      "\tspeed: 0.0174s/iter; left time: 387.3062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.2804108 Vali Loss: 0.2111473 Test Loss: 0.2331517\n",
      "Validation loss decreased (inf --> 0.211147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1487849\n",
      "\tspeed: 0.0372s/iter; left time: 821.7814s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122121\n",
      "\tspeed: 0.0175s/iter; left time: 385.5053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1569681 Vali Loss: 0.0871886 Test Loss: 0.0957581\n",
      "Validation loss decreased (0.211147 --> 0.087189).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0998303\n",
      "\tspeed: 0.0360s/iter; left time: 787.4339s\n",
      "\titers: 200, epoch: 3 | loss: 0.0900539\n",
      "\tspeed: 0.0172s/iter; left time: 375.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0995899 Vali Loss: 0.0780850 Test Loss: 0.0863740\n",
      "Validation loss decreased (0.087189 --> 0.078085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0908242\n",
      "\tspeed: 0.0364s/iter; left time: 787.0179s\n",
      "\titers: 200, epoch: 4 | loss: 0.0860295\n",
      "\tspeed: 0.0176s/iter; left time: 379.2616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0868707 Vali Loss: 0.0739030 Test Loss: 0.0811787\n",
      "Validation loss decreased (0.078085 --> 0.073903).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0818111\n",
      "\tspeed: 0.0375s/iter; left time: 802.0927s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754183\n",
      "\tspeed: 0.0181s/iter; left time: 385.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0790223 Vali Loss: 0.0694488 Test Loss: 0.0807753\n",
      "Validation loss decreased (0.073903 --> 0.069449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741047\n",
      "\tspeed: 0.0391s/iter; left time: 828.0456s\n",
      "\titers: 200, epoch: 6 | loss: 0.0749590\n",
      "\tspeed: 0.0216s/iter; left time: 454.3014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0735093 Vali Loss: 0.0666800 Test Loss: 0.0808575\n",
      "Validation loss decreased (0.069449 --> 0.066680).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0736243\n",
      "\tspeed: 0.0380s/iter; left time: 795.4230s\n",
      "\titers: 200, epoch: 7 | loss: 0.0661629\n",
      "\tspeed: 0.0177s/iter; left time: 368.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0714205 Vali Loss: 0.0655510 Test Loss: 0.0802032\n",
      "Validation loss decreased (0.066680 --> 0.065551).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729664\n",
      "\tspeed: 0.0407s/iter; left time: 843.2198s\n",
      "\titers: 200, epoch: 8 | loss: 0.0714460\n",
      "\tspeed: 0.0209s/iter; left time: 431.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0694222 Vali Loss: 0.0644655 Test Loss: 0.0811112\n",
      "Validation loss decreased (0.065551 --> 0.064465).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0659208\n",
      "\tspeed: 0.0369s/iter; left time: 756.4808s\n",
      "\titers: 200, epoch: 9 | loss: 0.0711732\n",
      "\tspeed: 0.0173s/iter; left time: 352.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0683030 Vali Loss: 0.0633331 Test Loss: 0.0808911\n",
      "Validation loss decreased (0.064465 --> 0.063333).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658178\n",
      "\tspeed: 0.0385s/iter; left time: 780.8806s\n",
      "\titers: 200, epoch: 10 | loss: 0.0632657\n",
      "\tspeed: 0.0206s/iter; left time: 416.7494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0671876 Vali Loss: 0.0626942 Test Loss: 0.0810161\n",
      "Validation loss decreased (0.063333 --> 0.062694).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0675375\n",
      "\tspeed: 0.0420s/iter; left time: 842.6574s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656089\n",
      "\tspeed: 0.0178s/iter; left time: 356.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 224 | Train Loss: 0.0663821 Vali Loss: 0.0650089 Test Loss: 0.0835631\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0698378\n",
      "\tspeed: 0.0374s/iter; left time: 742.3642s\n",
      "\titers: 200, epoch: 12 | loss: 0.0709315\n",
      "\tspeed: 0.0182s/iter; left time: 360.0192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0658216 Vali Loss: 0.0622524 Test Loss: 0.0804868\n",
      "Validation loss decreased (0.062694 --> 0.062252).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0702056\n",
      "\tspeed: 0.0372s/iter; left time: 730.0678s\n",
      "\titers: 200, epoch: 13 | loss: 0.0646744\n",
      "\tspeed: 0.0179s/iter; left time: 348.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0651245 Vali Loss: 0.0614892 Test Loss: 0.0798468\n",
      "Validation loss decreased (0.062252 --> 0.061489).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0666263\n",
      "\tspeed: 0.0383s/iter; left time: 742.3045s\n",
      "\titers: 200, epoch: 14 | loss: 0.0637792\n",
      "\tspeed: 0.0176s/iter; left time: 339.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0645446 Vali Loss: 0.0609676 Test Loss: 0.0781604\n",
      "Validation loss decreased (0.061489 --> 0.060968).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713808\n",
      "\tspeed: 0.0385s/iter; left time: 738.1148s\n",
      "\titers: 200, epoch: 15 | loss: 0.0672789\n",
      "\tspeed: 0.0220s/iter; left time: 420.2792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0644304 Vali Loss: 0.0603074 Test Loss: 0.0764001\n",
      "Validation loss decreased (0.060968 --> 0.060307).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0611395\n",
      "\tspeed: 0.0366s/iter; left time: 693.5715s\n",
      "\titers: 200, epoch: 16 | loss: 0.0639924\n",
      "\tspeed: 0.0171s/iter; left time: 323.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0638584 Vali Loss: 0.0604877 Test Loss: 0.0751136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0645290\n",
      "\tspeed: 0.0381s/iter; left time: 713.7701s\n",
      "\titers: 200, epoch: 17 | loss: 0.0622595\n",
      "\tspeed: 0.0171s/iter; left time: 319.0665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0634671 Vali Loss: 0.0599232 Test Loss: 0.0762809\n",
      "Validation loss decreased (0.060307 --> 0.059923).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0624876\n",
      "\tspeed: 0.0366s/iter; left time: 676.2772s\n",
      "\titers: 200, epoch: 18 | loss: 0.0637171\n",
      "\tspeed: 0.0175s/iter; left time: 321.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0630357 Vali Loss: 0.0595618 Test Loss: 0.0750244\n",
      "Validation loss decreased (0.059923 --> 0.059562).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0617419\n",
      "\tspeed: 0.0385s/iter; left time: 704.1668s\n",
      "\titers: 200, epoch: 19 | loss: 0.0608804\n",
      "\tspeed: 0.0172s/iter; left time: 311.8009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0629090 Vali Loss: 0.0596770 Test Loss: 0.0742886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0633113\n",
      "\tspeed: 0.0363s/iter; left time: 654.8177s\n",
      "\titers: 200, epoch: 20 | loss: 0.0655701\n",
      "\tspeed: 0.0173s/iter; left time: 310.7320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0625126 Vali Loss: 0.0595197 Test Loss: 0.0756664\n",
      "Validation loss decreased (0.059562 --> 0.059520).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0628558\n",
      "\tspeed: 0.0366s/iter; left time: 653.0582s\n",
      "\titers: 200, epoch: 21 | loss: 0.0602739\n",
      "\tspeed: 0.0173s/iter; left time: 306.5217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0623610 Vali Loss: 0.0591243 Test Loss: 0.0753350\n",
      "Validation loss decreased (0.059520 --> 0.059124).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0651103\n",
      "\tspeed: 0.0364s/iter; left time: 640.0614s\n",
      "\titers: 200, epoch: 22 | loss: 0.0575442\n",
      "\tspeed: 0.0174s/iter; left time: 304.0223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0621670 Vali Loss: 0.0592054 Test Loss: 0.0741855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0664264\n",
      "\tspeed: 0.0367s/iter; left time: 638.1007s\n",
      "\titers: 200, epoch: 23 | loss: 0.0587535\n",
      "\tspeed: 0.0172s/iter; left time: 297.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0620225 Vali Loss: 0.0589292 Test Loss: 0.0742925\n",
      "Validation loss decreased (0.059124 --> 0.058929).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0641541\n",
      "\tspeed: 0.0368s/iter; left time: 630.3895s\n",
      "\titers: 200, epoch: 24 | loss: 0.0634813\n",
      "\tspeed: 0.0174s/iter; left time: 297.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0621247 Vali Loss: 0.0589253 Test Loss: 0.0734498\n",
      "Validation loss decreased (0.058929 --> 0.058925).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0564462\n",
      "\tspeed: 0.0369s/iter; left time: 624.3433s\n",
      "\titers: 200, epoch: 25 | loss: 0.0637565\n",
      "\tspeed: 0.0174s/iter; left time: 291.9264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0617372 Vali Loss: 0.0589466 Test Loss: 0.0749519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0636609\n",
      "\tspeed: 0.0359s/iter; left time: 600.0659s\n",
      "\titers: 200, epoch: 26 | loss: 0.0584842\n",
      "\tspeed: 0.0172s/iter; left time: 285.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0616560 Vali Loss: 0.0590757 Test Loss: 0.0742946\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0581466\n",
      "\tspeed: 0.0357s/iter; left time: 588.6790s\n",
      "\titers: 200, epoch: 27 | loss: 0.0603953\n",
      "\tspeed: 0.0173s/iter; left time: 283.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0616052 Vali Loss: 0.0585262 Test Loss: 0.0741448\n",
      "Validation loss decreased (0.058925 --> 0.058526).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0577278\n",
      "\tspeed: 0.0392s/iter; left time: 637.3915s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644682\n",
      "\tspeed: 0.0181s/iter; left time: 291.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0618389 Vali Loss: 0.0587341 Test Loss: 0.0739767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0625474\n",
      "\tspeed: 0.0360s/iter; left time: 576.4015s\n",
      "\titers: 200, epoch: 29 | loss: 0.0580867\n",
      "\tspeed: 0.0171s/iter; left time: 272.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0613939 Vali Loss: 0.0586087 Test Loss: 0.0742347\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0590229\n",
      "\tspeed: 0.0355s/iter; left time: 561.1628s\n",
      "\titers: 200, epoch: 30 | loss: 0.0606227\n",
      "\tspeed: 0.0173s/iter; left time: 272.2874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0611694 Vali Loss: 0.0584188 Test Loss: 0.0739610\n",
      "Validation loss decreased (0.058526 --> 0.058419).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0643775\n",
      "\tspeed: 0.0367s/iter; left time: 571.0828s\n",
      "\titers: 200, epoch: 31 | loss: 0.0578023\n",
      "\tspeed: 0.0173s/iter; left time: 268.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0611918 Vali Loss: 0.0583375 Test Loss: 0.0744160\n",
      "Validation loss decreased (0.058419 --> 0.058337).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0579711\n",
      "\tspeed: 0.0377s/iter; left time: 579.2495s\n",
      "\titers: 200, epoch: 32 | loss: 0.0620027\n",
      "\tspeed: 0.0179s/iter; left time: 273.6753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0612068 Vali Loss: 0.0583986 Test Loss: 0.0742417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0653523\n",
      "\tspeed: 0.0403s/iter; left time: 609.4985s\n",
      "\titers: 200, epoch: 33 | loss: 0.0614485\n",
      "\tspeed: 0.0206s/iter; left time: 309.8559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0611182 Vali Loss: 0.0582882 Test Loss: 0.0733675\n",
      "Validation loss decreased (0.058337 --> 0.058288).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0647610\n",
      "\tspeed: 0.0366s/iter; left time: 545.1474s\n",
      "\titers: 200, epoch: 34 | loss: 0.0633823\n",
      "\tspeed: 0.0175s/iter; left time: 259.5481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0610971 Vali Loss: 0.0584576 Test Loss: 0.0729061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0626284\n",
      "\tspeed: 0.0390s/iter; left time: 573.3413s\n",
      "\titers: 200, epoch: 35 | loss: 0.0601387\n",
      "\tspeed: 0.0173s/iter; left time: 251.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0610140 Vali Loss: 0.0582965 Test Loss: 0.0737146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0639531\n",
      "\tspeed: 0.0359s/iter; left time: 518.8844s\n",
      "\titers: 200, epoch: 36 | loss: 0.0608174\n",
      "\tspeed: 0.0178s/iter; left time: 256.3027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0611647 Vali Loss: 0.0582508 Test Loss: 0.0736249\n",
      "Validation loss decreased (0.058288 --> 0.058251).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0602419\n",
      "\tspeed: 0.0366s/iter; left time: 521.4744s\n",
      "\titers: 200, epoch: 37 | loss: 0.0581153\n",
      "\tspeed: 0.0173s/iter; left time: 245.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0610484 Vali Loss: 0.0583448 Test Loss: 0.0732000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0600050\n",
      "\tspeed: 0.0365s/iter; left time: 510.8782s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618239\n",
      "\tspeed: 0.0172s/iter; left time: 239.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0609829 Vali Loss: 0.0584209 Test Loss: 0.0728817\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0601002\n",
      "\tspeed: 0.0355s/iter; left time: 488.8881s\n",
      "\titers: 200, epoch: 39 | loss: 0.0637596\n",
      "\tspeed: 0.0171s/iter; left time: 234.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0608545 Vali Loss: 0.0582400 Test Loss: 0.0727859\n",
      "Validation loss decreased (0.058251 --> 0.058240).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0579164\n",
      "\tspeed: 0.0380s/iter; left time: 515.7594s\n",
      "\titers: 200, epoch: 40 | loss: 0.0646479\n",
      "\tspeed: 0.0177s/iter; left time: 238.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0608278 Vali Loss: 0.0582177 Test Loss: 0.0733635\n",
      "Validation loss decreased (0.058240 --> 0.058218).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0616952\n",
      "\tspeed: 0.0405s/iter; left time: 540.6834s\n",
      "\titers: 200, epoch: 41 | loss: 0.0571715\n",
      "\tspeed: 0.0204s/iter; left time: 270.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0608960 Vali Loss: 0.0581996 Test Loss: 0.0732759\n",
      "Validation loss decreased (0.058218 --> 0.058200).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0631871\n",
      "\tspeed: 0.0375s/iter; left time: 491.4789s\n",
      "\titers: 200, epoch: 42 | loss: 0.0568571\n",
      "\tspeed: 0.0171s/iter; left time: 222.4476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0608211 Vali Loss: 0.0580944 Test Loss: 0.0728690\n",
      "Validation loss decreased (0.058200 --> 0.058094).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0618066\n",
      "\tspeed: 0.0370s/iter; left time: 476.8264s\n",
      "\titers: 200, epoch: 43 | loss: 0.0615122\n",
      "\tspeed: 0.0174s/iter; left time: 222.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0611374 Vali Loss: 0.0583234 Test Loss: 0.0724586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0589104\n",
      "\tspeed: 0.0392s/iter; left time: 497.1608s\n",
      "\titers: 200, epoch: 44 | loss: 0.0627911\n",
      "\tspeed: 0.0202s/iter; left time: 254.1602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0609306 Vali Loss: 0.0582577 Test Loss: 0.0726218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0628825\n",
      "\tspeed: 0.0368s/iter; left time: 458.3033s\n",
      "\titers: 200, epoch: 45 | loss: 0.0587390\n",
      "\tspeed: 0.0174s/iter; left time: 214.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0613185 Vali Loss: 0.0582871 Test Loss: 0.0725785\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0598876\n",
      "\tspeed: 0.0410s/iter; left time: 500.8020s\n",
      "\titers: 200, epoch: 46 | loss: 0.0615125\n",
      "\tspeed: 0.0216s/iter; left time: 261.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0608629 Vali Loss: 0.0581948 Test Loss: 0.0726809\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0631883\n",
      "\tspeed: 0.0369s/iter; left time: 442.5629s\n",
      "\titers: 200, epoch: 47 | loss: 0.0606678\n",
      "\tspeed: 0.0181s/iter; left time: 214.8732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0607024 Vali Loss: 0.0582297 Test Loss: 0.0723210\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0599459\n",
      "\tspeed: 0.0377s/iter; left time: 443.6570s\n",
      "\titers: 200, epoch: 48 | loss: 0.0553894\n",
      "\tspeed: 0.0172s/iter; left time: 201.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0608386 Vali Loss: 0.0579962 Test Loss: 0.0727201\n",
      "Validation loss decreased (0.058094 --> 0.057996).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0578657\n",
      "\tspeed: 0.0380s/iter; left time: 439.3892s\n",
      "\titers: 200, epoch: 49 | loss: 0.0608033\n",
      "\tspeed: 0.0180s/iter; left time: 206.3923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0609807 Vali Loss: 0.0581391 Test Loss: 0.0725509\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0621150\n",
      "\tspeed: 0.0358s/iter; left time: 405.6554s\n",
      "\titers: 200, epoch: 50 | loss: 0.0631911\n",
      "\tspeed: 0.0177s/iter; left time: 198.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0607364 Vali Loss: 0.0581990 Test Loss: 0.0728008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0609419\n",
      "\tspeed: 0.0358s/iter; left time: 397.3895s\n",
      "\titers: 200, epoch: 51 | loss: 0.0609045\n",
      "\tspeed: 0.0175s/iter; left time: 192.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0605976 Vali Loss: 0.0580235 Test Loss: 0.0729227\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0613372\n",
      "\tspeed: 0.0376s/iter; left time: 409.0928s\n",
      "\titers: 200, epoch: 52 | loss: 0.0578110\n",
      "\tspeed: 0.0173s/iter; left time: 186.7250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0606016 Vali Loss: 0.0580805 Test Loss: 0.0728458\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0597081\n",
      "\tspeed: 0.0362s/iter; left time: 385.8459s\n",
      "\titers: 200, epoch: 53 | loss: 0.0599167\n",
      "\tspeed: 0.0173s/iter; left time: 182.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0606716 Vali Loss: 0.0581069 Test Loss: 0.0723052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0602916\n",
      "\tspeed: 0.0362s/iter; left time: 377.1772s\n",
      "\titers: 200, epoch: 54 | loss: 0.0620375\n",
      "\tspeed: 0.0173s/iter; left time: 178.2611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0607120 Vali Loss: 0.0583016 Test Loss: 0.0727637\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0623368\n",
      "\tspeed: 0.0360s/iter; left time: 367.1473s\n",
      "\titers: 200, epoch: 55 | loss: 0.0654304\n",
      "\tspeed: 0.0178s/iter; left time: 180.3104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0606441 Vali Loss: 0.0581952 Test Loss: 0.0731348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0625696\n",
      "\tspeed: 0.0356s/iter; left time: 355.0182s\n",
      "\titers: 200, epoch: 56 | loss: 0.0563569\n",
      "\tspeed: 0.0172s/iter; left time: 169.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0607840 Vali Loss: 0.0580681 Test Loss: 0.0729142\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0616411\n",
      "\tspeed: 0.0359s/iter; left time: 349.8216s\n",
      "\titers: 200, epoch: 57 | loss: 0.0601746\n",
      "\tspeed: 0.0174s/iter; left time: 167.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0605397 Vali Loss: 0.0581108 Test Loss: 0.0730427\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0618836\n",
      "\tspeed: 0.0369s/iter; left time: 351.6512s\n",
      "\titers: 200, epoch: 58 | loss: 0.0594452\n",
      "\tspeed: 0.0171s/iter; left time: 161.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0606900 Vali Loss: 0.0581163 Test Loss: 0.0726102\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01282523199915886, rmse:0.1132485419511795, mae:0.07272014766931534, rse:0.33327677845954895\n",
      "Intermediate time for ES and pred_len 24: 00h:10m:47.64s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2699923\n",
      "\tspeed: 0.0421s/iter; left time: 937.9746s\n",
      "\titers: 200, epoch: 1 | loss: 0.2550710\n",
      "\tspeed: 0.0180s/iter; left time: 398.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.2779176 Vali Loss: 0.2090562 Test Loss: 0.2344670\n",
      "Validation loss decreased (inf --> 0.209056).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1451056\n",
      "\tspeed: 0.0375s/iter; left time: 827.5422s\n",
      "\titers: 200, epoch: 2 | loss: 0.1162974\n",
      "\tspeed: 0.0176s/iter; left time: 387.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1551280 Vali Loss: 0.1042353 Test Loss: 0.1172750\n",
      "Validation loss decreased (0.209056 --> 0.104235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089795\n",
      "\tspeed: 0.0373s/iter; left time: 815.6770s\n",
      "\titers: 200, epoch: 3 | loss: 0.1037570\n",
      "\tspeed: 0.0174s/iter; left time: 378.3567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1090032 Vali Loss: 0.0926297 Test Loss: 0.1092328\n",
      "Validation loss decreased (0.104235 --> 0.092630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0931839\n",
      "\tspeed: 0.0362s/iter; left time: 783.5263s\n",
      "\titers: 200, epoch: 4 | loss: 0.0921412\n",
      "\tspeed: 0.0174s/iter; left time: 374.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0958092 Vali Loss: 0.0869654 Test Loss: 0.1052669\n",
      "Validation loss decreased (0.092630 --> 0.086965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0885624\n",
      "\tspeed: 0.0370s/iter; left time: 792.7775s\n",
      "\titers: 200, epoch: 5 | loss: 0.0861385\n",
      "\tspeed: 0.0174s/iter; left time: 370.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0911318 Vali Loss: 0.0844819 Test Loss: 0.1059624\n",
      "Validation loss decreased (0.086965 --> 0.084482).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0869646\n",
      "\tspeed: 0.0375s/iter; left time: 793.3715s\n",
      "\titers: 200, epoch: 6 | loss: 0.0883404\n",
      "\tspeed: 0.0177s/iter; left time: 372.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0878641 Vali Loss: 0.0837793 Test Loss: 0.1088766\n",
      "Validation loss decreased (0.084482 --> 0.083779).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0886907\n",
      "\tspeed: 0.0388s/iter; left time: 813.2618s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817665\n",
      "\tspeed: 0.0182s/iter; left time: 380.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0862188 Vali Loss: 0.0827717 Test Loss: 0.1055454\n",
      "Validation loss decreased (0.083779 --> 0.082772).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847801\n",
      "\tspeed: 0.0373s/iter; left time: 773.0924s\n",
      "\titers: 200, epoch: 8 | loss: 0.0820215\n",
      "\tspeed: 0.0175s/iter; left time: 361.3767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0846143 Vali Loss: 0.0810567 Test Loss: 0.1060755\n",
      "Validation loss decreased (0.082772 --> 0.081057).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0844776\n",
      "\tspeed: 0.0386s/iter; left time: 792.4186s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794606\n",
      "\tspeed: 0.0195s/iter; left time: 397.7606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0838625 Vali Loss: 0.0811782 Test Loss: 0.1076061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0855363\n",
      "\tspeed: 0.0381s/iter; left time: 772.8100s\n",
      "\titers: 200, epoch: 10 | loss: 0.0853410\n",
      "\tspeed: 0.0223s/iter; left time: 449.1969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0832864 Vali Loss: 0.0808300 Test Loss: 0.1084978\n",
      "Validation loss decreased (0.081057 --> 0.080830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0816533\n",
      "\tspeed: 0.0376s/iter; left time: 755.2453s\n",
      "\titers: 200, epoch: 11 | loss: 0.0852584\n",
      "\tspeed: 0.0174s/iter; left time: 347.4976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0824372 Vali Loss: 0.0800179 Test Loss: 0.1059387\n",
      "Validation loss decreased (0.080830 --> 0.080018).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0845546\n",
      "\tspeed: 0.0394s/iter; left time: 781.4903s\n",
      "\titers: 200, epoch: 12 | loss: 0.0818359\n",
      "\tspeed: 0.0176s/iter; left time: 346.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0820708 Vali Loss: 0.0797471 Test Loss: 0.1046065\n",
      "Validation loss decreased (0.080018 --> 0.079747).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0820495\n",
      "\tspeed: 0.0378s/iter; left time: 741.1513s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821259\n",
      "\tspeed: 0.0174s/iter; left time: 339.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0817390 Vali Loss: 0.0797309 Test Loss: 0.1047793\n",
      "Validation loss decreased (0.079747 --> 0.079731).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0771034\n",
      "\tspeed: 0.0374s/iter; left time: 725.9512s\n",
      "\titers: 200, epoch: 14 | loss: 0.0803334\n",
      "\tspeed: 0.0177s/iter; left time: 341.0476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0816818 Vali Loss: 0.0795235 Test Loss: 0.1054109\n",
      "Validation loss decreased (0.079731 --> 0.079524).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0790244\n",
      "\tspeed: 0.0374s/iter; left time: 716.8276s\n",
      "\titers: 200, epoch: 15 | loss: 0.0830677\n",
      "\tspeed: 0.0176s/iter; left time: 336.2045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0809772 Vali Loss: 0.0793998 Test Loss: 0.1049986\n",
      "Validation loss decreased (0.079524 --> 0.079400).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0790241\n",
      "\tspeed: 0.0372s/iter; left time: 703.7488s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845467\n",
      "\tspeed: 0.0177s/iter; left time: 333.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0810577 Vali Loss: 0.0812501 Test Loss: 0.1041506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0794203\n",
      "\tspeed: 0.0369s/iter; left time: 689.9567s\n",
      "\titers: 200, epoch: 17 | loss: 0.0831470\n",
      "\tspeed: 0.0177s/iter; left time: 329.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0806764 Vali Loss: 0.0792494 Test Loss: 0.1062545\n",
      "Validation loss decreased (0.079400 --> 0.079249).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0804426\n",
      "\tspeed: 0.0377s/iter; left time: 698.1049s\n",
      "\titers: 200, epoch: 18 | loss: 0.0796953\n",
      "\tspeed: 0.0175s/iter; left time: 321.4670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0806038 Vali Loss: 0.0788590 Test Loss: 0.1040276\n",
      "Validation loss decreased (0.079249 --> 0.078859).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0802150\n",
      "\tspeed: 0.0374s/iter; left time: 682.7215s\n",
      "\titers: 200, epoch: 19 | loss: 0.0840697\n",
      "\tspeed: 0.0176s/iter; left time: 319.4835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0800741 Vali Loss: 0.0789752 Test Loss: 0.1047164\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0799749\n",
      "\tspeed: 0.0369s/iter; left time: 665.0032s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796723\n",
      "\tspeed: 0.0177s/iter; left time: 317.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0799620 Vali Loss: 0.0787971 Test Loss: 0.1043757\n",
      "Validation loss decreased (0.078859 --> 0.078797).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814895\n",
      "\tspeed: 0.0377s/iter; left time: 671.1743s\n",
      "\titers: 200, epoch: 21 | loss: 0.0775726\n",
      "\tspeed: 0.0176s/iter; left time: 311.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0799304 Vali Loss: 0.0786215 Test Loss: 0.1053541\n",
      "Validation loss decreased (0.078797 --> 0.078622).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0822030\n",
      "\tspeed: 0.0388s/iter; left time: 682.6459s\n",
      "\titers: 200, epoch: 22 | loss: 0.0822271\n",
      "\tspeed: 0.0194s/iter; left time: 339.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0797733 Vali Loss: 0.0788172 Test Loss: 0.1050946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0782094\n",
      "\tspeed: 0.0368s/iter; left time: 639.5816s\n",
      "\titers: 200, epoch: 23 | loss: 0.0817364\n",
      "\tspeed: 0.0174s/iter; left time: 299.9704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0796080 Vali Loss: 0.0783708 Test Loss: 0.1048175\n",
      "Validation loss decreased (0.078622 --> 0.078371).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0782946\n",
      "\tspeed: 0.0389s/iter; left time: 667.6350s\n",
      "\titers: 200, epoch: 24 | loss: 0.0759547\n",
      "\tspeed: 0.0193s/iter; left time: 329.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0795476 Vali Loss: 0.0784284 Test Loss: 0.1046700\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0781184\n",
      "\tspeed: 0.0385s/iter; left time: 651.9828s\n",
      "\titers: 200, epoch: 25 | loss: 0.0811927\n",
      "\tspeed: 0.0177s/iter; left time: 297.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0799517 Vali Loss: 0.0786431 Test Loss: 0.1045798\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0762303\n",
      "\tspeed: 0.0370s/iter; left time: 618.4891s\n",
      "\titers: 200, epoch: 26 | loss: 0.0799544\n",
      "\tspeed: 0.0181s/iter; left time: 300.6664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0793796 Vali Loss: 0.0786190 Test Loss: 0.1051480\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0789374\n",
      "\tspeed: 0.0370s/iter; left time: 609.6431s\n",
      "\titers: 200, epoch: 27 | loss: 0.0780281\n",
      "\tspeed: 0.0176s/iter; left time: 288.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0792773 Vali Loss: 0.0784299 Test Loss: 0.1052233\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0814020\n",
      "\tspeed: 0.0395s/iter; left time: 641.9937s\n",
      "\titers: 200, epoch: 28 | loss: 0.0798138\n",
      "\tspeed: 0.0186s/iter; left time: 299.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0791199 Vali Loss: 0.0783501 Test Loss: 0.1047811\n",
      "Validation loss decreased (0.078371 --> 0.078350).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0820562\n",
      "\tspeed: 0.0370s/iter; left time: 593.4710s\n",
      "\titers: 200, epoch: 29 | loss: 0.0808358\n",
      "\tspeed: 0.0189s/iter; left time: 300.3078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0791596 Vali Loss: 0.0785035 Test Loss: 0.1055300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0763969\n",
      "\tspeed: 0.0379s/iter; left time: 599.3888s\n",
      "\titers: 200, epoch: 30 | loss: 0.0771363\n",
      "\tspeed: 0.0176s/iter; left time: 276.2735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0791952 Vali Loss: 0.0784093 Test Loss: 0.1051583\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0785842\n",
      "\tspeed: 0.0374s/iter; left time: 582.5881s\n",
      "\titers: 200, epoch: 31 | loss: 0.0813041\n",
      "\tspeed: 0.0188s/iter; left time: 290.5109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0790166 Vali Loss: 0.0783721 Test Loss: 0.1051348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0805069\n",
      "\tspeed: 0.0370s/iter; left time: 568.1873s\n",
      "\titers: 200, epoch: 32 | loss: 0.0800453\n",
      "\tspeed: 0.0185s/iter; left time: 281.9049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0790431 Vali Loss: 0.0783341 Test Loss: 0.1047582\n",
      "Validation loss decreased (0.078350 --> 0.078334).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0781617\n",
      "\tspeed: 0.0379s/iter; left time: 572.8596s\n",
      "\titers: 200, epoch: 33 | loss: 0.0795569\n",
      "\tspeed: 0.0176s/iter; left time: 265.0821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0790344 Vali Loss: 0.0783522 Test Loss: 0.1054242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754284\n",
      "\tspeed: 0.0397s/iter; left time: 592.1762s\n",
      "\titers: 200, epoch: 34 | loss: 0.0840273\n",
      "\tspeed: 0.0201s/iter; left time: 296.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0790746 Vali Loss: 0.0782857 Test Loss: 0.1051250\n",
      "Validation loss decreased (0.078334 --> 0.078286).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0800861\n",
      "\tspeed: 0.0390s/iter; left time: 573.1407s\n",
      "\titers: 200, epoch: 35 | loss: 0.0839135\n",
      "\tspeed: 0.0176s/iter; left time: 256.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0789047 Vali Loss: 0.0782892 Test Loss: 0.1051449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0803963\n",
      "\tspeed: 0.0379s/iter; left time: 548.4311s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774545\n",
      "\tspeed: 0.0175s/iter; left time: 251.6576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0788350 Vali Loss: 0.0783046 Test Loss: 0.1055788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0808286\n",
      "\tspeed: 0.0373s/iter; left time: 530.5222s\n",
      "\titers: 200, epoch: 37 | loss: 0.0770837\n",
      "\tspeed: 0.0211s/iter; left time: 298.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0788810 Vali Loss: 0.0783464 Test Loss: 0.1056055\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0771653\n",
      "\tspeed: 0.0376s/iter; left time: 527.5544s\n",
      "\titers: 200, epoch: 38 | loss: 0.0761486\n",
      "\tspeed: 0.0175s/iter; left time: 243.8085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0791125 Vali Loss: 0.0782723 Test Loss: 0.1056459\n",
      "Validation loss decreased (0.078286 --> 0.078272).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0771597\n",
      "\tspeed: 0.0392s/iter; left time: 540.5652s\n",
      "\titers: 200, epoch: 39 | loss: 0.0795766\n",
      "\tspeed: 0.0211s/iter; left time: 288.2684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0789243 Vali Loss: 0.0781249 Test Loss: 0.1045209\n",
      "Validation loss decreased (0.078272 --> 0.078125).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0800514\n",
      "\tspeed: 0.0379s/iter; left time: 513.7359s\n",
      "\titers: 200, epoch: 40 | loss: 0.0769166\n",
      "\tspeed: 0.0174s/iter; left time: 233.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0787367 Vali Loss: 0.0781777 Test Loss: 0.1055735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0788939\n",
      "\tspeed: 0.0380s/iter; left time: 506.7403s\n",
      "\titers: 200, epoch: 41 | loss: 0.0796120\n",
      "\tspeed: 0.0194s/iter; left time: 256.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0787654 Vali Loss: 0.0783776 Test Loss: 0.1058984\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0801310\n",
      "\tspeed: 0.0377s/iter; left time: 494.3213s\n",
      "\titers: 200, epoch: 42 | loss: 0.0760927\n",
      "\tspeed: 0.0175s/iter; left time: 228.4381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0787919 Vali Loss: 0.0782467 Test Loss: 0.1052588\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0780973\n",
      "\tspeed: 0.0375s/iter; left time: 483.0579s\n",
      "\titers: 200, epoch: 43 | loss: 0.0798386\n",
      "\tspeed: 0.0174s/iter; left time: 222.5702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0787492 Vali Loss: 0.0781928 Test Loss: 0.1050963\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0823438\n",
      "\tspeed: 0.0373s/iter; left time: 472.6711s\n",
      "\titers: 200, epoch: 44 | loss: 0.0814990\n",
      "\tspeed: 0.0176s/iter; left time: 220.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0787495 Vali Loss: 0.0783943 Test Loss: 0.1058547\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0747283\n",
      "\tspeed: 0.0373s/iter; left time: 463.7394s\n",
      "\titers: 200, epoch: 45 | loss: 0.0808855\n",
      "\tspeed: 0.0189s/iter; left time: 233.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0786864 Vali Loss: 0.0781960 Test Loss: 0.1050198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0759459\n",
      "\tspeed: 0.0419s/iter; left time: 512.0966s\n",
      "\titers: 200, epoch: 46 | loss: 0.0787885\n",
      "\tspeed: 0.0174s/iter; left time: 210.5500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0786618 Vali Loss: 0.0782442 Test Loss: 0.1055460\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0770903\n",
      "\tspeed: 0.0374s/iter; left time: 448.5779s\n",
      "\titers: 200, epoch: 47 | loss: 0.0741980\n",
      "\tspeed: 0.0176s/iter; left time: 209.1131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0786734 Vali Loss: 0.0782155 Test Loss: 0.1053684\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0808809\n",
      "\tspeed: 0.0399s/iter; left time: 470.2276s\n",
      "\titers: 200, epoch: 48 | loss: 0.0765063\n",
      "\tspeed: 0.0204s/iter; left time: 238.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0787458 Vali Loss: 0.0782955 Test Loss: 0.1055569\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0781761\n",
      "\tspeed: 0.0370s/iter; left time: 427.0267s\n",
      "\titers: 200, epoch: 49 | loss: 0.0780755\n",
      "\tspeed: 0.0174s/iter; left time: 198.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0785175 Vali Loss: 0.0782023 Test Loss: 0.1054485\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02427673526108265, rmse:0.1558099389076233, mae:0.10452089458703995, rse:0.4577226936817169\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2807732\n",
      "\tspeed: 0.0241s/iter; left time: 538.3053s\n",
      "\titers: 200, epoch: 1 | loss: 0.2653032\n",
      "\tspeed: 0.0210s/iter; left time: 466.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.2841145 Vali Loss: 0.2130373 Test Loss: 0.2379890\n",
      "Validation loss decreased (inf --> 0.213037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1392819\n",
      "\tspeed: 0.0391s/iter; left time: 862.9989s\n",
      "\titers: 200, epoch: 2 | loss: 0.1165387\n",
      "\tspeed: 0.0176s/iter; left time: 387.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1551139 Vali Loss: 0.1124424 Test Loss: 0.1264123\n",
      "Validation loss decreased (0.213037 --> 0.112442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1126997\n",
      "\tspeed: 0.0389s/iter; left time: 850.2621s\n",
      "\titers: 200, epoch: 3 | loss: 0.1035556\n",
      "\tspeed: 0.0174s/iter; left time: 378.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1085227 Vali Loss: 0.0961990 Test Loss: 0.1101242\n",
      "Validation loss decreased (0.112442 --> 0.096199).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0962838\n",
      "\tspeed: 0.0387s/iter; left time: 837.5867s\n",
      "\titers: 200, epoch: 4 | loss: 0.0969591\n",
      "\tspeed: 0.0175s/iter; left time: 377.3183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0975332 Vali Loss: 0.0874930 Test Loss: 0.1175036\n",
      "Validation loss decreased (0.096199 --> 0.087493).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0933458\n",
      "\tspeed: 0.0409s/iter; left time: 874.7736s\n",
      "\titers: 200, epoch: 5 | loss: 0.0946651\n",
      "\tspeed: 0.0175s/iter; left time: 372.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0918568 Vali Loss: 0.0853591 Test Loss: 0.1164506\n",
      "Validation loss decreased (0.087493 --> 0.085359).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0905998\n",
      "\tspeed: 0.0410s/iter; left time: 868.6588s\n",
      "\titers: 200, epoch: 6 | loss: 0.0834064\n",
      "\tspeed: 0.0186s/iter; left time: 392.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0886637 Vali Loss: 0.0833173 Test Loss: 0.1190308\n",
      "Validation loss decreased (0.085359 --> 0.083317).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0859550\n",
      "\tspeed: 0.0387s/iter; left time: 810.8632s\n",
      "\titers: 200, epoch: 7 | loss: 0.0857930\n",
      "\tspeed: 0.0174s/iter; left time: 361.8929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0870941 Vali Loss: 0.0824725 Test Loss: 0.1289645\n",
      "Validation loss decreased (0.083317 --> 0.082472).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0835487\n",
      "\tspeed: 0.0394s/iter; left time: 816.0628s\n",
      "\titers: 200, epoch: 8 | loss: 0.0800077\n",
      "\tspeed: 0.0202s/iter; left time: 417.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0859448 Vali Loss: 0.0809953 Test Loss: 0.1246080\n",
      "Validation loss decreased (0.082472 --> 0.080995).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0829436\n",
      "\tspeed: 0.0376s/iter; left time: 771.6681s\n",
      "\titers: 200, epoch: 9 | loss: 0.0795209\n",
      "\tspeed: 0.0174s/iter; left time: 354.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0850060 Vali Loss: 0.0815726 Test Loss: 0.1122439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0820003\n",
      "\tspeed: 0.0370s/iter; left time: 750.4537s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848408\n",
      "\tspeed: 0.0174s/iter; left time: 350.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0839826 Vali Loss: 0.0810251 Test Loss: 0.1215878\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0819815\n",
      "\tspeed: 0.0400s/iter; left time: 802.8165s\n",
      "\titers: 200, epoch: 11 | loss: 0.0843423\n",
      "\tspeed: 0.0194s/iter; left time: 387.0046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0837573 Vali Loss: 0.0803522 Test Loss: 0.1226014\n",
      "Validation loss decreased (0.080995 --> 0.080352).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821579\n",
      "\tspeed: 0.0382s/iter; left time: 758.6621s\n",
      "\titers: 200, epoch: 12 | loss: 0.0825495\n",
      "\tspeed: 0.0173s/iter; left time: 342.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0829496 Vali Loss: 0.0797525 Test Loss: 0.1239641\n",
      "Validation loss decreased (0.080352 --> 0.079753).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0780287\n",
      "\tspeed: 0.0373s/iter; left time: 731.3173s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800011\n",
      "\tspeed: 0.0175s/iter; left time: 341.9818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0824018 Vali Loss: 0.0796889 Test Loss: 0.1207599\n",
      "Validation loss decreased (0.079753 --> 0.079689).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0824617\n",
      "\tspeed: 0.0383s/iter; left time: 743.4180s\n",
      "\titers: 200, epoch: 14 | loss: 0.0812564\n",
      "\tspeed: 0.0174s/iter; left time: 334.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0819560 Vali Loss: 0.0796502 Test Loss: 0.1245411\n",
      "Validation loss decreased (0.079689 --> 0.079650).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0830183\n",
      "\tspeed: 0.0380s/iter; left time: 728.2025s\n",
      "\titers: 200, epoch: 15 | loss: 0.0822272\n",
      "\tspeed: 0.0175s/iter; left time: 333.7254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0817088 Vali Loss: 0.0795031 Test Loss: 0.1285043\n",
      "Validation loss decreased (0.079650 --> 0.079503).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823791\n",
      "\tspeed: 0.0382s/iter; left time: 723.6515s\n",
      "\titers: 200, epoch: 16 | loss: 0.0843695\n",
      "\tspeed: 0.0176s/iter; left time: 330.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0813237 Vali Loss: 0.0790901 Test Loss: 0.1307180\n",
      "Validation loss decreased (0.079503 --> 0.079090).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0792187\n",
      "\tspeed: 0.0383s/iter; left time: 716.8989s\n",
      "\titers: 200, epoch: 17 | loss: 0.0829362\n",
      "\tspeed: 0.0174s/iter; left time: 323.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0812568 Vali Loss: 0.0794295 Test Loss: 0.1282273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0772294\n",
      "\tspeed: 0.0401s/iter; left time: 741.0517s\n",
      "\titers: 200, epoch: 18 | loss: 0.0806995\n",
      "\tspeed: 0.0202s/iter; left time: 371.5650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0811110 Vali Loss: 0.0793635 Test Loss: 0.1272759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0784017\n",
      "\tspeed: 0.0379s/iter; left time: 692.2446s\n",
      "\titers: 200, epoch: 19 | loss: 0.0811006\n",
      "\tspeed: 0.0176s/iter; left time: 319.2630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0807204 Vali Loss: 0.0791787 Test Loss: 0.1262407\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0806236\n",
      "\tspeed: 0.0376s/iter; left time: 678.5568s\n",
      "\titers: 200, epoch: 20 | loss: 0.0801287\n",
      "\tspeed: 0.0174s/iter; left time: 312.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0805928 Vali Loss: 0.0788154 Test Loss: 0.1241784\n",
      "Validation loss decreased (0.079090 --> 0.078815).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814793\n",
      "\tspeed: 0.0379s/iter; left time: 674.7187s\n",
      "\titers: 200, epoch: 21 | loss: 0.0794477\n",
      "\tspeed: 0.0174s/iter; left time: 308.1207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0805322 Vali Loss: 0.0791230 Test Loss: 0.1281666\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0802228\n",
      "\tspeed: 0.0371s/iter; left time: 652.9956s\n",
      "\titers: 200, epoch: 22 | loss: 0.0822596\n",
      "\tspeed: 0.0199s/iter; left time: 347.3298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0803095 Vali Loss: 0.0789785 Test Loss: 0.1211020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0813869\n",
      "\tspeed: 0.0410s/iter; left time: 712.1590s\n",
      "\titers: 200, epoch: 23 | loss: 0.0802233\n",
      "\tspeed: 0.0176s/iter; left time: 304.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0803901 Vali Loss: 0.0790809 Test Loss: 0.1202924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0823530\n",
      "\tspeed: 0.0375s/iter; left time: 643.7499s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754244\n",
      "\tspeed: 0.0175s/iter; left time: 298.4231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0799929 Vali Loss: 0.0786709 Test Loss: 0.1282071\n",
      "Validation loss decreased (0.078815 --> 0.078671).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0769625\n",
      "\tspeed: 0.0384s/iter; left time: 649.5076s\n",
      "\titers: 200, epoch: 25 | loss: 0.0787524\n",
      "\tspeed: 0.0177s/iter; left time: 297.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0799626 Vali Loss: 0.0787696 Test Loss: 0.1272044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0821803\n",
      "\tspeed: 0.0377s/iter; left time: 629.2086s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780077\n",
      "\tspeed: 0.0181s/iter; left time: 300.5271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0799785 Vali Loss: 0.0786442 Test Loss: 0.1239915\n",
      "Validation loss decreased (0.078671 --> 0.078644).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0795876\n",
      "\tspeed: 0.0400s/iter; left time: 659.8528s\n",
      "\titers: 200, epoch: 27 | loss: 0.0790085\n",
      "\tspeed: 0.0204s/iter; left time: 334.6971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0797704 Vali Loss: 0.0786359 Test Loss: 0.1259093\n",
      "Validation loss decreased (0.078644 --> 0.078636).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0818633\n",
      "\tspeed: 0.0381s/iter; left time: 619.7570s\n",
      "\titers: 200, epoch: 28 | loss: 0.0793344\n",
      "\tspeed: 0.0174s/iter; left time: 280.7484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0797060 Vali Loss: 0.0784768 Test Loss: 0.1269663\n",
      "Validation loss decreased (0.078636 --> 0.078477).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0812629\n",
      "\tspeed: 0.0433s/iter; left time: 694.5047s\n",
      "\titers: 200, epoch: 29 | loss: 0.0797160\n",
      "\tspeed: 0.0183s/iter; left time: 291.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0796613 Vali Loss: 0.0785777 Test Loss: 0.1275836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0785135\n",
      "\tspeed: 0.0379s/iter; left time: 599.4292s\n",
      "\titers: 200, epoch: 30 | loss: 0.0747149\n",
      "\tspeed: 0.0176s/iter; left time: 276.6621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0795775 Vali Loss: 0.0786406 Test Loss: 0.1256996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0790730\n",
      "\tspeed: 0.0373s/iter; left time: 581.5883s\n",
      "\titers: 200, epoch: 31 | loss: 0.0801010\n",
      "\tspeed: 0.0184s/iter; left time: 285.2870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0794757 Vali Loss: 0.0785512 Test Loss: 0.1254068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0801477\n",
      "\tspeed: 0.0377s/iter; left time: 578.5869s\n",
      "\titers: 200, epoch: 32 | loss: 0.0805202\n",
      "\tspeed: 0.0183s/iter; left time: 279.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0794999 Vali Loss: 0.0785085 Test Loss: 0.1251069\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0760565\n",
      "\tspeed: 0.0374s/iter; left time: 566.3457s\n",
      "\titers: 200, epoch: 33 | loss: 0.0793328\n",
      "\tspeed: 0.0176s/iter; left time: 264.0922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0795171 Vali Loss: 0.0785686 Test Loss: 0.1274197\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0773843\n",
      "\tspeed: 0.0380s/iter; left time: 566.1015s\n",
      "\titers: 200, epoch: 34 | loss: 0.0792592\n",
      "\tspeed: 0.0175s/iter; left time: 259.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0794413 Vali Loss: 0.0782065 Test Loss: 0.1235717\n",
      "Validation loss decreased (0.078477 --> 0.078206).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0784409\n",
      "\tspeed: 0.0379s/iter; left time: 556.2497s\n",
      "\titers: 200, epoch: 35 | loss: 0.0783178\n",
      "\tspeed: 0.0173s/iter; left time: 252.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0795024 Vali Loss: 0.0784416 Test Loss: 0.1234996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0821839\n",
      "\tspeed: 0.0375s/iter; left time: 542.2428s\n",
      "\titers: 200, epoch: 36 | loss: 0.0777974\n",
      "\tspeed: 0.0202s/iter; left time: 290.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0793642 Vali Loss: 0.0781588 Test Loss: 0.1211270\n",
      "Validation loss decreased (0.078206 --> 0.078159).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0747080\n",
      "\tspeed: 0.0436s/iter; left time: 621.1374s\n",
      "\titers: 200, epoch: 37 | loss: 0.0795331\n",
      "\tspeed: 0.0195s/iter; left time: 275.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0792608 Vali Loss: 0.0784312 Test Loss: 0.1257160\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0776572\n",
      "\tspeed: 0.0381s/iter; left time: 534.0900s\n",
      "\titers: 200, epoch: 38 | loss: 0.0762254\n",
      "\tspeed: 0.0176s/iter; left time: 244.4825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0794165 Vali Loss: 0.0782640 Test Loss: 0.1224292\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0813769\n",
      "\tspeed: 0.0422s/iter; left time: 581.9967s\n",
      "\titers: 200, epoch: 39 | loss: 0.0792352\n",
      "\tspeed: 0.0209s/iter; left time: 285.5187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0793261 Vali Loss: 0.0783679 Test Loss: 0.1225942\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0799571\n",
      "\tspeed: 0.0374s/iter; left time: 507.9205s\n",
      "\titers: 200, epoch: 40 | loss: 0.0804243\n",
      "\tspeed: 0.0174s/iter; left time: 233.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0792455 Vali Loss: 0.0784150 Test Loss: 0.1252133\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0813761\n",
      "\tspeed: 0.0372s/iter; left time: 495.7526s\n",
      "\titers: 200, epoch: 41 | loss: 0.0816666\n",
      "\tspeed: 0.0174s/iter; left time: 230.6579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0792573 Vali Loss: 0.0782532 Test Loss: 0.1225800\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0778905\n",
      "\tspeed: 0.0373s/iter; left time: 489.1493s\n",
      "\titers: 200, epoch: 42 | loss: 0.0788236\n",
      "\tspeed: 0.0176s/iter; left time: 229.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0792435 Vali Loss: 0.0781906 Test Loss: 0.1238133\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0783627\n",
      "\tspeed: 0.0393s/iter; left time: 506.2812s\n",
      "\titers: 200, epoch: 43 | loss: 0.0787241\n",
      "\tspeed: 0.0207s/iter; left time: 264.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0793239 Vali Loss: 0.0781083 Test Loss: 0.1231488\n",
      "Validation loss decreased (0.078159 --> 0.078108).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0763025\n",
      "\tspeed: 0.0416s/iter; left time: 526.6662s\n",
      "\titers: 200, epoch: 44 | loss: 0.0738823\n",
      "\tspeed: 0.0199s/iter; left time: 249.6092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0792564 Vali Loss: 0.0784912 Test Loss: 0.1267495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0757882\n",
      "\tspeed: 0.0410s/iter; left time: 509.6752s\n",
      "\titers: 200, epoch: 45 | loss: 0.0789459\n",
      "\tspeed: 0.0174s/iter; left time: 214.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0793981 Vali Loss: 0.0783084 Test Loss: 0.1237282\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0772759\n",
      "\tspeed: 0.0376s/iter; left time: 459.7951s\n",
      "\titers: 200, epoch: 46 | loss: 0.0767787\n",
      "\tspeed: 0.0177s/iter; left time: 214.2455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0790786 Vali Loss: 0.0783964 Test Loss: 0.1239477\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0750165\n",
      "\tspeed: 0.0380s/iter; left time: 456.1696s\n",
      "\titers: 200, epoch: 47 | loss: 0.0791191\n",
      "\tspeed: 0.0177s/iter; left time: 210.7319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0791732 Vali Loss: 0.0784350 Test Loss: 0.1260129\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0822771\n",
      "\tspeed: 0.0387s/iter; left time: 455.5598s\n",
      "\titers: 200, epoch: 48 | loss: 0.0833114\n",
      "\tspeed: 0.0200s/iter; left time: 233.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0792517 Vali Loss: 0.0783070 Test Loss: 0.1245301\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0782012\n",
      "\tspeed: 0.0379s/iter; left time: 437.8831s\n",
      "\titers: 200, epoch: 49 | loss: 0.0790513\n",
      "\tspeed: 0.0182s/iter; left time: 208.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0790816 Vali Loss: 0.0784223 Test Loss: 0.1252991\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0769528\n",
      "\tspeed: 0.0378s/iter; left time: 428.5405s\n",
      "\titers: 200, epoch: 50 | loss: 0.0796110\n",
      "\tspeed: 0.0183s/iter; left time: 205.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0792062 Vali Loss: 0.0781806 Test Loss: 0.1240269\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0821458\n",
      "\tspeed: 0.0405s/iter; left time: 449.8227s\n",
      "\titers: 200, epoch: 51 | loss: 0.0748606\n",
      "\tspeed: 0.0208s/iter; left time: 229.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0791860 Vali Loss: 0.0783969 Test Loss: 0.1252220\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0788861\n",
      "\tspeed: 0.0389s/iter; left time: 423.1191s\n",
      "\titers: 200, epoch: 52 | loss: 0.0744792\n",
      "\tspeed: 0.0175s/iter; left time: 188.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0791129 Vali Loss: 0.0783578 Test Loss: 0.1260209\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0779445\n",
      "\tspeed: 0.0373s/iter; left time: 397.8023s\n",
      "\titers: 200, epoch: 53 | loss: 0.0807185\n",
      "\tspeed: 0.0175s/iter; left time: 184.8857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0790737 Vali Loss: 0.0782593 Test Loss: 0.1245420\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04175650700926781, rmse:0.20434409379959106, mae:0.1231488287448883, rse:0.6003013849258423\n",
      "Intermediate time for ES and pred_len 96: 00h:09m:48.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2749318\n",
      "\tspeed: 0.0415s/iter; left time: 920.3683s\n",
      "\titers: 200, epoch: 1 | loss: 0.2637250\n",
      "\tspeed: 0.0177s/iter; left time: 390.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.2789764 Vali Loss: 0.2100756 Test Loss: 0.2343825\n",
      "Validation loss decreased (inf --> 0.210076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1421229\n",
      "\tspeed: 0.0373s/iter; left time: 819.5815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1207080\n",
      "\tspeed: 0.0177s/iter; left time: 388.2478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1543833 Vali Loss: 0.1086527 Test Loss: 0.1232387\n",
      "Validation loss decreased (0.210076 --> 0.108653).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1143583\n",
      "\tspeed: 0.0381s/iter; left time: 829.6279s\n",
      "\titers: 200, epoch: 3 | loss: 0.1035095\n",
      "\tspeed: 0.0180s/iter; left time: 390.2745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1096992 Vali Loss: 0.0961292 Test Loss: 0.1119838\n",
      "Validation loss decreased (0.108653 --> 0.096129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991537\n",
      "\tspeed: 0.0379s/iter; left time: 817.1208s\n",
      "\titers: 200, epoch: 4 | loss: 0.0941834\n",
      "\tspeed: 0.0179s/iter; left time: 383.5921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0979566 Vali Loss: 0.0913458 Test Loss: 0.1117256\n",
      "Validation loss decreased (0.096129 --> 0.091346).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0948883\n",
      "\tspeed: 0.0376s/iter; left time: 801.8857s\n",
      "\titers: 200, epoch: 5 | loss: 0.0904951\n",
      "\tspeed: 0.0181s/iter; left time: 383.7397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0934428 Vali Loss: 0.0899405 Test Loss: 0.1138975\n",
      "Validation loss decreased (0.091346 --> 0.089940).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889967\n",
      "\tspeed: 0.0388s/iter; left time: 817.4538s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896095\n",
      "\tspeed: 0.0178s/iter; left time: 373.9967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0908615 Vali Loss: 0.0874881 Test Loss: 0.1135529\n",
      "Validation loss decreased (0.089940 --> 0.087488).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891786\n",
      "\tspeed: 0.0377s/iter; left time: 786.8146s\n",
      "\titers: 200, epoch: 7 | loss: 0.0887473\n",
      "\tspeed: 0.0177s/iter; left time: 368.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.0893473 Vali Loss: 0.0867286 Test Loss: 0.1134460\n",
      "Validation loss decreased (0.087488 --> 0.086729).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847037\n",
      "\tspeed: 0.0387s/iter; left time: 798.8800s\n",
      "\titers: 200, epoch: 8 | loss: 0.0879599\n",
      "\tspeed: 0.0177s/iter; left time: 363.1379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0882717 Vali Loss: 0.0867410 Test Loss: 0.1150925\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0870168\n",
      "\tspeed: 0.0381s/iter; left time: 777.2110s\n",
      "\titers: 200, epoch: 9 | loss: 0.0849715\n",
      "\tspeed: 0.0178s/iter; left time: 361.2851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0878216 Vali Loss: 0.0872022 Test Loss: 0.1176080\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0875702\n",
      "\tspeed: 0.0378s/iter; left time: 762.7947s\n",
      "\titers: 200, epoch: 10 | loss: 0.0899240\n",
      "\tspeed: 0.0181s/iter; left time: 364.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0869609 Vali Loss: 0.0860930 Test Loss: 0.1131297\n",
      "Validation loss decreased (0.086729 --> 0.086093).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0882442\n",
      "\tspeed: 0.0385s/iter; left time: 769.2968s\n",
      "\titers: 200, epoch: 11 | loss: 0.0836711\n",
      "\tspeed: 0.0179s/iter; left time: 355.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0865654 Vali Loss: 0.0859699 Test Loss: 0.1132639\n",
      "Validation loss decreased (0.086093 --> 0.085970).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0827679\n",
      "\tspeed: 0.0383s/iter; left time: 755.5015s\n",
      "\titers: 200, epoch: 12 | loss: 0.0866363\n",
      "\tspeed: 0.0177s/iter; left time: 347.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0860623 Vali Loss: 0.0858304 Test Loss: 0.1128382\n",
      "Validation loss decreased (0.085970 --> 0.085830).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0829732\n",
      "\tspeed: 0.0378s/iter; left time: 738.1925s\n",
      "\titers: 200, epoch: 13 | loss: 0.0850765\n",
      "\tspeed: 0.0177s/iter; left time: 343.7003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.0856914 Vali Loss: 0.0856651 Test Loss: 0.1135978\n",
      "Validation loss decreased (0.085830 --> 0.085665).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841183\n",
      "\tspeed: 0.0396s/iter; left time: 763.7380s\n",
      "\titers: 200, epoch: 14 | loss: 0.0859597\n",
      "\tspeed: 0.0177s/iter; left time: 340.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0852342 Vali Loss: 0.0856685 Test Loss: 0.1136733\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0842968\n",
      "\tspeed: 0.0382s/iter; left time: 729.1758s\n",
      "\titers: 200, epoch: 15 | loss: 0.0909677\n",
      "\tspeed: 0.0178s/iter; left time: 337.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0852555 Vali Loss: 0.0855243 Test Loss: 0.1138341\n",
      "Validation loss decreased (0.085665 --> 0.085524).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0852345\n",
      "\tspeed: 0.0382s/iter; left time: 720.0223s\n",
      "\titers: 200, epoch: 16 | loss: 0.0851248\n",
      "\tspeed: 0.0203s/iter; left time: 380.5213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0847901 Vali Loss: 0.0851691 Test Loss: 0.1139723\n",
      "Validation loss decreased (0.085524 --> 0.085169).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0839362\n",
      "\tspeed: 0.0385s/iter; left time: 717.8357s\n",
      "\titers: 200, epoch: 17 | loss: 0.0833548\n",
      "\tspeed: 0.0177s/iter; left time: 328.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0845173 Vali Loss: 0.0850614 Test Loss: 0.1140275\n",
      "Validation loss decreased (0.085169 --> 0.085061).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0813416\n",
      "\tspeed: 0.0377s/iter; left time: 693.3347s\n",
      "\titers: 200, epoch: 18 | loss: 0.0866940\n",
      "\tspeed: 0.0192s/iter; left time: 351.3236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0843307 Vali Loss: 0.0847981 Test Loss: 0.1144203\n",
      "Validation loss decreased (0.085061 --> 0.084798).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0843313\n",
      "\tspeed: 0.0381s/iter; left time: 693.2385s\n",
      "\titers: 200, epoch: 19 | loss: 0.0832647\n",
      "\tspeed: 0.0180s/iter; left time: 325.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0842799 Vali Loss: 0.0846771 Test Loss: 0.1141960\n",
      "Validation loss decreased (0.084798 --> 0.084677).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0862335\n",
      "\tspeed: 0.0379s/iter; left time: 681.4529s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817612\n",
      "\tspeed: 0.0178s/iter; left time: 318.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0838804 Vali Loss: 0.0843563 Test Loss: 0.1145415\n",
      "Validation loss decreased (0.084677 --> 0.084356).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0837195\n",
      "\tspeed: 0.0404s/iter; left time: 716.5821s\n",
      "\titers: 200, epoch: 21 | loss: 0.1031141\n",
      "\tspeed: 0.0202s/iter; left time: 356.7964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0839049 Vali Loss: 0.0849667 Test Loss: 0.1150237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0836587\n",
      "\tspeed: 0.0377s/iter; left time: 660.8575s\n",
      "\titers: 200, epoch: 22 | loss: 0.0852197\n",
      "\tspeed: 0.0179s/iter; left time: 311.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0837684 Vali Loss: 0.0846416 Test Loss: 0.1158141\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0795333\n",
      "\tspeed: 0.0383s/iter; left time: 663.0939s\n",
      "\titers: 200, epoch: 23 | loss: 0.0865810\n",
      "\tspeed: 0.0178s/iter; left time: 306.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0835962 Vali Loss: 0.0847980 Test Loss: 0.1160617\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0831024\n",
      "\tspeed: 0.0373s/iter; left time: 637.2761s\n",
      "\titers: 200, epoch: 24 | loss: 0.0805572\n",
      "\tspeed: 0.0177s/iter; left time: 299.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0839736 Vali Loss: 0.0847975 Test Loss: 0.1165650\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0849554\n",
      "\tspeed: 0.0380s/iter; left time: 639.8876s\n",
      "\titers: 200, epoch: 25 | loss: 0.0840587\n",
      "\tspeed: 0.0189s/iter; left time: 316.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0834544 Vali Loss: 0.0845328 Test Loss: 0.1162506\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0892217\n",
      "\tspeed: 0.0375s/iter; left time: 623.1592s\n",
      "\titers: 200, epoch: 26 | loss: 0.0807220\n",
      "\tspeed: 0.0183s/iter; left time: 302.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0833992 Vali Loss: 0.0846728 Test Loss: 0.1164240\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0810502\n",
      "\tspeed: 0.0385s/iter; left time: 630.8216s\n",
      "\titers: 200, epoch: 27 | loss: 0.0854318\n",
      "\tspeed: 0.0178s/iter; left time: 291.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0833067 Vali Loss: 0.0845248 Test Loss: 0.1158283\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0797867\n",
      "\tspeed: 0.0403s/iter; left time: 651.9570s\n",
      "\titers: 200, epoch: 28 | loss: 0.0819262\n",
      "\tspeed: 0.0194s/iter; left time: 312.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0833002 Vali Loss: 0.0843592 Test Loss: 0.1163825\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0846014\n",
      "\tspeed: 0.0374s/iter; left time: 597.1936s\n",
      "\titers: 200, epoch: 29 | loss: 0.0876969\n",
      "\tspeed: 0.0177s/iter; left time: 280.5650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0833116 Vali Loss: 0.0845298 Test Loss: 0.1166252\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0819796\n",
      "\tspeed: 0.0395s/iter; left time: 621.2215s\n",
      "\titers: 200, epoch: 30 | loss: 0.0857283\n",
      "\tspeed: 0.0219s/iter; left time: 342.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0831343 Vali Loss: 0.0845026 Test Loss: 0.1163839\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0290948748588562, rmse:0.1705721914768219, mae:0.11454156041145325, rse:0.5011257529258728\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2807395\n",
      "\tspeed: 0.0197s/iter; left time: 437.4888s\n",
      "\titers: 200, epoch: 1 | loss: 0.2651633\n",
      "\tspeed: 0.0177s/iter; left time: 391.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.2830992 Vali Loss: 0.2142654 Test Loss: 0.2370222\n",
      "Validation loss decreased (inf --> 0.214265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1453094\n",
      "\tspeed: 0.0382s/iter; left time: 840.0588s\n",
      "\titers: 200, epoch: 2 | loss: 0.1242578\n",
      "\tspeed: 0.0180s/iter; left time: 393.8545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.1572299 Vali Loss: 0.1083790 Test Loss: 0.1231012\n",
      "Validation loss decreased (0.214265 --> 0.108379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1133961\n",
      "\tspeed: 0.0428s/iter; left time: 932.0011s\n",
      "\titers: 200, epoch: 3 | loss: 0.0982893\n",
      "\tspeed: 0.0208s/iter; left time: 451.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.1100277 Vali Loss: 0.0972046 Test Loss: 0.1224924\n",
      "Validation loss decreased (0.108379 --> 0.097205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0974868\n",
      "\tspeed: 0.0402s/iter; left time: 864.6889s\n",
      "\titers: 200, epoch: 4 | loss: 0.0972847\n",
      "\tspeed: 0.0178s/iter; left time: 382.2048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0984315 Vali Loss: 0.0914870 Test Loss: 0.1193569\n",
      "Validation loss decreased (0.097205 --> 0.091487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0947529\n",
      "\tspeed: 0.0390s/iter; left time: 831.2727s\n",
      "\titers: 200, epoch: 5 | loss: 0.0937127\n",
      "\tspeed: 0.0188s/iter; left time: 399.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0946569 Vali Loss: 0.0894347 Test Loss: 0.1191490\n",
      "Validation loss decreased (0.091487 --> 0.089435).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0918505\n",
      "\tspeed: 0.0394s/iter; left time: 831.3602s\n",
      "\titers: 200, epoch: 6 | loss: 0.0901247\n",
      "\tspeed: 0.0179s/iter; left time: 375.6055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0917058 Vali Loss: 0.0881212 Test Loss: 0.1236080\n",
      "Validation loss decreased (0.089435 --> 0.088121).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0917704\n",
      "\tspeed: 0.0382s/iter; left time: 797.0048s\n",
      "\titers: 200, epoch: 7 | loss: 0.0922219\n",
      "\tspeed: 0.0178s/iter; left time: 370.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0899804 Vali Loss: 0.0864551 Test Loss: 0.1166708\n",
      "Validation loss decreased (0.088121 --> 0.086455).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0917562\n",
      "\tspeed: 0.0390s/iter; left time: 805.6186s\n",
      "\titers: 200, epoch: 8 | loss: 0.0877953\n",
      "\tspeed: 0.0177s/iter; left time: 363.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0890128 Vali Loss: 0.0861659 Test Loss: 0.1123231\n",
      "Validation loss decreased (0.086455 --> 0.086166).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919937\n",
      "\tspeed: 0.0386s/iter; left time: 787.5926s\n",
      "\titers: 200, epoch: 9 | loss: 0.0899467\n",
      "\tspeed: 0.0178s/iter; left time: 362.6346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0910410 Vali Loss: 0.0899233 Test Loss: 0.1119124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0895764\n",
      "\tspeed: 0.0380s/iter; left time: 767.0532s\n",
      "\titers: 200, epoch: 10 | loss: 0.0906453\n",
      "\tspeed: 0.0177s/iter; left time: 355.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0887168 Vali Loss: 0.0859634 Test Loss: 0.1185711\n",
      "Validation loss decreased (0.086166 --> 0.085963).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0892631\n",
      "\tspeed: 0.0378s/iter; left time: 754.8397s\n",
      "\titers: 200, epoch: 11 | loss: 0.0895315\n",
      "\tspeed: 0.0177s/iter; left time: 351.0145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0871117 Vali Loss: 0.0853329 Test Loss: 0.1164193\n",
      "Validation loss decreased (0.085963 --> 0.085333).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0869905\n",
      "\tspeed: 0.0381s/iter; left time: 752.4551s\n",
      "\titers: 200, epoch: 12 | loss: 0.0848289\n",
      "\tspeed: 0.0178s/iter; left time: 349.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0865530 Vali Loss: 0.0852942 Test Loss: 0.1179176\n",
      "Validation loss decreased (0.085333 --> 0.085294).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0864150\n",
      "\tspeed: 0.0386s/iter; left time: 752.7703s\n",
      "\titers: 200, epoch: 13 | loss: 0.0838847\n",
      "\tspeed: 0.0177s/iter; left time: 343.7851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0862789 Vali Loss: 0.0850571 Test Loss: 0.1164684\n",
      "Validation loss decreased (0.085294 --> 0.085057).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0867992\n",
      "\tspeed: 0.0388s/iter; left time: 748.5236s\n",
      "\titers: 200, epoch: 14 | loss: 0.0845527\n",
      "\tspeed: 0.0177s/iter; left time: 338.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0858124 Vali Loss: 0.0850595 Test Loss: 0.1153065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0845146\n",
      "\tspeed: 0.0378s/iter; left time: 721.2674s\n",
      "\titers: 200, epoch: 15 | loss: 0.0846549\n",
      "\tspeed: 0.0182s/iter; left time: 344.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0856219 Vali Loss: 0.0849426 Test Loss: 0.1166757\n",
      "Validation loss decreased (0.085057 --> 0.084943).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0845102\n",
      "\tspeed: 0.0407s/iter; left time: 766.9892s\n",
      "\titers: 200, epoch: 16 | loss: 0.0888782\n",
      "\tspeed: 0.0199s/iter; left time: 373.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 223 | Train Loss: 0.0858942 Vali Loss: 0.0853336 Test Loss: 0.1119651\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0912922\n",
      "\tspeed: 0.0378s/iter; left time: 703.8816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0889382\n",
      "\tspeed: 0.0177s/iter; left time: 327.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0856840 Vali Loss: 0.0851839 Test Loss: 0.1192388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0845657\n",
      "\tspeed: 0.0402s/iter; left time: 739.8128s\n",
      "\titers: 200, epoch: 18 | loss: 0.0815924\n",
      "\tspeed: 0.0180s/iter; left time: 329.8848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0849107 Vali Loss: 0.0853217 Test Loss: 0.1206380\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0849029\n",
      "\tspeed: 0.0380s/iter; left time: 690.7471s\n",
      "\titers: 200, epoch: 19 | loss: 0.0853960\n",
      "\tspeed: 0.0179s/iter; left time: 323.5752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0848261 Vali Loss: 0.0846747 Test Loss: 0.1192671\n",
      "Validation loss decreased (0.084943 --> 0.084675).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811674\n",
      "\tspeed: 0.0386s/iter; left time: 693.0126s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817534\n",
      "\tspeed: 0.0178s/iter; left time: 318.6812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0845942 Vali Loss: 0.0847365 Test Loss: 0.1183660\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0826207\n",
      "\tspeed: 0.0375s/iter; left time: 665.2076s\n",
      "\titers: 200, epoch: 21 | loss: 0.0816803\n",
      "\tspeed: 0.0177s/iter; left time: 312.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0843873 Vali Loss: 0.0846548 Test Loss: 0.1183502\n",
      "Validation loss decreased (0.084675 --> 0.084655).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0834691\n",
      "\tspeed: 0.0381s/iter; left time: 667.4153s\n",
      "\titers: 200, epoch: 22 | loss: 0.0883418\n",
      "\tspeed: 0.0185s/iter; left time: 322.6009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0843994 Vali Loss: 0.0845420 Test Loss: 0.1178532\n",
      "Validation loss decreased (0.084655 --> 0.084542).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0847441\n",
      "\tspeed: 0.0384s/iter; left time: 663.9202s\n",
      "\titers: 200, epoch: 23 | loss: 0.0805724\n",
      "\tspeed: 0.0178s/iter; left time: 305.8888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0841674 Vali Loss: 0.0844933 Test Loss: 0.1170921\n",
      "Validation loss decreased (0.084542 --> 0.084493).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0839649\n",
      "\tspeed: 0.0392s/iter; left time: 668.4869s\n",
      "\titers: 200, epoch: 24 | loss: 0.0834868\n",
      "\tspeed: 0.0178s/iter; left time: 301.9828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0841976 Vali Loss: 0.0846161 Test Loss: 0.1172125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0881067\n",
      "\tspeed: 0.0398s/iter; left time: 670.4357s\n",
      "\titers: 200, epoch: 25 | loss: 0.0828818\n",
      "\tspeed: 0.0194s/iter; left time: 324.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0841515 Vali Loss: 0.0843772 Test Loss: 0.1175339\n",
      "Validation loss decreased (0.084493 --> 0.084377).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0825793\n",
      "\tspeed: 0.0410s/iter; left time: 682.0217s\n",
      "\titers: 200, epoch: 26 | loss: 0.0856509\n",
      "\tspeed: 0.0181s/iter; left time: 298.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 223 | Train Loss: 0.0842238 Vali Loss: 0.0844084 Test Loss: 0.1173107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0819396\n",
      "\tspeed: 0.0404s/iter; left time: 662.8102s\n",
      "\titers: 200, epoch: 27 | loss: 0.0869512\n",
      "\tspeed: 0.0195s/iter; left time: 317.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0840297 Vali Loss: 0.0846008 Test Loss: 0.1175796\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0859564\n",
      "\tspeed: 0.0386s/iter; left time: 624.9775s\n",
      "\titers: 200, epoch: 28 | loss: 0.0873584\n",
      "\tspeed: 0.0180s/iter; left time: 289.1979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0837992 Vali Loss: 0.0845674 Test Loss: 0.1199782\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0821546\n",
      "\tspeed: 0.0382s/iter; left time: 610.2197s\n",
      "\titers: 200, epoch: 29 | loss: 0.0846214\n",
      "\tspeed: 0.0178s/iter; left time: 282.3562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0837742 Vali Loss: 0.0844055 Test Loss: 0.1191112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0844201\n",
      "\tspeed: 0.0412s/iter; left time: 647.6364s\n",
      "\titers: 200, epoch: 30 | loss: 0.0841895\n",
      "\tspeed: 0.0222s/iter; left time: 346.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0837221 Vali Loss: 0.0842772 Test Loss: 0.1190496\n",
      "Validation loss decreased (0.084377 --> 0.084277).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0870948\n",
      "\tspeed: 0.0393s/iter; left time: 609.4403s\n",
      "\titers: 200, epoch: 31 | loss: 0.0821873\n",
      "\tspeed: 0.0177s/iter; left time: 273.4505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0836353 Vali Loss: 0.0842929 Test Loss: 0.1206920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0848337\n",
      "\tspeed: 0.0377s/iter; left time: 576.4363s\n",
      "\titers: 200, epoch: 32 | loss: 0.0830336\n",
      "\tspeed: 0.0177s/iter; left time: 268.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0837642 Vali Loss: 0.0842275 Test Loss: 0.1182323\n",
      "Validation loss decreased (0.084277 --> 0.084228).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0846711\n",
      "\tspeed: 0.0395s/iter; left time: 594.5822s\n",
      "\titers: 200, epoch: 33 | loss: 0.0801985\n",
      "\tspeed: 0.0180s/iter; left time: 269.5565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0836584 Vali Loss: 0.0844522 Test Loss: 0.1194240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0836901\n",
      "\tspeed: 0.0381s/iter; left time: 565.8463s\n",
      "\titers: 200, epoch: 34 | loss: 0.0838794\n",
      "\tspeed: 0.0177s/iter; left time: 260.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0836737 Vali Loss: 0.0843503 Test Loss: 0.1194371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0843293\n",
      "\tspeed: 0.0396s/iter; left time: 578.5798s\n",
      "\titers: 200, epoch: 35 | loss: 0.0848211\n",
      "\tspeed: 0.0179s/iter; left time: 259.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0835618 Vali Loss: 0.0844821 Test Loss: 0.1200642\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0810826\n",
      "\tspeed: 0.0387s/iter; left time: 556.7249s\n",
      "\titers: 200, epoch: 36 | loss: 0.0852567\n",
      "\tspeed: 0.0177s/iter; left time: 253.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0838000 Vali Loss: 0.0845061 Test Loss: 0.1194763\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0803306\n",
      "\tspeed: 0.0410s/iter; left time: 581.3790s\n",
      "\titers: 200, epoch: 37 | loss: 0.0833322\n",
      "\tspeed: 0.0182s/iter; left time: 255.9273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0835411 Vali Loss: 0.0843955 Test Loss: 0.1186716\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0823816\n",
      "\tspeed: 0.0381s/iter; left time: 531.2084s\n",
      "\titers: 200, epoch: 38 | loss: 0.0843670\n",
      "\tspeed: 0.0181s/iter; left time: 250.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0834298 Vali Loss: 0.0843624 Test Loss: 0.1192587\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0864377\n",
      "\tspeed: 0.0393s/iter; left time: 539.8572s\n",
      "\titers: 200, epoch: 39 | loss: 0.0857570\n",
      "\tspeed: 0.0178s/iter; left time: 242.5847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0836104 Vali Loss: 0.0843764 Test Loss: 0.1198429\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0814850\n",
      "\tspeed: 0.0378s/iter; left time: 510.7382s\n",
      "\titers: 200, epoch: 40 | loss: 0.0841378\n",
      "\tspeed: 0.0178s/iter; left time: 238.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0839965 Vali Loss: 0.0844893 Test Loss: 0.1194120\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0799215\n",
      "\tspeed: 0.0376s/iter; left time: 499.8096s\n",
      "\titers: 200, epoch: 41 | loss: 0.0783022\n",
      "\tspeed: 0.0179s/iter; left time: 235.6896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0834080 Vali Loss: 0.0841839 Test Loss: 0.1189149\n",
      "Validation loss decreased (0.084228 --> 0.084184).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0835249\n",
      "\tspeed: 0.0388s/iter; left time: 506.5320s\n",
      "\titers: 200, epoch: 42 | loss: 0.0811903\n",
      "\tspeed: 0.0178s/iter; left time: 230.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0834037 Vali Loss: 0.0844404 Test Loss: 0.1207593\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0831517\n",
      "\tspeed: 0.0379s/iter; left time: 486.5615s\n",
      "\titers: 200, epoch: 43 | loss: 0.0815078\n",
      "\tspeed: 0.0177s/iter; left time: 225.4865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0834141 Vali Loss: 0.0845041 Test Loss: 0.1203174\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0865642\n",
      "\tspeed: 0.0378s/iter; left time: 477.0652s\n",
      "\titers: 200, epoch: 44 | loss: 0.0847886\n",
      "\tspeed: 0.0182s/iter; left time: 227.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0835477 Vali Loss: 0.0844085 Test Loss: 0.1198660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0788437\n",
      "\tspeed: 0.0417s/iter; left time: 516.0462s\n",
      "\titers: 200, epoch: 45 | loss: 0.0816742\n",
      "\tspeed: 0.0179s/iter; left time: 220.3732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0834426 Vali Loss: 0.0842027 Test Loss: 0.1195737\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0830794\n",
      "\tspeed: 0.0397s/iter; left time: 482.8533s\n",
      "\titers: 200, epoch: 46 | loss: 0.0839437\n",
      "\tspeed: 0.0186s/iter; left time: 224.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 223 | Train Loss: 0.0833704 Vali Loss: 0.0842480 Test Loss: 0.1193747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0823590\n",
      "\tspeed: 0.0385s/iter; left time: 459.4566s\n",
      "\titers: 200, epoch: 47 | loss: 0.0856680\n",
      "\tspeed: 0.0177s/iter; left time: 209.2620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0832862 Vali Loss: 0.0841228 Test Loss: 0.1197550\n",
      "Validation loss decreased (0.084184 --> 0.084123).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0883429\n",
      "\tspeed: 0.0387s/iter; left time: 453.8099s\n",
      "\titers: 200, epoch: 48 | loss: 0.0826623\n",
      "\tspeed: 0.0177s/iter; left time: 205.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0833737 Vali Loss: 0.0842797 Test Loss: 0.1200274\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0815217\n",
      "\tspeed: 0.0387s/iter; left time: 444.5435s\n",
      "\titers: 200, epoch: 49 | loss: 0.0848437\n",
      "\tspeed: 0.0184s/iter; left time: 209.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0833760 Vali Loss: 0.0841590 Test Loss: 0.1200445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0827644\n",
      "\tspeed: 0.0379s/iter; left time: 427.7059s\n",
      "\titers: 200, epoch: 50 | loss: 0.0767582\n",
      "\tspeed: 0.0177s/iter; left time: 197.5258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0832877 Vali Loss: 0.0839660 Test Loss: 0.1184397\n",
      "Validation loss decreased (0.084123 --> 0.083966).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0835075\n",
      "\tspeed: 0.0384s/iter; left time: 424.8004s\n",
      "\titers: 200, epoch: 51 | loss: 0.0817596\n",
      "\tspeed: 0.0177s/iter; left time: 193.5049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0832505 Vali Loss: 0.0842132 Test Loss: 0.1197245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0808008\n",
      "\tspeed: 0.0377s/iter; left time: 408.7473s\n",
      "\titers: 200, epoch: 52 | loss: 0.0849158\n",
      "\tspeed: 0.0181s/iter; left time: 194.0784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0834962 Vali Loss: 0.0841127 Test Loss: 0.1192776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0800299\n",
      "\tspeed: 0.0407s/iter; left time: 431.5793s\n",
      "\titers: 200, epoch: 53 | loss: 0.0820698\n",
      "\tspeed: 0.0179s/iter; left time: 188.3099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0832694 Vali Loss: 0.0842121 Test Loss: 0.1194684\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0802618\n",
      "\tspeed: 0.0379s/iter; left time: 393.3319s\n",
      "\titers: 200, epoch: 54 | loss: 0.0827059\n",
      "\tspeed: 0.0178s/iter; left time: 183.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0833176 Vali Loss: 0.0842278 Test Loss: 0.1203044\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0861164\n",
      "\tspeed: 0.0401s/iter; left time: 407.5977s\n",
      "\titers: 200, epoch: 55 | loss: 0.0852268\n",
      "\tspeed: 0.0187s/iter; left time: 187.8602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0833072 Vali Loss: 0.0842820 Test Loss: 0.1206407\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0806998\n",
      "\tspeed: 0.0387s/iter; left time: 384.6696s\n",
      "\titers: 200, epoch: 56 | loss: 0.0823214\n",
      "\tspeed: 0.0178s/iter; left time: 174.6927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0834395 Vali Loss: 0.0842447 Test Loss: 0.1202066\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0837483\n",
      "\tspeed: 0.0387s/iter; left time: 376.3452s\n",
      "\titers: 200, epoch: 57 | loss: 0.0801571\n",
      "\tspeed: 0.0197s/iter; left time: 189.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0833268 Vali Loss: 0.0842674 Test Loss: 0.1203132\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0821808\n",
      "\tspeed: 0.0419s/iter; left time: 397.5706s\n",
      "\titers: 200, epoch: 58 | loss: 0.0829196\n",
      "\tspeed: 0.0200s/iter; left time: 187.7119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0832269 Vali Loss: 0.0843088 Test Loss: 0.1198582\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0822175\n",
      "\tspeed: 0.0380s/iter; left time: 352.3228s\n",
      "\titers: 200, epoch: 59 | loss: 0.0831296\n",
      "\tspeed: 0.0177s/iter; left time: 162.2464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0833064 Vali Loss: 0.0840443 Test Loss: 0.1194816\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0843803\n",
      "\tspeed: 0.0383s/iter; left time: 346.6295s\n",
      "\titers: 200, epoch: 60 | loss: 0.0825238\n",
      "\tspeed: 0.0177s/iter; left time: 158.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.0836524 Vali Loss: 0.0842534 Test Loss: 0.1202688\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03208500146865845, rmse:0.17912286520004272, mae:0.1184396892786026, rse:0.5262468457221985\n",
      "Intermediate time for ES and pred_len 168: 00h:08m:43.78s\n",
      "Intermediate time for ES: 00h:29m:19.98s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2387870\n",
      "\tspeed: 0.0372s/iter; left time: 836.6014s\n",
      "\titers: 200, epoch: 1 | loss: 0.2139293\n",
      "\tspeed: 0.0166s/iter; left time: 371.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.2391190 Vali Loss: 0.1718954 Test Loss: 0.1789114\n",
      "Validation loss decreased (inf --> 0.171895).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1444989\n",
      "\tspeed: 0.0290s/iter; left time: 646.5466s\n",
      "\titers: 200, epoch: 2 | loss: 0.1030055\n",
      "\tspeed: 0.0164s/iter; left time: 364.2849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.1399414 Vali Loss: 0.0846169 Test Loss: 0.0930004\n",
      "Validation loss decreased (0.171895 --> 0.084617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0855119\n",
      "\tspeed: 0.0387s/iter; left time: 853.1069s\n",
      "\titers: 200, epoch: 3 | loss: 0.0796396\n",
      "\tspeed: 0.0195s/iter; left time: 428.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 226 | Train Loss: 0.0862447 Vali Loss: 0.0776337 Test Loss: 0.0803794\n",
      "Validation loss decreased (0.084617 --> 0.077634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774116\n",
      "\tspeed: 0.0269s/iter; left time: 587.9104s\n",
      "\titers: 200, epoch: 4 | loss: 0.0713846\n",
      "\tspeed: 0.0107s/iter; left time: 232.0666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.62s\n",
      "Steps: 226 | Train Loss: 0.0744315 Vali Loss: 0.0723683 Test Loss: 0.0729725\n",
      "Validation loss decreased (0.077634 --> 0.072368).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0675851\n",
      "\tspeed: 0.0273s/iter; left time: 589.1216s\n",
      "\titers: 200, epoch: 5 | loss: 0.0648144\n",
      "\tspeed: 0.0164s/iter; left time: 353.4620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0683895 Vali Loss: 0.0677736 Test Loss: 0.0678707\n",
      "Validation loss decreased (0.072368 --> 0.067774).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0625560\n",
      "\tspeed: 0.0329s/iter; left time: 702.1603s\n",
      "\titers: 200, epoch: 6 | loss: 0.0605061\n",
      "\tspeed: 0.0172s/iter; left time: 365.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0641057 Vali Loss: 0.0669710 Test Loss: 0.0681956\n",
      "Validation loss decreased (0.067774 --> 0.066971).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0640559\n",
      "\tspeed: 0.0319s/iter; left time: 674.4038s\n",
      "\titers: 200, epoch: 7 | loss: 0.0622133\n",
      "\tspeed: 0.0175s/iter; left time: 368.6755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0617407 Vali Loss: 0.0671168 Test Loss: 0.0687033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596539\n",
      "\tspeed: 0.0319s/iter; left time: 667.6760s\n",
      "\titers: 200, epoch: 8 | loss: 0.0568511\n",
      "\tspeed: 0.0163s/iter; left time: 338.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0595213 Vali Loss: 0.0637386 Test Loss: 0.0658388\n",
      "Validation loss decreased (0.066971 --> 0.063739).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0613193\n",
      "\tspeed: 0.0376s/iter; left time: 778.7144s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555061\n",
      "\tspeed: 0.0194s/iter; left time: 399.3243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0582117 Vali Loss: 0.0640913 Test Loss: 0.0660351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564618\n",
      "\tspeed: 0.0343s/iter; left time: 701.3254s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569139\n",
      "\tspeed: 0.0157s/iter; left time: 319.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0570274 Vali Loss: 0.0628751 Test Loss: 0.0648090\n",
      "Validation loss decreased (0.063739 --> 0.062875).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0547675\n",
      "\tspeed: 0.0329s/iter; left time: 665.4400s\n",
      "\titers: 200, epoch: 11 | loss: 0.0522877\n",
      "\tspeed: 0.0181s/iter; left time: 364.4495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0563346 Vali Loss: 0.0616423 Test Loss: 0.0636703\n",
      "Validation loss decreased (0.062875 --> 0.061642).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0635433\n",
      "\tspeed: 0.0306s/iter; left time: 612.2893s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654986\n",
      "\tspeed: 0.0203s/iter; left time: 403.5458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0555374 Vali Loss: 0.0614510 Test Loss: 0.0635653\n",
      "Validation loss decreased (0.061642 --> 0.061451).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0531383\n",
      "\tspeed: 0.0375s/iter; left time: 742.8981s\n",
      "\titers: 200, epoch: 13 | loss: 0.0553830\n",
      "\tspeed: 0.0205s/iter; left time: 404.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 226 | Train Loss: 0.0548404 Vali Loss: 0.0604893 Test Loss: 0.0627076\n",
      "Validation loss decreased (0.061451 --> 0.060489).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0534457\n",
      "\tspeed: 0.0387s/iter; left time: 757.3095s\n",
      "\titers: 200, epoch: 14 | loss: 0.0527696\n",
      "\tspeed: 0.0148s/iter; left time: 288.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0542413 Vali Loss: 0.0604573 Test Loss: 0.0628189\n",
      "Validation loss decreased (0.060489 --> 0.060457).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0518984\n",
      "\tspeed: 0.0321s/iter; left time: 621.0095s\n",
      "\titers: 200, epoch: 15 | loss: 0.0516676\n",
      "\tspeed: 0.0169s/iter; left time: 324.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0537804 Vali Loss: 0.0600585 Test Loss: 0.0623806\n",
      "Validation loss decreased (0.060457 --> 0.060059).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0550333\n",
      "\tspeed: 0.0327s/iter; left time: 625.8643s\n",
      "\titers: 200, epoch: 16 | loss: 0.0510157\n",
      "\tspeed: 0.0168s/iter; left time: 318.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0535094 Vali Loss: 0.0602220 Test Loss: 0.0625936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0523797\n",
      "\tspeed: 0.0357s/iter; left time: 674.3092s\n",
      "\titers: 200, epoch: 17 | loss: 0.0531689\n",
      "\tspeed: 0.0221s/iter; left time: 414.3207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 226 | Train Loss: 0.0532145 Vali Loss: 0.0605116 Test Loss: 0.0627661\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0516262\n",
      "\tspeed: 0.0306s/iter; left time: 570.1852s\n",
      "\titers: 200, epoch: 18 | loss: 0.0522057\n",
      "\tspeed: 0.0132s/iter; left time: 245.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0530755 Vali Loss: 0.0596637 Test Loss: 0.0620338\n",
      "Validation loss decreased (0.060059 --> 0.059664).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0540840\n",
      "\tspeed: 0.0358s/iter; left time: 660.1307s\n",
      "\titers: 200, epoch: 19 | loss: 0.0570081\n",
      "\tspeed: 0.0213s/iter; left time: 390.4862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0527678 Vali Loss: 0.0602670 Test Loss: 0.0627092\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0530464\n",
      "\tspeed: 0.0343s/iter; left time: 625.0790s\n",
      "\titers: 200, epoch: 20 | loss: 0.0567837\n",
      "\tspeed: 0.0123s/iter; left time: 222.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 226 | Train Loss: 0.0526713 Vali Loss: 0.0596454 Test Loss: 0.0620650\n",
      "Validation loss decreased (0.059664 --> 0.059645).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0499494\n",
      "\tspeed: 0.0331s/iter; left time: 595.3982s\n",
      "\titers: 200, epoch: 21 | loss: 0.0520596\n",
      "\tspeed: 0.0243s/iter; left time: 434.1204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 226 | Train Loss: 0.0523840 Vali Loss: 0.0598361 Test Loss: 0.0620769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0509677\n",
      "\tspeed: 0.0362s/iter; left time: 642.1720s\n",
      "\titers: 200, epoch: 22 | loss: 0.0528032\n",
      "\tspeed: 0.0182s/iter; left time: 321.4773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0524401 Vali Loss: 0.0595239 Test Loss: 0.0619001\n",
      "Validation loss decreased (0.059645 --> 0.059524).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0528261\n",
      "\tspeed: 0.0317s/iter; left time: 555.8472s\n",
      "\titers: 200, epoch: 23 | loss: 0.0492108\n",
      "\tspeed: 0.0165s/iter; left time: 288.0443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0522637 Vali Loss: 0.0590840 Test Loss: 0.0614077\n",
      "Validation loss decreased (0.059524 --> 0.059084).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0518252\n",
      "\tspeed: 0.0338s/iter; left time: 585.2626s\n",
      "\titers: 200, epoch: 24 | loss: 0.0523993\n",
      "\tspeed: 0.0167s/iter; left time: 286.6116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0520737 Vali Loss: 0.0589433 Test Loss: 0.0612480\n",
      "Validation loss decreased (0.059084 --> 0.058943).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0526683\n",
      "\tspeed: 0.0354s/iter; left time: 605.1103s\n",
      "\titers: 200, epoch: 25 | loss: 0.0541010\n",
      "\tspeed: 0.0204s/iter; left time: 347.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 226 | Train Loss: 0.0521598 Vali Loss: 0.0588813 Test Loss: 0.0613570\n",
      "Validation loss decreased (0.058943 --> 0.058881).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0520070\n",
      "\tspeed: 0.0275s/iter; left time: 463.4306s\n",
      "\titers: 200, epoch: 26 | loss: 0.0532121\n",
      "\tspeed: 0.0095s/iter; left time: 159.4862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.47s\n",
      "Steps: 226 | Train Loss: 0.0518301 Vali Loss: 0.0587287 Test Loss: 0.0611357\n",
      "Validation loss decreased (0.058881 --> 0.058729).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0526764\n",
      "\tspeed: 0.0315s/iter; left time: 523.8758s\n",
      "\titers: 200, epoch: 27 | loss: 0.0514687\n",
      "\tspeed: 0.0152s/iter; left time: 250.7870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0517552 Vali Loss: 0.0590239 Test Loss: 0.0614569\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0513778\n",
      "\tspeed: 0.0345s/iter; left time: 566.2563s\n",
      "\titers: 200, epoch: 28 | loss: 0.0509993\n",
      "\tspeed: 0.0164s/iter; left time: 267.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0516570 Vali Loss: 0.0591060 Test Loss: 0.0615547\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0525079\n",
      "\tspeed: 0.0268s/iter; left time: 433.5700s\n",
      "\titers: 200, epoch: 29 | loss: 0.0533223\n",
      "\tspeed: 0.0183s/iter; left time: 294.8776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0516441 Vali Loss: 0.0588266 Test Loss: 0.0614746\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0481990\n",
      "\tspeed: 0.0345s/iter; left time: 549.9548s\n",
      "\titers: 200, epoch: 30 | loss: 0.0526182\n",
      "\tspeed: 0.0192s/iter; left time: 304.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 226 | Train Loss: 0.0515156 Vali Loss: 0.0585467 Test Loss: 0.0610625\n",
      "Validation loss decreased (0.058729 --> 0.058547).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0509937\n",
      "\tspeed: 0.0321s/iter; left time: 504.5547s\n",
      "\titers: 200, epoch: 31 | loss: 0.0554018\n",
      "\tspeed: 0.0141s/iter; left time: 220.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0514165 Vali Loss: 0.0584982 Test Loss: 0.0609978\n",
      "Validation loss decreased (0.058547 --> 0.058498).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0521961\n",
      "\tspeed: 0.0336s/iter; left time: 520.0480s\n",
      "\titers: 200, epoch: 32 | loss: 0.0502925\n",
      "\tspeed: 0.0181s/iter; left time: 279.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0514829 Vali Loss: 0.0585121 Test Loss: 0.0609906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0542395\n",
      "\tspeed: 0.0322s/iter; left time: 491.2185s\n",
      "\titers: 200, epoch: 33 | loss: 0.0552315\n",
      "\tspeed: 0.0162s/iter; left time: 246.0203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0513255 Vali Loss: 0.0585441 Test Loss: 0.0610287\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0502087\n",
      "\tspeed: 0.0259s/iter; left time: 389.3056s\n",
      "\titers: 200, epoch: 34 | loss: 0.0526543\n",
      "\tspeed: 0.0109s/iter; left time: 163.4999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.65s\n",
      "Steps: 226 | Train Loss: 0.0512074 Vali Loss: 0.0585198 Test Loss: 0.0610669\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0515986\n",
      "\tspeed: 0.0253s/iter; left time: 374.6177s\n",
      "\titers: 200, epoch: 35 | loss: 0.0516961\n",
      "\tspeed: 0.0111s/iter; left time: 163.1161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 226 | Train Loss: 0.0512349 Vali Loss: 0.0588582 Test Loss: 0.0614055\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0545352\n",
      "\tspeed: 0.0325s/iter; left time: 474.5437s\n",
      "\titers: 200, epoch: 36 | loss: 0.0521886\n",
      "\tspeed: 0.0149s/iter; left time: 215.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0511284 Vali Loss: 0.0586213 Test Loss: 0.0610915\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0492245\n",
      "\tspeed: 0.0320s/iter; left time: 460.3118s\n",
      "\titers: 200, epoch: 37 | loss: 0.0546065\n",
      "\tspeed: 0.0187s/iter; left time: 266.2676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0512189 Vali Loss: 0.0586420 Test Loss: 0.0611143\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0489465\n",
      "\tspeed: 0.0339s/iter; left time: 479.8878s\n",
      "\titers: 200, epoch: 38 | loss: 0.0510282\n",
      "\tspeed: 0.0204s/iter; left time: 286.3833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0512186 Vali Loss: 0.0585996 Test Loss: 0.0611576\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0521461\n",
      "\tspeed: 0.0336s/iter; left time: 467.2052s\n",
      "\titers: 200, epoch: 39 | loss: 0.0486002\n",
      "\tspeed: 0.0170s/iter; left time: 234.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0512181 Vali Loss: 0.0583023 Test Loss: 0.0607115\n",
      "Validation loss decreased (0.058498 --> 0.058302).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0483637\n",
      "\tspeed: 0.0304s/iter; left time: 415.9153s\n",
      "\titers: 200, epoch: 40 | loss: 0.0534848\n",
      "\tspeed: 0.0139s/iter; left time: 189.5062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0511078 Vali Loss: 0.0584909 Test Loss: 0.0609967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0510957\n",
      "\tspeed: 0.0267s/iter; left time: 359.9818s\n",
      "\titers: 200, epoch: 41 | loss: 0.0504879\n",
      "\tspeed: 0.0123s/iter; left time: 164.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0512328 Vali Loss: 0.0588054 Test Loss: 0.0613718\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0496044\n",
      "\tspeed: 0.0273s/iter; left time: 360.8408s\n",
      "\titers: 200, epoch: 42 | loss: 0.0513230\n",
      "\tspeed: 0.0137s/iter; left time: 180.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0509708 Vali Loss: 0.0584022 Test Loss: 0.0609477\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0525000\n",
      "\tspeed: 0.0279s/iter; left time: 362.9609s\n",
      "\titers: 200, epoch: 43 | loss: 0.0508434\n",
      "\tspeed: 0.0125s/iter; left time: 161.1673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0512291 Vali Loss: 0.0583417 Test Loss: 0.0607665\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0548755\n",
      "\tspeed: 0.0337s/iter; left time: 430.8043s\n",
      "\titers: 200, epoch: 44 | loss: 0.0522109\n",
      "\tspeed: 0.0174s/iter; left time: 221.2122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0510478 Vali Loss: 0.0582927 Test Loss: 0.0607605\n",
      "Validation loss decreased (0.058302 --> 0.058293).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0506126\n",
      "\tspeed: 0.0325s/iter; left time: 407.9411s\n",
      "\titers: 200, epoch: 45 | loss: 0.0528465\n",
      "\tspeed: 0.0181s/iter; left time: 226.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 226 | Train Loss: 0.0512065 Vali Loss: 0.0584716 Test Loss: 0.0607955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0543340\n",
      "\tspeed: 0.0289s/iter; left time: 356.3160s\n",
      "\titers: 200, epoch: 46 | loss: 0.0472873\n",
      "\tspeed: 0.0111s/iter; left time: 135.3325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0511917 Vali Loss: 0.0584659 Test Loss: 0.0609901\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0537727\n",
      "\tspeed: 0.0357s/iter; left time: 432.1095s\n",
      "\titers: 200, epoch: 47 | loss: 0.0553661\n",
      "\tspeed: 0.0211s/iter; left time: 252.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0511310 Vali Loss: 0.0588045 Test Loss: 0.0614261\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0514362\n",
      "\tspeed: 0.0390s/iter; left time: 463.5479s\n",
      "\titers: 200, epoch: 48 | loss: 0.0472045\n",
      "\tspeed: 0.0208s/iter; left time: 244.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 226 | Train Loss: 0.0510057 Vali Loss: 0.0584156 Test Loss: 0.0608528\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0496042\n",
      "\tspeed: 0.0378s/iter; left time: 440.3898s\n",
      "\titers: 200, epoch: 49 | loss: 0.0499088\n",
      "\tspeed: 0.0191s/iter; left time: 220.2751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 226 | Train Loss: 0.0511481 Vali Loss: 0.0587064 Test Loss: 0.0612833\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0537619\n",
      "\tspeed: 0.0347s/iter; left time: 396.2178s\n",
      "\titers: 200, epoch: 50 | loss: 0.0525173\n",
      "\tspeed: 0.0178s/iter; left time: 202.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0510573 Vali Loss: 0.0584213 Test Loss: 0.0609016\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0498492\n",
      "\tspeed: 0.0336s/iter; left time: 375.9466s\n",
      "\titers: 200, epoch: 51 | loss: 0.0518584\n",
      "\tspeed: 0.0176s/iter; left time: 195.3822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 226 | Train Loss: 0.0510924 Vali Loss: 0.0582117 Test Loss: 0.0606907\n",
      "Validation loss decreased (0.058293 --> 0.058212).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0508633\n",
      "\tspeed: 0.0335s/iter; left time: 367.6509s\n",
      "\titers: 200, epoch: 52 | loss: 0.0550103\n",
      "\tspeed: 0.0153s/iter; left time: 166.6187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0509129 Vali Loss: 0.0581993 Test Loss: 0.0607614\n",
      "Validation loss decreased (0.058212 --> 0.058199).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0480261\n",
      "\tspeed: 0.0354s/iter; left time: 380.1742s\n",
      "\titers: 200, epoch: 53 | loss: 0.0512180\n",
      "\tspeed: 0.0135s/iter; left time: 143.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0509997 Vali Loss: 0.0583812 Test Loss: 0.0609259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0531948\n",
      "\tspeed: 0.0275s/iter; left time: 289.6032s\n",
      "\titers: 200, epoch: 54 | loss: 0.0474615\n",
      "\tspeed: 0.0152s/iter; left time: 158.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0509769 Vali Loss: 0.0583499 Test Loss: 0.0608505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0507050\n",
      "\tspeed: 0.0330s/iter; left time: 339.8780s\n",
      "\titers: 200, epoch: 55 | loss: 0.0514766\n",
      "\tspeed: 0.0191s/iter; left time: 194.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0510671 Vali Loss: 0.0582356 Test Loss: 0.0607276\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0516714\n",
      "\tspeed: 0.0325s/iter; left time: 327.3084s\n",
      "\titers: 200, epoch: 56 | loss: 0.0518651\n",
      "\tspeed: 0.0148s/iter; left time: 147.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0510166 Vali Loss: 0.0582356 Test Loss: 0.0607591\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0489705\n",
      "\tspeed: 0.0337s/iter; left time: 331.6164s\n",
      "\titers: 200, epoch: 57 | loss: 0.0528853\n",
      "\tspeed: 0.0169s/iter; left time: 164.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0509707 Vali Loss: 0.0582195 Test Loss: 0.0607423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0502746\n",
      "\tspeed: 0.0344s/iter; left time: 330.6800s\n",
      "\titers: 200, epoch: 58 | loss: 0.0522595\n",
      "\tspeed: 0.0161s/iter; left time: 152.8633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0511142 Vali Loss: 0.0584232 Test Loss: 0.0608961\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0509823\n",
      "\tspeed: 0.0321s/iter; left time: 301.4973s\n",
      "\titers: 200, epoch: 59 | loss: 0.0486975\n",
      "\tspeed: 0.0173s/iter; left time: 160.6202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0508444 Vali Loss: 0.0588405 Test Loss: 0.0614654\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0516023\n",
      "\tspeed: 0.0349s/iter; left time: 319.4895s\n",
      "\titers: 200, epoch: 60 | loss: 0.0504437\n",
      "\tspeed: 0.0185s/iter; left time: 167.3402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 226 | Train Loss: 0.0511295 Vali Loss: 0.0581398 Test Loss: 0.0605930\n",
      "Validation loss decreased (0.058199 --> 0.058140).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0520362\n",
      "\tspeed: 0.0321s/iter; left time: 287.2443s\n",
      "\titers: 200, epoch: 61 | loss: 0.0556048\n",
      "\tspeed: 0.0149s/iter; left time: 132.1537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0510963 Vali Loss: 0.0583216 Test Loss: 0.0608756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0489466\n",
      "\tspeed: 0.0308s/iter; left time: 268.6907s\n",
      "\titers: 200, epoch: 62 | loss: 0.0509101\n",
      "\tspeed: 0.0167s/iter; left time: 143.5892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0509727 Vali Loss: 0.0582650 Test Loss: 0.0607129\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0520241\n",
      "\tspeed: 0.0300s/iter; left time: 254.4145s\n",
      "\titers: 200, epoch: 63 | loss: 0.0503084\n",
      "\tspeed: 0.0165s/iter; left time: 138.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0510012 Vali Loss: 0.0585479 Test Loss: 0.0611012\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0499376\n",
      "\tspeed: 0.0364s/iter; left time: 301.1208s\n",
      "\titers: 200, epoch: 64 | loss: 0.0512204\n",
      "\tspeed: 0.0198s/iter; left time: 161.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 226 | Train Loss: 0.0509128 Vali Loss: 0.0585969 Test Loss: 0.0610523\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0492525\n",
      "\tspeed: 0.0351s/iter; left time: 281.9243s\n",
      "\titers: 200, epoch: 65 | loss: 0.0499918\n",
      "\tspeed: 0.0154s/iter; left time: 122.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0509866 Vali Loss: 0.0582172 Test Loss: 0.0607015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0500380\n",
      "\tspeed: 0.0343s/iter; left time: 267.8132s\n",
      "\titers: 200, epoch: 66 | loss: 0.0492308\n",
      "\tspeed: 0.0129s/iter; left time: 99.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 226 | Train Loss: 0.0509230 Vali Loss: 0.0582179 Test Loss: 0.0606962\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0567633\n",
      "\tspeed: 0.0309s/iter; left time: 234.0709s\n",
      "\titers: 200, epoch: 67 | loss: 0.0497529\n",
      "\tspeed: 0.0165s/iter; left time: 123.5086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0509263 Vali Loss: 0.0583092 Test Loss: 0.0607846\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0494144\n",
      "\tspeed: 0.0312s/iter; left time: 229.9635s\n",
      "\titers: 200, epoch: 68 | loss: 0.0522436\n",
      "\tspeed: 0.0165s/iter; left time: 119.6559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0509374 Vali Loss: 0.0584095 Test Loss: 0.0608217\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0530711\n",
      "\tspeed: 0.0322s/iter; left time: 229.7920s\n",
      "\titers: 200, epoch: 69 | loss: 0.0486707\n",
      "\tspeed: 0.0140s/iter; left time: 98.2286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0508935 Vali Loss: 0.0582418 Test Loss: 0.0607684\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0478494\n",
      "\tspeed: 0.0312s/iter; left time: 215.1662s\n",
      "\titers: 200, epoch: 70 | loss: 0.0519286\n",
      "\tspeed: 0.0173s/iter; left time: 117.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0509530 Vali Loss: 0.0583988 Test Loss: 0.0609481\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011059106327593327, rmse:0.10516228526830673, mae:0.06059299036860466, rse:0.40571320056915283\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2416628\n",
      "\tspeed: 0.0195s/iter; left time: 439.8132s\n",
      "\titers: 200, epoch: 1 | loss: 0.2118645\n",
      "\tspeed: 0.0191s/iter; left time: 426.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.2365767 Vali Loss: 0.1752155 Test Loss: 0.1818404\n",
      "Validation loss decreased (inf --> 0.175215).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1395827\n",
      "\tspeed: 0.0319s/iter; left time: 710.5907s\n",
      "\titers: 200, epoch: 2 | loss: 0.1041168\n",
      "\tspeed: 0.0176s/iter; left time: 389.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.1377829 Vali Loss: 0.0912523 Test Loss: 0.0981285\n",
      "Validation loss decreased (0.175215 --> 0.091252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0868506\n",
      "\tspeed: 0.0353s/iter; left time: 777.5708s\n",
      "\titers: 200, epoch: 3 | loss: 0.0817878\n",
      "\tspeed: 0.0188s/iter; left time: 411.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0857371 Vali Loss: 0.0796753 Test Loss: 0.0823581\n",
      "Validation loss decreased (0.091252 --> 0.079675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0767839\n",
      "\tspeed: 0.0342s/iter; left time: 747.3954s\n",
      "\titers: 200, epoch: 4 | loss: 0.0726637\n",
      "\tspeed: 0.0171s/iter; left time: 371.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 226 | Train Loss: 0.0733852 Vali Loss: 0.0716293 Test Loss: 0.0714761\n",
      "Validation loss decreased (0.079675 --> 0.071629).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0654529\n",
      "\tspeed: 0.0325s/iter; left time: 701.3059s\n",
      "\titers: 200, epoch: 5 | loss: 0.0700655\n",
      "\tspeed: 0.0152s/iter; left time: 325.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0672182 Vali Loss: 0.0680346 Test Loss: 0.0680098\n",
      "Validation loss decreased (0.071629 --> 0.068035).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0712112\n",
      "\tspeed: 0.0335s/iter; left time: 716.6855s\n",
      "\titers: 200, epoch: 6 | loss: 0.0635504\n",
      "\tspeed: 0.0185s/iter; left time: 394.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0631633 Vali Loss: 0.0652654 Test Loss: 0.0669694\n",
      "Validation loss decreased (0.068035 --> 0.065265).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0623794\n",
      "\tspeed: 0.0332s/iter; left time: 702.2844s\n",
      "\titers: 200, epoch: 7 | loss: 0.0575420\n",
      "\tspeed: 0.0150s/iter; left time: 315.7085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0606888 Vali Loss: 0.0636692 Test Loss: 0.0657486\n",
      "Validation loss decreased (0.065265 --> 0.063669).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0561675\n",
      "\tspeed: 0.0312s/iter; left time: 652.1613s\n",
      "\titers: 200, epoch: 8 | loss: 0.0559797\n",
      "\tspeed: 0.0140s/iter; left time: 292.2053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0587371 Vali Loss: 0.0633773 Test Loss: 0.0654466\n",
      "Validation loss decreased (0.063669 --> 0.063377).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0564218\n",
      "\tspeed: 0.0360s/iter; left time: 745.4763s\n",
      "\titers: 200, epoch: 9 | loss: 0.0600520\n",
      "\tspeed: 0.0162s/iter; left time: 332.6574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0578731 Vali Loss: 0.0627705 Test Loss: 0.0648424\n",
      "Validation loss decreased (0.063377 --> 0.062771).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0573411\n",
      "\tspeed: 0.0265s/iter; left time: 541.8748s\n",
      "\titers: 200, epoch: 10 | loss: 0.0585905\n",
      "\tspeed: 0.0125s/iter; left time: 255.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0567742 Vali Loss: 0.0621514 Test Loss: 0.0644379\n",
      "Validation loss decreased (0.062771 --> 0.062151).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559383\n",
      "\tspeed: 0.0366s/iter; left time: 741.4936s\n",
      "\titers: 200, epoch: 11 | loss: 0.0565468\n",
      "\tspeed: 0.0157s/iter; left time: 316.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 226 | Train Loss: 0.0557982 Vali Loss: 0.0619139 Test Loss: 0.0639982\n",
      "Validation loss decreased (0.062151 --> 0.061914).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0525815\n",
      "\tspeed: 0.0317s/iter; left time: 635.3405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0535919\n",
      "\tspeed: 0.0132s/iter; left time: 263.1438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 226 | Train Loss: 0.0552507 Vali Loss: 0.0611877 Test Loss: 0.0635318\n",
      "Validation loss decreased (0.061914 --> 0.061188).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0581328\n",
      "\tspeed: 0.0310s/iter; left time: 613.7022s\n",
      "\titers: 200, epoch: 13 | loss: 0.0549002\n",
      "\tspeed: 0.0152s/iter; left time: 299.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0547234 Vali Loss: 0.0615271 Test Loss: 0.0636993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0568595\n",
      "\tspeed: 0.0320s/iter; left time: 625.4121s\n",
      "\titers: 200, epoch: 14 | loss: 0.0548544\n",
      "\tspeed: 0.0149s/iter; left time: 289.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0543082 Vali Loss: 0.0612200 Test Loss: 0.0635789\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0548684\n",
      "\tspeed: 0.0330s/iter; left time: 637.8120s\n",
      "\titers: 200, epoch: 15 | loss: 0.0530043\n",
      "\tspeed: 0.0170s/iter; left time: 326.7457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0537783 Vali Loss: 0.0612516 Test Loss: 0.0636767\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0521529\n",
      "\tspeed: 0.0320s/iter; left time: 611.2286s\n",
      "\titers: 200, epoch: 16 | loss: 0.0506460\n",
      "\tspeed: 0.0168s/iter; left time: 320.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0537510 Vali Loss: 0.0605211 Test Loss: 0.0629692\n",
      "Validation loss decreased (0.061188 --> 0.060521).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0543273\n",
      "\tspeed: 0.0339s/iter; left time: 640.3099s\n",
      "\titers: 200, epoch: 17 | loss: 0.0502027\n",
      "\tspeed: 0.0179s/iter; left time: 335.7044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0531656 Vali Loss: 0.0603622 Test Loss: 0.0628506\n",
      "Validation loss decreased (0.060521 --> 0.060362).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0546218\n",
      "\tspeed: 0.0347s/iter; left time: 647.7130s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563045\n",
      "\tspeed: 0.0210s/iter; left time: 389.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 226 | Train Loss: 0.0531353 Vali Loss: 0.0597555 Test Loss: 0.0621679\n",
      "Validation loss decreased (0.060362 --> 0.059756).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0578719\n",
      "\tspeed: 0.0311s/iter; left time: 573.5929s\n",
      "\titers: 200, epoch: 19 | loss: 0.0559273\n",
      "\tspeed: 0.0153s/iter; left time: 279.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0529508 Vali Loss: 0.0597700 Test Loss: 0.0623024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0500620\n",
      "\tspeed: 0.0334s/iter; left time: 607.8282s\n",
      "\titers: 200, epoch: 20 | loss: 0.0510834\n",
      "\tspeed: 0.0164s/iter; left time: 297.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0527228 Vali Loss: 0.0598549 Test Loss: 0.0622901\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0518224\n",
      "\tspeed: 0.0326s/iter; left time: 585.3250s\n",
      "\titers: 200, epoch: 21 | loss: 0.0519954\n",
      "\tspeed: 0.0174s/iter; left time: 310.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 226 | Train Loss: 0.0524627 Vali Loss: 0.0598198 Test Loss: 0.0622270\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0520502\n",
      "\tspeed: 0.0311s/iter; left time: 552.6466s\n",
      "\titers: 200, epoch: 22 | loss: 0.0541251\n",
      "\tspeed: 0.0203s/iter; left time: 357.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0524199 Vali Loss: 0.0601374 Test Loss: 0.0625613\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0513092\n",
      "\tspeed: 0.0337s/iter; left time: 589.8545s\n",
      "\titers: 200, epoch: 23 | loss: 0.0516593\n",
      "\tspeed: 0.0156s/iter; left time: 271.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0523227 Vali Loss: 0.0598450 Test Loss: 0.0623014\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0510257\n",
      "\tspeed: 0.0322s/iter; left time: 557.2097s\n",
      "\titers: 200, epoch: 24 | loss: 0.0487331\n",
      "\tspeed: 0.0170s/iter; left time: 291.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0521394 Vali Loss: 0.0594246 Test Loss: 0.0619224\n",
      "Validation loss decreased (0.059756 --> 0.059425).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0467195\n",
      "\tspeed: 0.0362s/iter; left time: 617.9581s\n",
      "\titers: 200, epoch: 25 | loss: 0.0519570\n",
      "\tspeed: 0.0179s/iter; left time: 304.5729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0519435 Vali Loss: 0.0593750 Test Loss: 0.0619810\n",
      "Validation loss decreased (0.059425 --> 0.059375).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0524631\n",
      "\tspeed: 0.0318s/iter; left time: 535.6440s\n",
      "\titers: 200, epoch: 26 | loss: 0.0534046\n",
      "\tspeed: 0.0149s/iter; left time: 249.9460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0518191 Vali Loss: 0.0591756 Test Loss: 0.0617106\n",
      "Validation loss decreased (0.059375 --> 0.059176).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0542041\n",
      "\tspeed: 0.0343s/iter; left time: 569.7595s\n",
      "\titers: 200, epoch: 27 | loss: 0.0519935\n",
      "\tspeed: 0.0195s/iter; left time: 321.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0519694 Vali Loss: 0.0597937 Test Loss: 0.0622555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0515420\n",
      "\tspeed: 0.0366s/iter; left time: 600.8277s\n",
      "\titers: 200, epoch: 28 | loss: 0.0502045\n",
      "\tspeed: 0.0205s/iter; left time: 334.1975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0521151 Vali Loss: 0.0595430 Test Loss: 0.0620863\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0641427\n",
      "\tspeed: 0.0351s/iter; left time: 568.1361s\n",
      "\titers: 200, epoch: 29 | loss: 0.0514867\n",
      "\tspeed: 0.0184s/iter; left time: 296.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0518454 Vali Loss: 0.0592493 Test Loss: 0.0618645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0513309\n",
      "\tspeed: 0.0326s/iter; left time: 520.3928s\n",
      "\titers: 200, epoch: 30 | loss: 0.0528735\n",
      "\tspeed: 0.0147s/iter; left time: 232.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.0516423 Vali Loss: 0.0591638 Test Loss: 0.0616811\n",
      "Validation loss decreased (0.059176 --> 0.059164).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0508543\n",
      "\tspeed: 0.0327s/iter; left time: 513.8776s\n",
      "\titers: 200, epoch: 31 | loss: 0.0532794\n",
      "\tspeed: 0.0143s/iter; left time: 224.1262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0515427 Vali Loss: 0.0593265 Test Loss: 0.0617769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0535211\n",
      "\tspeed: 0.0310s/iter; left time: 480.6860s\n",
      "\titers: 200, epoch: 32 | loss: 0.0515713\n",
      "\tspeed: 0.0134s/iter; left time: 206.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0515884 Vali Loss: 0.0592297 Test Loss: 0.0616450\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0506216\n",
      "\tspeed: 0.0376s/iter; left time: 574.4233s\n",
      "\titers: 200, epoch: 33 | loss: 0.0552973\n",
      "\tspeed: 0.0179s/iter; left time: 270.9593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 226 | Train Loss: 0.0514787 Vali Loss: 0.0593651 Test Loss: 0.0618762\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0500266\n",
      "\tspeed: 0.0367s/iter; left time: 551.4485s\n",
      "\titers: 200, epoch: 34 | loss: 0.0525294\n",
      "\tspeed: 0.0170s/iter; left time: 254.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0515054 Vali Loss: 0.0591138 Test Loss: 0.0617489\n",
      "Validation loss decreased (0.059164 --> 0.059114).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0515080\n",
      "\tspeed: 0.0322s/iter; left time: 477.3783s\n",
      "\titers: 200, epoch: 35 | loss: 0.0520318\n",
      "\tspeed: 0.0152s/iter; left time: 223.7932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0514527 Vali Loss: 0.0590694 Test Loss: 0.0616565\n",
      "Validation loss decreased (0.059114 --> 0.059069).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0530447\n",
      "\tspeed: 0.0350s/iter; left time: 511.2124s\n",
      "\titers: 200, epoch: 36 | loss: 0.0504718\n",
      "\tspeed: 0.0111s/iter; left time: 161.0108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0514593 Vali Loss: 0.0591461 Test Loss: 0.0618174\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0502356\n",
      "\tspeed: 0.0359s/iter; left time: 516.0171s\n",
      "\titers: 200, epoch: 37 | loss: 0.0500012\n",
      "\tspeed: 0.0125s/iter; left time: 177.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0514596 Vali Loss: 0.0598087 Test Loss: 0.0623762\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0530377\n",
      "\tspeed: 0.0318s/iter; left time: 449.4951s\n",
      "\titers: 200, epoch: 38 | loss: 0.0490269\n",
      "\tspeed: 0.0173s/iter; left time: 242.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0513402 Vali Loss: 0.0593734 Test Loss: 0.0619947\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0510635\n",
      "\tspeed: 0.0339s/iter; left time: 471.4628s\n",
      "\titers: 200, epoch: 39 | loss: 0.0519244\n",
      "\tspeed: 0.0181s/iter; left time: 249.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0514132 Vali Loss: 0.0592859 Test Loss: 0.0618880\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0479976\n",
      "\tspeed: 0.0329s/iter; left time: 449.6407s\n",
      "\titers: 200, epoch: 40 | loss: 0.0587389\n",
      "\tspeed: 0.0200s/iter; left time: 272.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0512591 Vali Loss: 0.0589257 Test Loss: 0.0614904\n",
      "Validation loss decreased (0.059069 --> 0.058926).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0499182\n",
      "\tspeed: 0.0371s/iter; left time: 499.5009s\n",
      "\titers: 200, epoch: 41 | loss: 0.0517714\n",
      "\tspeed: 0.0175s/iter; left time: 233.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 226 | Train Loss: 0.0513970 Vali Loss: 0.0589165 Test Loss: 0.0615032\n",
      "Validation loss decreased (0.058926 --> 0.058916).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0555581\n",
      "\tspeed: 0.0379s/iter; left time: 501.0847s\n",
      "\titers: 200, epoch: 42 | loss: 0.0493980\n",
      "\tspeed: 0.0197s/iter; left time: 259.3494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 226 | Train Loss: 0.0512042 Vali Loss: 0.0592286 Test Loss: 0.0617734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0499269\n",
      "\tspeed: 0.0348s/iter; left time: 453.0064s\n",
      "\titers: 200, epoch: 43 | loss: 0.0529789\n",
      "\tspeed: 0.0143s/iter; left time: 184.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0513263 Vali Loss: 0.0591241 Test Loss: 0.0616876\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0506182\n",
      "\tspeed: 0.0327s/iter; left time: 417.5317s\n",
      "\titers: 200, epoch: 44 | loss: 0.0491669\n",
      "\tspeed: 0.0166s/iter; left time: 210.6603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0512939 Vali Loss: 0.0588932 Test Loss: 0.0614789\n",
      "Validation loss decreased (0.058916 --> 0.058893).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0504569\n",
      "\tspeed: 0.0394s/iter; left time: 494.2587s\n",
      "\titers: 200, epoch: 45 | loss: 0.0495079\n",
      "\tspeed: 0.0163s/iter; left time: 202.4550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0511449 Vali Loss: 0.0590043 Test Loss: 0.0615300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0504148\n",
      "\tspeed: 0.0348s/iter; left time: 428.8185s\n",
      "\titers: 200, epoch: 46 | loss: 0.0546191\n",
      "\tspeed: 0.0190s/iter; left time: 232.3433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 226 | Train Loss: 0.0512323 Vali Loss: 0.0593695 Test Loss: 0.0620349\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0528963\n",
      "\tspeed: 0.0329s/iter; left time: 397.7923s\n",
      "\titers: 200, epoch: 47 | loss: 0.0509227\n",
      "\tspeed: 0.0156s/iter; left time: 186.7503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0512757 Vali Loss: 0.0589895 Test Loss: 0.0616225\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0522054\n",
      "\tspeed: 0.0310s/iter; left time: 368.2862s\n",
      "\titers: 200, epoch: 48 | loss: 0.0484653\n",
      "\tspeed: 0.0159s/iter; left time: 187.2899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0512539 Vali Loss: 0.0591156 Test Loss: 0.0617639\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0526090\n",
      "\tspeed: 0.0317s/iter; left time: 369.9610s\n",
      "\titers: 200, epoch: 49 | loss: 0.0553374\n",
      "\tspeed: 0.0110s/iter; left time: 126.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0513467 Vali Loss: 0.0589459 Test Loss: 0.0614353\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0502638\n",
      "\tspeed: 0.0254s/iter; left time: 290.2524s\n",
      "\titers: 200, epoch: 50 | loss: 0.0521959\n",
      "\tspeed: 0.0111s/iter; left time: 125.3675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.69s\n",
      "Steps: 226 | Train Loss: 0.0512335 Vali Loss: 0.0592556 Test Loss: 0.0619066\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0534625\n",
      "\tspeed: 0.0319s/iter; left time: 356.9499s\n",
      "\titers: 200, epoch: 51 | loss: 0.0522593\n",
      "\tspeed: 0.0171s/iter; left time: 189.6773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0512247 Vali Loss: 0.0590859 Test Loss: 0.0617177\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0478016\n",
      "\tspeed: 0.0334s/iter; left time: 366.3536s\n",
      "\titers: 200, epoch: 52 | loss: 0.0518351\n",
      "\tspeed: 0.0172s/iter; left time: 186.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0513318 Vali Loss: 0.0587435 Test Loss: 0.0613683\n",
      "Validation loss decreased (0.058893 --> 0.058744).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0524634\n",
      "\tspeed: 0.0329s/iter; left time: 353.8793s\n",
      "\titers: 200, epoch: 53 | loss: 0.0528184\n",
      "\tspeed: 0.0142s/iter; left time: 151.0979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 226 | Train Loss: 0.0511697 Vali Loss: 0.0595583 Test Loss: 0.0622298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0493532\n",
      "\tspeed: 0.0340s/iter; left time: 358.2648s\n",
      "\titers: 200, epoch: 54 | loss: 0.0491158\n",
      "\tspeed: 0.0198s/iter; left time: 206.5691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.0512054 Vali Loss: 0.0594513 Test Loss: 0.0620704\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0534966\n",
      "\tspeed: 0.0317s/iter; left time: 326.8456s\n",
      "\titers: 200, epoch: 55 | loss: 0.0487425\n",
      "\tspeed: 0.0178s/iter; left time: 181.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 226 | Train Loss: 0.0513194 Vali Loss: 0.0591265 Test Loss: 0.0616807\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0520311\n",
      "\tspeed: 0.0340s/iter; left time: 342.6129s\n",
      "\titers: 200, epoch: 56 | loss: 0.0511009\n",
      "\tspeed: 0.0151s/iter; left time: 150.8292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0512252 Vali Loss: 0.0588257 Test Loss: 0.0613912\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0501452\n",
      "\tspeed: 0.0321s/iter; left time: 316.0024s\n",
      "\titers: 200, epoch: 57 | loss: 0.0561148\n",
      "\tspeed: 0.0171s/iter; left time: 166.5062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0511195 Vali Loss: 0.0592716 Test Loss: 0.0618494\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0495522\n",
      "\tspeed: 0.0329s/iter; left time: 316.4605s\n",
      "\titers: 200, epoch: 58 | loss: 0.0490600\n",
      "\tspeed: 0.0147s/iter; left time: 139.5894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0510768 Vali Loss: 0.0589688 Test Loss: 0.0614992\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0488771\n",
      "\tspeed: 0.0363s/iter; left time: 341.0892s\n",
      "\titers: 200, epoch: 59 | loss: 0.0531398\n",
      "\tspeed: 0.0169s/iter; left time: 157.4804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0511723 Vali Loss: 0.0590542 Test Loss: 0.0616732\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0536283\n",
      "\tspeed: 0.0322s/iter; left time: 295.1166s\n",
      "\titers: 200, epoch: 60 | loss: 0.0513347\n",
      "\tspeed: 0.0142s/iter; left time: 128.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 226 | Train Loss: 0.0510745 Vali Loss: 0.0591924 Test Loss: 0.0618312\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0511971\n",
      "\tspeed: 0.0244s/iter; left time: 218.4595s\n",
      "\titers: 200, epoch: 61 | loss: 0.0507888\n",
      "\tspeed: 0.0096s/iter; left time: 85.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:02.45s\n",
      "Steps: 226 | Train Loss: 0.0512314 Vali Loss: 0.0591397 Test Loss: 0.0617536\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0488633\n",
      "\tspeed: 0.0312s/iter; left time: 272.1085s\n",
      "\titers: 200, epoch: 62 | loss: 0.0498987\n",
      "\tspeed: 0.0168s/iter; left time: 144.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0511543 Vali Loss: 0.0593258 Test Loss: 0.0620149\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01122244168072939, rmse:0.10593602806329727, mae:0.061368297785520554, rse:0.40869826078414917\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:00.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2399536\n",
      "\tspeed: 0.0363s/iter; left time: 812.0937s\n",
      "\titers: 200, epoch: 1 | loss: 0.2218693\n",
      "\tspeed: 0.0145s/iter; left time: 323.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.2435918 Vali Loss: 0.1775215 Test Loss: 0.1869208\n",
      "Validation loss decreased (inf --> 0.177521).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1348915\n",
      "\tspeed: 0.0315s/iter; left time: 699.4382s\n",
      "\titers: 200, epoch: 2 | loss: 0.0999899\n",
      "\tspeed: 0.0145s/iter; left time: 320.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.1339489 Vali Loss: 0.0989685 Test Loss: 0.1108424\n",
      "Validation loss decreased (0.177521 --> 0.098968).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0897997\n",
      "\tspeed: 0.0331s/iter; left time: 726.4421s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906458\n",
      "\tspeed: 0.0156s/iter; left time: 341.5702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0907362 Vali Loss: 0.0915546 Test Loss: 0.0976730\n",
      "Validation loss decreased (0.098968 --> 0.091555).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0803316\n",
      "\tspeed: 0.0305s/iter; left time: 663.1096s\n",
      "\titers: 200, epoch: 4 | loss: 0.0824087\n",
      "\tspeed: 0.0145s/iter; left time: 313.0065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0827918 Vali Loss: 0.0843838 Test Loss: 0.0914720\n",
      "Validation loss decreased (0.091555 --> 0.084384).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0784377\n",
      "\tspeed: 0.0277s/iter; left time: 596.2867s\n",
      "\titers: 200, epoch: 5 | loss: 0.0759989\n",
      "\tspeed: 0.0113s/iter; left time: 242.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 225 | Train Loss: 0.0780586 Vali Loss: 0.0813468 Test Loss: 0.0897788\n",
      "Validation loss decreased (0.084384 --> 0.081347).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0739028\n",
      "\tspeed: 0.0331s/iter; left time: 703.1759s\n",
      "\titers: 200, epoch: 6 | loss: 0.0733849\n",
      "\tspeed: 0.0156s/iter; left time: 330.5681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0752780 Vali Loss: 0.0799889 Test Loss: 0.0886891\n",
      "Validation loss decreased (0.081347 --> 0.079989).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0700873\n",
      "\tspeed: 0.0344s/iter; left time: 723.1578s\n",
      "\titers: 200, epoch: 7 | loss: 0.0707081\n",
      "\tspeed: 0.0152s/iter; left time: 319.4689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0736288 Vali Loss: 0.0790577 Test Loss: 0.0879290\n",
      "Validation loss decreased (0.079989 --> 0.079058).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0762281\n",
      "\tspeed: 0.0336s/iter; left time: 700.4877s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738689\n",
      "\tspeed: 0.0157s/iter; left time: 324.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0722952 Vali Loss: 0.0787441 Test Loss: 0.0879052\n",
      "Validation loss decreased (0.079058 --> 0.078744).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0683771\n",
      "\tspeed: 0.0326s/iter; left time: 671.2067s\n",
      "\titers: 200, epoch: 9 | loss: 0.0747857\n",
      "\tspeed: 0.0157s/iter; left time: 322.4174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0715896 Vali Loss: 0.0774867 Test Loss: 0.0866617\n",
      "Validation loss decreased (0.078744 --> 0.077487).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698917\n",
      "\tspeed: 0.0368s/iter; left time: 750.1355s\n",
      "\titers: 200, epoch: 10 | loss: 0.0716846\n",
      "\tspeed: 0.0151s/iter; left time: 306.5377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0704057 Vali Loss: 0.0769684 Test Loss: 0.0858415\n",
      "Validation loss decreased (0.077487 --> 0.076968).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0699004\n",
      "\tspeed: 0.0326s/iter; left time: 655.9198s\n",
      "\titers: 200, epoch: 11 | loss: 0.0707201\n",
      "\tspeed: 0.0156s/iter; left time: 313.3697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0697867 Vali Loss: 0.0764495 Test Loss: 0.0853819\n",
      "Validation loss decreased (0.076968 --> 0.076450).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0698846\n",
      "\tspeed: 0.0332s/iter; left time: 661.8796s\n",
      "\titers: 200, epoch: 12 | loss: 0.0716245\n",
      "\tspeed: 0.0157s/iter; left time: 311.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0691675 Vali Loss: 0.0769113 Test Loss: 0.0856977\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0649242\n",
      "\tspeed: 0.0312s/iter; left time: 614.6777s\n",
      "\titers: 200, epoch: 13 | loss: 0.0703803\n",
      "\tspeed: 0.0150s/iter; left time: 293.7334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0685956 Vali Loss: 0.0758379 Test Loss: 0.0847957\n",
      "Validation loss decreased (0.076450 --> 0.075838).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0711271\n",
      "\tspeed: 0.0341s/iter; left time: 664.7411s\n",
      "\titers: 200, epoch: 14 | loss: 0.0694447\n",
      "\tspeed: 0.0170s/iter; left time: 330.1845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.0680487 Vali Loss: 0.0758935 Test Loss: 0.0846345\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0656746\n",
      "\tspeed: 0.0288s/iter; left time: 553.5301s\n",
      "\titers: 200, epoch: 15 | loss: 0.0668071\n",
      "\tspeed: 0.0112s/iter; left time: 214.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 225 | Train Loss: 0.0678959 Vali Loss: 0.0754225 Test Loss: 0.0840952\n",
      "Validation loss decreased (0.075838 --> 0.075422).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0693426\n",
      "\tspeed: 0.0274s/iter; left time: 520.9245s\n",
      "\titers: 200, epoch: 16 | loss: 0.0683042\n",
      "\tspeed: 0.0113s/iter; left time: 213.9319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 225 | Train Loss: 0.0676131 Vali Loss: 0.0754790 Test Loss: 0.0842982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0665731\n",
      "\tspeed: 0.0284s/iter; left time: 533.9705s\n",
      "\titers: 200, epoch: 17 | loss: 0.0692905\n",
      "\tspeed: 0.0128s/iter; left time: 239.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0672391 Vali Loss: 0.0753235 Test Loss: 0.0840408\n",
      "Validation loss decreased (0.075422 --> 0.075323).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0675017\n",
      "\tspeed: 0.0319s/iter; left time: 593.3823s\n",
      "\titers: 200, epoch: 18 | loss: 0.0680042\n",
      "\tspeed: 0.0183s/iter; left time: 337.7477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0671991 Vali Loss: 0.0752749 Test Loss: 0.0838677\n",
      "Validation loss decreased (0.075323 --> 0.075275).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0657052\n",
      "\tspeed: 0.0343s/iter; left time: 629.8836s\n",
      "\titers: 200, epoch: 19 | loss: 0.0674223\n",
      "\tspeed: 0.0151s/iter; left time: 276.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0668679 Vali Loss: 0.0751044 Test Loss: 0.0839776\n",
      "Validation loss decreased (0.075275 --> 0.075104).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0669044\n",
      "\tspeed: 0.0360s/iter; left time: 653.0866s\n",
      "\titers: 200, epoch: 20 | loss: 0.0678561\n",
      "\tspeed: 0.0193s/iter; left time: 348.3795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.0666958 Vali Loss: 0.0752382 Test Loss: 0.0841614\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0627363\n",
      "\tspeed: 0.0349s/iter; left time: 625.5673s\n",
      "\titers: 200, epoch: 21 | loss: 0.0638758\n",
      "\tspeed: 0.0166s/iter; left time: 295.2491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 225 | Train Loss: 0.0664966 Vali Loss: 0.0751106 Test Loss: 0.0842004\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0678066\n",
      "\tspeed: 0.0367s/iter; left time: 648.0246s\n",
      "\titers: 200, epoch: 22 | loss: 0.0707027\n",
      "\tspeed: 0.0195s/iter; left time: 342.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0663971 Vali Loss: 0.0750149 Test Loss: 0.0839074\n",
      "Validation loss decreased (0.075104 --> 0.075015).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0725942\n",
      "\tspeed: 0.0332s/iter; left time: 578.7540s\n",
      "\titers: 200, epoch: 23 | loss: 0.0631115\n",
      "\tspeed: 0.0172s/iter; left time: 298.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0662704 Vali Loss: 0.0749497 Test Loss: 0.0838586\n",
      "Validation loss decreased (0.075015 --> 0.074950).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0666017\n",
      "\tspeed: 0.0345s/iter; left time: 593.5369s\n",
      "\titers: 200, epoch: 24 | loss: 0.0659782\n",
      "\tspeed: 0.0193s/iter; left time: 330.6768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0662504 Vali Loss: 0.0748828 Test Loss: 0.0839017\n",
      "Validation loss decreased (0.074950 --> 0.074883).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0667289\n",
      "\tspeed: 0.0323s/iter; left time: 549.5887s\n",
      "\titers: 200, epoch: 25 | loss: 0.0662316\n",
      "\tspeed: 0.0168s/iter; left time: 283.4324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0660893 Vali Loss: 0.0747243 Test Loss: 0.0837082\n",
      "Validation loss decreased (0.074883 --> 0.074724).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0672820\n",
      "\tspeed: 0.0301s/iter; left time: 505.6858s\n",
      "\titers: 200, epoch: 26 | loss: 0.0641873\n",
      "\tspeed: 0.0159s/iter; left time: 265.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0661890 Vali Loss: 0.0747570 Test Loss: 0.0837986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0659174\n",
      "\tspeed: 0.0306s/iter; left time: 505.9188s\n",
      "\titers: 200, epoch: 27 | loss: 0.0678228\n",
      "\tspeed: 0.0152s/iter; left time: 250.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0660290 Vali Loss: 0.0749338 Test Loss: 0.0840740\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0658934\n",
      "\tspeed: 0.0307s/iter; left time: 501.1573s\n",
      "\titers: 200, epoch: 28 | loss: 0.0669217\n",
      "\tspeed: 0.0159s/iter; left time: 257.6608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0660034 Vali Loss: 0.0746343 Test Loss: 0.0837211\n",
      "Validation loss decreased (0.074724 --> 0.074634).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0645059\n",
      "\tspeed: 0.0373s/iter; left time: 601.0624s\n",
      "\titers: 200, epoch: 29 | loss: 0.0661160\n",
      "\tspeed: 0.0174s/iter; left time: 278.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0660438 Vali Loss: 0.0746923 Test Loss: 0.0838302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0647524\n",
      "\tspeed: 0.0299s/iter; left time: 474.0192s\n",
      "\titers: 200, epoch: 30 | loss: 0.0642171\n",
      "\tspeed: 0.0097s/iter; left time: 153.5135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 225 | Train Loss: 0.0659379 Vali Loss: 0.0747332 Test Loss: 0.0839173\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0647936\n",
      "\tspeed: 0.0290s/iter; left time: 454.6078s\n",
      "\titers: 200, epoch: 31 | loss: 0.0682318\n",
      "\tspeed: 0.0148s/iter; left time: 229.9928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0657921 Vali Loss: 0.0746830 Test Loss: 0.0837747\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0651756\n",
      "\tspeed: 0.0287s/iter; left time: 442.2085s\n",
      "\titers: 200, epoch: 32 | loss: 0.0618787\n",
      "\tspeed: 0.0108s/iter; left time: 165.9499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0658708 Vali Loss: 0.0746024 Test Loss: 0.0837288\n",
      "Validation loss decreased (0.074634 --> 0.074602).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0668168\n",
      "\tspeed: 0.0338s/iter; left time: 513.6581s\n",
      "\titers: 200, epoch: 33 | loss: 0.0633686\n",
      "\tspeed: 0.0165s/iter; left time: 249.3568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0658372 Vali Loss: 0.0745602 Test Loss: 0.0835967\n",
      "Validation loss decreased (0.074602 --> 0.074560).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0647600\n",
      "\tspeed: 0.0316s/iter; left time: 473.0027s\n",
      "\titers: 200, epoch: 34 | loss: 0.0629268\n",
      "\tspeed: 0.0146s/iter; left time: 217.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0657470 Vali Loss: 0.0746374 Test Loss: 0.0837197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0641729\n",
      "\tspeed: 0.0345s/iter; left time: 508.2503s\n",
      "\titers: 200, epoch: 35 | loss: 0.0617976\n",
      "\tspeed: 0.0177s/iter; left time: 259.3231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0657178 Vali Loss: 0.0746599 Test Loss: 0.0838663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0682861\n",
      "\tspeed: 0.0345s/iter; left time: 501.5188s\n",
      "\titers: 200, epoch: 36 | loss: 0.0719490\n",
      "\tspeed: 0.0200s/iter; left time: 288.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0656840 Vali Loss: 0.0747683 Test Loss: 0.0839771\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0674170\n",
      "\tspeed: 0.0365s/iter; left time: 522.0842s\n",
      "\titers: 200, epoch: 37 | loss: 0.0645799\n",
      "\tspeed: 0.0177s/iter; left time: 251.6572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0657696 Vali Loss: 0.0745763 Test Loss: 0.0837600\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0679446\n",
      "\tspeed: 0.0361s/iter; left time: 507.7489s\n",
      "\titers: 200, epoch: 38 | loss: 0.0619880\n",
      "\tspeed: 0.0196s/iter; left time: 273.9043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0656903 Vali Loss: 0.0745828 Test Loss: 0.0835773\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0635080\n",
      "\tspeed: 0.0329s/iter; left time: 456.3189s\n",
      "\titers: 200, epoch: 39 | loss: 0.0654072\n",
      "\tspeed: 0.0167s/iter; left time: 229.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0656889 Vali Loss: 0.0746122 Test Loss: 0.0837281\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0648413\n",
      "\tspeed: 0.0350s/iter; left time: 476.7628s\n",
      "\titers: 200, epoch: 40 | loss: 0.0636021\n",
      "\tspeed: 0.0196s/iter; left time: 264.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0654821 Vali Loss: 0.0746146 Test Loss: 0.0837951\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0624976\n",
      "\tspeed: 0.0360s/iter; left time: 482.8451s\n",
      "\titers: 200, epoch: 41 | loss: 0.0613499\n",
      "\tspeed: 0.0168s/iter; left time: 224.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.0655606 Vali Loss: 0.0745522 Test Loss: 0.0837003\n",
      "Validation loss decreased (0.074560 --> 0.074552).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0655213\n",
      "\tspeed: 0.0311s/iter; left time: 409.8903s\n",
      "\titers: 200, epoch: 42 | loss: 0.0619614\n",
      "\tspeed: 0.0156s/iter; left time: 204.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0655404 Vali Loss: 0.0746655 Test Loss: 0.0837635\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0676364\n",
      "\tspeed: 0.0353s/iter; left time: 457.7237s\n",
      "\titers: 200, epoch: 43 | loss: 0.0665837\n",
      "\tspeed: 0.0173s/iter; left time: 222.4355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0656253 Vali Loss: 0.0745803 Test Loss: 0.0836900\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0677450\n",
      "\tspeed: 0.0371s/iter; left time: 472.1259s\n",
      "\titers: 200, epoch: 44 | loss: 0.0624176\n",
      "\tspeed: 0.0208s/iter; left time: 263.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 225 | Train Loss: 0.0656435 Vali Loss: 0.0746780 Test Loss: 0.0839206\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0664974\n",
      "\tspeed: 0.0377s/iter; left time: 471.5338s\n",
      "\titers: 200, epoch: 45 | loss: 0.0629244\n",
      "\tspeed: 0.0173s/iter; left time: 214.9845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0655669 Vali Loss: 0.0746178 Test Loss: 0.0837615\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0656827\n",
      "\tspeed: 0.0325s/iter; left time: 399.4772s\n",
      "\titers: 200, epoch: 46 | loss: 0.0656918\n",
      "\tspeed: 0.0151s/iter; left time: 184.0868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0656163 Vali Loss: 0.0747212 Test Loss: 0.0839002\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0688594\n",
      "\tspeed: 0.0355s/iter; left time: 427.6679s\n",
      "\titers: 200, epoch: 47 | loss: 0.0655751\n",
      "\tspeed: 0.0183s/iter; left time: 218.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0654692 Vali Loss: 0.0745072 Test Loss: 0.0836411\n",
      "Validation loss decreased (0.074552 --> 0.074507).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0682336\n",
      "\tspeed: 0.0370s/iter; left time: 437.2951s\n",
      "\titers: 200, epoch: 48 | loss: 0.0633480\n",
      "\tspeed: 0.0195s/iter; left time: 228.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0656726 Vali Loss: 0.0745180 Test Loss: 0.0836578\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0704546\n",
      "\tspeed: 0.0334s/iter; left time: 387.4953s\n",
      "\titers: 200, epoch: 49 | loss: 0.0642681\n",
      "\tspeed: 0.0160s/iter; left time: 184.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0654801 Vali Loss: 0.0745601 Test Loss: 0.0837021\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0658883\n",
      "\tspeed: 0.0335s/iter; left time: 381.5052s\n",
      "\titers: 200, epoch: 50 | loss: 0.0619239\n",
      "\tspeed: 0.0176s/iter; left time: 198.9926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0655309 Vali Loss: 0.0745200 Test Loss: 0.0836687\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0675842\n",
      "\tspeed: 0.0347s/iter; left time: 386.5840s\n",
      "\titers: 200, epoch: 51 | loss: 0.0630216\n",
      "\tspeed: 0.0211s/iter; left time: 233.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0655235 Vali Loss: 0.0747122 Test Loss: 0.0838947\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0621631\n",
      "\tspeed: 0.0323s/iter; left time: 352.7972s\n",
      "\titers: 200, epoch: 52 | loss: 0.0661019\n",
      "\tspeed: 0.0182s/iter; left time: 196.9440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.0655488 Vali Loss: 0.0745604 Test Loss: 0.0837188\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0655467\n",
      "\tspeed: 0.0321s/iter; left time: 343.7845s\n",
      "\titers: 200, epoch: 53 | loss: 0.0644962\n",
      "\tspeed: 0.0178s/iter; left time: 188.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0655646 Vali Loss: 0.0746658 Test Loss: 0.0838256\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0677637\n",
      "\tspeed: 0.0368s/iter; left time: 385.3133s\n",
      "\titers: 200, epoch: 54 | loss: 0.0620990\n",
      "\tspeed: 0.0190s/iter; left time: 196.7842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0654664 Vali Loss: 0.0746213 Test Loss: 0.0837417\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0688697\n",
      "\tspeed: 0.0337s/iter; left time: 345.6830s\n",
      "\titers: 200, epoch: 55 | loss: 0.0613465\n",
      "\tspeed: 0.0171s/iter; left time: 173.5259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0655057 Vali Loss: 0.0746580 Test Loss: 0.0838546\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0621942\n",
      "\tspeed: 0.0317s/iter; left time: 317.6353s\n",
      "\titers: 200, epoch: 56 | loss: 0.0620328\n",
      "\tspeed: 0.0152s/iter; left time: 150.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0658393 Vali Loss: 0.0746421 Test Loss: 0.0838695\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0651978\n",
      "\tspeed: 0.0325s/iter; left time: 318.5446s\n",
      "\titers: 200, epoch: 57 | loss: 0.0681412\n",
      "\tspeed: 0.0153s/iter; left time: 148.2241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0654082 Vali Loss: 0.0745729 Test Loss: 0.0837556\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020481519401073456, rmse:0.1431136578321457, mae:0.08364105224609375, rse:0.5536016821861267\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2388178\n",
      "\tspeed: 0.0246s/iter; left time: 552.0856s\n",
      "\titers: 200, epoch: 1 | loss: 0.2182519\n",
      "\tspeed: 0.0164s/iter; left time: 365.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.2399724 Vali Loss: 0.1777182 Test Loss: 0.1867836\n",
      "Validation loss decreased (inf --> 0.177718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1273558\n",
      "\tspeed: 0.0352s/iter; left time: 781.4662s\n",
      "\titers: 200, epoch: 2 | loss: 0.1026327\n",
      "\tspeed: 0.0152s/iter; left time: 336.6227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.1317914 Vali Loss: 0.0993074 Test Loss: 0.1113348\n",
      "Validation loss decreased (0.177718 --> 0.099307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0890958\n",
      "\tspeed: 0.0372s/iter; left time: 817.6551s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865826\n",
      "\tspeed: 0.0198s/iter; left time: 432.9223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.0907453 Vali Loss: 0.0894003 Test Loss: 0.0954325\n",
      "Validation loss decreased (0.099307 --> 0.089400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0838012\n",
      "\tspeed: 0.0337s/iter; left time: 732.2815s\n",
      "\titers: 200, epoch: 4 | loss: 0.0784943\n",
      "\tspeed: 0.0180s/iter; left time: 390.0139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.0831156 Vali Loss: 0.0839630 Test Loss: 0.0908817\n",
      "Validation loss decreased (0.089400 --> 0.083963).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758482\n",
      "\tspeed: 0.0332s/iter; left time: 713.0166s\n",
      "\titers: 200, epoch: 5 | loss: 0.0736847\n",
      "\tspeed: 0.0169s/iter; left time: 361.0933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0785101 Vali Loss: 0.0816287 Test Loss: 0.0896576\n",
      "Validation loss decreased (0.083963 --> 0.081629).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0728346\n",
      "\tspeed: 0.0359s/iter; left time: 763.0707s\n",
      "\titers: 200, epoch: 6 | loss: 0.0717377\n",
      "\tspeed: 0.0176s/iter; left time: 373.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0757676 Vali Loss: 0.0806589 Test Loss: 0.0891806\n",
      "Validation loss decreased (0.081629 --> 0.080659).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0755224\n",
      "\tspeed: 0.0345s/iter; left time: 727.0654s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664887\n",
      "\tspeed: 0.0150s/iter; left time: 314.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0739093 Vali Loss: 0.0794674 Test Loss: 0.0877857\n",
      "Validation loss decreased (0.080659 --> 0.079467).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0753219\n",
      "\tspeed: 0.0318s/iter; left time: 662.5818s\n",
      "\titers: 200, epoch: 8 | loss: 0.0710723\n",
      "\tspeed: 0.0151s/iter; left time: 312.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0723964 Vali Loss: 0.0791210 Test Loss: 0.0877187\n",
      "Validation loss decreased (0.079467 --> 0.079121).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0728624\n",
      "\tspeed: 0.0377s/iter; left time: 777.1781s\n",
      "\titers: 200, epoch: 9 | loss: 0.0668347\n",
      "\tspeed: 0.0174s/iter; left time: 357.3355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0715036 Vali Loss: 0.0779304 Test Loss: 0.0869970\n",
      "Validation loss decreased (0.079121 --> 0.077930).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0699616\n",
      "\tspeed: 0.0313s/iter; left time: 637.4537s\n",
      "\titers: 200, epoch: 10 | loss: 0.0692299\n",
      "\tspeed: 0.0143s/iter; left time: 290.7689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0704371 Vali Loss: 0.0773976 Test Loss: 0.0863333\n",
      "Validation loss decreased (0.077930 --> 0.077398).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0701377\n",
      "\tspeed: 0.0336s/iter; left time: 676.2188s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711334\n",
      "\tspeed: 0.0182s/iter; left time: 364.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0697987 Vali Loss: 0.0768846 Test Loss: 0.0858211\n",
      "Validation loss decreased (0.077398 --> 0.076885).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0698014\n",
      "\tspeed: 0.0354s/iter; left time: 704.8776s\n",
      "\titers: 200, epoch: 12 | loss: 0.0695472\n",
      "\tspeed: 0.0178s/iter; left time: 352.8105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0694048 Vali Loss: 0.0766271 Test Loss: 0.0852364\n",
      "Validation loss decreased (0.076885 --> 0.076627).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0675972\n",
      "\tspeed: 0.0365s/iter; left time: 719.3901s\n",
      "\titers: 200, epoch: 13 | loss: 0.0714289\n",
      "\tspeed: 0.0181s/iter; left time: 355.2345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0688381 Vali Loss: 0.0768167 Test Loss: 0.0856031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0700926\n",
      "\tspeed: 0.0359s/iter; left time: 698.5357s\n",
      "\titers: 200, epoch: 14 | loss: 0.0705423\n",
      "\tspeed: 0.0179s/iter; left time: 346.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0685697 Vali Loss: 0.0757709 Test Loss: 0.0846112\n",
      "Validation loss decreased (0.076627 --> 0.075771).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0666968\n",
      "\tspeed: 0.0378s/iter; left time: 728.3466s\n",
      "\titers: 200, epoch: 15 | loss: 0.0667904\n",
      "\tspeed: 0.0160s/iter; left time: 306.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0678830 Vali Loss: 0.0756376 Test Loss: 0.0844000\n",
      "Validation loss decreased (0.075771 --> 0.075638).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0671397\n",
      "\tspeed: 0.0373s/iter; left time: 710.1456s\n",
      "\titers: 200, epoch: 16 | loss: 0.0691180\n",
      "\tspeed: 0.0186s/iter; left time: 351.9403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0677403 Vali Loss: 0.0755905 Test Loss: 0.0843625\n",
      "Validation loss decreased (0.075638 --> 0.075590).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0662527\n",
      "\tspeed: 0.0380s/iter; left time: 713.6629s\n",
      "\titers: 200, epoch: 17 | loss: 0.0610230\n",
      "\tspeed: 0.0201s/iter; left time: 375.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 225 | Train Loss: 0.0675268 Vali Loss: 0.0756874 Test Loss: 0.0843866\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0695783\n",
      "\tspeed: 0.0383s/iter; left time: 711.1710s\n",
      "\titers: 200, epoch: 18 | loss: 0.0691342\n",
      "\tspeed: 0.0167s/iter; left time: 309.0759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0673784 Vali Loss: 0.0758241 Test Loss: 0.0845734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0719842\n",
      "\tspeed: 0.0371s/iter; left time: 681.1131s\n",
      "\titers: 200, epoch: 19 | loss: 0.0653379\n",
      "\tspeed: 0.0168s/iter; left time: 306.2336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0671919 Vali Loss: 0.0753380 Test Loss: 0.0841991\n",
      "Validation loss decreased (0.075590 --> 0.075338).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0687822\n",
      "\tspeed: 0.0333s/iter; left time: 604.0065s\n",
      "\titers: 200, epoch: 20 | loss: 0.0619461\n",
      "\tspeed: 0.0160s/iter; left time: 287.9467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0670129 Vali Loss: 0.0753580 Test Loss: 0.0842329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0677746\n",
      "\tspeed: 0.0330s/iter; left time: 591.4132s\n",
      "\titers: 200, epoch: 21 | loss: 0.0670879\n",
      "\tspeed: 0.0152s/iter; left time: 271.2192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0669365 Vali Loss: 0.0755064 Test Loss: 0.0842856\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0670374\n",
      "\tspeed: 0.0318s/iter; left time: 562.2980s\n",
      "\titers: 200, epoch: 22 | loss: 0.0655113\n",
      "\tspeed: 0.0153s/iter; left time: 269.2998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0667176 Vali Loss: 0.0750331 Test Loss: 0.0839804\n",
      "Validation loss decreased (0.075338 --> 0.075033).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0668420\n",
      "\tspeed: 0.0343s/iter; left time: 597.7805s\n",
      "\titers: 200, epoch: 23 | loss: 0.0658703\n",
      "\tspeed: 0.0165s/iter; left time: 285.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.0665682 Vali Loss: 0.0750212 Test Loss: 0.0839592\n",
      "Validation loss decreased (0.075033 --> 0.075021).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0648703\n",
      "\tspeed: 0.0328s/iter; left time: 564.8329s\n",
      "\titers: 200, epoch: 24 | loss: 0.0706152\n",
      "\tspeed: 0.0151s/iter; left time: 259.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0663835 Vali Loss: 0.0749902 Test Loss: 0.0838656\n",
      "Validation loss decreased (0.075021 --> 0.074990).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0653138\n",
      "\tspeed: 0.0386s/iter; left time: 656.1101s\n",
      "\titers: 200, epoch: 25 | loss: 0.0695039\n",
      "\tspeed: 0.0175s/iter; left time: 296.0069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0663624 Vali Loss: 0.0749484 Test Loss: 0.0837926\n",
      "Validation loss decreased (0.074990 --> 0.074948).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0691248\n",
      "\tspeed: 0.0335s/iter; left time: 561.4209s\n",
      "\titers: 200, epoch: 26 | loss: 0.0618585\n",
      "\tspeed: 0.0147s/iter; left time: 245.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0662928 Vali Loss: 0.0749143 Test Loss: 0.0837867\n",
      "Validation loss decreased (0.074948 --> 0.074914).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0626284\n",
      "\tspeed: 0.0319s/iter; left time: 528.5842s\n",
      "\titers: 200, epoch: 27 | loss: 0.0687371\n",
      "\tspeed: 0.0149s/iter; left time: 244.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0661510 Vali Loss: 0.0748319 Test Loss: 0.0835857\n",
      "Validation loss decreased (0.074914 --> 0.074832).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0651349\n",
      "\tspeed: 0.0311s/iter; left time: 508.4941s\n",
      "\titers: 200, epoch: 28 | loss: 0.0707700\n",
      "\tspeed: 0.0159s/iter; left time: 257.7610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0660908 Vali Loss: 0.0748184 Test Loss: 0.0835905\n",
      "Validation loss decreased (0.074832 --> 0.074818).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0658929\n",
      "\tspeed: 0.0322s/iter; left time: 517.8244s\n",
      "\titers: 200, epoch: 29 | loss: 0.0664856\n",
      "\tspeed: 0.0160s/iter; left time: 255.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0661918 Vali Loss: 0.0748716 Test Loss: 0.0837305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0693522\n",
      "\tspeed: 0.0319s/iter; left time: 506.3924s\n",
      "\titers: 200, epoch: 30 | loss: 0.0671649\n",
      "\tspeed: 0.0145s/iter; left time: 229.4532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0660417 Vali Loss: 0.0748484 Test Loss: 0.0838063\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0664139\n",
      "\tspeed: 0.0318s/iter; left time: 498.3755s\n",
      "\titers: 200, epoch: 31 | loss: 0.0674991\n",
      "\tspeed: 0.0153s/iter; left time: 237.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0660052 Vali Loss: 0.0748098 Test Loss: 0.0836985\n",
      "Validation loss decreased (0.074818 --> 0.074810).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0629480\n",
      "\tspeed: 0.0354s/iter; left time: 546.7001s\n",
      "\titers: 200, epoch: 32 | loss: 0.0679041\n",
      "\tspeed: 0.0172s/iter; left time: 264.1311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.0659681 Vali Loss: 0.0747911 Test Loss: 0.0836148\n",
      "Validation loss decreased (0.074810 --> 0.074791).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0672479\n",
      "\tspeed: 0.0295s/iter; left time: 448.1865s\n",
      "\titers: 200, epoch: 33 | loss: 0.0727934\n",
      "\tspeed: 0.0118s/iter; left time: 177.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0660251 Vali Loss: 0.0747474 Test Loss: 0.0836668\n",
      "Validation loss decreased (0.074791 --> 0.074747).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0706449\n",
      "\tspeed: 0.0341s/iter; left time: 511.2375s\n",
      "\titers: 200, epoch: 34 | loss: 0.0624950\n",
      "\tspeed: 0.0171s/iter; left time: 254.9002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0658645 Vali Loss: 0.0747966 Test Loss: 0.0837391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0653407\n",
      "\tspeed: 0.0336s/iter; left time: 495.1802s\n",
      "\titers: 200, epoch: 35 | loss: 0.0693895\n",
      "\tspeed: 0.0156s/iter; left time: 228.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0658733 Vali Loss: 0.0747852 Test Loss: 0.0836694\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0682885\n",
      "\tspeed: 0.0341s/iter; left time: 495.5976s\n",
      "\titers: 200, epoch: 36 | loss: 0.0668036\n",
      "\tspeed: 0.0166s/iter; left time: 239.1863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0657792 Vali Loss: 0.0747351 Test Loss: 0.0836585\n",
      "Validation loss decreased (0.074747 --> 0.074735).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0690809\n",
      "\tspeed: 0.0356s/iter; left time: 509.2706s\n",
      "\titers: 200, epoch: 37 | loss: 0.0640136\n",
      "\tspeed: 0.0171s/iter; left time: 243.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0658756 Vali Loss: 0.0747907 Test Loss: 0.0836819\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0670546\n",
      "\tspeed: 0.0327s/iter; left time: 460.9193s\n",
      "\titers: 200, epoch: 38 | loss: 0.0665384\n",
      "\tspeed: 0.0145s/iter; left time: 202.7471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0657899 Vali Loss: 0.0747696 Test Loss: 0.0836834\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0626673\n",
      "\tspeed: 0.0326s/iter; left time: 451.1311s\n",
      "\titers: 200, epoch: 39 | loss: 0.0650180\n",
      "\tspeed: 0.0169s/iter; left time: 231.9260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0656801 Vali Loss: 0.0748786 Test Loss: 0.0839305\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0671039\n",
      "\tspeed: 0.0330s/iter; left time: 449.0905s\n",
      "\titers: 200, epoch: 40 | loss: 0.0674989\n",
      "\tspeed: 0.0149s/iter; left time: 201.3616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0657427 Vali Loss: 0.0747225 Test Loss: 0.0836363\n",
      "Validation loss decreased (0.074735 --> 0.074723).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0650668\n",
      "\tspeed: 0.0314s/iter; left time: 420.7551s\n",
      "\titers: 200, epoch: 41 | loss: 0.0672973\n",
      "\tspeed: 0.0152s/iter; left time: 202.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0656366 Vali Loss: 0.0747689 Test Loss: 0.0837518\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0697005\n",
      "\tspeed: 0.0316s/iter; left time: 416.5228s\n",
      "\titers: 200, epoch: 42 | loss: 0.0656713\n",
      "\tspeed: 0.0152s/iter; left time: 199.0378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0657307 Vali Loss: 0.0747003 Test Loss: 0.0836473\n",
      "Validation loss decreased (0.074723 --> 0.074700).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0646323\n",
      "\tspeed: 0.0336s/iter; left time: 435.3986s\n",
      "\titers: 200, epoch: 43 | loss: 0.0638158\n",
      "\tspeed: 0.0159s/iter; left time: 204.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0656570 Vali Loss: 0.0747236 Test Loss: 0.0836677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0654169\n",
      "\tspeed: 0.0317s/iter; left time: 403.1378s\n",
      "\titers: 200, epoch: 44 | loss: 0.0667009\n",
      "\tspeed: 0.0154s/iter; left time: 194.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0655989 Vali Loss: 0.0746637 Test Loss: 0.0835448\n",
      "Validation loss decreased (0.074700 --> 0.074664).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0653667\n",
      "\tspeed: 0.0354s/iter; left time: 442.5793s\n",
      "\titers: 200, epoch: 45 | loss: 0.0623195\n",
      "\tspeed: 0.0162s/iter; left time: 201.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0655927 Vali Loss: 0.0746361 Test Loss: 0.0835031\n",
      "Validation loss decreased (0.074664 --> 0.074636).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0648136\n",
      "\tspeed: 0.0325s/iter; left time: 398.9867s\n",
      "\titers: 200, epoch: 46 | loss: 0.0634316\n",
      "\tspeed: 0.0154s/iter; left time: 187.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0656873 Vali Loss: 0.0746974 Test Loss: 0.0835906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0644567\n",
      "\tspeed: 0.0322s/iter; left time: 387.8203s\n",
      "\titers: 200, epoch: 47 | loss: 0.0674649\n",
      "\tspeed: 0.0149s/iter; left time: 177.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.0656318 Vali Loss: 0.0747004 Test Loss: 0.0835359\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0638885\n",
      "\tspeed: 0.0267s/iter; left time: 315.3132s\n",
      "\titers: 200, epoch: 48 | loss: 0.0633170\n",
      "\tspeed: 0.0127s/iter; left time: 149.3234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 225 | Train Loss: 0.0656023 Vali Loss: 0.0748286 Test Loss: 0.0838135\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0663939\n",
      "\tspeed: 0.0377s/iter; left time: 437.6171s\n",
      "\titers: 200, epoch: 49 | loss: 0.0685082\n",
      "\tspeed: 0.0179s/iter; left time: 205.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0656506 Vali Loss: 0.0747889 Test Loss: 0.0837646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0632886\n",
      "\tspeed: 0.0352s/iter; left time: 400.1008s\n",
      "\titers: 200, epoch: 50 | loss: 0.0671445\n",
      "\tspeed: 0.0173s/iter; left time: 195.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0655780 Vali Loss: 0.0747806 Test Loss: 0.0835741\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0623374\n",
      "\tspeed: 0.0347s/iter; left time: 387.3919s\n",
      "\titers: 200, epoch: 51 | loss: 0.0643868\n",
      "\tspeed: 0.0178s/iter; left time: 197.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0655646 Vali Loss: 0.0747436 Test Loss: 0.0837317\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0636110\n",
      "\tspeed: 0.0348s/iter; left time: 380.2505s\n",
      "\titers: 200, epoch: 52 | loss: 0.0663075\n",
      "\tspeed: 0.0176s/iter; left time: 190.5632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0656421 Vali Loss: 0.0746701 Test Loss: 0.0835855\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0626311\n",
      "\tspeed: 0.0334s/iter; left time: 357.6473s\n",
      "\titers: 200, epoch: 53 | loss: 0.0688870\n",
      "\tspeed: 0.0157s/iter; left time: 166.6019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0655239 Vali Loss: 0.0746517 Test Loss: 0.0835584\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0718522\n",
      "\tspeed: 0.0316s/iter; left time: 330.8418s\n",
      "\titers: 200, epoch: 54 | loss: 0.0653040\n",
      "\tspeed: 0.0152s/iter; left time: 157.8334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0656512 Vali Loss: 0.0746795 Test Loss: 0.0836077\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0699099\n",
      "\tspeed: 0.0331s/iter; left time: 339.6789s\n",
      "\titers: 200, epoch: 55 | loss: 0.0656586\n",
      "\tspeed: 0.0128s/iter; left time: 129.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0656060 Vali Loss: 0.0746935 Test Loss: 0.0836827\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020380981266498566, rmse:0.1427619755268097, mae:0.0835031047463417, rse:0.5522412657737732\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:28.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2457695\n",
      "\tspeed: 0.0362s/iter; left time: 811.3178s\n",
      "\titers: 200, epoch: 1 | loss: 0.2214903\n",
      "\tspeed: 0.0132s/iter; left time: 294.9859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.2463344 Vali Loss: 0.1826521 Test Loss: 0.1912599\n",
      "Validation loss decreased (inf --> 0.182652).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1277386\n",
      "\tspeed: 0.0361s/iter; left time: 800.4511s\n",
      "\titers: 200, epoch: 2 | loss: 0.1018808\n",
      "\tspeed: 0.0181s/iter; left time: 400.5990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.1313877 Vali Loss: 0.1018746 Test Loss: 0.1139771\n",
      "Validation loss decreased (0.182652 --> 0.101875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0908557\n",
      "\tspeed: 0.0314s/iter; left time: 688.6626s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855185\n",
      "\tspeed: 0.0100s/iter; left time: 217.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 225 | Train Loss: 0.0930013 Vali Loss: 0.0921000 Test Loss: 0.0991172\n",
      "Validation loss decreased (0.101875 --> 0.092100).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891004\n",
      "\tspeed: 0.0319s/iter; left time: 693.6035s\n",
      "\titers: 200, epoch: 4 | loss: 0.0825887\n",
      "\tspeed: 0.0181s/iter; left time: 390.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0853147 Vali Loss: 0.0864257 Test Loss: 0.0946696\n",
      "Validation loss decreased (0.092100 --> 0.086426).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0822017\n",
      "\tspeed: 0.0361s/iter; left time: 775.1247s\n",
      "\titers: 200, epoch: 5 | loss: 0.0771825\n",
      "\tspeed: 0.0189s/iter; left time: 404.4532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0809365 Vali Loss: 0.0845859 Test Loss: 0.0936776\n",
      "Validation loss decreased (0.086426 --> 0.084586).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798835\n",
      "\tspeed: 0.0316s/iter; left time: 672.2007s\n",
      "\titers: 200, epoch: 6 | loss: 0.0827646\n",
      "\tspeed: 0.0153s/iter; left time: 323.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0789175 Vali Loss: 0.0837064 Test Loss: 0.0930236\n",
      "Validation loss decreased (0.084586 --> 0.083706).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752266\n",
      "\tspeed: 0.0335s/iter; left time: 705.7749s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747587\n",
      "\tspeed: 0.0159s/iter; left time: 333.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0769645 Vali Loss: 0.0841499 Test Loss: 0.0934944\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0705568\n",
      "\tspeed: 0.0361s/iter; left time: 752.7324s\n",
      "\titers: 200, epoch: 8 | loss: 0.0763874\n",
      "\tspeed: 0.0183s/iter; left time: 378.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0758539 Vali Loss: 0.0830533 Test Loss: 0.0929134\n",
      "Validation loss decreased (0.083706 --> 0.083053).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0757157\n",
      "\tspeed: 0.0329s/iter; left time: 677.7953s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759397\n",
      "\tspeed: 0.0170s/iter; left time: 348.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0749634 Vali Loss: 0.0820992 Test Loss: 0.0920538\n",
      "Validation loss decreased (0.083053 --> 0.082099).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0745221\n",
      "\tspeed: 0.0341s/iter; left time: 693.9088s\n",
      "\titers: 200, epoch: 10 | loss: 0.0719350\n",
      "\tspeed: 0.0156s/iter; left time: 315.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0741297 Vali Loss: 0.0814455 Test Loss: 0.0910367\n",
      "Validation loss decreased (0.082099 --> 0.081445).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764837\n",
      "\tspeed: 0.0330s/iter; left time: 664.7576s\n",
      "\titers: 200, epoch: 11 | loss: 0.0695029\n",
      "\tspeed: 0.0167s/iter; left time: 334.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0739676 Vali Loss: 0.0803295 Test Loss: 0.0898504\n",
      "Validation loss decreased (0.081445 --> 0.080330).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716958\n",
      "\tspeed: 0.0339s/iter; left time: 676.3389s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746069\n",
      "\tspeed: 0.0154s/iter; left time: 305.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.0731553 Vali Loss: 0.0803021 Test Loss: 0.0901671\n",
      "Validation loss decreased (0.080330 --> 0.080302).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0708047\n",
      "\tspeed: 0.0332s/iter; left time: 654.9965s\n",
      "\titers: 200, epoch: 13 | loss: 0.0687040\n",
      "\tspeed: 0.0154s/iter; left time: 301.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0726615 Vali Loss: 0.0803218 Test Loss: 0.0901097\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0758782\n",
      "\tspeed: 0.0353s/iter; left time: 688.2904s\n",
      "\titers: 200, epoch: 14 | loss: 0.0756663\n",
      "\tspeed: 0.0168s/iter; left time: 325.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0721283 Vali Loss: 0.0797881 Test Loss: 0.0894258\n",
      "Validation loss decreased (0.080302 --> 0.079788).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686727\n",
      "\tspeed: 0.0352s/iter; left time: 676.9565s\n",
      "\titers: 200, epoch: 15 | loss: 0.0697988\n",
      "\tspeed: 0.0183s/iter; left time: 351.3483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0717592 Vali Loss: 0.0802344 Test Loss: 0.0899736\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0721867\n",
      "\tspeed: 0.0338s/iter; left time: 642.7947s\n",
      "\titers: 200, epoch: 16 | loss: 0.0747293\n",
      "\tspeed: 0.0156s/iter; left time: 295.3021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0713627 Vali Loss: 0.0796205 Test Loss: 0.0895057\n",
      "Validation loss decreased (0.079788 --> 0.079620).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0694145\n",
      "\tspeed: 0.0326s/iter; left time: 612.9694s\n",
      "\titers: 200, epoch: 17 | loss: 0.0718711\n",
      "\tspeed: 0.0153s/iter; left time: 286.9771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0710901 Vali Loss: 0.0796221 Test Loss: 0.0895598\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0694964\n",
      "\tspeed: 0.0318s/iter; left time: 590.3239s\n",
      "\titers: 200, epoch: 18 | loss: 0.0708955\n",
      "\tspeed: 0.0156s/iter; left time: 287.7132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0709736 Vali Loss: 0.0796491 Test Loss: 0.0896595\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0705740\n",
      "\tspeed: 0.0345s/iter; left time: 632.2647s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759989\n",
      "\tspeed: 0.0203s/iter; left time: 370.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0706302 Vali Loss: 0.0795927 Test Loss: 0.0897387\n",
      "Validation loss decreased (0.079620 --> 0.079593).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0687659\n",
      "\tspeed: 0.0360s/iter; left time: 652.8019s\n",
      "\titers: 200, epoch: 20 | loss: 0.0704639\n",
      "\tspeed: 0.0188s/iter; left time: 338.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0705626 Vali Loss: 0.0795450 Test Loss: 0.0897743\n",
      "Validation loss decreased (0.079593 --> 0.079545).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0697231\n",
      "\tspeed: 0.0375s/iter; left time: 671.0817s\n",
      "\titers: 200, epoch: 21 | loss: 0.0732484\n",
      "\tspeed: 0.0179s/iter; left time: 319.0506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0702737 Vali Loss: 0.0794629 Test Loss: 0.0898503\n",
      "Validation loss decreased (0.079545 --> 0.079463).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0725980\n",
      "\tspeed: 0.0336s/iter; left time: 594.0949s\n",
      "\titers: 200, epoch: 22 | loss: 0.0697240\n",
      "\tspeed: 0.0156s/iter; left time: 273.6543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0701744 Vali Loss: 0.0795757 Test Loss: 0.0897552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0662951\n",
      "\tspeed: 0.0346s/iter; left time: 603.3260s\n",
      "\titers: 200, epoch: 23 | loss: 0.0705444\n",
      "\tspeed: 0.0172s/iter; left time: 298.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0700460 Vali Loss: 0.0793628 Test Loss: 0.0896879\n",
      "Validation loss decreased (0.079463 --> 0.079363).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0696745\n",
      "\tspeed: 0.0333s/iter; left time: 573.1230s\n",
      "\titers: 200, epoch: 24 | loss: 0.0661158\n",
      "\tspeed: 0.0164s/iter; left time: 280.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0700054 Vali Loss: 0.0795738 Test Loss: 0.0900811\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0697619\n",
      "\tspeed: 0.0321s/iter; left time: 546.4155s\n",
      "\titers: 200, epoch: 25 | loss: 0.0687341\n",
      "\tspeed: 0.0151s/iter; left time: 255.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0697976 Vali Loss: 0.0793890 Test Loss: 0.0897973\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0694301\n",
      "\tspeed: 0.0310s/iter; left time: 520.3398s\n",
      "\titers: 200, epoch: 26 | loss: 0.0664604\n",
      "\tspeed: 0.0178s/iter; left time: 296.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0697441 Vali Loss: 0.0797010 Test Loss: 0.0899496\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0656098\n",
      "\tspeed: 0.0327s/iter; left time: 541.5560s\n",
      "\titers: 200, epoch: 27 | loss: 0.0713333\n",
      "\tspeed: 0.0185s/iter; left time: 304.0791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0696657 Vali Loss: 0.0794763 Test Loss: 0.0897405\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0722426\n",
      "\tspeed: 0.0318s/iter; left time: 519.4311s\n",
      "\titers: 200, epoch: 28 | loss: 0.0686098\n",
      "\tspeed: 0.0154s/iter; left time: 250.1012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0695880 Vali Loss: 0.0795084 Test Loss: 0.0898208\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0712926\n",
      "\tspeed: 0.0325s/iter; left time: 522.9468s\n",
      "\titers: 200, epoch: 29 | loss: 0.0702594\n",
      "\tspeed: 0.0189s/iter; left time: 302.6665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0695667 Vali Loss: 0.0794929 Test Loss: 0.0898527\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0701126\n",
      "\tspeed: 0.0347s/iter; left time: 550.8938s\n",
      "\titers: 200, epoch: 30 | loss: 0.0691674\n",
      "\tspeed: 0.0191s/iter; left time: 300.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0696097 Vali Loss: 0.0795344 Test Loss: 0.0901617\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0710925\n",
      "\tspeed: 0.0371s/iter; left time: 580.9741s\n",
      "\titers: 200, epoch: 31 | loss: 0.0686123\n",
      "\tspeed: 0.0172s/iter; left time: 267.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0694451 Vali Loss: 0.0796398 Test Loss: 0.0897871\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0677457\n",
      "\tspeed: 0.0316s/iter; left time: 486.7493s\n",
      "\titers: 200, epoch: 32 | loss: 0.0712155\n",
      "\tspeed: 0.0198s/iter; left time: 303.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0694937 Vali Loss: 0.0794603 Test Loss: 0.0898027\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0665110\n",
      "\tspeed: 0.0325s/iter; left time: 494.0400s\n",
      "\titers: 200, epoch: 33 | loss: 0.0714712\n",
      "\tspeed: 0.0172s/iter; left time: 260.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0694073 Vali Loss: 0.0795294 Test Loss: 0.0898771\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022908687591552734, rmse:0.15135616064071655, mae:0.08968787640333176, rse:0.5862167477607727\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2475315\n",
      "\tspeed: 0.0211s/iter; left time: 472.8780s\n",
      "\titers: 200, epoch: 1 | loss: 0.2264819\n",
      "\tspeed: 0.0162s/iter; left time: 361.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.2456049 Vali Loss: 0.1833336 Test Loss: 0.1914726\n",
      "Validation loss decreased (inf --> 0.183334).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1228585\n",
      "\tspeed: 0.0353s/iter; left time: 783.0027s\n",
      "\titers: 200, epoch: 2 | loss: 0.0990242\n",
      "\tspeed: 0.0189s/iter; left time: 417.5302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.1301335 Vali Loss: 0.1014620 Test Loss: 0.1144908\n",
      "Validation loss decreased (0.183334 --> 0.101462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0894346\n",
      "\tspeed: 0.0352s/iter; left time: 772.6325s\n",
      "\titers: 200, epoch: 3 | loss: 0.0878249\n",
      "\tspeed: 0.0197s/iter; left time: 429.6286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0933888 Vali Loss: 0.0927016 Test Loss: 0.0995768\n",
      "Validation loss decreased (0.101462 --> 0.092702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0936179\n",
      "\tspeed: 0.0346s/iter; left time: 752.6978s\n",
      "\titers: 200, epoch: 4 | loss: 0.0834910\n",
      "\tspeed: 0.0178s/iter; left time: 385.7731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0856615 Vali Loss: 0.0868466 Test Loss: 0.0954649\n",
      "Validation loss decreased (0.092702 --> 0.086847).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0841565\n",
      "\tspeed: 0.0376s/iter; left time: 809.3174s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807808\n",
      "\tspeed: 0.0184s/iter; left time: 393.9126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0812586 Vali Loss: 0.0858457 Test Loss: 0.0945108\n",
      "Validation loss decreased (0.086847 --> 0.085846).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0802644\n",
      "\tspeed: 0.0372s/iter; left time: 791.6161s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779895\n",
      "\tspeed: 0.0174s/iter; left time: 368.4587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0787631 Vali Loss: 0.0846770 Test Loss: 0.0937102\n",
      "Validation loss decreased (0.085846 --> 0.084677).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776361\n",
      "\tspeed: 0.0333s/iter; left time: 700.2247s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771536\n",
      "\tspeed: 0.0167s/iter; left time: 350.7077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0769995 Vali Loss: 0.0834739 Test Loss: 0.0923947\n",
      "Validation loss decreased (0.084677 --> 0.083474).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780043\n",
      "\tspeed: 0.0334s/iter; left time: 695.5313s\n",
      "\titers: 200, epoch: 8 | loss: 0.0787861\n",
      "\tspeed: 0.0170s/iter; left time: 353.2850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0756832 Vali Loss: 0.0826148 Test Loss: 0.0918682\n",
      "Validation loss decreased (0.083474 --> 0.082615).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0705152\n",
      "\tspeed: 0.0353s/iter; left time: 727.6348s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718096\n",
      "\tspeed: 0.0205s/iter; left time: 420.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0750352 Vali Loss: 0.0820301 Test Loss: 0.0913356\n",
      "Validation loss decreased (0.082615 --> 0.082030).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738082\n",
      "\tspeed: 0.0365s/iter; left time: 743.6972s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705996\n",
      "\tspeed: 0.0186s/iter; left time: 376.6756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0740733 Vali Loss: 0.0816444 Test Loss: 0.0911710\n",
      "Validation loss decreased (0.082030 --> 0.081644).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0694988\n",
      "\tspeed: 0.0346s/iter; left time: 696.7456s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711344\n",
      "\tspeed: 0.0170s/iter; left time: 341.0570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0734706 Vali Loss: 0.0814154 Test Loss: 0.0910744\n",
      "Validation loss decreased (0.081644 --> 0.081415).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716891\n",
      "\tspeed: 0.0351s/iter; left time: 698.6890s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729579\n",
      "\tspeed: 0.0163s/iter; left time: 323.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0728471 Vali Loss: 0.0812354 Test Loss: 0.0910280\n",
      "Validation loss decreased (0.081415 --> 0.081235).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0727554\n",
      "\tspeed: 0.0331s/iter; left time: 652.7930s\n",
      "\titers: 200, epoch: 13 | loss: 0.0719812\n",
      "\tspeed: 0.0114s/iter; left time: 223.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0725295 Vali Loss: 0.0807067 Test Loss: 0.0906308\n",
      "Validation loss decreased (0.081235 --> 0.080707).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0737901\n",
      "\tspeed: 0.0315s/iter; left time: 612.5244s\n",
      "\titers: 200, epoch: 14 | loss: 0.0761006\n",
      "\tspeed: 0.0156s/iter; left time: 302.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0721327 Vali Loss: 0.0807022 Test Loss: 0.0907606\n",
      "Validation loss decreased (0.080707 --> 0.080702).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0736133\n",
      "\tspeed: 0.0322s/iter; left time: 620.4389s\n",
      "\titers: 200, epoch: 15 | loss: 0.0723154\n",
      "\tspeed: 0.0168s/iter; left time: 322.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0717245 Vali Loss: 0.0804117 Test Loss: 0.0902714\n",
      "Validation loss decreased (0.080702 --> 0.080412).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0687496\n",
      "\tspeed: 0.0375s/iter; left time: 714.1060s\n",
      "\titers: 200, epoch: 16 | loss: 0.0708548\n",
      "\tspeed: 0.0199s/iter; left time: 377.5447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0714129 Vali Loss: 0.0799183 Test Loss: 0.0899097\n",
      "Validation loss decreased (0.080412 --> 0.079918).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0679504\n",
      "\tspeed: 0.0348s/iter; left time: 653.8244s\n",
      "\titers: 200, epoch: 17 | loss: 0.0778753\n",
      "\tspeed: 0.0178s/iter; left time: 332.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0711230 Vali Loss: 0.0798044 Test Loss: 0.0900320\n",
      "Validation loss decreased (0.079918 --> 0.079804).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0694376\n",
      "\tspeed: 0.0442s/iter; left time: 821.7637s\n",
      "\titers: 200, epoch: 18 | loss: 0.0710280\n",
      "\tspeed: 0.0174s/iter; left time: 321.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0709428 Vali Loss: 0.0797784 Test Loss: 0.0898284\n",
      "Validation loss decreased (0.079804 --> 0.079778).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0688043\n",
      "\tspeed: 0.0359s/iter; left time: 659.1749s\n",
      "\titers: 200, epoch: 19 | loss: 0.0711079\n",
      "\tspeed: 0.0189s/iter; left time: 344.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0708623 Vali Loss: 0.0799950 Test Loss: 0.0903919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0645109\n",
      "\tspeed: 0.0345s/iter; left time: 625.4423s\n",
      "\titers: 200, epoch: 20 | loss: 0.0717572\n",
      "\tspeed: 0.0182s/iter; left time: 327.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0705810 Vali Loss: 0.0797130 Test Loss: 0.0902688\n",
      "Validation loss decreased (0.079778 --> 0.079713).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0678085\n",
      "\tspeed: 0.0359s/iter; left time: 642.0294s\n",
      "\titers: 200, epoch: 21 | loss: 0.0693727\n",
      "\tspeed: 0.0182s/iter; left time: 324.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0704802 Vali Loss: 0.0796383 Test Loss: 0.0902148\n",
      "Validation loss decreased (0.079713 --> 0.079638).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0698550\n",
      "\tspeed: 0.0306s/iter; left time: 541.3396s\n",
      "\titers: 200, epoch: 22 | loss: 0.0697957\n",
      "\tspeed: 0.0222s/iter; left time: 391.0625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0704161 Vali Loss: 0.0797148 Test Loss: 0.0903682\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0724288\n",
      "\tspeed: 0.0367s/iter; left time: 641.2787s\n",
      "\titers: 200, epoch: 23 | loss: 0.0695834\n",
      "\tspeed: 0.0150s/iter; left time: 259.9841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0703086 Vali Loss: 0.0799217 Test Loss: 0.0903951\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0704532\n",
      "\tspeed: 0.0369s/iter; left time: 636.2909s\n",
      "\titers: 200, epoch: 24 | loss: 0.0708161\n",
      "\tspeed: 0.0190s/iter; left time: 325.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.0701037 Vali Loss: 0.0799287 Test Loss: 0.0905475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0711049\n",
      "\tspeed: 0.0368s/iter; left time: 625.1959s\n",
      "\titers: 200, epoch: 25 | loss: 0.0708909\n",
      "\tspeed: 0.0184s/iter; left time: 310.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0701468 Vali Loss: 0.0800464 Test Loss: 0.0906366\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0692690\n",
      "\tspeed: 0.0340s/iter; left time: 570.0768s\n",
      "\titers: 200, epoch: 26 | loss: 0.0730075\n",
      "\tspeed: 0.0186s/iter; left time: 309.3823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0701595 Vali Loss: 0.0801362 Test Loss: 0.0907676\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722371\n",
      "\tspeed: 0.0326s/iter; left time: 539.2172s\n",
      "\titers: 200, epoch: 27 | loss: 0.0678109\n",
      "\tspeed: 0.0173s/iter; left time: 284.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0699988 Vali Loss: 0.0799063 Test Loss: 0.0905414\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0755869\n",
      "\tspeed: 0.0320s/iter; left time: 522.5504s\n",
      "\titers: 200, epoch: 28 | loss: 0.0650524\n",
      "\tspeed: 0.0176s/iter; left time: 284.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0699465 Vali Loss: 0.0796831 Test Loss: 0.0902116\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0678778\n",
      "\tspeed: 0.0347s/iter; left time: 558.5371s\n",
      "\titers: 200, epoch: 29 | loss: 0.0683460\n",
      "\tspeed: 0.0173s/iter; left time: 277.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 225 | Train Loss: 0.0698914 Vali Loss: 0.0797773 Test Loss: 0.0904671\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0732322\n",
      "\tspeed: 0.0356s/iter; left time: 564.5030s\n",
      "\titers: 200, epoch: 30 | loss: 0.0698619\n",
      "\tspeed: 0.0184s/iter; left time: 290.1244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0697509 Vali Loss: 0.0798239 Test Loss: 0.0905032\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0718747\n",
      "\tspeed: 0.0356s/iter; left time: 556.8336s\n",
      "\titers: 200, epoch: 31 | loss: 0.0708746\n",
      "\tspeed: 0.0168s/iter; left time: 261.3923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0699904 Vali Loss: 0.0794514 Test Loss: 0.0901573\n",
      "Validation loss decreased (0.079638 --> 0.079451).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0675547\n",
      "\tspeed: 0.0356s/iter; left time: 549.8464s\n",
      "\titers: 200, epoch: 32 | loss: 0.0683894\n",
      "\tspeed: 0.0164s/iter; left time: 251.8167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0696626 Vali Loss: 0.0796696 Test Loss: 0.0903575\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0685225\n",
      "\tspeed: 0.0323s/iter; left time: 490.9030s\n",
      "\titers: 200, epoch: 33 | loss: 0.0686906\n",
      "\tspeed: 0.0171s/iter; left time: 258.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0696908 Vali Loss: 0.0795452 Test Loss: 0.0901167\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0667701\n",
      "\tspeed: 0.0349s/iter; left time: 523.2245s\n",
      "\titers: 200, epoch: 34 | loss: 0.0682344\n",
      "\tspeed: 0.0177s/iter; left time: 263.3715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 225 | Train Loss: 0.0698480 Vali Loss: 0.0795390 Test Loss: 0.0901924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0728837\n",
      "\tspeed: 0.0344s/iter; left time: 507.6933s\n",
      "\titers: 200, epoch: 35 | loss: 0.0682282\n",
      "\tspeed: 0.0192s/iter; left time: 281.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0697524 Vali Loss: 0.0795052 Test Loss: 0.0902432\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0698334\n",
      "\tspeed: 0.0327s/iter; left time: 474.3197s\n",
      "\titers: 200, epoch: 36 | loss: 0.0653570\n",
      "\tspeed: 0.0146s/iter; left time: 210.8943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0696060 Vali Loss: 0.0797219 Test Loss: 0.0904662\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0688643\n",
      "\tspeed: 0.0350s/iter; left time: 500.3553s\n",
      "\titers: 200, epoch: 37 | loss: 0.0726332\n",
      "\tspeed: 0.0161s/iter; left time: 229.1044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0695769 Vali Loss: 0.0801196 Test Loss: 0.0909049\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0683476\n",
      "\tspeed: 0.0369s/iter; left time: 520.0695s\n",
      "\titers: 200, epoch: 38 | loss: 0.0744995\n",
      "\tspeed: 0.0161s/iter; left time: 224.6159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0696177 Vali Loss: 0.0794538 Test Loss: 0.0900954\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0695931\n",
      "\tspeed: 0.0325s/iter; left time: 450.4762s\n",
      "\titers: 200, epoch: 39 | loss: 0.0729357\n",
      "\tspeed: 0.0155s/iter; left time: 213.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0694720 Vali Loss: 0.0795424 Test Loss: 0.0902805\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0661439\n",
      "\tspeed: 0.0314s/iter; left time: 427.9428s\n",
      "\titers: 200, epoch: 40 | loss: 0.0719939\n",
      "\tspeed: 0.0140s/iter; left time: 189.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0695547 Vali Loss: 0.0796985 Test Loss: 0.0904467\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0714126\n",
      "\tspeed: 0.0338s/iter; left time: 453.0411s\n",
      "\titers: 200, epoch: 41 | loss: 0.0713710\n",
      "\tspeed: 0.0164s/iter; left time: 218.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0694798 Vali Loss: 0.0796473 Test Loss: 0.0904636\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023290717974305153, rmse:0.15261296927928925, mae:0.09015733748674393, rse:0.5910844802856445\n",
      "Intermediate time for FR and pred_len 168: 00h:06m:33.01s\n",
      "Intermediate time for FR: 00h:27m:02.97s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2748396\n",
      "\tspeed: 0.0417s/iter; left time: 937.2237s\n",
      "\titers: 200, epoch: 1 | loss: 0.2437673\n",
      "\tspeed: 0.0146s/iter; left time: 326.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.2755289 Vali Loss: 0.1856256 Test Loss: 0.1920305\n",
      "Validation loss decreased (inf --> 0.185626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1493361\n",
      "\tspeed: 0.0294s/iter; left time: 655.6071s\n",
      "\titers: 200, epoch: 2 | loss: 0.1137058\n",
      "\tspeed: 0.0130s/iter; left time: 288.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.1543205 Vali Loss: 0.0913810 Test Loss: 0.0918437\n",
      "Validation loss decreased (0.185626 --> 0.091381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1026489\n",
      "\tspeed: 0.0302s/iter; left time: 665.1519s\n",
      "\titers: 200, epoch: 3 | loss: 0.0962690\n",
      "\tspeed: 0.0150s/iter; left time: 329.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.1004594 Vali Loss: 0.0835395 Test Loss: 0.0854951\n",
      "Validation loss decreased (0.091381 --> 0.083539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915175\n",
      "\tspeed: 0.0310s/iter; left time: 677.2316s\n",
      "\titers: 200, epoch: 4 | loss: 0.0810010\n",
      "\tspeed: 0.0156s/iter; left time: 338.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0900728 Vali Loss: 0.0788191 Test Loss: 0.0802079\n",
      "Validation loss decreased (0.083539 --> 0.078819).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0855739\n",
      "\tspeed: 0.0296s/iter; left time: 640.1663s\n",
      "\titers: 200, epoch: 5 | loss: 0.0812334\n",
      "\tspeed: 0.0155s/iter; left time: 333.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0840692 Vali Loss: 0.0760780 Test Loss: 0.0758319\n",
      "Validation loss decreased (0.078819 --> 0.076078).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0776363\n",
      "\tspeed: 0.0298s/iter; left time: 637.7694s\n",
      "\titers: 200, epoch: 6 | loss: 0.0761937\n",
      "\tspeed: 0.0147s/iter; left time: 312.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0797316 Vali Loss: 0.0726597 Test Loss: 0.0717476\n",
      "Validation loss decreased (0.076078 --> 0.072660).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0815444\n",
      "\tspeed: 0.0330s/iter; left time: 697.0667s\n",
      "\titers: 200, epoch: 7 | loss: 0.0786124\n",
      "\tspeed: 0.0155s/iter; left time: 325.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0767705 Vali Loss: 0.0700167 Test Loss: 0.0696374\n",
      "Validation loss decreased (0.072660 --> 0.070017).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0715965\n",
      "\tspeed: 0.0356s/iter; left time: 744.7882s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738217\n",
      "\tspeed: 0.0206s/iter; left time: 427.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 226 | Train Loss: 0.0745824 Vali Loss: 0.0685167 Test Loss: 0.0687677\n",
      "Validation loss decreased (0.070017 --> 0.068517).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0756384\n",
      "\tspeed: 0.0333s/iter; left time: 689.5123s\n",
      "\titers: 200, epoch: 9 | loss: 0.0742270\n",
      "\tspeed: 0.0147s/iter; left time: 302.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.0727980 Vali Loss: 0.0671877 Test Loss: 0.0674993\n",
      "Validation loss decreased (0.068517 --> 0.067188).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0706152\n",
      "\tspeed: 0.0369s/iter; left time: 756.1406s\n",
      "\titers: 200, epoch: 10 | loss: 0.0760004\n",
      "\tspeed: 0.0217s/iter; left time: 441.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0716838 Vali Loss: 0.0665030 Test Loss: 0.0669898\n",
      "Validation loss decreased (0.067188 --> 0.066503).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702347\n",
      "\tspeed: 0.0318s/iter; left time: 643.2816s\n",
      "\titers: 200, epoch: 11 | loss: 0.0718995\n",
      "\tspeed: 0.0172s/iter; left time: 346.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0707948 Vali Loss: 0.0666187 Test Loss: 0.0674490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0734934\n",
      "\tspeed: 0.0328s/iter; left time: 655.5600s\n",
      "\titers: 200, epoch: 12 | loss: 0.0709180\n",
      "\tspeed: 0.0171s/iter; left time: 341.2346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0698628 Vali Loss: 0.0650645 Test Loss: 0.0659001\n",
      "Validation loss decreased (0.066503 --> 0.065064).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0696956\n",
      "\tspeed: 0.0353s/iter; left time: 698.2108s\n",
      "\titers: 200, epoch: 13 | loss: 0.0614012\n",
      "\tspeed: 0.0181s/iter; left time: 356.4350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0692104 Vali Loss: 0.0647886 Test Loss: 0.0656072\n",
      "Validation loss decreased (0.065064 --> 0.064789).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0693385\n",
      "\tspeed: 0.0355s/iter; left time: 693.9144s\n",
      "\titers: 200, epoch: 14 | loss: 0.0682732\n",
      "\tspeed: 0.0167s/iter; left time: 324.4456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0685786 Vali Loss: 0.0644128 Test Loss: 0.0652005\n",
      "Validation loss decreased (0.064789 --> 0.064413).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0638366\n",
      "\tspeed: 0.0251s/iter; left time: 486.1250s\n",
      "\titers: 200, epoch: 15 | loss: 0.0725680\n",
      "\tspeed: 0.0097s/iter; left time: 185.7303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.36s\n",
      "Steps: 226 | Train Loss: 0.0681003 Vali Loss: 0.0639429 Test Loss: 0.0648437\n",
      "Validation loss decreased (0.064413 --> 0.063943).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0701464\n",
      "\tspeed: 0.0319s/iter; left time: 609.2977s\n",
      "\titers: 200, epoch: 16 | loss: 0.0647896\n",
      "\tspeed: 0.0155s/iter; left time: 294.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0675665 Vali Loss: 0.0636157 Test Loss: 0.0646268\n",
      "Validation loss decreased (0.063943 --> 0.063616).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0655411\n",
      "\tspeed: 0.0309s/iter; left time: 582.7417s\n",
      "\titers: 200, epoch: 17 | loss: 0.0670703\n",
      "\tspeed: 0.0163s/iter; left time: 305.4474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0669401 Vali Loss: 0.0634104 Test Loss: 0.0643599\n",
      "Validation loss decreased (0.063616 --> 0.063410).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0698583\n",
      "\tspeed: 0.0316s/iter; left time: 590.3265s\n",
      "\titers: 200, epoch: 18 | loss: 0.0653305\n",
      "\tspeed: 0.0101s/iter; left time: 187.0687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 226 | Train Loss: 0.0667295 Vali Loss: 0.0626011 Test Loss: 0.0639532\n",
      "Validation loss decreased (0.063410 --> 0.062601).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0661613\n",
      "\tspeed: 0.0295s/iter; left time: 544.4511s\n",
      "\titers: 200, epoch: 19 | loss: 0.0649737\n",
      "\tspeed: 0.0164s/iter; left time: 300.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0663652 Vali Loss: 0.0619979 Test Loss: 0.0636087\n",
      "Validation loss decreased (0.062601 --> 0.061998).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0649312\n",
      "\tspeed: 0.0353s/iter; left time: 643.0561s\n",
      "\titers: 200, epoch: 20 | loss: 0.0673294\n",
      "\tspeed: 0.0185s/iter; left time: 334.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0662496 Vali Loss: 0.0621928 Test Loss: 0.0636217\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0673968\n",
      "\tspeed: 0.0336s/iter; left time: 604.5872s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683301\n",
      "\tspeed: 0.0198s/iter; left time: 353.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0660445 Vali Loss: 0.0619915 Test Loss: 0.0636112\n",
      "Validation loss decreased (0.061998 --> 0.061992).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0616098\n",
      "\tspeed: 0.0332s/iter; left time: 588.6153s\n",
      "\titers: 200, epoch: 22 | loss: 0.0679803\n",
      "\tspeed: 0.0150s/iter; left time: 265.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0657187 Vali Loss: 0.0618104 Test Loss: 0.0633237\n",
      "Validation loss decreased (0.061992 --> 0.061810).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0601932\n",
      "\tspeed: 0.0353s/iter; left time: 619.6269s\n",
      "\titers: 200, epoch: 23 | loss: 0.0639134\n",
      "\tspeed: 0.0197s/iter; left time: 342.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0654844 Vali Loss: 0.0615780 Test Loss: 0.0632567\n",
      "Validation loss decreased (0.061810 --> 0.061578).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0621948\n",
      "\tspeed: 0.0365s/iter; left time: 632.3301s\n",
      "\titers: 200, epoch: 24 | loss: 0.0668994\n",
      "\tspeed: 0.0198s/iter; left time: 341.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 226 | Train Loss: 0.0654431 Vali Loss: 0.0612439 Test Loss: 0.0631715\n",
      "Validation loss decreased (0.061578 --> 0.061244).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0627289\n",
      "\tspeed: 0.0318s/iter; left time: 542.2627s\n",
      "\titers: 200, epoch: 25 | loss: 0.0677464\n",
      "\tspeed: 0.0147s/iter; left time: 248.9377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0652054 Vali Loss: 0.0613669 Test Loss: 0.0629946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0604987\n",
      "\tspeed: 0.0315s/iter; left time: 530.1911s\n",
      "\titers: 200, epoch: 26 | loss: 0.0686064\n",
      "\tspeed: 0.0169s/iter; left time: 283.6809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0650758 Vali Loss: 0.0612290 Test Loss: 0.0629992\n",
      "Validation loss decreased (0.061244 --> 0.061229).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0660665\n",
      "\tspeed: 0.0351s/iter; left time: 583.3352s\n",
      "\titers: 200, epoch: 27 | loss: 0.0662128\n",
      "\tspeed: 0.0195s/iter; left time: 322.0848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 226 | Train Loss: 0.0649722 Vali Loss: 0.0614886 Test Loss: 0.0630154\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0650454\n",
      "\tspeed: 0.0333s/iter; left time: 546.8758s\n",
      "\titers: 200, epoch: 28 | loss: 0.0631211\n",
      "\tspeed: 0.0158s/iter; left time: 257.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0649112 Vali Loss: 0.0611055 Test Loss: 0.0628059\n",
      "Validation loss decreased (0.061229 --> 0.061105).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0670574\n",
      "\tspeed: 0.0305s/iter; left time: 493.6834s\n",
      "\titers: 200, epoch: 29 | loss: 0.0646305\n",
      "\tspeed: 0.0146s/iter; left time: 235.4256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0650379 Vali Loss: 0.0611235 Test Loss: 0.0630979\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0619116\n",
      "\tspeed: 0.0338s/iter; left time: 538.7668s\n",
      "\titers: 200, epoch: 30 | loss: 0.0688088\n",
      "\tspeed: 0.0150s/iter; left time: 238.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0646989 Vali Loss: 0.0609421 Test Loss: 0.0627098\n",
      "Validation loss decreased (0.061105 --> 0.060942).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0645512\n",
      "\tspeed: 0.0343s/iter; left time: 538.8844s\n",
      "\titers: 200, epoch: 31 | loss: 0.0659291\n",
      "\tspeed: 0.0169s/iter; left time: 264.6613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0646035 Vali Loss: 0.0611472 Test Loss: 0.0629095\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0626861\n",
      "\tspeed: 0.0310s/iter; left time: 480.4085s\n",
      "\titers: 200, epoch: 32 | loss: 0.0652184\n",
      "\tspeed: 0.0148s/iter; left time: 228.2659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0646430 Vali Loss: 0.0610199 Test Loss: 0.0626497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0652788\n",
      "\tspeed: 0.0337s/iter; left time: 515.2608s\n",
      "\titers: 200, epoch: 33 | loss: 0.0659325\n",
      "\tspeed: 0.0170s/iter; left time: 258.5736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0645845 Vali Loss: 0.0608501 Test Loss: 0.0625451\n",
      "Validation loss decreased (0.060942 --> 0.060850).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0590962\n",
      "\tspeed: 0.0343s/iter; left time: 516.5190s\n",
      "\titers: 200, epoch: 34 | loss: 0.0679324\n",
      "\tspeed: 0.0169s/iter; left time: 252.1092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0644537 Vali Loss: 0.0607062 Test Loss: 0.0626173\n",
      "Validation loss decreased (0.060850 --> 0.060706).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0630025\n",
      "\tspeed: 0.0310s/iter; left time: 459.5427s\n",
      "\titers: 200, epoch: 35 | loss: 0.0656969\n",
      "\tspeed: 0.0151s/iter; left time: 222.7457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0646521 Vali Loss: 0.0611565 Test Loss: 0.0627958\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0650596\n",
      "\tspeed: 0.0318s/iter; left time: 464.0778s\n",
      "\titers: 200, epoch: 36 | loss: 0.0631918\n",
      "\tspeed: 0.0149s/iter; left time: 215.4710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0644221 Vali Loss: 0.0606643 Test Loss: 0.0624270\n",
      "Validation loss decreased (0.060706 --> 0.060664).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0654559\n",
      "\tspeed: 0.0299s/iter; left time: 428.9926s\n",
      "\titers: 200, epoch: 37 | loss: 0.0641655\n",
      "\tspeed: 0.0167s/iter; left time: 238.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0645150 Vali Loss: 0.0606552 Test Loss: 0.0625015\n",
      "Validation loss decreased (0.060664 --> 0.060655).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0633260\n",
      "\tspeed: 0.0335s/iter; left time: 474.2394s\n",
      "\titers: 200, epoch: 38 | loss: 0.0695505\n",
      "\tspeed: 0.0184s/iter; left time: 258.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0642804 Vali Loss: 0.0609270 Test Loss: 0.0626896\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0642076\n",
      "\tspeed: 0.0321s/iter; left time: 446.0454s\n",
      "\titers: 200, epoch: 39 | loss: 0.0640506\n",
      "\tspeed: 0.0174s/iter; left time: 240.2730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0643265 Vali Loss: 0.0606977 Test Loss: 0.0624603\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0686188\n",
      "\tspeed: 0.0296s/iter; left time: 405.5487s\n",
      "\titers: 200, epoch: 40 | loss: 0.0625081\n",
      "\tspeed: 0.0149s/iter; left time: 202.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0643408 Vali Loss: 0.0604858 Test Loss: 0.0624120\n",
      "Validation loss decreased (0.060655 --> 0.060486).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0631014\n",
      "\tspeed: 0.0331s/iter; left time: 445.7334s\n",
      "\titers: 200, epoch: 41 | loss: 0.0699809\n",
      "\tspeed: 0.0178s/iter; left time: 238.1735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0642466 Vali Loss: 0.0605204 Test Loss: 0.0623931\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0619243\n",
      "\tspeed: 0.0333s/iter; left time: 440.4574s\n",
      "\titers: 200, epoch: 42 | loss: 0.0649035\n",
      "\tspeed: 0.0179s/iter; left time: 235.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0641566 Vali Loss: 0.0607848 Test Loss: 0.0625766\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0657198\n",
      "\tspeed: 0.0302s/iter; left time: 392.5188s\n",
      "\titers: 200, epoch: 43 | loss: 0.0621232\n",
      "\tspeed: 0.0179s/iter; left time: 231.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0642341 Vali Loss: 0.0605430 Test Loss: 0.0624739\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0633814\n",
      "\tspeed: 0.0295s/iter; left time: 376.8730s\n",
      "\titers: 200, epoch: 44 | loss: 0.0651713\n",
      "\tspeed: 0.0123s/iter; left time: 155.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.0641601 Vali Loss: 0.0609071 Test Loss: 0.0626294\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0628465\n",
      "\tspeed: 0.0325s/iter; left time: 408.2180s\n",
      "\titers: 200, epoch: 45 | loss: 0.0660572\n",
      "\tspeed: 0.0155s/iter; left time: 193.5537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0642404 Vali Loss: 0.0605895 Test Loss: 0.0625237\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0685697\n",
      "\tspeed: 0.0339s/iter; left time: 417.8552s\n",
      "\titers: 200, epoch: 46 | loss: 0.0621873\n",
      "\tspeed: 0.0200s/iter; left time: 244.8965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 226 | Train Loss: 0.0642729 Vali Loss: 0.0607251 Test Loss: 0.0624833\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0646147\n",
      "\tspeed: 0.0326s/iter; left time: 394.6524s\n",
      "\titers: 200, epoch: 47 | loss: 0.0673378\n",
      "\tspeed: 0.0150s/iter; left time: 180.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0641940 Vali Loss: 0.0605492 Test Loss: 0.0623635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0633266\n",
      "\tspeed: 0.0336s/iter; left time: 398.8785s\n",
      "\titers: 200, epoch: 48 | loss: 0.0628880\n",
      "\tspeed: 0.0198s/iter; left time: 233.4596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0640995 Vali Loss: 0.0604947 Test Loss: 0.0624149\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0641017\n",
      "\tspeed: 0.0326s/iter; left time: 380.2014s\n",
      "\titers: 200, epoch: 49 | loss: 0.0668483\n",
      "\tspeed: 0.0159s/iter; left time: 184.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0640413 Vali Loss: 0.0605283 Test Loss: 0.0623423\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0645802\n",
      "\tspeed: 0.0312s/iter; left time: 356.0131s\n",
      "\titers: 200, epoch: 50 | loss: 0.0681049\n",
      "\tspeed: 0.0168s/iter; left time: 190.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0640587 Vali Loss: 0.0605727 Test Loss: 0.0623666\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010827051475644112, rmse:0.10405311733484268, mae:0.06241200491786003, rse:0.3931654989719391\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2683806\n",
      "\tspeed: 0.0178s/iter; left time: 400.4553s\n",
      "\titers: 200, epoch: 1 | loss: 0.2500031\n",
      "\tspeed: 0.0164s/iter; left time: 367.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.2719273 Vali Loss: 0.1840928 Test Loss: 0.1898444\n",
      "Validation loss decreased (inf --> 0.184093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1473255\n",
      "\tspeed: 0.0356s/iter; left time: 792.3217s\n",
      "\titers: 200, epoch: 2 | loss: 0.1141868\n",
      "\tspeed: 0.0174s/iter; left time: 384.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.1519194 Vali Loss: 0.0927569 Test Loss: 0.0932253\n",
      "Validation loss decreased (0.184093 --> 0.092757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1015654\n",
      "\tspeed: 0.0336s/iter; left time: 740.5653s\n",
      "\titers: 200, epoch: 3 | loss: 0.0946531\n",
      "\tspeed: 0.0158s/iter; left time: 346.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.1000551 Vali Loss: 0.0842878 Test Loss: 0.0861395\n",
      "Validation loss decreased (0.092757 --> 0.084288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0961696\n",
      "\tspeed: 0.0309s/iter; left time: 674.1843s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867536\n",
      "\tspeed: 0.0171s/iter; left time: 370.9738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0895216 Vali Loss: 0.0783139 Test Loss: 0.0783058\n",
      "Validation loss decreased (0.084288 --> 0.078314).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0827323\n",
      "\tspeed: 0.0310s/iter; left time: 668.8156s\n",
      "\titers: 200, epoch: 5 | loss: 0.0823020\n",
      "\tspeed: 0.0154s/iter; left time: 331.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0828466 Vali Loss: 0.0737580 Test Loss: 0.0737559\n",
      "Validation loss decreased (0.078314 --> 0.073758).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794151\n",
      "\tspeed: 0.0367s/iter; left time: 784.5256s\n",
      "\titers: 200, epoch: 6 | loss: 0.0737667\n",
      "\tspeed: 0.0182s/iter; left time: 387.3200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0783047 Vali Loss: 0.0704807 Test Loss: 0.0705242\n",
      "Validation loss decreased (0.073758 --> 0.070481).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0736217\n",
      "\tspeed: 0.0343s/iter; left time: 724.3221s\n",
      "\titers: 200, epoch: 7 | loss: 0.0697554\n",
      "\tspeed: 0.0153s/iter; left time: 322.6356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0753732 Vali Loss: 0.0690016 Test Loss: 0.0695043\n",
      "Validation loss decreased (0.070481 --> 0.069002).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0740855\n",
      "\tspeed: 0.0339s/iter; left time: 709.4961s\n",
      "\titers: 200, epoch: 8 | loss: 0.0729932\n",
      "\tspeed: 0.0167s/iter; left time: 346.6540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0735638 Vali Loss: 0.0673765 Test Loss: 0.0681725\n",
      "Validation loss decreased (0.069002 --> 0.067376).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0741466\n",
      "\tspeed: 0.0252s/iter; left time: 521.6940s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699058\n",
      "\tspeed: 0.0153s/iter; left time: 315.8517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 226 | Train Loss: 0.0719995 Vali Loss: 0.0672796 Test Loss: 0.0680970\n",
      "Validation loss decreased (0.067376 --> 0.067280).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0702154\n",
      "\tspeed: 0.0325s/iter; left time: 666.1266s\n",
      "\titers: 200, epoch: 10 | loss: 0.0715199\n",
      "\tspeed: 0.0154s/iter; left time: 313.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 226 | Train Loss: 0.0706106 Vali Loss: 0.0660015 Test Loss: 0.0670486\n",
      "Validation loss decreased (0.067280 --> 0.066002).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0648683\n",
      "\tspeed: 0.0315s/iter; left time: 638.2128s\n",
      "\titers: 200, epoch: 11 | loss: 0.0669258\n",
      "\tspeed: 0.0169s/iter; left time: 340.9636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0697243 Vali Loss: 0.0652760 Test Loss: 0.0661902\n",
      "Validation loss decreased (0.066002 --> 0.065276).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712571\n",
      "\tspeed: 0.0314s/iter; left time: 628.3819s\n",
      "\titers: 200, epoch: 12 | loss: 0.0662717\n",
      "\tspeed: 0.0174s/iter; left time: 347.1460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0687956 Vali Loss: 0.0644891 Test Loss: 0.0659832\n",
      "Validation loss decreased (0.065276 --> 0.064489).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0688350\n",
      "\tspeed: 0.0304s/iter; left time: 600.7452s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723955\n",
      "\tspeed: 0.0167s/iter; left time: 328.7659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0682971 Vali Loss: 0.0655814 Test Loss: 0.0672650\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0626216\n",
      "\tspeed: 0.0333s/iter; left time: 652.0142s\n",
      "\titers: 200, epoch: 14 | loss: 0.0653330\n",
      "\tspeed: 0.0181s/iter; left time: 352.5416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0676314 Vali Loss: 0.0636220 Test Loss: 0.0650536\n",
      "Validation loss decreased (0.064489 --> 0.063622).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0657042\n",
      "\tspeed: 0.0338s/iter; left time: 653.5294s\n",
      "\titers: 200, epoch: 15 | loss: 0.0669574\n",
      "\tspeed: 0.0179s/iter; left time: 344.2830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0668961 Vali Loss: 0.0634391 Test Loss: 0.0649784\n",
      "Validation loss decreased (0.063622 --> 0.063439).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0697312\n",
      "\tspeed: 0.0331s/iter; left time: 632.9849s\n",
      "\titers: 200, epoch: 16 | loss: 0.0630022\n",
      "\tspeed: 0.0177s/iter; left time: 336.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 226 | Train Loss: 0.0664600 Vali Loss: 0.0630070 Test Loss: 0.0646449\n",
      "Validation loss decreased (0.063439 --> 0.063007).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0637233\n",
      "\tspeed: 0.0476s/iter; left time: 898.0290s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637252\n",
      "\tspeed: 0.0154s/iter; left time: 288.8108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0659325 Vali Loss: 0.0624811 Test Loss: 0.0643669\n",
      "Validation loss decreased (0.063007 --> 0.062481).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0649766\n",
      "\tspeed: 0.0334s/iter; left time: 623.6352s\n",
      "\titers: 200, epoch: 18 | loss: 0.0627688\n",
      "\tspeed: 0.0136s/iter; left time: 252.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0658954 Vali Loss: 0.0630394 Test Loss: 0.0648154\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0659889\n",
      "\tspeed: 0.0314s/iter; left time: 578.7307s\n",
      "\titers: 200, epoch: 19 | loss: 0.0662282\n",
      "\tspeed: 0.0148s/iter; left time: 270.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 226 | Train Loss: 0.0656105 Vali Loss: 0.0625913 Test Loss: 0.0644748\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0655865\n",
      "\tspeed: 0.0341s/iter; left time: 620.8576s\n",
      "\titers: 200, epoch: 20 | loss: 0.0657419\n",
      "\tspeed: 0.0164s/iter; left time: 297.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 226 | Train Loss: 0.0654036 Vali Loss: 0.0621260 Test Loss: 0.0637845\n",
      "Validation loss decreased (0.062481 --> 0.062126).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0695874\n",
      "\tspeed: 0.0327s/iter; left time: 588.7165s\n",
      "\titers: 200, epoch: 21 | loss: 0.0634244\n",
      "\tspeed: 0.0166s/iter; left time: 297.4133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.0651018 Vali Loss: 0.0619380 Test Loss: 0.0638644\n",
      "Validation loss decreased (0.062126 --> 0.061938).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0650325\n",
      "\tspeed: 0.0307s/iter; left time: 544.6062s\n",
      "\titers: 200, epoch: 22 | loss: 0.0630519\n",
      "\tspeed: 0.0155s/iter; left time: 273.4876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0649287 Vali Loss: 0.0616359 Test Loss: 0.0637903\n",
      "Validation loss decreased (0.061938 --> 0.061636).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0641462\n",
      "\tspeed: 0.0308s/iter; left time: 540.1850s\n",
      "\titers: 200, epoch: 23 | loss: 0.0719948\n",
      "\tspeed: 0.0153s/iter; left time: 267.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0647936 Vali Loss: 0.0615581 Test Loss: 0.0639146\n",
      "Validation loss decreased (0.061636 --> 0.061558).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0681741\n",
      "\tspeed: 0.0327s/iter; left time: 565.9736s\n",
      "\titers: 200, epoch: 24 | loss: 0.0643590\n",
      "\tspeed: 0.0150s/iter; left time: 258.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0646900 Vali Loss: 0.0612422 Test Loss: 0.0634298\n",
      "Validation loss decreased (0.061558 --> 0.061242).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0616931\n",
      "\tspeed: 0.0308s/iter; left time: 526.0258s\n",
      "\titers: 200, epoch: 25 | loss: 0.0661258\n",
      "\tspeed: 0.0150s/iter; left time: 254.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0644749 Vali Loss: 0.0617726 Test Loss: 0.0638768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0671707\n",
      "\tspeed: 0.0298s/iter; left time: 502.4363s\n",
      "\titers: 200, epoch: 26 | loss: 0.0633176\n",
      "\tspeed: 0.0190s/iter; left time: 317.6319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0642615 Vali Loss: 0.0610944 Test Loss: 0.0634198\n",
      "Validation loss decreased (0.061242 --> 0.061094).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0674960\n",
      "\tspeed: 0.0355s/iter; left time: 589.5168s\n",
      "\titers: 200, epoch: 27 | loss: 0.0583401\n",
      "\tspeed: 0.0184s/iter; left time: 303.9895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0641232 Vali Loss: 0.0611686 Test Loss: 0.0632927\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0650903\n",
      "\tspeed: 0.0305s/iter; left time: 500.4951s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644257\n",
      "\tspeed: 0.0156s/iter; left time: 254.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0643254 Vali Loss: 0.0615976 Test Loss: 0.0636764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0650363\n",
      "\tspeed: 0.0327s/iter; left time: 528.5208s\n",
      "\titers: 200, epoch: 29 | loss: 0.0612404\n",
      "\tspeed: 0.0150s/iter; left time: 241.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0641005 Vali Loss: 0.0610079 Test Loss: 0.0633634\n",
      "Validation loss decreased (0.061094 --> 0.061008).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0642853\n",
      "\tspeed: 0.0309s/iter; left time: 492.7942s\n",
      "\titers: 200, epoch: 30 | loss: 0.0671432\n",
      "\tspeed: 0.0152s/iter; left time: 241.6337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0640129 Vali Loss: 0.0607666 Test Loss: 0.0629210\n",
      "Validation loss decreased (0.061008 --> 0.060767).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0637396\n",
      "\tspeed: 0.0329s/iter; left time: 516.9158s\n",
      "\titers: 200, epoch: 31 | loss: 0.0668434\n",
      "\tspeed: 0.0153s/iter; left time: 238.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0639195 Vali Loss: 0.0608141 Test Loss: 0.0631239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0630049\n",
      "\tspeed: 0.0327s/iter; left time: 507.3852s\n",
      "\titers: 200, epoch: 32 | loss: 0.0637505\n",
      "\tspeed: 0.0148s/iter; left time: 227.1868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0638752 Vali Loss: 0.0608141 Test Loss: 0.0631300\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0624260\n",
      "\tspeed: 0.0329s/iter; left time: 503.0974s\n",
      "\titers: 200, epoch: 33 | loss: 0.0629199\n",
      "\tspeed: 0.0171s/iter; left time: 259.8773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 226 | Train Loss: 0.0637798 Vali Loss: 0.0608580 Test Loss: 0.0632233\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0678928\n",
      "\tspeed: 0.0304s/iter; left time: 457.5547s\n",
      "\titers: 200, epoch: 34 | loss: 0.0654967\n",
      "\tspeed: 0.0183s/iter; left time: 273.0672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0635867 Vali Loss: 0.0606437 Test Loss: 0.0629190\n",
      "Validation loss decreased (0.060767 --> 0.060644).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0626763\n",
      "\tspeed: 0.0327s/iter; left time: 484.0725s\n",
      "\titers: 200, epoch: 35 | loss: 0.0595072\n",
      "\tspeed: 0.0097s/iter; left time: 142.8096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0636496 Vali Loss: 0.0607713 Test Loss: 0.0630210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0632355\n",
      "\tspeed: 0.0310s/iter; left time: 452.4127s\n",
      "\titers: 200, epoch: 36 | loss: 0.0626784\n",
      "\tspeed: 0.0165s/iter; left time: 239.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0635934 Vali Loss: 0.0607727 Test Loss: 0.0631237\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0646072\n",
      "\tspeed: 0.0299s/iter; left time: 429.9258s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619449\n",
      "\tspeed: 0.0146s/iter; left time: 208.4793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0637344 Vali Loss: 0.0604826 Test Loss: 0.0628754\n",
      "Validation loss decreased (0.060644 --> 0.060483).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0628808\n",
      "\tspeed: 0.0353s/iter; left time: 498.5920s\n",
      "\titers: 200, epoch: 38 | loss: 0.0625452\n",
      "\tspeed: 0.0173s/iter; left time: 243.1245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0635299 Vali Loss: 0.0607594 Test Loss: 0.0630251\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0618605\n",
      "\tspeed: 0.0328s/iter; left time: 456.1279s\n",
      "\titers: 200, epoch: 39 | loss: 0.0630019\n",
      "\tspeed: 0.0151s/iter; left time: 209.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0635054 Vali Loss: 0.0604440 Test Loss: 0.0628059\n",
      "Validation loss decreased (0.060483 --> 0.060444).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0633831\n",
      "\tspeed: 0.0341s/iter; left time: 467.0752s\n",
      "\titers: 200, epoch: 40 | loss: 0.0619897\n",
      "\tspeed: 0.0166s/iter; left time: 226.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0633871 Vali Loss: 0.0604068 Test Loss: 0.0627636\n",
      "Validation loss decreased (0.060444 --> 0.060407).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0637393\n",
      "\tspeed: 0.0338s/iter; left time: 455.1581s\n",
      "\titers: 200, epoch: 41 | loss: 0.0667270\n",
      "\tspeed: 0.0151s/iter; left time: 202.2399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0634874 Vali Loss: 0.0605568 Test Loss: 0.0628070\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0642112\n",
      "\tspeed: 0.0318s/iter; left time: 421.1110s\n",
      "\titers: 200, epoch: 42 | loss: 0.0642818\n",
      "\tspeed: 0.0169s/iter; left time: 221.9380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0634600 Vali Loss: 0.0604853 Test Loss: 0.0628637\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0662356\n",
      "\tspeed: 0.0292s/iter; left time: 380.4633s\n",
      "\titers: 200, epoch: 43 | loss: 0.0618695\n",
      "\tspeed: 0.0121s/iter; left time: 155.9720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 226 | Train Loss: 0.0635914 Vali Loss: 0.0605979 Test Loss: 0.0628928\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0643022\n",
      "\tspeed: 0.0287s/iter; left time: 366.8359s\n",
      "\titers: 200, epoch: 44 | loss: 0.0604591\n",
      "\tspeed: 0.0145s/iter; left time: 183.5275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0634527 Vali Loss: 0.0604677 Test Loss: 0.0628158\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0598588\n",
      "\tspeed: 0.0316s/iter; left time: 397.3438s\n",
      "\titers: 200, epoch: 45 | loss: 0.0621295\n",
      "\tspeed: 0.0166s/iter; left time: 206.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 226 | Train Loss: 0.0632411 Vali Loss: 0.0605021 Test Loss: 0.0628431\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0609445\n",
      "\tspeed: 0.0321s/iter; left time: 395.3985s\n",
      "\titers: 200, epoch: 46 | loss: 0.0611818\n",
      "\tspeed: 0.0165s/iter; left time: 202.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 226 | Train Loss: 0.0634811 Vali Loss: 0.0604158 Test Loss: 0.0629384\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0620083\n",
      "\tspeed: 0.0314s/iter; left time: 380.1078s\n",
      "\titers: 200, epoch: 47 | loss: 0.0650088\n",
      "\tspeed: 0.0151s/iter; left time: 180.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0632877 Vali Loss: 0.0604093 Test Loss: 0.0628394\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0626589\n",
      "\tspeed: 0.0335s/iter; left time: 397.7635s\n",
      "\titers: 200, epoch: 48 | loss: 0.0617674\n",
      "\tspeed: 0.0155s/iter; left time: 182.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0634256 Vali Loss: 0.0605984 Test Loss: 0.0629385\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0801785\n",
      "\tspeed: 0.0339s/iter; left time: 395.3750s\n",
      "\titers: 200, epoch: 49 | loss: 0.0644043\n",
      "\tspeed: 0.0182s/iter; left time: 210.3114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0633992 Vali Loss: 0.0605179 Test Loss: 0.0629123\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0656605\n",
      "\tspeed: 0.0339s/iter; left time: 387.2193s\n",
      "\titers: 200, epoch: 50 | loss: 0.0648636\n",
      "\tspeed: 0.0154s/iter; left time: 174.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0633635 Vali Loss: 0.0603140 Test Loss: 0.0628248\n",
      "Validation loss decreased (0.060407 --> 0.060314).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0649489\n",
      "\tspeed: 0.0326s/iter; left time: 365.2338s\n",
      "\titers: 200, epoch: 51 | loss: 0.0648584\n",
      "\tspeed: 0.0186s/iter; left time: 206.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0633087 Vali Loss: 0.0604656 Test Loss: 0.0627679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0614670\n",
      "\tspeed: 0.0305s/iter; left time: 334.5138s\n",
      "\titers: 200, epoch: 52 | loss: 0.0604024\n",
      "\tspeed: 0.0191s/iter; left time: 208.1896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0634348 Vali Loss: 0.0603848 Test Loss: 0.0627892\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0597789\n",
      "\tspeed: 0.0318s/iter; left time: 342.0200s\n",
      "\titers: 200, epoch: 53 | loss: 0.0624102\n",
      "\tspeed: 0.0164s/iter; left time: 175.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 226 | Train Loss: 0.0632580 Vali Loss: 0.0603975 Test Loss: 0.0627268\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0661077\n",
      "\tspeed: 0.0301s/iter; left time: 316.5067s\n",
      "\titers: 200, epoch: 54 | loss: 0.0639733\n",
      "\tspeed: 0.0164s/iter; left time: 171.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0633711 Vali Loss: 0.0603307 Test Loss: 0.0627780\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0634417\n",
      "\tspeed: 0.0326s/iter; left time: 335.6777s\n",
      "\titers: 200, epoch: 55 | loss: 0.0628030\n",
      "\tspeed: 0.0150s/iter; left time: 153.2811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0632948 Vali Loss: 0.0603213 Test Loss: 0.0627216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0656375\n",
      "\tspeed: 0.0335s/iter; left time: 337.8010s\n",
      "\titers: 200, epoch: 56 | loss: 0.0626009\n",
      "\tspeed: 0.0169s/iter; left time: 168.4996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0632629 Vali Loss: 0.0602907 Test Loss: 0.0627626\n",
      "Validation loss decreased (0.060314 --> 0.060291).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0606608\n",
      "\tspeed: 0.0341s/iter; left time: 335.6841s\n",
      "\titers: 200, epoch: 57 | loss: 0.0667918\n",
      "\tspeed: 0.0169s/iter; left time: 164.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0632846 Vali Loss: 0.0604346 Test Loss: 0.0628324\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0614186\n",
      "\tspeed: 0.0319s/iter; left time: 306.5196s\n",
      "\titers: 200, epoch: 58 | loss: 0.0616034\n",
      "\tspeed: 0.0177s/iter; left time: 168.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0632635 Vali Loss: 0.0603961 Test Loss: 0.0627379\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0648625\n",
      "\tspeed: 0.0300s/iter; left time: 281.9206s\n",
      "\titers: 200, epoch: 59 | loss: 0.0606599\n",
      "\tspeed: 0.0150s/iter; left time: 139.3519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0632889 Vali Loss: 0.0604271 Test Loss: 0.0627835\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0595693\n",
      "\tspeed: 0.0356s/iter; left time: 325.9394s\n",
      "\titers: 200, epoch: 60 | loss: 0.0608444\n",
      "\tspeed: 0.0207s/iter; left time: 187.7066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0632423 Vali Loss: 0.0604059 Test Loss: 0.0627771\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0611959\n",
      "\tspeed: 0.0372s/iter; left time: 332.8292s\n",
      "\titers: 200, epoch: 61 | loss: 0.0614771\n",
      "\tspeed: 0.0206s/iter; left time: 182.0880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 226 | Train Loss: 0.0633894 Vali Loss: 0.0603203 Test Loss: 0.0627730\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0627258\n",
      "\tspeed: 0.0374s/iter; left time: 325.8472s\n",
      "\titers: 200, epoch: 62 | loss: 0.0658270\n",
      "\tspeed: 0.0177s/iter; left time: 152.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 226 | Train Loss: 0.0631786 Vali Loss: 0.0603669 Test Loss: 0.0628356\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0643718\n",
      "\tspeed: 0.0334s/iter; left time: 283.9527s\n",
      "\titers: 200, epoch: 63 | loss: 0.0651433\n",
      "\tspeed: 0.0153s/iter; left time: 128.7398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0633000 Vali Loss: 0.0603122 Test Loss: 0.0626970\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0600079\n",
      "\tspeed: 0.0272s/iter; left time: 224.9807s\n",
      "\titers: 200, epoch: 64 | loss: 0.0663806\n",
      "\tspeed: 0.0208s/iter; left time: 169.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0631326 Vali Loss: 0.0603702 Test Loss: 0.0627292\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0659940\n",
      "\tspeed: 0.0382s/iter; left time: 306.6183s\n",
      "\titers: 200, epoch: 65 | loss: 0.0599802\n",
      "\tspeed: 0.0227s/iter; left time: 180.2711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 226 | Train Loss: 0.0632878 Vali Loss: 0.0603091 Test Loss: 0.0626982\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0627154\n",
      "\tspeed: 0.0364s/iter; left time: 284.1278s\n",
      "\titers: 200, epoch: 66 | loss: 0.0643168\n",
      "\tspeed: 0.0162s/iter; left time: 124.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0632404 Vali Loss: 0.0603718 Test Loss: 0.0627312\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010896671563386917, rmse:0.10438712686300278, mae:0.06276259571313858, rse:0.3944275379180908\n",
      "Intermediate time for IT and pred_len 24: 00h:09m:39.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2777186\n",
      "\tspeed: 0.0429s/iter; left time: 961.0489s\n",
      "\titers: 200, epoch: 1 | loss: 0.2569139\n",
      "\tspeed: 0.0150s/iter; left time: 335.2937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.2819139 Vali Loss: 0.1959135 Test Loss: 0.2025781\n",
      "Validation loss decreased (inf --> 0.195914).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1503462\n",
      "\tspeed: 0.0330s/iter; left time: 731.6456s\n",
      "\titers: 200, epoch: 2 | loss: 0.1258866\n",
      "\tspeed: 0.0166s/iter; left time: 367.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.1587552 Vali Loss: 0.1118642 Test Loss: 0.1198275\n",
      "Validation loss decreased (0.195914 --> 0.111864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1137129\n",
      "\tspeed: 0.0332s/iter; left time: 729.7910s\n",
      "\titers: 200, epoch: 3 | loss: 0.1097044\n",
      "\tspeed: 0.0152s/iter; left time: 331.1760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.1154826 Vali Loss: 0.1006880 Test Loss: 0.1063467\n",
      "Validation loss decreased (0.111864 --> 0.100688).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1010056\n",
      "\tspeed: 0.0342s/iter; left time: 742.1826s\n",
      "\titers: 200, epoch: 4 | loss: 0.1015733\n",
      "\tspeed: 0.0171s/iter; left time: 368.8469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.1046104 Vali Loss: 0.0929637 Test Loss: 0.0947932\n",
      "Validation loss decreased (0.100688 --> 0.092964).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931383\n",
      "\tspeed: 0.0321s/iter; left time: 690.8377s\n",
      "\titers: 200, epoch: 5 | loss: 0.0927026\n",
      "\tspeed: 0.0128s/iter; left time: 274.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 225 | Train Loss: 0.0980567 Vali Loss: 0.0881273 Test Loss: 0.0907078\n",
      "Validation loss decreased (0.092964 --> 0.088127).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0922307\n",
      "\tspeed: 0.0324s/iter; left time: 688.9151s\n",
      "\titers: 200, epoch: 6 | loss: 0.0929584\n",
      "\tspeed: 0.0150s/iter; left time: 318.6271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0937415 Vali Loss: 0.0870895 Test Loss: 0.0893921\n",
      "Validation loss decreased (0.088127 --> 0.087090).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0876376\n",
      "\tspeed: 0.0304s/iter; left time: 640.8364s\n",
      "\titers: 200, epoch: 7 | loss: 0.0913200\n",
      "\tspeed: 0.0152s/iter; left time: 319.4856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0917897 Vali Loss: 0.0873184 Test Loss: 0.0884443\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0914330\n",
      "\tspeed: 0.0311s/iter; left time: 647.4304s\n",
      "\titers: 200, epoch: 8 | loss: 0.0905815\n",
      "\tspeed: 0.0135s/iter; left time: 280.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0901037 Vali Loss: 0.0847947 Test Loss: 0.0869199\n",
      "Validation loss decreased (0.087090 --> 0.084795).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0856609\n",
      "\tspeed: 0.0312s/iter; left time: 642.2962s\n",
      "\titers: 200, epoch: 9 | loss: 0.0856232\n",
      "\tspeed: 0.0148s/iter; left time: 304.3502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0886598 Vali Loss: 0.0832606 Test Loss: 0.0864825\n",
      "Validation loss decreased (0.084795 --> 0.083261).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0846817\n",
      "\tspeed: 0.0336s/iter; left time: 684.0704s\n",
      "\titers: 200, epoch: 10 | loss: 0.0886836\n",
      "\tspeed: 0.0174s/iter; left time: 353.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0876424 Vali Loss: 0.0821826 Test Loss: 0.0856964\n",
      "Validation loss decreased (0.083261 --> 0.082183).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0854393\n",
      "\tspeed: 0.0325s/iter; left time: 653.9121s\n",
      "\titers: 200, epoch: 11 | loss: 0.0864105\n",
      "\tspeed: 0.0167s/iter; left time: 333.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0867340 Vali Loss: 0.0822964 Test Loss: 0.0857694\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0855199\n",
      "\tspeed: 0.0344s/iter; left time: 685.3361s\n",
      "\titers: 200, epoch: 12 | loss: 0.0839509\n",
      "\tspeed: 0.0159s/iter; left time: 314.3120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0861404 Vali Loss: 0.0814085 Test Loss: 0.0855265\n",
      "Validation loss decreased (0.082183 --> 0.081408).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0868975\n",
      "\tspeed: 0.0349s/iter; left time: 688.2557s\n",
      "\titers: 200, epoch: 13 | loss: 0.0869677\n",
      "\tspeed: 0.0173s/iter; left time: 338.8974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0854552 Vali Loss: 0.0811413 Test Loss: 0.0852011\n",
      "Validation loss decreased (0.081408 --> 0.081141).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0895584\n",
      "\tspeed: 0.0358s/iter; left time: 697.4273s\n",
      "\titers: 200, epoch: 14 | loss: 0.0863725\n",
      "\tspeed: 0.0185s/iter; left time: 358.6055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0850139 Vali Loss: 0.0810665 Test Loss: 0.0850852\n",
      "Validation loss decreased (0.081141 --> 0.081066).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0829848\n",
      "\tspeed: 0.0370s/iter; left time: 711.9327s\n",
      "\titers: 200, epoch: 15 | loss: 0.0862410\n",
      "\tspeed: 0.0177s/iter; left time: 339.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0848629 Vali Loss: 0.0807258 Test Loss: 0.0846477\n",
      "Validation loss decreased (0.081066 --> 0.080726).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0863633\n",
      "\tspeed: 0.0348s/iter; left time: 661.3818s\n",
      "\titers: 200, epoch: 16 | loss: 0.0844380\n",
      "\tspeed: 0.0158s/iter; left time: 299.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0842551 Vali Loss: 0.0807420 Test Loss: 0.0847929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0799475\n",
      "\tspeed: 0.0352s/iter; left time: 661.7758s\n",
      "\titers: 200, epoch: 17 | loss: 0.0838205\n",
      "\tspeed: 0.0180s/iter; left time: 337.4556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0838634 Vali Loss: 0.0803780 Test Loss: 0.0846857\n",
      "Validation loss decreased (0.080726 --> 0.080378).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0869446\n",
      "\tspeed: 0.0341s/iter; left time: 633.0774s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812265\n",
      "\tspeed: 0.0150s/iter; left time: 276.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0837593 Vali Loss: 0.0805071 Test Loss: 0.0846009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0842634\n",
      "\tspeed: 0.0311s/iter; left time: 570.3352s\n",
      "\titers: 200, epoch: 19 | loss: 0.0814005\n",
      "\tspeed: 0.0149s/iter; left time: 272.7924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0835424 Vali Loss: 0.0801593 Test Loss: 0.0845342\n",
      "Validation loss decreased (0.080378 --> 0.080159).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0785947\n",
      "\tspeed: 0.0302s/iter; left time: 546.5463s\n",
      "\titers: 200, epoch: 20 | loss: 0.0831343\n",
      "\tspeed: 0.0098s/iter; left time: 176.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0830553 Vali Loss: 0.0797146 Test Loss: 0.0843138\n",
      "Validation loss decreased (0.080159 --> 0.079715).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0833767\n",
      "\tspeed: 0.0305s/iter; left time: 545.3059s\n",
      "\titers: 200, epoch: 21 | loss: 0.0770623\n",
      "\tspeed: 0.0164s/iter; left time: 291.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0830372 Vali Loss: 0.0799927 Test Loss: 0.0844230\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0853504\n",
      "\tspeed: 0.0342s/iter; left time: 605.1978s\n",
      "\titers: 200, epoch: 22 | loss: 0.0816715\n",
      "\tspeed: 0.0197s/iter; left time: 345.5864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0829589 Vali Loss: 0.0797679 Test Loss: 0.0844153\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0850140\n",
      "\tspeed: 0.0351s/iter; left time: 612.2322s\n",
      "\titers: 200, epoch: 23 | loss: 0.0841234\n",
      "\tspeed: 0.0171s/iter; left time: 296.0620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0828476 Vali Loss: 0.0798274 Test Loss: 0.0842461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0811909\n",
      "\tspeed: 0.0340s/iter; left time: 586.3451s\n",
      "\titers: 200, epoch: 24 | loss: 0.0802586\n",
      "\tspeed: 0.0180s/iter; left time: 307.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0826429 Vali Loss: 0.0795573 Test Loss: 0.0841798\n",
      "Validation loss decreased (0.079715 --> 0.079557).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0818036\n",
      "\tspeed: 0.0345s/iter; left time: 587.3012s\n",
      "\titers: 200, epoch: 25 | loss: 0.0837724\n",
      "\tspeed: 0.0170s/iter; left time: 286.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0825855 Vali Loss: 0.0795854 Test Loss: 0.0841127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0862241\n",
      "\tspeed: 0.0333s/iter; left time: 558.4197s\n",
      "\titers: 200, epoch: 26 | loss: 0.0794363\n",
      "\tspeed: 0.0175s/iter; left time: 291.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.0824944 Vali Loss: 0.0795109 Test Loss: 0.0841575\n",
      "Validation loss decreased (0.079557 --> 0.079511).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0837308\n",
      "\tspeed: 0.0366s/iter; left time: 606.5219s\n",
      "\titers: 200, epoch: 27 | loss: 0.0837827\n",
      "\tspeed: 0.0166s/iter; left time: 272.6125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0824191 Vali Loss: 0.0793480 Test Loss: 0.0840780\n",
      "Validation loss decreased (0.079511 --> 0.079348).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0826852\n",
      "\tspeed: 0.0324s/iter; left time: 529.1745s\n",
      "\titers: 200, epoch: 28 | loss: 0.0801488\n",
      "\tspeed: 0.0174s/iter; left time: 282.3352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0824533 Vali Loss: 0.0794025 Test Loss: 0.0841289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0853649\n",
      "\tspeed: 0.0334s/iter; left time: 538.3358s\n",
      "\titers: 200, epoch: 29 | loss: 0.0783699\n",
      "\tspeed: 0.0182s/iter; left time: 290.4769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0823509 Vali Loss: 0.0792908 Test Loss: 0.0840861\n",
      "Validation loss decreased (0.079348 --> 0.079291).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0823211\n",
      "\tspeed: 0.0327s/iter; left time: 519.9043s\n",
      "\titers: 200, epoch: 30 | loss: 0.0827666\n",
      "\tspeed: 0.0176s/iter; left time: 277.8531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0822907 Vali Loss: 0.0792715 Test Loss: 0.0839312\n",
      "Validation loss decreased (0.079291 --> 0.079272).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0808998\n",
      "\tspeed: 0.0325s/iter; left time: 509.1454s\n",
      "\titers: 200, epoch: 31 | loss: 0.0807928\n",
      "\tspeed: 0.0192s/iter; left time: 298.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0821265 Vali Loss: 0.0792237 Test Loss: 0.0839969\n",
      "Validation loss decreased (0.079272 --> 0.079224).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0815765\n",
      "\tspeed: 0.0357s/iter; left time: 550.7602s\n",
      "\titers: 200, epoch: 32 | loss: 0.0843080\n",
      "\tspeed: 0.0174s/iter; left time: 266.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0820431 Vali Loss: 0.0791623 Test Loss: 0.0839657\n",
      "Validation loss decreased (0.079224 --> 0.079162).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0847938\n",
      "\tspeed: 0.0354s/iter; left time: 537.3809s\n",
      "\titers: 200, epoch: 33 | loss: 0.0855501\n",
      "\tspeed: 0.0203s/iter; left time: 307.0463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0820090 Vali Loss: 0.0793583 Test Loss: 0.0840243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0875249\n",
      "\tspeed: 0.0349s/iter; left time: 522.5661s\n",
      "\titers: 200, epoch: 34 | loss: 0.0807978\n",
      "\tspeed: 0.0174s/iter; left time: 258.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0820447 Vali Loss: 0.0791663 Test Loss: 0.0839047\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0820323\n",
      "\tspeed: 0.0336s/iter; left time: 496.1109s\n",
      "\titers: 200, epoch: 35 | loss: 0.0817046\n",
      "\tspeed: 0.0170s/iter; left time: 248.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.0820172 Vali Loss: 0.0792771 Test Loss: 0.0839085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0853832\n",
      "\tspeed: 0.0383s/iter; left time: 555.7814s\n",
      "\titers: 200, epoch: 36 | loss: 0.0840510\n",
      "\tspeed: 0.0205s/iter; left time: 295.2685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 225 | Train Loss: 0.0818907 Vali Loss: 0.0792983 Test Loss: 0.0839392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0841038\n",
      "\tspeed: 0.0337s/iter; left time: 481.5279s\n",
      "\titers: 200, epoch: 37 | loss: 0.0768642\n",
      "\tspeed: 0.0155s/iter; left time: 220.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0818594 Vali Loss: 0.0791648 Test Loss: 0.0838817\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0840093\n",
      "\tspeed: 0.0330s/iter; left time: 464.6572s\n",
      "\titers: 200, epoch: 38 | loss: 0.0796729\n",
      "\tspeed: 0.0155s/iter; left time: 217.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0819101 Vali Loss: 0.0791788 Test Loss: 0.0838323\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0785457\n",
      "\tspeed: 0.0331s/iter; left time: 458.1444s\n",
      "\titers: 200, epoch: 39 | loss: 0.0818148\n",
      "\tspeed: 0.0174s/iter; left time: 238.7875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0817813 Vali Loss: 0.0791711 Test Loss: 0.0839773\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0786763\n",
      "\tspeed: 0.0342s/iter; left time: 465.5255s\n",
      "\titers: 200, epoch: 40 | loss: 0.0864732\n",
      "\tspeed: 0.0170s/iter; left time: 229.6591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0818996 Vali Loss: 0.0791738 Test Loss: 0.0838895\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0772040\n",
      "\tspeed: 0.0364s/iter; left time: 487.5658s\n",
      "\titers: 200, epoch: 41 | loss: 0.0768942\n",
      "\tspeed: 0.0187s/iter; left time: 248.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0819151 Vali Loss: 0.0793107 Test Loss: 0.0837918\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0828241\n",
      "\tspeed: 0.0319s/iter; left time: 420.5608s\n",
      "\titers: 200, epoch: 42 | loss: 0.0808430\n",
      "\tspeed: 0.0152s/iter; left time: 199.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0817570 Vali Loss: 0.0792095 Test Loss: 0.0838636\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01884772628545761, rmse:0.13728702068328857, mae:0.08396567404270172, rse:0.5190970301628113\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2806228\n",
      "\tspeed: 0.0206s/iter; left time: 461.4312s\n",
      "\titers: 200, epoch: 1 | loss: 0.2607370\n",
      "\tspeed: 0.0164s/iter; left time: 364.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.2831202 Vali Loss: 0.1983966 Test Loss: 0.2050680\n",
      "Validation loss decreased (inf --> 0.198397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1462103\n",
      "\tspeed: 0.0340s/iter; left time: 753.8183s\n",
      "\titers: 200, epoch: 2 | loss: 0.1279159\n",
      "\tspeed: 0.0181s/iter; left time: 398.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.1583383 Vali Loss: 0.1096080 Test Loss: 0.1172922\n",
      "Validation loss decreased (0.198397 --> 0.109608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1173452\n",
      "\tspeed: 0.0341s/iter; left time: 749.0793s\n",
      "\titers: 200, epoch: 3 | loss: 0.1107076\n",
      "\tspeed: 0.0160s/iter; left time: 348.6146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.1156612 Vali Loss: 0.0991728 Test Loss: 0.1039855\n",
      "Validation loss decreased (0.109608 --> 0.099173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1042874\n",
      "\tspeed: 0.0383s/iter; left time: 831.3813s\n",
      "\titers: 200, epoch: 4 | loss: 0.1006773\n",
      "\tspeed: 0.0155s/iter; left time: 334.3438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.1042152 Vali Loss: 0.0926457 Test Loss: 0.0946814\n",
      "Validation loss decreased (0.099173 --> 0.092646).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0966639\n",
      "\tspeed: 0.0351s/iter; left time: 755.6407s\n",
      "\titers: 200, epoch: 5 | loss: 0.0967009\n",
      "\tspeed: 0.0197s/iter; left time: 422.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0973508 Vali Loss: 0.0883805 Test Loss: 0.0907344\n",
      "Validation loss decreased (0.092646 --> 0.088380).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0990865\n",
      "\tspeed: 0.0327s/iter; left time: 695.9985s\n",
      "\titers: 200, epoch: 6 | loss: 0.0904820\n",
      "\tspeed: 0.0158s/iter; left time: 333.7299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0936973 Vali Loss: 0.0869135 Test Loss: 0.0890371\n",
      "Validation loss decreased (0.088380 --> 0.086913).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0910847\n",
      "\tspeed: 0.0330s/iter; left time: 694.2954s\n",
      "\titers: 200, epoch: 7 | loss: 0.0939122\n",
      "\tspeed: 0.0163s/iter; left time: 341.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0915057 Vali Loss: 0.0855780 Test Loss: 0.0873110\n",
      "Validation loss decreased (0.086913 --> 0.085578).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0887241\n",
      "\tspeed: 0.0327s/iter; left time: 681.5565s\n",
      "\titers: 200, epoch: 8 | loss: 0.0864781\n",
      "\tspeed: 0.0175s/iter; left time: 362.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0897954 Vali Loss: 0.0844579 Test Loss: 0.0867044\n",
      "Validation loss decreased (0.085578 --> 0.084458).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0920255\n",
      "\tspeed: 0.0335s/iter; left time: 691.0493s\n",
      "\titers: 200, epoch: 9 | loss: 0.0843511\n",
      "\tspeed: 0.0175s/iter; left time: 358.8526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0883764 Vali Loss: 0.0829569 Test Loss: 0.0858086\n",
      "Validation loss decreased (0.084458 --> 0.082957).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0842601\n",
      "\tspeed: 0.0332s/iter; left time: 675.9181s\n",
      "\titers: 200, epoch: 10 | loss: 0.0844496\n",
      "\tspeed: 0.0149s/iter; left time: 302.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0878313 Vali Loss: 0.0819504 Test Loss: 0.0851816\n",
      "Validation loss decreased (0.082957 --> 0.081950).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0903435\n",
      "\tspeed: 0.0331s/iter; left time: 667.1771s\n",
      "\titers: 200, epoch: 11 | loss: 0.0884159\n",
      "\tspeed: 0.0129s/iter; left time: 258.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0869585 Vali Loss: 0.0821840 Test Loss: 0.0849077\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0880806\n",
      "\tspeed: 0.0311s/iter; left time: 618.9819s\n",
      "\titers: 200, epoch: 12 | loss: 0.0892761\n",
      "\tspeed: 0.0169s/iter; left time: 335.8036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0861288 Vali Loss: 0.0821766 Test Loss: 0.0846017\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0847698\n",
      "\tspeed: 0.0335s/iter; left time: 659.6273s\n",
      "\titers: 200, epoch: 13 | loss: 0.0886499\n",
      "\tspeed: 0.0155s/iter; left time: 303.6435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0856551 Vali Loss: 0.0813699 Test Loss: 0.0850033\n",
      "Validation loss decreased (0.081950 --> 0.081370).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0837286\n",
      "\tspeed: 0.0344s/iter; left time: 669.7197s\n",
      "\titers: 200, epoch: 14 | loss: 0.0861768\n",
      "\tspeed: 0.0163s/iter; left time: 315.9275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0849992 Vali Loss: 0.0807958 Test Loss: 0.0844888\n",
      "Validation loss decreased (0.081370 --> 0.080796).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0842981\n",
      "\tspeed: 0.0323s/iter; left time: 620.8995s\n",
      "\titers: 200, epoch: 15 | loss: 0.0860519\n",
      "\tspeed: 0.0152s/iter; left time: 290.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0846049 Vali Loss: 0.0808427 Test Loss: 0.0845398\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0834388\n",
      "\tspeed: 0.0315s/iter; left time: 599.4554s\n",
      "\titers: 200, epoch: 16 | loss: 0.0891821\n",
      "\tspeed: 0.0158s/iter; left time: 299.3982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0842148 Vali Loss: 0.0807076 Test Loss: 0.0839392\n",
      "Validation loss decreased (0.080796 --> 0.080708).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0813520\n",
      "\tspeed: 0.0341s/iter; left time: 640.7734s\n",
      "\titers: 200, epoch: 17 | loss: 0.0820236\n",
      "\tspeed: 0.0158s/iter; left time: 295.8973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0841889 Vali Loss: 0.0807928 Test Loss: 0.0843021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0794783\n",
      "\tspeed: 0.0315s/iter; left time: 584.3165s\n",
      "\titers: 200, epoch: 18 | loss: 0.0819564\n",
      "\tspeed: 0.0150s/iter; left time: 277.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0837958 Vali Loss: 0.0800502 Test Loss: 0.0839954\n",
      "Validation loss decreased (0.080708 --> 0.080050).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0825035\n",
      "\tspeed: 0.0330s/iter; left time: 604.9470s\n",
      "\titers: 200, epoch: 19 | loss: 0.0834793\n",
      "\tspeed: 0.0156s/iter; left time: 284.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0833411 Vali Loss: 0.0804612 Test Loss: 0.0840887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0849448\n",
      "\tspeed: 0.0320s/iter; left time: 580.4257s\n",
      "\titers: 200, epoch: 20 | loss: 0.0859698\n",
      "\tspeed: 0.0160s/iter; left time: 289.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0833001 Vali Loss: 0.0801358 Test Loss: 0.0839652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0786478\n",
      "\tspeed: 0.0340s/iter; left time: 609.4255s\n",
      "\titers: 200, epoch: 21 | loss: 0.0870727\n",
      "\tspeed: 0.0189s/iter; left time: 336.6549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0831646 Vali Loss: 0.0799826 Test Loss: 0.0838264\n",
      "Validation loss decreased (0.080050 --> 0.079983).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0886545\n",
      "\tspeed: 0.0376s/iter; left time: 665.4101s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784292\n",
      "\tspeed: 0.0182s/iter; left time: 319.6706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0830313 Vali Loss: 0.0801070 Test Loss: 0.0838581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0820926\n",
      "\tspeed: 0.0332s/iter; left time: 578.8328s\n",
      "\titers: 200, epoch: 23 | loss: 0.0841963\n",
      "\tspeed: 0.0163s/iter; left time: 282.6336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0829299 Vali Loss: 0.0797106 Test Loss: 0.0837441\n",
      "Validation loss decreased (0.079983 --> 0.079711).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0813720\n",
      "\tspeed: 0.0337s/iter; left time: 580.5527s\n",
      "\titers: 200, epoch: 24 | loss: 0.0823814\n",
      "\tspeed: 0.0178s/iter; left time: 304.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0825387 Vali Loss: 0.0800385 Test Loss: 0.0841180\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0840227\n",
      "\tspeed: 0.0329s/iter; left time: 559.7043s\n",
      "\titers: 200, epoch: 25 | loss: 0.0792319\n",
      "\tspeed: 0.0180s/iter; left time: 304.6460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0825908 Vali Loss: 0.0795311 Test Loss: 0.0836701\n",
      "Validation loss decreased (0.079711 --> 0.079531).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0843800\n",
      "\tspeed: 0.0321s/iter; left time: 538.7035s\n",
      "\titers: 200, epoch: 26 | loss: 0.0830451\n",
      "\tspeed: 0.0152s/iter; left time: 253.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0825504 Vali Loss: 0.0797684 Test Loss: 0.0835431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0853239\n",
      "\tspeed: 0.0337s/iter; left time: 557.7382s\n",
      "\titers: 200, epoch: 27 | loss: 0.0819135\n",
      "\tspeed: 0.0178s/iter; left time: 292.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0823064 Vali Loss: 0.0796968 Test Loss: 0.0834956\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0836991\n",
      "\tspeed: 0.0340s/iter; left time: 554.6246s\n",
      "\titers: 200, epoch: 28 | loss: 0.0823716\n",
      "\tspeed: 0.0173s/iter; left time: 281.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0823479 Vali Loss: 0.0795949 Test Loss: 0.0834777\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0901566\n",
      "\tspeed: 0.0337s/iter; left time: 542.6435s\n",
      "\titers: 200, epoch: 29 | loss: 0.0815871\n",
      "\tspeed: 0.0180s/iter; left time: 287.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0822618 Vali Loss: 0.0793890 Test Loss: 0.0835268\n",
      "Validation loss decreased (0.079531 --> 0.079389).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0797134\n",
      "\tspeed: 0.0345s/iter; left time: 548.2422s\n",
      "\titers: 200, epoch: 30 | loss: 0.0839581\n",
      "\tspeed: 0.0160s/iter; left time: 252.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0822651 Vali Loss: 0.0798529 Test Loss: 0.0836726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0784735\n",
      "\tspeed: 0.0332s/iter; left time: 520.2067s\n",
      "\titers: 200, epoch: 31 | loss: 0.0858933\n",
      "\tspeed: 0.0160s/iter; left time: 248.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0821580 Vali Loss: 0.0797668 Test Loss: 0.0835013\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0843875\n",
      "\tspeed: 0.0352s/iter; left time: 543.4274s\n",
      "\titers: 200, epoch: 32 | loss: 0.0813760\n",
      "\tspeed: 0.0199s/iter; left time: 304.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0820451 Vali Loss: 0.0796548 Test Loss: 0.0835479\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0811357\n",
      "\tspeed: 0.0326s/iter; left time: 495.2098s\n",
      "\titers: 200, epoch: 33 | loss: 0.0862090\n",
      "\tspeed: 0.0151s/iter; left time: 228.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0819303 Vali Loss: 0.0795747 Test Loss: 0.0835437\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0850448\n",
      "\tspeed: 0.0318s/iter; left time: 476.1474s\n",
      "\titers: 200, epoch: 34 | loss: 0.0820336\n",
      "\tspeed: 0.0162s/iter; left time: 240.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0819054 Vali Loss: 0.0796066 Test Loss: 0.0836889\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0863909\n",
      "\tspeed: 0.0340s/iter; left time: 501.8651s\n",
      "\titers: 200, epoch: 35 | loss: 0.0772811\n",
      "\tspeed: 0.0188s/iter; left time: 275.7436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0818685 Vali Loss: 0.0795604 Test Loss: 0.0834159\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0811598\n",
      "\tspeed: 0.0343s/iter; left time: 497.7105s\n",
      "\titers: 200, epoch: 36 | loss: 0.0852249\n",
      "\tspeed: 0.0159s/iter; left time: 229.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0818304 Vali Loss: 0.0795000 Test Loss: 0.0835749\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0823470\n",
      "\tspeed: 0.0330s/iter; left time: 471.3904s\n",
      "\titers: 200, epoch: 37 | loss: 0.0786397\n",
      "\tspeed: 0.0129s/iter; left time: 182.7688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0818090 Vali Loss: 0.0792918 Test Loss: 0.0834800\n",
      "Validation loss decreased (0.079389 --> 0.079292).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0813787\n",
      "\tspeed: 0.0305s/iter; left time: 429.1995s\n",
      "\titers: 200, epoch: 38 | loss: 0.0800484\n",
      "\tspeed: 0.0155s/iter; left time: 217.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0817770 Vali Loss: 0.0793174 Test Loss: 0.0834549\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0846778\n",
      "\tspeed: 0.0314s/iter; left time: 434.5278s\n",
      "\titers: 200, epoch: 39 | loss: 0.0876444\n",
      "\tspeed: 0.0143s/iter; left time: 197.0363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0818475 Vali Loss: 0.0794521 Test Loss: 0.0833526\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0840096\n",
      "\tspeed: 0.0312s/iter; left time: 425.0502s\n",
      "\titers: 200, epoch: 40 | loss: 0.0797139\n",
      "\tspeed: 0.0138s/iter; left time: 186.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0818729 Vali Loss: 0.0792610 Test Loss: 0.0834639\n",
      "Validation loss decreased (0.079292 --> 0.079261).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0809445\n",
      "\tspeed: 0.0320s/iter; left time: 429.4419s\n",
      "\titers: 200, epoch: 41 | loss: 0.0835953\n",
      "\tspeed: 0.0162s/iter; left time: 215.7696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0817603 Vali Loss: 0.0793753 Test Loss: 0.0834233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0818785\n",
      "\tspeed: 0.0299s/iter; left time: 394.2577s\n",
      "\titers: 200, epoch: 42 | loss: 0.0793468\n",
      "\tspeed: 0.0134s/iter; left time: 175.2373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0819900 Vali Loss: 0.0794616 Test Loss: 0.0834463\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1099899\n",
      "\tspeed: 0.0310s/iter; left time: 400.9493s\n",
      "\titers: 200, epoch: 43 | loss: 0.0863156\n",
      "\tspeed: 0.0151s/iter; left time: 193.7663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0818719 Vali Loss: 0.0794408 Test Loss: 0.0834186\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0830130\n",
      "\tspeed: 0.0323s/iter; left time: 411.4115s\n",
      "\titers: 200, epoch: 44 | loss: 0.0839347\n",
      "\tspeed: 0.0165s/iter; left time: 208.6284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0817068 Vali Loss: 0.0794648 Test Loss: 0.0834181\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0816569\n",
      "\tspeed: 0.0345s/iter; left time: 431.1847s\n",
      "\titers: 200, epoch: 45 | loss: 0.0795054\n",
      "\tspeed: 0.0202s/iter; left time: 250.7269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0817080 Vali Loss: 0.0793059 Test Loss: 0.0834380\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0873833\n",
      "\tspeed: 0.0390s/iter; left time: 479.1947s\n",
      "\titers: 200, epoch: 46 | loss: 0.0815155\n",
      "\tspeed: 0.0204s/iter; left time: 247.8165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0816783 Vali Loss: 0.0794770 Test Loss: 0.0834538\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0832890\n",
      "\tspeed: 0.0357s/iter; left time: 429.6640s\n",
      "\titers: 200, epoch: 47 | loss: 0.0856036\n",
      "\tspeed: 0.0253s/iter; left time: 302.3401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.0817624 Vali Loss: 0.0793323 Test Loss: 0.0834635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0817167\n",
      "\tspeed: 0.0403s/iter; left time: 476.9329s\n",
      "\titers: 200, epoch: 48 | loss: 0.0815217\n",
      "\tspeed: 0.0191s/iter; left time: 223.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0818865 Vali Loss: 0.0792611 Test Loss: 0.0835811\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0825997\n",
      "\tspeed: 0.0336s/iter; left time: 389.4293s\n",
      "\titers: 200, epoch: 49 | loss: 0.0801011\n",
      "\tspeed: 0.0181s/iter; left time: 208.5030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0816532 Vali Loss: 0.0792115 Test Loss: 0.0833805\n",
      "Validation loss decreased (0.079261 --> 0.079212).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0815825\n",
      "\tspeed: 0.0373s/iter; left time: 424.2101s\n",
      "\titers: 200, epoch: 50 | loss: 0.0805301\n",
      "\tspeed: 0.0222s/iter; left time: 250.2353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 225 | Train Loss: 0.0819056 Vali Loss: 0.0794098 Test Loss: 0.0833791\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0823547\n",
      "\tspeed: 0.0388s/iter; left time: 432.2377s\n",
      "\titers: 200, epoch: 51 | loss: 0.0836692\n",
      "\tspeed: 0.0183s/iter; left time: 202.7276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0818337 Vali Loss: 0.0793652 Test Loss: 0.0833687\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0836443\n",
      "\tspeed: 0.0391s/iter; left time: 426.8916s\n",
      "\titers: 200, epoch: 52 | loss: 0.0822562\n",
      "\tspeed: 0.0214s/iter; left time: 232.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 225 | Train Loss: 0.0817083 Vali Loss: 0.0794672 Test Loss: 0.0835472\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0861320\n",
      "\tspeed: 0.0332s/iter; left time: 355.3428s\n",
      "\titers: 200, epoch: 53 | loss: 0.0794507\n",
      "\tspeed: 0.0209s/iter; left time: 221.4396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0817173 Vali Loss: 0.0793203 Test Loss: 0.0834329\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0831790\n",
      "\tspeed: 0.0318s/iter; left time: 333.2922s\n",
      "\titers: 200, epoch: 54 | loss: 0.0841627\n",
      "\tspeed: 0.0167s/iter; left time: 173.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0816611 Vali Loss: 0.0792993 Test Loss: 0.0834191\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0849556\n",
      "\tspeed: 0.0365s/iter; left time: 373.7607s\n",
      "\titers: 200, epoch: 55 | loss: 0.0824604\n",
      "\tspeed: 0.0200s/iter; left time: 203.3368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 225 | Train Loss: 0.0817934 Vali Loss: 0.0794798 Test Loss: 0.0834827\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0812058\n",
      "\tspeed: 0.0373s/iter; left time: 373.7917s\n",
      "\titers: 200, epoch: 56 | loss: 0.0791957\n",
      "\tspeed: 0.0189s/iter; left time: 187.5394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0818979 Vali Loss: 0.0792933 Test Loss: 0.0833512\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0799724\n",
      "\tspeed: 0.0389s/iter; left time: 380.9441s\n",
      "\titers: 200, epoch: 57 | loss: 0.0825712\n",
      "\tspeed: 0.0207s/iter; left time: 200.6459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0815750 Vali Loss: 0.0792557 Test Loss: 0.0833730\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0836057\n",
      "\tspeed: 0.0392s/iter; left time: 375.7318s\n",
      "\titers: 200, epoch: 58 | loss: 0.0862104\n",
      "\tspeed: 0.0203s/iter; left time: 192.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 225 | Train Loss: 0.0816147 Vali Loss: 0.0792267 Test Loss: 0.0833841\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0843756\n",
      "\tspeed: 0.0412s/iter; left time: 384.9438s\n",
      "\titers: 200, epoch: 59 | loss: 0.0816607\n",
      "\tspeed: 0.0220s/iter; left time: 203.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 225 | Train Loss: 0.0815761 Vali Loss: 0.0794703 Test Loss: 0.0834059\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01843404211103916, rmse:0.13577201962471008, mae:0.08338046818971634, rse:0.5133686661720276\n",
      "Intermediate time for IT and pred_len 96: 00h:08m:46.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2871464\n",
      "\tspeed: 0.0350s/iter; left time: 784.8044s\n",
      "\titers: 200, epoch: 1 | loss: 0.2552790\n",
      "\tspeed: 0.0118s/iter; left time: 262.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 225 | Train Loss: 0.2854011 Vali Loss: 0.1998132 Test Loss: 0.2056278\n",
      "Validation loss decreased (inf --> 0.199813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431440\n",
      "\tspeed: 0.0294s/iter; left time: 651.6778s\n",
      "\titers: 200, epoch: 2 | loss: 0.1307513\n",
      "\tspeed: 0.0150s/iter; left time: 330.5901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.1579776 Vali Loss: 0.1133125 Test Loss: 0.1184016\n",
      "Validation loss decreased (0.199813 --> 0.113313).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1170752\n",
      "\tspeed: 0.0313s/iter; left time: 687.0419s\n",
      "\titers: 200, epoch: 3 | loss: 0.1130971\n",
      "\tspeed: 0.0157s/iter; left time: 343.8582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.1175846 Vali Loss: 0.1013606 Test Loss: 0.1047844\n",
      "Validation loss decreased (0.113313 --> 0.101361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1119373\n",
      "\tspeed: 0.0353s/iter; left time: 767.0267s\n",
      "\titers: 200, epoch: 4 | loss: 0.1014683\n",
      "\tspeed: 0.0170s/iter; left time: 367.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.1058096 Vali Loss: 0.0938735 Test Loss: 0.0943376\n",
      "Validation loss decreased (0.101361 --> 0.093873).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0974286\n",
      "\tspeed: 0.0337s/iter; left time: 724.7678s\n",
      "\titers: 200, epoch: 5 | loss: 0.0965309\n",
      "\tspeed: 0.0170s/iter; left time: 362.9570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.1000301 Vali Loss: 0.0928358 Test Loss: 0.0944088\n",
      "Validation loss decreased (0.093873 --> 0.092836).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0954938\n",
      "\tspeed: 0.0337s/iter; left time: 716.1494s\n",
      "\titers: 200, epoch: 6 | loss: 0.0964621\n",
      "\tspeed: 0.0158s/iter; left time: 335.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0964602 Vali Loss: 0.0884258 Test Loss: 0.0906295\n",
      "Validation loss decreased (0.092836 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0978478\n",
      "\tspeed: 0.0326s/iter; left time: 686.2370s\n",
      "\titers: 200, epoch: 7 | loss: 0.0921040\n",
      "\tspeed: 0.0202s/iter; left time: 424.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0944398 Vali Loss: 0.0873658 Test Loss: 0.0898157\n",
      "Validation loss decreased (0.088426 --> 0.087366).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0869991\n",
      "\tspeed: 0.0334s/iter; left time: 695.3612s\n",
      "\titers: 200, epoch: 8 | loss: 0.0936323\n",
      "\tspeed: 0.0181s/iter; left time: 375.0768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0931402 Vali Loss: 0.0878391 Test Loss: 0.0891272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0928500\n",
      "\tspeed: 0.0331s/iter; left time: 682.1536s\n",
      "\titers: 200, epoch: 9 | loss: 0.0924792\n",
      "\tspeed: 0.0163s/iter; left time: 334.8110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0919907 Vali Loss: 0.0864041 Test Loss: 0.0892081\n",
      "Validation loss decreased (0.087366 --> 0.086404).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0924637\n",
      "\tspeed: 0.0359s/iter; left time: 730.5564s\n",
      "\titers: 200, epoch: 10 | loss: 0.0947547\n",
      "\tspeed: 0.0194s/iter; left time: 393.5467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0911751 Vali Loss: 0.0859731 Test Loss: 0.0885750\n",
      "Validation loss decreased (0.086404 --> 0.085973).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0918101\n",
      "\tspeed: 0.0373s/iter; left time: 752.2057s\n",
      "\titers: 200, epoch: 11 | loss: 0.0909410\n",
      "\tspeed: 0.0191s/iter; left time: 383.2827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0903794 Vali Loss: 0.0853820 Test Loss: 0.0884126\n",
      "Validation loss decreased (0.085973 --> 0.085382).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0880149\n",
      "\tspeed: 0.0341s/iter; left time: 678.9690s\n",
      "\titers: 200, epoch: 12 | loss: 0.0892051\n",
      "\tspeed: 0.0177s/iter; left time: 351.1211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0897380 Vali Loss: 0.0853620 Test Loss: 0.0886176\n",
      "Validation loss decreased (0.085382 --> 0.085362).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0866742\n",
      "\tspeed: 0.0351s/iter; left time: 692.4664s\n",
      "\titers: 200, epoch: 13 | loss: 0.0866411\n",
      "\tspeed: 0.0166s/iter; left time: 326.0934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.0890611 Vali Loss: 0.0852427 Test Loss: 0.0886245\n",
      "Validation loss decreased (0.085362 --> 0.085243).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0873050\n",
      "\tspeed: 0.0367s/iter; left time: 715.3164s\n",
      "\titers: 200, epoch: 14 | loss: 0.0878594\n",
      "\tspeed: 0.0190s/iter; left time: 367.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0886383 Vali Loss: 0.0850008 Test Loss: 0.0882895\n",
      "Validation loss decreased (0.085243 --> 0.085001).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0871279\n",
      "\tspeed: 0.0381s/iter; left time: 733.5587s\n",
      "\titers: 200, epoch: 15 | loss: 0.0854510\n",
      "\tspeed: 0.0187s/iter; left time: 358.7479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0881073 Vali Loss: 0.0858327 Test Loss: 0.0889315\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0884793\n",
      "\tspeed: 0.0378s/iter; left time: 719.8521s\n",
      "\titers: 200, epoch: 16 | loss: 0.0910140\n",
      "\tspeed: 0.0169s/iter; left time: 319.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0878829 Vali Loss: 0.0851838 Test Loss: 0.0881989\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0851787\n",
      "\tspeed: 0.0331s/iter; left time: 622.0127s\n",
      "\titers: 200, epoch: 17 | loss: 0.0884906\n",
      "\tspeed: 0.0160s/iter; left time: 299.6306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0876183 Vali Loss: 0.0851970 Test Loss: 0.0888068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0861608\n",
      "\tspeed: 0.0361s/iter; left time: 669.8588s\n",
      "\titers: 200, epoch: 18 | loss: 0.0879488\n",
      "\tspeed: 0.0199s/iter; left time: 368.1378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 225 | Train Loss: 0.0872039 Vali Loss: 0.0847646 Test Loss: 0.0885455\n",
      "Validation loss decreased (0.085001 --> 0.084765).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0841821\n",
      "\tspeed: 0.0339s/iter; left time: 622.7458s\n",
      "\titers: 200, epoch: 19 | loss: 0.0927313\n",
      "\tspeed: 0.0162s/iter; left time: 295.9263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0871038 Vali Loss: 0.0841301 Test Loss: 0.0879659\n",
      "Validation loss decreased (0.084765 --> 0.084130).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0864908\n",
      "\tspeed: 0.0349s/iter; left time: 632.3668s\n",
      "\titers: 200, epoch: 20 | loss: 0.0873407\n",
      "\tspeed: 0.0190s/iter; left time: 342.2039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0869607 Vali Loss: 0.0842529 Test Loss: 0.0880568\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0866177\n",
      "\tspeed: 0.0381s/iter; left time: 682.5803s\n",
      "\titers: 200, epoch: 21 | loss: 0.0867517\n",
      "\tspeed: 0.0203s/iter; left time: 360.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 225 | Train Loss: 0.0868113 Vali Loss: 0.0843626 Test Loss: 0.0878616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0879350\n",
      "\tspeed: 0.0384s/iter; left time: 679.3041s\n",
      "\titers: 200, epoch: 22 | loss: 0.0870513\n",
      "\tspeed: 0.0211s/iter; left time: 369.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0864764 Vali Loss: 0.0842002 Test Loss: 0.0879332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0858359\n",
      "\tspeed: 0.0348s/iter; left time: 606.6333s\n",
      "\titers: 200, epoch: 23 | loss: 0.0851808\n",
      "\tspeed: 0.0181s/iter; left time: 314.3908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0864841 Vali Loss: 0.0842316 Test Loss: 0.0881075\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0861321\n",
      "\tspeed: 0.0339s/iter; left time: 583.2187s\n",
      "\titers: 200, epoch: 24 | loss: 0.0962015\n",
      "\tspeed: 0.0183s/iter; left time: 313.5735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0864967 Vali Loss: 0.0848464 Test Loss: 0.0883762\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0878875\n",
      "\tspeed: 0.0339s/iter; left time: 576.0413s\n",
      "\titers: 200, epoch: 25 | loss: 0.0865147\n",
      "\tspeed: 0.0215s/iter; left time: 362.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0863466 Vali Loss: 0.0841036 Test Loss: 0.0880151\n",
      "Validation loss decreased (0.084130 --> 0.084104).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0824846\n",
      "\tspeed: 0.0333s/iter; left time: 559.0410s\n",
      "\titers: 200, epoch: 26 | loss: 0.0877685\n",
      "\tspeed: 0.0165s/iter; left time: 274.5133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0861868 Vali Loss: 0.0843329 Test Loss: 0.0881836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0860167\n",
      "\tspeed: 0.0338s/iter; left time: 559.1916s\n",
      "\titers: 200, epoch: 27 | loss: 0.0872357\n",
      "\tspeed: 0.0185s/iter; left time: 304.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0861339 Vali Loss: 0.0842179 Test Loss: 0.0879376\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0890730\n",
      "\tspeed: 0.0349s/iter; left time: 569.0543s\n",
      "\titers: 200, epoch: 28 | loss: 0.0879922\n",
      "\tspeed: 0.0209s/iter; left time: 339.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0859794 Vali Loss: 0.0840635 Test Loss: 0.0877377\n",
      "Validation loss decreased (0.084104 --> 0.084064).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0911478\n",
      "\tspeed: 0.0341s/iter; left time: 548.3408s\n",
      "\titers: 200, epoch: 29 | loss: 0.0832314\n",
      "\tspeed: 0.0181s/iter; left time: 290.2558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 225 | Train Loss: 0.0859579 Vali Loss: 0.0840073 Test Loss: 0.0878611\n",
      "Validation loss decreased (0.084064 --> 0.084007).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0865786\n",
      "\tspeed: 0.0390s/iter; left time: 619.8198s\n",
      "\titers: 200, epoch: 30 | loss: 0.0882897\n",
      "\tspeed: 0.0203s/iter; left time: 320.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0859757 Vali Loss: 0.0840215 Test Loss: 0.0875936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0837739\n",
      "\tspeed: 0.0378s/iter; left time: 591.3445s\n",
      "\titers: 200, epoch: 31 | loss: 0.0823950\n",
      "\tspeed: 0.0160s/iter; left time: 248.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0860808 Vali Loss: 0.0840814 Test Loss: 0.0878295\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0830447\n",
      "\tspeed: 0.0393s/iter; left time: 605.8139s\n",
      "\titers: 200, epoch: 32 | loss: 0.0859739\n",
      "\tspeed: 0.0205s/iter; left time: 314.8236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0863978 Vali Loss: 0.0840468 Test Loss: 0.0878614\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0895207\n",
      "\tspeed: 0.0366s/iter; left time: 556.4685s\n",
      "\titers: 200, epoch: 33 | loss: 0.0877355\n",
      "\tspeed: 0.0185s/iter; left time: 278.7051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0858421 Vali Loss: 0.0839666 Test Loss: 0.0877551\n",
      "Validation loss decreased (0.084007 --> 0.083967).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0866324\n",
      "\tspeed: 0.0325s/iter; left time: 486.0566s\n",
      "\titers: 200, epoch: 34 | loss: 0.0839846\n",
      "\tspeed: 0.0154s/iter; left time: 229.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0857940 Vali Loss: 0.0839135 Test Loss: 0.0877007\n",
      "Validation loss decreased (0.083967 --> 0.083914).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0840788\n",
      "\tspeed: 0.0379s/iter; left time: 559.0763s\n",
      "\titers: 200, epoch: 35 | loss: 0.0875866\n",
      "\tspeed: 0.0195s/iter; left time: 286.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0858123 Vali Loss: 0.0842424 Test Loss: 0.0877640\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0867140\n",
      "\tspeed: 0.0369s/iter; left time: 536.6394s\n",
      "\titers: 200, epoch: 36 | loss: 0.0856331\n",
      "\tspeed: 0.0191s/iter; left time: 275.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 225 | Train Loss: 0.0859275 Vali Loss: 0.0840178 Test Loss: 0.0876656\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0900123\n",
      "\tspeed: 0.0394s/iter; left time: 563.3746s\n",
      "\titers: 200, epoch: 37 | loss: 0.0830691\n",
      "\tspeed: 0.0182s/iter; left time: 258.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0857823 Vali Loss: 0.0838440 Test Loss: 0.0878202\n",
      "Validation loss decreased (0.083914 --> 0.083844).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0872962\n",
      "\tspeed: 0.0318s/iter; left time: 447.0716s\n",
      "\titers: 200, epoch: 38 | loss: 0.0843079\n",
      "\tspeed: 0.0169s/iter; left time: 236.0514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0856478 Vali Loss: 0.0842055 Test Loss: 0.0877056\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0836912\n",
      "\tspeed: 0.0380s/iter; left time: 526.5336s\n",
      "\titers: 200, epoch: 39 | loss: 0.0842630\n",
      "\tspeed: 0.0218s/iter; left time: 299.1031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0857615 Vali Loss: 0.0839735 Test Loss: 0.0878095\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0847262\n",
      "\tspeed: 0.0333s/iter; left time: 453.3733s\n",
      "\titers: 200, epoch: 40 | loss: 0.0846217\n",
      "\tspeed: 0.0164s/iter; left time: 221.3080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0855740 Vali Loss: 0.0839487 Test Loss: 0.0876373\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0832063\n",
      "\tspeed: 0.0370s/iter; left time: 495.7891s\n",
      "\titers: 200, epoch: 41 | loss: 0.0881097\n",
      "\tspeed: 0.0198s/iter; left time: 263.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 225 | Train Loss: 0.0855960 Vali Loss: 0.0839609 Test Loss: 0.0877863\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0827914\n",
      "\tspeed: 0.0354s/iter; left time: 466.6708s\n",
      "\titers: 200, epoch: 42 | loss: 0.0866479\n",
      "\tspeed: 0.0176s/iter; left time: 230.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0856862 Vali Loss: 0.0838571 Test Loss: 0.0877914\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0855684\n",
      "\tspeed: 0.0334s/iter; left time: 432.9205s\n",
      "\titers: 200, epoch: 43 | loss: 0.0898735\n",
      "\tspeed: 0.0217s/iter; left time: 278.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0857198 Vali Loss: 0.0840194 Test Loss: 0.0876936\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0840490\n",
      "\tspeed: 0.0348s/iter; left time: 443.0039s\n",
      "\titers: 200, epoch: 44 | loss: 0.0835335\n",
      "\tspeed: 0.0163s/iter; left time: 205.6175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0856540 Vali Loss: 0.0838441 Test Loss: 0.0877947\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0838612\n",
      "\tspeed: 0.0331s/iter; left time: 413.8472s\n",
      "\titers: 200, epoch: 45 | loss: 0.0866728\n",
      "\tspeed: 0.0170s/iter; left time: 210.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0855881 Vali Loss: 0.0840154 Test Loss: 0.0877012\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0848497\n",
      "\tspeed: 0.0335s/iter; left time: 411.6408s\n",
      "\titers: 200, epoch: 46 | loss: 0.0840844\n",
      "\tspeed: 0.0165s/iter; left time: 200.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0857706 Vali Loss: 0.0837818 Test Loss: 0.0878212\n",
      "Validation loss decreased (0.083844 --> 0.083782).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0809108\n",
      "\tspeed: 0.0323s/iter; left time: 389.2313s\n",
      "\titers: 200, epoch: 47 | loss: 0.0876100\n",
      "\tspeed: 0.0213s/iter; left time: 254.1294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0855649 Vali Loss: 0.0838934 Test Loss: 0.0876507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0854100\n",
      "\tspeed: 0.0345s/iter; left time: 408.0850s\n",
      "\titers: 200, epoch: 48 | loss: 0.0830703\n",
      "\tspeed: 0.0165s/iter; left time: 193.9145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0854888 Vali Loss: 0.0837947 Test Loss: 0.0877474\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0881180\n",
      "\tspeed: 0.0329s/iter; left time: 381.6648s\n",
      "\titers: 200, epoch: 49 | loss: 0.0825081\n",
      "\tspeed: 0.0162s/iter; left time: 186.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0855913 Vali Loss: 0.0839997 Test Loss: 0.0876720\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0842309\n",
      "\tspeed: 0.0336s/iter; left time: 382.2480s\n",
      "\titers: 200, epoch: 50 | loss: 0.0896637\n",
      "\tspeed: 0.0170s/iter; left time: 191.4956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0855575 Vali Loss: 0.0836746 Test Loss: 0.0876439\n",
      "Validation loss decreased (0.083782 --> 0.083675).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0803221\n",
      "\tspeed: 0.0328s/iter; left time: 365.8281s\n",
      "\titers: 200, epoch: 51 | loss: 0.0852165\n",
      "\tspeed: 0.0166s/iter; left time: 183.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0857192 Vali Loss: 0.0838952 Test Loss: 0.0876832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0891636\n",
      "\tspeed: 0.0323s/iter; left time: 352.7288s\n",
      "\titers: 200, epoch: 52 | loss: 0.0858402\n",
      "\tspeed: 0.0155s/iter; left time: 168.0515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0855586 Vali Loss: 0.0839647 Test Loss: 0.0877191\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0857720\n",
      "\tspeed: 0.0358s/iter; left time: 382.6640s\n",
      "\titers: 200, epoch: 53 | loss: 0.0827048\n",
      "\tspeed: 0.0196s/iter; left time: 207.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0854881 Vali Loss: 0.0838258 Test Loss: 0.0876724\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0894596\n",
      "\tspeed: 0.0329s/iter; left time: 344.6078s\n",
      "\titers: 200, epoch: 54 | loss: 0.0887103\n",
      "\tspeed: 0.0158s/iter; left time: 163.4961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0856003 Vali Loss: 0.0839257 Test Loss: 0.0877173\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0881316\n",
      "\tspeed: 0.0338s/iter; left time: 346.4570s\n",
      "\titers: 200, epoch: 55 | loss: 0.0862180\n",
      "\tspeed: 0.0159s/iter; left time: 161.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0855120 Vali Loss: 0.0838650 Test Loss: 0.0877261\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0841388\n",
      "\tspeed: 0.0334s/iter; left time: 334.6769s\n",
      "\titers: 200, epoch: 56 | loss: 0.0869091\n",
      "\tspeed: 0.0181s/iter; left time: 179.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0856856 Vali Loss: 0.0836929 Test Loss: 0.0878890\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0832032\n",
      "\tspeed: 0.0355s/iter; left time: 348.0622s\n",
      "\titers: 200, epoch: 57 | loss: 0.0826762\n",
      "\tspeed: 0.0178s/iter; left time: 173.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0856178 Vali Loss: 0.0839305 Test Loss: 0.0877205\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0862195\n",
      "\tspeed: 0.0341s/iter; left time: 326.8623s\n",
      "\titers: 200, epoch: 58 | loss: 0.0849153\n",
      "\tspeed: 0.0173s/iter; left time: 163.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0855426 Vali Loss: 0.0836311 Test Loss: 0.0877388\n",
      "Validation loss decreased (0.083675 --> 0.083631).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0874458\n",
      "\tspeed: 0.0337s/iter; left time: 315.5775s\n",
      "\titers: 200, epoch: 59 | loss: 0.0856677\n",
      "\tspeed: 0.0152s/iter; left time: 140.8290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0854076 Vali Loss: 0.0837660 Test Loss: 0.0877864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0862853\n",
      "\tspeed: 0.0383s/iter; left time: 349.1669s\n",
      "\titers: 200, epoch: 60 | loss: 0.0846376\n",
      "\tspeed: 0.0202s/iter; left time: 182.4430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 225 | Train Loss: 0.0855039 Vali Loss: 0.0839287 Test Loss: 0.0877160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0831357\n",
      "\tspeed: 0.0380s/iter; left time: 338.5553s\n",
      "\titers: 200, epoch: 61 | loss: 0.0843221\n",
      "\tspeed: 0.0216s/iter; left time: 189.9404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0854917 Vali Loss: 0.0837465 Test Loss: 0.0877291\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0863590\n",
      "\tspeed: 0.0384s/iter; left time: 332.7523s\n",
      "\titers: 200, epoch: 62 | loss: 0.0844525\n",
      "\tspeed: 0.0200s/iter; left time: 171.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0855115 Vali Loss: 0.0839486 Test Loss: 0.0877433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0835522\n",
      "\tspeed: 0.0345s/iter; left time: 291.3142s\n",
      "\titers: 200, epoch: 63 | loss: 0.0858202\n",
      "\tspeed: 0.0175s/iter; left time: 146.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0854575 Vali Loss: 0.0838609 Test Loss: 0.0876994\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0863423\n",
      "\tspeed: 0.0367s/iter; left time: 301.7965s\n",
      "\titers: 200, epoch: 64 | loss: 0.0882498\n",
      "\tspeed: 0.0192s/iter; left time: 155.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0853901 Vali Loss: 0.0837660 Test Loss: 0.0876815\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0795603\n",
      "\tspeed: 0.0342s/iter; left time: 273.4767s\n",
      "\titers: 200, epoch: 65 | loss: 0.0861610\n",
      "\tspeed: 0.0159s/iter; left time: 125.6800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0854072 Vali Loss: 0.0837482 Test Loss: 0.0877235\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0849181\n",
      "\tspeed: 0.0373s/iter; left time: 290.0356s\n",
      "\titers: 200, epoch: 66 | loss: 0.0865337\n",
      "\tspeed: 0.0176s/iter; left time: 135.3886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 225 | Train Loss: 0.0855410 Vali Loss: 0.0837984 Test Loss: 0.0877984\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0806636\n",
      "\tspeed: 0.0382s/iter; left time: 288.8172s\n",
      "\titers: 200, epoch: 67 | loss: 0.0847101\n",
      "\tspeed: 0.0201s/iter; left time: 149.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0854205 Vali Loss: 0.0839564 Test Loss: 0.0877346\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0891916\n",
      "\tspeed: 0.0342s/iter; left time: 250.2153s\n",
      "\titers: 200, epoch: 68 | loss: 0.0856488\n",
      "\tspeed: 0.0191s/iter; left time: 138.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0855271 Vali Loss: 0.0839384 Test Loss: 0.0878300\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01985144428908825, rmse:0.14089515805244446, mae:0.08773878216743469, rse:0.5332347750663757\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2811901\n",
      "\tspeed: 0.0192s/iter; left time: 430.7573s\n",
      "\titers: 200, epoch: 1 | loss: 0.2555557\n",
      "\tspeed: 0.0160s/iter; left time: 355.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.2855597 Vali Loss: 0.2034866 Test Loss: 0.2095738\n",
      "Validation loss decreased (inf --> 0.203487).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1407049\n",
      "\tspeed: 0.0329s/iter; left time: 730.2627s\n",
      "\titers: 200, epoch: 2 | loss: 0.1255486\n",
      "\tspeed: 0.0098s/iter; left time: 217.3034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 225 | Train Loss: 0.1563358 Vali Loss: 0.1131076 Test Loss: 0.1202545\n",
      "Validation loss decreased (0.203487 --> 0.113108).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1179366\n",
      "\tspeed: 0.0346s/iter; left time: 759.7440s\n",
      "\titers: 200, epoch: 3 | loss: 0.1155250\n",
      "\tspeed: 0.0149s/iter; left time: 325.6192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.1178324 Vali Loss: 0.1009700 Test Loss: 0.1035364\n",
      "Validation loss decreased (0.113108 --> 0.100970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1069622\n",
      "\tspeed: 0.0381s/iter; left time: 826.9655s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056391\n",
      "\tspeed: 0.0190s/iter; left time: 410.1421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.1062726 Vali Loss: 0.0952413 Test Loss: 0.0965261\n",
      "Validation loss decreased (0.100970 --> 0.095241).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0975991\n",
      "\tspeed: 0.0334s/iter; left time: 717.6973s\n",
      "\titers: 200, epoch: 5 | loss: 0.1003618\n",
      "\tspeed: 0.0152s/iter; left time: 324.4944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.1005352 Vali Loss: 0.0913371 Test Loss: 0.0940908\n",
      "Validation loss decreased (0.095241 --> 0.091337).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0990696\n",
      "\tspeed: 0.0373s/iter; left time: 793.5207s\n",
      "\titers: 200, epoch: 6 | loss: 0.1006796\n",
      "\tspeed: 0.0189s/iter; left time: 399.8170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0975591 Vali Loss: 0.0896493 Test Loss: 0.0929677\n",
      "Validation loss decreased (0.091337 --> 0.089649).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0946059\n",
      "\tspeed: 0.0359s/iter; left time: 756.2554s\n",
      "\titers: 200, epoch: 7 | loss: 0.0987749\n",
      "\tspeed: 0.0175s/iter; left time: 366.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0952434 Vali Loss: 0.0885789 Test Loss: 0.0906260\n",
      "Validation loss decreased (0.089649 --> 0.088579).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0912916\n",
      "\tspeed: 0.0315s/iter; left time: 654.9935s\n",
      "\titers: 200, epoch: 8 | loss: 0.0941708\n",
      "\tspeed: 0.0135s/iter; left time: 279.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0937680 Vali Loss: 0.0880198 Test Loss: 0.0900427\n",
      "Validation loss decreased (0.088579 --> 0.088020).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0892983\n",
      "\tspeed: 0.0314s/iter; left time: 647.8609s\n",
      "\titers: 200, epoch: 9 | loss: 0.0933996\n",
      "\tspeed: 0.0128s/iter; left time: 262.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0926713 Vali Loss: 0.0868229 Test Loss: 0.0900808\n",
      "Validation loss decreased (0.088020 --> 0.086823).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0906593\n",
      "\tspeed: 0.0340s/iter; left time: 693.3928s\n",
      "\titers: 200, epoch: 10 | loss: 0.0939311\n",
      "\tspeed: 0.0168s/iter; left time: 339.9877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0914059 Vali Loss: 0.0864519 Test Loss: 0.0892728\n",
      "Validation loss decreased (0.086823 --> 0.086452).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0897200\n",
      "\tspeed: 0.0346s/iter; left time: 696.5937s\n",
      "\titers: 200, epoch: 11 | loss: 0.0882291\n",
      "\tspeed: 0.0163s/iter; left time: 326.2275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0904506 Vali Loss: 0.0862451 Test Loss: 0.0891356\n",
      "Validation loss decreased (0.086452 --> 0.086245).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0927711\n",
      "\tspeed: 0.0286s/iter; left time: 569.8227s\n",
      "\titers: 200, epoch: 12 | loss: 0.0938112\n",
      "\tspeed: 0.0172s/iter; left time: 341.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0897738 Vali Loss: 0.0862953 Test Loss: 0.0888204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893305\n",
      "\tspeed: 0.0340s/iter; left time: 669.1768s\n",
      "\titers: 200, epoch: 13 | loss: 0.0923870\n",
      "\tspeed: 0.0182s/iter; left time: 357.6593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0891380 Vali Loss: 0.0859750 Test Loss: 0.0888117\n",
      "Validation loss decreased (0.086245 --> 0.085975).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0903896\n",
      "\tspeed: 0.0324s/iter; left time: 631.5628s\n",
      "\titers: 200, epoch: 14 | loss: 0.0873978\n",
      "\tspeed: 0.0175s/iter; left time: 338.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0887752 Vali Loss: 0.0853476 Test Loss: 0.0883505\n",
      "Validation loss decreased (0.085975 --> 0.085348).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0904353\n",
      "\tspeed: 0.0340s/iter; left time: 654.3193s\n",
      "\titers: 200, epoch: 15 | loss: 0.0884306\n",
      "\tspeed: 0.0133s/iter; left time: 254.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0883704 Vali Loss: 0.0849287 Test Loss: 0.0884772\n",
      "Validation loss decreased (0.085348 --> 0.084929).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865225\n",
      "\tspeed: 0.0329s/iter; left time: 626.6952s\n",
      "\titers: 200, epoch: 16 | loss: 0.0862006\n",
      "\tspeed: 0.0143s/iter; left time: 271.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0879999 Vali Loss: 0.0850746 Test Loss: 0.0880633\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0891528\n",
      "\tspeed: 0.0344s/iter; left time: 646.5989s\n",
      "\titers: 200, epoch: 17 | loss: 0.0878572\n",
      "\tspeed: 0.0145s/iter; left time: 270.6813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0878672 Vali Loss: 0.0847102 Test Loss: 0.0881083\n",
      "Validation loss decreased (0.084929 --> 0.084710).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0881433\n",
      "\tspeed: 0.0347s/iter; left time: 643.9944s\n",
      "\titers: 200, epoch: 18 | loss: 0.0901565\n",
      "\tspeed: 0.0159s/iter; left time: 294.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0874882 Vali Loss: 0.0848959 Test Loss: 0.0880535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0862640\n",
      "\tspeed: 0.0297s/iter; left time: 545.4961s\n",
      "\titers: 200, epoch: 19 | loss: 0.0926718\n",
      "\tspeed: 0.0173s/iter; left time: 316.0817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0874914 Vali Loss: 0.0846168 Test Loss: 0.0882703\n",
      "Validation loss decreased (0.084710 --> 0.084617).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0858740\n",
      "\tspeed: 0.0378s/iter; left time: 685.6659s\n",
      "\titers: 200, epoch: 20 | loss: 0.0878472\n",
      "\tspeed: 0.0158s/iter; left time: 284.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0871674 Vali Loss: 0.0845910 Test Loss: 0.0877174\n",
      "Validation loss decreased (0.084617 --> 0.084591).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0822908\n",
      "\tspeed: 0.0355s/iter; left time: 634.8406s\n",
      "\titers: 200, epoch: 21 | loss: 0.0888437\n",
      "\tspeed: 0.0179s/iter; left time: 318.0568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0869461 Vali Loss: 0.0846306 Test Loss: 0.0877483\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0889016\n",
      "\tspeed: 0.0346s/iter; left time: 611.6671s\n",
      "\titers: 200, epoch: 22 | loss: 0.0853360\n",
      "\tspeed: 0.0163s/iter; left time: 286.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0868771 Vali Loss: 0.0845347 Test Loss: 0.0878567\n",
      "Validation loss decreased (0.084591 --> 0.084535).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0878374\n",
      "\tspeed: 0.0355s/iter; left time: 620.3362s\n",
      "\titers: 200, epoch: 23 | loss: 0.0857313\n",
      "\tspeed: 0.0186s/iter; left time: 323.4378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0867781 Vali Loss: 0.0845471 Test Loss: 0.0879436\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0893482\n",
      "\tspeed: 0.0302s/iter; left time: 519.4805s\n",
      "\titers: 200, epoch: 24 | loss: 0.0847237\n",
      "\tspeed: 0.0102s/iter; left time: 174.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 225 | Train Loss: 0.0868089 Vali Loss: 0.0843728 Test Loss: 0.0877755\n",
      "Validation loss decreased (0.084535 --> 0.084373).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0856335\n",
      "\tspeed: 0.0328s/iter; left time: 558.1006s\n",
      "\titers: 200, epoch: 25 | loss: 0.0884197\n",
      "\tspeed: 0.0144s/iter; left time: 243.7999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0866318 Vali Loss: 0.0844467 Test Loss: 0.0877618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0915473\n",
      "\tspeed: 0.0340s/iter; left time: 570.9848s\n",
      "\titers: 200, epoch: 26 | loss: 0.0861925\n",
      "\tspeed: 0.0156s/iter; left time: 259.8701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0864816 Vali Loss: 0.0843100 Test Loss: 0.0880293\n",
      "Validation loss decreased (0.084373 --> 0.084310).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0888533\n",
      "\tspeed: 0.0332s/iter; left time: 548.8214s\n",
      "\titers: 200, epoch: 27 | loss: 0.0828652\n",
      "\tspeed: 0.0159s/iter; left time: 261.2533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0864010 Vali Loss: 0.0840675 Test Loss: 0.0878859\n",
      "Validation loss decreased (0.084310 --> 0.084068).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0866069\n",
      "\tspeed: 0.0335s/iter; left time: 546.6210s\n",
      "\titers: 200, epoch: 28 | loss: 0.0846799\n",
      "\tspeed: 0.0151s/iter; left time: 245.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0863566 Vali Loss: 0.0841139 Test Loss: 0.0878939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0864667\n",
      "\tspeed: 0.0320s/iter; left time: 515.8490s\n",
      "\titers: 200, epoch: 29 | loss: 0.0849992\n",
      "\tspeed: 0.0153s/iter; left time: 244.6983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0861578 Vali Loss: 0.0842914 Test Loss: 0.0877159\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0887233\n",
      "\tspeed: 0.0317s/iter; left time: 502.5355s\n",
      "\titers: 200, epoch: 30 | loss: 0.0850501\n",
      "\tspeed: 0.0174s/iter; left time: 274.3911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0861103 Vali Loss: 0.0840877 Test Loss: 0.0877250\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0850813\n",
      "\tspeed: 0.0367s/iter; left time: 574.6106s\n",
      "\titers: 200, epoch: 31 | loss: 0.0864127\n",
      "\tspeed: 0.0118s/iter; left time: 183.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0861136 Vali Loss: 0.0841656 Test Loss: 0.0876141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0869038\n",
      "\tspeed: 0.0286s/iter; left time: 440.7895s\n",
      "\titers: 200, epoch: 32 | loss: 0.0882633\n",
      "\tspeed: 0.0111s/iter; left time: 169.6003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 225 | Train Loss: 0.0860620 Vali Loss: 0.0840440 Test Loss: 0.0875890\n",
      "Validation loss decreased (0.084068 --> 0.084044).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0830199\n",
      "\tspeed: 0.0288s/iter; left time: 437.8174s\n",
      "\titers: 200, epoch: 33 | loss: 0.0820900\n",
      "\tspeed: 0.0125s/iter; left time: 189.3045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 225 | Train Loss: 0.0860683 Vali Loss: 0.0840771 Test Loss: 0.0877418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0851234\n",
      "\tspeed: 0.0361s/iter; left time: 540.5820s\n",
      "\titers: 200, epoch: 34 | loss: 0.0869063\n",
      "\tspeed: 0.0162s/iter; left time: 241.0766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0860582 Vali Loss: 0.0841589 Test Loss: 0.0876531\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0853247\n",
      "\tspeed: 0.0328s/iter; left time: 484.3153s\n",
      "\titers: 200, epoch: 35 | loss: 0.0821250\n",
      "\tspeed: 0.0189s/iter; left time: 277.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.0859170 Vali Loss: 0.0837935 Test Loss: 0.0877555\n",
      "Validation loss decreased (0.084044 --> 0.083794).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0848440\n",
      "\tspeed: 0.0339s/iter; left time: 492.5746s\n",
      "\titers: 200, epoch: 36 | loss: 0.0825796\n",
      "\tspeed: 0.0155s/iter; left time: 224.2212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.0859620 Vali Loss: 0.0839452 Test Loss: 0.0875413\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0834437\n",
      "\tspeed: 0.0362s/iter; left time: 517.5947s\n",
      "\titers: 200, epoch: 37 | loss: 0.0914393\n",
      "\tspeed: 0.0175s/iter; left time: 249.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0858014 Vali Loss: 0.0838901 Test Loss: 0.0875761\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0870592\n",
      "\tspeed: 0.0320s/iter; left time: 450.5334s\n",
      "\titers: 200, epoch: 38 | loss: 0.0849523\n",
      "\tspeed: 0.0171s/iter; left time: 238.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0857765 Vali Loss: 0.0838603 Test Loss: 0.0876727\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0813147\n",
      "\tspeed: 0.0289s/iter; left time: 400.1122s\n",
      "\titers: 200, epoch: 39 | loss: 0.0890005\n",
      "\tspeed: 0.0157s/iter; left time: 216.0689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0859399 Vali Loss: 0.0838971 Test Loss: 0.0876239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0830819\n",
      "\tspeed: 0.0314s/iter; left time: 427.4216s\n",
      "\titers: 200, epoch: 40 | loss: 0.0856972\n",
      "\tspeed: 0.0138s/iter; left time: 186.1187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0860559 Vali Loss: 0.0839531 Test Loss: 0.0874863\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0860740\n",
      "\tspeed: 0.0336s/iter; left time: 450.3678s\n",
      "\titers: 200, epoch: 41 | loss: 0.0863928\n",
      "\tspeed: 0.0162s/iter; left time: 215.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0858800 Vali Loss: 0.0839168 Test Loss: 0.0875721\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0892703\n",
      "\tspeed: 0.0320s/iter; left time: 422.1587s\n",
      "\titers: 200, epoch: 42 | loss: 0.0883598\n",
      "\tspeed: 0.0166s/iter; left time: 217.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0857964 Vali Loss: 0.0837697 Test Loss: 0.0875823\n",
      "Validation loss decreased (0.083794 --> 0.083770).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0879114\n",
      "\tspeed: 0.0348s/iter; left time: 450.2445s\n",
      "\titers: 200, epoch: 43 | loss: 0.0877481\n",
      "\tspeed: 0.0163s/iter; left time: 208.9116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0858649 Vali Loss: 0.0837876 Test Loss: 0.0874805\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0840065\n",
      "\tspeed: 0.0318s/iter; left time: 405.0638s\n",
      "\titers: 200, epoch: 44 | loss: 0.0844992\n",
      "\tspeed: 0.0149s/iter; left time: 187.8384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0858228 Vali Loss: 0.0838888 Test Loss: 0.0876042\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0876887\n",
      "\tspeed: 0.0343s/iter; left time: 428.3675s\n",
      "\titers: 200, epoch: 45 | loss: 0.0862209\n",
      "\tspeed: 0.0160s/iter; left time: 198.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0858926 Vali Loss: 0.0838959 Test Loss: 0.0875133\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0850273\n",
      "\tspeed: 0.0324s/iter; left time: 398.2815s\n",
      "\titers: 200, epoch: 46 | loss: 0.0850483\n",
      "\tspeed: 0.0154s/iter; left time: 186.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0857520 Vali Loss: 0.0840085 Test Loss: 0.0876112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0873501\n",
      "\tspeed: 0.0315s/iter; left time: 379.6881s\n",
      "\titers: 200, epoch: 47 | loss: 0.0857628\n",
      "\tspeed: 0.0156s/iter; left time: 186.6653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0856933 Vali Loss: 0.0840146 Test Loss: 0.0875916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0866789\n",
      "\tspeed: 0.0323s/iter; left time: 381.4637s\n",
      "\titers: 200, epoch: 48 | loss: 0.0857183\n",
      "\tspeed: 0.0136s/iter; left time: 159.4248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0858344 Vali Loss: 0.0838272 Test Loss: 0.0874924\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0856871\n",
      "\tspeed: 0.0306s/iter; left time: 355.1994s\n",
      "\titers: 200, epoch: 49 | loss: 0.0848251\n",
      "\tspeed: 0.0133s/iter; left time: 152.5324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 225 | Train Loss: 0.0857752 Vali Loss: 0.0838986 Test Loss: 0.0874747\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0884241\n",
      "\tspeed: 0.0319s/iter; left time: 362.6406s\n",
      "\titers: 200, epoch: 50 | loss: 0.0847695\n",
      "\tspeed: 0.0155s/iter; left time: 174.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0856900 Vali Loss: 0.0837343 Test Loss: 0.0876015\n",
      "Validation loss decreased (0.083770 --> 0.083734).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0916913\n",
      "\tspeed: 0.0304s/iter; left time: 339.0639s\n",
      "\titers: 200, epoch: 51 | loss: 0.0854367\n",
      "\tspeed: 0.0138s/iter; left time: 152.2391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0857145 Vali Loss: 0.0839531 Test Loss: 0.0874348\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0813114\n",
      "\tspeed: 0.0313s/iter; left time: 341.4976s\n",
      "\titers: 200, epoch: 52 | loss: 0.0878581\n",
      "\tspeed: 0.0141s/iter; left time: 152.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0857817 Vali Loss: 0.0840421 Test Loss: 0.0875262\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0855496\n",
      "\tspeed: 0.0313s/iter; left time: 335.2605s\n",
      "\titers: 200, epoch: 53 | loss: 0.0854577\n",
      "\tspeed: 0.0156s/iter; left time: 165.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0858797 Vali Loss: 0.0838894 Test Loss: 0.0875471\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0848776\n",
      "\tspeed: 0.0323s/iter; left time: 338.4287s\n",
      "\titers: 200, epoch: 54 | loss: 0.0854730\n",
      "\tspeed: 0.0152s/iter; left time: 158.1405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0855863 Vali Loss: 0.0837929 Test Loss: 0.0875680\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0851004\n",
      "\tspeed: 0.0324s/iter; left time: 332.6410s\n",
      "\titers: 200, epoch: 55 | loss: 0.0866423\n",
      "\tspeed: 0.0160s/iter; left time: 162.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0856860 Vali Loss: 0.0839773 Test Loss: 0.0875212\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0851850\n",
      "\tspeed: 0.0322s/iter; left time: 322.8402s\n",
      "\titers: 200, epoch: 56 | loss: 0.0869962\n",
      "\tspeed: 0.0128s/iter; left time: 126.7313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0857411 Vali Loss: 0.0838174 Test Loss: 0.0875457\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0855275\n",
      "\tspeed: 0.0323s/iter; left time: 316.3555s\n",
      "\titers: 200, epoch: 57 | loss: 0.0821422\n",
      "\tspeed: 0.0155s/iter; left time: 150.0504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0857449 Vali Loss: 0.0836694 Test Loss: 0.0876946\n",
      "Validation loss decreased (0.083734 --> 0.083669).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0852302\n",
      "\tspeed: 0.0313s/iter; left time: 300.1953s\n",
      "\titers: 200, epoch: 58 | loss: 0.0813387\n",
      "\tspeed: 0.0141s/iter; left time: 133.5898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0856328 Vali Loss: 0.0838333 Test Loss: 0.0876395\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0865474\n",
      "\tspeed: 0.0319s/iter; left time: 297.9664s\n",
      "\titers: 200, epoch: 59 | loss: 0.0864555\n",
      "\tspeed: 0.0181s/iter; left time: 167.7657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0857513 Vali Loss: 0.0838587 Test Loss: 0.0875407\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0815425\n",
      "\tspeed: 0.0336s/iter; left time: 306.1960s\n",
      "\titers: 200, epoch: 60 | loss: 0.0846148\n",
      "\tspeed: 0.0132s/iter; left time: 119.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0856650 Vali Loss: 0.0838523 Test Loss: 0.0875463\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0817179\n",
      "\tspeed: 0.0349s/iter; left time: 310.3364s\n",
      "\titers: 200, epoch: 61 | loss: 0.0882797\n",
      "\tspeed: 0.0169s/iter; left time: 148.5799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0857247 Vali Loss: 0.0837791 Test Loss: 0.0875305\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0847188\n",
      "\tspeed: 0.0304s/iter; left time: 263.4557s\n",
      "\titers: 200, epoch: 62 | loss: 0.0864886\n",
      "\tspeed: 0.0172s/iter; left time: 147.6845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0856562 Vali Loss: 0.0837275 Test Loss: 0.0875718\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0876755\n",
      "\tspeed: 0.0329s/iter; left time: 277.9308s\n",
      "\titers: 200, epoch: 63 | loss: 0.0876397\n",
      "\tspeed: 0.0154s/iter; left time: 128.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0856394 Vali Loss: 0.0837758 Test Loss: 0.0876276\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0870029\n",
      "\tspeed: 0.0323s/iter; left time: 265.3085s\n",
      "\titers: 200, epoch: 64 | loss: 0.0860020\n",
      "\tspeed: 0.0155s/iter; left time: 126.1215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0856961 Vali Loss: 0.0837211 Test Loss: 0.0875373\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0852330\n",
      "\tspeed: 0.0336s/iter; left time: 269.0732s\n",
      "\titers: 200, epoch: 65 | loss: 0.0844138\n",
      "\tspeed: 0.0179s/iter; left time: 141.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0855918 Vali Loss: 0.0838730 Test Loss: 0.0874921\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0866955\n",
      "\tspeed: 0.0336s/iter; left time: 261.4932s\n",
      "\titers: 200, epoch: 66 | loss: 0.0854436\n",
      "\tspeed: 0.0164s/iter; left time: 125.8727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0858716 Vali Loss: 0.0839868 Test Loss: 0.0875049\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0849778\n",
      "\tspeed: 0.0344s/iter; left time: 259.7289s\n",
      "\titers: 200, epoch: 67 | loss: 0.0866626\n",
      "\tspeed: 0.0166s/iter; left time: 123.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0856807 Vali Loss: 0.0837630 Test Loss: 0.0875618\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019952882081270218, rmse:0.14125467836856842, mae:0.08769454061985016, rse:0.5345954895019531\n",
      "Intermediate time for IT and pred_len 168: 00h:11m:37.36s\n",
      "Intermediate time for IT: 00h:30m:03.60s\n",
      "Total time: 02h:39m:39.71s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len=336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>0.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.1505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1473  0.0914\n",
       "        96        0.0378  0.1945  0.1299\n",
       "        168       0.0459  0.2143  0.1411\n",
       "ES      24        0.0128  0.1130  0.0728\n",
       "        96        0.0330  0.1801  0.1138\n",
       "        168       0.0306  0.1748  0.1165\n",
       "FR      24        0.0111  0.1055  0.0610\n",
       "        96        0.0204  0.1429  0.0836\n",
       "        168       0.0231  0.1520  0.0899\n",
       "GB      24        0.0259  0.1608  0.1038\n",
       "        96        0.0432  0.2079  0.1433\n",
       "        168       0.0478  0.2186  0.1505\n",
       "IT      24        0.0109  0.1042  0.0626\n",
       "        96        0.0186  0.1365  0.0837\n",
       "        168       0.0199  0.1411  0.0877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)\n",
    "\n",
    "It is a channel mixing model, and therefore it needs more dimension of embeddings to capture complex patterns between features. \n",
    "\n",
    "Therefore, it is not fair to keep same d_model and d_ff as in channel mixing. In this regard, we scale them based on number of input features.\n",
    "\n",
    "In other words, for DE data with 5 columns, d_model = 128 x 5, and d_ff = 256 x 5.\n",
    "\n",
    "For ES: d_model = 128 x 3 and d_ff = 256 x 3, etc. It is adjusted automatically in code.\n",
    "\n",
    "Since it converges fast, we reduced max number of epochs and patience.\n",
    "\n",
    "Complete results are in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1051457\n",
      "\tspeed: 0.1703s/iter; left time: 3781.7709s\n",
      "\titers: 200, epoch: 1 | loss: 0.0932204\n",
      "\tspeed: 0.1458s/iter; left time: 3221.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 223 | Train Loss: 0.1071621 Vali Loss: 0.1028725 Test Loss: 0.1150246\n",
      "Validation loss decreased (inf --> 0.102873).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0896473\n",
      "\tspeed: 0.2421s/iter; left time: 5320.6976s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852750\n",
      "\tspeed: 0.1465s/iter; left time: 3204.1615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0888812 Vali Loss: 0.1054194 Test Loss: 0.1180188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0801186\n",
      "\tspeed: 0.2385s/iter; left time: 5189.3113s\n",
      "\titers: 200, epoch: 3 | loss: 0.0752198\n",
      "\tspeed: 0.1471s/iter; left time: 3185.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 223 | Train Loss: 0.0808936 Vali Loss: 0.1088918 Test Loss: 0.1218244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764754\n",
      "\tspeed: 0.2386s/iter; left time: 5136.7827s\n",
      "\titers: 200, epoch: 4 | loss: 0.0668249\n",
      "\tspeed: 0.1475s/iter; left time: 3162.1212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 223 | Train Loss: 0.0712032 Vali Loss: 0.1164811 Test Loss: 0.1314963\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0584339\n",
      "\tspeed: 0.2388s/iter; left time: 5087.6700s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615544\n",
      "\tspeed: 0.1467s/iter; left time: 3111.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.85s\n",
      "Steps: 223 | Train Loss: 0.0614232 Vali Loss: 0.1146671 Test Loss: 0.1260481\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0533759\n",
      "\tspeed: 0.2367s/iter; left time: 4990.1201s\n",
      "\titers: 200, epoch: 6 | loss: 0.0495681\n",
      "\tspeed: 0.1466s/iter; left time: 3077.0692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 223 | Train Loss: 0.0537273 Vali Loss: 0.1115397 Test Loss: 0.1244299\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0473040\n",
      "\tspeed: 0.2379s/iter; left time: 4962.2669s\n",
      "\titers: 200, epoch: 7 | loss: 0.0490480\n",
      "\tspeed: 0.1467s/iter; left time: 3046.3001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 223 | Train Loss: 0.0485017 Vali Loss: 0.1118774 Test Loss: 0.1266170\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0428582\n",
      "\tspeed: 0.2373s/iter; left time: 4897.0955s\n",
      "\titers: 200, epoch: 8 | loss: 0.0423327\n",
      "\tspeed: 0.1464s/iter; left time: 3006.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.77s\n",
      "Steps: 223 | Train Loss: 0.0436265 Vali Loss: 0.1113263 Test Loss: 0.1248961\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0409019\n",
      "\tspeed: 0.2371s/iter; left time: 4841.5272s\n",
      "\titers: 200, epoch: 9 | loss: 0.0388029\n",
      "\tspeed: 0.1463s/iter; left time: 2971.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.73s\n",
      "Steps: 223 | Train Loss: 0.0416113 Vali Loss: 0.1129987 Test Loss: 0.1294562\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0386123\n",
      "\tspeed: 0.2363s/iter; left time: 4771.1943s\n",
      "\titers: 200, epoch: 10 | loss: 0.0380670\n",
      "\tspeed: 0.1463s/iter; left time: 2940.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0399942 Vali Loss: 0.1123616 Test Loss: 0.1261321\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0382017\n",
      "\tspeed: 0.2373s/iter; left time: 4739.1549s\n",
      "\titers: 200, epoch: 11 | loss: 0.0367740\n",
      "\tspeed: 0.1463s/iter; left time: 2906.8815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0381936 Vali Loss: 0.1106567 Test Loss: 0.1257289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028743868693709373, rmse:0.1695401668548584, mae:0.11502459645271301, rse:0.5848655104637146\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1056844\n",
      "\tspeed: 0.1474s/iter; left time: 3273.2981s\n",
      "\titers: 200, epoch: 1 | loss: 0.0887723\n",
      "\tspeed: 0.1462s/iter; left time: 3231.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.79s\n",
      "Steps: 223 | Train Loss: 0.1076930 Vali Loss: 0.1034200 Test Loss: 0.1157358\n",
      "Validation loss decreased (inf --> 0.103420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871905\n",
      "\tspeed: 0.2427s/iter; left time: 5333.6320s\n",
      "\titers: 200, epoch: 2 | loss: 0.0820583\n",
      "\tspeed: 0.1465s/iter; left time: 3205.9718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 223 | Train Loss: 0.0888926 Vali Loss: 0.1046297 Test Loss: 0.1171767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0843876\n",
      "\tspeed: 0.2379s/iter; left time: 5175.5638s\n",
      "\titers: 200, epoch: 3 | loss: 0.0818222\n",
      "\tspeed: 0.1464s/iter; left time: 3169.5225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.81s\n",
      "Steps: 223 | Train Loss: 0.0815588 Vali Loss: 0.1086011 Test Loss: 0.1196759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0724633\n",
      "\tspeed: 0.2380s/iter; left time: 5125.0562s\n",
      "\titers: 200, epoch: 4 | loss: 0.0665326\n",
      "\tspeed: 0.1466s/iter; left time: 3142.6231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 223 | Train Loss: 0.0715411 Vali Loss: 0.1171121 Test Loss: 0.1247998\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0588575\n",
      "\tspeed: 0.2378s/iter; left time: 5066.5772s\n",
      "\titers: 200, epoch: 5 | loss: 0.0584292\n",
      "\tspeed: 0.1465s/iter; left time: 3107.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0616918 Vali Loss: 0.1111074 Test Loss: 0.1225118\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0505120\n",
      "\tspeed: 0.2374s/iter; left time: 5005.2128s\n",
      "\titers: 200, epoch: 6 | loss: 0.0511305\n",
      "\tspeed: 0.1461s/iter; left time: 3066.8633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0532696 Vali Loss: 0.1103224 Test Loss: 0.1216622\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0483326\n",
      "\tspeed: 0.2370s/iter; left time: 4944.9578s\n",
      "\titers: 200, epoch: 7 | loss: 0.0455461\n",
      "\tspeed: 0.1462s/iter; left time: 3035.8085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0479013 Vali Loss: 0.1107165 Test Loss: 0.1228329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0439964\n",
      "\tspeed: 0.2375s/iter; left time: 4902.2376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449820\n",
      "\tspeed: 0.1463s/iter; left time: 3004.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.75s\n",
      "Steps: 223 | Train Loss: 0.0444204 Vali Loss: 0.1109379 Test Loss: 0.1237228\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0418664\n",
      "\tspeed: 0.2376s/iter; left time: 4851.4845s\n",
      "\titers: 200, epoch: 9 | loss: 0.0413343\n",
      "\tspeed: 0.1464s/iter; left time: 2974.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0413205 Vali Loss: 0.1107434 Test Loss: 0.1236369\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0371369\n",
      "\tspeed: 0.2377s/iter; left time: 4800.6975s\n",
      "\titers: 200, epoch: 10 | loss: 0.0389452\n",
      "\tspeed: 0.1463s/iter; left time: 2938.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 223 | Train Loss: 0.0396608 Vali Loss: 0.1118143 Test Loss: 0.1250867\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0370215\n",
      "\tspeed: 0.2380s/iter; left time: 4752.2605s\n",
      "\titers: 200, epoch: 11 | loss: 0.0395964\n",
      "\tspeed: 0.1465s/iter; left time: 2910.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0381358 Vali Loss: 0.1105671 Test Loss: 0.1246427\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029005983844399452, rmse:0.17031143605709076, mae:0.11573578417301178, rse:0.5875261425971985\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:21.02s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1156728\n",
      "\tspeed: 0.1709s/iter; left time: 3777.5477s\n",
      "\titers: 200, epoch: 1 | loss: 0.1047598\n",
      "\tspeed: 0.1498s/iter; left time: 3295.9343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.44s\n",
      "Steps: 222 | Train Loss: 0.1199832 Vali Loss: 0.1229378 Test Loss: 0.1452433\n",
      "Validation loss decreased (inf --> 0.122938).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1146321\n",
      "\tspeed: 0.2501s/iter; left time: 5472.0933s\n",
      "\titers: 200, epoch: 2 | loss: 0.0956471\n",
      "\tspeed: 0.1487s/iter; left time: 3238.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.31s\n",
      "Steps: 222 | Train Loss: 0.1067851 Vali Loss: 0.1402225 Test Loss: 0.1606241\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0768545\n",
      "\tspeed: 0.2397s/iter; left time: 5190.7345s\n",
      "\titers: 200, epoch: 3 | loss: 0.0670673\n",
      "\tspeed: 0.1484s/iter; left time: 3198.8019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.08s\n",
      "Steps: 222 | Train Loss: 0.0784635 Vali Loss: 0.1549436 Test Loss: 0.1626762\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615202\n",
      "\tspeed: 0.2398s/iter; left time: 5139.7258s\n",
      "\titers: 200, epoch: 4 | loss: 0.0553973\n",
      "\tspeed: 0.1484s/iter; left time: 3166.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.11s\n",
      "Steps: 222 | Train Loss: 0.0621905 Vali Loss: 0.1486871 Test Loss: 0.1585362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0881757\n",
      "\tspeed: 0.2398s/iter; left time: 5086.7055s\n",
      "\titers: 200, epoch: 5 | loss: 0.0501511\n",
      "\tspeed: 0.1487s/iter; left time: 3139.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.12s\n",
      "Steps: 222 | Train Loss: 0.0527247 Vali Loss: 0.1394723 Test Loss: 0.1576203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0477496\n",
      "\tspeed: 0.2399s/iter; left time: 5035.0269s\n",
      "\titers: 200, epoch: 6 | loss: 0.0474090\n",
      "\tspeed: 0.1484s/iter; left time: 3101.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.11s\n",
      "Steps: 222 | Train Loss: 0.0484712 Vali Loss: 0.1370355 Test Loss: 0.1556998\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412586\n",
      "\tspeed: 0.2400s/iter; left time: 4983.5867s\n",
      "\titers: 200, epoch: 7 | loss: 0.0407524\n",
      "\tspeed: 0.1485s/iter; left time: 3069.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0431573 Vali Loss: 0.1348506 Test Loss: 0.1544424\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0423980\n",
      "\tspeed: 0.2402s/iter; left time: 4935.6244s\n",
      "\titers: 200, epoch: 8 | loss: 0.0422410\n",
      "\tspeed: 0.1487s/iter; left time: 3039.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0418209 Vali Loss: 0.1379111 Test Loss: 0.1536960\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0395810\n",
      "\tspeed: 0.2392s/iter; left time: 4861.3254s\n",
      "\titers: 200, epoch: 9 | loss: 0.0401174\n",
      "\tspeed: 0.1485s/iter; left time: 3003.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.08s\n",
      "Steps: 222 | Train Loss: 0.0393178 Vali Loss: 0.1330695 Test Loss: 0.1526520\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0376254\n",
      "\tspeed: 0.2403s/iter; left time: 4830.8311s\n",
      "\titers: 200, epoch: 10 | loss: 0.0342666\n",
      "\tspeed: 0.1487s/iter; left time: 2974.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.20s\n",
      "Steps: 222 | Train Loss: 0.0370651 Vali Loss: 0.1324363 Test Loss: 0.1522708\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0352456\n",
      "\tspeed: 0.2408s/iter; left time: 4787.1133s\n",
      "\titers: 200, epoch: 11 | loss: 0.0371032\n",
      "\tspeed: 0.1487s/iter; left time: 2940.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.19s\n",
      "Steps: 222 | Train Loss: 0.0362890 Vali Loss: 0.1320634 Test Loss: 0.1527143\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04341920092701912, rmse:0.20837274193763733, mae:0.1452433168888092, rse:0.7205820083618164\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1165444\n",
      "\tspeed: 0.1494s/iter; left time: 3302.5688s\n",
      "\titers: 200, epoch: 1 | loss: 0.1111383\n",
      "\tspeed: 0.1485s/iter; left time: 3267.8121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.1201055 Vali Loss: 0.1230098 Test Loss: 0.1451796\n",
      "Validation loss decreased (inf --> 0.123010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1108082\n",
      "\tspeed: 0.2554s/iter; left time: 5588.7955s\n",
      "\titers: 200, epoch: 2 | loss: 0.0935105\n",
      "\tspeed: 0.1486s/iter; left time: 3235.8232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.24s\n",
      "Steps: 222 | Train Loss: 0.1068995 Vali Loss: 0.1398159 Test Loss: 0.1669322\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0784802\n",
      "\tspeed: 0.2413s/iter; left time: 5226.1157s\n",
      "\titers: 200, epoch: 3 | loss: 0.0735279\n",
      "\tspeed: 0.1487s/iter; left time: 3206.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.20s\n",
      "Steps: 222 | Train Loss: 0.0795587 Vali Loss: 0.1421815 Test Loss: 0.1656734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637211\n",
      "\tspeed: 0.2420s/iter; left time: 5186.7990s\n",
      "\titers: 200, epoch: 4 | loss: 0.0617426\n",
      "\tspeed: 0.1487s/iter; left time: 3171.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0648935 Vali Loss: 0.1376564 Test Loss: 0.1604086\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0552284\n",
      "\tspeed: 0.2417s/iter; left time: 5127.4756s\n",
      "\titers: 200, epoch: 5 | loss: 0.0531027\n",
      "\tspeed: 0.1486s/iter; left time: 3137.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.17s\n",
      "Steps: 222 | Train Loss: 0.0553986 Vali Loss: 0.1340457 Test Loss: 0.1575819\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0478428\n",
      "\tspeed: 0.2412s/iter; left time: 5063.8890s\n",
      "\titers: 200, epoch: 6 | loss: 0.0523911\n",
      "\tspeed: 0.1486s/iter; left time: 3103.9163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0490555 Vali Loss: 0.1340929 Test Loss: 0.1550300\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0459050\n",
      "\tspeed: 0.2413s/iter; left time: 5011.3346s\n",
      "\titers: 200, epoch: 7 | loss: 0.0428679\n",
      "\tspeed: 0.1485s/iter; left time: 3069.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.0447298 Vali Loss: 0.1341426 Test Loss: 0.1539580\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0405288\n",
      "\tspeed: 0.2414s/iter; left time: 4960.5656s\n",
      "\titers: 200, epoch: 8 | loss: 0.0405174\n",
      "\tspeed: 0.1482s/iter; left time: 3030.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0419976 Vali Loss: 0.1378684 Test Loss: 0.1581065\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0382658\n",
      "\tspeed: 0.2406s/iter; left time: 4891.0947s\n",
      "\titers: 200, epoch: 9 | loss: 0.0395453\n",
      "\tspeed: 0.1486s/iter; left time: 3005.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.0404064 Vali Loss: 0.1317059 Test Loss: 0.1522986\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0378837\n",
      "\tspeed: 0.2412s/iter; left time: 4848.7059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0369272\n",
      "\tspeed: 0.1485s/iter; left time: 2970.4434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0381774 Vali Loss: 0.1314865 Test Loss: 0.1513584\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0358450\n",
      "\tspeed: 0.2409s/iter; left time: 4789.2445s\n",
      "\titers: 200, epoch: 11 | loss: 0.0374405\n",
      "\tspeed: 0.1488s/iter; left time: 2943.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0363881 Vali Loss: 0.1307979 Test Loss: 0.1516058\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04355882108211517, rmse:0.20870749652385712, mae:0.1451796293258667, rse:0.7217395901679993\n",
      "Intermediate time for GB and pred_len 96: 00h:14m:36.03s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1177407\n",
      "\tspeed: 0.1745s/iter; left time: 3857.2506s\n",
      "\titers: 200, epoch: 1 | loss: 0.1147017\n",
      "\tspeed: 0.1503s/iter; left time: 3306.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.78s\n",
      "Steps: 222 | Train Loss: 0.1225829 Vali Loss: 0.1266081 Test Loss: 0.1497908\n",
      "Validation loss decreased (inf --> 0.126608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1123300\n",
      "\tspeed: 0.2887s/iter; left time: 6315.4126s\n",
      "\titers: 200, epoch: 2 | loss: 0.0922024\n",
      "\tspeed: 0.1506s/iter; left time: 3280.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.1073465 Vali Loss: 0.1534391 Test Loss: 0.1633927\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0715112\n",
      "\tspeed: 0.2422s/iter; left time: 5244.5989s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678034\n",
      "\tspeed: 0.1507s/iter; left time: 3249.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.64s\n",
      "Steps: 222 | Train Loss: 0.0751841 Vali Loss: 0.1467895 Test Loss: 0.1613366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0583339\n",
      "\tspeed: 0.2417s/iter; left time: 5180.5349s\n",
      "\titers: 200, epoch: 4 | loss: 0.0547504\n",
      "\tspeed: 0.1506s/iter; left time: 3213.8292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.62s\n",
      "Steps: 222 | Train Loss: 0.0591856 Vali Loss: 0.1385507 Test Loss: 0.1562234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0566366\n",
      "\tspeed: 0.2418s/iter; left time: 5129.7138s\n",
      "\titers: 200, epoch: 5 | loss: 0.0517352\n",
      "\tspeed: 0.1507s/iter; left time: 3182.7699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.61s\n",
      "Steps: 222 | Train Loss: 0.0521256 Vali Loss: 0.1398461 Test Loss: 0.1579931\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0485455\n",
      "\tspeed: 0.2414s/iter; left time: 5066.7254s\n",
      "\titers: 200, epoch: 6 | loss: 0.0483025\n",
      "\tspeed: 0.1508s/iter; left time: 3149.5819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0479918 Vali Loss: 0.1388285 Test Loss: 0.1559225\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412977\n",
      "\tspeed: 0.2417s/iter; left time: 5019.4109s\n",
      "\titers: 200, epoch: 7 | loss: 0.0430455\n",
      "\tspeed: 0.1509s/iter; left time: 3118.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0437611 Vali Loss: 0.1360448 Test Loss: 0.1562288\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0412615\n",
      "\tspeed: 0.2412s/iter; left time: 4956.3507s\n",
      "\titers: 200, epoch: 8 | loss: 0.0435497\n",
      "\tspeed: 0.1508s/iter; left time: 3084.3684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0422933 Vali Loss: 0.1364408 Test Loss: 0.1566917\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0399560\n",
      "\tspeed: 0.2421s/iter; left time: 4920.5603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0365216\n",
      "\tspeed: 0.1508s/iter; left time: 3049.0123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.62s\n",
      "Steps: 222 | Train Loss: 0.0392865 Vali Loss: 0.1353271 Test Loss: 0.1550491\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0372904\n",
      "\tspeed: 0.2423s/iter; left time: 4869.9806s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402687\n",
      "\tspeed: 0.1511s/iter; left time: 3022.6342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.69s\n",
      "Steps: 222 | Train Loss: 0.0405217 Vali Loss: 0.1355167 Test Loss: 0.1553616\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0355937\n",
      "\tspeed: 0.2413s/iter; left time: 4797.8155s\n",
      "\titers: 200, epoch: 11 | loss: 0.0380037\n",
      "\tspeed: 0.1509s/iter; left time: 2984.6356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0374547 Vali Loss: 0.1346184 Test Loss: 0.1547808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045506544411182404, rmse:0.21332262456417084, mae:0.14979074895381927, rse:0.7396202087402344\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1164795\n",
      "\tspeed: 0.1520s/iter; left time: 3360.0338s\n",
      "\titers: 200, epoch: 1 | loss: 0.1178308\n",
      "\tspeed: 0.1507s/iter; left time: 3315.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.64s\n",
      "Steps: 222 | Train Loss: 0.1227937 Vali Loss: 0.1269568 Test Loss: 0.1500853\n",
      "Validation loss decreased (inf --> 0.126957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1080633\n",
      "\tspeed: 0.2832s/iter; left time: 6196.1052s\n",
      "\titers: 200, epoch: 2 | loss: 0.0911027\n",
      "\tspeed: 0.1506s/iter; left time: 3279.7866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.63s\n",
      "Steps: 222 | Train Loss: 0.1069387 Vali Loss: 0.1472872 Test Loss: 0.1704258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0766009\n",
      "\tspeed: 0.2439s/iter; left time: 5282.7984s\n",
      "\titers: 200, epoch: 3 | loss: 0.0693914\n",
      "\tspeed: 0.1509s/iter; left time: 3253.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.70s\n",
      "Steps: 222 | Train Loss: 0.0753113 Vali Loss: 0.1423926 Test Loss: 0.1651071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0579466\n",
      "\tspeed: 0.2448s/iter; left time: 5246.9351s\n",
      "\titers: 200, epoch: 4 | loss: 0.0602810\n",
      "\tspeed: 0.1509s/iter; left time: 3220.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0602860 Vali Loss: 0.1388860 Test Loss: 0.1613450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0529091\n",
      "\tspeed: 0.2440s/iter; left time: 5175.5351s\n",
      "\titers: 200, epoch: 5 | loss: 0.0478933\n",
      "\tspeed: 0.1510s/iter; left time: 3188.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.68s\n",
      "Steps: 222 | Train Loss: 0.0532050 Vali Loss: 0.1397931 Test Loss: 0.1621394\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0488900\n",
      "\tspeed: 0.2441s/iter; left time: 5124.3289s\n",
      "\titers: 200, epoch: 6 | loss: 0.0479902\n",
      "\tspeed: 0.1508s/iter; left time: 3151.2421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0490049 Vali Loss: 0.1387042 Test Loss: 0.1603853\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0458506\n",
      "\tspeed: 0.2432s/iter; left time: 5051.5493s\n",
      "\titers: 200, epoch: 7 | loss: 0.0413319\n",
      "\tspeed: 0.1508s/iter; left time: 3117.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.67s\n",
      "Steps: 222 | Train Loss: 0.0447227 Vali Loss: 0.1376807 Test Loss: 0.1579818\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0406756\n",
      "\tspeed: 0.2439s/iter; left time: 5010.5233s\n",
      "\titers: 200, epoch: 8 | loss: 0.0401300\n",
      "\tspeed: 0.1510s/iter; left time: 3086.5883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0428238 Vali Loss: 0.1362697 Test Loss: 0.1593084\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0425120\n",
      "\tspeed: 0.2438s/iter; left time: 4955.0447s\n",
      "\titers: 200, epoch: 9 | loss: 0.0428176\n",
      "\tspeed: 0.1510s/iter; left time: 3053.1021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.67s\n",
      "Steps: 222 | Train Loss: 0.0406100 Vali Loss: 0.1351584 Test Loss: 0.1575931\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0391058\n",
      "\tspeed: 0.2447s/iter; left time: 4919.7646s\n",
      "\titers: 200, epoch: 10 | loss: 0.0359502\n",
      "\tspeed: 0.1509s/iter; left time: 3018.1160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0388262 Vali Loss: 0.1357430 Test Loss: 0.1580252\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0361103\n",
      "\tspeed: 0.2442s/iter; left time: 4854.2990s\n",
      "\titers: 200, epoch: 11 | loss: 0.0373988\n",
      "\tspeed: 0.1510s/iter; left time: 2987.8669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.68s\n",
      "Steps: 222 | Train Loss: 0.0368991 Vali Loss: 0.1348735 Test Loss: 0.1577474\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045674242079257965, rmse:0.2137153297662735, mae:0.15008527040481567, rse:0.7409817576408386\n",
      "Intermediate time for GB and pred_len 168: 00h:14m:55.51s\n",
      "Intermediate time for GB: 00h:43m:52.56s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1083394\n",
      "\tspeed: 0.0573s/iter; left time: 1277.9257s\n",
      "\titers: 200, epoch: 1 | loss: 0.0949330\n",
      "\tspeed: 0.0326s/iter; left time: 723.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.1146521 Vali Loss: 0.0854233 Test Loss: 0.0978887\n",
      "Validation loss decreased (inf --> 0.085423).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0694569\n",
      "\tspeed: 0.0622s/iter; left time: 1372.0866s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682702\n",
      "\tspeed: 0.0326s/iter; left time: 715.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0716935 Vali Loss: 0.0656114 Test Loss: 0.0731752\n",
      "Validation loss decreased (0.085423 --> 0.065611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638887\n",
      "\tspeed: 0.0622s/iter; left time: 1358.9573s\n",
      "\titers: 200, epoch: 3 | loss: 0.0625745\n",
      "\tspeed: 0.0326s/iter; left time: 709.3744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0642866 Vali Loss: 0.0630241 Test Loss: 0.0710565\n",
      "Validation loss decreased (0.065611 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611238\n",
      "\tspeed: 0.0620s/iter; left time: 1340.0211s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643910\n",
      "\tspeed: 0.0325s/iter; left time: 699.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0619596 Vali Loss: 0.0643963 Test Loss: 0.0716253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0614629\n",
      "\tspeed: 0.0593s/iter; left time: 1268.8093s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591143\n",
      "\tspeed: 0.0325s/iter; left time: 692.8271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0598301 Vali Loss: 0.0612322 Test Loss: 0.0694189\n",
      "Validation loss decreased (0.063024 --> 0.061232).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568408\n",
      "\tspeed: 0.0610s/iter; left time: 1292.2982s\n",
      "\titers: 200, epoch: 6 | loss: 0.0567278\n",
      "\tspeed: 0.0325s/iter; left time: 685.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0577446 Vali Loss: 0.0609693 Test Loss: 0.0682407\n",
      "Validation loss decreased (0.061232 --> 0.060969).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562621\n",
      "\tspeed: 0.0612s/iter; left time: 1282.4153s\n",
      "\titers: 200, epoch: 7 | loss: 0.0554868\n",
      "\tspeed: 0.0325s/iter; left time: 678.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0561681 Vali Loss: 0.0597783 Test Loss: 0.0675127\n",
      "Validation loss decreased (0.060969 --> 0.059778).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569908\n",
      "\tspeed: 0.0611s/iter; left time: 1266.2956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577169\n",
      "\tspeed: 0.0325s/iter; left time: 671.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0544420 Vali Loss: 0.0602443 Test Loss: 0.0683316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521781\n",
      "\tspeed: 0.0602s/iter; left time: 1235.5452s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503141\n",
      "\tspeed: 0.0327s/iter; left time: 667.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0526811 Vali Loss: 0.0609316 Test Loss: 0.0681847\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0519583\n",
      "\tspeed: 0.0596s/iter; left time: 1208.3835s\n",
      "\titers: 200, epoch: 10 | loss: 0.0487051\n",
      "\tspeed: 0.0329s/iter; left time: 664.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0512578 Vali Loss: 0.0613501 Test Loss: 0.0695660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517822\n",
      "\tspeed: 0.0598s/iter; left time: 1200.4242s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482223\n",
      "\tspeed: 0.0327s/iter; left time: 652.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0498223 Vali Loss: 0.0620379 Test Loss: 0.0702392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494305\n",
      "\tspeed: 0.0599s/iter; left time: 1188.9516s\n",
      "\titers: 200, epoch: 12 | loss: 0.0481998\n",
      "\tspeed: 0.0327s/iter; left time: 645.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0483653 Vali Loss: 0.0612045 Test Loss: 0.0701841\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0462038\n",
      "\tspeed: 0.0607s/iter; left time: 1190.1800s\n",
      "\titers: 200, epoch: 13 | loss: 0.0461890\n",
      "\tspeed: 0.0328s/iter; left time: 639.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0470476 Vali Loss: 0.0618377 Test Loss: 0.0701277\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0474969\n",
      "\tspeed: 0.0600s/iter; left time: 1164.1216s\n",
      "\titers: 200, epoch: 14 | loss: 0.0462358\n",
      "\tspeed: 0.0327s/iter; left time: 631.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0460021 Vali Loss: 0.0619138 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0441642\n",
      "\tspeed: 0.0601s/iter; left time: 1152.4789s\n",
      "\titers: 200, epoch: 15 | loss: 0.0437523\n",
      "\tspeed: 0.0327s/iter; left time: 623.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0449358 Vali Loss: 0.0615214 Test Loss: 0.0704811\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0440189\n",
      "\tspeed: 0.0606s/iter; left time: 1146.9950s\n",
      "\titers: 200, epoch: 16 | loss: 0.0432764\n",
      "\tspeed: 0.0328s/iter; left time: 618.5290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0439870 Vali Loss: 0.0616211 Test Loss: 0.0707664\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0423084\n",
      "\tspeed: 0.0598s/iter; left time: 1118.4282s\n",
      "\titers: 200, epoch: 17 | loss: 0.0415025\n",
      "\tspeed: 0.0328s/iter; left time: 610.5798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0431494 Vali Loss: 0.0620262 Test Loss: 0.0715410\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01133799646049738, rmse:0.10648002475500107, mae:0.06751272827386856, rse:0.3133578300476074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1059176\n",
      "\tspeed: 0.0346s/iter; left time: 772.7058s\n",
      "\titers: 200, epoch: 1 | loss: 0.0954594\n",
      "\tspeed: 0.0327s/iter; left time: 726.2629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.1132807 Vali Loss: 0.0858611 Test Loss: 0.0978220\n",
      "Validation loss decreased (inf --> 0.085861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0672946\n",
      "\tspeed: 0.0635s/iter; left time: 1401.7909s\n",
      "\titers: 200, epoch: 2 | loss: 0.0662497\n",
      "\tspeed: 0.0326s/iter; left time: 715.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0716624 Vali Loss: 0.0645302 Test Loss: 0.0728868\n",
      "Validation loss decreased (0.085861 --> 0.064530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636461\n",
      "\tspeed: 0.0619s/iter; left time: 1352.4904s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644167\n",
      "\tspeed: 0.0328s/iter; left time: 712.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0639991 Vali Loss: 0.0630432 Test Loss: 0.0709006\n",
      "Validation loss decreased (0.064530 --> 0.063043).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0621769\n",
      "\tspeed: 0.0621s/iter; left time: 1342.1702s\n",
      "\titers: 200, epoch: 4 | loss: 0.0600844\n",
      "\tspeed: 0.0326s/iter; left time: 701.0833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0615069 Vali Loss: 0.0610647 Test Loss: 0.0695123\n",
      "Validation loss decreased (0.063043 --> 0.061065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0606961\n",
      "\tspeed: 0.0630s/iter; left time: 1348.5926s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597096\n",
      "\tspeed: 0.0327s/iter; left time: 696.7172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0594661 Vali Loss: 0.0604619 Test Loss: 0.0694347\n",
      "Validation loss decreased (0.061065 --> 0.060462).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0590119\n",
      "\tspeed: 0.0623s/iter; left time: 1319.7344s\n",
      "\titers: 200, epoch: 6 | loss: 0.0569254\n",
      "\tspeed: 0.0327s/iter; left time: 690.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0579130 Vali Loss: 0.0610369 Test Loss: 0.0684163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0548901\n",
      "\tspeed: 0.0603s/iter; left time: 1263.4103s\n",
      "\titers: 200, epoch: 7 | loss: 0.0539524\n",
      "\tspeed: 0.0327s/iter; left time: 680.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0559329 Vali Loss: 0.0594218 Test Loss: 0.0678336\n",
      "Validation loss decreased (0.060462 --> 0.059422).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0538018\n",
      "\tspeed: 0.0648s/iter; left time: 1344.4634s\n",
      "\titers: 200, epoch: 8 | loss: 0.0530818\n",
      "\tspeed: 0.0325s/iter; left time: 671.3128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0542583 Vali Loss: 0.0599612 Test Loss: 0.0689581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552536\n",
      "\tspeed: 0.0601s/iter; left time: 1232.8386s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516640\n",
      "\tspeed: 0.0325s/iter; left time: 663.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0527426 Vali Loss: 0.0591997 Test Loss: 0.0679362\n",
      "Validation loss decreased (0.059422 --> 0.059200).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536080\n",
      "\tspeed: 0.0617s/iter; left time: 1251.9853s\n",
      "\titers: 200, epoch: 10 | loss: 0.0499571\n",
      "\tspeed: 0.0325s/iter; left time: 656.0193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0512842 Vali Loss: 0.0599653 Test Loss: 0.0687808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517187\n",
      "\tspeed: 0.0604s/iter; left time: 1210.6819s\n",
      "\titers: 200, epoch: 11 | loss: 0.0499973\n",
      "\tspeed: 0.0326s/iter; left time: 651.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0497935 Vali Loss: 0.0604572 Test Loss: 0.0696274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0468627\n",
      "\tspeed: 0.0595s/iter; left time: 1181.2420s\n",
      "\titers: 200, epoch: 12 | loss: 0.0489540\n",
      "\tspeed: 0.0328s/iter; left time: 648.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0483913 Vali Loss: 0.0602030 Test Loss: 0.0697745\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0496078\n",
      "\tspeed: 0.0598s/iter; left time: 1172.5827s\n",
      "\titers: 200, epoch: 13 | loss: 0.0476634\n",
      "\tspeed: 0.0323s/iter; left time: 630.7452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0473625 Vali Loss: 0.0604081 Test Loss: 0.0700828\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0464205\n",
      "\tspeed: 0.0594s/iter; left time: 1152.2500s\n",
      "\titers: 200, epoch: 14 | loss: 0.0435993\n",
      "\tspeed: 0.0323s/iter; left time: 623.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0461338 Vali Loss: 0.0605141 Test Loss: 0.0701649\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0460268\n",
      "\tspeed: 0.0599s/iter; left time: 1147.0383s\n",
      "\titers: 200, epoch: 15 | loss: 0.0453027\n",
      "\tspeed: 0.0323s/iter; left time: 616.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0451875 Vali Loss: 0.0609419 Test Loss: 0.0697475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0459039\n",
      "\tspeed: 0.0604s/iter; left time: 1143.9558s\n",
      "\titers: 200, epoch: 16 | loss: 0.0434766\n",
      "\tspeed: 0.0326s/iter; left time: 614.5761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0443061 Vali Loss: 0.0615374 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0443573\n",
      "\tspeed: 0.0599s/iter; left time: 1122.0651s\n",
      "\titers: 200, epoch: 17 | loss: 0.0425250\n",
      "\tspeed: 0.0324s/iter; left time: 603.5718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0435606 Vali Loss: 0.0604851 Test Loss: 0.0707585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0413324\n",
      "\tspeed: 0.0602s/iter; left time: 1113.7053s\n",
      "\titers: 200, epoch: 18 | loss: 0.0445203\n",
      "\tspeed: 0.0325s/iter; left time: 598.5775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0428060 Vali Loss: 0.0611732 Test Loss: 0.0707645\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0436631\n",
      "\tspeed: 0.0596s/iter; left time: 1088.8430s\n",
      "\titers: 200, epoch: 19 | loss: 0.0429139\n",
      "\tspeed: 0.0325s/iter; left time: 591.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0421968 Vali Loss: 0.0612346 Test Loss: 0.0706914\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011598608456552029, rmse:0.10769683867692947, mae:0.06793618202209473, rse:0.31693875789642334\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:48.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1167209\n",
      "\tspeed: 0.0581s/iter; left time: 1296.1155s\n",
      "\titers: 200, epoch: 1 | loss: 0.1056875\n",
      "\tspeed: 0.0331s/iter; left time: 735.3584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.1227398 Vali Loss: 0.0988195 Test Loss: 0.1124716\n",
      "Validation loss decreased (inf --> 0.098819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888136\n",
      "\tspeed: 0.0650s/iter; left time: 1434.6344s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841860\n",
      "\tspeed: 0.0332s/iter; left time: 730.6599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0888445 Vali Loss: 0.0866662 Test Loss: 0.0969930\n",
      "Validation loss decreased (0.098819 --> 0.086666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0807913\n",
      "\tspeed: 0.0628s/iter; left time: 1372.0226s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785247\n",
      "\tspeed: 0.0331s/iter; left time: 720.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0809936 Vali Loss: 0.0850435 Test Loss: 0.0962780\n",
      "Validation loss decreased (0.086666 --> 0.085044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0752124\n",
      "\tspeed: 0.0652s/iter; left time: 1409.4935s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712232\n",
      "\tspeed: 0.0332s/iter; left time: 714.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0751077 Vali Loss: 0.0873182 Test Loss: 0.0995040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689497\n",
      "\tspeed: 0.0621s/iter; left time: 1328.1937s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683093\n",
      "\tspeed: 0.0332s/iter; left time: 707.3728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 224 | Train Loss: 0.0684474 Vali Loss: 0.0864051 Test Loss: 0.1003118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0626845\n",
      "\tspeed: 0.0614s/iter; left time: 1300.7891s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603980\n",
      "\tspeed: 0.0331s/iter; left time: 698.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0631113 Vali Loss: 0.0877236 Test Loss: 0.1011920\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590933\n",
      "\tspeed: 0.0609s/iter; left time: 1275.9670s\n",
      "\titers: 200, epoch: 7 | loss: 0.0597084\n",
      "\tspeed: 0.0331s/iter; left time: 690.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0589081 Vali Loss: 0.0872310 Test Loss: 0.1004953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0552450\n",
      "\tspeed: 0.0611s/iter; left time: 1265.8009s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551953\n",
      "\tspeed: 0.0331s/iter; left time: 683.5963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0555059 Vali Loss: 0.0881087 Test Loss: 0.1008888\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0524991\n",
      "\tspeed: 0.0613s/iter; left time: 1257.9821s\n",
      "\titers: 200, epoch: 9 | loss: 0.0530768\n",
      "\tspeed: 0.0332s/iter; left time: 677.0410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0527471 Vali Loss: 0.0886423 Test Loss: 0.1020612\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0515361\n",
      "\tspeed: 0.0615s/iter; left time: 1248.0465s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495522\n",
      "\tspeed: 0.0333s/iter; left time: 672.0863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0506641 Vali Loss: 0.0878667 Test Loss: 0.1018857\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0495449\n",
      "\tspeed: 0.0622s/iter; left time: 1247.0062s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484085\n",
      "\tspeed: 0.0335s/iter; left time: 668.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0487303 Vali Loss: 0.0874963 Test Loss: 0.1018826\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0460823\n",
      "\tspeed: 0.0613s/iter; left time: 1215.3686s\n",
      "\titers: 200, epoch: 12 | loss: 0.0487627\n",
      "\tspeed: 0.0331s/iter; left time: 653.6800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0472277 Vali Loss: 0.0875905 Test Loss: 0.1023017\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0471489\n",
      "\tspeed: 0.0612s/iter; left time: 1201.1524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0454935\n",
      "\tspeed: 0.0331s/iter; left time: 645.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0459133 Vali Loss: 0.0874007 Test Loss: 0.1019594\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021271303296089172, rmse:0.14584684371948242, mae:0.09627804905176163, rse:0.4284541606903076\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1204117\n",
      "\tspeed: 0.0347s/iter; left time: 773.2841s\n",
      "\titers: 200, epoch: 1 | loss: 0.1046546\n",
      "\tspeed: 0.0330s/iter; left time: 733.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.1222082 Vali Loss: 0.0986339 Test Loss: 0.1127096\n",
      "Validation loss decreased (inf --> 0.098634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892475\n",
      "\tspeed: 0.0637s/iter; left time: 1405.5402s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875973\n",
      "\tspeed: 0.0331s/iter; left time: 727.3245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0889160 Vali Loss: 0.0860521 Test Loss: 0.0965959\n",
      "Validation loss decreased (0.098634 --> 0.086052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820314\n",
      "\tspeed: 0.0746s/iter; left time: 1629.4846s\n",
      "\titers: 200, epoch: 3 | loss: 0.0766245\n",
      "\tspeed: 0.0331s/iter; left time: 720.1125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0810734 Vali Loss: 0.0846253 Test Loss: 0.0976963\n",
      "Validation loss decreased (0.086052 --> 0.084625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731675\n",
      "\tspeed: 0.0660s/iter; left time: 1426.5197s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741658\n",
      "\tspeed: 0.0335s/iter; left time: 721.5715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0754243 Vali Loss: 0.0878123 Test Loss: 0.1005267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0716164\n",
      "\tspeed: 0.0616s/iter; left time: 1317.6022s\n",
      "\titers: 200, epoch: 5 | loss: 0.0671426\n",
      "\tspeed: 0.0331s/iter; left time: 705.6265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0690027 Vali Loss: 0.0878285 Test Loss: 0.1006422\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641997\n",
      "\tspeed: 0.0612s/iter; left time: 1295.4053s\n",
      "\titers: 200, epoch: 6 | loss: 0.0674796\n",
      "\tspeed: 0.0331s/iter; left time: 697.8527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0635019 Vali Loss: 0.0878592 Test Loss: 0.1024417\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0591606\n",
      "\tspeed: 0.0615s/iter; left time: 1288.8847s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583029\n",
      "\tspeed: 0.0331s/iter; left time: 691.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0588996 Vali Loss: 0.0877868 Test Loss: 0.1020480\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0553827\n",
      "\tspeed: 0.0614s/iter; left time: 1272.8050s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554482\n",
      "\tspeed: 0.0332s/iter; left time: 684.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0554791 Vali Loss: 0.0881074 Test Loss: 0.1035934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0541625\n",
      "\tspeed: 0.0616s/iter; left time: 1263.4282s\n",
      "\titers: 200, epoch: 9 | loss: 0.0502246\n",
      "\tspeed: 0.0332s/iter; left time: 676.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0527017 Vali Loss: 0.0881722 Test Loss: 0.1024241\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0498284\n",
      "\tspeed: 0.0612s/iter; left time: 1240.7351s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489367\n",
      "\tspeed: 0.0331s/iter; left time: 668.2251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0506088 Vali Loss: 0.0888529 Test Loss: 0.1031139\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0476753\n",
      "\tspeed: 0.0623s/iter; left time: 1249.1649s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481353\n",
      "\tspeed: 0.0331s/iter; left time: 660.8999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0486823 Vali Loss: 0.0881064 Test Loss: 0.1029631\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0461587\n",
      "\tspeed: 0.0609s/iter; left time: 1208.6124s\n",
      "\titers: 200, epoch: 12 | loss: 0.0474565\n",
      "\tspeed: 0.0330s/iter; left time: 650.9760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0471709 Vali Loss: 0.0887941 Test Loss: 0.1031620\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465209\n",
      "\tspeed: 0.0616s/iter; left time: 1207.6783s\n",
      "\titers: 200, epoch: 13 | loss: 0.0457823\n",
      "\tspeed: 0.0332s/iter; left time: 647.9063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0457775 Vali Loss: 0.0880506 Test Loss: 0.1036356\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021871840581297874, rmse:0.1478913128376007, mae:0.09769626706838608, rse:0.4344601631164551\n",
      "Intermediate time for ES and pred_len 96: 00h:04m:21.86s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163252\n",
      "\tspeed: 0.0624s/iter; left time: 1385.7644s\n",
      "\titers: 200, epoch: 1 | loss: 0.1111509\n",
      "\tspeed: 0.0337s/iter; left time: 745.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.1248032 Vali Loss: 0.1023557 Test Loss: 0.1157608\n",
      "Validation loss decreased (inf --> 0.102356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0920324\n",
      "\tspeed: 0.0733s/iter; left time: 1611.7066s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905396\n",
      "\tspeed: 0.0337s/iter; left time: 738.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0927347 Vali Loss: 0.0911596 Test Loss: 0.1026373\n",
      "Validation loss decreased (0.102356 --> 0.091160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0813993\n",
      "\tspeed: 0.0775s/iter; left time: 1685.0918s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804934\n",
      "\tspeed: 0.0338s/iter; left time: 732.9091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0837477 Vali Loss: 0.0901361 Test Loss: 0.1034494\n",
      "Validation loss decreased (0.091160 --> 0.090136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0745005\n",
      "\tspeed: 0.0755s/iter; left time: 1625.6449s\n",
      "\titers: 200, epoch: 4 | loss: 0.0743757\n",
      "\tspeed: 0.0338s/iter; left time: 723.6099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0773343 Vali Loss: 0.0920163 Test Loss: 0.1045371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0717543\n",
      "\tspeed: 0.0623s/iter; left time: 1327.8117s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683926\n",
      "\tspeed: 0.0339s/iter; left time: 717.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0706961 Vali Loss: 0.0927095 Test Loss: 0.1056051\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0635267\n",
      "\tspeed: 0.0626s/iter; left time: 1319.7380s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626201\n",
      "\tspeed: 0.0338s/iter; left time: 709.7059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0648583 Vali Loss: 0.0928507 Test Loss: 0.1066073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0594731\n",
      "\tspeed: 0.0620s/iter; left time: 1292.7169s\n",
      "\titers: 200, epoch: 7 | loss: 0.0574201\n",
      "\tspeed: 0.0340s/iter; left time: 705.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0604445 Vali Loss: 0.0937179 Test Loss: 0.1071184\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0578186\n",
      "\tspeed: 0.0640s/iter; left time: 1321.4657s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562383\n",
      "\tspeed: 0.0338s/iter; left time: 694.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0571987 Vali Loss: 0.0920181 Test Loss: 0.1071269\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552342\n",
      "\tspeed: 0.0626s/iter; left time: 1277.5305s\n",
      "\titers: 200, epoch: 9 | loss: 0.0548123\n",
      "\tspeed: 0.0339s/iter; left time: 687.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0545950 Vali Loss: 0.0930666 Test Loss: 0.1075234\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0529762\n",
      "\tspeed: 0.0622s/iter; left time: 1255.6336s\n",
      "\titers: 200, epoch: 10 | loss: 0.0518859\n",
      "\tspeed: 0.0339s/iter; left time: 681.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0524777 Vali Loss: 0.0920488 Test Loss: 0.1072294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0511605\n",
      "\tspeed: 0.0620s/iter; left time: 1237.8479s\n",
      "\titers: 200, epoch: 11 | loss: 0.0511627\n",
      "\tspeed: 0.0339s/iter; left time: 674.3273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0506818 Vali Loss: 0.0927317 Test Loss: 0.1083499\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0496722\n",
      "\tspeed: 0.0624s/iter; left time: 1232.3483s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484021\n",
      "\tspeed: 0.0339s/iter; left time: 666.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0491604 Vali Loss: 0.0922555 Test Loss: 0.1075642\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0480842\n",
      "\tspeed: 0.0623s/iter; left time: 1215.7753s\n",
      "\titers: 200, epoch: 13 | loss: 0.0480131\n",
      "\tspeed: 0.0340s/iter; left time: 659.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0478748 Vali Loss: 0.0920726 Test Loss: 0.1082650\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0238569937646389, rmse:0.15445709228515625, mae:0.10344940423965454, rse:0.45378103852272034\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1175357\n",
      "\tspeed: 0.0360s/iter; left time: 799.3014s\n",
      "\titers: 200, epoch: 1 | loss: 0.1085309\n",
      "\tspeed: 0.0339s/iter; left time: 749.2484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 223 | Train Loss: 0.1244877 Vali Loss: 0.1024658 Test Loss: 0.1162681\n",
      "Validation loss decreased (inf --> 0.102466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892978\n",
      "\tspeed: 0.0724s/iter; left time: 1591.8888s\n",
      "\titers: 200, epoch: 2 | loss: 0.0858404\n",
      "\tspeed: 0.0339s/iter; left time: 742.3876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 223 | Train Loss: 0.0925368 Vali Loss: 0.0931649 Test Loss: 0.1041178\n",
      "Validation loss decreased (0.102466 --> 0.093165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0832203\n",
      "\tspeed: 0.0679s/iter; left time: 1477.8758s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824200\n",
      "\tspeed: 0.0339s/iter; left time: 733.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 223 | Train Loss: 0.0840002 Vali Loss: 0.0918773 Test Loss: 0.1027539\n",
      "Validation loss decreased (0.093165 --> 0.091877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755718\n",
      "\tspeed: 0.0684s/iter; left time: 1473.3897s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789680\n",
      "\tspeed: 0.0340s/iter; left time: 728.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0778846 Vali Loss: 0.0915824 Test Loss: 0.1033742\n",
      "Validation loss decreased (0.091877 --> 0.091582).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740893\n",
      "\tspeed: 0.0689s/iter; left time: 1468.1146s\n",
      "\titers: 200, epoch: 5 | loss: 0.0704942\n",
      "\tspeed: 0.0339s/iter; left time: 718.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0719597 Vali Loss: 0.0934459 Test Loss: 0.1050283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0674252\n",
      "\tspeed: 0.0634s/iter; left time: 1336.3706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634718\n",
      "\tspeed: 0.0340s/iter; left time: 713.3638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0659032 Vali Loss: 0.0927102 Test Loss: 0.1051720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0629653\n",
      "\tspeed: 0.0642s/iter; left time: 1338.9348s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605651\n",
      "\tspeed: 0.0342s/iter; left time: 709.2852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0613759 Vali Loss: 0.0924244 Test Loss: 0.1051302\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563948\n",
      "\tspeed: 0.0629s/iter; left time: 1297.6812s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562144\n",
      "\tspeed: 0.0339s/iter; left time: 696.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0577199 Vali Loss: 0.0931844 Test Loss: 0.1064090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559244\n",
      "\tspeed: 0.0636s/iter; left time: 1298.2004s\n",
      "\titers: 200, epoch: 9 | loss: 0.0532067\n",
      "\tspeed: 0.0339s/iter; left time: 689.7418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0549016 Vali Loss: 0.0936035 Test Loss: 0.1066466\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514232\n",
      "\tspeed: 0.0628s/iter; left time: 1268.0533s\n",
      "\titers: 200, epoch: 10 | loss: 0.0512180\n",
      "\tspeed: 0.0338s/iter; left time: 680.0949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0526190 Vali Loss: 0.0929514 Test Loss: 0.1060959\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0514014\n",
      "\tspeed: 0.0625s/iter; left time: 1248.3156s\n",
      "\titers: 200, epoch: 11 | loss: 0.0494085\n",
      "\tspeed: 0.0340s/iter; left time: 675.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 223 | Train Loss: 0.0508202 Vali Loss: 0.0938980 Test Loss: 0.1071277\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0495044\n",
      "\tspeed: 0.0643s/iter; left time: 1270.2817s\n",
      "\titers: 200, epoch: 12 | loss: 0.0483764\n",
      "\tspeed: 0.0339s/iter; left time: 666.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0491536 Vali Loss: 0.0933724 Test Loss: 0.1070942\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0487324\n",
      "\tspeed: 0.0627s/iter; left time: 1224.8408s\n",
      "\titers: 200, epoch: 13 | loss: 0.0466656\n",
      "\tspeed: 0.0339s/iter; left time: 658.3644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0478594 Vali Loss: 0.0935658 Test Loss: 0.1077204\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0470098\n",
      "\tspeed: 0.0633s/iter; left time: 1221.3799s\n",
      "\titers: 200, epoch: 14 | loss: 0.0454411\n",
      "\tspeed: 0.0340s/iter; left time: 652.9709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 223 | Train Loss: 0.0467149 Vali Loss: 0.0932253 Test Loss: 0.1074122\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023433756083250046, rmse:0.15308088064193726, mae:0.10337422043085098, rse:0.44973787665367126\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:41.40s\n",
      "Intermediate time for ES: 00h:14m:52.14s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0825739\n",
      "\tspeed: 0.0440s/iter; left time: 989.1272s\n",
      "\titers: 200, epoch: 1 | loss: 0.0720544\n",
      "\tspeed: 0.0179s/iter; left time: 400.4240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 226 | Train Loss: 0.0892576 Vali Loss: 0.0763335 Test Loss: 0.0833760\n",
      "Validation loss decreased (inf --> 0.076333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0519041\n",
      "\tspeed: 0.0395s/iter; left time: 879.1817s\n",
      "\titers: 200, epoch: 2 | loss: 0.0478711\n",
      "\tspeed: 0.0180s/iter; left time: 399.4832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0525726 Vali Loss: 0.0569420 Test Loss: 0.0612847\n",
      "Validation loss decreased (0.076333 --> 0.056942).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0440858\n",
      "\tspeed: 0.0394s/iter; left time: 868.8589s\n",
      "\titers: 200, epoch: 3 | loss: 0.0461644\n",
      "\tspeed: 0.0181s/iter; left time: 397.5345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0464609 Vali Loss: 0.0550702 Test Loss: 0.0593229\n",
      "Validation loss decreased (0.056942 --> 0.055070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0446937\n",
      "\tspeed: 0.0383s/iter; left time: 834.9939s\n",
      "\titers: 200, epoch: 4 | loss: 0.0430271\n",
      "\tspeed: 0.0185s/iter; left time: 402.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0446763 Vali Loss: 0.0546017 Test Loss: 0.0593835\n",
      "Validation loss decreased (0.055070 --> 0.054602).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0449143\n",
      "\tspeed: 0.0391s/iter; left time: 845.1750s\n",
      "\titers: 200, epoch: 5 | loss: 0.0423666\n",
      "\tspeed: 0.0179s/iter; left time: 384.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0431179 Vali Loss: 0.0536028 Test Loss: 0.0577287\n",
      "Validation loss decreased (0.054602 --> 0.053603).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0447902\n",
      "\tspeed: 0.0414s/iter; left time: 884.3643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0402884\n",
      "\tspeed: 0.0179s/iter; left time: 380.7906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0419177 Vali Loss: 0.0532793 Test Loss: 0.0576561\n",
      "Validation loss decreased (0.053603 --> 0.053279).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0400641\n",
      "\tspeed: 0.0380s/iter; left time: 803.0530s\n",
      "\titers: 200, epoch: 7 | loss: 0.0413724\n",
      "\tspeed: 0.0180s/iter; left time: 377.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0406169 Vali Loss: 0.0529187 Test Loss: 0.0586069\n",
      "Validation loss decreased (0.053279 --> 0.052919).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0422125\n",
      "\tspeed: 0.0385s/iter; left time: 804.8030s\n",
      "\titers: 200, epoch: 8 | loss: 0.0390262\n",
      "\tspeed: 0.0177s/iter; left time: 368.7307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0396278 Vali Loss: 0.0532204 Test Loss: 0.0586753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0396171\n",
      "\tspeed: 0.0362s/iter; left time: 749.2150s\n",
      "\titers: 200, epoch: 9 | loss: 0.0392884\n",
      "\tspeed: 0.0178s/iter; left time: 365.5394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0383368 Vali Loss: 0.0533056 Test Loss: 0.0592961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0352243\n",
      "\tspeed: 0.0365s/iter; left time: 746.7584s\n",
      "\titers: 200, epoch: 10 | loss: 0.0382171\n",
      "\tspeed: 0.0178s/iter; left time: 361.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0371329 Vali Loss: 0.0542546 Test Loss: 0.0600371\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0372575\n",
      "\tspeed: 0.0366s/iter; left time: 741.1142s\n",
      "\titers: 200, epoch: 11 | loss: 0.0357848\n",
      "\tspeed: 0.0179s/iter; left time: 359.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0361327 Vali Loss: 0.0540272 Test Loss: 0.0606850\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0339495\n",
      "\tspeed: 0.0370s/iter; left time: 740.6702s\n",
      "\titers: 200, epoch: 12 | loss: 0.0343725\n",
      "\tspeed: 0.0178s/iter; left time: 355.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0351717 Vali Loss: 0.0541665 Test Loss: 0.0607401\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0350991\n",
      "\tspeed: 0.0367s/iter; left time: 725.8432s\n",
      "\titers: 200, epoch: 13 | loss: 0.0356509\n",
      "\tspeed: 0.0182s/iter; left time: 358.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0342767 Vali Loss: 0.0543875 Test Loss: 0.0612607\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0323812\n",
      "\tspeed: 0.0368s/iter; left time: 719.6369s\n",
      "\titers: 200, epoch: 14 | loss: 0.0324937\n",
      "\tspeed: 0.0178s/iter; left time: 347.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0336061 Vali Loss: 0.0549471 Test Loss: 0.0617569\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0328720\n",
      "\tspeed: 0.0369s/iter; left time: 712.8441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0327561\n",
      "\tspeed: 0.0177s/iter; left time: 341.1970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0329703 Vali Loss: 0.0550517 Test Loss: 0.0612711\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0303529\n",
      "\tspeed: 0.0369s/iter; left time: 705.4486s\n",
      "\titers: 200, epoch: 16 | loss: 0.0308379\n",
      "\tspeed: 0.0179s/iter; left time: 340.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0323310 Vali Loss: 0.0550910 Test Loss: 0.0609389\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0322276\n",
      "\tspeed: 0.0368s/iter; left time: 694.5076s\n",
      "\titers: 200, epoch: 17 | loss: 0.0307707\n",
      "\tspeed: 0.0177s/iter; left time: 333.4214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0318553 Vali Loss: 0.0549174 Test Loss: 0.0618004\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0108979232609272, rmse:0.1043931171298027, mae:0.05860685557126999, rse:0.4027457535266876\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0808246\n",
      "\tspeed: 0.0211s/iter; left time: 474.1064s\n",
      "\titers: 200, epoch: 1 | loss: 0.0777871\n",
      "\tspeed: 0.0188s/iter; left time: 420.6441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.0886302 Vali Loss: 0.0765412 Test Loss: 0.0835635\n",
      "Validation loss decreased (inf --> 0.076541).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0512616\n",
      "\tspeed: 0.0396s/iter; left time: 882.4648s\n",
      "\titers: 200, epoch: 2 | loss: 0.0489905\n",
      "\tspeed: 0.0178s/iter; left time: 394.5675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0525013 Vali Loss: 0.0562015 Test Loss: 0.0609805\n",
      "Validation loss decreased (0.076541 --> 0.056202).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0472980\n",
      "\tspeed: 0.0394s/iter; left time: 867.7970s\n",
      "\titers: 200, epoch: 3 | loss: 0.0457077\n",
      "\tspeed: 0.0178s/iter; left time: 391.5989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0466549 Vali Loss: 0.0544775 Test Loss: 0.0589031\n",
      "Validation loss decreased (0.056202 --> 0.054478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0453555\n",
      "\tspeed: 0.0389s/iter; left time: 849.9809s\n",
      "\titers: 200, epoch: 4 | loss: 0.0427258\n",
      "\tspeed: 0.0181s/iter; left time: 392.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0447521 Vali Loss: 0.0536225 Test Loss: 0.0581660\n",
      "Validation loss decreased (0.054478 --> 0.053622).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0439419\n",
      "\tspeed: 0.0387s/iter; left time: 836.7352s\n",
      "\titers: 200, epoch: 5 | loss: 0.0437575\n",
      "\tspeed: 0.0177s/iter; left time: 381.3332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0432652 Vali Loss: 0.0528611 Test Loss: 0.0578288\n",
      "Validation loss decreased (0.053622 --> 0.052861).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0424836\n",
      "\tspeed: 0.0397s/iter; left time: 849.0424s\n",
      "\titers: 200, epoch: 6 | loss: 0.0434853\n",
      "\tspeed: 0.0178s/iter; left time: 378.7619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0422494 Vali Loss: 0.0533285 Test Loss: 0.0580732\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412046\n",
      "\tspeed: 0.0369s/iter; left time: 781.2850s\n",
      "\titers: 200, epoch: 7 | loss: 0.0417114\n",
      "\tspeed: 0.0178s/iter; left time: 373.9462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0411409 Vali Loss: 0.0528526 Test Loss: 0.0578768\n",
      "Validation loss decreased (0.052861 --> 0.052853).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0405956\n",
      "\tspeed: 0.0383s/iter; left time: 801.0011s\n",
      "\titers: 200, epoch: 8 | loss: 0.0414334\n",
      "\tspeed: 0.0178s/iter; left time: 370.1795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0399912 Vali Loss: 0.0526390 Test Loss: 0.0583228\n",
      "Validation loss decreased (0.052853 --> 0.052639).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0392249\n",
      "\tspeed: 0.0396s/iter; left time: 819.5750s\n",
      "\titers: 200, epoch: 9 | loss: 0.0397011\n",
      "\tspeed: 0.0177s/iter; left time: 364.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0390025 Vali Loss: 0.0525965 Test Loss: 0.0577715\n",
      "Validation loss decreased (0.052639 --> 0.052597).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0352390\n",
      "\tspeed: 0.0403s/iter; left time: 825.6378s\n",
      "\titers: 200, epoch: 10 | loss: 0.0390021\n",
      "\tspeed: 0.0204s/iter; left time: 414.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0378733 Vali Loss: 0.0526242 Test Loss: 0.0583718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0355981\n",
      "\tspeed: 0.0372s/iter; left time: 752.0537s\n",
      "\titers: 200, epoch: 11 | loss: 0.0361680\n",
      "\tspeed: 0.0180s/iter; left time: 362.7102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0368099 Vali Loss: 0.0531015 Test Loss: 0.0590410\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0343426\n",
      "\tspeed: 0.0373s/iter; left time: 745.7549s\n",
      "\titers: 200, epoch: 12 | loss: 0.0386787\n",
      "\tspeed: 0.0177s/iter; left time: 352.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0359604 Vali Loss: 0.0532657 Test Loss: 0.0590416\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0358210\n",
      "\tspeed: 0.0370s/iter; left time: 732.6723s\n",
      "\titers: 200, epoch: 13 | loss: 0.0385372\n",
      "\tspeed: 0.0185s/iter; left time: 364.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0351373 Vali Loss: 0.0539517 Test Loss: 0.0593859\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0342100\n",
      "\tspeed: 0.0372s/iter; left time: 728.1848s\n",
      "\titers: 200, epoch: 14 | loss: 0.0354560\n",
      "\tspeed: 0.0180s/iter; left time: 349.6016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0343315 Vali Loss: 0.0538370 Test Loss: 0.0604549\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0339227\n",
      "\tspeed: 0.0368s/iter; left time: 712.4510s\n",
      "\titers: 200, epoch: 15 | loss: 0.0324195\n",
      "\tspeed: 0.0177s/iter; left time: 341.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0336581 Vali Loss: 0.0539099 Test Loss: 0.0599087\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0363340\n",
      "\tspeed: 0.0375s/iter; left time: 716.4222s\n",
      "\titers: 200, epoch: 16 | loss: 0.0296580\n",
      "\tspeed: 0.0178s/iter; left time: 338.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0331135 Vali Loss: 0.0539095 Test Loss: 0.0599806\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0320749\n",
      "\tspeed: 0.0379s/iter; left time: 714.9103s\n",
      "\titers: 200, epoch: 17 | loss: 0.0329088\n",
      "\tspeed: 0.0178s/iter; left time: 334.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0326186 Vali Loss: 0.0540928 Test Loss: 0.0603553\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0313287\n",
      "\tspeed: 0.0379s/iter; left time: 706.8323s\n",
      "\titers: 200, epoch: 18 | loss: 0.0325896\n",
      "\tspeed: 0.0179s/iter; left time: 331.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0321234 Vali Loss: 0.0542886 Test Loss: 0.0603496\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0324607\n",
      "\tspeed: 0.0366s/iter; left time: 674.4744s\n",
      "\titers: 200, epoch: 19 | loss: 0.0300568\n",
      "\tspeed: 0.0179s/iter; left time: 327.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0317324 Vali Loss: 0.0542460 Test Loss: 0.0601043\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010704690590500832, rmse:0.10346347838640213, mae:0.0577714666724205, rse:0.39915919303894043\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:33.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0949994\n",
      "\tspeed: 0.0456s/iter; left time: 1022.1274s\n",
      "\titers: 200, epoch: 1 | loss: 0.0818396\n",
      "\tspeed: 0.0181s/iter; left time: 404.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0984444 Vali Loss: 0.0880076 Test Loss: 0.0994513\n",
      "Validation loss decreased (inf --> 0.088008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0642481\n",
      "\tspeed: 0.0411s/iter; left time: 910.9899s\n",
      "\titers: 200, epoch: 2 | loss: 0.0622116\n",
      "\tspeed: 0.0182s/iter; left time: 400.9970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0677669 Vali Loss: 0.0737542 Test Loss: 0.0843380\n",
      "Validation loss decreased (0.088008 --> 0.073754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0635156\n",
      "\tspeed: 0.0402s/iter; left time: 883.3367s\n",
      "\titers: 200, epoch: 3 | loss: 0.0583343\n",
      "\tspeed: 0.0187s/iter; left time: 407.8178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0608415 Vali Loss: 0.0740786 Test Loss: 0.0821252\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0573911\n",
      "\tspeed: 0.0384s/iter; left time: 834.2952s\n",
      "\titers: 200, epoch: 4 | loss: 0.0538883\n",
      "\tspeed: 0.0183s/iter; left time: 396.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0571251 Vali Loss: 0.0752631 Test Loss: 0.0843270\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0542980\n",
      "\tspeed: 0.0377s/iter; left time: 811.0578s\n",
      "\titers: 200, epoch: 5 | loss: 0.0494459\n",
      "\tspeed: 0.0181s/iter; left time: 386.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0532236 Vali Loss: 0.0759761 Test Loss: 0.0854147\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0505165\n",
      "\tspeed: 0.0371s/iter; left time: 790.0507s\n",
      "\titers: 200, epoch: 6 | loss: 0.0506002\n",
      "\tspeed: 0.0183s/iter; left time: 387.8944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0501787 Vali Loss: 0.0768308 Test Loss: 0.0852290\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0480088\n",
      "\tspeed: 0.0382s/iter; left time: 804.1262s\n",
      "\titers: 200, epoch: 7 | loss: 0.0443931\n",
      "\tspeed: 0.0185s/iter; left time: 387.2987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0476712 Vali Loss: 0.0764843 Test Loss: 0.0855211\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0477575\n",
      "\tspeed: 0.0380s/iter; left time: 790.6320s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449111\n",
      "\tspeed: 0.0180s/iter; left time: 373.4726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0455909 Vali Loss: 0.0765070 Test Loss: 0.0847537\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0444669\n",
      "\tspeed: 0.0380s/iter; left time: 782.3708s\n",
      "\titers: 200, epoch: 9 | loss: 0.0466012\n",
      "\tspeed: 0.0186s/iter; left time: 381.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0438265 Vali Loss: 0.0768355 Test Loss: 0.0856286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0435193\n",
      "\tspeed: 0.0379s/iter; left time: 772.4439s\n",
      "\titers: 200, epoch: 10 | loss: 0.0399701\n",
      "\tspeed: 0.0182s/iter; left time: 368.5660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0423801 Vali Loss: 0.0769819 Test Loss: 0.0855340\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0414985\n",
      "\tspeed: 0.0377s/iter; left time: 759.6218s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408975\n",
      "\tspeed: 0.0181s/iter; left time: 363.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0411706 Vali Loss: 0.0774362 Test Loss: 0.0854421\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0397998\n",
      "\tspeed: 0.0381s/iter; left time: 759.1696s\n",
      "\titers: 200, epoch: 12 | loss: 0.0391970\n",
      "\tspeed: 0.0181s/iter; left time: 358.7041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0401057 Vali Loss: 0.0769203 Test Loss: 0.0855711\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020127102732658386, rmse:0.14187002182006836, mae:0.08433804661035538, rse:0.5487909913063049\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0942150\n",
      "\tspeed: 0.0202s/iter; left time: 453.1591s\n",
      "\titers: 200, epoch: 1 | loss: 0.0819090\n",
      "\tspeed: 0.0180s/iter; left time: 402.2137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0978670 Vali Loss: 0.0881797 Test Loss: 0.0994574\n",
      "Validation loss decreased (inf --> 0.088180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0664974\n",
      "\tspeed: 0.0413s/iter; left time: 916.2054s\n",
      "\titers: 200, epoch: 2 | loss: 0.0632625\n",
      "\tspeed: 0.0185s/iter; left time: 408.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0679474 Vali Loss: 0.0738612 Test Loss: 0.0836209\n",
      "Validation loss decreased (0.088180 --> 0.073861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0601718\n",
      "\tspeed: 0.0442s/iter; left time: 969.4626s\n",
      "\titers: 200, epoch: 3 | loss: 0.0622078\n",
      "\tspeed: 0.0184s/iter; left time: 401.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0612250 Vali Loss: 0.0731753 Test Loss: 0.0819078\n",
      "Validation loss decreased (0.073861 --> 0.073175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0579952\n",
      "\tspeed: 0.0398s/iter; left time: 865.2752s\n",
      "\titers: 200, epoch: 4 | loss: 0.0564419\n",
      "\tspeed: 0.0181s/iter; left time: 392.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0574971 Vali Loss: 0.0752813 Test Loss: 0.0844468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0572532\n",
      "\tspeed: 0.0377s/iter; left time: 810.4702s\n",
      "\titers: 200, epoch: 5 | loss: 0.0534076\n",
      "\tspeed: 0.0181s/iter; left time: 387.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0539225 Vali Loss: 0.0754249 Test Loss: 0.0834574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0501882\n",
      "\tspeed: 0.0380s/iter; left time: 808.8260s\n",
      "\titers: 200, epoch: 6 | loss: 0.0494513\n",
      "\tspeed: 0.0181s/iter; left time: 384.2060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0507724 Vali Loss: 0.0762898 Test Loss: 0.0839536\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0474354\n",
      "\tspeed: 0.0397s/iter; left time: 835.1748s\n",
      "\titers: 200, epoch: 7 | loss: 0.0489970\n",
      "\tspeed: 0.0190s/iter; left time: 397.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0482603 Vali Loss: 0.0765327 Test Loss: 0.0842737\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0459890\n",
      "\tspeed: 0.0381s/iter; left time: 793.1110s\n",
      "\titers: 200, epoch: 8 | loss: 0.0453775\n",
      "\tspeed: 0.0185s/iter; left time: 382.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0462406 Vali Loss: 0.0767720 Test Loss: 0.0844933\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0424829\n",
      "\tspeed: 0.0380s/iter; left time: 782.5921s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439030\n",
      "\tspeed: 0.0182s/iter; left time: 372.4860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0444618 Vali Loss: 0.0772027 Test Loss: 0.0855004\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0433870\n",
      "\tspeed: 0.0380s/iter; left time: 773.6652s\n",
      "\titers: 200, epoch: 10 | loss: 0.0414537\n",
      "\tspeed: 0.0183s/iter; left time: 370.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0430081 Vali Loss: 0.0774466 Test Loss: 0.0858750\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0424098\n",
      "\tspeed: 0.0394s/iter; left time: 794.0385s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408237\n",
      "\tspeed: 0.0181s/iter; left time: 362.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0417295 Vali Loss: 0.0773811 Test Loss: 0.0860263\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0397430\n",
      "\tspeed: 0.0383s/iter; left time: 763.8141s\n",
      "\titers: 200, epoch: 12 | loss: 0.0397619\n",
      "\tspeed: 0.0187s/iter; left time: 371.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0406975 Vali Loss: 0.0766426 Test Loss: 0.0861305\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0392018\n",
      "\tspeed: 0.0395s/iter; left time: 777.6916s\n",
      "\titers: 200, epoch: 13 | loss: 0.0406257\n",
      "\tspeed: 0.0182s/iter; left time: 356.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0398008 Vali Loss: 0.0765993 Test Loss: 0.0865211\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018997935578227043, rmse:0.13783299922943115, mae:0.08190777897834778, rse:0.5331746935844421\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:35.62s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0908656\n",
      "\tspeed: 0.0445s/iter; left time: 996.9496s\n",
      "\titers: 200, epoch: 1 | loss: 0.0891940\n",
      "\tspeed: 0.0186s/iter; left time: 415.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1014871 Vali Loss: 0.0917853 Test Loss: 0.1026675\n",
      "Validation loss decreased (inf --> 0.091785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0684629\n",
      "\tspeed: 0.0409s/iter; left time: 906.4908s\n",
      "\titers: 200, epoch: 2 | loss: 0.0672442\n",
      "\tspeed: 0.0185s/iter; left time: 407.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0723063 Vali Loss: 0.0782374 Test Loss: 0.0879902\n",
      "Validation loss decreased (0.091785 --> 0.078237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0619121\n",
      "\tspeed: 0.0438s/iter; left time: 961.5666s\n",
      "\titers: 200, epoch: 3 | loss: 0.0598689\n",
      "\tspeed: 0.0185s/iter; left time: 404.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0647034 Vali Loss: 0.0780730 Test Loss: 0.0865445\n",
      "Validation loss decreased (0.078237 --> 0.078073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0606524\n",
      "\tspeed: 0.0486s/iter; left time: 1056.8225s\n",
      "\titers: 200, epoch: 4 | loss: 0.0594136\n",
      "\tspeed: 0.0188s/iter; left time: 407.3998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0603122 Vali Loss: 0.0804714 Test Loss: 0.0876513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0565531\n",
      "\tspeed: 0.0382s/iter; left time: 822.2550s\n",
      "\titers: 200, epoch: 5 | loss: 0.0558551\n",
      "\tspeed: 0.0184s/iter; left time: 394.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0566340 Vali Loss: 0.0817166 Test Loss: 0.0889156\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0553974\n",
      "\tspeed: 0.0387s/iter; left time: 823.8927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0514911\n",
      "\tspeed: 0.0193s/iter; left time: 407.8428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0532845 Vali Loss: 0.0825787 Test Loss: 0.0885907\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0522775\n",
      "\tspeed: 0.0385s/iter; left time: 810.6988s\n",
      "\titers: 200, epoch: 7 | loss: 0.0490751\n",
      "\tspeed: 0.0184s/iter; left time: 385.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0506605 Vali Loss: 0.0819513 Test Loss: 0.0896498\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0481883\n",
      "\tspeed: 0.0389s/iter; left time: 811.1528s\n",
      "\titers: 200, epoch: 8 | loss: 0.0474817\n",
      "\tspeed: 0.0192s/iter; left time: 397.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0484786 Vali Loss: 0.0840234 Test Loss: 0.0901825\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0470933\n",
      "\tspeed: 0.0400s/iter; left time: 824.1000s\n",
      "\titers: 200, epoch: 9 | loss: 0.0446422\n",
      "\tspeed: 0.0185s/iter; left time: 378.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0467293 Vali Loss: 0.0832497 Test Loss: 0.0904056\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0455585\n",
      "\tspeed: 0.0399s/iter; left time: 811.9973s\n",
      "\titers: 200, epoch: 10 | loss: 0.0460681\n",
      "\tspeed: 0.0197s/iter; left time: 398.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 225 | Train Loss: 0.0453248 Vali Loss: 0.0837281 Test Loss: 0.0903833\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0434859\n",
      "\tspeed: 0.0419s/iter; left time: 845.1868s\n",
      "\titers: 200, epoch: 11 | loss: 0.0438852\n",
      "\tspeed: 0.0185s/iter; left time: 369.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0440360 Vali Loss: 0.0829143 Test Loss: 0.0909697\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0423885\n",
      "\tspeed: 0.0382s/iter; left time: 760.2230s\n",
      "\titers: 200, epoch: 12 | loss: 0.0401541\n",
      "\tspeed: 0.0184s/iter; left time: 365.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0429602 Vali Loss: 0.0840859 Test Loss: 0.0908408\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0415776\n",
      "\tspeed: 0.0390s/iter; left time: 768.8135s\n",
      "\titers: 200, epoch: 13 | loss: 0.0405993\n",
      "\tspeed: 0.0192s/iter; left time: 377.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0420540 Vali Loss: 0.0836687 Test Loss: 0.0909934\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020075254142284393, rmse:0.14168716967105865, mae:0.08654448390007019, rse:0.5487678050994873\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0945257\n",
      "\tspeed: 0.0207s/iter; left time: 463.0542s\n",
      "\titers: 200, epoch: 1 | loss: 0.0830759\n",
      "\tspeed: 0.0186s/iter; left time: 414.1154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.1009076 Vali Loss: 0.0917944 Test Loss: 0.1025656\n",
      "Validation loss decreased (inf --> 0.091794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0700706\n",
      "\tspeed: 0.0414s/iter; left time: 918.4545s\n",
      "\titers: 200, epoch: 2 | loss: 0.0660276\n",
      "\tspeed: 0.0185s/iter; left time: 408.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0723461 Vali Loss: 0.0790639 Test Loss: 0.0894321\n",
      "Validation loss decreased (0.091794 --> 0.079064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0639853\n",
      "\tspeed: 0.0431s/iter; left time: 945.4431s\n",
      "\titers: 200, epoch: 3 | loss: 0.0622231\n",
      "\tspeed: 0.0191s/iter; left time: 416.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0647785 Vali Loss: 0.0787261 Test Loss: 0.0880830\n",
      "Validation loss decreased (0.079064 --> 0.078726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630164\n",
      "\tspeed: 0.0558s/iter; left time: 1212.8221s\n",
      "\titers: 200, epoch: 4 | loss: 0.0602266\n",
      "\tspeed: 0.0184s/iter; left time: 397.8483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0603927 Vali Loss: 0.0806556 Test Loss: 0.0891107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0562662\n",
      "\tspeed: 0.0392s/iter; left time: 842.6537s\n",
      "\titers: 200, epoch: 5 | loss: 0.0541140\n",
      "\tspeed: 0.0185s/iter; left time: 395.2849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0563509 Vali Loss: 0.0811103 Test Loss: 0.0888919\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0523157\n",
      "\tspeed: 0.0392s/iter; left time: 833.0026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0513288\n",
      "\tspeed: 0.0185s/iter; left time: 391.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0530924 Vali Loss: 0.0807032 Test Loss: 0.0897623\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0500884\n",
      "\tspeed: 0.0394s/iter; left time: 829.3137s\n",
      "\titers: 200, epoch: 7 | loss: 0.0500115\n",
      "\tspeed: 0.0184s/iter; left time: 385.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0504590 Vali Loss: 0.0820986 Test Loss: 0.0894578\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0479878\n",
      "\tspeed: 0.0385s/iter; left time: 801.4588s\n",
      "\titers: 200, epoch: 8 | loss: 0.0484171\n",
      "\tspeed: 0.0185s/iter; left time: 383.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0482995 Vali Loss: 0.0821091 Test Loss: 0.0903916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0458567\n",
      "\tspeed: 0.0394s/iter; left time: 810.6843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0477157\n",
      "\tspeed: 0.0187s/iter; left time: 382.5386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0466534 Vali Loss: 0.0833053 Test Loss: 0.0899950\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0471632\n",
      "\tspeed: 0.0392s/iter; left time: 799.0429s\n",
      "\titers: 200, epoch: 10 | loss: 0.0469389\n",
      "\tspeed: 0.0185s/iter; left time: 374.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0452414 Vali Loss: 0.0830634 Test Loss: 0.0917294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0441526\n",
      "\tspeed: 0.0392s/iter; left time: 789.5945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0439629\n",
      "\tspeed: 0.0190s/iter; left time: 380.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0440587 Vali Loss: 0.0837354 Test Loss: 0.0909154\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0436273\n",
      "\tspeed: 0.0405s/iter; left time: 806.6968s\n",
      "\titers: 200, epoch: 12 | loss: 0.0430317\n",
      "\tspeed: 0.0185s/iter; left time: 366.3883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0430000 Vali Loss: 0.0836592 Test Loss: 0.0912588\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0423120\n",
      "\tspeed: 0.0397s/iter; left time: 782.0449s\n",
      "\titers: 200, epoch: 13 | loss: 0.0426837\n",
      "\tspeed: 0.0190s/iter; left time: 371.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0421225 Vali Loss: 0.0831803 Test Loss: 0.0908114\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020790696144104004, rmse:0.14418978989124298, mae:0.08808299899101257, rse:0.5584607124328613\n",
      "Intermediate time for FR and pred_len 168: 00h:02m:47.11s\n",
      "Intermediate time for FR: 00h:08m:56.14s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1186669\n",
      "\tspeed: 0.0437s/iter; left time: 982.3349s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038871\n",
      "\tspeed: 0.0177s/iter; left time: 396.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.1271104 Vali Loss: 0.0885935 Test Loss: 0.0908134\n",
      "Validation loss decreased (inf --> 0.088594).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0683111\n",
      "\tspeed: 0.0396s/iter; left time: 881.0199s\n",
      "\titers: 200, epoch: 2 | loss: 0.0647918\n",
      "\tspeed: 0.0177s/iter; left time: 392.1878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0725847 Vali Loss: 0.0627410 Test Loss: 0.0653730\n",
      "Validation loss decreased (0.088594 --> 0.062741).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0620086\n",
      "\tspeed: 0.0401s/iter; left time: 883.9944s\n",
      "\titers: 200, epoch: 3 | loss: 0.0679798\n",
      "\tspeed: 0.0178s/iter; left time: 391.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0636721 Vali Loss: 0.0587901 Test Loss: 0.0619358\n",
      "Validation loss decreased (0.062741 --> 0.058790).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620091\n",
      "\tspeed: 0.0391s/iter; left time: 853.6076s\n",
      "\titers: 200, epoch: 4 | loss: 0.0562509\n",
      "\tspeed: 0.0180s/iter; left time: 390.7383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0611027 Vali Loss: 0.0581652 Test Loss: 0.0608983\n",
      "Validation loss decreased (0.058790 --> 0.058165).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612355\n",
      "\tspeed: 0.0396s/iter; left time: 854.9812s\n",
      "\titers: 200, epoch: 5 | loss: 0.0565420\n",
      "\tspeed: 0.0177s/iter; left time: 380.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0594019 Vali Loss: 0.0568237 Test Loss: 0.0601146\n",
      "Validation loss decreased (0.058165 --> 0.056824).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579325\n",
      "\tspeed: 0.0383s/iter; left time: 818.7290s\n",
      "\titers: 200, epoch: 6 | loss: 0.0553782\n",
      "\tspeed: 0.0180s/iter; left time: 382.6175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0578790 Vali Loss: 0.0563135 Test Loss: 0.0592824\n",
      "Validation loss decreased (0.056824 --> 0.056313).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590282\n",
      "\tspeed: 0.0389s/iter; left time: 823.2705s\n",
      "\titers: 200, epoch: 7 | loss: 0.0608191\n",
      "\tspeed: 0.0177s/iter; left time: 372.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0567683 Vali Loss: 0.0565626 Test Loss: 0.0589534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0570408\n",
      "\tspeed: 0.0363s/iter; left time: 758.6925s\n",
      "\titers: 200, epoch: 8 | loss: 0.0567258\n",
      "\tspeed: 0.0178s/iter; left time: 369.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0555047 Vali Loss: 0.0565501 Test Loss: 0.0589465\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0539403\n",
      "\tspeed: 0.0378s/iter; left time: 783.1071s\n",
      "\titers: 200, epoch: 9 | loss: 0.0558067\n",
      "\tspeed: 0.0177s/iter; left time: 364.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0543611 Vali Loss: 0.0559711 Test Loss: 0.0584920\n",
      "Validation loss decreased (0.056313 --> 0.055971).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0480541\n",
      "\tspeed: 0.0391s/iter; left time: 799.4237s\n",
      "\titers: 200, epoch: 10 | loss: 0.0515454\n",
      "\tspeed: 0.0177s/iter; left time: 361.0255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0533515 Vali Loss: 0.0562107 Test Loss: 0.0589197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0505390\n",
      "\tspeed: 0.0366s/iter; left time: 740.7503s\n",
      "\titers: 200, epoch: 11 | loss: 0.0505183\n",
      "\tspeed: 0.0177s/iter; left time: 356.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0523736 Vali Loss: 0.0565854 Test Loss: 0.0583816\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0493615\n",
      "\tspeed: 0.0362s/iter; left time: 725.0631s\n",
      "\titers: 200, epoch: 12 | loss: 0.0513223\n",
      "\tspeed: 0.0176s/iter; left time: 351.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0513761 Vali Loss: 0.0566836 Test Loss: 0.0582515\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0495898\n",
      "\tspeed: 0.0363s/iter; left time: 717.7518s\n",
      "\titers: 200, epoch: 13 | loss: 0.0460916\n",
      "\tspeed: 0.0177s/iter; left time: 348.7666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0502435 Vali Loss: 0.0569636 Test Loss: 0.0586153\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0491502\n",
      "\tspeed: 0.0368s/iter; left time: 720.7901s\n",
      "\titers: 200, epoch: 14 | loss: 0.0497240\n",
      "\tspeed: 0.0177s/iter; left time: 343.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0493753 Vali Loss: 0.0566386 Test Loss: 0.0585247\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0487527\n",
      "\tspeed: 0.0360s/iter; left time: 695.8543s\n",
      "\titers: 200, epoch: 15 | loss: 0.0464090\n",
      "\tspeed: 0.0177s/iter; left time: 340.1844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0485031 Vali Loss: 0.0565502 Test Loss: 0.0588691\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0486492\n",
      "\tspeed: 0.0370s/iter; left time: 706.4464s\n",
      "\titers: 200, epoch: 16 | loss: 0.0468850\n",
      "\tspeed: 0.0176s/iter; left time: 335.2313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0476619 Vali Loss: 0.0570641 Test Loss: 0.0588286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0484204\n",
      "\tspeed: 0.0361s/iter; left time: 681.3553s\n",
      "\titers: 200, epoch: 17 | loss: 0.0457373\n",
      "\tspeed: 0.0177s/iter; left time: 332.1292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0469115 Vali Loss: 0.0571258 Test Loss: 0.0593243\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0459390\n",
      "\tspeed: 0.0377s/iter; left time: 704.2634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0463988\n",
      "\tspeed: 0.0177s/iter; left time: 328.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0463835 Vali Loss: 0.0574036 Test Loss: 0.0591414\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0449952\n",
      "\tspeed: 0.0376s/iter; left time: 693.2720s\n",
      "\titers: 200, epoch: 19 | loss: 0.0478959\n",
      "\tspeed: 0.0178s/iter; left time: 326.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0457615 Vali Loss: 0.0572451 Test Loss: 0.0597154\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010480063036084175, rmse:0.1023721769452095, mae:0.058492016047239304, rse:0.38681402802467346\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1183293\n",
      "\tspeed: 0.0199s/iter; left time: 446.9918s\n",
      "\titers: 200, epoch: 1 | loss: 0.1023478\n",
      "\tspeed: 0.0182s/iter; left time: 408.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.1252369 Vali Loss: 0.0887429 Test Loss: 0.0913487\n",
      "Validation loss decreased (inf --> 0.088743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0721573\n",
      "\tspeed: 0.0391s/iter; left time: 870.0501s\n",
      "\titers: 200, epoch: 2 | loss: 0.0695804\n",
      "\tspeed: 0.0188s/iter; left time: 417.3505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0725251 Vali Loss: 0.0620892 Test Loss: 0.0651353\n",
      "Validation loss decreased (0.088743 --> 0.062089).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0637120\n",
      "\tspeed: 0.0395s/iter; left time: 870.4122s\n",
      "\titers: 200, epoch: 3 | loss: 0.0642457\n",
      "\tspeed: 0.0177s/iter; left time: 387.5393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0637578 Vali Loss: 0.0588995 Test Loss: 0.0622270\n",
      "Validation loss decreased (0.062089 --> 0.058899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0622228\n",
      "\tspeed: 0.0378s/iter; left time: 825.3745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0597051\n",
      "\tspeed: 0.0177s/iter; left time: 383.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0611976 Vali Loss: 0.0583031 Test Loss: 0.0612591\n",
      "Validation loss decreased (0.058899 --> 0.058303).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0569705\n",
      "\tspeed: 0.0424s/iter; left time: 915.5773s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624648\n",
      "\tspeed: 0.0178s/iter; left time: 381.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0594146 Vali Loss: 0.0572613 Test Loss: 0.0605500\n",
      "Validation loss decreased (0.058303 --> 0.057261).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0574250\n",
      "\tspeed: 0.0397s/iter; left time: 848.6427s\n",
      "\titers: 200, epoch: 6 | loss: 0.0574117\n",
      "\tspeed: 0.0176s/iter; left time: 374.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0580177 Vali Loss: 0.0570326 Test Loss: 0.0598851\n",
      "Validation loss decreased (0.057261 --> 0.057033).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562002\n",
      "\tspeed: 0.0383s/iter; left time: 809.9356s\n",
      "\titers: 200, epoch: 7 | loss: 0.0591149\n",
      "\tspeed: 0.0184s/iter; left time: 387.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0568774 Vali Loss: 0.0560135 Test Loss: 0.0586588\n",
      "Validation loss decreased (0.057033 --> 0.056013).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0573453\n",
      "\tspeed: 0.0382s/iter; left time: 798.0599s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589271\n",
      "\tspeed: 0.0178s/iter; left time: 371.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0557198 Vali Loss: 0.0562147 Test Loss: 0.0584597\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0532231\n",
      "\tspeed: 0.0377s/iter; left time: 781.0276s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533374\n",
      "\tspeed: 0.0180s/iter; left time: 369.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0546067 Vali Loss: 0.0557521 Test Loss: 0.0584721\n",
      "Validation loss decreased (0.056013 --> 0.055752).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0554328\n",
      "\tspeed: 0.0385s/iter; left time: 787.5572s\n",
      "\titers: 200, epoch: 10 | loss: 0.0529305\n",
      "\tspeed: 0.0177s/iter; left time: 359.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0534864 Vali Loss: 0.0556840 Test Loss: 0.0580632\n",
      "Validation loss decreased (0.055752 --> 0.055684).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0490568\n",
      "\tspeed: 0.0381s/iter; left time: 772.0579s\n",
      "\titers: 200, epoch: 11 | loss: 0.0579109\n",
      "\tspeed: 0.0181s/iter; left time: 364.4441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0524901 Vali Loss: 0.0556808 Test Loss: 0.0582837\n",
      "Validation loss decreased (0.055684 --> 0.055681).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0545119\n",
      "\tspeed: 0.0384s/iter; left time: 769.3993s\n",
      "\titers: 200, epoch: 12 | loss: 0.0526492\n",
      "\tspeed: 0.0177s/iter; left time: 351.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0515282 Vali Loss: 0.0556845 Test Loss: 0.0587237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0512061\n",
      "\tspeed: 0.0370s/iter; left time: 731.6856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0485435\n",
      "\tspeed: 0.0177s/iter; left time: 348.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0505559 Vali Loss: 0.0561550 Test Loss: 0.0583473\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0505487\n",
      "\tspeed: 0.0368s/iter; left time: 719.7775s\n",
      "\titers: 200, epoch: 14 | loss: 0.0488571\n",
      "\tspeed: 0.0179s/iter; left time: 349.1453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0496760 Vali Loss: 0.0567544 Test Loss: 0.0589902\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0486834\n",
      "\tspeed: 0.0374s/iter; left time: 722.9436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0485694\n",
      "\tspeed: 0.0177s/iter; left time: 340.2375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0489163 Vali Loss: 0.0564030 Test Loss: 0.0587402\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0472454\n",
      "\tspeed: 0.0367s/iter; left time: 700.4890s\n",
      "\titers: 200, epoch: 16 | loss: 0.0488778\n",
      "\tspeed: 0.0177s/iter; left time: 336.0587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0480489 Vali Loss: 0.0567949 Test Loss: 0.0590802\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0461510\n",
      "\tspeed: 0.0385s/iter; left time: 727.4193s\n",
      "\titers: 200, epoch: 17 | loss: 0.0470704\n",
      "\tspeed: 0.0194s/iter; left time: 364.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0474308 Vali Loss: 0.0565297 Test Loss: 0.0589807\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0475236\n",
      "\tspeed: 0.0371s/iter; left time: 692.2523s\n",
      "\titers: 200, epoch: 18 | loss: 0.0432625\n",
      "\tspeed: 0.0176s/iter; left time: 327.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0467678 Vali Loss: 0.0568878 Test Loss: 0.0593559\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0432556\n",
      "\tspeed: 0.0365s/iter; left time: 673.2113s\n",
      "\titers: 200, epoch: 19 | loss: 0.0448248\n",
      "\tspeed: 0.0179s/iter; left time: 328.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0461628 Vali Loss: 0.0567260 Test Loss: 0.0594797\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0493075\n",
      "\tspeed: 0.0376s/iter; left time: 684.2777s\n",
      "\titers: 200, epoch: 20 | loss: 0.0476661\n",
      "\tspeed: 0.0177s/iter; left time: 319.8866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0458511 Vali Loss: 0.0567330 Test Loss: 0.0594195\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0462077\n",
      "\tspeed: 0.0365s/iter; left time: 656.7331s\n",
      "\titers: 200, epoch: 21 | loss: 0.0431399\n",
      "\tspeed: 0.0177s/iter; left time: 316.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0453313 Vali Loss: 0.0569593 Test Loss: 0.0592954\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010335121303796768, rmse:0.1016618013381958, mae:0.058283690363168716, rse:0.3841298818588257\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:54.81s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1310730\n",
      "\tspeed: 0.0441s/iter; left time: 988.4177s\n",
      "\titers: 200, epoch: 1 | loss: 0.1159046\n",
      "\tspeed: 0.0181s/iter; left time: 402.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.1386889 Vali Loss: 0.1017228 Test Loss: 0.1046455\n",
      "Validation loss decreased (inf --> 0.101723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0922018\n",
      "\tspeed: 0.0404s/iter; left time: 895.4513s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875287\n",
      "\tspeed: 0.0180s/iter; left time: 398.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0913242 Vali Loss: 0.0810804 Test Loss: 0.0859926\n",
      "Validation loss decreased (0.101723 --> 0.081080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0851930\n",
      "\tspeed: 0.0403s/iter; left time: 884.8194s\n",
      "\titers: 200, epoch: 3 | loss: 0.0848009\n",
      "\tspeed: 0.0181s/iter; left time: 396.1145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0831508 Vali Loss: 0.0784393 Test Loss: 0.0841096\n",
      "Validation loss decreased (0.081080 --> 0.078439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810510\n",
      "\tspeed: 0.0400s/iter; left time: 868.2449s\n",
      "\titers: 200, epoch: 4 | loss: 0.0782053\n",
      "\tspeed: 0.0180s/iter; left time: 389.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0795676 Vali Loss: 0.0784156 Test Loss: 0.0839126\n",
      "Validation loss decreased (0.078439 --> 0.078416).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0816101\n",
      "\tspeed: 0.0390s/iter; left time: 839.4009s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721341\n",
      "\tspeed: 0.0180s/iter; left time: 385.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0762387 Vali Loss: 0.0790260 Test Loss: 0.0830072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0740837\n",
      "\tspeed: 0.0371s/iter; left time: 789.8721s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762524\n",
      "\tspeed: 0.0187s/iter; left time: 395.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0728276 Vali Loss: 0.0801343 Test Loss: 0.0841383\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0702368\n",
      "\tspeed: 0.0367s/iter; left time: 773.1533s\n",
      "\titers: 200, epoch: 7 | loss: 0.0654386\n",
      "\tspeed: 0.0181s/iter; left time: 378.4053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0698180 Vali Loss: 0.0802404 Test Loss: 0.0828267\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0711698\n",
      "\tspeed: 0.0373s/iter; left time: 776.2859s\n",
      "\titers: 200, epoch: 8 | loss: 0.0639507\n",
      "\tspeed: 0.0180s/iter; left time: 374.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0670037 Vali Loss: 0.0815448 Test Loss: 0.0840982\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0627414\n",
      "\tspeed: 0.0377s/iter; left time: 776.9450s\n",
      "\titers: 200, epoch: 9 | loss: 0.0609370\n",
      "\tspeed: 0.0181s/iter; left time: 370.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0644941 Vali Loss: 0.0811407 Test Loss: 0.0839700\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0619954\n",
      "\tspeed: 0.0373s/iter; left time: 760.0455s\n",
      "\titers: 200, epoch: 10 | loss: 0.0627662\n",
      "\tspeed: 0.0182s/iter; left time: 369.9898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0622920 Vali Loss: 0.0826805 Test Loss: 0.0853803\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642111\n",
      "\tspeed: 0.0370s/iter; left time: 745.9526s\n",
      "\titers: 200, epoch: 11 | loss: 0.0608653\n",
      "\tspeed: 0.0181s/iter; left time: 363.4407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0603079 Vali Loss: 0.0826404 Test Loss: 0.0851099\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0570892\n",
      "\tspeed: 0.0370s/iter; left time: 737.3791s\n",
      "\titers: 200, epoch: 12 | loss: 0.0618150\n",
      "\tspeed: 0.0180s/iter; left time: 357.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0586184 Vali Loss: 0.0831143 Test Loss: 0.0854465\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0575813\n",
      "\tspeed: 0.0384s/iter; left time: 756.6247s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571408\n",
      "\tspeed: 0.0191s/iter; left time: 374.3883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0572359 Vali Loss: 0.0832216 Test Loss: 0.0854676\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0556617\n",
      "\tspeed: 0.0372s/iter; left time: 723.8908s\n",
      "\titers: 200, epoch: 14 | loss: 0.0540459\n",
      "\tspeed: 0.0182s/iter; left time: 353.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0558948 Vali Loss: 0.0837388 Test Loss: 0.0862194\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01954498514533043, rmse:0.13980337977409363, mae:0.08391264081001282, rse:0.5286116600036621\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1263471\n",
      "\tspeed: 0.0199s/iter; left time: 444.9298s\n",
      "\titers: 200, epoch: 1 | loss: 0.1159365\n",
      "\tspeed: 0.0182s/iter; left time: 404.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.1380923 Vali Loss: 0.1020415 Test Loss: 0.1047741\n",
      "Validation loss decreased (inf --> 0.102042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0909317\n",
      "\tspeed: 0.0410s/iter; left time: 908.6552s\n",
      "\titers: 200, epoch: 2 | loss: 0.0883571\n",
      "\tspeed: 0.0184s/iter; left time: 407.2738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0914261 Vali Loss: 0.0803037 Test Loss: 0.0852146\n",
      "Validation loss decreased (0.102042 --> 0.080304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0859512\n",
      "\tspeed: 0.0417s/iter; left time: 914.5156s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811047\n",
      "\tspeed: 0.0181s/iter; left time: 395.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0831277 Vali Loss: 0.0784896 Test Loss: 0.0827625\n",
      "Validation loss decreased (0.080304 --> 0.078490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0767060\n",
      "\tspeed: 0.0399s/iter; left time: 867.1353s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806868\n",
      "\tspeed: 0.0180s/iter; left time: 389.6694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0796888 Vali Loss: 0.0783908 Test Loss: 0.0829460\n",
      "Validation loss decreased (0.078490 --> 0.078391).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0777936\n",
      "\tspeed: 0.0400s/iter; left time: 859.3647s\n",
      "\titers: 200, epoch: 5 | loss: 0.0772324\n",
      "\tspeed: 0.0180s/iter; left time: 385.5814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0760393 Vali Loss: 0.0800801 Test Loss: 0.0835676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0714719\n",
      "\tspeed: 0.0381s/iter; left time: 809.8240s\n",
      "\titers: 200, epoch: 6 | loss: 0.0720436\n",
      "\tspeed: 0.0184s/iter; left time: 390.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0725466 Vali Loss: 0.0804555 Test Loss: 0.0829974\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0696251\n",
      "\tspeed: 0.0378s/iter; left time: 794.7793s\n",
      "\titers: 200, epoch: 7 | loss: 0.0676035\n",
      "\tspeed: 0.0182s/iter; left time: 381.2569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0692073 Vali Loss: 0.0817006 Test Loss: 0.0846338\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0691494\n",
      "\tspeed: 0.0382s/iter; left time: 796.2091s\n",
      "\titers: 200, epoch: 8 | loss: 0.0647662\n",
      "\tspeed: 0.0180s/iter; left time: 373.8621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0662966 Vali Loss: 0.0818667 Test Loss: 0.0849675\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0623415\n",
      "\tspeed: 0.0374s/iter; left time: 770.5469s\n",
      "\titers: 200, epoch: 9 | loss: 0.0608835\n",
      "\tspeed: 0.0181s/iter; left time: 372.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0637759 Vali Loss: 0.0822691 Test Loss: 0.0853241\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0635078\n",
      "\tspeed: 0.0382s/iter; left time: 778.6474s\n",
      "\titers: 200, epoch: 10 | loss: 0.0581507\n",
      "\tspeed: 0.0181s/iter; left time: 366.2177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0615833 Vali Loss: 0.0827696 Test Loss: 0.0859685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0572104\n",
      "\tspeed: 0.0378s/iter; left time: 761.9479s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578615\n",
      "\tspeed: 0.0183s/iter; left time: 367.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0598117 Vali Loss: 0.0834219 Test Loss: 0.0876955\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567229\n",
      "\tspeed: 0.0373s/iter; left time: 743.5879s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560101\n",
      "\tspeed: 0.0181s/iter; left time: 358.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0581680 Vali Loss: 0.0832148 Test Loss: 0.0870609\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0569095\n",
      "\tspeed: 0.0401s/iter; left time: 790.2327s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528492\n",
      "\tspeed: 0.0182s/iter; left time: 356.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0568319 Vali Loss: 0.0832953 Test Loss: 0.0874218\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0592510\n",
      "\tspeed: 0.0389s/iter; left time: 757.8687s\n",
      "\titers: 200, epoch: 14 | loss: 0.0547856\n",
      "\tspeed: 0.0185s/iter; left time: 358.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0558380 Vali Loss: 0.0831213 Test Loss: 0.0874076\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01917097717523575, rmse:0.13845929503440857, mae:0.08294600993394852, rse:0.5235295295715332\n",
      "Intermediate time for IT and pred_len 96: 00h:02m:50.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1275234\n",
      "\tspeed: 0.0489s/iter; left time: 1095.7558s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189954\n",
      "\tspeed: 0.0184s/iter; left time: 410.1009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.1412950 Vali Loss: 0.1040635 Test Loss: 0.1070162\n",
      "Validation loss decreased (inf --> 0.104064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964050\n",
      "\tspeed: 0.0446s/iter; left time: 988.6547s\n",
      "\titers: 200, epoch: 2 | loss: 0.0886111\n",
      "\tspeed: 0.0186s/iter; left time: 411.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0955518 Vali Loss: 0.0854652 Test Loss: 0.0895273\n",
      "Validation loss decreased (0.104064 --> 0.085465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0866833\n",
      "\tspeed: 0.0403s/iter; left time: 884.2453s\n",
      "\titers: 200, epoch: 3 | loss: 0.0814698\n",
      "\tspeed: 0.0184s/iter; left time: 401.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0871050 Vali Loss: 0.0848689 Test Loss: 0.0877781\n",
      "Validation loss decreased (0.085465 --> 0.084869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0808554\n",
      "\tspeed: 0.0399s/iter; left time: 867.7698s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826341\n",
      "\tspeed: 0.0184s/iter; left time: 398.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0828756 Vali Loss: 0.0852374 Test Loss: 0.0874300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791364\n",
      "\tspeed: 0.0395s/iter; left time: 849.4162s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785064\n",
      "\tspeed: 0.0188s/iter; left time: 402.0365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0790885 Vali Loss: 0.0861373 Test Loss: 0.0885819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774719\n",
      "\tspeed: 0.0388s/iter; left time: 826.0458s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751552\n",
      "\tspeed: 0.0185s/iter; left time: 391.8285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0760913 Vali Loss: 0.0866237 Test Loss: 0.0889733\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0741134\n",
      "\tspeed: 0.0385s/iter; left time: 811.0575s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721804\n",
      "\tspeed: 0.0184s/iter; left time: 385.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0732284 Vali Loss: 0.0865928 Test Loss: 0.0902340\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724975\n",
      "\tspeed: 0.0382s/iter; left time: 795.6113s\n",
      "\titers: 200, epoch: 8 | loss: 0.0668545\n",
      "\tspeed: 0.0187s/iter; left time: 388.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0703631 Vali Loss: 0.0864248 Test Loss: 0.0899004\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0685533\n",
      "\tspeed: 0.0388s/iter; left time: 799.9027s\n",
      "\titers: 200, epoch: 9 | loss: 0.0653959\n",
      "\tspeed: 0.0185s/iter; left time: 378.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0678736 Vali Loss: 0.0872525 Test Loss: 0.0919391\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666165\n",
      "\tspeed: 0.0386s/iter; left time: 787.0395s\n",
      "\titers: 200, epoch: 10 | loss: 0.0637973\n",
      "\tspeed: 0.0184s/iter; left time: 372.3653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0657089 Vali Loss: 0.0874528 Test Loss: 0.0922164\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0632579\n",
      "\tspeed: 0.0385s/iter; left time: 775.3910s\n",
      "\titers: 200, epoch: 11 | loss: 0.0619213\n",
      "\tspeed: 0.0184s/iter; left time: 369.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0639057 Vali Loss: 0.0867941 Test Loss: 0.0914731\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0624109\n",
      "\tspeed: 0.0389s/iter; left time: 774.8493s\n",
      "\titers: 200, epoch: 12 | loss: 0.0628552\n",
      "\tspeed: 0.0188s/iter; left time: 372.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0624616 Vali Loss: 0.0871244 Test Loss: 0.0930709\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0590759\n",
      "\tspeed: 0.0386s/iter; left time: 760.5655s\n",
      "\titers: 200, epoch: 13 | loss: 0.0594228\n",
      "\tspeed: 0.0184s/iter; left time: 360.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0609735 Vali Loss: 0.0873015 Test Loss: 0.0925411\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02027822844684124, rmse:0.14240165054798126, mae:0.0877780169248581, rse:0.5389363169670105\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1299536\n",
      "\tspeed: 0.0203s/iter; left time: 454.0323s\n",
      "\titers: 200, epoch: 1 | loss: 0.1161951\n",
      "\tspeed: 0.0184s/iter; left time: 410.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.1414682 Vali Loss: 0.1044085 Test Loss: 0.1074294\n",
      "Validation loss decreased (inf --> 0.104409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0972994\n",
      "\tspeed: 0.0414s/iter; left time: 918.8161s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901106\n",
      "\tspeed: 0.0184s/iter; left time: 406.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0957896 Vali Loss: 0.0854568 Test Loss: 0.0893396\n",
      "Validation loss decreased (0.104409 --> 0.085457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0885999\n",
      "\tspeed: 0.0417s/iter; left time: 915.1863s\n",
      "\titers: 200, epoch: 3 | loss: 0.0868260\n",
      "\tspeed: 0.0189s/iter; left time: 414.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0873431 Vali Loss: 0.0845915 Test Loss: 0.0883179\n",
      "Validation loss decreased (0.085457 --> 0.084591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0882138\n",
      "\tspeed: 0.0415s/iter; left time: 901.0840s\n",
      "\titers: 200, epoch: 4 | loss: 0.0833410\n",
      "\tspeed: 0.0188s/iter; left time: 406.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0834392 Vali Loss: 0.0851915 Test Loss: 0.0894194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0792511\n",
      "\tspeed: 0.0394s/iter; left time: 846.8447s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755284\n",
      "\tspeed: 0.0187s/iter; left time: 400.5799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0796267 Vali Loss: 0.0848287 Test Loss: 0.0895064\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0772265\n",
      "\tspeed: 0.0386s/iter; left time: 820.3110s\n",
      "\titers: 200, epoch: 6 | loss: 0.0731446\n",
      "\tspeed: 0.0184s/iter; left time: 389.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0765081 Vali Loss: 0.0859261 Test Loss: 0.0894576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0733916\n",
      "\tspeed: 0.0391s/iter; left time: 822.9563s\n",
      "\titers: 200, epoch: 7 | loss: 0.0741833\n",
      "\tspeed: 0.0184s/iter; left time: 386.3229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0736420 Vali Loss: 0.0860845 Test Loss: 0.0922697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725332\n",
      "\tspeed: 0.0392s/iter; left time: 815.8906s\n",
      "\titers: 200, epoch: 8 | loss: 0.0704023\n",
      "\tspeed: 0.0184s/iter; left time: 380.7749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0709409 Vali Loss: 0.0858436 Test Loss: 0.0913357\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673422\n",
      "\tspeed: 0.0397s/iter; left time: 817.1669s\n",
      "\titers: 200, epoch: 9 | loss: 0.0649461\n",
      "\tspeed: 0.0186s/iter; left time: 381.4714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0682619 Vali Loss: 0.0864067 Test Loss: 0.0929804\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666464\n",
      "\tspeed: 0.0399s/iter; left time: 812.7487s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675855\n",
      "\tspeed: 0.0185s/iter; left time: 374.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0661923 Vali Loss: 0.0862028 Test Loss: 0.0925525\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0661159\n",
      "\tspeed: 0.0393s/iter; left time: 792.4639s\n",
      "\titers: 200, epoch: 11 | loss: 0.0636477\n",
      "\tspeed: 0.0185s/iter; left time: 371.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0644045 Vali Loss: 0.0867072 Test Loss: 0.0929461\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0620243\n",
      "\tspeed: 0.0391s/iter; left time: 779.0745s\n",
      "\titers: 200, epoch: 12 | loss: 0.0625289\n",
      "\tspeed: 0.0184s/iter; left time: 363.8933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0629564 Vali Loss: 0.0861273 Test Loss: 0.0923139\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0624796\n",
      "\tspeed: 0.0387s/iter; left time: 762.3120s\n",
      "\titers: 200, epoch: 13 | loss: 0.0605377\n",
      "\tspeed: 0.0184s/iter; left time: 360.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0615932 Vali Loss: 0.0867980 Test Loss: 0.0913889\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020756619051098824, rmse:0.1440715789794922, mae:0.08831792324781418, rse:0.5452563762664795\n",
      "Intermediate time for IT and pred_len 168: 00h:02m:43.78s\n",
      "Intermediate time for IT: 00h:09m:29.43s\n",
      "Total time: 01h:17m:10.27s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_MIX_FEATURES.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len = 336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.0834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0264  0.1626  0.1055\n",
       "        96        0.0448  0.2117  0.1447\n",
       "        168       0.0443  0.2104  0.1441\n",
       "ES      24        0.0115  0.1071  0.0677\n",
       "        96        0.0216  0.1469  0.0970\n",
       "        168       0.0236  0.1538  0.1034\n",
       "FR      24        0.0108  0.1039  0.0582\n",
       "        96        0.0196  0.1399  0.0831\n",
       "        168       0.0204  0.1429  0.0873\n",
       "GB      24        0.0289  0.1699  0.1154\n",
       "        96        0.0435  0.2085  0.1452\n",
       "        168       0.0456  0.2135  0.1499\n",
       "IT      24        0.0104  0.1020  0.0584\n",
       "        96        0.0194  0.1391  0.0834\n",
       "        168       0.0205  0.1432  0.0880"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_MIX_FEATURES.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0766317\n",
      "\tspeed: 0.1594s/iter; left time: 704.8764s\n",
      "\titers: 200, epoch: 1 | loss: 0.0695265\n",
      "\tspeed: 0.1316s/iter; left time: 568.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.51s\n",
      "Steps: 226 | Train Loss: 0.0817155 Vali Loss: 0.0705644 Test Loss: 0.0732726\n",
      "Validation loss decreased (inf --> 0.070564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0562303\n",
      "\tspeed: 0.2236s/iter; left time: 938.0175s\n",
      "\titers: 200, epoch: 2 | loss: 0.0503308\n",
      "\tspeed: 0.1293s/iter; left time: 529.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.42s\n",
      "Steps: 226 | Train Loss: 0.0548762 Vali Loss: 0.0606296 Test Loss: 0.0633584\n",
      "Validation loss decreased (0.070564 --> 0.060630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0513493\n",
      "\tspeed: 0.2205s/iter; left time: 875.1299s\n",
      "\titers: 200, epoch: 3 | loss: 0.0548947\n",
      "\tspeed: 0.1285s/iter; left time: 497.1762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 226 | Train Loss: 0.0505532 Vali Loss: 0.0587098 Test Loss: 0.0624320\n",
      "Validation loss decreased (0.060630 --> 0.058710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0527826\n",
      "\tspeed: 0.2214s/iter; left time: 828.5555s\n",
      "\titers: 200, epoch: 4 | loss: 0.0514440\n",
      "\tspeed: 0.1308s/iter; left time: 476.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.41s\n",
      "Steps: 226 | Train Loss: 0.0490150 Vali Loss: 0.0584218 Test Loss: 0.0620288\n",
      "Validation loss decreased (0.058710 --> 0.058422).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0478798\n",
      "\tspeed: 0.2201s/iter; left time: 773.9429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0479713\n",
      "\tspeed: 0.1288s/iter; left time: 440.2405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.33s\n",
      "Steps: 226 | Train Loss: 0.0479430 Vali Loss: 0.0563894 Test Loss: 0.0599632\n",
      "Validation loss decreased (0.058422 --> 0.056389).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0510816\n",
      "\tspeed: 0.2214s/iter; left time: 728.4802s\n",
      "\titers: 200, epoch: 6 | loss: 0.0462048\n",
      "\tspeed: 0.1288s/iter; left time: 410.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.50s\n",
      "Steps: 226 | Train Loss: 0.0474372 Vali Loss: 0.0566435 Test Loss: 0.0606992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0459774\n",
      "\tspeed: 0.2215s/iter; left time: 679.0356s\n",
      "\titers: 200, epoch: 7 | loss: 0.0513296\n",
      "\tspeed: 0.1256s/iter; left time: 372.4693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.97s\n",
      "Steps: 226 | Train Loss: 0.0469073 Vali Loss: 0.0559441 Test Loss: 0.0600186\n",
      "Validation loss decreased (0.056389 --> 0.055944).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0457944\n",
      "\tspeed: 0.2160s/iter; left time: 613.3527s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448213\n",
      "\tspeed: 0.1306s/iter; left time: 357.7047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.20s\n",
      "Steps: 226 | Train Loss: 0.0464634 Vali Loss: 0.0558273 Test Loss: 0.0593858\n",
      "Validation loss decreased (0.055944 --> 0.055827).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0463735\n",
      "\tspeed: 0.2207s/iter; left time: 576.7132s\n",
      "\titers: 200, epoch: 9 | loss: 0.0489007\n",
      "\tspeed: 0.1280s/iter; left time: 321.7713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.29s\n",
      "Steps: 226 | Train Loss: 0.0461754 Vali Loss: 0.0556516 Test Loss: 0.0595443\n",
      "Validation loss decreased (0.055827 --> 0.055652).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0466776\n",
      "\tspeed: 0.2180s/iter; left time: 520.3154s\n",
      "\titers: 200, epoch: 10 | loss: 0.0459872\n",
      "\tspeed: 0.1278s/iter; left time: 292.3615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.21s\n",
      "Steps: 226 | Train Loss: 0.0457334 Vali Loss: 0.0548611 Test Loss: 0.0585909\n",
      "Validation loss decreased (0.055652 --> 0.054861).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0433881\n",
      "\tspeed: 0.2203s/iter; left time: 476.1144s\n",
      "\titers: 200, epoch: 11 | loss: 0.0430847\n",
      "\tspeed: 0.1303s/iter; left time: 268.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.64s\n",
      "Steps: 226 | Train Loss: 0.0453992 Vali Loss: 0.0553987 Test Loss: 0.0589465\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0467320\n",
      "\tspeed: 0.2355s/iter; left time: 455.6640s\n",
      "\titers: 200, epoch: 12 | loss: 0.0414491\n",
      "\tspeed: 0.1276s/iter; left time: 234.2293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.63s\n",
      "Steps: 226 | Train Loss: 0.0452521 Vali Loss: 0.0548284 Test Loss: 0.0586648\n",
      "Validation loss decreased (0.054861 --> 0.054828).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0455686\n",
      "\tspeed: 0.2175s/iter; left time: 371.7388s\n",
      "\titers: 200, epoch: 13 | loss: 0.0478617\n",
      "\tspeed: 0.1292s/iter; left time: 207.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 226 | Train Loss: 0.0450395 Vali Loss: 0.0549135 Test Loss: 0.0585464\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0442970\n",
      "\tspeed: 0.2223s/iter; left time: 329.6137s\n",
      "\titers: 200, epoch: 14 | loss: 0.0503605\n",
      "\tspeed: 0.1325s/iter; left time: 183.2741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.95s\n",
      "Steps: 226 | Train Loss: 0.0447735 Vali Loss: 0.0546823 Test Loss: 0.0583076\n",
      "Validation loss decreased (0.054828 --> 0.054682).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0424463\n",
      "\tspeed: 0.2271s/iter; left time: 285.4459s\n",
      "\titers: 200, epoch: 15 | loss: 0.0444540\n",
      "\tspeed: 0.1271s/iter; left time: 147.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 226 | Train Loss: 0.0446773 Vali Loss: 0.0546821 Test Loss: 0.0582906\n",
      "Validation loss decreased (0.054682 --> 0.054682).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0437147\n",
      "\tspeed: 0.2197s/iter; left time: 226.5216s\n",
      "\titers: 200, epoch: 16 | loss: 0.0457383\n",
      "\tspeed: 0.1265s/iter; left time: 117.7277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:29.24s\n",
      "Steps: 226 | Train Loss: 0.0444284 Vali Loss: 0.0544112 Test Loss: 0.0578407\n",
      "Validation loss decreased (0.054682 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0409016\n",
      "\tspeed: 0.2172s/iter; left time: 174.8492s\n",
      "\titers: 200, epoch: 17 | loss: 0.0478386\n",
      "\tspeed: 0.1298s/iter; left time: 91.5071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.49s\n",
      "Steps: 226 | Train Loss: 0.0443060 Vali Loss: 0.0542591 Test Loss: 0.0578918\n",
      "Validation loss decreased (0.054411 --> 0.054259).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0443076\n",
      "\tspeed: 0.2171s/iter; left time: 125.7041s\n",
      "\titers: 200, epoch: 18 | loss: 0.0450188\n",
      "\tspeed: 0.1293s/iter; left time: 61.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 226 | Train Loss: 0.0441691 Vali Loss: 0.0540334 Test Loss: 0.0580545\n",
      "Validation loss decreased (0.054259 --> 0.054033).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0454062\n",
      "\tspeed: 0.2185s/iter; left time: 77.1218s\n",
      "\titers: 200, epoch: 19 | loss: 0.0424051\n",
      "\tspeed: 0.1292s/iter; left time: 32.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.50s\n",
      "Steps: 226 | Train Loss: 0.0440228 Vali Loss: 0.0539079 Test Loss: 0.0574121\n",
      "Validation loss decreased (0.054033 --> 0.053908).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0425628\n",
      "\tspeed: 0.2249s/iter; left time: 28.5604s\n",
      "\titers: 200, epoch: 20 | loss: 0.0424072\n",
      "\tspeed: 0.1289s/iter; left time: 3.4791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.57s\n",
      "Steps: 226 | Train Loss: 0.0439709 Vali Loss: 0.0540611 Test Loss: 0.0577443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010757667943835258, rmse:0.10371917486190796, mae:0.057412099093198776, rse:0.4001457095146179\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0778962\n",
      "\tspeed: 0.1302s/iter; left time: 575.4611s\n",
      "\titers: 200, epoch: 1 | loss: 0.0747243\n",
      "\tspeed: 0.1281s/iter; left time: 553.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.17s\n",
      "Steps: 226 | Train Loss: 0.0831907 Vali Loss: 0.0704090 Test Loss: 0.0729090\n",
      "Validation loss decreased (inf --> 0.070409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0543477\n",
      "\tspeed: 0.2208s/iter; left time: 926.2374s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524221\n",
      "\tspeed: 0.1277s/iter; left time: 523.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.06s\n",
      "Steps: 226 | Train Loss: 0.0553467 Vali Loss: 0.0607321 Test Loss: 0.0636736\n",
      "Validation loss decreased (0.070409 --> 0.060732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0470920\n",
      "\tspeed: 0.2191s/iter; left time: 869.6660s\n",
      "\titers: 200, epoch: 3 | loss: 0.0494604\n",
      "\tspeed: 0.1267s/iter; left time: 490.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.01s\n",
      "Steps: 226 | Train Loss: 0.0507888 Vali Loss: 0.0581976 Test Loss: 0.0614593\n",
      "Validation loss decreased (0.060732 --> 0.058198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0472974\n",
      "\tspeed: 0.2199s/iter; left time: 823.1736s\n",
      "\titers: 200, epoch: 4 | loss: 0.0468269\n",
      "\tspeed: 0.1290s/iter; left time: 469.9367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.37s\n",
      "Steps: 226 | Train Loss: 0.0489967 Vali Loss: 0.0577703 Test Loss: 0.0621285\n",
      "Validation loss decreased (0.058198 --> 0.057770).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0490690\n",
      "\tspeed: 0.2222s/iter; left time: 781.3646s\n",
      "\titers: 200, epoch: 5 | loss: 0.0480625\n",
      "\tspeed: 0.1290s/iter; left time: 440.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.28s\n",
      "Steps: 226 | Train Loss: 0.0481537 Vali Loss: 0.0568581 Test Loss: 0.0606220\n",
      "Validation loss decreased (0.057770 --> 0.056858).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0454466\n",
      "\tspeed: 0.2245s/iter; left time: 738.7034s\n",
      "\titers: 200, epoch: 6 | loss: 0.0472364\n",
      "\tspeed: 0.1300s/iter; left time: 414.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.66s\n",
      "Steps: 226 | Train Loss: 0.0473543 Vali Loss: 0.0561352 Test Loss: 0.0599884\n",
      "Validation loss decreased (0.056858 --> 0.056135).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0457151\n",
      "\tspeed: 0.2253s/iter; left time: 690.5855s\n",
      "\titers: 200, epoch: 7 | loss: 0.0485219\n",
      "\tspeed: 0.1273s/iter; left time: 377.4637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.23s\n",
      "Steps: 226 | Train Loss: 0.0469531 Vali Loss: 0.0555767 Test Loss: 0.0595131\n",
      "Validation loss decreased (0.056135 --> 0.055577).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0456666\n",
      "\tspeed: 0.2198s/iter; left time: 624.1087s\n",
      "\titers: 200, epoch: 8 | loss: 0.0436416\n",
      "\tspeed: 0.1267s/iter; left time: 347.0364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.02s\n",
      "Steps: 226 | Train Loss: 0.0464396 Vali Loss: 0.0560706 Test Loss: 0.0598718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0451892\n",
      "\tspeed: 0.2140s/iter; left time: 559.1509s\n",
      "\titers: 200, epoch: 9 | loss: 0.0475388\n",
      "\tspeed: 0.1279s/iter; left time: 321.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.83s\n",
      "Steps: 226 | Train Loss: 0.0460145 Vali Loss: 0.0551534 Test Loss: 0.0584895\n",
      "Validation loss decreased (0.055577 --> 0.055153).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0418452\n",
      "\tspeed: 0.2255s/iter; left time: 538.1840s\n",
      "\titers: 200, epoch: 10 | loss: 0.0461544\n",
      "\tspeed: 0.1294s/iter; left time: 295.8721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.55s\n",
      "Steps: 226 | Train Loss: 0.0457849 Vali Loss: 0.0551798 Test Loss: 0.0594885\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0420638\n",
      "\tspeed: 0.2259s/iter; left time: 488.2519s\n",
      "\titers: 200, epoch: 11 | loss: 0.0461470\n",
      "\tspeed: 0.1284s/iter; left time: 264.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.36s\n",
      "Steps: 226 | Train Loss: 0.0454104 Vali Loss: 0.0548973 Test Loss: 0.0588777\n",
      "Validation loss decreased (0.055153 --> 0.054897).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0470574\n",
      "\tspeed: 0.2291s/iter; left time: 443.3602s\n",
      "\titers: 200, epoch: 12 | loss: 0.0454375\n",
      "\tspeed: 0.1288s/iter; left time: 236.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 226 | Train Loss: 0.0451413 Vali Loss: 0.0549472 Test Loss: 0.0585421\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0454469\n",
      "\tspeed: 0.2142s/iter; left time: 366.1507s\n",
      "\titers: 200, epoch: 13 | loss: 0.0446453\n",
      "\tspeed: 0.1260s/iter; left time: 202.6874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.90s\n",
      "Steps: 226 | Train Loss: 0.0450150 Vali Loss: 0.0546606 Test Loss: 0.0587026\n",
      "Validation loss decreased (0.054897 --> 0.054661).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0417745\n",
      "\tspeed: 0.2182s/iter; left time: 323.5572s\n",
      "\titers: 200, epoch: 14 | loss: 0.0470195\n",
      "\tspeed: 0.1297s/iter; left time: 179.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.25s\n",
      "Steps: 226 | Train Loss: 0.0447190 Vali Loss: 0.0546096 Test Loss: 0.0580985\n",
      "Validation loss decreased (0.054661 --> 0.054610).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0412011\n",
      "\tspeed: 0.2209s/iter; left time: 277.6884s\n",
      "\titers: 200, epoch: 15 | loss: 0.0458716\n",
      "\tspeed: 0.1267s/iter; left time: 146.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.73s\n",
      "Steps: 226 | Train Loss: 0.0445536 Vali Loss: 0.0544069 Test Loss: 0.0583128\n",
      "Validation loss decreased (0.054610 --> 0.054407).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0444622\n",
      "\tspeed: 0.2213s/iter; left time: 228.1786s\n",
      "\titers: 200, epoch: 16 | loss: 0.0436480\n",
      "\tspeed: 0.1282s/iter; left time: 119.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 226 | Train Loss: 0.0444886 Vali Loss: 0.0541725 Test Loss: 0.0580277\n",
      "Validation loss decreased (0.054407 --> 0.054172).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0422892\n",
      "\tspeed: 0.2222s/iter; left time: 178.8709s\n",
      "\titers: 200, epoch: 17 | loss: 0.0470878\n",
      "\tspeed: 0.1280s/iter; left time: 90.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.43s\n",
      "Steps: 226 | Train Loss: 0.0442781 Vali Loss: 0.0540447 Test Loss: 0.0577816\n",
      "Validation loss decreased (0.054172 --> 0.054045).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0428621\n",
      "\tspeed: 0.2221s/iter; left time: 128.6126s\n",
      "\titers: 200, epoch: 18 | loss: 0.0420758\n",
      "\tspeed: 0.1283s/iter; left time: 61.4677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.21s\n",
      "Steps: 226 | Train Loss: 0.0441897 Vali Loss: 0.0538316 Test Loss: 0.0574501\n",
      "Validation loss decreased (0.054045 --> 0.053832).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0450100\n",
      "\tspeed: 0.2262s/iter; left time: 79.8356s\n",
      "\titers: 200, epoch: 19 | loss: 0.0438370\n",
      "\tspeed: 0.1301s/iter; left time: 32.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.64s\n",
      "Steps: 226 | Train Loss: 0.0440705 Vali Loss: 0.0542827 Test Loss: 0.0579725\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0456248\n",
      "\tspeed: 0.2326s/iter; left time: 29.5355s\n",
      "\titers: 200, epoch: 20 | loss: 0.0453012\n",
      "\tspeed: 0.1281s/iter; left time: 3.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.80s\n",
      "Steps: 226 | Train Loss: 0.0439894 Vali Loss: 0.0539670 Test Loss: 0.0578357\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010744874365627766, rmse:0.10365748405456543, mae:0.057450130581855774, rse:0.3999077081680298\n",
      "Intermediate time for FR and pred_len 24: 00h:23m:39.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0821435\n",
      "\tspeed: 0.1545s/iter; left time: 679.7485s\n",
      "\titers: 200, epoch: 1 | loss: 0.0831200\n",
      "\tspeed: 0.1290s/iter; left time: 554.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.47s\n",
      "Steps: 225 | Train Loss: 0.0913107 Vali Loss: 0.0835734 Test Loss: 0.0922536\n",
      "Validation loss decreased (inf --> 0.083573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0678073\n",
      "\tspeed: 0.2200s/iter; left time: 918.6109s\n",
      "\titers: 200, epoch: 2 | loss: 0.0694359\n",
      "\tspeed: 0.1323s/iter; left time: 539.0511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.51s\n",
      "Steps: 225 | Train Loss: 0.0713360 Vali Loss: 0.0779968 Test Loss: 0.0871771\n",
      "Validation loss decreased (0.083573 --> 0.077997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0693156\n",
      "\tspeed: 0.2307s/iter; left time: 911.5833s\n",
      "\titers: 200, epoch: 3 | loss: 0.0701405\n",
      "\tspeed: 0.1332s/iter; left time: 512.7959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.04s\n",
      "Steps: 225 | Train Loss: 0.0673879 Vali Loss: 0.0758549 Test Loss: 0.0862915\n",
      "Validation loss decreased (0.077997 --> 0.075855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0674907\n",
      "\tspeed: 0.2312s/iter; left time: 861.4394s\n",
      "\titers: 200, epoch: 4 | loss: 0.0651132\n",
      "\tspeed: 0.1320s/iter; left time: 478.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.88s\n",
      "Steps: 225 | Train Loss: 0.0659649 Vali Loss: 0.0749174 Test Loss: 0.0851213\n",
      "Validation loss decreased (0.075855 --> 0.074917).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0647665\n",
      "\tspeed: 0.2353s/iter; left time: 823.8602s\n",
      "\titers: 200, epoch: 5 | loss: 0.0680801\n",
      "\tspeed: 0.1313s/iter; left time: 446.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.94s\n",
      "Steps: 225 | Train Loss: 0.0647660 Vali Loss: 0.0744220 Test Loss: 0.0845276\n",
      "Validation loss decreased (0.074917 --> 0.074422).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0638947\n",
      "\tspeed: 0.2260s/iter; left time: 740.4066s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613103\n",
      "\tspeed: 0.1293s/iter; left time: 410.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.40s\n",
      "Steps: 225 | Train Loss: 0.0637174 Vali Loss: 0.0733305 Test Loss: 0.0838157\n",
      "Validation loss decreased (0.074422 --> 0.073331).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0639387\n",
      "\tspeed: 0.2250s/iter; left time: 686.4712s\n",
      "\titers: 200, epoch: 7 | loss: 0.0675600\n",
      "\tspeed: 0.1322s/iter; left time: 390.1876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.76s\n",
      "Steps: 225 | Train Loss: 0.0629273 Vali Loss: 0.0727968 Test Loss: 0.0837717\n",
      "Validation loss decreased (0.073331 --> 0.072797).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0639801\n",
      "\tspeed: 0.2265s/iter; left time: 639.9718s\n",
      "\titers: 200, epoch: 8 | loss: 0.0635716\n",
      "\tspeed: 0.1335s/iter; left time: 363.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.93s\n",
      "Steps: 225 | Train Loss: 0.0625018 Vali Loss: 0.0732585 Test Loss: 0.0833542\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0613126\n",
      "\tspeed: 0.2306s/iter; left time: 599.6642s\n",
      "\titers: 200, epoch: 9 | loss: 0.0657632\n",
      "\tspeed: 0.1333s/iter; left time: 333.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:30.36s\n",
      "Steps: 225 | Train Loss: 0.0620127 Vali Loss: 0.0723178 Test Loss: 0.0833246\n",
      "Validation loss decreased (0.072797 --> 0.072318).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0602790\n",
      "\tspeed: 0.2521s/iter; left time: 599.0509s\n",
      "\titers: 200, epoch: 10 | loss: 0.0600664\n",
      "\tspeed: 0.1314s/iter; left time: 299.0723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:30.65s\n",
      "Steps: 225 | Train Loss: 0.0616372 Vali Loss: 0.0726278 Test Loss: 0.0831672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0597956\n",
      "\tspeed: 0.2272s/iter; left time: 488.7564s\n",
      "\titers: 200, epoch: 11 | loss: 0.0623358\n",
      "\tspeed: 0.1313s/iter; left time: 269.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.38s\n",
      "Steps: 225 | Train Loss: 0.0612253 Vali Loss: 0.0724789 Test Loss: 0.0828953\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0646971\n",
      "\tspeed: 0.2234s/iter; left time: 430.1962s\n",
      "\titers: 200, epoch: 12 | loss: 0.0596059\n",
      "\tspeed: 0.1309s/iter; left time: 239.0566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.43s\n",
      "Steps: 225 | Train Loss: 0.0609990 Vali Loss: 0.0719485 Test Loss: 0.0828231\n",
      "Validation loss decreased (0.072318 --> 0.071948).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0582323\n",
      "\tspeed: 0.2297s/iter; left time: 390.7735s\n",
      "\titers: 200, epoch: 13 | loss: 0.0634934\n",
      "\tspeed: 0.1343s/iter; left time: 215.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:30.37s\n",
      "Steps: 225 | Train Loss: 0.0607619 Vali Loss: 0.0720306 Test Loss: 0.0829450\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0619525\n",
      "\tspeed: 0.2277s/iter; left time: 336.1307s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590660\n",
      "\tspeed: 0.1288s/iter; left time: 177.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.32s\n",
      "Steps: 225 | Train Loss: 0.0605827 Vali Loss: 0.0714336 Test Loss: 0.0823739\n",
      "Validation loss decreased (0.071948 --> 0.071434).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0587442\n",
      "\tspeed: 0.2352s/iter; left time: 294.2492s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619651\n",
      "\tspeed: 0.1357s/iter; left time: 156.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.52s\n",
      "Steps: 225 | Train Loss: 0.0603027 Vali Loss: 0.0718620 Test Loss: 0.0827420\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0584721\n",
      "\tspeed: 0.2438s/iter; left time: 250.1415s\n",
      "\titers: 200, epoch: 16 | loss: 0.0555041\n",
      "\tspeed: 0.1298s/iter; left time: 120.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.02s\n",
      "Steps: 225 | Train Loss: 0.0602388 Vali Loss: 0.0716047 Test Loss: 0.0822622\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0603823\n",
      "\tspeed: 0.2270s/iter; left time: 181.8549s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582806\n",
      "\tspeed: 0.1320s/iter; left time: 92.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0599569 Vali Loss: 0.0717798 Test Loss: 0.0822858\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0589450\n",
      "\tspeed: 0.2184s/iter; left time: 125.7864s\n",
      "\titers: 200, epoch: 18 | loss: 0.0634137\n",
      "\tspeed: 0.1286s/iter; left time: 61.2225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.28s\n",
      "Steps: 225 | Train Loss: 0.0598509 Vali Loss: 0.0716802 Test Loss: 0.0823941\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0584398\n",
      "\tspeed: 0.2293s/iter; left time: 80.4760s\n",
      "\titers: 200, epoch: 19 | loss: 0.0588430\n",
      "\tspeed: 0.1327s/iter; left time: 33.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.98s\n",
      "Steps: 225 | Train Loss: 0.0596980 Vali Loss: 0.0715777 Test Loss: 0.0823717\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020205451175570488, rmse:0.14214588701725006, mae:0.08237384259700775, rse:0.549858033657074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0894169\n",
      "\tspeed: 0.1355s/iter; left time: 596.4210s\n",
      "\titers: 200, epoch: 1 | loss: 0.0878222\n",
      "\tspeed: 0.1323s/iter; left time: 568.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0921728 Vali Loss: 0.0833592 Test Loss: 0.0920192\n",
      "Validation loss decreased (inf --> 0.083359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0669506\n",
      "\tspeed: 0.2316s/iter; left time: 967.1961s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688249\n",
      "\tspeed: 0.1379s/iter; left time: 562.2376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.68s\n",
      "Steps: 225 | Train Loss: 0.0714438 Vali Loss: 0.0777502 Test Loss: 0.0868886\n",
      "Validation loss decreased (0.083359 --> 0.077750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638473\n",
      "\tspeed: 0.2275s/iter; left time: 898.6594s\n",
      "\titers: 200, epoch: 3 | loss: 0.0689979\n",
      "\tspeed: 0.1291s/iter; left time: 497.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.42s\n",
      "Steps: 225 | Train Loss: 0.0672572 Vali Loss: 0.0760684 Test Loss: 0.0863736\n",
      "Validation loss decreased (0.077750 --> 0.076068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0672900\n",
      "\tspeed: 0.2176s/iter; left time: 810.6828s\n",
      "\titers: 200, epoch: 4 | loss: 0.0639855\n",
      "\tspeed: 0.1278s/iter; left time: 463.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.98s\n",
      "Steps: 225 | Train Loss: 0.0658523 Vali Loss: 0.0749936 Test Loss: 0.0854241\n",
      "Validation loss decreased (0.076068 --> 0.074994).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0626215\n",
      "\tspeed: 0.2190s/iter; left time: 766.5479s\n",
      "\titers: 200, epoch: 5 | loss: 0.0626608\n",
      "\tspeed: 0.1280s/iter; left time: 435.2641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.04s\n",
      "Steps: 225 | Train Loss: 0.0646476 Vali Loss: 0.0739110 Test Loss: 0.0846380\n",
      "Validation loss decreased (0.074994 --> 0.073911).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641698\n",
      "\tspeed: 0.2408s/iter; left time: 788.9978s\n",
      "\titers: 200, epoch: 6 | loss: 0.0627856\n",
      "\tspeed: 0.1388s/iter; left time: 440.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.55s\n",
      "Steps: 225 | Train Loss: 0.0639034 Vali Loss: 0.0747545 Test Loss: 0.0855872\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0652396\n",
      "\tspeed: 0.2333s/iter; left time: 711.9271s\n",
      "\titers: 200, epoch: 7 | loss: 0.0667626\n",
      "\tspeed: 0.1315s/iter; left time: 387.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.77s\n",
      "Steps: 225 | Train Loss: 0.0631427 Vali Loss: 0.0732717 Test Loss: 0.0834854\n",
      "Validation loss decreased (0.073911 --> 0.073272).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0631166\n",
      "\tspeed: 0.2220s/iter; left time: 627.4747s\n",
      "\titers: 200, epoch: 8 | loss: 0.0626838\n",
      "\tspeed: 0.1296s/iter; left time: 353.2473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.34s\n",
      "Steps: 225 | Train Loss: 0.0625255 Vali Loss: 0.0733401 Test Loss: 0.0836931\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0613080\n",
      "\tspeed: 0.2264s/iter; left time: 588.7666s\n",
      "\titers: 200, epoch: 9 | loss: 0.0632498\n",
      "\tspeed: 0.1335s/iter; left time: 333.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.98s\n",
      "Steps: 225 | Train Loss: 0.0621014 Vali Loss: 0.0734221 Test Loss: 0.0835117\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0624017\n",
      "\tspeed: 0.2320s/iter; left time: 551.2138s\n",
      "\titers: 200, epoch: 10 | loss: 0.0701763\n",
      "\tspeed: 0.1306s/iter; left time: 297.2850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.73s\n",
      "Steps: 225 | Train Loss: 0.0616782 Vali Loss: 0.0723835 Test Loss: 0.0828523\n",
      "Validation loss decreased (0.073272 --> 0.072383).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0656709\n",
      "\tspeed: 0.2371s/iter; left time: 510.0696s\n",
      "\titers: 200, epoch: 11 | loss: 0.0620192\n",
      "\tspeed: 0.1364s/iter; left time: 279.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0613649 Vali Loss: 0.0728863 Test Loss: 0.0833074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0611714\n",
      "\tspeed: 0.2154s/iter; left time: 414.8459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0589759\n",
      "\tspeed: 0.1288s/iter; left time: 235.1587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.04s\n",
      "Steps: 225 | Train Loss: 0.0611654 Vali Loss: 0.0720310 Test Loss: 0.0828215\n",
      "Validation loss decreased (0.072383 --> 0.072031).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0601530\n",
      "\tspeed: 0.2293s/iter; left time: 390.0917s\n",
      "\titers: 200, epoch: 13 | loss: 0.0627939\n",
      "\tspeed: 0.1299s/iter; left time: 207.9448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0608504 Vali Loss: 0.0722075 Test Loss: 0.0826092\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0604201\n",
      "\tspeed: 0.2315s/iter; left time: 341.7533s\n",
      "\titers: 200, epoch: 14 | loss: 0.0634251\n",
      "\tspeed: 0.1313s/iter; left time: 180.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0606327 Vali Loss: 0.0726777 Test Loss: 0.0831189\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0640372\n",
      "\tspeed: 0.2379s/iter; left time: 297.5685s\n",
      "\titers: 200, epoch: 15 | loss: 0.0630407\n",
      "\tspeed: 0.1352s/iter; left time: 155.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0604669 Vali Loss: 0.0721378 Test Loss: 0.0825559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0591577\n",
      "\tspeed: 0.2499s/iter; left time: 256.4079s\n",
      "\titers: 200, epoch: 16 | loss: 0.0630949\n",
      "\tspeed: 0.1303s/iter; left time: 120.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.05s\n",
      "Steps: 225 | Train Loss: 0.0602721 Vali Loss: 0.0723365 Test Loss: 0.0823819\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0585780\n",
      "\tspeed: 0.2232s/iter; left time: 178.7965s\n",
      "\titers: 200, epoch: 17 | loss: 0.0607349\n",
      "\tspeed: 0.1285s/iter; left time: 90.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.10s\n",
      "Steps: 225 | Train Loss: 0.0601261 Vali Loss: 0.0719406 Test Loss: 0.0822569\n",
      "Validation loss decreased (0.072031 --> 0.071941).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0573446\n",
      "\tspeed: 0.2356s/iter; left time: 135.7109s\n",
      "\titers: 200, epoch: 18 | loss: 0.0599148\n",
      "\tspeed: 0.1314s/iter; left time: 62.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.67s\n",
      "Steps: 225 | Train Loss: 0.0599890 Vali Loss: 0.0719018 Test Loss: 0.0822290\n",
      "Validation loss decreased (0.071941 --> 0.071902).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0560430\n",
      "\tspeed: 0.2310s/iter; left time: 81.0980s\n",
      "\titers: 200, epoch: 19 | loss: 0.0599572\n",
      "\tspeed: 0.1354s/iter; left time: 33.9758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0598794 Vali Loss: 0.0721454 Test Loss: 0.0823054\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0642339\n",
      "\tspeed: 0.2471s/iter; left time: 31.1371s\n",
      "\titers: 200, epoch: 20 | loss: 0.0639723\n",
      "\tspeed: 0.1287s/iter; left time: 3.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.57s\n",
      "Steps: 225 | Train Loss: 0.0597939 Vali Loss: 0.0717466 Test Loss: 0.0819931\n",
      "Validation loss decreased (0.071902 --> 0.071747).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019991254433989525, rmse:0.14139042794704437, mae:0.08199303597211838, rse:0.5469357967376709\n",
      "Intermediate time for FR and pred_len 96: 00h:23m:48.64s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0916881\n",
      "\tspeed: 0.1560s/iter; left time: 686.5020s\n",
      "\titers: 200, epoch: 1 | loss: 0.0869237\n",
      "\tspeed: 0.1299s/iter; left time: 558.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0946456 Vali Loss: 0.0873302 Test Loss: 0.0960933\n",
      "Validation loss decreased (inf --> 0.087330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0765944\n",
      "\tspeed: 0.2283s/iter; left time: 953.3026s\n",
      "\titers: 200, epoch: 2 | loss: 0.0703099\n",
      "\tspeed: 0.1304s/iter; left time: 531.6284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.74s\n",
      "Steps: 225 | Train Loss: 0.0755584 Vali Loss: 0.0817829 Test Loss: 0.0917741\n",
      "Validation loss decreased (0.087330 --> 0.081783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0746351\n",
      "\tspeed: 0.2314s/iter; left time: 914.1378s\n",
      "\titers: 200, epoch: 3 | loss: 0.0698561\n",
      "\tspeed: 0.1303s/iter; left time: 501.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.53s\n",
      "Steps: 225 | Train Loss: 0.0723485 Vali Loss: 0.0802219 Test Loss: 0.0911483\n",
      "Validation loss decreased (0.081783 --> 0.080222).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729910\n",
      "\tspeed: 0.2407s/iter; left time: 896.8529s\n",
      "\titers: 200, epoch: 4 | loss: 0.0687222\n",
      "\tspeed: 0.1320s/iter; left time: 478.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.99s\n",
      "Steps: 225 | Train Loss: 0.0707458 Vali Loss: 0.0792043 Test Loss: 0.0905273\n",
      "Validation loss decreased (0.080222 --> 0.079204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0712522\n",
      "\tspeed: 0.2426s/iter; left time: 849.1715s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685331\n",
      "\tspeed: 0.1376s/iter; left time: 468.0457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.85s\n",
      "Steps: 225 | Train Loss: 0.0694804 Vali Loss: 0.0787229 Test Loss: 0.0898371\n",
      "Validation loss decreased (0.079204 --> 0.078723).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0689771\n",
      "\tspeed: 0.2448s/iter; left time: 802.0766s\n",
      "\titers: 200, epoch: 6 | loss: 0.0695027\n",
      "\tspeed: 0.1285s/iter; left time: 408.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 225 | Train Loss: 0.0686404 Vali Loss: 0.0781113 Test Loss: 0.0888023\n",
      "Validation loss decreased (0.078723 --> 0.078111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0682323\n",
      "\tspeed: 0.2350s/iter; left time: 717.0457s\n",
      "\titers: 200, epoch: 7 | loss: 0.0699818\n",
      "\tspeed: 0.1299s/iter; left time: 383.3049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.94s\n",
      "Steps: 225 | Train Loss: 0.0679058 Vali Loss: 0.0782345 Test Loss: 0.0895413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0707153\n",
      "\tspeed: 0.2300s/iter; left time: 649.8795s\n",
      "\titers: 200, epoch: 8 | loss: 0.0695843\n",
      "\tspeed: 0.1323s/iter; left time: 360.5899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.95s\n",
      "Steps: 225 | Train Loss: 0.0674135 Vali Loss: 0.0771264 Test Loss: 0.0888884\n",
      "Validation loss decreased (0.078111 --> 0.077126).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0653303\n",
      "\tspeed: 0.2277s/iter; left time: 592.3061s\n",
      "\titers: 200, epoch: 9 | loss: 0.0724449\n",
      "\tspeed: 0.1330s/iter; left time: 332.6720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:30.07s\n",
      "Steps: 225 | Train Loss: 0.0669095 Vali Loss: 0.0773865 Test Loss: 0.0887160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0634143\n",
      "\tspeed: 0.2379s/iter; left time: 565.1939s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633310\n",
      "\tspeed: 0.1394s/iter; left time: 317.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 225 | Train Loss: 0.0665528 Vali Loss: 0.0775114 Test Loss: 0.0891376\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642596\n",
      "\tspeed: 0.2275s/iter; left time: 489.4264s\n",
      "\titers: 200, epoch: 11 | loss: 0.0683906\n",
      "\tspeed: 0.1276s/iter; left time: 261.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.03s\n",
      "Steps: 225 | Train Loss: 0.0662428 Vali Loss: 0.0768049 Test Loss: 0.0883481\n",
      "Validation loss decreased (0.077126 --> 0.076805).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0624630\n",
      "\tspeed: 0.2224s/iter; left time: 428.3307s\n",
      "\titers: 200, epoch: 12 | loss: 0.0640266\n",
      "\tspeed: 0.1273s/iter; left time: 232.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.06s\n",
      "Steps: 225 | Train Loss: 0.0660178 Vali Loss: 0.0770547 Test Loss: 0.0880818\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0683184\n",
      "\tspeed: 0.2192s/iter; left time: 372.8130s\n",
      "\titers: 200, epoch: 13 | loss: 0.0646703\n",
      "\tspeed: 0.1305s/iter; left time: 208.9174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.52s\n",
      "Steps: 225 | Train Loss: 0.0657393 Vali Loss: 0.0767636 Test Loss: 0.0878029\n",
      "Validation loss decreased (0.076805 --> 0.076764).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0680823\n",
      "\tspeed: 0.2324s/iter; left time: 343.0095s\n",
      "\titers: 200, epoch: 14 | loss: 0.0666962\n",
      "\tspeed: 0.1327s/iter; left time: 182.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.85s\n",
      "Steps: 225 | Train Loss: 0.0655135 Vali Loss: 0.0769423 Test Loss: 0.0880894\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665233\n",
      "\tspeed: 0.2246s/iter; left time: 281.0342s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659037\n",
      "\tspeed: 0.1345s/iter; left time: 154.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.31s\n",
      "Steps: 225 | Train Loss: 0.0653375 Vali Loss: 0.0765706 Test Loss: 0.0880015\n",
      "Validation loss decreased (0.076764 --> 0.076571).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0669951\n",
      "\tspeed: 0.2355s/iter; left time: 241.6049s\n",
      "\titers: 200, epoch: 16 | loss: 0.0666725\n",
      "\tspeed: 0.1388s/iter; left time: 128.5453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.74s\n",
      "Steps: 225 | Train Loss: 0.0651356 Vali Loss: 0.0767214 Test Loss: 0.0881702\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0642989\n",
      "\tspeed: 0.2467s/iter; left time: 197.5974s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637477\n",
      "\tspeed: 0.1343s/iter; left time: 94.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:30.53s\n",
      "Steps: 225 | Train Loss: 0.0649981 Vali Loss: 0.0762711 Test Loss: 0.0878609\n",
      "Validation loss decreased (0.076571 --> 0.076271).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0646516\n",
      "\tspeed: 0.2447s/iter; left time: 140.9559s\n",
      "\titers: 200, epoch: 18 | loss: 0.0679890\n",
      "\tspeed: 0.1346s/iter; left time: 64.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:30.47s\n",
      "Steps: 225 | Train Loss: 0.0648507 Vali Loss: 0.0767555 Test Loss: 0.0878701\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0642924\n",
      "\tspeed: 0.2296s/iter; left time: 80.5763s\n",
      "\titers: 200, epoch: 19 | loss: 0.0647242\n",
      "\tspeed: 0.1311s/iter; left time: 32.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.71s\n",
      "Steps: 225 | Train Loss: 0.0647024 Vali Loss: 0.0764668 Test Loss: 0.0877801\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0624535\n",
      "\tspeed: 0.2363s/iter; left time: 29.7705s\n",
      "\titers: 200, epoch: 20 | loss: 0.0675110\n",
      "\tspeed: 0.1368s/iter; left time: 3.5563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0646263 Vali Loss: 0.0767285 Test Loss: 0.0880821\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02186432108283043, rmse:0.147865891456604, mae:0.08786085247993469, rse:0.5726985931396484\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0919613\n",
      "\tspeed: 0.1358s/iter; left time: 597.7374s\n",
      "\titers: 200, epoch: 1 | loss: 0.0867113\n",
      "\tspeed: 0.1342s/iter; left time: 577.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.35s\n",
      "Steps: 225 | Train Loss: 0.0940161 Vali Loss: 0.0871972 Test Loss: 0.0960238\n",
      "Validation loss decreased (inf --> 0.087197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0713059\n",
      "\tspeed: 0.2526s/iter; left time: 1054.7877s\n",
      "\titers: 200, epoch: 2 | loss: 0.0714525\n",
      "\tspeed: 0.1323s/iter; left time: 539.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.07s\n",
      "Steps: 225 | Train Loss: 0.0757864 Vali Loss: 0.0823225 Test Loss: 0.0925486\n",
      "Validation loss decreased (0.087197 --> 0.082323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0671578\n",
      "\tspeed: 0.2375s/iter; left time: 938.2541s\n",
      "\titers: 200, epoch: 3 | loss: 0.0709672\n",
      "\tspeed: 0.1327s/iter; left time: 511.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.16s\n",
      "Steps: 225 | Train Loss: 0.0723406 Vali Loss: 0.0810314 Test Loss: 0.0920664\n",
      "Validation loss decreased (0.082323 --> 0.081031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0700649\n",
      "\tspeed: 0.2308s/iter; left time: 859.8207s\n",
      "\titers: 200, epoch: 4 | loss: 0.0703632\n",
      "\tspeed: 0.1333s/iter; left time: 483.2822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:30.08s\n",
      "Steps: 225 | Train Loss: 0.0707206 Vali Loss: 0.0790750 Test Loss: 0.0903970\n",
      "Validation loss decreased (0.081031 --> 0.079075).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0656126\n",
      "\tspeed: 0.2482s/iter; left time: 869.1222s\n",
      "\titers: 200, epoch: 5 | loss: 0.0692182\n",
      "\tspeed: 0.1333s/iter; left time: 453.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.34s\n",
      "Steps: 225 | Train Loss: 0.0694477 Vali Loss: 0.0789509 Test Loss: 0.0901828\n",
      "Validation loss decreased (0.079075 --> 0.078951).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0686687\n",
      "\tspeed: 0.2328s/iter; left time: 762.7674s\n",
      "\titers: 200, epoch: 6 | loss: 0.0678676\n",
      "\tspeed: 0.1305s/iter; left time: 414.3539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.92s\n",
      "Steps: 225 | Train Loss: 0.0686255 Vali Loss: 0.0783217 Test Loss: 0.0896430\n",
      "Validation loss decreased (0.078951 --> 0.078322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0661045\n",
      "\tspeed: 0.2638s/iter; left time: 804.9863s\n",
      "\titers: 200, epoch: 7 | loss: 0.0682785\n",
      "\tspeed: 0.1376s/iter; left time: 406.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.81s\n",
      "Steps: 225 | Train Loss: 0.0678917 Vali Loss: 0.0783234 Test Loss: 0.0887447\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0683451\n",
      "\tspeed: 0.2095s/iter; left time: 591.9777s\n",
      "\titers: 200, epoch: 8 | loss: 0.0687753\n",
      "\tspeed: 0.1242s/iter; left time: 338.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 225 | Train Loss: 0.0673855 Vali Loss: 0.0778848 Test Loss: 0.0888012\n",
      "Validation loss decreased (0.078322 --> 0.077885).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0657038\n",
      "\tspeed: 0.2074s/iter; left time: 539.5108s\n",
      "\titers: 200, epoch: 9 | loss: 0.0665707\n",
      "\tspeed: 0.1242s/iter; left time: 310.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 225 | Train Loss: 0.0668863 Vali Loss: 0.0776036 Test Loss: 0.0886073\n",
      "Validation loss decreased (0.077885 --> 0.077604).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0667441\n",
      "\tspeed: 0.2228s/iter; left time: 529.2991s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633583\n",
      "\tspeed: 0.1245s/iter; left time: 283.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0664838 Vali Loss: 0.0774441 Test Loss: 0.0883286\n",
      "Validation loss decreased (0.077604 --> 0.077444).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0627698\n",
      "\tspeed: 0.2068s/iter; left time: 444.8338s\n",
      "\titers: 200, epoch: 11 | loss: 0.0660751\n",
      "\tspeed: 0.1249s/iter; left time: 256.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 225 | Train Loss: 0.0662418 Vali Loss: 0.0770156 Test Loss: 0.0887772\n",
      "Validation loss decreased (0.077444 --> 0.077016).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0683075\n",
      "\tspeed: 0.2137s/iter; left time: 411.6625s\n",
      "\titers: 200, epoch: 12 | loss: 0.0689828\n",
      "\tspeed: 0.1246s/iter; left time: 227.5600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0658903 Vali Loss: 0.0768637 Test Loss: 0.0878356\n",
      "Validation loss decreased (0.077016 --> 0.076864).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0688406\n",
      "\tspeed: 0.2060s/iter; left time: 350.4884s\n",
      "\titers: 200, epoch: 13 | loss: 0.0636687\n",
      "\tspeed: 0.1243s/iter; left time: 199.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0656338 Vali Loss: 0.0767962 Test Loss: 0.0876834\n",
      "Validation loss decreased (0.076864 --> 0.076796).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0652549\n",
      "\tspeed: 0.2430s/iter; left time: 358.6146s\n",
      "\titers: 200, epoch: 14 | loss: 0.0669380\n",
      "\tspeed: 0.1244s/iter; left time: 171.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0654096 Vali Loss: 0.0768992 Test Loss: 0.0880054\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0605805\n",
      "\tspeed: 0.2051s/iter; left time: 256.5708s\n",
      "\titers: 200, epoch: 15 | loss: 0.0669335\n",
      "\tspeed: 0.1242s/iter; left time: 142.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.10s\n",
      "Steps: 225 | Train Loss: 0.0652253 Vali Loss: 0.0767318 Test Loss: 0.0878261\n",
      "Validation loss decreased (0.076796 --> 0.076732).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0649559\n",
      "\tspeed: 0.2810s/iter; left time: 288.3519s\n",
      "\titers: 200, epoch: 16 | loss: 0.0645573\n",
      "\tspeed: 0.1239s/iter; left time: 114.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.07s\n",
      "Steps: 225 | Train Loss: 0.0650691 Vali Loss: 0.0766515 Test Loss: 0.0880999\n",
      "Validation loss decreased (0.076732 --> 0.076652).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0705975\n",
      "\tspeed: 0.2069s/iter; left time: 165.6977s\n",
      "\titers: 200, epoch: 17 | loss: 0.0659833\n",
      "\tspeed: 0.1246s/iter; left time: 87.3566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0648604 Vali Loss: 0.0765938 Test Loss: 0.0877360\n",
      "Validation loss decreased (0.076652 --> 0.076594).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0670262\n",
      "\tspeed: 0.2088s/iter; left time: 120.2704s\n",
      "\titers: 200, epoch: 18 | loss: 0.0629649\n",
      "\tspeed: 0.1242s/iter; left time: 59.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 225 | Train Loss: 0.0647039 Vali Loss: 0.0767391 Test Loss: 0.0876653\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0651461\n",
      "\tspeed: 0.2065s/iter; left time: 72.4737s\n",
      "\titers: 200, epoch: 19 | loss: 0.0666738\n",
      "\tspeed: 0.1247s/iter; left time: 31.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0646175 Vali Loss: 0.0765972 Test Loss: 0.0876592\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0639071\n",
      "\tspeed: 0.2063s/iter; left time: 25.9905s\n",
      "\titers: 200, epoch: 20 | loss: 0.0667633\n",
      "\tspeed: 0.1248s/iter; left time: 3.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 225 | Train Loss: 0.0645528 Vali Loss: 0.0764963 Test Loss: 0.0876327\n",
      "Validation loss decreased (0.076594 --> 0.076496).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021848367527127266, rmse:0.14781193435192108, mae:0.08763277530670166, rse:0.5724896192550659\n",
      "Intermediate time for FR and pred_len 168: 00h:24m:15.00s\n",
      "Intermediate time for FR: 01h:11m:43.09s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1121790\n",
      "\tspeed: 0.1485s/iter; left time: 656.3155s\n",
      "\titers: 200, epoch: 1 | loss: 0.1071127\n",
      "\tspeed: 0.1232s/iter; left time: 532.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 226 | Train Loss: 0.1183522 Vali Loss: 0.0811168 Test Loss: 0.0823932\n",
      "Validation loss decreased (inf --> 0.081117).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0740139\n",
      "\tspeed: 0.2044s/iter; left time: 857.5001s\n",
      "\titers: 200, epoch: 2 | loss: 0.0693383\n",
      "\tspeed: 0.1233s/iter; left time: 504.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 226 | Train Loss: 0.0758895 Vali Loss: 0.0661073 Test Loss: 0.0684309\n",
      "Validation loss decreased (0.081117 --> 0.066107).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0692373\n",
      "\tspeed: 0.2102s/iter; left time: 834.3075s\n",
      "\titers: 200, epoch: 3 | loss: 0.0680119\n",
      "\tspeed: 0.1235s/iter; left time: 477.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 226 | Train Loss: 0.0688669 Vali Loss: 0.0632555 Test Loss: 0.0659584\n",
      "Validation loss decreased (0.066107 --> 0.063256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0691024\n",
      "\tspeed: 0.2072s/iter; left time: 775.4327s\n",
      "\titers: 200, epoch: 4 | loss: 0.0713159\n",
      "\tspeed: 0.1235s/iter; left time: 449.9605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 226 | Train Loss: 0.0659160 Vali Loss: 0.0616597 Test Loss: 0.0638568\n",
      "Validation loss decreased (0.063256 --> 0.061660).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0636145\n",
      "\tspeed: 0.2046s/iter; left time: 719.5598s\n",
      "\titers: 200, epoch: 5 | loss: 0.0682091\n",
      "\tspeed: 0.1239s/iter; left time: 423.2400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 226 | Train Loss: 0.0640215 Vali Loss: 0.0601045 Test Loss: 0.0630680\n",
      "Validation loss decreased (0.061660 --> 0.060105).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0645924\n",
      "\tspeed: 0.2080s/iter; left time: 684.6706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0623100\n",
      "\tspeed: 0.1244s/iter; left time: 396.8996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 226 | Train Loss: 0.0623804 Vali Loss: 0.0589569 Test Loss: 0.0620875\n",
      "Validation loss decreased (0.060105 --> 0.058957).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0597447\n",
      "\tspeed: 0.2059s/iter; left time: 631.1167s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645506\n",
      "\tspeed: 0.1241s/iter; left time: 368.0582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 226 | Train Loss: 0.0614329 Vali Loss: 0.0588587 Test Loss: 0.0619362\n",
      "Validation loss decreased (0.058957 --> 0.058859).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0571509\n",
      "\tspeed: 0.2078s/iter; left time: 589.9646s\n",
      "\titers: 200, epoch: 8 | loss: 0.0552820\n",
      "\tspeed: 0.1242s/iter; left time: 340.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 226 | Train Loss: 0.0606643 Vali Loss: 0.0580877 Test Loss: 0.0607174\n",
      "Validation loss decreased (0.058859 --> 0.058088).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0629100\n",
      "\tspeed: 0.2072s/iter; left time: 541.3866s\n",
      "\titers: 200, epoch: 9 | loss: 0.0620225\n",
      "\tspeed: 0.1241s/iter; left time: 311.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 226 | Train Loss: 0.0599683 Vali Loss: 0.0578587 Test Loss: 0.0605800\n",
      "Validation loss decreased (0.058088 --> 0.057859).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0574319\n",
      "\tspeed: 0.2074s/iter; left time: 495.0400s\n",
      "\titers: 200, epoch: 10 | loss: 0.0602710\n",
      "\tspeed: 0.1243s/iter; left time: 284.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 226 | Train Loss: 0.0595075 Vali Loss: 0.0576037 Test Loss: 0.0601031\n",
      "Validation loss decreased (0.057859 --> 0.057604).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0606948\n",
      "\tspeed: 0.2064s/iter; left time: 446.0991s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578572\n",
      "\tspeed: 0.1242s/iter; left time: 255.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 226 | Train Loss: 0.0590668 Vali Loss: 0.0575622 Test Loss: 0.0603818\n",
      "Validation loss decreased (0.057604 --> 0.057562).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0614702\n",
      "\tspeed: 0.2109s/iter; left time: 408.0815s\n",
      "\titers: 200, epoch: 12 | loss: 0.0576249\n",
      "\tspeed: 0.1240s/iter; left time: 227.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.19s\n",
      "Steps: 226 | Train Loss: 0.0588322 Vali Loss: 0.0570690 Test Loss: 0.0595613\n",
      "Validation loss decreased (0.057562 --> 0.057069).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0536879\n",
      "\tspeed: 0.2054s/iter; left time: 350.9909s\n",
      "\titers: 200, epoch: 13 | loss: 0.0548065\n",
      "\tspeed: 0.1238s/iter; left time: 199.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 226 | Train Loss: 0.0584687 Vali Loss: 0.0568619 Test Loss: 0.0593011\n",
      "Validation loss decreased (0.057069 --> 0.056862).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0570590\n",
      "\tspeed: 0.2051s/iter; left time: 304.2340s\n",
      "\titers: 200, epoch: 14 | loss: 0.0629808\n",
      "\tspeed: 0.1233s/iter; left time: 170.4929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 226 | Train Loss: 0.0580641 Vali Loss: 0.0568366 Test Loss: 0.0590742\n",
      "Validation loss decreased (0.056862 --> 0.056837).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571397\n",
      "\tspeed: 0.2038s/iter; left time: 256.1308s\n",
      "\titers: 200, epoch: 15 | loss: 0.0618289\n",
      "\tspeed: 0.1230s/iter; left time: 142.3411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 226 | Train Loss: 0.0577726 Vali Loss: 0.0567835 Test Loss: 0.0589230\n",
      "Validation loss decreased (0.056837 --> 0.056783).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0589630\n",
      "\tspeed: 0.2039s/iter; left time: 210.1841s\n",
      "\titers: 200, epoch: 16 | loss: 0.0573150\n",
      "\tspeed: 0.1231s/iter; left time: 114.5785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0576216 Vali Loss: 0.0564624 Test Loss: 0.0587323\n",
      "Validation loss decreased (0.056783 --> 0.056462).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0625905\n",
      "\tspeed: 0.2044s/iter; left time: 164.5188s\n",
      "\titers: 200, epoch: 17 | loss: 0.0577565\n",
      "\tspeed: 0.1232s/iter; left time: 86.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 226 | Train Loss: 0.0573842 Vali Loss: 0.0568271 Test Loss: 0.0590868\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0595494\n",
      "\tspeed: 0.2032s/iter; left time: 117.6542s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563744\n",
      "\tspeed: 0.1231s/iter; left time: 58.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0572813 Vali Loss: 0.0563119 Test Loss: 0.0589350\n",
      "Validation loss decreased (0.056462 --> 0.056312).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0563603\n",
      "\tspeed: 0.2111s/iter; left time: 74.5156s\n",
      "\titers: 200, epoch: 19 | loss: 0.0545016\n",
      "\tspeed: 0.1231s/iter; left time: 31.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 226 | Train Loss: 0.0570930 Vali Loss: 0.0561932 Test Loss: 0.0585328\n",
      "Validation loss decreased (0.056312 --> 0.056193).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0566096\n",
      "\tspeed: 0.2045s/iter; left time: 25.9745s\n",
      "\titers: 200, epoch: 20 | loss: 0.0562457\n",
      "\tspeed: 0.1232s/iter; left time: 3.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0569631 Vali Loss: 0.0565658 Test Loss: 0.0586333\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010333484970033169, rmse:0.10165374726057053, mae:0.05853284150362015, rse:0.38409945368766785\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1148740\n",
      "\tspeed: 0.1241s/iter; left time: 548.5404s\n",
      "\titers: 200, epoch: 1 | loss: 0.1035100\n",
      "\tspeed: 0.1231s/iter; left time: 531.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.1211798 Vali Loss: 0.0813818 Test Loss: 0.0824983\n",
      "Validation loss decreased (inf --> 0.081382).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0743233\n",
      "\tspeed: 0.2036s/iter; left time: 854.1455s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723142\n",
      "\tspeed: 0.1233s/iter; left time: 504.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 226 | Train Loss: 0.0766999 Vali Loss: 0.0664761 Test Loss: 0.0689256\n",
      "Validation loss decreased (0.081382 --> 0.066476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0662167\n",
      "\tspeed: 0.2042s/iter; left time: 810.5253s\n",
      "\titers: 200, epoch: 3 | loss: 0.0662025\n",
      "\tspeed: 0.1231s/iter; left time: 476.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0688360 Vali Loss: 0.0637087 Test Loss: 0.0665311\n",
      "Validation loss decreased (0.066476 --> 0.063709).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0641758\n",
      "\tspeed: 0.2029s/iter; left time: 759.5616s\n",
      "\titers: 200, epoch: 4 | loss: 0.0634328\n",
      "\tspeed: 0.1232s/iter; left time: 448.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.95s\n",
      "Steps: 226 | Train Loss: 0.0661288 Vali Loss: 0.0619317 Test Loss: 0.0649719\n",
      "Validation loss decreased (0.063709 --> 0.061932).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0694065\n",
      "\tspeed: 0.2036s/iter; left time: 716.1528s\n",
      "\titers: 200, epoch: 5 | loss: 0.0643803\n",
      "\tspeed: 0.1230s/iter; left time: 420.1641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.89s\n",
      "Steps: 226 | Train Loss: 0.0639748 Vali Loss: 0.0606104 Test Loss: 0.0633659\n",
      "Validation loss decreased (0.061932 --> 0.060610).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637849\n",
      "\tspeed: 0.2024s/iter; left time: 666.0609s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608316\n",
      "\tspeed: 0.1231s/iter; left time: 392.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.91s\n",
      "Steps: 226 | Train Loss: 0.0624958 Vali Loss: 0.0588577 Test Loss: 0.0615097\n",
      "Validation loss decreased (0.060610 --> 0.058858).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0591928\n",
      "\tspeed: 0.2033s/iter; left time: 623.0883s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583320\n",
      "\tspeed: 0.1233s/iter; left time: 365.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.98s\n",
      "Steps: 226 | Train Loss: 0.0614027 Vali Loss: 0.0586346 Test Loss: 0.0618780\n",
      "Validation loss decreased (0.058858 --> 0.058635).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0588122\n",
      "\tspeed: 0.2059s/iter; left time: 584.6852s\n",
      "\titers: 200, epoch: 8 | loss: 0.0603447\n",
      "\tspeed: 0.1233s/iter; left time: 337.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0605622 Vali Loss: 0.0581572 Test Loss: 0.0613240\n",
      "Validation loss decreased (0.058635 --> 0.058157).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0627868\n",
      "\tspeed: 0.2067s/iter; left time: 540.1944s\n",
      "\titers: 200, epoch: 9 | loss: 0.0602490\n",
      "\tspeed: 0.1235s/iter; left time: 310.4578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.09s\n",
      "Steps: 226 | Train Loss: 0.0599007 Vali Loss: 0.0575575 Test Loss: 0.0602312\n",
      "Validation loss decreased (0.058157 --> 0.057558).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0568765\n",
      "\tspeed: 0.2092s/iter; left time: 499.3861s\n",
      "\titers: 200, epoch: 10 | loss: 0.0624954\n",
      "\tspeed: 0.1240s/iter; left time: 283.6920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 226 | Train Loss: 0.0593471 Vali Loss: 0.0574005 Test Loss: 0.0601187\n",
      "Validation loss decreased (0.057558 --> 0.057400).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0596192\n",
      "\tspeed: 0.2111s/iter; left time: 456.0823s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592127\n",
      "\tspeed: 0.1240s/iter; left time: 255.4822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 226 | Train Loss: 0.0590144 Vali Loss: 0.0572044 Test Loss: 0.0598468\n",
      "Validation loss decreased (0.057400 --> 0.057204).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0615893\n",
      "\tspeed: 0.2488s/iter; left time: 481.3734s\n",
      "\titers: 200, epoch: 12 | loss: 0.0559695\n",
      "\tspeed: 0.1233s/iter; left time: 226.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.07s\n",
      "Steps: 226 | Train Loss: 0.0584624 Vali Loss: 0.0569848 Test Loss: 0.0595079\n",
      "Validation loss decreased (0.057204 --> 0.056985).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0584085\n",
      "\tspeed: 0.2060s/iter; left time: 352.1014s\n",
      "\titers: 200, epoch: 13 | loss: 0.0579237\n",
      "\tspeed: 0.1232s/iter; left time: 198.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 226 | Train Loss: 0.0582000 Vali Loss: 0.0570694 Test Loss: 0.0599025\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0592260\n",
      "\tspeed: 0.2046s/iter; left time: 303.4499s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572892\n",
      "\tspeed: 0.1232s/iter; left time: 170.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 226 | Train Loss: 0.0580283 Vali Loss: 0.0570102 Test Loss: 0.0598739\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0573419\n",
      "\tspeed: 0.2042s/iter; left time: 256.6187s\n",
      "\titers: 200, epoch: 15 | loss: 0.0580359\n",
      "\tspeed: 0.1232s/iter; left time: 142.5573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0577937 Vali Loss: 0.0566747 Test Loss: 0.0594992\n",
      "Validation loss decreased (0.056985 --> 0.056675).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0595963\n",
      "\tspeed: 0.2052s/iter; left time: 211.5397s\n",
      "\titers: 200, epoch: 16 | loss: 0.0581507\n",
      "\tspeed: 0.1232s/iter; left time: 114.7433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0575645 Vali Loss: 0.0563853 Test Loss: 0.0590242\n",
      "Validation loss decreased (0.056675 --> 0.056385).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0537569\n",
      "\tspeed: 0.2030s/iter; left time: 163.3863s\n",
      "\titers: 200, epoch: 17 | loss: 0.0591558\n",
      "\tspeed: 0.1232s/iter; left time: 86.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0572866 Vali Loss: 0.0562514 Test Loss: 0.0589677\n",
      "Validation loss decreased (0.056385 --> 0.056251).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0616697\n",
      "\tspeed: 0.2047s/iter; left time: 118.5172s\n",
      "\titers: 200, epoch: 18 | loss: 0.0598275\n",
      "\tspeed: 0.1234s/iter; left time: 59.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 226 | Train Loss: 0.0571565 Vali Loss: 0.0560796 Test Loss: 0.0589612\n",
      "Validation loss decreased (0.056251 --> 0.056080).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0564034\n",
      "\tspeed: 0.2039s/iter; left time: 71.9723s\n",
      "\titers: 200, epoch: 19 | loss: 0.0553540\n",
      "\tspeed: 0.1234s/iter; left time: 31.2220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 226 | Train Loss: 0.0570096 Vali Loss: 0.0560311 Test Loss: 0.0588667\n",
      "Validation loss decreased (0.056080 --> 0.056031).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0543480\n",
      "\tspeed: 0.2057s/iter; left time: 26.1271s\n",
      "\titers: 200, epoch: 20 | loss: 0.0582589\n",
      "\tspeed: 0.1231s/iter; left time: 3.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 226 | Train Loss: 0.0568625 Vali Loss: 0.0558932 Test Loss: 0.0588943\n",
      "Validation loss decreased (0.056031 --> 0.055893).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010509154759347439, rmse:0.10251417011022568, mae:0.058894332498311996, rse:0.38735058903694153\n",
      "Intermediate time for IT and pred_len 24: 00h:22m:16.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1246291\n",
      "\tspeed: 0.1502s/iter; left time: 661.2296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1170714\n",
      "\tspeed: 0.1238s/iter; left time: 532.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.1307737 Vali Loss: 0.0961518 Test Loss: 0.0997427\n",
      "Validation loss decreased (inf --> 0.096152).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0948495\n",
      "\tspeed: 0.2148s/iter; left time: 896.9106s\n",
      "\titers: 200, epoch: 2 | loss: 0.0954342\n",
      "\tspeed: 0.1237s/iter; left time: 504.1970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0978327 Vali Loss: 0.0849951 Test Loss: 0.0893700\n",
      "Validation loss decreased (0.096152 --> 0.084995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0911742\n",
      "\tspeed: 0.2054s/iter; left time: 811.6634s\n",
      "\titers: 200, epoch: 3 | loss: 0.0884128\n",
      "\tspeed: 0.1237s/iter; left time: 476.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 225 | Train Loss: 0.0892406 Vali Loss: 0.0825536 Test Loss: 0.0875067\n",
      "Validation loss decreased (0.084995 --> 0.082554).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0867200\n",
      "\tspeed: 0.2058s/iter; left time: 766.8796s\n",
      "\titers: 200, epoch: 4 | loss: 0.0846905\n",
      "\tspeed: 0.1239s/iter; left time: 449.1484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0855845 Vali Loss: 0.0808799 Test Loss: 0.0862431\n",
      "Validation loss decreased (0.082554 --> 0.080880).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0797206\n",
      "\tspeed: 0.2094s/iter; left time: 733.1353s\n",
      "\titers: 200, epoch: 5 | loss: 0.0888789\n",
      "\tspeed: 0.1238s/iter; left time: 421.2037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0834375 Vali Loss: 0.0790271 Test Loss: 0.0843552\n",
      "Validation loss decreased (0.080880 --> 0.079027).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0826562\n",
      "\tspeed: 0.2102s/iter; left time: 688.7716s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778374\n",
      "\tspeed: 0.1240s/iter; left time: 393.7166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0821521 Vali Loss: 0.0782054 Test Loss: 0.0836802\n",
      "Validation loss decreased (0.079027 --> 0.078205).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0799794\n",
      "\tspeed: 0.2217s/iter; left time: 676.3642s\n",
      "\titers: 200, epoch: 7 | loss: 0.0788258\n",
      "\tspeed: 0.1239s/iter; left time: 365.7743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0813023 Vali Loss: 0.0782941 Test Loss: 0.0837826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0789111\n",
      "\tspeed: 0.2070s/iter; left time: 585.0643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0816973\n",
      "\tspeed: 0.1240s/iter; left time: 338.0102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 225 | Train Loss: 0.0806553 Vali Loss: 0.0778118 Test Loss: 0.0829287\n",
      "Validation loss decreased (0.078205 --> 0.077812).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0801560\n",
      "\tspeed: 0.2108s/iter; left time: 548.3920s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835952\n",
      "\tspeed: 0.1246s/iter; left time: 311.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0801367 Vali Loss: 0.0776850 Test Loss: 0.0827472\n",
      "Validation loss decreased (0.077812 --> 0.077685).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809377\n",
      "\tspeed: 0.2122s/iter; left time: 504.1102s\n",
      "\titers: 200, epoch: 10 | loss: 0.0785008\n",
      "\tspeed: 0.1244s/iter; left time: 283.1045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0797318 Vali Loss: 0.0775685 Test Loss: 0.0825838\n",
      "Validation loss decreased (0.077685 --> 0.077569).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773143\n",
      "\tspeed: 0.2090s/iter; left time: 449.5153s\n",
      "\titers: 200, epoch: 11 | loss: 0.0786918\n",
      "\tspeed: 0.1238s/iter; left time: 253.8170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0793911 Vali Loss: 0.0773214 Test Loss: 0.0821988\n",
      "Validation loss decreased (0.077569 --> 0.077321).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0843383\n",
      "\tspeed: 0.2057s/iter; left time: 396.2053s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793643\n",
      "\tspeed: 0.1236s/iter; left time: 225.7655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0790657 Vali Loss: 0.0772528 Test Loss: 0.0820618\n",
      "Validation loss decreased (0.077321 --> 0.077253).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0776302\n",
      "\tspeed: 0.2073s/iter; left time: 352.5856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800399\n",
      "\tspeed: 0.1238s/iter; left time: 198.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 225 | Train Loss: 0.0787998 Vali Loss: 0.0769798 Test Loss: 0.0813489\n",
      "Validation loss decreased (0.077253 --> 0.076980).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0797844\n",
      "\tspeed: 0.2163s/iter; left time: 319.2716s\n",
      "\titers: 200, epoch: 14 | loss: 0.0793766\n",
      "\tspeed: 0.1239s/iter; left time: 170.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0785462 Vali Loss: 0.0769688 Test Loss: 0.0817476\n",
      "Validation loss decreased (0.076980 --> 0.076969).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755080\n",
      "\tspeed: 0.2114s/iter; left time: 264.5179s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763225\n",
      "\tspeed: 0.1237s/iter; left time: 142.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 225 | Train Loss: 0.0783976 Vali Loss: 0.0769022 Test Loss: 0.0815266\n",
      "Validation loss decreased (0.076969 --> 0.076902).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0759583\n",
      "\tspeed: 0.2252s/iter; left time: 231.1064s\n",
      "\titers: 200, epoch: 16 | loss: 0.0809015\n",
      "\tspeed: 0.1237s/iter; left time: 114.5102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 225 | Train Loss: 0.0782896 Vali Loss: 0.0767670 Test Loss: 0.0815434\n",
      "Validation loss decreased (0.076902 --> 0.076767).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807900\n",
      "\tspeed: 0.2069s/iter; left time: 165.7560s\n",
      "\titers: 200, epoch: 17 | loss: 0.0796471\n",
      "\tspeed: 0.1236s/iter; left time: 86.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0780911 Vali Loss: 0.0765583 Test Loss: 0.0813489\n",
      "Validation loss decreased (0.076767 --> 0.076558).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750794\n",
      "\tspeed: 0.2082s/iter; left time: 119.9227s\n",
      "\titers: 200, epoch: 18 | loss: 0.0804618\n",
      "\tspeed: 0.1238s/iter; left time: 58.9253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0778818 Vali Loss: 0.0766912 Test Loss: 0.0816509\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737888\n",
      "\tspeed: 0.2070s/iter; left time: 72.6420s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769352\n",
      "\tspeed: 0.1236s/iter; left time: 31.0254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0777152 Vali Loss: 0.0764046 Test Loss: 0.0812570\n",
      "Validation loss decreased (0.076558 --> 0.076405).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0773344\n",
      "\tspeed: 0.2066s/iter; left time: 26.0332s\n",
      "\titers: 200, epoch: 20 | loss: 0.0809498\n",
      "\tspeed: 0.1237s/iter; left time: 3.2171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0776153 Vali Loss: 0.0764732 Test Loss: 0.0810120\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018536528572440147, rmse:0.13614891469478607, mae:0.08125697821378708, rse:0.5147936940193176\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1274510\n",
      "\tspeed: 0.1244s/iter; left time: 547.5407s\n",
      "\titers: 200, epoch: 1 | loss: 0.1164847\n",
      "\tspeed: 0.1235s/iter; left time: 531.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.93s\n",
      "Steps: 225 | Train Loss: 0.1317651 Vali Loss: 0.0965845 Test Loss: 0.1001872\n",
      "Validation loss decreased (inf --> 0.096585).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0931384\n",
      "\tspeed: 0.2059s/iter; left time: 859.8003s\n",
      "\titers: 200, epoch: 2 | loss: 0.0937748\n",
      "\tspeed: 0.1237s/iter; left time: 504.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0983610 Vali Loss: 0.0854578 Test Loss: 0.0899371\n",
      "Validation loss decreased (0.096585 --> 0.085458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0879004\n",
      "\tspeed: 0.2064s/iter; left time: 815.6114s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821228\n",
      "\tspeed: 0.1238s/iter; left time: 476.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0891939 Vali Loss: 0.0823376 Test Loss: 0.0874421\n",
      "Validation loss decreased (0.085458 --> 0.082338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863800\n",
      "\tspeed: 0.2064s/iter; left time: 769.2313s\n",
      "\titers: 200, epoch: 4 | loss: 0.0839542\n",
      "\tspeed: 0.1237s/iter; left time: 448.7139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0857099 Vali Loss: 0.0812594 Test Loss: 0.0861944\n",
      "Validation loss decreased (0.082338 --> 0.081259).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0866721\n",
      "\tspeed: 0.2086s/iter; left time: 730.2604s\n",
      "\titers: 200, epoch: 5 | loss: 0.0816669\n",
      "\tspeed: 0.1237s/iter; left time: 420.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0838621 Vali Loss: 0.0807487 Test Loss: 0.0857736\n",
      "Validation loss decreased (0.081259 --> 0.080749).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839811\n",
      "\tspeed: 0.2056s/iter; left time: 673.5906s\n",
      "\titers: 200, epoch: 6 | loss: 0.0856897\n",
      "\tspeed: 0.1236s/iter; left time: 392.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 225 | Train Loss: 0.0824806 Vali Loss: 0.0787402 Test Loss: 0.0840767\n",
      "Validation loss decreased (0.080749 --> 0.078740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0824418\n",
      "\tspeed: 0.2073s/iter; left time: 632.4306s\n",
      "\titers: 200, epoch: 7 | loss: 0.0837693\n",
      "\tspeed: 0.1236s/iter; left time: 364.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0817001 Vali Loss: 0.0782434 Test Loss: 0.0841690\n",
      "Validation loss decreased (0.078740 --> 0.078243).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0798583\n",
      "\tspeed: 0.2053s/iter; left time: 580.1476s\n",
      "\titers: 200, epoch: 8 | loss: 0.0807079\n",
      "\tspeed: 0.1237s/iter; left time: 337.1205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0809182 Vali Loss: 0.0780490 Test Loss: 0.0831145\n",
      "Validation loss decreased (0.078243 --> 0.078049).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792143\n",
      "\tspeed: 0.2077s/iter; left time: 540.2567s\n",
      "\titers: 200, epoch: 9 | loss: 0.0885995\n",
      "\tspeed: 0.1240s/iter; left time: 310.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0805063 Vali Loss: 0.0778816 Test Loss: 0.0831148\n",
      "Validation loss decreased (0.078049 --> 0.077882).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0826082\n",
      "\tspeed: 0.2055s/iter; left time: 488.1716s\n",
      "\titers: 200, epoch: 10 | loss: 0.0805768\n",
      "\tspeed: 0.1239s/iter; left time: 282.1076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 225 | Train Loss: 0.0798953 Vali Loss: 0.0776451 Test Loss: 0.0828241\n",
      "Validation loss decreased (0.077882 --> 0.077645).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0783376\n",
      "\tspeed: 0.2062s/iter; left time: 443.5818s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749998\n",
      "\tspeed: 0.1243s/iter; left time: 254.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0794778 Vali Loss: 0.0775692 Test Loss: 0.0823288\n",
      "Validation loss decreased (0.077645 --> 0.077569).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0794503\n",
      "\tspeed: 0.2062s/iter; left time: 397.2318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0762411\n",
      "\tspeed: 0.1248s/iter; left time: 227.7985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0791353 Vali Loss: 0.0772091 Test Loss: 0.0826240\n",
      "Validation loss decreased (0.077569 --> 0.077209).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0795701\n",
      "\tspeed: 0.2074s/iter; left time: 352.7250s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782318\n",
      "\tspeed: 0.1243s/iter; left time: 198.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0788803 Vali Loss: 0.0770195 Test Loss: 0.0825596\n",
      "Validation loss decreased (0.077209 --> 0.077020).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0823900\n",
      "\tspeed: 0.2073s/iter; left time: 305.9652s\n",
      "\titers: 200, epoch: 14 | loss: 0.0794970\n",
      "\tspeed: 0.1244s/iter; left time: 171.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0786027 Vali Loss: 0.0769410 Test Loss: 0.0823892\n",
      "Validation loss decreased (0.077020 --> 0.076941).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0766661\n",
      "\tspeed: 0.2087s/iter; left time: 261.0253s\n",
      "\titers: 200, epoch: 15 | loss: 0.0806809\n",
      "\tspeed: 0.1242s/iter; left time: 142.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.13s\n",
      "Steps: 225 | Train Loss: 0.0783255 Vali Loss: 0.0767500 Test Loss: 0.0819774\n",
      "Validation loss decreased (0.076941 --> 0.076750).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0756244\n",
      "\tspeed: 0.2075s/iter; left time: 212.9265s\n",
      "\titers: 200, epoch: 16 | loss: 0.0810186\n",
      "\tspeed: 0.1237s/iter; left time: 114.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0781282 Vali Loss: 0.0768651 Test Loss: 0.0821056\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807884\n",
      "\tspeed: 0.2031s/iter; left time: 162.7110s\n",
      "\titers: 200, epoch: 17 | loss: 0.0767048\n",
      "\tspeed: 0.1235s/iter; left time: 86.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.93s\n",
      "Steps: 225 | Train Loss: 0.0778863 Vali Loss: 0.0768578 Test Loss: 0.0821329\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0774752\n",
      "\tspeed: 0.2075s/iter; left time: 119.5412s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812058\n",
      "\tspeed: 0.1238s/iter; left time: 58.9159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.10s\n",
      "Steps: 225 | Train Loss: 0.0777132 Vali Loss: 0.0766468 Test Loss: 0.0820385\n",
      "Validation loss decreased (0.076750 --> 0.076647).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0832625\n",
      "\tspeed: 0.2046s/iter; left time: 71.8297s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773597\n",
      "\tspeed: 0.1242s/iter; left time: 31.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0775751 Vali Loss: 0.0764721 Test Loss: 0.0817944\n",
      "Validation loss decreased (0.076647 --> 0.076472).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0786291\n",
      "\tspeed: 0.2056s/iter; left time: 25.9106s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785749\n",
      "\tspeed: 0.1248s/iter; left time: 3.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0774495 Vali Loss: 0.0764009 Test Loss: 0.0816955\n",
      "Validation loss decreased (0.076472 --> 0.076401).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018820010125637054, rmse:0.13718603551387787, mae:0.08169551938772202, rse:0.5187152028083801\n",
      "Intermediate time for IT and pred_len 96: 00h:22m:26.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1274062\n",
      "\tspeed: 0.1487s/iter; left time: 654.5295s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201956\n",
      "\tspeed: 0.1255s/iter; left time: 539.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 225 | Train Loss: 0.1337667 Vali Loss: 0.0992412 Test Loss: 0.1025607\n",
      "Validation loss decreased (inf --> 0.099241).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0999286\n",
      "\tspeed: 0.2093s/iter; left time: 874.2423s\n",
      "\titers: 200, epoch: 2 | loss: 0.0971880\n",
      "\tspeed: 0.1240s/iter; left time: 505.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.1026157 Vali Loss: 0.0904709 Test Loss: 0.0948137\n",
      "Validation loss decreased (0.099241 --> 0.090471).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945068\n",
      "\tspeed: 0.2068s/iter; left time: 817.0345s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920321\n",
      "\tspeed: 0.1240s/iter; left time: 477.4222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0944772 Vali Loss: 0.0859233 Test Loss: 0.0916047\n",
      "Validation loss decreased (0.090471 --> 0.085923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0924504\n",
      "\tspeed: 0.2065s/iter; left time: 769.5238s\n",
      "\titers: 200, epoch: 4 | loss: 0.0887412\n",
      "\tspeed: 0.1243s/iter; left time: 450.5452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.12s\n",
      "Steps: 225 | Train Loss: 0.0908827 Vali Loss: 0.0868275 Test Loss: 0.0906128\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0887746\n",
      "\tspeed: 0.2071s/iter; left time: 724.9291s\n",
      "\titers: 200, epoch: 5 | loss: 0.0888827\n",
      "\tspeed: 0.1252s/iter; left time: 425.7346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0887758 Vali Loss: 0.0842572 Test Loss: 0.0898299\n",
      "Validation loss decreased (0.085923 --> 0.084257).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897459\n",
      "\tspeed: 0.2071s/iter; left time: 678.5198s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841771\n",
      "\tspeed: 0.1247s/iter; left time: 396.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.21s\n",
      "Steps: 225 | Train Loss: 0.0874938 Vali Loss: 0.0833510 Test Loss: 0.0876509\n",
      "Validation loss decreased (0.084257 --> 0.083351).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0841005\n",
      "\tspeed: 0.2065s/iter; left time: 629.8886s\n",
      "\titers: 200, epoch: 7 | loss: 0.0883561\n",
      "\tspeed: 0.1246s/iter; left time: 367.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 225 | Train Loss: 0.0864298 Vali Loss: 0.0829024 Test Loss: 0.0872512\n",
      "Validation loss decreased (0.083351 --> 0.082902).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0864878\n",
      "\tspeed: 0.2065s/iter; left time: 583.5700s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836292\n",
      "\tspeed: 0.1244s/iter; left time: 339.0295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 225 | Train Loss: 0.0858088 Vali Loss: 0.0824455 Test Loss: 0.0869225\n",
      "Validation loss decreased (0.082902 --> 0.082446).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0883054\n",
      "\tspeed: 0.2067s/iter; left time: 537.6703s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835050\n",
      "\tspeed: 0.1243s/iter; left time: 310.7687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0852685 Vali Loss: 0.0827654 Test Loss: 0.0869103\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0833669\n",
      "\tspeed: 0.2058s/iter; left time: 489.0270s\n",
      "\titers: 200, epoch: 10 | loss: 0.0865522\n",
      "\tspeed: 0.1248s/iter; left time: 283.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0848592 Vali Loss: 0.0819396 Test Loss: 0.0861626\n",
      "Validation loss decreased (0.082446 --> 0.081940).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0845838\n",
      "\tspeed: 0.2060s/iter; left time: 443.1676s\n",
      "\titers: 200, epoch: 11 | loss: 0.0861566\n",
      "\tspeed: 0.1244s/iter; left time: 255.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0845001 Vali Loss: 0.0820744 Test Loss: 0.0859507\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0851333\n",
      "\tspeed: 0.2081s/iter; left time: 400.7558s\n",
      "\titers: 200, epoch: 12 | loss: 0.0838776\n",
      "\tspeed: 0.1247s/iter; left time: 227.7526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0842150 Vali Loss: 0.0822200 Test Loss: 0.0856628\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0833532\n",
      "\tspeed: 0.2085s/iter; left time: 354.6808s\n",
      "\titers: 200, epoch: 13 | loss: 0.0793798\n",
      "\tspeed: 0.1250s/iter; left time: 200.0957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 225 | Train Loss: 0.0838517 Vali Loss: 0.0816093 Test Loss: 0.0854676\n",
      "Validation loss decreased (0.081940 --> 0.081609).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0838834\n",
      "\tspeed: 0.2074s/iter; left time: 306.1636s\n",
      "\titers: 200, epoch: 14 | loss: 0.0833073\n",
      "\tspeed: 0.1246s/iter; left time: 171.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 225 | Train Loss: 0.0836320 Vali Loss: 0.0817205 Test Loss: 0.0854512\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0802528\n",
      "\tspeed: 0.2063s/iter; left time: 258.0424s\n",
      "\titers: 200, epoch: 15 | loss: 0.0804740\n",
      "\tspeed: 0.1245s/iter; left time: 143.2631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0834320 Vali Loss: 0.0816327 Test Loss: 0.0855313\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829816\n",
      "\tspeed: 0.2053s/iter; left time: 210.6108s\n",
      "\titers: 200, epoch: 16 | loss: 0.0838366\n",
      "\tspeed: 0.1250s/iter; left time: 115.7589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.30s\n",
      "Steps: 225 | Train Loss: 0.0831726 Vali Loss: 0.0816667 Test Loss: 0.0854638\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0814890\n",
      "\tspeed: 0.2073s/iter; left time: 166.0414s\n",
      "\titers: 200, epoch: 17 | loss: 0.0822350\n",
      "\tspeed: 0.1256s/iter; left time: 88.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.39s\n",
      "Steps: 225 | Train Loss: 0.0829919 Vali Loss: 0.0820202 Test Loss: 0.0856585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839811\n",
      "\tspeed: 0.2077s/iter; left time: 119.6551s\n",
      "\titers: 200, epoch: 18 | loss: 0.0843205\n",
      "\tspeed: 0.1256s/iter; left time: 59.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 225 | Train Loss: 0.0828663 Vali Loss: 0.0817814 Test Loss: 0.0856330\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0196785070002079, rmse:0.1402800977230072, mae:0.08546759188175201, rse:0.5309070944786072\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1252874\n",
      "\tspeed: 0.1258s/iter; left time: 553.5807s\n",
      "\titers: 200, epoch: 1 | loss: 0.1240589\n",
      "\tspeed: 0.1251s/iter; left time: 537.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.1343383 Vali Loss: 0.0994309 Test Loss: 0.1027002\n",
      "Validation loss decreased (inf --> 0.099431).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1012369\n",
      "\tspeed: 0.2111s/iter; left time: 881.4227s\n",
      "\titers: 200, epoch: 2 | loss: 0.0978683\n",
      "\tspeed: 0.1247s/iter; left time: 508.3698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.1025567 Vali Loss: 0.0899358 Test Loss: 0.0946148\n",
      "Validation loss decreased (0.099431 --> 0.089936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0953144\n",
      "\tspeed: 0.2091s/iter; left time: 825.9906s\n",
      "\titers: 200, epoch: 3 | loss: 0.0942210\n",
      "\tspeed: 0.1250s/iter; left time: 481.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0939962 Vali Loss: 0.0862187 Test Loss: 0.0924182\n",
      "Validation loss decreased (0.089936 --> 0.086219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0886576\n",
      "\tspeed: 0.2070s/iter; left time: 771.3484s\n",
      "\titers: 200, epoch: 4 | loss: 0.0866066\n",
      "\tspeed: 0.1250s/iter; left time: 453.1968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.30s\n",
      "Steps: 225 | Train Loss: 0.0907466 Vali Loss: 0.0852378 Test Loss: 0.0902182\n",
      "Validation loss decreased (0.086219 --> 0.085238).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0886593\n",
      "\tspeed: 0.2072s/iter; left time: 725.5006s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915526\n",
      "\tspeed: 0.1247s/iter; left time: 424.1730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0887809 Vali Loss: 0.0845530 Test Loss: 0.0897828\n",
      "Validation loss decreased (0.085238 --> 0.084553).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0855750\n",
      "\tspeed: 0.2105s/iter; left time: 689.7385s\n",
      "\titers: 200, epoch: 6 | loss: 0.0881630\n",
      "\tspeed: 0.1254s/iter; left time: 398.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 225 | Train Loss: 0.0876069 Vali Loss: 0.0839415 Test Loss: 0.0886852\n",
      "Validation loss decreased (0.084553 --> 0.083941).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0855649\n",
      "\tspeed: 0.2094s/iter; left time: 638.9149s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861583\n",
      "\tspeed: 0.1251s/iter; left time: 369.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0867376 Vali Loss: 0.0830761 Test Loss: 0.0885835\n",
      "Validation loss decreased (0.083941 --> 0.083076).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0900731\n",
      "\tspeed: 0.2115s/iter; left time: 597.7728s\n",
      "\titers: 200, epoch: 8 | loss: 0.0837901\n",
      "\tspeed: 0.1249s/iter; left time: 340.4302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 225 | Train Loss: 0.0862249 Vali Loss: 0.0828923 Test Loss: 0.0886307\n",
      "Validation loss decreased (0.083076 --> 0.082892).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0850363\n",
      "\tspeed: 0.2107s/iter; left time: 548.1492s\n",
      "\titers: 200, epoch: 9 | loss: 0.0847476\n",
      "\tspeed: 0.1255s/iter; left time: 313.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 225 | Train Loss: 0.0856819 Vali Loss: 0.0822114 Test Loss: 0.0875634\n",
      "Validation loss decreased (0.082892 --> 0.082211).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0865811\n",
      "\tspeed: 0.2078s/iter; left time: 493.7087s\n",
      "\titers: 200, epoch: 10 | loss: 0.0885911\n",
      "\tspeed: 0.1250s/iter; left time: 284.5643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0852687 Vali Loss: 0.0822291 Test Loss: 0.0871013\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0820281\n",
      "\tspeed: 0.2088s/iter; left time: 449.0294s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828203\n",
      "\tspeed: 0.1248s/iter; left time: 255.9540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0847809 Vali Loss: 0.0817572 Test Loss: 0.0870292\n",
      "Validation loss decreased (0.082211 --> 0.081757).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821820\n",
      "\tspeed: 0.2064s/iter; left time: 397.4723s\n",
      "\titers: 200, epoch: 12 | loss: 0.0837839\n",
      "\tspeed: 0.1249s/iter; left time: 228.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0845500 Vali Loss: 0.0819127 Test Loss: 0.0866175\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0802262\n",
      "\tspeed: 0.2076s/iter; left time: 353.1202s\n",
      "\titers: 200, epoch: 13 | loss: 0.0826065\n",
      "\tspeed: 0.1251s/iter; left time: 200.2906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 225 | Train Loss: 0.0842274 Vali Loss: 0.0817468 Test Loss: 0.0864959\n",
      "Validation loss decreased (0.081757 --> 0.081747).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841475\n",
      "\tspeed: 0.2083s/iter; left time: 307.4843s\n",
      "\titers: 200, epoch: 14 | loss: 0.0823566\n",
      "\tspeed: 0.1249s/iter; left time: 171.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0840051 Vali Loss: 0.0814703 Test Loss: 0.0864162\n",
      "Validation loss decreased (0.081747 --> 0.081470).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0832792\n",
      "\tspeed: 0.2078s/iter; left time: 259.9452s\n",
      "\titers: 200, epoch: 15 | loss: 0.0832064\n",
      "\tspeed: 0.1246s/iter; left time: 143.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0837586 Vali Loss: 0.0815400 Test Loss: 0.0859518\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0816924\n",
      "\tspeed: 0.2051s/iter; left time: 210.4502s\n",
      "\titers: 200, epoch: 16 | loss: 0.0879495\n",
      "\tspeed: 0.1248s/iter; left time: 115.6038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.19s\n",
      "Steps: 225 | Train Loss: 0.0834792 Vali Loss: 0.0814463 Test Loss: 0.0862716\n",
      "Validation loss decreased (0.081470 --> 0.081446).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0814074\n",
      "\tspeed: 0.2072s/iter; left time: 165.9816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0830946\n",
      "\tspeed: 0.1248s/iter; left time: 87.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.27s\n",
      "Steps: 225 | Train Loss: 0.0833982 Vali Loss: 0.0813847 Test Loss: 0.0859058\n",
      "Validation loss decreased (0.081446 --> 0.081385).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0828545\n",
      "\tspeed: 0.2064s/iter; left time: 118.8758s\n",
      "\titers: 200, epoch: 18 | loss: 0.0824811\n",
      "\tspeed: 0.1247s/iter; left time: 59.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0832192 Vali Loss: 0.0813554 Test Loss: 0.0859548\n",
      "Validation loss decreased (0.081385 --> 0.081355).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0864082\n",
      "\tspeed: 0.2073s/iter; left time: 72.7458s\n",
      "\titers: 200, epoch: 19 | loss: 0.0809942\n",
      "\tspeed: 0.1252s/iter; left time: 31.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.0830247 Vali Loss: 0.0809955 Test Loss: 0.0858491\n",
      "Validation loss decreased (0.081355 --> 0.080996).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0841437\n",
      "\tspeed: 0.2081s/iter; left time: 26.2232s\n",
      "\titers: 200, epoch: 20 | loss: 0.0797103\n",
      "\tspeed: 0.1254s/iter; left time: 3.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 225 | Train Loss: 0.0828929 Vali Loss: 0.0811498 Test Loss: 0.0856923\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020069275051355362, rmse:0.14166606962680817, mae:0.08584906160831451, rse:0.5361524224281311\n",
      "Intermediate time for IT and pred_len 168: 00h:21m:19.68s\n",
      "Intermediate time for IT: 01h:06m:01.95s\n",
      "Total time: 02h:17m:45.04s\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list\n",
    "patchtst_results = []\n",
    "\n",
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "\n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len=336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            if seq_len == 512:\n",
    "                batch_size = 64\n",
    "            else:\n",
    "                batch_size = 128\n",
    "                \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0365  0.1910  0.1267\n",
       "        168       0.0384  0.1959  0.1325\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1037  0.0574\n",
       "        96        0.0201  0.1418  0.0822\n",
       "        168       0.0219  0.1478  0.0877\n",
       "GB      24        0.0263  0.1621  0.1036\n",
       "        96        0.0425  0.2061  0.1391\n",
       "        168       0.0442  0.2102  0.1445\n",
       "IT      24        0.0104  0.1021  0.0587\n",
       "        96        0.0187  0.1367  0.0815\n",
       "        168       0.0199  0.1410  0.0857"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1467022\n",
      "\tspeed: 0.1228s/iter; left time: 2738.2303s\n",
      "\titers: 200, epoch: 1 | loss: 0.1380337\n",
      "\tspeed: 0.0523s/iter; left time: 1161.8565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:17.55s\n",
      "Steps: 224 | Train Loss: 0.1492598 Vali Loss: 0.1491447 Test Loss: 0.1573455\n",
      "Validation loss decreased (inf --> 0.149145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0933916\n",
      "\tspeed: 0.0933s/iter; left time: 2059.6937s\n",
      "\titers: 200, epoch: 2 | loss: 0.0793409\n",
      "\tspeed: 0.0520s/iter; left time: 1143.6026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0958381 Vali Loss: 0.0959918 Test Loss: 0.0965967\n",
      "Validation loss decreased (0.149145 --> 0.095992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804107\n",
      "\tspeed: 0.0927s/iter; left time: 2026.3754s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822360\n",
      "\tspeed: 0.0521s/iter; left time: 1133.9835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0800409 Vali Loss: 0.0911792 Test Loss: 0.0924903\n",
      "Validation loss decreased (0.095992 --> 0.091179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0721088\n",
      "\tspeed: 0.0919s/iter; left time: 1988.3672s\n",
      "\titers: 200, epoch: 4 | loss: 0.0784065\n",
      "\tspeed: 0.0521s/iter; left time: 1121.0181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0768202 Vali Loss: 0.0894785 Test Loss: 0.0912090\n",
      "Validation loss decreased (0.091179 --> 0.089479).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0701359\n",
      "\tspeed: 0.0919s/iter; left time: 1968.0610s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721674\n",
      "\tspeed: 0.0520s/iter; left time: 1108.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0751275 Vali Loss: 0.0886305 Test Loss: 0.0903440\n",
      "Validation loss decreased (0.089479 --> 0.088631).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0747568\n",
      "\tspeed: 0.0922s/iter; left time: 1952.3521s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739783\n",
      "\tspeed: 0.0520s/iter; left time: 1095.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.82s\n",
      "Steps: 224 | Train Loss: 0.0740978 Vali Loss: 0.0879776 Test Loss: 0.0896847\n",
      "Validation loss decreased (0.088631 --> 0.087978).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0773371\n",
      "\tspeed: 0.0916s/iter; left time: 1918.9129s\n",
      "\titers: 200, epoch: 7 | loss: 0.0693570\n",
      "\tspeed: 0.0521s/iter; left time: 1085.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0731795 Vali Loss: 0.0878054 Test Loss: 0.0894686\n",
      "Validation loss decreased (0.087978 --> 0.087805).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742184\n",
      "\tspeed: 0.0920s/iter; left time: 1907.8917s\n",
      "\titers: 200, epoch: 8 | loss: 0.0694305\n",
      "\tspeed: 0.0520s/iter; left time: 1073.5789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0726620 Vali Loss: 0.0872411 Test Loss: 0.0890743\n",
      "Validation loss decreased (0.087805 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0730793\n",
      "\tspeed: 0.0919s/iter; left time: 1884.5651s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740317\n",
      "\tspeed: 0.0521s/iter; left time: 1063.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0721427 Vali Loss: 0.0873636 Test Loss: 0.0895516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0651195\n",
      "\tspeed: 0.0912s/iter; left time: 1849.6289s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683019\n",
      "\tspeed: 0.0520s/iter; left time: 1049.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0717890 Vali Loss: 0.0870031 Test Loss: 0.0891616\n",
      "Validation loss decreased (0.087241 --> 0.087003).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0714403\n",
      "\tspeed: 0.0917s/iter; left time: 1840.4068s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766668\n",
      "\tspeed: 0.0522s/iter; left time: 1042.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0714359 Vali Loss: 0.0870827 Test Loss: 0.0894357\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0713613\n",
      "\tspeed: 0.0918s/iter; left time: 1821.7477s\n",
      "\titers: 200, epoch: 12 | loss: 0.0730791\n",
      "\tspeed: 0.0520s/iter; left time: 1027.2456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0711605 Vali Loss: 0.0868916 Test Loss: 0.0890513\n",
      "Validation loss decreased (0.087003 --> 0.086892).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0658389\n",
      "\tspeed: 0.0923s/iter; left time: 1810.5726s\n",
      "\titers: 200, epoch: 13 | loss: 0.0685006\n",
      "\tspeed: 0.0522s/iter; left time: 1017.9258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0708652 Vali Loss: 0.0865712 Test Loss: 0.0891132\n",
      "Validation loss decreased (0.086892 --> 0.086571).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0742952\n",
      "\tspeed: 0.0923s/iter; left time: 1790.4333s\n",
      "\titers: 200, epoch: 14 | loss: 0.0701290\n",
      "\tspeed: 0.0522s/iter; left time: 1007.3169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0706609 Vali Loss: 0.0864862 Test Loss: 0.0889904\n",
      "Validation loss decreased (0.086571 --> 0.086486).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0725446\n",
      "\tspeed: 0.0918s/iter; left time: 1759.3193s\n",
      "\titers: 200, epoch: 15 | loss: 0.0695209\n",
      "\tspeed: 0.0521s/iter; left time: 994.0532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0704827 Vali Loss: 0.0864452 Test Loss: 0.0889387\n",
      "Validation loss decreased (0.086486 --> 0.086445).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0676632\n",
      "\tspeed: 0.0926s/iter; left time: 1754.8505s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735662\n",
      "\tspeed: 0.0522s/iter; left time: 983.1992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0703078 Vali Loss: 0.0865087 Test Loss: 0.0890939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0669014\n",
      "\tspeed: 0.0913s/iter; left time: 1709.1642s\n",
      "\titers: 200, epoch: 17 | loss: 0.0692772\n",
      "\tspeed: 0.0520s/iter; left time: 968.4467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0701388 Vali Loss: 0.0867771 Test Loss: 0.0890331\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0704841\n",
      "\tspeed: 0.0918s/iter; left time: 1698.3764s\n",
      "\titers: 200, epoch: 18 | loss: 0.0685036\n",
      "\tspeed: 0.0520s/iter; left time: 956.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0699684 Vali Loss: 0.0864049 Test Loss: 0.0891183\n",
      "Validation loss decreased (0.086445 --> 0.086405).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0693344\n",
      "\tspeed: 0.0918s/iter; left time: 1677.6074s\n",
      "\titers: 200, epoch: 19 | loss: 0.0699148\n",
      "\tspeed: 0.0520s/iter; left time: 945.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.82s\n",
      "Steps: 224 | Train Loss: 0.0698359 Vali Loss: 0.0864480 Test Loss: 0.0891146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0743156\n",
      "\tspeed: 0.0915s/iter; left time: 1651.0797s\n",
      "\titers: 200, epoch: 20 | loss: 0.0695782\n",
      "\tspeed: 0.0522s/iter; left time: 935.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0698212 Vali Loss: 0.0862729 Test Loss: 0.0889007\n",
      "Validation loss decreased (0.086405 --> 0.086273).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0642834\n",
      "\tspeed: 0.0928s/iter; left time: 1653.1337s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729156\n",
      "\tspeed: 0.0522s/iter; left time: 924.9015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0696815 Vali Loss: 0.0863191 Test Loss: 0.0889219\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0668081\n",
      "\tspeed: 0.0917s/iter; left time: 1614.1587s\n",
      "\titers: 200, epoch: 22 | loss: 0.0675850\n",
      "\tspeed: 0.0519s/iter; left time: 908.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0696013 Vali Loss: 0.0863717 Test Loss: 0.0890059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0662554\n",
      "\tspeed: 0.0918s/iter; left time: 1595.3221s\n",
      "\titers: 200, epoch: 23 | loss: 0.0715963\n",
      "\tspeed: 0.0523s/iter; left time: 902.7860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0694505 Vali Loss: 0.0862607 Test Loss: 0.0890646\n",
      "Validation loss decreased (0.086273 --> 0.086261).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0695211\n",
      "\tspeed: 0.0919s/iter; left time: 1576.1074s\n",
      "\titers: 200, epoch: 24 | loss: 0.0653179\n",
      "\tspeed: 0.0521s/iter; left time: 888.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0693793 Vali Loss: 0.0863263 Test Loss: 0.0889909\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0677006\n",
      "\tspeed: 0.0917s/iter; left time: 1551.5624s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705059\n",
      "\tspeed: 0.0521s/iter; left time: 876.4930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0693588 Vali Loss: 0.0863821 Test Loss: 0.0890807\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0654885\n",
      "\tspeed: 0.0909s/iter; left time: 1518.4668s\n",
      "\titers: 200, epoch: 26 | loss: 0.0649945\n",
      "\tspeed: 0.0522s/iter; left time: 867.3155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0692742 Vali Loss: 0.0864751 Test Loss: 0.0893381\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0677808\n",
      "\tspeed: 0.0915s/iter; left time: 1507.1605s\n",
      "\titers: 200, epoch: 27 | loss: 0.0714075\n",
      "\tspeed: 0.0521s/iter; left time: 853.5828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.82s\n",
      "Steps: 224 | Train Loss: 0.0692092 Vali Loss: 0.0862476 Test Loss: 0.0890449\n",
      "Validation loss decreased (0.086261 --> 0.086248).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0650818\n",
      "\tspeed: 0.0932s/iter; left time: 1515.3784s\n",
      "\titers: 200, epoch: 28 | loss: 0.0720823\n",
      "\tspeed: 0.0523s/iter; left time: 844.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0691955 Vali Loss: 0.0863042 Test Loss: 0.0889602\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0675507\n",
      "\tspeed: 0.0913s/iter; left time: 1463.5355s\n",
      "\titers: 200, epoch: 29 | loss: 0.0689953\n",
      "\tspeed: 0.0522s/iter; left time: 832.1837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0691315 Vali Loss: 0.0862055 Test Loss: 0.0891577\n",
      "Validation loss decreased (0.086248 --> 0.086206).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0723119\n",
      "\tspeed: 0.0921s/iter; left time: 1456.2687s\n",
      "\titers: 200, epoch: 30 | loss: 0.0689444\n",
      "\tspeed: 0.0522s/iter; left time: 819.8923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0690726 Vali Loss: 0.0864122 Test Loss: 0.0891799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0699471\n",
      "\tspeed: 0.0913s/iter; left time: 1422.4287s\n",
      "\titers: 200, epoch: 31 | loss: 0.0650906\n",
      "\tspeed: 0.0520s/iter; left time: 805.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:11.82s\n",
      "Steps: 224 | Train Loss: 0.0690898 Vali Loss: 0.0861617 Test Loss: 0.0890982\n",
      "Validation loss decreased (0.086206 --> 0.086162).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0697123\n",
      "\tspeed: 0.0923s/iter; left time: 1417.4605s\n",
      "\titers: 200, epoch: 32 | loss: 0.0689837\n",
      "\tspeed: 0.0522s/iter; left time: 796.3078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0690290 Vali Loss: 0.0862783 Test Loss: 0.0891600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0689367\n",
      "\tspeed: 0.0921s/iter; left time: 1393.5575s\n",
      "\titers: 200, epoch: 33 | loss: 0.0651389\n",
      "\tspeed: 0.0521s/iter; left time: 783.5860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0689599 Vali Loss: 0.0864315 Test Loss: 0.0891968\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0703542\n",
      "\tspeed: 0.0922s/iter; left time: 1374.2428s\n",
      "\titers: 200, epoch: 34 | loss: 0.0736774\n",
      "\tspeed: 0.0523s/iter; left time: 774.3701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0689449 Vali Loss: 0.0863892 Test Loss: 0.0892073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0694088\n",
      "\tspeed: 0.0920s/iter; left time: 1350.4302s\n",
      "\titers: 200, epoch: 35 | loss: 0.0643488\n",
      "\tspeed: 0.0521s/iter; left time: 760.2767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0689930 Vali Loss: 0.0862459 Test Loss: 0.0891558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0662179\n",
      "\tspeed: 0.0917s/iter; left time: 1326.3345s\n",
      "\titers: 200, epoch: 36 | loss: 0.0716586\n",
      "\tspeed: 0.0522s/iter; left time: 750.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0689090 Vali Loss: 0.0862916 Test Loss: 0.0891562\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0689815\n",
      "\tspeed: 0.0918s/iter; left time: 1306.4955s\n",
      "\titers: 200, epoch: 37 | loss: 0.0692148\n",
      "\tspeed: 0.0521s/iter; left time: 736.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0688933 Vali Loss: 0.0864036 Test Loss: 0.0891469\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0756959\n",
      "\tspeed: 0.0920s/iter; left time: 1288.5300s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706713\n",
      "\tspeed: 0.0522s/iter; left time: 726.3920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0689504 Vali Loss: 0.0863323 Test Loss: 0.0891482\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0717678\n",
      "\tspeed: 0.0921s/iter; left time: 1269.8383s\n",
      "\titers: 200, epoch: 39 | loss: 0.0696688\n",
      "\tspeed: 0.0523s/iter; left time: 715.6231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0688292 Vali Loss: 0.0862189 Test Loss: 0.0891291\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0669256\n",
      "\tspeed: 0.0917s/iter; left time: 1243.5590s\n",
      "\titers: 200, epoch: 40 | loss: 0.0677449\n",
      "\tspeed: 0.0520s/iter; left time: 700.3289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0688930 Vali Loss: 0.0861876 Test Loss: 0.0891016\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0648098\n",
      "\tspeed: 0.0914s/iter; left time: 1219.2675s\n",
      "\titers: 200, epoch: 41 | loss: 0.0646161\n",
      "\tspeed: 0.0523s/iter; left time: 693.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0688258 Vali Loss: 0.0862216 Test Loss: 0.0891206\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021291740238666534, rmse:0.1459168940782547, mae:0.08909820020198822, rse:0.5149609446525574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1485177\n",
      "\tspeed: 0.0536s/iter; left time: 1194.7774s\n",
      "\titers: 200, epoch: 1 | loss: 0.1372107\n",
      "\tspeed: 0.0520s/iter; left time: 1155.3213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.1479508 Vali Loss: 0.1469130 Test Loss: 0.1552787\n",
      "Validation loss decreased (inf --> 0.146913).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0860679\n",
      "\tspeed: 0.0933s/iter; left time: 2058.9109s\n",
      "\titers: 200, epoch: 2 | loss: 0.0842555\n",
      "\tspeed: 0.0523s/iter; left time: 1149.7879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0963806 Vali Loss: 0.0965345 Test Loss: 0.0970062\n",
      "Validation loss decreased (0.146913 --> 0.096534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0792745\n",
      "\tspeed: 0.0931s/iter; left time: 2033.9156s\n",
      "\titers: 200, epoch: 3 | loss: 0.0799089\n",
      "\tspeed: 0.0524s/iter; left time: 1140.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0806034 Vali Loss: 0.0915469 Test Loss: 0.0932558\n",
      "Validation loss decreased (0.096534 --> 0.091547).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0692745\n",
      "\tspeed: 0.0931s/iter; left time: 2013.9274s\n",
      "\titers: 200, epoch: 4 | loss: 0.0753272\n",
      "\tspeed: 0.0524s/iter; left time: 1129.0058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0771334 Vali Loss: 0.0894109 Test Loss: 0.0913275\n",
      "Validation loss decreased (0.091547 --> 0.089411).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0780892\n",
      "\tspeed: 0.0933s/iter; left time: 1996.3633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733127\n",
      "\tspeed: 0.0521s/iter; left time: 1110.4064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0752457 Vali Loss: 0.0887977 Test Loss: 0.0907949\n",
      "Validation loss decreased (0.089411 --> 0.088798).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0735669\n",
      "\tspeed: 0.0927s/iter; left time: 1964.5271s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754406\n",
      "\tspeed: 0.0521s/iter; left time: 1098.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0741429 Vali Loss: 0.0879942 Test Loss: 0.0900813\n",
      "Validation loss decreased (0.088798 --> 0.087994).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0708586\n",
      "\tspeed: 0.0925s/iter; left time: 1939.5686s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723750\n",
      "\tspeed: 0.0520s/iter; left time: 1084.7077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0733710 Vali Loss: 0.0877222 Test Loss: 0.0897023\n",
      "Validation loss decreased (0.087994 --> 0.087722).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0735653\n",
      "\tspeed: 0.0931s/iter; left time: 1931.0122s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752200\n",
      "\tspeed: 0.0523s/iter; left time: 1079.1748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0726825 Vali Loss: 0.0871324 Test Loss: 0.0893786\n",
      "Validation loss decreased (0.087722 --> 0.087132).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738944\n",
      "\tspeed: 0.0928s/iter; left time: 1903.5217s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740931\n",
      "\tspeed: 0.0521s/iter; left time: 1063.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0721897 Vali Loss: 0.0869960 Test Loss: 0.0890788\n",
      "Validation loss decreased (0.087132 --> 0.086996).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751932\n",
      "\tspeed: 0.0925s/iter; left time: 1875.5854s\n",
      "\titers: 200, epoch: 10 | loss: 0.0673028\n",
      "\tspeed: 0.0521s/iter; left time: 1052.6095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0717408 Vali Loss: 0.0867880 Test Loss: 0.0891405\n",
      "Validation loss decreased (0.086996 --> 0.086788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0667565\n",
      "\tspeed: 0.0930s/iter; left time: 1865.8693s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711614\n",
      "\tspeed: 0.0522s/iter; left time: 1041.6901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0714507 Vali Loss: 0.0870664 Test Loss: 0.0891779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710983\n",
      "\tspeed: 0.0923s/iter; left time: 1831.1766s\n",
      "\titers: 200, epoch: 12 | loss: 0.0680309\n",
      "\tspeed: 0.0521s/iter; left time: 1027.6809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0711380 Vali Loss: 0.0867219 Test Loss: 0.0890017\n",
      "Validation loss decreased (0.086788 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719549\n",
      "\tspeed: 0.0936s/iter; left time: 1836.1844s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728736\n",
      "\tspeed: 0.0522s/iter; left time: 1017.8660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0709379 Vali Loss: 0.0864662 Test Loss: 0.0890279\n",
      "Validation loss decreased (0.086722 --> 0.086466).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0695809\n",
      "\tspeed: 0.0939s/iter; left time: 1819.8176s\n",
      "\titers: 200, epoch: 14 | loss: 0.0691624\n",
      "\tspeed: 0.0524s/iter; left time: 1010.3812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0707244 Vali Loss: 0.0867192 Test Loss: 0.0890669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662107\n",
      "\tspeed: 0.0920s/iter; left time: 1763.4149s\n",
      "\titers: 200, epoch: 15 | loss: 0.0770034\n",
      "\tspeed: 0.0523s/iter; left time: 996.6752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0704650 Vali Loss: 0.0864952 Test Loss: 0.0890869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746670\n",
      "\tspeed: 0.0919s/iter; left time: 1740.9086s\n",
      "\titers: 200, epoch: 16 | loss: 0.0751349\n",
      "\tspeed: 0.0521s/iter; left time: 981.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0703478 Vali Loss: 0.0866213 Test Loss: 0.0890552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0691212\n",
      "\tspeed: 0.0920s/iter; left time: 1722.2517s\n",
      "\titers: 200, epoch: 17 | loss: 0.0701027\n",
      "\tspeed: 0.0521s/iter; left time: 969.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0701723 Vali Loss: 0.0864791 Test Loss: 0.0890113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0723499\n",
      "\tspeed: 0.0919s/iter; left time: 1700.2176s\n",
      "\titers: 200, epoch: 18 | loss: 0.0661663\n",
      "\tspeed: 0.0517s/iter; left time: 951.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.81s\n",
      "Steps: 224 | Train Loss: 0.0700250 Vali Loss: 0.0864334 Test Loss: 0.0889767\n",
      "Validation loss decreased (0.086466 --> 0.086433).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0676247\n",
      "\tspeed: 0.0937s/iter; left time: 1712.6457s\n",
      "\titers: 200, epoch: 19 | loss: 0.0656377\n",
      "\tspeed: 0.0520s/iter; left time: 945.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0698972 Vali Loss: 0.0863700 Test Loss: 0.0890557\n",
      "Validation loss decreased (0.086433 --> 0.086370).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0731429\n",
      "\tspeed: 0.0929s/iter; left time: 1675.8486s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692441\n",
      "\tspeed: 0.0521s/iter; left time: 935.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0697965 Vali Loss: 0.0862033 Test Loss: 0.0890447\n",
      "Validation loss decreased (0.086370 --> 0.086203).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0687015\n",
      "\tspeed: 0.0925s/iter; left time: 1647.6947s\n",
      "\titers: 200, epoch: 21 | loss: 0.0658207\n",
      "\tspeed: 0.0522s/iter; left time: 924.5576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0696816 Vali Loss: 0.0863567 Test Loss: 0.0893161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0706210\n",
      "\tspeed: 0.0920s/iter; left time: 1619.2148s\n",
      "\titers: 200, epoch: 22 | loss: 0.0746962\n",
      "\tspeed: 0.0521s/iter; left time: 912.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0696258 Vali Loss: 0.0863918 Test Loss: 0.0891025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0717456\n",
      "\tspeed: 0.0924s/iter; left time: 1604.8759s\n",
      "\titers: 200, epoch: 23 | loss: 0.0713271\n",
      "\tspeed: 0.0521s/iter; left time: 899.6638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0695054 Vali Loss: 0.0861524 Test Loss: 0.0890253\n",
      "Validation loss decreased (0.086203 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0754816\n",
      "\tspeed: 0.0929s/iter; left time: 1593.2847s\n",
      "\titers: 200, epoch: 24 | loss: 0.0685918\n",
      "\tspeed: 0.0522s/iter; left time: 889.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0694104 Vali Loss: 0.0862667 Test Loss: 0.0890559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0633278\n",
      "\tspeed: 0.0919s/iter; left time: 1556.0090s\n",
      "\titers: 200, epoch: 25 | loss: 0.0648984\n",
      "\tspeed: 0.0520s/iter; left time: 875.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:11.81s\n",
      "Steps: 224 | Train Loss: 0.0693590 Vali Loss: 0.0861933 Test Loss: 0.0891097\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0697152\n",
      "\tspeed: 0.0922s/iter; left time: 1539.2391s\n",
      "\titers: 200, epoch: 26 | loss: 0.0684530\n",
      "\tspeed: 0.0521s/iter; left time: 864.9047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0692901 Vali Loss: 0.0861402 Test Loss: 0.0891699\n",
      "Validation loss decreased (0.086152 --> 0.086140).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0680913\n",
      "\tspeed: 0.0929s/iter; left time: 1530.7129s\n",
      "\titers: 200, epoch: 27 | loss: 0.0710975\n",
      "\tspeed: 0.0520s/iter; left time: 851.4128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0692415 Vali Loss: 0.0861493 Test Loss: 0.0890312\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662386\n",
      "\tspeed: 0.0922s/iter; left time: 1498.0141s\n",
      "\titers: 200, epoch: 28 | loss: 0.0694833\n",
      "\tspeed: 0.0521s/iter; left time: 841.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0691602 Vali Loss: 0.0861183 Test Loss: 0.0892049\n",
      "Validation loss decreased (0.086140 --> 0.086118).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0725555\n",
      "\tspeed: 0.0936s/iter; left time: 1500.0613s\n",
      "\titers: 200, epoch: 29 | loss: 0.0715661\n",
      "\tspeed: 0.0524s/iter; left time: 835.2625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0691908 Vali Loss: 0.0860879 Test Loss: 0.0891321\n",
      "Validation loss decreased (0.086118 --> 0.086088).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0675764\n",
      "\tspeed: 0.0936s/iter; left time: 1478.5720s\n",
      "\titers: 200, epoch: 30 | loss: 0.0685819\n",
      "\tspeed: 0.0521s/iter; left time: 817.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0691524 Vali Loss: 0.0860893 Test Loss: 0.0891131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0705770\n",
      "\tspeed: 0.0921s/iter; left time: 1435.6957s\n",
      "\titers: 200, epoch: 31 | loss: 0.0713090\n",
      "\tspeed: 0.0520s/iter; left time: 805.1706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0691323 Vali Loss: 0.0861251 Test Loss: 0.0891209\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725021\n",
      "\tspeed: 0.0919s/iter; left time: 1411.8306s\n",
      "\titers: 200, epoch: 32 | loss: 0.0674104\n",
      "\tspeed: 0.0522s/iter; left time: 796.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0690699 Vali Loss: 0.0860819 Test Loss: 0.0890955\n",
      "Validation loss decreased (0.086088 --> 0.086082).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0671740\n",
      "\tspeed: 0.0930s/iter; left time: 1406.7771s\n",
      "\titers: 200, epoch: 33 | loss: 0.0640508\n",
      "\tspeed: 0.0522s/iter; left time: 784.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0690287 Vali Loss: 0.0861212 Test Loss: 0.0891954\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0705414\n",
      "\tspeed: 0.0917s/iter; left time: 1367.8583s\n",
      "\titers: 200, epoch: 34 | loss: 0.0681740\n",
      "\tspeed: 0.0521s/iter; left time: 771.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0689596 Vali Loss: 0.0862194 Test Loss: 0.0890935\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0701695\n",
      "\tspeed: 0.0923s/iter; left time: 1354.8329s\n",
      "\titers: 200, epoch: 35 | loss: 0.0673041\n",
      "\tspeed: 0.0521s/iter; left time: 760.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0689486 Vali Loss: 0.0861580 Test Loss: 0.0891037\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0642554\n",
      "\tspeed: 0.0935s/iter; left time: 1352.7820s\n",
      "\titers: 200, epoch: 36 | loss: 0.0672532\n",
      "\tspeed: 0.0520s/iter; left time: 747.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0689205 Vali Loss: 0.0860491 Test Loss: 0.0890471\n",
      "Validation loss decreased (0.086082 --> 0.086049).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0744950\n",
      "\tspeed: 0.0928s/iter; left time: 1321.7060s\n",
      "\titers: 200, epoch: 37 | loss: 0.0638594\n",
      "\tspeed: 0.0523s/iter; left time: 740.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0689579 Vali Loss: 0.0861269 Test Loss: 0.0891083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0700178\n",
      "\tspeed: 0.0924s/iter; left time: 1294.5238s\n",
      "\titers: 200, epoch: 38 | loss: 0.0661885\n",
      "\tspeed: 0.0520s/iter; left time: 723.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0688744 Vali Loss: 0.0861560 Test Loss: 0.0891225\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0645115\n",
      "\tspeed: 0.0922s/iter; left time: 1271.8806s\n",
      "\titers: 200, epoch: 39 | loss: 0.0643578\n",
      "\tspeed: 0.0522s/iter; left time: 714.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0689252 Vali Loss: 0.0861439 Test Loss: 0.0890523\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712911\n",
      "\tspeed: 0.0919s/iter; left time: 1246.2058s\n",
      "\titers: 200, epoch: 40 | loss: 0.0740808\n",
      "\tspeed: 0.0520s/iter; left time: 700.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0688536 Vali Loss: 0.0859760 Test Loss: 0.0890604\n",
      "Validation loss decreased (0.086049 --> 0.085976).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0645042\n",
      "\tspeed: 0.0949s/iter; left time: 1265.5498s\n",
      "\titers: 200, epoch: 41 | loss: 0.0700506\n",
      "\tspeed: 0.0519s/iter; left time: 687.2646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.79s\n",
      "Steps: 224 | Train Loss: 0.0688851 Vali Loss: 0.0861665 Test Loss: 0.0890974\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0722492\n",
      "\tspeed: 0.0919s/iter; left time: 1204.9191s\n",
      "\titers: 200, epoch: 42 | loss: 0.0705930\n",
      "\tspeed: 0.0520s/iter; left time: 677.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0688321 Vali Loss: 0.0860264 Test Loss: 0.0891213\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0742681\n",
      "\tspeed: 0.0919s/iter; left time: 1185.2241s\n",
      "\titers: 200, epoch: 43 | loss: 0.0690211\n",
      "\tspeed: 0.0524s/iter; left time: 669.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0688786 Vali Loss: 0.0860898 Test Loss: 0.0890831\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0646683\n",
      "\tspeed: 0.0920s/iter; left time: 1165.0368s\n",
      "\titers: 200, epoch: 44 | loss: 0.0692453\n",
      "\tspeed: 0.0520s/iter; left time: 654.0766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0688329 Vali Loss: 0.0861044 Test Loss: 0.0890925\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0659040\n",
      "\tspeed: 0.0919s/iter; left time: 1144.2450s\n",
      "\titers: 200, epoch: 45 | loss: 0.0643121\n",
      "\tspeed: 0.0521s/iter; left time: 643.3371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0688306 Vali Loss: 0.0860788 Test Loss: 0.0891090\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0707033\n",
      "\tspeed: 0.0924s/iter; left time: 1129.4004s\n",
      "\titers: 200, epoch: 46 | loss: 0.0666583\n",
      "\tspeed: 0.0520s/iter; left time: 630.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0687669 Vali Loss: 0.0861802 Test Loss: 0.0891388\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0668203\n",
      "\tspeed: 0.0921s/iter; left time: 1104.7161s\n",
      "\titers: 200, epoch: 47 | loss: 0.0678259\n",
      "\tspeed: 0.0520s/iter; left time: 618.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0687843 Vali Loss: 0.0860328 Test Loss: 0.0891000\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0671443\n",
      "\tspeed: 0.0922s/iter; left time: 1085.1757s\n",
      "\titers: 200, epoch: 48 | loss: 0.0705720\n",
      "\tspeed: 0.0522s/iter; left time: 609.3206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0687883 Vali Loss: 0.0860063 Test Loss: 0.0891141\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0660993\n",
      "\tspeed: 0.0924s/iter; left time: 1066.6538s\n",
      "\titers: 200, epoch: 49 | loss: 0.0729448\n",
      "\tspeed: 0.0520s/iter; left time: 595.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0687500 Vali Loss: 0.0861000 Test Loss: 0.0891243\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0677664\n",
      "\tspeed: 0.0920s/iter; left time: 1041.5790s\n",
      "\titers: 200, epoch: 50 | loss: 0.0669769\n",
      "\tspeed: 0.0520s/iter; left time: 584.2153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0687967 Vali Loss: 0.0861120 Test Loss: 0.0891771\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02123580500483513, rmse:0.1457251012325287, mae:0.08906044065952301, rse:0.514284074306488\n",
      "Intermediate time for DE and pred_len 24: 00h:22m:10.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1454190\n",
      "\tspeed: 0.1060s/iter; left time: 2343.0393s\n",
      "\titers: 200, epoch: 1 | loss: 0.1458661\n",
      "\tspeed: 0.0810s/iter; left time: 1782.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.46s\n",
      "Steps: 222 | Train Loss: 0.1548092 Vali Loss: 0.1579965 Test Loss: 0.1693504\n",
      "Validation loss decreased (inf --> 0.157997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1108921\n",
      "\tspeed: 0.1399s/iter; left time: 3061.5215s\n",
      "\titers: 200, epoch: 2 | loss: 0.1092338\n",
      "\tspeed: 0.0808s/iter; left time: 1758.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.1152091 Vali Loss: 0.1214901 Test Loss: 0.1276618\n",
      "Validation loss decreased (0.157997 --> 0.121490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1038423\n",
      "\tspeed: 0.1501s/iter; left time: 3251.0604s\n",
      "\titers: 200, epoch: 3 | loss: 0.1005785\n",
      "\tspeed: 0.0808s/iter; left time: 1742.5413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.1043968 Vali Loss: 0.1193286 Test Loss: 0.1262590\n",
      "Validation loss decreased (0.121490 --> 0.119329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1001219\n",
      "\tspeed: 0.1419s/iter; left time: 3042.1401s\n",
      "\titers: 200, epoch: 4 | loss: 0.1055598\n",
      "\tspeed: 0.0809s/iter; left time: 1725.6153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 222 | Train Loss: 0.1018228 Vali Loss: 0.1181283 Test Loss: 0.1252880\n",
      "Validation loss decreased (0.119329 --> 0.118128).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0935889\n",
      "\tspeed: 0.1394s/iter; left time: 2956.1491s\n",
      "\titers: 200, epoch: 5 | loss: 0.1000896\n",
      "\tspeed: 0.0809s/iter; left time: 1707.1809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.1001162 Vali Loss: 0.1181318 Test Loss: 0.1253805\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0993517\n",
      "\tspeed: 0.1377s/iter; left time: 2891.3916s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011612\n",
      "\tspeed: 0.0807s/iter; left time: 1685.7866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 222 | Train Loss: 0.0986901 Vali Loss: 0.1178792 Test Loss: 0.1254846\n",
      "Validation loss decreased (0.118128 --> 0.117879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1014253\n",
      "\tspeed: 0.1398s/iter; left time: 2903.2043s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973408\n",
      "\tspeed: 0.0807s/iter; left time: 1668.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0973229 Vali Loss: 0.1176305 Test Loss: 0.1256454\n",
      "Validation loss decreased (0.117879 --> 0.117631).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0960878\n",
      "\tspeed: 0.1392s/iter; left time: 2860.8441s\n",
      "\titers: 200, epoch: 8 | loss: 0.0905648\n",
      "\tspeed: 0.0808s/iter; left time: 1651.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 222 | Train Loss: 0.0960914 Vali Loss: 0.1177847 Test Loss: 0.1265147\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0934249\n",
      "\tspeed: 0.1380s/iter; left time: 2805.6270s\n",
      "\titers: 200, epoch: 9 | loss: 0.0898847\n",
      "\tspeed: 0.0809s/iter; left time: 1635.9969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0949588 Vali Loss: 0.1184804 Test Loss: 0.1269547\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0914064\n",
      "\tspeed: 0.1383s/iter; left time: 2779.6687s\n",
      "\titers: 200, epoch: 10 | loss: 0.0934437\n",
      "\tspeed: 0.0809s/iter; left time: 1618.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 222 | Train Loss: 0.0937266 Vali Loss: 0.1183242 Test Loss: 0.1279009\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0910332\n",
      "\tspeed: 0.1389s/iter; left time: 2761.5205s\n",
      "\titers: 200, epoch: 11 | loss: 0.0906390\n",
      "\tspeed: 0.0808s/iter; left time: 1598.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0926955 Vali Loss: 0.1190470 Test Loss: 0.1288897\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0865961\n",
      "\tspeed: 0.1382s/iter; left time: 2716.9350s\n",
      "\titers: 200, epoch: 12 | loss: 0.0923659\n",
      "\tspeed: 0.0808s/iter; left time: 1580.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0917330 Vali Loss: 0.1193468 Test Loss: 0.1290237\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0886916\n",
      "\tspeed: 0.1380s/iter; left time: 2682.3713s\n",
      "\titers: 200, epoch: 13 | loss: 0.0926560\n",
      "\tspeed: 0.0809s/iter; left time: 1563.7415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0908295 Vali Loss: 0.1193039 Test Loss: 0.1281978\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0902207\n",
      "\tspeed: 0.1387s/iter; left time: 2665.8168s\n",
      "\titers: 200, epoch: 14 | loss: 0.0890490\n",
      "\tspeed: 0.0808s/iter; left time: 1544.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0901019 Vali Loss: 0.1200060 Test Loss: 0.1297680\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0905493\n",
      "\tspeed: 0.1390s/iter; left time: 2640.8043s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844494\n",
      "\tspeed: 0.0808s/iter; left time: 1526.3635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0892479 Vali Loss: 0.1205788 Test Loss: 0.1293451\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0887716\n",
      "\tspeed: 0.1386s/iter; left time: 2600.8186s\n",
      "\titers: 200, epoch: 16 | loss: 0.0878107\n",
      "\tspeed: 0.0809s/iter; left time: 1509.6764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 222 | Train Loss: 0.0886576 Vali Loss: 0.1206160 Test Loss: 0.1295768\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0838581\n",
      "\tspeed: 0.1381s/iter; left time: 2560.9219s\n",
      "\titers: 200, epoch: 17 | loss: 0.0864668\n",
      "\tspeed: 0.0809s/iter; left time: 1493.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0880864 Vali Loss: 0.1208832 Test Loss: 0.1299632\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03595266863703728, rmse:0.18961189687252045, mae:0.12564539909362793, rse:0.6714540719985962\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1529302\n",
      "\tspeed: 0.0823s/iter; left time: 1819.1837s\n",
      "\titers: 200, epoch: 1 | loss: 0.1456952\n",
      "\tspeed: 0.0807s/iter; left time: 1775.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 222 | Train Loss: 0.1547636 Vali Loss: 0.1578183 Test Loss: 0.1693984\n",
      "Validation loss decreased (inf --> 0.157818).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1156026\n",
      "\tspeed: 0.1422s/iter; left time: 3110.5332s\n",
      "\titers: 200, epoch: 2 | loss: 0.1080172\n",
      "\tspeed: 0.0806s/iter; left time: 1756.3528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.1157705 Vali Loss: 0.1214437 Test Loss: 0.1283181\n",
      "Validation loss decreased (0.157818 --> 0.121444).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1046785\n",
      "\tspeed: 0.1411s/iter; left time: 3055.6022s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011220\n",
      "\tspeed: 0.0808s/iter; left time: 1741.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.1044551 Vali Loss: 0.1195383 Test Loss: 0.1268237\n",
      "Validation loss decreased (0.121444 --> 0.119538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991604\n",
      "\tspeed: 0.1420s/iter; left time: 3042.9044s\n",
      "\titers: 200, epoch: 4 | loss: 0.0966208\n",
      "\tspeed: 0.0807s/iter; left time: 1722.6233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.1019964 Vali Loss: 0.1182762 Test Loss: 0.1255367\n",
      "Validation loss decreased (0.119538 --> 0.118276).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0979637\n",
      "\tspeed: 0.1461s/iter; left time: 3099.3415s\n",
      "\titers: 200, epoch: 5 | loss: 0.0931982\n",
      "\tspeed: 0.0807s/iter; left time: 1704.6328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.1001509 Vali Loss: 0.1182702 Test Loss: 0.1250817\n",
      "Validation loss decreased (0.118276 --> 0.118270).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1015567\n",
      "\tspeed: 0.1399s/iter; left time: 2936.0198s\n",
      "\titers: 200, epoch: 6 | loss: 0.0909793\n",
      "\tspeed: 0.0807s/iter; left time: 1686.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0985937 Vali Loss: 0.1180413 Test Loss: 0.1251034\n",
      "Validation loss decreased (0.118270 --> 0.118041).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0943053\n",
      "\tspeed: 0.1410s/iter; left time: 2928.7755s\n",
      "\titers: 200, epoch: 7 | loss: 0.0968980\n",
      "\tspeed: 0.0808s/iter; left time: 1669.9386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 222 | Train Loss: 0.0970384 Vali Loss: 0.1180715 Test Loss: 0.1261100\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0952572\n",
      "\tspeed: 0.1399s/iter; left time: 2875.3100s\n",
      "\titers: 200, epoch: 8 | loss: 0.0973560\n",
      "\tspeed: 0.0812s/iter; left time: 1659.3842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 222 | Train Loss: 0.0955456 Vali Loss: 0.1184433 Test Loss: 0.1263607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0947614\n",
      "\tspeed: 0.1394s/iter; left time: 2833.1742s\n",
      "\titers: 200, epoch: 9 | loss: 0.0937324\n",
      "\tspeed: 0.0808s/iter; left time: 1633.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0941390 Vali Loss: 0.1191633 Test Loss: 0.1275874\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920048\n",
      "\tspeed: 0.1395s/iter; left time: 2803.6539s\n",
      "\titers: 200, epoch: 10 | loss: 0.0914769\n",
      "\tspeed: 0.0809s/iter; left time: 1618.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0928133 Vali Loss: 0.1188206 Test Loss: 0.1281140\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0923302\n",
      "\tspeed: 0.1401s/iter; left time: 2784.9030s\n",
      "\titers: 200, epoch: 11 | loss: 0.0908889\n",
      "\tspeed: 0.0807s/iter; left time: 1596.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0917612 Vali Loss: 0.1195217 Test Loss: 0.1288757\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0973572\n",
      "\tspeed: 0.1393s/iter; left time: 2737.8168s\n",
      "\titers: 200, epoch: 12 | loss: 0.0875574\n",
      "\tspeed: 0.0807s/iter; left time: 1578.6173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0908663 Vali Loss: 0.1199547 Test Loss: 0.1287506\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0962057\n",
      "\tspeed: 0.1405s/iter; left time: 2731.7486s\n",
      "\titers: 200, epoch: 13 | loss: 0.0874106\n",
      "\tspeed: 0.0806s/iter; left time: 1559.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0899556 Vali Loss: 0.1201837 Test Loss: 0.1298474\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0878442\n",
      "\tspeed: 0.1396s/iter; left time: 2682.5639s\n",
      "\titers: 200, epoch: 14 | loss: 0.0867968\n",
      "\tspeed: 0.0808s/iter; left time: 1544.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0893488 Vali Loss: 0.1203016 Test Loss: 0.1307302\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0855336\n",
      "\tspeed: 0.1405s/iter; left time: 2668.3176s\n",
      "\titers: 200, epoch: 15 | loss: 0.0859972\n",
      "\tspeed: 0.0809s/iter; left time: 1528.1479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0885958 Vali Loss: 0.1204547 Test Loss: 0.1307303\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0880300\n",
      "\tspeed: 0.1401s/iter; left time: 2629.8427s\n",
      "\titers: 200, epoch: 16 | loss: 0.0898835\n",
      "\tspeed: 0.0809s/iter; left time: 1509.6834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 222 | Train Loss: 0.0880733 Vali Loss: 0.1205709 Test Loss: 0.1303698\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0352337621152401, rmse:0.1877065896987915, mae:0.1251034140586853, rse:0.6647070050239563\n",
      "Intermediate time for DE and pred_len 96: 00h:12m:23.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1567775\n",
      "\tspeed: 0.1087s/iter; left time: 2401.5694s\n",
      "\titers: 200, epoch: 1 | loss: 0.1513248\n",
      "\tspeed: 0.0813s/iter; left time: 1789.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.51s\n",
      "Steps: 222 | Train Loss: 0.1564996 Vali Loss: 0.1594110 Test Loss: 0.1722484\n",
      "Validation loss decreased (inf --> 0.159411).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1169308\n",
      "\tspeed: 0.1407s/iter; left time: 3077.4090s\n",
      "\titers: 200, epoch: 2 | loss: 0.1121136\n",
      "\tspeed: 0.0813s/iter; left time: 1770.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1197778 Vali Loss: 0.1248173 Test Loss: 0.1331121\n",
      "Validation loss decreased (0.159411 --> 0.124817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1040951\n",
      "\tspeed: 0.1408s/iter; left time: 3048.7281s\n",
      "\titers: 200, epoch: 3 | loss: 0.1140926\n",
      "\tspeed: 0.0813s/iter; left time: 1752.5344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.1098576 Vali Loss: 0.1228079 Test Loss: 0.1325458\n",
      "Validation loss decreased (0.124817 --> 0.122808).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1032582\n",
      "\tspeed: 0.1414s/iter; left time: 3030.1456s\n",
      "\titers: 200, epoch: 4 | loss: 0.1121941\n",
      "\tspeed: 0.0816s/iter; left time: 1740.1548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 222 | Train Loss: 0.1072469 Vali Loss: 0.1222584 Test Loss: 0.1313323\n",
      "Validation loss decreased (0.122808 --> 0.122258).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1076371\n",
      "\tspeed: 0.1408s/iter; left time: 2987.7798s\n",
      "\titers: 200, epoch: 5 | loss: 0.1119657\n",
      "\tspeed: 0.0813s/iter; left time: 1717.2104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.1051176 Vali Loss: 0.1217997 Test Loss: 0.1318150\n",
      "Validation loss decreased (0.122258 --> 0.121800).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1028062\n",
      "\tspeed: 0.1410s/iter; left time: 2958.8591s\n",
      "\titers: 200, epoch: 6 | loss: 0.1075840\n",
      "\tspeed: 0.0814s/iter; left time: 1701.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.1031791 Vali Loss: 0.1216158 Test Loss: 0.1321796\n",
      "Validation loss decreased (0.121800 --> 0.121616).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1020667\n",
      "\tspeed: 0.1414s/iter; left time: 2936.5526s\n",
      "\titers: 200, epoch: 7 | loss: 0.0999745\n",
      "\tspeed: 0.0814s/iter; left time: 1683.4031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1012984 Vali Loss: 0.1222705 Test Loss: 0.1328824\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1024710\n",
      "\tspeed: 0.1410s/iter; left time: 2896.9789s\n",
      "\titers: 200, epoch: 8 | loss: 0.1013188\n",
      "\tspeed: 0.0814s/iter; left time: 1664.7842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0996514 Vali Loss: 0.1231942 Test Loss: 0.1332751\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1011731\n",
      "\tspeed: 0.1396s/iter; left time: 2838.1328s\n",
      "\titers: 200, epoch: 9 | loss: 0.0969350\n",
      "\tspeed: 0.0814s/iter; left time: 1645.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.0980915 Vali Loss: 0.1237174 Test Loss: 0.1340225\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0941293\n",
      "\tspeed: 0.1408s/iter; left time: 2830.0382s\n",
      "\titers: 200, epoch: 10 | loss: 0.0965152\n",
      "\tspeed: 0.0814s/iter; left time: 1627.4495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0967392 Vali Loss: 0.1234175 Test Loss: 0.1346313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0937904\n",
      "\tspeed: 0.1406s/iter; left time: 2794.5166s\n",
      "\titers: 200, epoch: 11 | loss: 0.0946716\n",
      "\tspeed: 0.0812s/iter; left time: 1606.5533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0955147 Vali Loss: 0.1240949 Test Loss: 0.1351768\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0918052\n",
      "\tspeed: 0.1399s/iter; left time: 2749.6484s\n",
      "\titers: 200, epoch: 12 | loss: 0.0966095\n",
      "\tspeed: 0.0811s/iter; left time: 1586.5761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.0943976 Vali Loss: 0.1244152 Test Loss: 0.1353770\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0908815\n",
      "\tspeed: 0.1399s/iter; left time: 2719.8300s\n",
      "\titers: 200, epoch: 13 | loss: 0.0946134\n",
      "\tspeed: 0.0815s/iter; left time: 1576.4029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.0934874 Vali Loss: 0.1243682 Test Loss: 0.1359254\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0948062\n",
      "\tspeed: 0.1404s/iter; left time: 2698.6876s\n",
      "\titers: 200, epoch: 14 | loss: 0.0925005\n",
      "\tspeed: 0.0813s/iter; left time: 1553.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.0926105 Vali Loss: 0.1244345 Test Loss: 0.1361633\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0930774\n",
      "\tspeed: 0.1415s/iter; left time: 2688.0997s\n",
      "\titers: 200, epoch: 15 | loss: 0.0914964\n",
      "\tspeed: 0.0813s/iter; left time: 1535.2321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.0918648 Vali Loss: 0.1247319 Test Loss: 0.1368228\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0891043\n",
      "\tspeed: 0.1399s/iter; left time: 2625.6884s\n",
      "\titers: 200, epoch: 16 | loss: 0.0967203\n",
      "\tspeed: 0.0812s/iter; left time: 1516.9319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.0910989 Vali Loss: 0.1251153 Test Loss: 0.1371230\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03817787021398544, rmse:0.19539158046245575, mae:0.13217949867248535, rse:0.6920927166938782\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1584320\n",
      "\tspeed: 0.0829s/iter; left time: 1832.6007s\n",
      "\titers: 200, epoch: 1 | loss: 0.1539989\n",
      "\tspeed: 0.0812s/iter; left time: 1786.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.1572925 Vali Loss: 0.1603549 Test Loss: 0.1732188\n",
      "Validation loss decreased (inf --> 0.160355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1229231\n",
      "\tspeed: 0.1451s/iter; left time: 3175.2502s\n",
      "\titers: 200, epoch: 2 | loss: 0.1093951\n",
      "\tspeed: 0.0813s/iter; left time: 1771.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1213124 Vali Loss: 0.1254657 Test Loss: 0.1345205\n",
      "Validation loss decreased (0.160355 --> 0.125466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1082131\n",
      "\tspeed: 0.1441s/iter; left time: 3120.6045s\n",
      "\titers: 200, epoch: 3 | loss: 0.1081986\n",
      "\tspeed: 0.0813s/iter; left time: 1753.1902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.1101862 Vali Loss: 0.1233200 Test Loss: 0.1328761\n",
      "Validation loss decreased (0.125466 --> 0.123320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1075606\n",
      "\tspeed: 0.1422s/iter; left time: 3047.8200s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056124\n",
      "\tspeed: 0.0812s/iter; left time: 1732.5695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.1071764 Vali Loss: 0.1220768 Test Loss: 0.1326651\n",
      "Validation loss decreased (0.123320 --> 0.122077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1011877\n",
      "\tspeed: 0.1426s/iter; left time: 3024.5506s\n",
      "\titers: 200, epoch: 5 | loss: 0.1052904\n",
      "\tspeed: 0.0814s/iter; left time: 1717.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1050479 Vali Loss: 0.1229597 Test Loss: 0.1319391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1010514\n",
      "\tspeed: 0.1400s/iter; left time: 2939.7290s\n",
      "\titers: 200, epoch: 6 | loss: 0.1084885\n",
      "\tspeed: 0.0813s/iter; left time: 1699.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 222 | Train Loss: 0.1031179 Vali Loss: 0.1229192 Test Loss: 0.1332220\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1013987\n",
      "\tspeed: 0.1416s/iter; left time: 2940.6401s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027911\n",
      "\tspeed: 0.0813s/iter; left time: 1681.0609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.1015164 Vali Loss: 0.1232137 Test Loss: 0.1343062\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0949016\n",
      "\tspeed: 0.1407s/iter; left time: 2891.6230s\n",
      "\titers: 200, epoch: 8 | loss: 0.1015967\n",
      "\tspeed: 0.0813s/iter; left time: 1662.8910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0998196 Vali Loss: 0.1241509 Test Loss: 0.1345583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0980298\n",
      "\tspeed: 0.1413s/iter; left time: 2871.6177s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990568\n",
      "\tspeed: 0.0814s/iter; left time: 1645.9629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 222 | Train Loss: 0.0983526 Vali Loss: 0.1248584 Test Loss: 0.1345823\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0965817\n",
      "\tspeed: 0.1408s/iter; left time: 2829.6648s\n",
      "\titers: 200, epoch: 10 | loss: 0.0910069\n",
      "\tspeed: 0.0813s/iter; left time: 1625.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0969771 Vali Loss: 0.1248797 Test Loss: 0.1352504\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0921308\n",
      "\tspeed: 0.1422s/iter; left time: 2826.9040s\n",
      "\titers: 200, epoch: 11 | loss: 0.0946201\n",
      "\tspeed: 0.0815s/iter; left time: 1611.3782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.39s\n",
      "Steps: 222 | Train Loss: 0.0957095 Vali Loss: 0.1254821 Test Loss: 0.1363082\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0953712\n",
      "\tspeed: 0.1419s/iter; left time: 2790.2231s\n",
      "\titers: 200, epoch: 12 | loss: 0.0938992\n",
      "\tspeed: 0.0815s/iter; left time: 1594.4512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.36s\n",
      "Steps: 222 | Train Loss: 0.0945926 Vali Loss: 0.1264368 Test Loss: 0.1374227\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0939670\n",
      "\tspeed: 0.1418s/iter; left time: 2756.9232s\n",
      "\titers: 200, epoch: 13 | loss: 0.0957235\n",
      "\tspeed: 0.0817s/iter; left time: 1579.5557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0935417 Vali Loss: 0.1268010 Test Loss: 0.1383561\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0911809\n",
      "\tspeed: 0.1416s/iter; left time: 2720.8860s\n",
      "\titers: 200, epoch: 14 | loss: 0.0954952\n",
      "\tspeed: 0.0814s/iter; left time: 1556.4209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0926690 Vali Loss: 0.1271380 Test Loss: 0.1381323\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03783639147877693, rmse:0.19451579451560974, mae:0.1326650083065033, rse:0.688990592956543\n",
      "Intermediate time for DE and pred_len 168: 00h:11m:24.64s\n",
      "Intermediate time for DE: 00h:45m:59.02s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1348483\n",
      "\tspeed: 0.1062s/iter; left time: 2357.5424s\n",
      "\titers: 200, epoch: 1 | loss: 0.1235475\n",
      "\tspeed: 0.0804s/iter; left time: 1777.8606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.41s\n",
      "Steps: 223 | Train Loss: 0.1346395 Vali Loss: 0.1334999 Test Loss: 0.1537496\n",
      "Validation loss decreased (inf --> 0.133500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0891610\n",
      "\tspeed: 0.1383s/iter; left time: 3038.5504s\n",
      "\titers: 200, epoch: 2 | loss: 0.0834034\n",
      "\tspeed: 0.0801s/iter; left time: 1753.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0898294 Vali Loss: 0.0928724 Test Loss: 0.1040984\n",
      "Validation loss decreased (0.133500 --> 0.092872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0818716\n",
      "\tspeed: 0.1388s/iter; left time: 3019.7473s\n",
      "\titers: 200, epoch: 3 | loss: 0.0716305\n",
      "\tspeed: 0.0803s/iter; left time: 1738.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0784626 Vali Loss: 0.0912489 Test Loss: 0.1033492\n",
      "Validation loss decreased (0.092872 --> 0.091249).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0787505\n",
      "\tspeed: 0.1394s/iter; left time: 3001.9322s\n",
      "\titers: 200, epoch: 4 | loss: 0.0758759\n",
      "\tspeed: 0.0802s/iter; left time: 1719.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0766306 Vali Loss: 0.0901929 Test Loss: 0.1032344\n",
      "Validation loss decreased (0.091249 --> 0.090193).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788459\n",
      "\tspeed: 0.1387s/iter; left time: 2955.4293s\n",
      "\titers: 200, epoch: 5 | loss: 0.0738315\n",
      "\tspeed: 0.0802s/iter; left time: 1700.6017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0755506 Vali Loss: 0.0901071 Test Loss: 0.1029200\n",
      "Validation loss decreased (0.090193 --> 0.090107).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0759309\n",
      "\tspeed: 0.1395s/iter; left time: 2941.6222s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739040\n",
      "\tspeed: 0.0803s/iter; left time: 1684.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0746222 Vali Loss: 0.0896171 Test Loss: 0.1028844\n",
      "Validation loss decreased (0.090107 --> 0.089617).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0724300\n",
      "\tspeed: 0.1397s/iter; left time: 2913.8349s\n",
      "\titers: 200, epoch: 7 | loss: 0.0740469\n",
      "\tspeed: 0.0802s/iter; left time: 1665.8637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 223 | Train Loss: 0.0740470 Vali Loss: 0.0890901 Test Loss: 0.1023908\n",
      "Validation loss decreased (0.089617 --> 0.089090).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761165\n",
      "\tspeed: 0.1392s/iter; left time: 2873.1964s\n",
      "\titers: 200, epoch: 8 | loss: 0.0689072\n",
      "\tspeed: 0.0802s/iter; left time: 1647.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0734278 Vali Loss: 0.0891402 Test Loss: 0.1023248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0715905\n",
      "\tspeed: 0.1382s/iter; left time: 2821.7113s\n",
      "\titers: 200, epoch: 9 | loss: 0.0787396\n",
      "\tspeed: 0.0803s/iter; left time: 1630.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0729763 Vali Loss: 0.0887639 Test Loss: 0.1022937\n",
      "Validation loss decreased (0.089090 --> 0.088764).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738042\n",
      "\tspeed: 0.1395s/iter; left time: 2816.8249s\n",
      "\titers: 200, epoch: 10 | loss: 0.0750337\n",
      "\tspeed: 0.0804s/iter; left time: 1614.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 223 | Train Loss: 0.0725319 Vali Loss: 0.0888586 Test Loss: 0.1019429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0752971\n",
      "\tspeed: 0.1385s/iter; left time: 2766.3056s\n",
      "\titers: 200, epoch: 11 | loss: 0.0718730\n",
      "\tspeed: 0.0804s/iter; left time: 1598.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 223 | Train Loss: 0.0722108 Vali Loss: 0.0887466 Test Loss: 0.1020114\n",
      "Validation loss decreased (0.088764 --> 0.088747).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0683566\n",
      "\tspeed: 0.1395s/iter; left time: 2755.8191s\n",
      "\titers: 200, epoch: 12 | loss: 0.0716865\n",
      "\tspeed: 0.0803s/iter; left time: 1576.7561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0718465 Vali Loss: 0.0886935 Test Loss: 0.1024904\n",
      "Validation loss decreased (0.088747 --> 0.088694).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749665\n",
      "\tspeed: 0.1396s/iter; left time: 2726.3606s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728019\n",
      "\tspeed: 0.0802s/iter; left time: 1558.2728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0715018 Vali Loss: 0.0887555 Test Loss: 0.1022899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0727171\n",
      "\tspeed: 0.1387s/iter; left time: 2676.8611s\n",
      "\titers: 200, epoch: 14 | loss: 0.0698338\n",
      "\tspeed: 0.0802s/iter; left time: 1540.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0712557 Vali Loss: 0.0884080 Test Loss: 0.1021220\n",
      "Validation loss decreased (0.088694 --> 0.088408).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738606\n",
      "\tspeed: 0.1397s/iter; left time: 2665.5034s\n",
      "\titers: 200, epoch: 15 | loss: 0.0688558\n",
      "\tspeed: 0.0802s/iter; left time: 1522.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0710802 Vali Loss: 0.0886561 Test Loss: 0.1022697\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0734921\n",
      "\tspeed: 0.1387s/iter; left time: 2616.1925s\n",
      "\titers: 200, epoch: 16 | loss: 0.0693150\n",
      "\tspeed: 0.0802s/iter; left time: 1505.0634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0707799 Vali Loss: 0.0886526 Test Loss: 0.1023837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0721558\n",
      "\tspeed: 0.1386s/iter; left time: 2583.4339s\n",
      "\titers: 200, epoch: 17 | loss: 0.0740197\n",
      "\tspeed: 0.0803s/iter; left time: 1487.3542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0706303 Vali Loss: 0.0882642 Test Loss: 0.1022535\n",
      "Validation loss decreased (0.088408 --> 0.088264).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0711871\n",
      "\tspeed: 0.1388s/iter; left time: 2555.7726s\n",
      "\titers: 200, epoch: 18 | loss: 0.0816860\n",
      "\tspeed: 0.0802s/iter; left time: 1469.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0703854 Vali Loss: 0.0883601 Test Loss: 0.1020565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0741602\n",
      "\tspeed: 0.1383s/iter; left time: 2515.3679s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713896\n",
      "\tspeed: 0.0802s/iter; left time: 1451.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 223 | Train Loss: 0.0702685 Vali Loss: 0.0881388 Test Loss: 0.1022986\n",
      "Validation loss decreased (0.088264 --> 0.088139).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0719018\n",
      "\tspeed: 0.1403s/iter; left time: 2520.0933s\n",
      "\titers: 200, epoch: 20 | loss: 0.0690474\n",
      "\tspeed: 0.0802s/iter; left time: 1433.5442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0700933 Vali Loss: 0.0881721 Test Loss: 0.1021070\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0712346\n",
      "\tspeed: 0.1392s/iter; left time: 2470.4293s\n",
      "\titers: 200, epoch: 21 | loss: 0.0659650\n",
      "\tspeed: 0.0801s/iter; left time: 1413.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0699631 Vali Loss: 0.0881782 Test Loss: 0.1021644\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0652486\n",
      "\tspeed: 0.1388s/iter; left time: 2431.3012s\n",
      "\titers: 200, epoch: 22 | loss: 0.0682071\n",
      "\tspeed: 0.0803s/iter; left time: 1399.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0698734 Vali Loss: 0.0880684 Test Loss: 0.1022999\n",
      "Validation loss decreased (0.088139 --> 0.088068).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0746235\n",
      "\tspeed: 0.1391s/iter; left time: 2406.4139s\n",
      "\titers: 200, epoch: 23 | loss: 0.0693815\n",
      "\tspeed: 0.0803s/iter; left time: 1380.4914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0696701 Vali Loss: 0.0879686 Test Loss: 0.1021321\n",
      "Validation loss decreased (0.088068 --> 0.087969).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0730705\n",
      "\tspeed: 0.1390s/iter; left time: 2373.1870s\n",
      "\titers: 200, epoch: 24 | loss: 0.0711131\n",
      "\tspeed: 0.0803s/iter; left time: 1363.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0696299 Vali Loss: 0.0878839 Test Loss: 0.1022739\n",
      "Validation loss decreased (0.087969 --> 0.087884).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0689954\n",
      "\tspeed: 0.1394s/iter; left time: 2349.2926s\n",
      "\titers: 200, epoch: 25 | loss: 0.0713015\n",
      "\tspeed: 0.0802s/iter; left time: 1343.8483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0695589 Vali Loss: 0.0881440 Test Loss: 0.1023520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0637646\n",
      "\tspeed: 0.1388s/iter; left time: 2307.1585s\n",
      "\titers: 200, epoch: 26 | loss: 0.0662034\n",
      "\tspeed: 0.0804s/iter; left time: 1328.7657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 223 | Train Loss: 0.0695231 Vali Loss: 0.0880633 Test Loss: 0.1021806\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0698196\n",
      "\tspeed: 0.1379s/iter; left time: 2261.5097s\n",
      "\titers: 200, epoch: 27 | loss: 0.0658523\n",
      "\tspeed: 0.0802s/iter; left time: 1308.2035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0694681 Vali Loss: 0.0880745 Test Loss: 0.1022816\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0673808\n",
      "\tspeed: 0.1387s/iter; left time: 2244.1304s\n",
      "\titers: 200, epoch: 28 | loss: 0.0676038\n",
      "\tspeed: 0.0802s/iter; left time: 1289.0261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0692791 Vali Loss: 0.0880488 Test Loss: 0.1023436\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0751908\n",
      "\tspeed: 0.1378s/iter; left time: 2199.1928s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731162\n",
      "\tspeed: 0.0803s/iter; left time: 1273.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0692822 Vali Loss: 0.0880311 Test Loss: 0.1022699\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0660743\n",
      "\tspeed: 0.1380s/iter; left time: 2171.2260s\n",
      "\titers: 200, epoch: 30 | loss: 0.0733489\n",
      "\tspeed: 0.0796s/iter; left time: 1244.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 223 | Train Loss: 0.0692286 Vali Loss: 0.0880953 Test Loss: 0.1023546\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0704500\n",
      "\tspeed: 0.1379s/iter; left time: 2138.8533s\n",
      "\titers: 200, epoch: 31 | loss: 0.0656725\n",
      "\tspeed: 0.0801s/iter; left time: 1234.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0691443 Vali Loss: 0.0880416 Test Loss: 0.1022984\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0761222\n",
      "\tspeed: 0.1380s/iter; left time: 2109.0803s\n",
      "\titers: 200, epoch: 32 | loss: 0.0687318\n",
      "\tspeed: 0.0801s/iter; left time: 1216.4699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0690752 Vali Loss: 0.0879020 Test Loss: 0.1023048\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0661833\n",
      "\tspeed: 0.1376s/iter; left time: 2072.8011s\n",
      "\titers: 200, epoch: 33 | loss: 0.0732448\n",
      "\tspeed: 0.0801s/iter; left time: 1198.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0690798 Vali Loss: 0.0878879 Test Loss: 0.1023647\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0719190\n",
      "\tspeed: 0.1375s/iter; left time: 2040.4420s\n",
      "\titers: 200, epoch: 34 | loss: 0.0688583\n",
      "\tspeed: 0.0805s/iter; left time: 1187.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0690935 Vali Loss: 0.0880725 Test Loss: 0.1024172\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025716405361890793, rmse:0.1603633612394333, mae:0.10227393358945847, rse:0.5532081127166748\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1366708\n",
      "\tspeed: 0.0817s/iter; left time: 1813.9799s\n",
      "\titers: 200, epoch: 1 | loss: 0.1241749\n",
      "\tspeed: 0.0801s/iter; left time: 1770.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.1342851 Vali Loss: 0.1348039 Test Loss: 0.1549900\n",
      "Validation loss decreased (inf --> 0.134804).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0886100\n",
      "\tspeed: 0.1390s/iter; left time: 3054.6923s\n",
      "\titers: 200, epoch: 2 | loss: 0.0809548\n",
      "\tspeed: 0.0797s/iter; left time: 1743.9849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 223 | Train Loss: 0.0914494 Vali Loss: 0.0932200 Test Loss: 0.1052101\n",
      "Validation loss decreased (0.134804 --> 0.093220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0700615\n",
      "\tspeed: 0.1392s/iter; left time: 3028.0525s\n",
      "\titers: 200, epoch: 3 | loss: 0.0744769\n",
      "\tspeed: 0.0801s/iter; left time: 1733.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 223 | Train Loss: 0.0786488 Vali Loss: 0.0908873 Test Loss: 0.1033789\n",
      "Validation loss decreased (0.093220 --> 0.090887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0741743\n",
      "\tspeed: 0.1380s/iter; left time: 2972.0448s\n",
      "\titers: 200, epoch: 4 | loss: 0.0743613\n",
      "\tspeed: 0.0795s/iter; left time: 1704.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.96s\n",
      "Steps: 223 | Train Loss: 0.0766186 Vali Loss: 0.0908253 Test Loss: 0.1032803\n",
      "Validation loss decreased (0.090887 --> 0.090825).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0684796\n",
      "\tspeed: 0.1381s/iter; left time: 2941.8794s\n",
      "\titers: 200, epoch: 5 | loss: 0.0779562\n",
      "\tspeed: 0.0799s/iter; left time: 1694.7403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.02s\n",
      "Steps: 223 | Train Loss: 0.0753809 Vali Loss: 0.0893297 Test Loss: 0.1028940\n",
      "Validation loss decreased (0.090825 --> 0.089330).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0696775\n",
      "\tspeed: 0.1389s/iter; left time: 2927.9471s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745337\n",
      "\tspeed: 0.0800s/iter; left time: 1679.3151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0745349 Vali Loss: 0.0894449 Test Loss: 0.1024341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0785604\n",
      "\tspeed: 0.1381s/iter; left time: 2880.6686s\n",
      "\titers: 200, epoch: 7 | loss: 0.0679719\n",
      "\tspeed: 0.0800s/iter; left time: 1660.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 223 | Train Loss: 0.0739043 Vali Loss: 0.0892957 Test Loss: 0.1023731\n",
      "Validation loss decreased (0.089330 --> 0.089296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774263\n",
      "\tspeed: 0.1385s/iter; left time: 2859.5245s\n",
      "\titers: 200, epoch: 8 | loss: 0.0668307\n",
      "\tspeed: 0.0801s/iter; left time: 1645.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0733547 Vali Loss: 0.0889244 Test Loss: 0.1024472\n",
      "Validation loss decreased (0.089296 --> 0.088924).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0746945\n",
      "\tspeed: 0.1387s/iter; left time: 2831.6787s\n",
      "\titers: 200, epoch: 9 | loss: 0.0714779\n",
      "\tspeed: 0.0800s/iter; left time: 1626.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0729554 Vali Loss: 0.0887235 Test Loss: 0.1022474\n",
      "Validation loss decreased (0.088924 --> 0.088724).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0718831\n",
      "\tspeed: 0.1401s/iter; left time: 2829.1447s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704201\n",
      "\tspeed: 0.0800s/iter; left time: 1607.2016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 223 | Train Loss: 0.0724501 Vali Loss: 0.0885421 Test Loss: 0.1020218\n",
      "Validation loss decreased (0.088724 --> 0.088542).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0733186\n",
      "\tspeed: 0.1394s/iter; left time: 2784.5216s\n",
      "\titers: 200, epoch: 11 | loss: 0.0735558\n",
      "\tspeed: 0.0800s/iter; left time: 1588.9534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0721375 Vali Loss: 0.0884050 Test Loss: 0.1017645\n",
      "Validation loss decreased (0.088542 --> 0.088405).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0722721\n",
      "\tspeed: 0.1382s/iter; left time: 2728.4261s\n",
      "\titers: 200, epoch: 12 | loss: 0.0696643\n",
      "\tspeed: 0.0801s/iter; left time: 1573.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 223 | Train Loss: 0.0718774 Vali Loss: 0.0883413 Test Loss: 0.1020326\n",
      "Validation loss decreased (0.088405 --> 0.088341).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0729654\n",
      "\tspeed: 0.1392s/iter; left time: 2716.9914s\n",
      "\titers: 200, epoch: 13 | loss: 0.0749668\n",
      "\tspeed: 0.0800s/iter; left time: 1553.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 223 | Train Loss: 0.0715923 Vali Loss: 0.0884434 Test Loss: 0.1023562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0688052\n",
      "\tspeed: 0.1381s/iter; left time: 2666.1109s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697273\n",
      "\tspeed: 0.0801s/iter; left time: 1538.4669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0713526 Vali Loss: 0.0883750 Test Loss: 0.1020522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0679391\n",
      "\tspeed: 0.1384s/iter; left time: 2641.0054s\n",
      "\titers: 200, epoch: 15 | loss: 0.0700785\n",
      "\tspeed: 0.0801s/iter; left time: 1520.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0710252 Vali Loss: 0.0881383 Test Loss: 0.1018744\n",
      "Validation loss decreased (0.088341 --> 0.088138).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715094\n",
      "\tspeed: 0.1404s/iter; left time: 2646.9341s\n",
      "\titers: 200, epoch: 16 | loss: 0.0719865\n",
      "\tspeed: 0.0802s/iter; left time: 1503.9750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0708653 Vali Loss: 0.0879714 Test Loss: 0.1020792\n",
      "Validation loss decreased (0.088138 --> 0.087971).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748008\n",
      "\tspeed: 0.1389s/iter; left time: 2588.8541s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705557\n",
      "\tspeed: 0.0800s/iter; left time: 1481.7785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0707088 Vali Loss: 0.0880462 Test Loss: 0.1023607\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0679809\n",
      "\tspeed: 0.1384s/iter; left time: 2547.2937s\n",
      "\titers: 200, epoch: 18 | loss: 0.0725685\n",
      "\tspeed: 0.0801s/iter; left time: 1466.1961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0704286 Vali Loss: 0.0880920 Test Loss: 0.1020400\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0667965\n",
      "\tspeed: 0.1383s/iter; left time: 2514.7743s\n",
      "\titers: 200, epoch: 19 | loss: 0.0677409\n",
      "\tspeed: 0.0801s/iter; left time: 1448.8163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0702506 Vali Loss: 0.0880540 Test Loss: 0.1022111\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685981\n",
      "\tspeed: 0.1385s/iter; left time: 2487.7643s\n",
      "\titers: 200, epoch: 20 | loss: 0.0648524\n",
      "\tspeed: 0.0801s/iter; left time: 1431.3251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0701828 Vali Loss: 0.0880403 Test Loss: 0.1022138\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0684365\n",
      "\tspeed: 0.1380s/iter; left time: 2447.5438s\n",
      "\titers: 200, epoch: 21 | loss: 0.0661878\n",
      "\tspeed: 0.0799s/iter; left time: 1410.0784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.03s\n",
      "Steps: 223 | Train Loss: 0.0699923 Vali Loss: 0.0880152 Test Loss: 0.1020563\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0721140\n",
      "\tspeed: 0.1389s/iter; left time: 2433.8766s\n",
      "\titers: 200, epoch: 22 | loss: 0.0700619\n",
      "\tspeed: 0.0801s/iter; left time: 1395.7775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0698893 Vali Loss: 0.0880357 Test Loss: 0.1022364\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0723281\n",
      "\tspeed: 0.1383s/iter; left time: 2391.6151s\n",
      "\titers: 200, epoch: 23 | loss: 0.0717652\n",
      "\tspeed: 0.0801s/iter; left time: 1376.6324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0697248 Vali Loss: 0.0880475 Test Loss: 0.1022223\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0668357\n",
      "\tspeed: 0.1382s/iter; left time: 2358.5072s\n",
      "\titers: 200, epoch: 24 | loss: 0.0756700\n",
      "\tspeed: 0.0800s/iter; left time: 1358.2168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0696926 Vali Loss: 0.0879637 Test Loss: 0.1021364\n",
      "Validation loss decreased (0.087971 --> 0.087964).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0724150\n",
      "\tspeed: 0.1396s/iter; left time: 2352.7915s\n",
      "\titers: 200, epoch: 25 | loss: 0.0723249\n",
      "\tspeed: 0.0802s/iter; left time: 1343.0970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0695450 Vali Loss: 0.0879783 Test Loss: 0.1022011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0680662\n",
      "\tspeed: 0.1386s/iter; left time: 2304.0037s\n",
      "\titers: 200, epoch: 26 | loss: 0.0669919\n",
      "\tspeed: 0.0802s/iter; left time: 1326.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0695108 Vali Loss: 0.0880587 Test Loss: 0.1021642\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0691096\n",
      "\tspeed: 0.1388s/iter; left time: 2276.4538s\n",
      "\titers: 200, epoch: 27 | loss: 0.0648874\n",
      "\tspeed: 0.0801s/iter; left time: 1306.0938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0694146 Vali Loss: 0.0879691 Test Loss: 0.1022430\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0681378\n",
      "\tspeed: 0.1389s/iter; left time: 2247.8991s\n",
      "\titers: 200, epoch: 28 | loss: 0.0642104\n",
      "\tspeed: 0.0801s/iter; left time: 1287.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0693545 Vali Loss: 0.0879410 Test Loss: 0.1022402\n",
      "Validation loss decreased (0.087964 --> 0.087941).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0667084\n",
      "\tspeed: 0.1392s/iter; left time: 2221.3044s\n",
      "\titers: 200, epoch: 29 | loss: 0.0688164\n",
      "\tspeed: 0.0801s/iter; left time: 1269.8224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0693225 Vali Loss: 0.0880652 Test Loss: 0.1022794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0681703\n",
      "\tspeed: 0.1385s/iter; left time: 2178.9509s\n",
      "\titers: 200, epoch: 30 | loss: 0.0693843\n",
      "\tspeed: 0.0801s/iter; left time: 1252.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 223 | Train Loss: 0.0692618 Vali Loss: 0.0880007 Test Loss: 0.1023244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0670438\n",
      "\tspeed: 0.1385s/iter; left time: 2148.6375s\n",
      "\titers: 200, epoch: 31 | loss: 0.0717225\n",
      "\tspeed: 0.0800s/iter; left time: 1233.0719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 223 | Train Loss: 0.0691872 Vali Loss: 0.0879294 Test Loss: 0.1023856\n",
      "Validation loss decreased (0.087941 --> 0.087929).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0682997\n",
      "\tspeed: 0.1394s/iter; left time: 2131.2663s\n",
      "\titers: 200, epoch: 32 | loss: 0.0684763\n",
      "\tspeed: 0.0802s/iter; left time: 1217.3402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0690877 Vali Loss: 0.0880422 Test Loss: 0.1023571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0701336\n",
      "\tspeed: 0.1382s/iter; left time: 2082.1144s\n",
      "\titers: 200, epoch: 33 | loss: 0.0700182\n",
      "\tspeed: 0.0802s/iter; left time: 1200.8834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0690832 Vali Loss: 0.0879702 Test Loss: 0.1022660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0709029\n",
      "\tspeed: 0.1384s/iter; left time: 2054.6799s\n",
      "\titers: 200, epoch: 34 | loss: 0.0640473\n",
      "\tspeed: 0.0802s/iter; left time: 1182.4620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0690259 Vali Loss: 0.0879758 Test Loss: 0.1023446\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0705968\n",
      "\tspeed: 0.1383s/iter; left time: 2022.2637s\n",
      "\titers: 200, epoch: 35 | loss: 0.0717035\n",
      "\tspeed: 0.0800s/iter; left time: 1161.9997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0689972 Vali Loss: 0.0879484 Test Loss: 0.1023216\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0669579\n",
      "\tspeed: 0.1385s/iter; left time: 1993.3011s\n",
      "\titers: 200, epoch: 36 | loss: 0.0741236\n",
      "\tspeed: 0.0801s/iter; left time: 1145.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0689777 Vali Loss: 0.0880503 Test Loss: 0.1023325\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0677079\n",
      "\tspeed: 0.1390s/iter; left time: 1970.0005s\n",
      "\titers: 200, epoch: 37 | loss: 0.0674071\n",
      "\tspeed: 0.0803s/iter; left time: 1129.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0689180 Vali Loss: 0.0880585 Test Loss: 0.1023927\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0700749\n",
      "\tspeed: 0.1387s/iter; left time: 1934.5878s\n",
      "\titers: 200, epoch: 38 | loss: 0.0709952\n",
      "\tspeed: 0.0800s/iter; left time: 1108.6246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0689011 Vali Loss: 0.0879418 Test Loss: 0.1023480\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0670714\n",
      "\tspeed: 0.1392s/iter; left time: 1911.0750s\n",
      "\titers: 200, epoch: 39 | loss: 0.0700057\n",
      "\tspeed: 0.0801s/iter; left time: 1091.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0688655 Vali Loss: 0.0879522 Test Loss: 0.1023728\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0683985\n",
      "\tspeed: 0.1385s/iter; left time: 1870.5270s\n",
      "\titers: 200, epoch: 40 | loss: 0.0715017\n",
      "\tspeed: 0.0801s/iter; left time: 1073.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0688567 Vali Loss: 0.0879054 Test Loss: 0.1023428\n",
      "Validation loss decreased (0.087929 --> 0.087905).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0670869\n",
      "\tspeed: 0.1408s/iter; left time: 1869.5676s\n",
      "\titers: 200, epoch: 41 | loss: 0.0683611\n",
      "\tspeed: 0.0801s/iter; left time: 1055.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0688425 Vali Loss: 0.0879598 Test Loss: 0.1023723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0749719\n",
      "\tspeed: 0.1380s/iter; left time: 1802.5750s\n",
      "\titers: 200, epoch: 42 | loss: 0.0689353\n",
      "\tspeed: 0.0800s/iter; left time: 1036.3447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 223 | Train Loss: 0.0687792 Vali Loss: 0.0879433 Test Loss: 0.1024432\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0679562\n",
      "\tspeed: 0.1378s/iter; left time: 1768.9955s\n",
      "\titers: 200, epoch: 43 | loss: 0.0753458\n",
      "\tspeed: 0.0800s/iter; left time: 1019.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0688359 Vali Loss: 0.0879439 Test Loss: 0.1023748\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0721654\n",
      "\tspeed: 0.1376s/iter; left time: 1736.0321s\n",
      "\titers: 200, epoch: 44 | loss: 0.0668151\n",
      "\tspeed: 0.0799s/iter; left time: 1000.2783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 223 | Train Loss: 0.0687932 Vali Loss: 0.0879905 Test Loss: 0.1023978\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0727886\n",
      "\tspeed: 0.1376s/iter; left time: 1704.9246s\n",
      "\titers: 200, epoch: 45 | loss: 0.0697393\n",
      "\tspeed: 0.0800s/iter; left time: 982.7047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 223 | Train Loss: 0.0688187 Vali Loss: 0.0879540 Test Loss: 0.1023846\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0716208\n",
      "\tspeed: 0.1375s/iter; left time: 1672.3700s\n",
      "\titers: 200, epoch: 46 | loss: 0.0696595\n",
      "\tspeed: 0.0799s/iter; left time: 963.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 223 | Train Loss: 0.0687803 Vali Loss: 0.0879580 Test Loss: 0.1024324\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0673338\n",
      "\tspeed: 0.1380s/iter; left time: 1648.2307s\n",
      "\titers: 200, epoch: 47 | loss: 0.0685025\n",
      "\tspeed: 0.0799s/iter; left time: 946.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0687667 Vali Loss: 0.0880418 Test Loss: 0.1024176\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0642225\n",
      "\tspeed: 0.1379s/iter; left time: 1616.3080s\n",
      "\titers: 200, epoch: 48 | loss: 0.0709631\n",
      "\tspeed: 0.0800s/iter; left time: 929.8183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0687600 Vali Loss: 0.0879649 Test Loss: 0.1024027\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0651251\n",
      "\tspeed: 0.1385s/iter; left time: 1592.5670s\n",
      "\titers: 200, epoch: 49 | loss: 0.0700690\n",
      "\tspeed: 0.0800s/iter; left time: 911.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0687423 Vali Loss: 0.0880024 Test Loss: 0.1024056\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0694808\n",
      "\tspeed: 0.1386s/iter; left time: 1562.3954s\n",
      "\titers: 200, epoch: 50 | loss: 0.0728666\n",
      "\tspeed: 0.0801s/iter; left time: 895.3182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0687120 Vali Loss: 0.0880527 Test Loss: 0.1024245\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025694113224744797, rmse:0.1602938324213028, mae:0.10234277695417404, rse:0.5529683232307434\n",
      "Intermediate time for GB and pred_len 24: 00h:30m:52.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1358091\n",
      "\tspeed: 0.1060s/iter; left time: 2342.1521s\n",
      "\titers: 200, epoch: 1 | loss: 0.1349047\n",
      "\tspeed: 0.0807s/iter; left time: 1775.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.37s\n",
      "Steps: 222 | Train Loss: 0.1414604 Vali Loss: 0.1448565 Test Loss: 0.1698220\n",
      "Validation loss decreased (inf --> 0.144856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1088362\n",
      "\tspeed: 0.1409s/iter; left time: 3082.2045s\n",
      "\titers: 200, epoch: 2 | loss: 0.1076481\n",
      "\tspeed: 0.0808s/iter; left time: 1759.2820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.1105519 Vali Loss: 0.1171972 Test Loss: 0.1389077\n",
      "Validation loss decreased (0.144856 --> 0.117197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0983290\n",
      "\tspeed: 0.1403s/iter; left time: 3038.4772s\n",
      "\titers: 200, epoch: 3 | loss: 0.1036651\n",
      "\tspeed: 0.0807s/iter; left time: 1740.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.1017730 Vali Loss: 0.1162336 Test Loss: 0.1390613\n",
      "Validation loss decreased (0.117197 --> 0.116234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1023673\n",
      "\tspeed: 0.1401s/iter; left time: 3002.8141s\n",
      "\titers: 200, epoch: 4 | loss: 0.0994180\n",
      "\tspeed: 0.0809s/iter; left time: 1726.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0996428 Vali Loss: 0.1154969 Test Loss: 0.1391144\n",
      "Validation loss decreased (0.116234 --> 0.115497).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0971655\n",
      "\tspeed: 0.1406s/iter; left time: 2982.7213s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963834\n",
      "\tspeed: 0.0807s/iter; left time: 1702.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0980626 Vali Loss: 0.1158063 Test Loss: 0.1411522\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0982594\n",
      "\tspeed: 0.1378s/iter; left time: 2893.0686s\n",
      "\titers: 200, epoch: 6 | loss: 0.0976275\n",
      "\tspeed: 0.0806s/iter; left time: 1683.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0965680 Vali Loss: 0.1155324 Test Loss: 0.1414398\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0927428\n",
      "\tspeed: 0.1393s/iter; left time: 2893.1079s\n",
      "\titers: 200, epoch: 7 | loss: 0.0932568\n",
      "\tspeed: 0.0808s/iter; left time: 1669.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0951679 Vali Loss: 0.1151066 Test Loss: 0.1423663\n",
      "Validation loss decreased (0.115497 --> 0.115107).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0970360\n",
      "\tspeed: 0.1407s/iter; left time: 2890.8038s\n",
      "\titers: 200, epoch: 8 | loss: 0.0886637\n",
      "\tspeed: 0.0807s/iter; left time: 1650.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 222 | Train Loss: 0.0936608 Vali Loss: 0.1151603 Test Loss: 0.1438675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0899512\n",
      "\tspeed: 0.1384s/iter; left time: 2812.3019s\n",
      "\titers: 200, epoch: 9 | loss: 0.0887586\n",
      "\tspeed: 0.0805s/iter; left time: 1628.8723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 222 | Train Loss: 0.0923841 Vali Loss: 0.1151062 Test Loss: 0.1445265\n",
      "Validation loss decreased (0.115107 --> 0.115106).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0902266\n",
      "\tspeed: 0.1405s/iter; left time: 2824.7093s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846719\n",
      "\tspeed: 0.0805s/iter; left time: 1610.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 222 | Train Loss: 0.0910080 Vali Loss: 0.1150696 Test Loss: 0.1448590\n",
      "Validation loss decreased (0.115106 --> 0.115070).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0889520\n",
      "\tspeed: 0.1400s/iter; left time: 2783.6996s\n",
      "\titers: 200, epoch: 11 | loss: 0.0883325\n",
      "\tspeed: 0.0806s/iter; left time: 1593.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0897821 Vali Loss: 0.1159446 Test Loss: 0.1465855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0860249\n",
      "\tspeed: 0.1388s/iter; left time: 2729.6262s\n",
      "\titers: 200, epoch: 12 | loss: 0.0861240\n",
      "\tspeed: 0.0805s/iter; left time: 1573.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 222 | Train Loss: 0.0884889 Vali Loss: 0.1161465 Test Loss: 0.1472885\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0880837\n",
      "\tspeed: 0.1396s/iter; left time: 2712.7592s\n",
      "\titers: 200, epoch: 13 | loss: 0.0861884\n",
      "\tspeed: 0.0806s/iter; left time: 1558.6562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0875239 Vali Loss: 0.1165294 Test Loss: 0.1474077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0887766\n",
      "\tspeed: 0.1381s/iter; left time: 2654.2521s\n",
      "\titers: 200, epoch: 14 | loss: 0.0835006\n",
      "\tspeed: 0.0807s/iter; left time: 1541.8736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0865451 Vali Loss: 0.1182222 Test Loss: 0.1485320\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0906235\n",
      "\tspeed: 0.1395s/iter; left time: 2649.9562s\n",
      "\titers: 200, epoch: 15 | loss: 0.0860536\n",
      "\tspeed: 0.0808s/iter; left time: 1525.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0857539 Vali Loss: 0.1185830 Test Loss: 0.1495188\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0864211\n",
      "\tspeed: 0.1382s/iter; left time: 2594.7448s\n",
      "\titers: 200, epoch: 16 | loss: 0.0855064\n",
      "\tspeed: 0.0806s/iter; left time: 1504.1109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 222 | Train Loss: 0.0849867 Vali Loss: 0.1185916 Test Loss: 0.1497924\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0849342\n",
      "\tspeed: 0.1388s/iter; left time: 2575.5074s\n",
      "\titers: 200, epoch: 17 | loss: 0.0859643\n",
      "\tspeed: 0.0808s/iter; left time: 1489.9697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0844976 Vali Loss: 0.1189754 Test Loss: 0.1503125\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0867529\n",
      "\tspeed: 0.1384s/iter; left time: 2536.3141s\n",
      "\titers: 200, epoch: 18 | loss: 0.0841190\n",
      "\tspeed: 0.0807s/iter; left time: 1470.2874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0838787 Vali Loss: 0.1192779 Test Loss: 0.1504883\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0843950\n",
      "\tspeed: 0.1382s/iter; left time: 2502.7071s\n",
      "\titers: 200, epoch: 19 | loss: 0.0836716\n",
      "\tspeed: 0.0801s/iter; left time: 1442.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:17.98s\n",
      "Steps: 222 | Train Loss: 0.0833456 Vali Loss: 0.1201275 Test Loss: 0.1502754\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0815062\n",
      "\tspeed: 0.1380s/iter; left time: 2467.2989s\n",
      "\titers: 200, epoch: 20 | loss: 0.0901580\n",
      "\tspeed: 0.0806s/iter; left time: 1432.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 222 | Train Loss: 0.0829971 Vali Loss: 0.1198272 Test Loss: 0.1505910\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04585912451148033, rmse:0.2141474336385727, mae:0.1448589712381363, rse:0.7405516505241394\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1389547\n",
      "\tspeed: 0.0823s/iter; left time: 1818.7680s\n",
      "\titers: 200, epoch: 1 | loss: 0.1327076\n",
      "\tspeed: 0.0808s/iter; left time: 1776.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.1421077 Vali Loss: 0.1456874 Test Loss: 0.1706855\n",
      "Validation loss decreased (inf --> 0.145687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1122408\n",
      "\tspeed: 0.1409s/iter; left time: 3083.2981s\n",
      "\titers: 200, epoch: 2 | loss: 0.1036625\n",
      "\tspeed: 0.0807s/iter; left time: 1758.1235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.1115317 Vali Loss: 0.1174392 Test Loss: 0.1394317\n",
      "Validation loss decreased (0.145687 --> 0.117439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019299\n",
      "\tspeed: 0.1456s/iter; left time: 3152.2284s\n",
      "\titers: 200, epoch: 3 | loss: 0.0972814\n",
      "\tspeed: 0.0806s/iter; left time: 1737.7109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.1020559 Vali Loss: 0.1162187 Test Loss: 0.1396693\n",
      "Validation loss decreased (0.117439 --> 0.116219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993500\n",
      "\tspeed: 0.1412s/iter; left time: 3027.4768s\n",
      "\titers: 200, epoch: 4 | loss: 0.0995188\n",
      "\tspeed: 0.0806s/iter; left time: 1720.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0997396 Vali Loss: 0.1157485 Test Loss: 0.1406896\n",
      "Validation loss decreased (0.116219 --> 0.115749).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0968165\n",
      "\tspeed: 0.1424s/iter; left time: 3019.9645s\n",
      "\titers: 200, epoch: 5 | loss: 0.1007464\n",
      "\tspeed: 0.0807s/iter; left time: 1704.7160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0979422 Vali Loss: 0.1149712 Test Loss: 0.1407970\n",
      "Validation loss decreased (0.115749 --> 0.114971).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0946351\n",
      "\tspeed: 0.1417s/iter; left time: 2975.4706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0939036\n",
      "\tspeed: 0.0806s/iter; left time: 1683.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0962292 Vali Loss: 0.1152229 Test Loss: 0.1415257\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0939565\n",
      "\tspeed: 0.1403s/iter; left time: 2913.3856s\n",
      "\titers: 200, epoch: 7 | loss: 0.0928832\n",
      "\tspeed: 0.0806s/iter; left time: 1665.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0945780 Vali Loss: 0.1153166 Test Loss: 0.1427085\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0905723\n",
      "\tspeed: 0.1396s/iter; left time: 2869.2149s\n",
      "\titers: 200, epoch: 8 | loss: 0.0928991\n",
      "\tspeed: 0.0805s/iter; left time: 1646.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 222 | Train Loss: 0.0930087 Vali Loss: 0.1158621 Test Loss: 0.1432852\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0974457\n",
      "\tspeed: 0.1389s/iter; left time: 2823.7890s\n",
      "\titers: 200, epoch: 9 | loss: 0.0915007\n",
      "\tspeed: 0.0806s/iter; left time: 1629.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0914214 Vali Loss: 0.1161837 Test Loss: 0.1440141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0934651\n",
      "\tspeed: 0.1391s/iter; left time: 2795.6718s\n",
      "\titers: 200, epoch: 10 | loss: 0.0912926\n",
      "\tspeed: 0.0805s/iter; left time: 1609.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0901336 Vali Loss: 0.1175008 Test Loss: 0.1453111\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0854642\n",
      "\tspeed: 0.1395s/iter; left time: 2773.6587s\n",
      "\titers: 200, epoch: 11 | loss: 0.0908249\n",
      "\tspeed: 0.0806s/iter; left time: 1593.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0889183 Vali Loss: 0.1184011 Test Loss: 0.1458802\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0828760\n",
      "\tspeed: 0.1387s/iter; left time: 2727.2699s\n",
      "\titers: 200, epoch: 12 | loss: 0.0861469\n",
      "\tspeed: 0.0808s/iter; left time: 1579.4885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 222 | Train Loss: 0.0878806 Vali Loss: 0.1183724 Test Loss: 0.1460292\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0887259\n",
      "\tspeed: 0.1397s/iter; left time: 2715.6352s\n",
      "\titers: 200, epoch: 13 | loss: 0.0837332\n",
      "\tspeed: 0.0809s/iter; left time: 1563.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.0869470 Vali Loss: 0.1185323 Test Loss: 0.1464543\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0832796\n",
      "\tspeed: 0.1391s/iter; left time: 2671.9162s\n",
      "\titers: 200, epoch: 14 | loss: 0.0869908\n",
      "\tspeed: 0.0803s/iter; left time: 1534.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 222 | Train Loss: 0.0861373 Vali Loss: 0.1191460 Test Loss: 0.1477436\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0838692\n",
      "\tspeed: 0.1386s/iter; left time: 2632.5983s\n",
      "\titers: 200, epoch: 15 | loss: 0.0864395\n",
      "\tspeed: 0.0807s/iter; left time: 1524.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 222 | Train Loss: 0.0854612 Vali Loss: 0.1197591 Test Loss: 0.1484080\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0425884984433651, rmse:0.2063698172569275, mae:0.14079692959785461, rse:0.7136555910110474\n",
      "Intermediate time for GB and pred_len 96: 00h:13m:06.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1398706\n",
      "\tspeed: 0.1068s/iter; left time: 2361.2180s\n",
      "\titers: 200, epoch: 1 | loss: 0.1382439\n",
      "\tspeed: 0.0814s/iter; left time: 1791.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.54s\n",
      "Steps: 222 | Train Loss: 0.1429146 Vali Loss: 0.1471829 Test Loss: 0.1729666\n",
      "Validation loss decreased (inf --> 0.147183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1098959\n",
      "\tspeed: 0.1408s/iter; left time: 3081.3877s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087988\n",
      "\tspeed: 0.0812s/iter; left time: 1769.1272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 222 | Train Loss: 0.1143142 Vali Loss: 0.1217393 Test Loss: 0.1444807\n",
      "Validation loss decreased (0.147183 --> 0.121739).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1046128\n",
      "\tspeed: 0.1406s/iter; left time: 3044.6341s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066747\n",
      "\tspeed: 0.0816s/iter; left time: 1758.8457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.1060163 Vali Loss: 0.1199054 Test Loss: 0.1455345\n",
      "Validation loss decreased (0.121739 --> 0.119905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1033576\n",
      "\tspeed: 0.1419s/iter; left time: 3041.1615s\n",
      "\titers: 200, epoch: 4 | loss: 0.1030032\n",
      "\tspeed: 0.0814s/iter; left time: 1737.4647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.1033712 Vali Loss: 0.1203927 Test Loss: 0.1471462\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1010814\n",
      "\tspeed: 0.1393s/iter; left time: 2954.4741s\n",
      "\titers: 200, epoch: 5 | loss: 0.0997352\n",
      "\tspeed: 0.0814s/iter; left time: 1718.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 222 | Train Loss: 0.1010653 Vali Loss: 0.1205869 Test Loss: 0.1493505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0962149\n",
      "\tspeed: 0.1406s/iter; left time: 2950.9309s\n",
      "\titers: 200, epoch: 6 | loss: 0.1000016\n",
      "\tspeed: 0.0811s/iter; left time: 1694.3372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.34s\n",
      "Steps: 222 | Train Loss: 0.0988993 Vali Loss: 0.1206984 Test Loss: 0.1489712\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0959983\n",
      "\tspeed: 0.1398s/iter; left time: 2904.1469s\n",
      "\titers: 200, epoch: 7 | loss: 0.0942835\n",
      "\tspeed: 0.0813s/iter; left time: 1679.9238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.0969016 Vali Loss: 0.1214482 Test Loss: 0.1511385\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0948653\n",
      "\tspeed: 0.1389s/iter; left time: 2854.4583s\n",
      "\titers: 200, epoch: 8 | loss: 0.0935265\n",
      "\tspeed: 0.0811s/iter; left time: 1658.9569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 222 | Train Loss: 0.0950081 Vali Loss: 0.1208681 Test Loss: 0.1513408\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0944575\n",
      "\tspeed: 0.1397s/iter; left time: 2840.0386s\n",
      "\titers: 200, epoch: 9 | loss: 0.0945373\n",
      "\tspeed: 0.0814s/iter; left time: 1646.6899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0932375 Vali Loss: 0.1216507 Test Loss: 0.1517617\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0912117\n",
      "\tspeed: 0.1400s/iter; left time: 2814.2967s\n",
      "\titers: 200, epoch: 10 | loss: 0.0915381\n",
      "\tspeed: 0.0812s/iter; left time: 1623.7370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 222 | Train Loss: 0.0916975 Vali Loss: 0.1230478 Test Loss: 0.1538335\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0911945\n",
      "\tspeed: 0.1395s/iter; left time: 2774.2939s\n",
      "\titers: 200, epoch: 11 | loss: 0.0884001\n",
      "\tspeed: 0.0813s/iter; left time: 1607.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.0903979 Vali Loss: 0.1235992 Test Loss: 0.1541341\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0880264\n",
      "\tspeed: 0.1391s/iter; left time: 2735.3835s\n",
      "\titers: 200, epoch: 12 | loss: 0.0866772\n",
      "\tspeed: 0.0815s/iter; left time: 1594.7638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.0892005 Vali Loss: 0.1242566 Test Loss: 0.1546974\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0874250\n",
      "\tspeed: 0.1387s/iter; left time: 2696.3822s\n",
      "\titers: 200, epoch: 13 | loss: 0.0880191\n",
      "\tspeed: 0.0812s/iter; left time: 1570.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0882589 Vali Loss: 0.1245862 Test Loss: 0.1551056\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04369062930345535, rmse:0.20902302861213684, mae:0.14553453028202057, rse:0.7247128486633301\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1419638\n",
      "\tspeed: 0.0828s/iter; left time: 1830.3672s\n",
      "\titers: 200, epoch: 1 | loss: 0.1385796\n",
      "\tspeed: 0.0813s/iter; left time: 1787.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.1434565 Vali Loss: 0.1476240 Test Loss: 0.1734360\n",
      "Validation loss decreased (inf --> 0.147624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1124867\n",
      "\tspeed: 0.1419s/iter; left time: 3105.6768s\n",
      "\titers: 200, epoch: 2 | loss: 0.1091222\n",
      "\tspeed: 0.0811s/iter; left time: 1765.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.1151475 Vali Loss: 0.1221997 Test Loss: 0.1450011\n",
      "Validation loss decreased (0.147624 --> 0.122200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1074508\n",
      "\tspeed: 0.1404s/iter; left time: 3041.6527s\n",
      "\titers: 200, epoch: 3 | loss: 0.1105702\n",
      "\tspeed: 0.0811s/iter; left time: 1748.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.1062980 Vali Loss: 0.1204826 Test Loss: 0.1468059\n",
      "Validation loss decreased (0.122200 --> 0.120483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1053387\n",
      "\tspeed: 0.1405s/iter; left time: 3011.8811s\n",
      "\titers: 200, epoch: 4 | loss: 0.1039608\n",
      "\tspeed: 0.0811s/iter; left time: 1730.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.1037557 Vali Loss: 0.1203048 Test Loss: 0.1477481\n",
      "Validation loss decreased (0.120483 --> 0.120305).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036354\n",
      "\tspeed: 0.1408s/iter; left time: 2987.0007s\n",
      "\titers: 200, epoch: 5 | loss: 0.0983951\n",
      "\tspeed: 0.0811s/iter; left time: 1712.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.1015428 Vali Loss: 0.1195792 Test Loss: 0.1480534\n",
      "Validation loss decreased (0.120305 --> 0.119579).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994660\n",
      "\tspeed: 0.1418s/iter; left time: 2976.3285s\n",
      "\titers: 200, epoch: 6 | loss: 0.0961423\n",
      "\tspeed: 0.0814s/iter; left time: 1700.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0993276 Vali Loss: 0.1202111 Test Loss: 0.1496725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0958781\n",
      "\tspeed: 0.1395s/iter; left time: 2897.0162s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959541\n",
      "\tspeed: 0.0811s/iter; left time: 1675.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.0972312 Vali Loss: 0.1203471 Test Loss: 0.1500919\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0944401\n",
      "\tspeed: 0.1396s/iter; left time: 2867.4243s\n",
      "\titers: 200, epoch: 8 | loss: 0.0966303\n",
      "\tspeed: 0.0811s/iter; left time: 1658.0043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0954563 Vali Loss: 0.1199050 Test Loss: 0.1506354\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0943413\n",
      "\tspeed: 0.1409s/iter; left time: 2863.6914s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965194\n",
      "\tspeed: 0.0815s/iter; left time: 1647.5000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.0937926 Vali Loss: 0.1209276 Test Loss: 0.1508951\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920365\n",
      "\tspeed: 0.1400s/iter; left time: 2815.2283s\n",
      "\titers: 200, epoch: 10 | loss: 0.0944835\n",
      "\tspeed: 0.0811s/iter; left time: 1621.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0923184 Vali Loss: 0.1216158 Test Loss: 0.1523672\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0890176\n",
      "\tspeed: 0.1395s/iter; left time: 2772.7185s\n",
      "\titers: 200, epoch: 11 | loss: 0.0903773\n",
      "\tspeed: 0.0813s/iter; left time: 1607.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.0910789 Vali Loss: 0.1217306 Test Loss: 0.1521261\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0872232\n",
      "\tspeed: 0.1396s/iter; left time: 2744.6620s\n",
      "\titers: 200, epoch: 12 | loss: 0.0923500\n",
      "\tspeed: 0.0811s/iter; left time: 1586.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.0899829 Vali Loss: 0.1231703 Test Loss: 0.1537110\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0872186\n",
      "\tspeed: 0.1397s/iter; left time: 2714.4259s\n",
      "\titers: 200, epoch: 13 | loss: 0.0887902\n",
      "\tspeed: 0.0811s/iter; left time: 1567.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.0890337 Vali Loss: 0.1235894 Test Loss: 0.1542339\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0884640\n",
      "\tspeed: 0.1395s/iter; left time: 2681.4181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0870688\n",
      "\tspeed: 0.0810s/iter; left time: 1549.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0882041 Vali Loss: 0.1238865 Test Loss: 0.1543076\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0922166\n",
      "\tspeed: 0.1408s/iter; left time: 2674.9680s\n",
      "\titers: 200, epoch: 15 | loss: 0.0888370\n",
      "\tspeed: 0.0813s/iter; left time: 1535.7108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0873947 Vali Loss: 0.1243513 Test Loss: 0.1549856\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04569704458117485, rmse:0.21376867592334747, mae:0.1480533480644226, rse:0.7411666512489319\n",
      "Intermediate time for GB and pred_len 168: 00h:10m:36.44s\n",
      "Intermediate time for GB: 00h:54m:35.29s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1526842\n",
      "\tspeed: 0.0609s/iter; left time: 1358.8946s\n",
      "\titers: 200, epoch: 1 | loss: 0.1366305\n",
      "\tspeed: 0.0341s/iter; left time: 757.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.1550454 Vali Loss: 0.1393994 Test Loss: 0.1681718\n",
      "Validation loss decreased (inf --> 0.139399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0732484\n",
      "\tspeed: 0.0644s/iter; left time: 1422.6868s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723599\n",
      "\tspeed: 0.0342s/iter; left time: 751.8843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0805116 Vali Loss: 0.0647224 Test Loss: 0.0717992\n",
      "Validation loss decreased (0.139399 --> 0.064722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670712\n",
      "\tspeed: 0.0665s/iter; left time: 1454.2014s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631713\n",
      "\tspeed: 0.0341s/iter; left time: 742.5281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0640164 Vali Loss: 0.0604511 Test Loss: 0.0675387\n",
      "Validation loss decreased (0.064722 --> 0.060451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615953\n",
      "\tspeed: 0.0642s/iter; left time: 1387.7785s\n",
      "\titers: 200, epoch: 4 | loss: 0.0594863\n",
      "\tspeed: 0.0341s/iter; left time: 734.9610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0607313 Vali Loss: 0.0585351 Test Loss: 0.0652289\n",
      "Validation loss decreased (0.060451 --> 0.058535).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582284\n",
      "\tspeed: 0.0640s/iter; left time: 1370.6194s\n",
      "\titers: 200, epoch: 5 | loss: 0.0548869\n",
      "\tspeed: 0.0344s/iter; left time: 733.7277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0586365 Vali Loss: 0.0571023 Test Loss: 0.0640453\n",
      "Validation loss decreased (0.058535 --> 0.057102).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568549\n",
      "\tspeed: 0.0643s/iter; left time: 1361.1592s\n",
      "\titers: 200, epoch: 6 | loss: 0.0545233\n",
      "\tspeed: 0.0339s/iter; left time: 714.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0572533 Vali Loss: 0.0562853 Test Loss: 0.0630265\n",
      "Validation loss decreased (0.057102 --> 0.056285).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588305\n",
      "\tspeed: 0.0646s/iter; left time: 1353.0178s\n",
      "\titers: 200, epoch: 7 | loss: 0.0523065\n",
      "\tspeed: 0.0346s/iter; left time: 721.7980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0561701 Vali Loss: 0.0557691 Test Loss: 0.0625740\n",
      "Validation loss decreased (0.056285 --> 0.055769).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0549896\n",
      "\tspeed: 0.0646s/iter; left time: 1340.1382s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590127\n",
      "\tspeed: 0.0340s/iter; left time: 702.0055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0555243 Vali Loss: 0.0552860 Test Loss: 0.0622382\n",
      "Validation loss decreased (0.055769 --> 0.055286).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0538663\n",
      "\tspeed: 0.0661s/iter; left time: 1355.4103s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581174\n",
      "\tspeed: 0.0357s/iter; left time: 728.5238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0549856 Vali Loss: 0.0547778 Test Loss: 0.0615789\n",
      "Validation loss decreased (0.055286 --> 0.054778).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0544842\n",
      "\tspeed: 0.0644s/iter; left time: 1305.6717s\n",
      "\titers: 200, epoch: 10 | loss: 0.0509822\n",
      "\tspeed: 0.0341s/iter; left time: 687.6872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0545583 Vali Loss: 0.0547986 Test Loss: 0.0614929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541769\n",
      "\tspeed: 0.0625s/iter; left time: 1253.8060s\n",
      "\titers: 200, epoch: 11 | loss: 0.0549371\n",
      "\tspeed: 0.0340s/iter; left time: 677.6949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0541390 Vali Loss: 0.0542580 Test Loss: 0.0609762\n",
      "Validation loss decreased (0.054778 --> 0.054258).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0538365\n",
      "\tspeed: 0.0638s/iter; left time: 1265.0536s\n",
      "\titers: 200, epoch: 12 | loss: 0.0529875\n",
      "\tspeed: 0.0344s/iter; left time: 678.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0538779 Vali Loss: 0.0541497 Test Loss: 0.0608541\n",
      "Validation loss decreased (0.054258 --> 0.054150).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0556539\n",
      "\tspeed: 0.0631s/iter; left time: 1238.1737s\n",
      "\titers: 200, epoch: 13 | loss: 0.0526646\n",
      "\tspeed: 0.0344s/iter; left time: 670.3316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0536023 Vali Loss: 0.0540321 Test Loss: 0.0606161\n",
      "Validation loss decreased (0.054150 --> 0.054032).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0543625\n",
      "\tspeed: 0.0645s/iter; left time: 1250.2886s\n",
      "\titers: 200, epoch: 14 | loss: 0.0530023\n",
      "\tspeed: 0.0348s/iter; left time: 670.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0533630 Vali Loss: 0.0541184 Test Loss: 0.0608187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0521512\n",
      "\tspeed: 0.0630s/iter; left time: 1208.2481s\n",
      "\titers: 200, epoch: 15 | loss: 0.0521281\n",
      "\tspeed: 0.0344s/iter; left time: 656.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0531000 Vali Loss: 0.0539720 Test Loss: 0.0605283\n",
      "Validation loss decreased (0.054032 --> 0.053972).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509178\n",
      "\tspeed: 0.0627s/iter; left time: 1187.9921s\n",
      "\titers: 200, epoch: 16 | loss: 0.0512274\n",
      "\tspeed: 0.0337s/iter; left time: 635.2819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0529989 Vali Loss: 0.0536041 Test Loss: 0.0602776\n",
      "Validation loss decreased (0.053972 --> 0.053604).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0513468\n",
      "\tspeed: 0.0627s/iter; left time: 1173.1582s\n",
      "\titers: 200, epoch: 17 | loss: 0.0483066\n",
      "\tspeed: 0.0340s/iter; left time: 632.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0528339 Vali Loss: 0.0536399 Test Loss: 0.0601474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0508105\n",
      "\tspeed: 0.0629s/iter; left time: 1163.3793s\n",
      "\titers: 200, epoch: 18 | loss: 0.0472548\n",
      "\tspeed: 0.0337s/iter; left time: 620.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0526830 Vali Loss: 0.0535131 Test Loss: 0.0600573\n",
      "Validation loss decreased (0.053604 --> 0.053513).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0543427\n",
      "\tspeed: 0.0631s/iter; left time: 1151.9394s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539975\n",
      "\tspeed: 0.0339s/iter; left time: 615.9884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0526239 Vali Loss: 0.0534467 Test Loss: 0.0600467\n",
      "Validation loss decreased (0.053513 --> 0.053447).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0512956\n",
      "\tspeed: 0.0633s/iter; left time: 1142.3240s\n",
      "\titers: 200, epoch: 20 | loss: 0.0518979\n",
      "\tspeed: 0.0338s/iter; left time: 605.6957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0524580 Vali Loss: 0.0534504 Test Loss: 0.0601290\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0516894\n",
      "\tspeed: 0.0625s/iter; left time: 1114.1185s\n",
      "\titers: 200, epoch: 21 | loss: 0.0514001\n",
      "\tspeed: 0.0340s/iter; left time: 601.7961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0523597 Vali Loss: 0.0533231 Test Loss: 0.0599976\n",
      "Validation loss decreased (0.053447 --> 0.053323).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0483420\n",
      "\tspeed: 0.0626s/iter; left time: 1102.2952s\n",
      "\titers: 200, epoch: 22 | loss: 0.0524221\n",
      "\tspeed: 0.0337s/iter; left time: 590.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0522725 Vali Loss: 0.0532108 Test Loss: 0.0598633\n",
      "Validation loss decreased (0.053323 --> 0.053211).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0503389\n",
      "\tspeed: 0.0628s/iter; left time: 1090.2020s\n",
      "\titers: 200, epoch: 23 | loss: 0.0539414\n",
      "\tspeed: 0.0338s/iter; left time: 583.9849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0522263 Vali Loss: 0.0532671 Test Loss: 0.0599022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0542046\n",
      "\tspeed: 0.0624s/iter; left time: 1070.4008s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510984\n",
      "\tspeed: 0.0338s/iter; left time: 575.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0521891 Vali Loss: 0.0531939 Test Loss: 0.0597542\n",
      "Validation loss decreased (0.053211 --> 0.053194).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0514270\n",
      "\tspeed: 0.0627s/iter; left time: 1060.7629s\n",
      "\titers: 200, epoch: 25 | loss: 0.0550747\n",
      "\tspeed: 0.0337s/iter; left time: 567.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0520553 Vali Loss: 0.0530766 Test Loss: 0.0597279\n",
      "Validation loss decreased (0.053194 --> 0.053077).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0486141\n",
      "\tspeed: 0.0628s/iter; left time: 1048.8454s\n",
      "\titers: 200, epoch: 26 | loss: 0.0538085\n",
      "\tspeed: 0.0338s/iter; left time: 560.6971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0519923 Vali Loss: 0.0531875 Test Loss: 0.0597662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0524277\n",
      "\tspeed: 0.0620s/iter; left time: 1021.1319s\n",
      "\titers: 200, epoch: 27 | loss: 0.0521245\n",
      "\tspeed: 0.0338s/iter; left time: 553.4254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0520323 Vali Loss: 0.0530715 Test Loss: 0.0596598\n",
      "Validation loss decreased (0.053077 --> 0.053071).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0528489\n",
      "\tspeed: 0.0631s/iter; left time: 1025.7348s\n",
      "\titers: 200, epoch: 28 | loss: 0.0528272\n",
      "\tspeed: 0.0338s/iter; left time: 546.2785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0519045 Vali Loss: 0.0530310 Test Loss: 0.0596944\n",
      "Validation loss decreased (0.053071 --> 0.053031).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0494530\n",
      "\tspeed: 0.0629s/iter; left time: 1007.4482s\n",
      "\titers: 200, epoch: 29 | loss: 0.0549773\n",
      "\tspeed: 0.0337s/iter; left time: 537.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0518919 Vali Loss: 0.0531214 Test Loss: 0.0597658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0509516\n",
      "\tspeed: 0.0626s/iter; left time: 990.1646s\n",
      "\titers: 200, epoch: 30 | loss: 0.0541899\n",
      "\tspeed: 0.0339s/iter; left time: 531.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0518665 Vali Loss: 0.0530275 Test Loss: 0.0596586\n",
      "Validation loss decreased (0.053031 --> 0.053028).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0517120\n",
      "\tspeed: 0.0628s/iter; left time: 978.0485s\n",
      "\titers: 200, epoch: 31 | loss: 0.0504429\n",
      "\tspeed: 0.0337s/iter; left time: 521.0384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0518409 Vali Loss: 0.0530472 Test Loss: 0.0595775\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0496667\n",
      "\tspeed: 0.0625s/iter; left time: 960.1056s\n",
      "\titers: 200, epoch: 32 | loss: 0.0514431\n",
      "\tspeed: 0.0342s/iter; left time: 521.5338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0518175 Vali Loss: 0.0530794 Test Loss: 0.0596468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0489944\n",
      "\tspeed: 0.0622s/iter; left time: 941.2344s\n",
      "\titers: 200, epoch: 33 | loss: 0.0532939\n",
      "\tspeed: 0.0338s/iter; left time: 508.6785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0517973 Vali Loss: 0.0530503 Test Loss: 0.0596521\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0528417\n",
      "\tspeed: 0.0626s/iter; left time: 932.9459s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519611\n",
      "\tspeed: 0.0338s/iter; left time: 500.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0517021 Vali Loss: 0.0530652 Test Loss: 0.0594816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0530752\n",
      "\tspeed: 0.0628s/iter; left time: 922.1408s\n",
      "\titers: 200, epoch: 35 | loss: 0.0518166\n",
      "\tspeed: 0.0339s/iter; left time: 494.1251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0517347 Vali Loss: 0.0528620 Test Loss: 0.0595123\n",
      "Validation loss decreased (0.053028 --> 0.052862).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0506464\n",
      "\tspeed: 0.0645s/iter; left time: 932.4568s\n",
      "\titers: 200, epoch: 36 | loss: 0.0517927\n",
      "\tspeed: 0.0338s/iter; left time: 484.9614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0516731 Vali Loss: 0.0529967 Test Loss: 0.0596204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0519233\n",
      "\tspeed: 0.0623s/iter; left time: 887.4264s\n",
      "\titers: 200, epoch: 37 | loss: 0.0506047\n",
      "\tspeed: 0.0340s/iter; left time: 480.4417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0516810 Vali Loss: 0.0530068 Test Loss: 0.0595802\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0507490\n",
      "\tspeed: 0.0625s/iter; left time: 876.1894s\n",
      "\titers: 200, epoch: 38 | loss: 0.0562936\n",
      "\tspeed: 0.0340s/iter; left time: 472.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0516737 Vali Loss: 0.0529319 Test Loss: 0.0594970\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0492359\n",
      "\tspeed: 0.0624s/iter; left time: 860.4935s\n",
      "\titers: 200, epoch: 39 | loss: 0.0538159\n",
      "\tspeed: 0.0338s/iter; left time: 462.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0516829 Vali Loss: 0.0529696 Test Loss: 0.0594831\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0513327\n",
      "\tspeed: 0.0620s/iter; left time: 841.4094s\n",
      "\titers: 200, epoch: 40 | loss: 0.0514433\n",
      "\tspeed: 0.0338s/iter; left time: 455.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0516562 Vali Loss: 0.0530150 Test Loss: 0.0596243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0518598\n",
      "\tspeed: 0.0629s/iter; left time: 839.1156s\n",
      "\titers: 200, epoch: 41 | loss: 0.0497989\n",
      "\tspeed: 0.0340s/iter; left time: 450.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0516688 Vali Loss: 0.0528681 Test Loss: 0.0594650\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0497980\n",
      "\tspeed: 0.0624s/iter; left time: 818.5636s\n",
      "\titers: 200, epoch: 42 | loss: 0.0535568\n",
      "\tspeed: 0.0343s/iter; left time: 446.3473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0516297 Vali Loss: 0.0529409 Test Loss: 0.0594555\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0522472\n",
      "\tspeed: 0.0625s/iter; left time: 805.6177s\n",
      "\titers: 200, epoch: 43 | loss: 0.0489027\n",
      "\tspeed: 0.0339s/iter; left time: 433.5713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0516606 Vali Loss: 0.0529695 Test Loss: 0.0595177\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0520200\n",
      "\tspeed: 0.0623s/iter; left time: 789.8724s\n",
      "\titers: 200, epoch: 44 | loss: 0.0508248\n",
      "\tspeed: 0.0339s/iter; left time: 426.3386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0515849 Vali Loss: 0.0529528 Test Loss: 0.0595244\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0524924\n",
      "\tspeed: 0.0621s/iter; left time: 773.0018s\n",
      "\titers: 200, epoch: 45 | loss: 0.0509926\n",
      "\tspeed: 0.0337s/iter; left time: 415.9272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0515887 Vali Loss: 0.0530027 Test Loss: 0.0595490\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009823016822338104, rmse:0.09911113232374191, mae:0.05951228737831116, rse:0.2916720509529114\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1579360\n",
      "\tspeed: 0.0362s/iter; left time: 806.2461s\n",
      "\titers: 200, epoch: 1 | loss: 0.1345574\n",
      "\tspeed: 0.0341s/iter; left time: 756.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.1544287 Vali Loss: 0.1378902 Test Loss: 0.1664125\n",
      "Validation loss decreased (inf --> 0.137890).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0723953\n",
      "\tspeed: 0.0643s/iter; left time: 1420.1447s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673680\n",
      "\tspeed: 0.0338s/iter; left time: 741.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0807752 Vali Loss: 0.0640944 Test Loss: 0.0714371\n",
      "Validation loss decreased (0.137890 --> 0.064094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0664814\n",
      "\tspeed: 0.0635s/iter; left time: 1388.3982s\n",
      "\titers: 200, epoch: 3 | loss: 0.0602823\n",
      "\tspeed: 0.0342s/iter; left time: 743.4186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0644568 Vali Loss: 0.0613151 Test Loss: 0.0682127\n",
      "Validation loss decreased (0.064094 --> 0.061315).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0619137\n",
      "\tspeed: 0.0636s/iter; left time: 1376.4854s\n",
      "\titers: 200, epoch: 4 | loss: 0.0629501\n",
      "\tspeed: 0.0343s/iter; left time: 739.5180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0613793 Vali Loss: 0.0588372 Test Loss: 0.0659621\n",
      "Validation loss decreased (0.061315 --> 0.058837).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0599205\n",
      "\tspeed: 0.0638s/iter; left time: 1365.4802s\n",
      "\titers: 200, epoch: 5 | loss: 0.0566143\n",
      "\tspeed: 0.0340s/iter; left time: 724.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0592500 Vali Loss: 0.0577281 Test Loss: 0.0648115\n",
      "Validation loss decreased (0.058837 --> 0.057728).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0587412\n",
      "\tspeed: 0.0641s/iter; left time: 1357.6046s\n",
      "\titers: 200, epoch: 6 | loss: 0.0555555\n",
      "\tspeed: 0.0344s/iter; left time: 724.7994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0577187 Vali Loss: 0.0565377 Test Loss: 0.0634899\n",
      "Validation loss decreased (0.057728 --> 0.056538).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0582398\n",
      "\tspeed: 0.0631s/iter; left time: 1322.1493s\n",
      "\titers: 200, epoch: 7 | loss: 0.0569732\n",
      "\tspeed: 0.0343s/iter; left time: 714.9028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0565804 Vali Loss: 0.0560253 Test Loss: 0.0630894\n",
      "Validation loss decreased (0.056538 --> 0.056025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0576674\n",
      "\tspeed: 0.0637s/iter; left time: 1321.0784s\n",
      "\titers: 200, epoch: 8 | loss: 0.0565004\n",
      "\tspeed: 0.0342s/iter; left time: 704.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0557787 Vali Loss: 0.0554661 Test Loss: 0.0624663\n",
      "Validation loss decreased (0.056025 --> 0.055466).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0545671\n",
      "\tspeed: 0.0638s/iter; left time: 1307.7506s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577309\n",
      "\tspeed: 0.0345s/iter; left time: 703.1860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0551741 Vali Loss: 0.0550627 Test Loss: 0.0620055\n",
      "Validation loss decreased (0.055466 --> 0.055063).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536375\n",
      "\tspeed: 0.0641s/iter; left time: 1300.5337s\n",
      "\titers: 200, epoch: 10 | loss: 0.0555455\n",
      "\tspeed: 0.0344s/iter; left time: 693.8047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0547537 Vali Loss: 0.0550868 Test Loss: 0.0618774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0518436\n",
      "\tspeed: 0.0626s/iter; left time: 1256.4904s\n",
      "\titers: 200, epoch: 11 | loss: 0.0547084\n",
      "\tspeed: 0.0338s/iter; left time: 674.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0543565 Vali Loss: 0.0546177 Test Loss: 0.0611843\n",
      "Validation loss decreased (0.055063 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567422\n",
      "\tspeed: 0.0640s/iter; left time: 1268.7299s\n",
      "\titers: 200, epoch: 12 | loss: 0.0523581\n",
      "\tspeed: 0.0338s/iter; left time: 667.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0540275 Vali Loss: 0.0544829 Test Loss: 0.0609822\n",
      "Validation loss decreased (0.054618 --> 0.054483).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0552673\n",
      "\tspeed: 0.0639s/iter; left time: 1252.5990s\n",
      "\titers: 200, epoch: 13 | loss: 0.0510562\n",
      "\tspeed: 0.0341s/iter; left time: 665.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0537494 Vali Loss: 0.0542448 Test Loss: 0.0610533\n",
      "Validation loss decreased (0.054483 --> 0.054245).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0562548\n",
      "\tspeed: 0.0634s/iter; left time: 1228.8678s\n",
      "\titers: 200, epoch: 14 | loss: 0.0558280\n",
      "\tspeed: 0.0339s/iter; left time: 654.3415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0534659 Vali Loss: 0.0541800 Test Loss: 0.0609532\n",
      "Validation loss decreased (0.054245 --> 0.054180).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0524575\n",
      "\tspeed: 0.0637s/iter; left time: 1221.5597s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552186\n",
      "\tspeed: 0.0342s/iter; left time: 651.7205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0533038 Vali Loss: 0.0540752 Test Loss: 0.0606174\n",
      "Validation loss decreased (0.054180 --> 0.054075).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0530639\n",
      "\tspeed: 0.0639s/iter; left time: 1210.1429s\n",
      "\titers: 200, epoch: 16 | loss: 0.0518307\n",
      "\tspeed: 0.0340s/iter; left time: 639.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0531068 Vali Loss: 0.0539237 Test Loss: 0.0606197\n",
      "Validation loss decreased (0.054075 --> 0.053924).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0549129\n",
      "\tspeed: 0.0640s/iter; left time: 1198.4220s\n",
      "\titers: 200, epoch: 17 | loss: 0.0486911\n",
      "\tspeed: 0.0339s/iter; left time: 630.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0529943 Vali Loss: 0.0538352 Test Loss: 0.0604584\n",
      "Validation loss decreased (0.053924 --> 0.053835).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0533815\n",
      "\tspeed: 0.0632s/iter; left time: 1168.3594s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563068\n",
      "\tspeed: 0.0339s/iter; left time: 624.3753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0528632 Vali Loss: 0.0536740 Test Loss: 0.0603638\n",
      "Validation loss decreased (0.053835 --> 0.053674).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0529857\n",
      "\tspeed: 0.0641s/iter; left time: 1171.2782s\n",
      "\titers: 200, epoch: 19 | loss: 0.0518051\n",
      "\tspeed: 0.0361s/iter; left time: 655.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 224 | Train Loss: 0.0526865 Vali Loss: 0.0534223 Test Loss: 0.0601238\n",
      "Validation loss decreased (0.053674 --> 0.053422).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0509609\n",
      "\tspeed: 0.0648s/iter; left time: 1169.1304s\n",
      "\titers: 200, epoch: 20 | loss: 0.0505578\n",
      "\tspeed: 0.0342s/iter; left time: 613.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0526346 Vali Loss: 0.0535342 Test Loss: 0.0601085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0515755\n",
      "\tspeed: 0.0631s/iter; left time: 1125.0728s\n",
      "\titers: 200, epoch: 21 | loss: 0.0507104\n",
      "\tspeed: 0.0336s/iter; left time: 595.6313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0525259 Vali Loss: 0.0534651 Test Loss: 0.0600710\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0511437\n",
      "\tspeed: 0.0626s/iter; left time: 1102.4177s\n",
      "\titers: 200, epoch: 22 | loss: 0.0498561\n",
      "\tspeed: 0.0337s/iter; left time: 588.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0524205 Vali Loss: 0.0534762 Test Loss: 0.0601843\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0535026\n",
      "\tspeed: 0.0636s/iter; left time: 1104.5741s\n",
      "\titers: 200, epoch: 23 | loss: 0.0500406\n",
      "\tspeed: 0.0343s/iter; left time: 592.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0523597 Vali Loss: 0.0534131 Test Loss: 0.0600998\n",
      "Validation loss decreased (0.053422 --> 0.053413).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0492497\n",
      "\tspeed: 0.0639s/iter; left time: 1096.5966s\n",
      "\titers: 200, epoch: 24 | loss: 0.0506229\n",
      "\tspeed: 0.0339s/iter; left time: 578.1455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0522823 Vali Loss: 0.0532963 Test Loss: 0.0599198\n",
      "Validation loss decreased (0.053413 --> 0.053296).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0521318\n",
      "\tspeed: 0.0655s/iter; left time: 1108.0073s\n",
      "\titers: 200, epoch: 25 | loss: 0.0511510\n",
      "\tspeed: 0.0344s/iter; left time: 578.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0522033 Vali Loss: 0.0533299 Test Loss: 0.0599659\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0504086\n",
      "\tspeed: 0.0631s/iter; left time: 1053.2769s\n",
      "\titers: 200, epoch: 26 | loss: 0.0505698\n",
      "\tspeed: 0.0338s/iter; left time: 560.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0521587 Vali Loss: 0.0533623 Test Loss: 0.0599633\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0529970\n",
      "\tspeed: 0.0633s/iter; left time: 1042.1823s\n",
      "\titers: 200, epoch: 27 | loss: 0.0493081\n",
      "\tspeed: 0.0339s/iter; left time: 555.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0521429 Vali Loss: 0.0534271 Test Loss: 0.0600620\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0561010\n",
      "\tspeed: 0.0628s/iter; left time: 1019.8882s\n",
      "\titers: 200, epoch: 28 | loss: 0.0526673\n",
      "\tspeed: 0.0338s/iter; left time: 546.3516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0520879 Vali Loss: 0.0532309 Test Loss: 0.0596975\n",
      "Validation loss decreased (0.053296 --> 0.053231).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0538653\n",
      "\tspeed: 0.0641s/iter; left time: 1027.4060s\n",
      "\titers: 200, epoch: 29 | loss: 0.0507462\n",
      "\tspeed: 0.0343s/iter; left time: 546.1889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0520182 Vali Loss: 0.0532914 Test Loss: 0.0598624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0564779\n",
      "\tspeed: 0.0626s/iter; left time: 989.2602s\n",
      "\titers: 200, epoch: 30 | loss: 0.0513206\n",
      "\tspeed: 0.0338s/iter; left time: 531.3166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0519411 Vali Loss: 0.0531523 Test Loss: 0.0597022\n",
      "Validation loss decreased (0.053231 --> 0.053152).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0504823\n",
      "\tspeed: 0.0635s/iter; left time: 989.2336s\n",
      "\titers: 200, epoch: 31 | loss: 0.0540285\n",
      "\tspeed: 0.0338s/iter; left time: 522.4879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0519207 Vali Loss: 0.0531699 Test Loss: 0.0596743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0498894\n",
      "\tspeed: 0.0639s/iter; left time: 981.5846s\n",
      "\titers: 200, epoch: 32 | loss: 0.0540251\n",
      "\tspeed: 0.0350s/iter; left time: 534.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0519015 Vali Loss: 0.0531963 Test Loss: 0.0597262\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0543305\n",
      "\tspeed: 0.0640s/iter; left time: 969.1034s\n",
      "\titers: 200, epoch: 33 | loss: 0.0495824\n",
      "\tspeed: 0.0344s/iter; left time: 517.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0518915 Vali Loss: 0.0531901 Test Loss: 0.0596950\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0508410\n",
      "\tspeed: 0.0630s/iter; left time: 939.0433s\n",
      "\titers: 200, epoch: 34 | loss: 0.0491989\n",
      "\tspeed: 0.0337s/iter; left time: 498.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0518669 Vali Loss: 0.0531966 Test Loss: 0.0597255\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0490082\n",
      "\tspeed: 0.0639s/iter; left time: 939.1057s\n",
      "\titers: 200, epoch: 35 | loss: 0.0526008\n",
      "\tspeed: 0.0341s/iter; left time: 497.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0518020 Vali Loss: 0.0531861 Test Loss: 0.0596925\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0554945\n",
      "\tspeed: 0.0623s/iter; left time: 901.4166s\n",
      "\titers: 200, epoch: 36 | loss: 0.0519463\n",
      "\tspeed: 0.0338s/iter; left time: 485.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0518643 Vali Loss: 0.0531078 Test Loss: 0.0596932\n",
      "Validation loss decreased (0.053152 --> 0.053108).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0496504\n",
      "\tspeed: 0.0652s/iter; left time: 928.4305s\n",
      "\titers: 200, epoch: 37 | loss: 0.0498719\n",
      "\tspeed: 0.0340s/iter; left time: 480.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0518462 Vali Loss: 0.0531845 Test Loss: 0.0596469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0510170\n",
      "\tspeed: 0.0629s/iter; left time: 880.7925s\n",
      "\titers: 200, epoch: 38 | loss: 0.0542504\n",
      "\tspeed: 0.0338s/iter; left time: 470.3769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0518217 Vali Loss: 0.0531203 Test Loss: 0.0596973\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0488454\n",
      "\tspeed: 0.0628s/iter; left time: 865.2811s\n",
      "\titers: 200, epoch: 39 | loss: 0.0506440\n",
      "\tspeed: 0.0340s/iter; left time: 465.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0517673 Vali Loss: 0.0530957 Test Loss: 0.0596440\n",
      "Validation loss decreased (0.053108 --> 0.053096).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0500557\n",
      "\tspeed: 0.0645s/iter; left time: 874.3162s\n",
      "\titers: 200, epoch: 40 | loss: 0.0513093\n",
      "\tspeed: 0.0343s/iter; left time: 461.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0517291 Vali Loss: 0.0530914 Test Loss: 0.0595172\n",
      "Validation loss decreased (0.053096 --> 0.053091).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0547261\n",
      "\tspeed: 0.0645s/iter; left time: 859.9562s\n",
      "\titers: 200, epoch: 41 | loss: 0.0481549\n",
      "\tspeed: 0.0336s/iter; left time: 445.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0517457 Vali Loss: 0.0530916 Test Loss: 0.0596419\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0524280\n",
      "\tspeed: 0.0636s/iter; left time: 834.1583s\n",
      "\titers: 200, epoch: 42 | loss: 0.0527511\n",
      "\tspeed: 0.0340s/iter; left time: 442.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0517541 Vali Loss: 0.0532012 Test Loss: 0.0597727\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0527208\n",
      "\tspeed: 0.0632s/iter; left time: 815.1594s\n",
      "\titers: 200, epoch: 43 | loss: 0.0518980\n",
      "\tspeed: 0.0339s/iter; left time: 433.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0517267 Vali Loss: 0.0529711 Test Loss: 0.0595133\n",
      "Validation loss decreased (0.053091 --> 0.052971).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0536714\n",
      "\tspeed: 0.0631s/iter; left time: 798.7845s\n",
      "\titers: 200, epoch: 44 | loss: 0.0551635\n",
      "\tspeed: 0.0339s/iter; left time: 425.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0517666 Vali Loss: 0.0530981 Test Loss: 0.0596632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0518254\n",
      "\tspeed: 0.0627s/iter; left time: 780.7698s\n",
      "\titers: 200, epoch: 45 | loss: 0.0512678\n",
      "\tspeed: 0.0338s/iter; left time: 417.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0516751 Vali Loss: 0.0531732 Test Loss: 0.0596597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0521856\n",
      "\tspeed: 0.0633s/iter; left time: 773.5642s\n",
      "\titers: 200, epoch: 46 | loss: 0.0487361\n",
      "\tspeed: 0.0343s/iter; left time: 415.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0516208 Vali Loss: 0.0530561 Test Loss: 0.0595802\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0530450\n",
      "\tspeed: 0.0633s/iter; left time: 759.7925s\n",
      "\titers: 200, epoch: 47 | loss: 0.0445639\n",
      "\tspeed: 0.0342s/iter; left time: 406.7416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0516959 Vali Loss: 0.0531059 Test Loss: 0.0596224\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0539990\n",
      "\tspeed: 0.0626s/iter; left time: 737.1421s\n",
      "\titers: 200, epoch: 48 | loss: 0.0513229\n",
      "\tspeed: 0.0338s/iter; left time: 394.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0516967 Vali Loss: 0.0530909 Test Loss: 0.0596255\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0525027\n",
      "\tspeed: 0.0627s/iter; left time: 724.6279s\n",
      "\titers: 200, epoch: 49 | loss: 0.0530085\n",
      "\tspeed: 0.0339s/iter; left time: 387.6731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0516743 Vali Loss: 0.0531389 Test Loss: 0.0596946\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0477419\n",
      "\tspeed: 0.0629s/iter; left time: 712.5456s\n",
      "\titers: 200, epoch: 50 | loss: 0.0513889\n",
      "\tspeed: 0.0344s/iter; left time: 386.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0516918 Vali Loss: 0.0530067 Test Loss: 0.0595521\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0530295\n",
      "\tspeed: 0.0628s/iter; left time: 697.4549s\n",
      "\titers: 200, epoch: 51 | loss: 0.0510417\n",
      "\tspeed: 0.0348s/iter; left time: 383.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0516617 Vali Loss: 0.0531040 Test Loss: 0.0595510\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0517732\n",
      "\tspeed: 0.0634s/iter; left time: 689.7686s\n",
      "\titers: 200, epoch: 52 | loss: 0.0523332\n",
      "\tspeed: 0.0343s/iter; left time: 369.3020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0517148 Vali Loss: 0.0530957 Test Loss: 0.0596316\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0531154\n",
      "\tspeed: 0.0635s/iter; left time: 676.7211s\n",
      "\titers: 200, epoch: 53 | loss: 0.0505686\n",
      "\tspeed: 0.0338s/iter; left time: 356.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0516867 Vali Loss: 0.0530429 Test Loss: 0.0595754\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00980827771127224, rmse:0.09903674572706223, mae:0.059513285756111145, rse:0.29145318269729614\n",
      "Intermediate time for ES and pred_len 24: 00h:16m:07.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1583152\n",
      "\tspeed: 0.0612s/iter; left time: 1364.4116s\n",
      "\titers: 200, epoch: 1 | loss: 0.1448403\n",
      "\tspeed: 0.0347s/iter; left time: 769.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 224 | Train Loss: 0.1628648 Vali Loss: 0.1497765 Test Loss: 0.1801975\n",
      "Validation loss decreased (inf --> 0.149776).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0921436\n",
      "\tspeed: 0.0656s/iter; left time: 1448.2323s\n",
      "\titers: 200, epoch: 2 | loss: 0.0816166\n",
      "\tspeed: 0.0347s/iter; left time: 763.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0972727 Vali Loss: 0.0838135 Test Loss: 0.0948474\n",
      "Validation loss decreased (0.149776 --> 0.083813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829061\n",
      "\tspeed: 0.0658s/iter; left time: 1437.4137s\n",
      "\titers: 200, epoch: 3 | loss: 0.0841351\n",
      "\tspeed: 0.0345s/iter; left time: 751.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0835706 Vali Loss: 0.0805995 Test Loss: 0.0918064\n",
      "Validation loss decreased (0.083813 --> 0.080599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807449\n",
      "\tspeed: 0.0665s/iter; left time: 1437.7731s\n",
      "\titers: 200, epoch: 4 | loss: 0.0770914\n",
      "\tspeed: 0.0350s/iter; left time: 753.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0804804 Vali Loss: 0.0785825 Test Loss: 0.0897993\n",
      "Validation loss decreased (0.080599 --> 0.078583).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813333\n",
      "\tspeed: 0.0674s/iter; left time: 1442.3017s\n",
      "\titers: 200, epoch: 5 | loss: 0.0801107\n",
      "\tspeed: 0.0342s/iter; left time: 728.3903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0785711 Vali Loss: 0.0776296 Test Loss: 0.0890472\n",
      "Validation loss decreased (0.078583 --> 0.077630).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0758659\n",
      "\tspeed: 0.0673s/iter; left time: 1424.6065s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811755\n",
      "\tspeed: 0.0345s/iter; left time: 727.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0773020 Vali Loss: 0.0770908 Test Loss: 0.0882573\n",
      "Validation loss decreased (0.077630 --> 0.077091).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0749255\n",
      "\tspeed: 0.0656s/iter; left time: 1374.6973s\n",
      "\titers: 200, epoch: 7 | loss: 0.0767308\n",
      "\tspeed: 0.0344s/iter; left time: 717.8206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0764460 Vali Loss: 0.0769096 Test Loss: 0.0878721\n",
      "Validation loss decreased (0.077091 --> 0.076910).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0756682\n",
      "\tspeed: 0.0659s/iter; left time: 1366.1915s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762002\n",
      "\tspeed: 0.0346s/iter; left time: 714.9174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0758666 Vali Loss: 0.0765788 Test Loss: 0.0876366\n",
      "Validation loss decreased (0.076910 --> 0.076579).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0734542\n",
      "\tspeed: 0.0664s/iter; left time: 1362.4641s\n",
      "\titers: 200, epoch: 9 | loss: 0.0735278\n",
      "\tspeed: 0.0343s/iter; left time: 700.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0753596 Vali Loss: 0.0765925 Test Loss: 0.0876100\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0753230\n",
      "\tspeed: 0.0648s/iter; left time: 1315.0359s\n",
      "\titers: 200, epoch: 10 | loss: 0.0781913\n",
      "\tspeed: 0.0352s/iter; left time: 710.0928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0748802 Vali Loss: 0.0762593 Test Loss: 0.0871955\n",
      "Validation loss decreased (0.076579 --> 0.076259).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0749062\n",
      "\tspeed: 0.0663s/iter; left time: 1329.3207s\n",
      "\titers: 200, epoch: 11 | loss: 0.0777845\n",
      "\tspeed: 0.0346s/iter; left time: 689.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0745766 Vali Loss: 0.0759519 Test Loss: 0.0867373\n",
      "Validation loss decreased (0.076259 --> 0.075952).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0746499\n",
      "\tspeed: 0.0654s/iter; left time: 1297.0991s\n",
      "\titers: 200, epoch: 12 | loss: 0.0707181\n",
      "\tspeed: 0.0344s/iter; left time: 679.4859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0741716 Vali Loss: 0.0759469 Test Loss: 0.0867018\n",
      "Validation loss decreased (0.075952 --> 0.075947).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0738060\n",
      "\tspeed: 0.0657s/iter; left time: 1288.3863s\n",
      "\titers: 200, epoch: 13 | loss: 0.0733494\n",
      "\tspeed: 0.0344s/iter; left time: 672.1512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0739369 Vali Loss: 0.0760515 Test Loss: 0.0871067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0706884\n",
      "\tspeed: 0.0645s/iter; left time: 1249.8551s\n",
      "\titers: 200, epoch: 14 | loss: 0.0737723\n",
      "\tspeed: 0.0347s/iter; left time: 668.5379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0736894 Vali Loss: 0.0760189 Test Loss: 0.0869981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755268\n",
      "\tspeed: 0.0648s/iter; left time: 1241.5654s\n",
      "\titers: 200, epoch: 15 | loss: 0.0732484\n",
      "\tspeed: 0.0344s/iter; left time: 656.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0733935 Vali Loss: 0.0757354 Test Loss: 0.0867739\n",
      "Validation loss decreased (0.075947 --> 0.075735).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715213\n",
      "\tspeed: 0.0668s/iter; left time: 1265.6637s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740862\n",
      "\tspeed: 0.0351s/iter; left time: 660.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0732062 Vali Loss: 0.0755924 Test Loss: 0.0867386\n",
      "Validation loss decreased (0.075735 --> 0.075592).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0706640\n",
      "\tspeed: 0.0664s/iter; left time: 1242.7653s\n",
      "\titers: 200, epoch: 17 | loss: 0.0721274\n",
      "\tspeed: 0.0349s/iter; left time: 648.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0730183 Vali Loss: 0.0758885 Test Loss: 0.0868945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0740165\n",
      "\tspeed: 0.0648s/iter; left time: 1199.0903s\n",
      "\titers: 200, epoch: 18 | loss: 0.0715243\n",
      "\tspeed: 0.0344s/iter; left time: 633.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0728788 Vali Loss: 0.0759454 Test Loss: 0.0867216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0722490\n",
      "\tspeed: 0.0652s/iter; left time: 1191.9980s\n",
      "\titers: 200, epoch: 19 | loss: 0.0700200\n",
      "\tspeed: 0.0364s/iter; left time: 661.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 224 | Train Loss: 0.0728002 Vali Loss: 0.0754850 Test Loss: 0.0865807\n",
      "Validation loss decreased (0.075592 --> 0.075485).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0729250\n",
      "\tspeed: 0.0663s/iter; left time: 1196.3559s\n",
      "\titers: 200, epoch: 20 | loss: 0.0730267\n",
      "\tspeed: 0.0345s/iter; left time: 619.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0726108 Vali Loss: 0.0756786 Test Loss: 0.0865085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0720294\n",
      "\tspeed: 0.0651s/iter; left time: 1160.8490s\n",
      "\titers: 200, epoch: 21 | loss: 0.0724624\n",
      "\tspeed: 0.0344s/iter; left time: 610.3188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0724719 Vali Loss: 0.0756035 Test Loss: 0.0865330\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0717145\n",
      "\tspeed: 0.0653s/iter; left time: 1149.9067s\n",
      "\titers: 200, epoch: 22 | loss: 0.0705282\n",
      "\tspeed: 0.0351s/iter; left time: 614.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0723564 Vali Loss: 0.0755396 Test Loss: 0.0866191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0681314\n",
      "\tspeed: 0.0642s/iter; left time: 1115.5540s\n",
      "\titers: 200, epoch: 23 | loss: 0.0691133\n",
      "\tspeed: 0.0344s/iter; left time: 595.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0722308 Vali Loss: 0.0756375 Test Loss: 0.0867327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0723156\n",
      "\tspeed: 0.0658s/iter; left time: 1127.7112s\n",
      "\titers: 200, epoch: 24 | loss: 0.0737724\n",
      "\tspeed: 0.0348s/iter; left time: 592.6772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0722322 Vali Loss: 0.0753499 Test Loss: 0.0864964\n",
      "Validation loss decreased (0.075485 --> 0.075350).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0734103\n",
      "\tspeed: 0.0667s/iter; left time: 1128.6299s\n",
      "\titers: 200, epoch: 25 | loss: 0.0698764\n",
      "\tspeed: 0.0343s/iter; left time: 577.0296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0721284 Vali Loss: 0.0755213 Test Loss: 0.0866127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0749125\n",
      "\tspeed: 0.0646s/iter; left time: 1079.6370s\n",
      "\titers: 200, epoch: 26 | loss: 0.0681941\n",
      "\tspeed: 0.0342s/iter; left time: 568.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0720451 Vali Loss: 0.0755095 Test Loss: 0.0866491\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0748759\n",
      "\tspeed: 0.0645s/iter; left time: 1063.2388s\n",
      "\titers: 200, epoch: 27 | loss: 0.0692100\n",
      "\tspeed: 0.0343s/iter; left time: 561.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0719510 Vali Loss: 0.0755535 Test Loss: 0.0866617\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0701714\n",
      "\tspeed: 0.0656s/iter; left time: 1066.7963s\n",
      "\titers: 200, epoch: 28 | loss: 0.0740284\n",
      "\tspeed: 0.0366s/iter; left time: 590.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0718891 Vali Loss: 0.0755887 Test Loss: 0.0867537\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0725884\n",
      "\tspeed: 0.0676s/iter; left time: 1083.1938s\n",
      "\titers: 200, epoch: 29 | loss: 0.0677367\n",
      "\tspeed: 0.0343s/iter; left time: 546.9958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 224 | Train Loss: 0.0718561 Vali Loss: 0.0753443 Test Loss: 0.0863624\n",
      "Validation loss decreased (0.075350 --> 0.075344).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0719654\n",
      "\tspeed: 0.0654s/iter; left time: 1033.4551s\n",
      "\titers: 200, epoch: 30 | loss: 0.0742018\n",
      "\tspeed: 0.0342s/iter; left time: 537.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0718349 Vali Loss: 0.0753530 Test Loss: 0.0864401\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0718995\n",
      "\tspeed: 0.0646s/iter; left time: 1006.3866s\n",
      "\titers: 200, epoch: 31 | loss: 0.0726714\n",
      "\tspeed: 0.0341s/iter; left time: 528.4695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0716989 Vali Loss: 0.0755160 Test Loss: 0.0866547\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725034\n",
      "\tspeed: 0.0645s/iter; left time: 991.1844s\n",
      "\titers: 200, epoch: 32 | loss: 0.0703748\n",
      "\tspeed: 0.0347s/iter; left time: 528.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0716934 Vali Loss: 0.0754083 Test Loss: 0.0864467\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0715083\n",
      "\tspeed: 0.0648s/iter; left time: 980.6246s\n",
      "\titers: 200, epoch: 33 | loss: 0.0704834\n",
      "\tspeed: 0.0344s/iter; left time: 517.0409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0716789 Vali Loss: 0.0755103 Test Loss: 0.0866822\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697350\n",
      "\tspeed: 0.0651s/iter; left time: 970.2827s\n",
      "\titers: 200, epoch: 34 | loss: 0.0721267\n",
      "\tspeed: 0.0348s/iter; left time: 515.9512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0716551 Vali Loss: 0.0756040 Test Loss: 0.0869137\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0750437\n",
      "\tspeed: 0.0646s/iter; left time: 948.6420s\n",
      "\titers: 200, epoch: 35 | loss: 0.0722882\n",
      "\tspeed: 0.0343s/iter; left time: 499.5850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0716405 Vali Loss: 0.0754976 Test Loss: 0.0866905\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0708376\n",
      "\tspeed: 0.0649s/iter; left time: 938.6410s\n",
      "\titers: 200, epoch: 36 | loss: 0.0717003\n",
      "\tspeed: 0.0345s/iter; left time: 495.1747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0715762 Vali Loss: 0.0754502 Test Loss: 0.0866363\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0710196\n",
      "\tspeed: 0.0645s/iter; left time: 917.8728s\n",
      "\titers: 200, epoch: 37 | loss: 0.0715786\n",
      "\tspeed: 0.0344s/iter; left time: 485.6077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0715935 Vali Loss: 0.0754666 Test Loss: 0.0865808\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0731768\n",
      "\tspeed: 0.0647s/iter; left time: 906.7087s\n",
      "\titers: 200, epoch: 38 | loss: 0.0697412\n",
      "\tspeed: 0.0345s/iter; left time: 480.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0715302 Vali Loss: 0.0754760 Test Loss: 0.0866731\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0720512\n",
      "\tspeed: 0.0647s/iter; left time: 892.7129s\n",
      "\titers: 200, epoch: 39 | loss: 0.0706587\n",
      "\tspeed: 0.0344s/iter; left time: 470.9681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0715180 Vali Loss: 0.0755162 Test Loss: 0.0867972\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0185981597751379, rmse:0.1363750696182251, mae:0.08636235445737839, rse:0.4006288945674896\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1582830\n",
      "\tspeed: 0.0364s/iter; left time: 811.6288s\n",
      "\titers: 200, epoch: 1 | loss: 0.1536793\n",
      "\tspeed: 0.0350s/iter; left time: 776.4891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1618317 Vali Loss: 0.1495777 Test Loss: 0.1801662\n",
      "Validation loss decreased (inf --> 0.149578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0939178\n",
      "\tspeed: 0.0683s/iter; left time: 1507.8242s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864733\n",
      "\tspeed: 0.0345s/iter; left time: 758.7742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0985453 Vali Loss: 0.0839609 Test Loss: 0.0956050\n",
      "Validation loss decreased (0.149578 --> 0.083961).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878430\n",
      "\tspeed: 0.0662s/iter; left time: 1446.6138s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782254\n",
      "\tspeed: 0.0345s/iter; left time: 751.0563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0840291 Vali Loss: 0.0807863 Test Loss: 0.0920472\n",
      "Validation loss decreased (0.083961 --> 0.080786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836028\n",
      "\tspeed: 0.0658s/iter; left time: 1423.3504s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806706\n",
      "\tspeed: 0.0342s/iter; left time: 737.0876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0807939 Vali Loss: 0.0788258 Test Loss: 0.0900378\n",
      "Validation loss decreased (0.080786 --> 0.078826).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788435\n",
      "\tspeed: 0.0655s/iter; left time: 1401.4825s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807367\n",
      "\tspeed: 0.0340s/iter; left time: 723.4673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0788217 Vali Loss: 0.0780139 Test Loss: 0.0892532\n",
      "Validation loss decreased (0.078826 --> 0.078014).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0773067\n",
      "\tspeed: 0.0669s/iter; left time: 1415.9893s\n",
      "\titers: 200, epoch: 6 | loss: 0.0772312\n",
      "\tspeed: 0.0345s/iter; left time: 726.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0775746 Vali Loss: 0.0777914 Test Loss: 0.0886277\n",
      "Validation loss decreased (0.078014 --> 0.077791).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0767768\n",
      "\tspeed: 0.0664s/iter; left time: 1390.6157s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746151\n",
      "\tspeed: 0.0342s/iter; left time: 713.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0767128 Vali Loss: 0.0770210 Test Loss: 0.0880919\n",
      "Validation loss decreased (0.077791 --> 0.077021).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772053\n",
      "\tspeed: 0.0665s/iter; left time: 1377.8853s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728543\n",
      "\tspeed: 0.0343s/iter; left time: 707.0327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0759991 Vali Loss: 0.0769128 Test Loss: 0.0879381\n",
      "Validation loss decreased (0.077021 --> 0.076913).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0746797\n",
      "\tspeed: 0.0663s/iter; left time: 1359.5577s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793813\n",
      "\tspeed: 0.0342s/iter; left time: 698.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0754255 Vali Loss: 0.0765287 Test Loss: 0.0876836\n",
      "Validation loss decreased (0.076913 --> 0.076529).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0778281\n",
      "\tspeed: 0.0659s/iter; left time: 1336.2387s\n",
      "\titers: 200, epoch: 10 | loss: 0.0760081\n",
      "\tspeed: 0.0346s/iter; left time: 697.8025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0749424 Vali Loss: 0.0765791 Test Loss: 0.0876946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761849\n",
      "\tspeed: 0.0649s/iter; left time: 1301.6645s\n",
      "\titers: 200, epoch: 11 | loss: 0.0759281\n",
      "\tspeed: 0.0341s/iter; left time: 679.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0745479 Vali Loss: 0.0765141 Test Loss: 0.0871809\n",
      "Validation loss decreased (0.076529 --> 0.076514).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0740213\n",
      "\tspeed: 0.0658s/iter; left time: 1304.3973s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729842\n",
      "\tspeed: 0.0345s/iter; left time: 680.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0742243 Vali Loss: 0.0766330 Test Loss: 0.0873586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0739172\n",
      "\tspeed: 0.0656s/iter; left time: 1285.6386s\n",
      "\titers: 200, epoch: 13 | loss: 0.0755008\n",
      "\tspeed: 0.0347s/iter; left time: 677.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0739385 Vali Loss: 0.0763564 Test Loss: 0.0872647\n",
      "Validation loss decreased (0.076514 --> 0.076356).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0703849\n",
      "\tspeed: 0.0672s/iter; left time: 1303.7925s\n",
      "\titers: 200, epoch: 14 | loss: 0.0713772\n",
      "\tspeed: 0.0343s/iter; left time: 661.0950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0736357 Vali Loss: 0.0765072 Test Loss: 0.0869802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0685526\n",
      "\tspeed: 0.0641s/iter; left time: 1229.4245s\n",
      "\titers: 200, epoch: 15 | loss: 0.0744490\n",
      "\tspeed: 0.0343s/iter; left time: 654.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0733645 Vali Loss: 0.0765096 Test Loss: 0.0869906\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0745860\n",
      "\tspeed: 0.0650s/iter; left time: 1231.3518s\n",
      "\titers: 200, epoch: 16 | loss: 0.0714565\n",
      "\tspeed: 0.0344s/iter; left time: 647.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0731870 Vali Loss: 0.0763907 Test Loss: 0.0867740\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0767808\n",
      "\tspeed: 0.0648s/iter; left time: 1213.3498s\n",
      "\titers: 200, epoch: 17 | loss: 0.0734670\n",
      "\tspeed: 0.0340s/iter; left time: 632.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0729853 Vali Loss: 0.0765046 Test Loss: 0.0869768\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0747071\n",
      "\tspeed: 0.0656s/iter; left time: 1212.3278s\n",
      "\titers: 200, epoch: 18 | loss: 0.0728723\n",
      "\tspeed: 0.0343s/iter; left time: 631.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0727439 Vali Loss: 0.0765303 Test Loss: 0.0870398\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0708978\n",
      "\tspeed: 0.0658s/iter; left time: 1202.2714s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723809\n",
      "\tspeed: 0.0346s/iter; left time: 629.1745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0725793 Vali Loss: 0.0764471 Test Loss: 0.0870042\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0734421\n",
      "\tspeed: 0.0691s/iter; left time: 1246.2761s\n",
      "\titers: 200, epoch: 20 | loss: 0.0769663\n",
      "\tspeed: 0.0345s/iter; left time: 618.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 224 | Train Loss: 0.0725307 Vali Loss: 0.0765048 Test Loss: 0.0870345\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0716774\n",
      "\tspeed: 0.0658s/iter; left time: 1173.5035s\n",
      "\titers: 200, epoch: 21 | loss: 0.0718850\n",
      "\tspeed: 0.0345s/iter; left time: 612.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0723870 Vali Loss: 0.0766452 Test Loss: 0.0869602\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0720396\n",
      "\tspeed: 0.0649s/iter; left time: 1142.3563s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696126\n",
      "\tspeed: 0.0343s/iter; left time: 600.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0722414 Vali Loss: 0.0765089 Test Loss: 0.0867656\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0730018\n",
      "\tspeed: 0.0649s/iter; left time: 1127.8702s\n",
      "\titers: 200, epoch: 23 | loss: 0.0753521\n",
      "\tspeed: 0.0343s/iter; left time: 592.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0721670 Vali Loss: 0.0766542 Test Loss: 0.0870228\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018632538616657257, rmse:0.13650105893611908, mae:0.08726463466882706, rse:0.4009990394115448\n",
      "Intermediate time for ES and pred_len 96: 00h:10m:34.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1581242\n",
      "\tspeed: 0.0689s/iter; left time: 1528.7480s\n",
      "\titers: 200, epoch: 1 | loss: 0.1507171\n",
      "\tspeed: 0.0361s/iter; left time: 797.9049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 223 | Train Loss: 0.1638708 Vali Loss: 0.1523550 Test Loss: 0.1819388\n",
      "Validation loss decreased (inf --> 0.152355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986643\n",
      "\tspeed: 0.0680s/iter; left time: 1495.1640s\n",
      "\titers: 200, epoch: 2 | loss: 0.0934433\n",
      "\tspeed: 0.0354s/iter; left time: 773.8502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.1013446 Vali Loss: 0.0890421 Test Loss: 0.1011388\n",
      "Validation loss decreased (0.152355 --> 0.089042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0940395\n",
      "\tspeed: 0.0664s/iter; left time: 1444.6917s\n",
      "\titers: 200, epoch: 3 | loss: 0.0868575\n",
      "\tspeed: 0.0351s/iter; left time: 760.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0888059 Vali Loss: 0.0860402 Test Loss: 0.0980579\n",
      "Validation loss decreased (0.089042 --> 0.086040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0851304\n",
      "\tspeed: 0.0673s/iter; left time: 1448.8477s\n",
      "\titers: 200, epoch: 4 | loss: 0.0841597\n",
      "\tspeed: 0.0352s/iter; left time: 753.3763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0857711 Vali Loss: 0.0841981 Test Loss: 0.0959112\n",
      "Validation loss decreased (0.086040 --> 0.084198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0825492\n",
      "\tspeed: 0.0667s/iter; left time: 1422.2021s\n",
      "\titers: 200, epoch: 5 | loss: 0.0825241\n",
      "\tspeed: 0.0346s/iter; left time: 734.7796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0838901 Vali Loss: 0.0835975 Test Loss: 0.0951364\n",
      "Validation loss decreased (0.084198 --> 0.083597).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831312\n",
      "\tspeed: 0.0664s/iter; left time: 1399.8241s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821218\n",
      "\tspeed: 0.0349s/iter; left time: 731.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0827609 Vali Loss: 0.0835203 Test Loss: 0.0949269\n",
      "Validation loss decreased (0.083597 --> 0.083520).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0847962\n",
      "\tspeed: 0.0669s/iter; left time: 1395.8924s\n",
      "\titers: 200, epoch: 7 | loss: 0.0801695\n",
      "\tspeed: 0.0350s/iter; left time: 725.8276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0820128 Vali Loss: 0.0828906 Test Loss: 0.0942042\n",
      "Validation loss decreased (0.083520 --> 0.082891).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826582\n",
      "\tspeed: 0.0661s/iter; left time: 1364.9834s\n",
      "\titers: 200, epoch: 8 | loss: 0.0829372\n",
      "\tspeed: 0.0352s/iter; left time: 722.1369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0813807 Vali Loss: 0.0829064 Test Loss: 0.0940305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0785602\n",
      "\tspeed: 0.0651s/iter; left time: 1328.5128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0813846\n",
      "\tspeed: 0.0358s/iter; left time: 726.9449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0808702 Vali Loss: 0.0826419 Test Loss: 0.0939117\n",
      "Validation loss decreased (0.082891 --> 0.082642).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0784310\n",
      "\tspeed: 0.0666s/iter; left time: 1345.3745s\n",
      "\titers: 200, epoch: 10 | loss: 0.0772360\n",
      "\tspeed: 0.0347s/iter; left time: 696.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0803654 Vali Loss: 0.0824731 Test Loss: 0.0937046\n",
      "Validation loss decreased (0.082642 --> 0.082473).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0798821\n",
      "\tspeed: 0.0671s/iter; left time: 1340.7770s\n",
      "\titers: 200, epoch: 11 | loss: 0.0784780\n",
      "\tspeed: 0.0350s/iter; left time: 695.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0799386 Vali Loss: 0.0822538 Test Loss: 0.0935915\n",
      "Validation loss decreased (0.082473 --> 0.082254).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0809544\n",
      "\tspeed: 0.0677s/iter; left time: 1336.4860s\n",
      "\titers: 200, epoch: 12 | loss: 0.0804690\n",
      "\tspeed: 0.0349s/iter; left time: 685.9779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0795472 Vali Loss: 0.0822670 Test Loss: 0.0936214\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0796984\n",
      "\tspeed: 0.0661s/iter; left time: 1289.7716s\n",
      "\titers: 200, epoch: 13 | loss: 0.0766402\n",
      "\tspeed: 0.0346s/iter; left time: 671.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0792191 Vali Loss: 0.0818180 Test Loss: 0.0939182\n",
      "Validation loss decreased (0.082254 --> 0.081818).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0797491\n",
      "\tspeed: 0.0672s/iter; left time: 1296.1919s\n",
      "\titers: 200, epoch: 14 | loss: 0.0768970\n",
      "\tspeed: 0.0350s/iter; left time: 671.4356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0789267 Vali Loss: 0.0818768 Test Loss: 0.0939726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793521\n",
      "\tspeed: 0.0655s/iter; left time: 1250.5548s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760051\n",
      "\tspeed: 0.0346s/iter; left time: 657.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0786685 Vali Loss: 0.0820166 Test Loss: 0.0940066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786998\n",
      "\tspeed: 0.0658s/iter; left time: 1240.9156s\n",
      "\titers: 200, epoch: 16 | loss: 0.0790844\n",
      "\tspeed: 0.0347s/iter; left time: 651.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0784924 Vali Loss: 0.0818277 Test Loss: 0.0944564\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0776468\n",
      "\tspeed: 0.0665s/iter; left time: 1238.5488s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762781\n",
      "\tspeed: 0.0347s/iter; left time: 642.6656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0782404 Vali Loss: 0.0818648 Test Loss: 0.0947103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0797928\n",
      "\tspeed: 0.0657s/iter; left time: 1208.8282s\n",
      "\titers: 200, epoch: 18 | loss: 0.0767054\n",
      "\tspeed: 0.0349s/iter; left time: 638.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0780503 Vali Loss: 0.0820865 Test Loss: 0.0952556\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800530\n",
      "\tspeed: 0.0672s/iter; left time: 1222.8283s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773672\n",
      "\tspeed: 0.0348s/iter; left time: 629.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0779013 Vali Loss: 0.0819001 Test Loss: 0.0952660\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764023\n",
      "\tspeed: 0.0654s/iter; left time: 1175.2099s\n",
      "\titers: 200, epoch: 20 | loss: 0.0789287\n",
      "\tspeed: 0.0346s/iter; left time: 618.5432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0777259 Vali Loss: 0.0817606 Test Loss: 0.0951863\n",
      "Validation loss decreased (0.081818 --> 0.081761).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766384\n",
      "\tspeed: 0.0676s/iter; left time: 1199.6317s\n",
      "\titers: 200, epoch: 21 | loss: 0.0782197\n",
      "\tspeed: 0.0358s/iter; left time: 630.8749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 223 | Train Loss: 0.0775856 Vali Loss: 0.0819180 Test Loss: 0.0953271\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756970\n",
      "\tspeed: 0.0652s/iter; left time: 1142.9382s\n",
      "\titers: 200, epoch: 22 | loss: 0.0782074\n",
      "\tspeed: 0.0346s/iter; left time: 603.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0774701 Vali Loss: 0.0816166 Test Loss: 0.0955943\n",
      "Validation loss decreased (0.081761 --> 0.081617).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767044\n",
      "\tspeed: 0.0682s/iter; left time: 1179.0716s\n",
      "\titers: 200, epoch: 23 | loss: 0.0780989\n",
      "\tspeed: 0.0353s/iter; left time: 607.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0773348 Vali Loss: 0.0818224 Test Loss: 0.0957033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0800862\n",
      "\tspeed: 0.0649s/iter; left time: 1107.8149s\n",
      "\titers: 200, epoch: 24 | loss: 0.0712628\n",
      "\tspeed: 0.0354s/iter; left time: 600.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 223 | Train Loss: 0.0772094 Vali Loss: 0.0816642 Test Loss: 0.0957151\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0788048\n",
      "\tspeed: 0.0697s/iter; left time: 1174.6549s\n",
      "\titers: 200, epoch: 25 | loss: 0.0728152\n",
      "\tspeed: 0.0392s/iter; left time: 656.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.82s\n",
      "Steps: 223 | Train Loss: 0.0771515 Vali Loss: 0.0817642 Test Loss: 0.0957897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0781624\n",
      "\tspeed: 0.0662s/iter; left time: 1101.1165s\n",
      "\titers: 200, epoch: 26 | loss: 0.0739947\n",
      "\tspeed: 0.0346s/iter; left time: 571.0519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0770992 Vali Loss: 0.0816698 Test Loss: 0.0958092\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0785158\n",
      "\tspeed: 0.0653s/iter; left time: 1070.8971s\n",
      "\titers: 200, epoch: 27 | loss: 0.0776058\n",
      "\tspeed: 0.0345s/iter; left time: 562.8449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0770031 Vali Loss: 0.0817289 Test Loss: 0.0957823\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762650\n",
      "\tspeed: 0.0649s/iter; left time: 1049.7568s\n",
      "\titers: 200, epoch: 28 | loss: 0.0730262\n",
      "\tspeed: 0.0349s/iter; left time: 560.7453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0769375 Vali Loss: 0.0817190 Test Loss: 0.0960716\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0779013\n",
      "\tspeed: 0.0660s/iter; left time: 1053.8148s\n",
      "\titers: 200, epoch: 29 | loss: 0.0780241\n",
      "\tspeed: 0.0346s/iter; left time: 548.5717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0768650 Vali Loss: 0.0818699 Test Loss: 0.0961976\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0775625\n",
      "\tspeed: 0.0662s/iter; left time: 1042.0484s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751118\n",
      "\tspeed: 0.0356s/iter; left time: 556.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 223 | Train Loss: 0.0768085 Vali Loss: 0.0818688 Test Loss: 0.0963391\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0737045\n",
      "\tspeed: 0.0660s/iter; left time: 1023.8356s\n",
      "\titers: 200, epoch: 31 | loss: 0.0770995\n",
      "\tspeed: 0.0350s/iter; left time: 539.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0767635 Vali Loss: 0.0816762 Test Loss: 0.0960850\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0781929\n",
      "\tspeed: 0.0657s/iter; left time: 1004.8351s\n",
      "\titers: 200, epoch: 32 | loss: 0.0797998\n",
      "\tspeed: 0.0346s/iter; left time: 525.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0767546 Vali Loss: 0.0817475 Test Loss: 0.0963959\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02126566879451275, rmse:0.1458275318145752, mae:0.0955943912267685, rse:0.42842817306518555\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1622073\n",
      "\tspeed: 0.0371s/iter; left time: 824.2287s\n",
      "\titers: 200, epoch: 1 | loss: 0.1511776\n",
      "\tspeed: 0.0348s/iter; left time: 770.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1635544 Vali Loss: 0.1513875 Test Loss: 0.1804619\n",
      "Validation loss decreased (inf --> 0.151388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0963681\n",
      "\tspeed: 0.0682s/iter; left time: 1497.9875s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897276\n",
      "\tspeed: 0.0349s/iter; left time: 764.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.1009506 Vali Loss: 0.0887425 Test Loss: 0.1008672\n",
      "Validation loss decreased (0.151388 --> 0.088743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0909871\n",
      "\tspeed: 0.0707s/iter; left time: 1537.4113s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840339\n",
      "\tspeed: 0.0377s/iter; left time: 815.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 223 | Train Loss: 0.0886917 Vali Loss: 0.0861339 Test Loss: 0.0982522\n",
      "Validation loss decreased (0.088743 --> 0.086134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863238\n",
      "\tspeed: 0.0692s/iter; left time: 1489.5158s\n",
      "\titers: 200, epoch: 4 | loss: 0.0863077\n",
      "\tspeed: 0.0350s/iter; left time: 749.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0857665 Vali Loss: 0.0844378 Test Loss: 0.0962862\n",
      "Validation loss decreased (0.086134 --> 0.084438).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0852887\n",
      "\tspeed: 0.0684s/iter; left time: 1457.8487s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826804\n",
      "\tspeed: 0.0353s/iter; left time: 747.9916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 223 | Train Loss: 0.0839180 Vali Loss: 0.0839240 Test Loss: 0.0957661\n",
      "Validation loss decreased (0.084438 --> 0.083924).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0836342\n",
      "\tspeed: 0.0703s/iter; left time: 1482.6421s\n",
      "\titers: 200, epoch: 6 | loss: 0.0806390\n",
      "\tspeed: 0.0373s/iter; left time: 783.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 223 | Train Loss: 0.0828160 Vali Loss: 0.0837571 Test Loss: 0.0950037\n",
      "Validation loss decreased (0.083924 --> 0.083757).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0857420\n",
      "\tspeed: 0.0682s/iter; left time: 1423.2851s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848666\n",
      "\tspeed: 0.0350s/iter; left time: 727.4349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0820557 Vali Loss: 0.0831144 Test Loss: 0.0942615\n",
      "Validation loss decreased (0.083757 --> 0.083114).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834368\n",
      "\tspeed: 0.0696s/iter; left time: 1435.6608s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797058\n",
      "\tspeed: 0.0350s/iter; left time: 719.8850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 223 | Train Loss: 0.0814393 Vali Loss: 0.0832333 Test Loss: 0.0942153\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792525\n",
      "\tspeed: 0.0665s/iter; left time: 1357.0644s\n",
      "\titers: 200, epoch: 9 | loss: 0.0831456\n",
      "\tspeed: 0.0354s/iter; left time: 718.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0809265 Vali Loss: 0.0834103 Test Loss: 0.0940458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0839281\n",
      "\tspeed: 0.0671s/iter; left time: 1355.8758s\n",
      "\titers: 200, epoch: 10 | loss: 0.0820906\n",
      "\tspeed: 0.0354s/iter; left time: 711.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0804400 Vali Loss: 0.0831343 Test Loss: 0.0936590\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0800651\n",
      "\tspeed: 0.0672s/iter; left time: 1342.3950s\n",
      "\titers: 200, epoch: 11 | loss: 0.0795596\n",
      "\tspeed: 0.0351s/iter; left time: 696.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0799918 Vali Loss: 0.0829600 Test Loss: 0.0931671\n",
      "Validation loss decreased (0.083114 --> 0.082960).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0811823\n",
      "\tspeed: 0.0679s/iter; left time: 1341.1906s\n",
      "\titers: 200, epoch: 12 | loss: 0.0830218\n",
      "\tspeed: 0.0348s/iter; left time: 684.0976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0796409 Vali Loss: 0.0829638 Test Loss: 0.0932920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763461\n",
      "\tspeed: 0.0661s/iter; left time: 1291.0902s\n",
      "\titers: 200, epoch: 13 | loss: 0.0818228\n",
      "\tspeed: 0.0344s/iter; left time: 667.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0793178 Vali Loss: 0.0828459 Test Loss: 0.0931148\n",
      "Validation loss decreased (0.082960 --> 0.082846).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0800062\n",
      "\tspeed: 0.0671s/iter; left time: 1294.3812s\n",
      "\titers: 200, epoch: 14 | loss: 0.0819832\n",
      "\tspeed: 0.0345s/iter; left time: 663.3308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0789994 Vali Loss: 0.0825182 Test Loss: 0.0933117\n",
      "Validation loss decreased (0.082846 --> 0.082518).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0812188\n",
      "\tspeed: 0.0680s/iter; left time: 1297.1837s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769876\n",
      "\tspeed: 0.0345s/iter; left time: 654.2046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0787149 Vali Loss: 0.0826182 Test Loss: 0.0934537\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786891\n",
      "\tspeed: 0.0665s/iter; left time: 1254.5914s\n",
      "\titers: 200, epoch: 16 | loss: 0.0829321\n",
      "\tspeed: 0.0346s/iter; left time: 648.0698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0785222 Vali Loss: 0.0824578 Test Loss: 0.0933246\n",
      "Validation loss decreased (0.082518 --> 0.082458).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0766105\n",
      "\tspeed: 0.0660s/iter; left time: 1228.8647s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775430\n",
      "\tspeed: 0.0345s/iter; left time: 639.5157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0782164 Vali Loss: 0.0823364 Test Loss: 0.0936304\n",
      "Validation loss decreased (0.082458 --> 0.082336).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0737783\n",
      "\tspeed: 0.0679s/iter; left time: 1249.5334s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795119\n",
      "\tspeed: 0.0345s/iter; left time: 631.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0780388 Vali Loss: 0.0823434 Test Loss: 0.0939227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0779562\n",
      "\tspeed: 0.0664s/iter; left time: 1207.5432s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744572\n",
      "\tspeed: 0.0346s/iter; left time: 625.0926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0778180 Vali Loss: 0.0823256 Test Loss: 0.0938507\n",
      "Validation loss decreased (0.082336 --> 0.082326).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811709\n",
      "\tspeed: 0.0665s/iter; left time: 1194.6992s\n",
      "\titers: 200, epoch: 20 | loss: 0.0786681\n",
      "\tspeed: 0.0345s/iter; left time: 615.5700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0775951 Vali Loss: 0.0823114 Test Loss: 0.0941019\n",
      "Validation loss decreased (0.082326 --> 0.082311).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0748576\n",
      "\tspeed: 0.0672s/iter; left time: 1193.0233s\n",
      "\titers: 200, epoch: 21 | loss: 0.0787515\n",
      "\tspeed: 0.0348s/iter; left time: 613.8924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0774586 Vali Loss: 0.0820314 Test Loss: 0.0940175\n",
      "Validation loss decreased (0.082311 --> 0.082031).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0802003\n",
      "\tspeed: 0.0674s/iter; left time: 1180.7295s\n",
      "\titers: 200, epoch: 22 | loss: 0.0754237\n",
      "\tspeed: 0.0348s/iter; left time: 606.5265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0773000 Vali Loss: 0.0820159 Test Loss: 0.0942531\n",
      "Validation loss decreased (0.082031 --> 0.082016).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0779743\n",
      "\tspeed: 0.0678s/iter; left time: 1172.8826s\n",
      "\titers: 200, epoch: 23 | loss: 0.0747215\n",
      "\tspeed: 0.0350s/iter; left time: 601.5548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0772234 Vali Loss: 0.0822244 Test Loss: 0.0947550\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0775924\n",
      "\tspeed: 0.0665s/iter; left time: 1135.0784s\n",
      "\titers: 200, epoch: 24 | loss: 0.0774336\n",
      "\tspeed: 0.0345s/iter; left time: 585.2632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0770066 Vali Loss: 0.0819901 Test Loss: 0.0946638\n",
      "Validation loss decreased (0.082016 --> 0.081990).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0765772\n",
      "\tspeed: 0.0670s/iter; left time: 1128.2230s\n",
      "\titers: 200, epoch: 25 | loss: 0.0774296\n",
      "\tspeed: 0.0347s/iter; left time: 580.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0769184 Vali Loss: 0.0818508 Test Loss: 0.0945564\n",
      "Validation loss decreased (0.081990 --> 0.081851).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0752274\n",
      "\tspeed: 0.0670s/iter; left time: 1114.0727s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780611\n",
      "\tspeed: 0.0348s/iter; left time: 574.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0768677 Vali Loss: 0.0820124 Test Loss: 0.0949415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0767367\n",
      "\tspeed: 0.0670s/iter; left time: 1098.4792s\n",
      "\titers: 200, epoch: 27 | loss: 0.0761459\n",
      "\tspeed: 0.0363s/iter; left time: 591.3927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 223 | Train Loss: 0.0767765 Vali Loss: 0.0820813 Test Loss: 0.0948841\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0743221\n",
      "\tspeed: 0.0684s/iter; left time: 1107.3506s\n",
      "\titers: 200, epoch: 28 | loss: 0.0752958\n",
      "\tspeed: 0.0351s/iter; left time: 564.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 223 | Train Loss: 0.0767860 Vali Loss: 0.0819307 Test Loss: 0.0946716\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0782983\n",
      "\tspeed: 0.0666s/iter; left time: 1063.0058s\n",
      "\titers: 200, epoch: 29 | loss: 0.0778854\n",
      "\tspeed: 0.0357s/iter; left time: 566.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 223 | Train Loss: 0.0766185 Vali Loss: 0.0818122 Test Loss: 0.0950429\n",
      "Validation loss decreased (0.081851 --> 0.081812).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0740042\n",
      "\tspeed: 0.0673s/iter; left time: 1059.5981s\n",
      "\titers: 200, epoch: 30 | loss: 0.0801981\n",
      "\tspeed: 0.0345s/iter; left time: 538.7677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0765305 Vali Loss: 0.0820920 Test Loss: 0.0952042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0767182\n",
      "\tspeed: 0.0653s/iter; left time: 1013.0907s\n",
      "\titers: 200, epoch: 31 | loss: 0.0758625\n",
      "\tspeed: 0.0346s/iter; left time: 532.5713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0765871 Vali Loss: 0.0818485 Test Loss: 0.0951992\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0781168\n",
      "\tspeed: 0.0670s/iter; left time: 1024.4357s\n",
      "\titers: 200, epoch: 32 | loss: 0.0793877\n",
      "\tspeed: 0.0352s/iter; left time: 535.2964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0764493 Vali Loss: 0.0820237 Test Loss: 0.0955673\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0740315\n",
      "\tspeed: 0.0654s/iter; left time: 985.6079s\n",
      "\titers: 200, epoch: 33 | loss: 0.0757111\n",
      "\tspeed: 0.0347s/iter; left time: 519.9320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0763936 Vali Loss: 0.0819379 Test Loss: 0.0954416\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0753173\n",
      "\tspeed: 0.0657s/iter; left time: 974.7022s\n",
      "\titers: 200, epoch: 34 | loss: 0.0706699\n",
      "\tspeed: 0.0352s/iter; left time: 518.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0763890 Vali Loss: 0.0819006 Test Loss: 0.0955024\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0773871\n",
      "\tspeed: 0.0655s/iter; left time: 957.2772s\n",
      "\titers: 200, epoch: 35 | loss: 0.0741799\n",
      "\tspeed: 0.0349s/iter; left time: 507.1043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0763201 Vali Loss: 0.0818680 Test Loss: 0.0954335\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0785499\n",
      "\tspeed: 0.0652s/iter; left time: 938.3553s\n",
      "\titers: 200, epoch: 36 | loss: 0.0738299\n",
      "\tspeed: 0.0345s/iter; left time: 493.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0762440 Vali Loss: 0.0819575 Test Loss: 0.0954877\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755313\n",
      "\tspeed: 0.0655s/iter; left time: 927.8703s\n",
      "\titers: 200, epoch: 37 | loss: 0.0735468\n",
      "\tspeed: 0.0346s/iter; left time: 487.5966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0762236 Vali Loss: 0.0820155 Test Loss: 0.0955825\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0732269\n",
      "\tspeed: 0.0676s/iter; left time: 943.2274s\n",
      "\titers: 200, epoch: 38 | loss: 0.0770698\n",
      "\tspeed: 0.0344s/iter; left time: 476.4420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0762167 Vali Loss: 0.0818996 Test Loss: 0.0954762\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765640\n",
      "\tspeed: 0.0662s/iter; left time: 908.9614s\n",
      "\titers: 200, epoch: 39 | loss: 0.0754804\n",
      "\tspeed: 0.0351s/iter; left time: 478.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0761922 Vali Loss: 0.0818792 Test Loss: 0.0953627\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02110309898853302, rmse:0.14526905119419098, mae:0.09504284709692001, rse:0.42678743600845337\n",
      "Intermediate time for ES and pred_len 168: 00h:12m:17.38s\n",
      "Intermediate time for ES: 00h:38m:58.75s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1181538\n",
      "\tspeed: 0.0512s/iter; left time: 1151.7002s\n",
      "\titers: 200, epoch: 1 | loss: 0.1003178\n",
      "\tspeed: 0.0244s/iter; left time: 547.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.1170270 Vali Loss: 0.1172993 Test Loss: 0.1302999\n",
      "Validation loss decreased (inf --> 0.117299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0619097\n",
      "\tspeed: 0.0472s/iter; left time: 1051.0409s\n",
      "\titers: 200, epoch: 2 | loss: 0.0544771\n",
      "\tspeed: 0.0240s/iter; left time: 531.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 226 | Train Loss: 0.0654789 Vali Loss: 0.0618007 Test Loss: 0.0638786\n",
      "Validation loss decreased (0.117299 --> 0.061801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0528410\n",
      "\tspeed: 0.0478s/iter; left time: 1052.9309s\n",
      "\titers: 200, epoch: 3 | loss: 0.0507370\n",
      "\tspeed: 0.0283s/iter; left time: 620.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0510558 Vali Loss: 0.0580366 Test Loss: 0.0603052\n",
      "Validation loss decreased (0.061801 --> 0.058037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0520147\n",
      "\tspeed: 0.0497s/iter; left time: 1085.1892s\n",
      "\titers: 200, epoch: 4 | loss: 0.0432217\n",
      "\tspeed: 0.0323s/iter; left time: 700.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 226 | Train Loss: 0.0484834 Vali Loss: 0.0563872 Test Loss: 0.0588450\n",
      "Validation loss decreased (0.058037 --> 0.056387).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0448531\n",
      "\tspeed: 0.0473s/iter; left time: 1022.4748s\n",
      "\titers: 200, epoch: 5 | loss: 0.0467714\n",
      "\tspeed: 0.0289s/iter; left time: 621.1112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0468747 Vali Loss: 0.0547840 Test Loss: 0.0575932\n",
      "Validation loss decreased (0.056387 --> 0.054784).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0465157\n",
      "\tspeed: 0.0549s/iter; left time: 1172.4276s\n",
      "\titers: 200, epoch: 6 | loss: 0.0471361\n",
      "\tspeed: 0.0298s/iter; left time: 633.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 226 | Train Loss: 0.0456765 Vali Loss: 0.0538354 Test Loss: 0.0568870\n",
      "Validation loss decreased (0.054784 --> 0.053835).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0464228\n",
      "\tspeed: 0.0506s/iter; left time: 1070.3317s\n",
      "\titers: 200, epoch: 7 | loss: 0.0428562\n",
      "\tspeed: 0.0207s/iter; left time: 434.8164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 226 | Train Loss: 0.0448067 Vali Loss: 0.0531672 Test Loss: 0.0561855\n",
      "Validation loss decreased (0.053835 --> 0.053167).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0414287\n",
      "\tspeed: 0.0514s/iter; left time: 1075.8979s\n",
      "\titers: 200, epoch: 8 | loss: 0.0414663\n",
      "\tspeed: 0.0231s/iter; left time: 480.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 226 | Train Loss: 0.0441156 Vali Loss: 0.0528043 Test Loss: 0.0558938\n",
      "Validation loss decreased (0.053167 --> 0.052804).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0396454\n",
      "\tspeed: 0.0497s/iter; left time: 1027.8371s\n",
      "\titers: 200, epoch: 9 | loss: 0.0445222\n",
      "\tspeed: 0.0263s/iter; left time: 541.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 226 | Train Loss: 0.0437219 Vali Loss: 0.0524473 Test Loss: 0.0555881\n",
      "Validation loss decreased (0.052804 --> 0.052447).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0465342\n",
      "\tspeed: 0.0490s/iter; left time: 1003.1988s\n",
      "\titers: 200, epoch: 10 | loss: 0.0447787\n",
      "\tspeed: 0.0282s/iter; left time: 574.5490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 226 | Train Loss: 0.0433464 Vali Loss: 0.0524429 Test Loss: 0.0555543\n",
      "Validation loss decreased (0.052447 --> 0.052443).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0463950\n",
      "\tspeed: 0.0465s/iter; left time: 941.8945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0471261\n",
      "\tspeed: 0.0262s/iter; left time: 527.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 226 | Train Loss: 0.0430885 Vali Loss: 0.0520855 Test Loss: 0.0553389\n",
      "Validation loss decreased (0.052443 --> 0.052086).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0440239\n",
      "\tspeed: 0.0500s/iter; left time: 1000.4495s\n",
      "\titers: 200, epoch: 12 | loss: 0.0431861\n",
      "\tspeed: 0.0253s/iter; left time: 503.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 226 | Train Loss: 0.0427594 Vali Loss: 0.0520969 Test Loss: 0.0552671\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0460427\n",
      "\tspeed: 0.0483s/iter; left time: 955.3089s\n",
      "\titers: 200, epoch: 13 | loss: 0.0407886\n",
      "\tspeed: 0.0235s/iter; left time: 462.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 226 | Train Loss: 0.0425987 Vali Loss: 0.0519302 Test Loss: 0.0550461\n",
      "Validation loss decreased (0.052086 --> 0.051930).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0436107\n",
      "\tspeed: 0.0523s/iter; left time: 1022.8773s\n",
      "\titers: 200, epoch: 14 | loss: 0.0460468\n",
      "\tspeed: 0.0294s/iter; left time: 573.0106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 226 | Train Loss: 0.0424552 Vali Loss: 0.0518532 Test Loss: 0.0550036\n",
      "Validation loss decreased (0.051930 --> 0.051853).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0402645\n",
      "\tspeed: 0.0567s/iter; left time: 1095.9107s\n",
      "\titers: 200, epoch: 15 | loss: 0.0445272\n",
      "\tspeed: 0.0292s/iter; left time: 561.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 226 | Train Loss: 0.0422743 Vali Loss: 0.0517325 Test Loss: 0.0548619\n",
      "Validation loss decreased (0.051853 --> 0.051732).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0438543\n",
      "\tspeed: 0.0456s/iter; left time: 871.5470s\n",
      "\titers: 200, epoch: 16 | loss: 0.0432302\n",
      "\tspeed: 0.0214s/iter; left time: 406.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 226 | Train Loss: 0.0421779 Vali Loss: 0.0516198 Test Loss: 0.0546895\n",
      "Validation loss decreased (0.051732 --> 0.051620).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0420478\n",
      "\tspeed: 0.0502s/iter; left time: 948.6092s\n",
      "\titers: 200, epoch: 17 | loss: 0.0416950\n",
      "\tspeed: 0.0257s/iter; left time: 482.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0420557 Vali Loss: 0.0514453 Test Loss: 0.0546779\n",
      "Validation loss decreased (0.051620 --> 0.051445).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0412639\n",
      "\tspeed: 0.0495s/iter; left time: 923.9595s\n",
      "\titers: 200, epoch: 18 | loss: 0.0401191\n",
      "\tspeed: 0.0261s/iter; left time: 483.6662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 226 | Train Loss: 0.0419732 Vali Loss: 0.0515109 Test Loss: 0.0546205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0420400\n",
      "\tspeed: 0.0477s/iter; left time: 878.9548s\n",
      "\titers: 200, epoch: 19 | loss: 0.0422216\n",
      "\tspeed: 0.0273s/iter; left time: 500.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0418645 Vali Loss: 0.0514373 Test Loss: 0.0545614\n",
      "Validation loss decreased (0.051445 --> 0.051437).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0434768\n",
      "\tspeed: 0.0474s/iter; left time: 862.3987s\n",
      "\titers: 200, epoch: 20 | loss: 0.0388558\n",
      "\tspeed: 0.0210s/iter; left time: 380.7805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 226 | Train Loss: 0.0417754 Vali Loss: 0.0513995 Test Loss: 0.0544768\n",
      "Validation loss decreased (0.051437 --> 0.051399).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0394034\n",
      "\tspeed: 0.0493s/iter; left time: 885.8111s\n",
      "\titers: 200, epoch: 21 | loss: 0.0404570\n",
      "\tspeed: 0.0265s/iter; left time: 473.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0417436 Vali Loss: 0.0513565 Test Loss: 0.0544110\n",
      "Validation loss decreased (0.051399 --> 0.051356).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0408854\n",
      "\tspeed: 0.0488s/iter; left time: 866.0392s\n",
      "\titers: 200, epoch: 22 | loss: 0.0402349\n",
      "\tspeed: 0.0264s/iter; left time: 465.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 226 | Train Loss: 0.0416521 Vali Loss: 0.0513761 Test Loss: 0.0544329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0412479\n",
      "\tspeed: 0.0558s/iter; left time: 977.2998s\n",
      "\titers: 200, epoch: 23 | loss: 0.0419215\n",
      "\tspeed: 0.0300s/iter; left time: 522.4368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 226 | Train Loss: 0.0416237 Vali Loss: 0.0514683 Test Loss: 0.0544846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0403025\n",
      "\tspeed: 0.0490s/iter; left time: 847.3580s\n",
      "\titers: 200, epoch: 24 | loss: 0.0403031\n",
      "\tspeed: 0.0186s/iter; left time: 320.7997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 226 | Train Loss: 0.0415419 Vali Loss: 0.0513075 Test Loss: 0.0543513\n",
      "Validation loss decreased (0.051356 --> 0.051307).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0388115\n",
      "\tspeed: 0.0412s/iter; left time: 703.9726s\n",
      "\titers: 200, epoch: 25 | loss: 0.0417404\n",
      "\tspeed: 0.0260s/iter; left time: 441.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 226 | Train Loss: 0.0415224 Vali Loss: 0.0511409 Test Loss: 0.0542526\n",
      "Validation loss decreased (0.051307 --> 0.051141).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0413413\n",
      "\tspeed: 0.0429s/iter; left time: 722.6165s\n",
      "\titers: 200, epoch: 26 | loss: 0.0387699\n",
      "\tspeed: 0.0256s/iter; left time: 428.5616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 226 | Train Loss: 0.0415136 Vali Loss: 0.0512980 Test Loss: 0.0542906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0426343\n",
      "\tspeed: 0.0534s/iter; left time: 887.9830s\n",
      "\titers: 200, epoch: 27 | loss: 0.0408687\n",
      "\tspeed: 0.0277s/iter; left time: 458.1653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 226 | Train Loss: 0.0414671 Vali Loss: 0.0512499 Test Loss: 0.0542798\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0407607\n",
      "\tspeed: 0.0511s/iter; left time: 837.4815s\n",
      "\titers: 200, epoch: 28 | loss: 0.0404382\n",
      "\tspeed: 0.0244s/iter; left time: 396.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0414232 Vali Loss: 0.0511967 Test Loss: 0.0542340\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0418660\n",
      "\tspeed: 0.0486s/iter; left time: 785.9019s\n",
      "\titers: 200, epoch: 29 | loss: 0.0461494\n",
      "\tspeed: 0.0233s/iter; left time: 374.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 226 | Train Loss: 0.0414108 Vali Loss: 0.0511942 Test Loss: 0.0542963\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0387321\n",
      "\tspeed: 0.0491s/iter; left time: 782.7273s\n",
      "\titers: 200, epoch: 30 | loss: 0.0443478\n",
      "\tspeed: 0.0236s/iter; left time: 373.7893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 226 | Train Loss: 0.0413687 Vali Loss: 0.0511919 Test Loss: 0.0541996\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0386426\n",
      "\tspeed: 0.0491s/iter; left time: 772.4493s\n",
      "\titers: 200, epoch: 31 | loss: 0.0406933\n",
      "\tspeed: 0.0250s/iter; left time: 389.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 226 | Train Loss: 0.0413150 Vali Loss: 0.0510859 Test Loss: 0.0542480\n",
      "Validation loss decreased (0.051141 --> 0.051086).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0413825\n",
      "\tspeed: 0.0497s/iter; left time: 769.9086s\n",
      "\titers: 200, epoch: 32 | loss: 0.0430385\n",
      "\tspeed: 0.0265s/iter; left time: 407.9187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 226 | Train Loss: 0.0413569 Vali Loss: 0.0511404 Test Loss: 0.0542026\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0414003\n",
      "\tspeed: 0.0488s/iter; left time: 744.4190s\n",
      "\titers: 200, epoch: 33 | loss: 0.0416502\n",
      "\tspeed: 0.0220s/iter; left time: 333.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 226 | Train Loss: 0.0413078 Vali Loss: 0.0511158 Test Loss: 0.0542135\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0440531\n",
      "\tspeed: 0.0431s/iter; left time: 648.1282s\n",
      "\titers: 200, epoch: 34 | loss: 0.0423279\n",
      "\tspeed: 0.0262s/iter; left time: 391.0081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 226 | Train Loss: 0.0413079 Vali Loss: 0.0510071 Test Loss: 0.0541874\n",
      "Validation loss decreased (0.051086 --> 0.051007).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0438803\n",
      "\tspeed: 0.0531s/iter; left time: 787.0705s\n",
      "\titers: 200, epoch: 35 | loss: 0.0389386\n",
      "\tspeed: 0.0279s/iter; left time: 410.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 226 | Train Loss: 0.0413145 Vali Loss: 0.0511008 Test Loss: 0.0541847\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0472102\n",
      "\tspeed: 0.0507s/iter; left time: 740.2141s\n",
      "\titers: 200, epoch: 36 | loss: 0.0386646\n",
      "\tspeed: 0.0298s/iter; left time: 432.5491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 226 | Train Loss: 0.0413326 Vali Loss: 0.0509946 Test Loss: 0.0541957\n",
      "Validation loss decreased (0.051007 --> 0.050995).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0415711\n",
      "\tspeed: 0.0471s/iter; left time: 676.7013s\n",
      "\titers: 200, epoch: 37 | loss: 0.0403833\n",
      "\tspeed: 0.0231s/iter; left time: 330.1552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 226 | Train Loss: 0.0412730 Vali Loss: 0.0510368 Test Loss: 0.0541667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0435312\n",
      "\tspeed: 0.0512s/iter; left time: 723.3549s\n",
      "\titers: 200, epoch: 38 | loss: 0.0391161\n",
      "\tspeed: 0.0284s/iter; left time: 399.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 226 | Train Loss: 0.0412630 Vali Loss: 0.0510862 Test Loss: 0.0541457\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0423625\n",
      "\tspeed: 0.0543s/iter; left time: 755.9302s\n",
      "\titers: 200, epoch: 39 | loss: 0.0436461\n",
      "\tspeed: 0.0306s/iter; left time: 422.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 226 | Train Loss: 0.0412700 Vali Loss: 0.0510823 Test Loss: 0.0541865\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0388188\n",
      "\tspeed: 0.0464s/iter; left time: 635.6226s\n",
      "\titers: 200, epoch: 40 | loss: 0.0421896\n",
      "\tspeed: 0.0201s/iter; left time: 273.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 226 | Train Loss: 0.0412645 Vali Loss: 0.0511344 Test Loss: 0.0541581\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416249\n",
      "\tspeed: 0.0444s/iter; left time: 597.6767s\n",
      "\titers: 200, epoch: 41 | loss: 0.0399476\n",
      "\tspeed: 0.0208s/iter; left time: 277.8426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 226 | Train Loss: 0.0412606 Vali Loss: 0.0511338 Test Loss: 0.0541512\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0414979\n",
      "\tspeed: 0.0523s/iter; left time: 692.3976s\n",
      "\titers: 200, epoch: 42 | loss: 0.0431815\n",
      "\tspeed: 0.0277s/iter; left time: 363.2903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 226 | Train Loss: 0.0412452 Vali Loss: 0.0511097 Test Loss: 0.0541572\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0408163\n",
      "\tspeed: 0.0463s/iter; left time: 601.8237s\n",
      "\titers: 200, epoch: 43 | loss: 0.0406738\n",
      "\tspeed: 0.0194s/iter; left time: 250.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 226 | Train Loss: 0.0412199 Vali Loss: 0.0510517 Test Loss: 0.0541587\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0390890\n",
      "\tspeed: 0.0490s/iter; left time: 626.5797s\n",
      "\titers: 200, epoch: 44 | loss: 0.0395521\n",
      "\tspeed: 0.0295s/iter; left time: 374.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 226 | Train Loss: 0.0412448 Vali Loss: 0.0510430 Test Loss: 0.0541468\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0431649\n",
      "\tspeed: 0.0496s/iter; left time: 622.6231s\n",
      "\titers: 200, epoch: 45 | loss: 0.0421387\n",
      "\tspeed: 0.0296s/iter; left time: 369.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 226 | Train Loss: 0.0412236 Vali Loss: 0.0510134 Test Loss: 0.0541102\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0387131\n",
      "\tspeed: 0.0555s/iter; left time: 684.3485s\n",
      "\titers: 200, epoch: 46 | loss: 0.0402467\n",
      "\tspeed: 0.0338s/iter; left time: 412.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 226 | Train Loss: 0.0412133 Vali Loss: 0.0508858 Test Loss: 0.0541043\n",
      "Validation loss decreased (0.050995 --> 0.050886).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0409243\n",
      "\tspeed: 0.0519s/iter; left time: 628.6759s\n",
      "\titers: 200, epoch: 47 | loss: 0.0427487\n",
      "\tspeed: 0.0292s/iter; left time: 351.0371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 226 | Train Loss: 0.0411864 Vali Loss: 0.0510773 Test Loss: 0.0541381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0411739\n",
      "\tspeed: 0.0529s/iter; left time: 628.8035s\n",
      "\titers: 200, epoch: 48 | loss: 0.0400346\n",
      "\tspeed: 0.0298s/iter; left time: 350.6919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 226 | Train Loss: 0.0412303 Vali Loss: 0.0510280 Test Loss: 0.0541061\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0392074\n",
      "\tspeed: 0.0514s/iter; left time: 599.3333s\n",
      "\titers: 200, epoch: 49 | loss: 0.0425270\n",
      "\tspeed: 0.0232s/iter; left time: 268.0406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 226 | Train Loss: 0.0412285 Vali Loss: 0.0510358 Test Loss: 0.0541527\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0410978\n",
      "\tspeed: 0.0429s/iter; left time: 490.1766s\n",
      "\titers: 200, epoch: 50 | loss: 0.0380185\n",
      "\tspeed: 0.0237s/iter; left time: 268.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 226 | Train Loss: 0.0411887 Vali Loss: 0.0510428 Test Loss: 0.0541054\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0409625\n",
      "\tspeed: 0.0551s/iter; left time: 616.6258s\n",
      "\titers: 200, epoch: 51 | loss: 0.0422957\n",
      "\tspeed: 0.0266s/iter; left time: 295.3196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 226 | Train Loss: 0.0412051 Vali Loss: 0.0510952 Test Loss: 0.0541243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0445837\n",
      "\tspeed: 0.0482s/iter; left time: 528.4640s\n",
      "\titers: 200, epoch: 52 | loss: 0.0395759\n",
      "\tspeed: 0.0237s/iter; left time: 257.6549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 226 | Train Loss: 0.0411853 Vali Loss: 0.0510290 Test Loss: 0.0541174\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0417441\n",
      "\tspeed: 0.0433s/iter; left time: 465.5154s\n",
      "\titers: 200, epoch: 53 | loss: 0.0429232\n",
      "\tspeed: 0.0207s/iter; left time: 220.8348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 226 | Train Loss: 0.0411807 Vali Loss: 0.0510417 Test Loss: 0.0541382\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0413381\n",
      "\tspeed: 0.0488s/iter; left time: 513.9451s\n",
      "\titers: 200, epoch: 54 | loss: 0.0414263\n",
      "\tspeed: 0.0249s/iter; left time: 259.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 226 | Train Loss: 0.0412373 Vali Loss: 0.0510291 Test Loss: 0.0541415\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0415313\n",
      "\tspeed: 0.0495s/iter; left time: 510.0006s\n",
      "\titers: 200, epoch: 55 | loss: 0.0427520\n",
      "\tspeed: 0.0299s/iter; left time: 305.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 226 | Train Loss: 0.0411794 Vali Loss: 0.0510427 Test Loss: 0.0541164\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0402257\n",
      "\tspeed: 0.0542s/iter; left time: 546.0304s\n",
      "\titers: 200, epoch: 56 | loss: 0.0419502\n",
      "\tspeed: 0.0322s/iter; left time: 320.7520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 226 | Train Loss: 0.0411687 Vali Loss: 0.0510630 Test Loss: 0.0541254\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009846783243119717, rmse:0.09923096001148224, mae:0.0541042760014534, rse:0.38283032178878784\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1182429\n",
      "\tspeed: 0.0258s/iter; left time: 580.9970s\n",
      "\titers: 200, epoch: 1 | loss: 0.1087598\n",
      "\tspeed: 0.0242s/iter; left time: 542.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 226 | Train Loss: 0.1173186 Vali Loss: 0.1173352 Test Loss: 0.1300844\n",
      "Validation loss decreased (inf --> 0.117335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0651111\n",
      "\tspeed: 0.0555s/iter; left time: 1237.0380s\n",
      "\titers: 200, epoch: 2 | loss: 0.0529706\n",
      "\tspeed: 0.0243s/iter; left time: 538.6773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 226 | Train Loss: 0.0664123 Vali Loss: 0.0623895 Test Loss: 0.0646706\n",
      "Validation loss decreased (0.117335 --> 0.062389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0472664\n",
      "\tspeed: 0.0492s/iter; left time: 1085.5112s\n",
      "\titers: 200, epoch: 3 | loss: 0.0473599\n",
      "\tspeed: 0.0245s/iter; left time: 538.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 226 | Train Loss: 0.0515785 Vali Loss: 0.0584495 Test Loss: 0.0607335\n",
      "Validation loss decreased (0.062389 --> 0.058449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0478847\n",
      "\tspeed: 0.0472s/iter; left time: 1029.1145s\n",
      "\titers: 200, epoch: 4 | loss: 0.0477668\n",
      "\tspeed: 0.0285s/iter; left time: 618.3240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0488677 Vali Loss: 0.0565804 Test Loss: 0.0591537\n",
      "Validation loss decreased (0.058449 --> 0.056580).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0465839\n",
      "\tspeed: 0.0506s/iter; left time: 1092.4474s\n",
      "\titers: 200, epoch: 5 | loss: 0.0449112\n",
      "\tspeed: 0.0235s/iter; left time: 505.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 226 | Train Loss: 0.0472675 Vali Loss: 0.0552322 Test Loss: 0.0579919\n",
      "Validation loss decreased (0.056580 --> 0.055232).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0488357\n",
      "\tspeed: 0.0505s/iter; left time: 1079.7151s\n",
      "\titers: 200, epoch: 6 | loss: 0.0461491\n",
      "\tspeed: 0.0239s/iter; left time: 507.7448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 226 | Train Loss: 0.0460159 Vali Loss: 0.0541305 Test Loss: 0.0573544\n",
      "Validation loss decreased (0.055232 --> 0.054131).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0451231\n",
      "\tspeed: 0.0485s/iter; left time: 1026.0216s\n",
      "\titers: 200, epoch: 7 | loss: 0.0468216\n",
      "\tspeed: 0.0275s/iter; left time: 579.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 226 | Train Loss: 0.0450794 Vali Loss: 0.0535126 Test Loss: 0.0566724\n",
      "Validation loss decreased (0.054131 --> 0.053513).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0442903\n",
      "\tspeed: 0.0458s/iter; left time: 958.7857s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449988\n",
      "\tspeed: 0.0257s/iter; left time: 535.4839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 226 | Train Loss: 0.0443544 Vali Loss: 0.0528316 Test Loss: 0.0561518\n",
      "Validation loss decreased (0.053513 --> 0.052832).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0455078\n",
      "\tspeed: 0.0480s/iter; left time: 992.5128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0443731\n",
      "\tspeed: 0.0271s/iter; left time: 558.8277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 226 | Train Loss: 0.0438602 Vali Loss: 0.0526205 Test Loss: 0.0557751\n",
      "Validation loss decreased (0.052832 --> 0.052621).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0415070\n",
      "\tspeed: 0.0528s/iter; left time: 1080.2887s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402026\n",
      "\tspeed: 0.0226s/iter; left time: 459.6664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0434354 Vali Loss: 0.0523072 Test Loss: 0.0554496\n",
      "Validation loss decreased (0.052621 --> 0.052307).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0426357\n",
      "\tspeed: 0.0524s/iter; left time: 1061.3547s\n",
      "\titers: 200, epoch: 11 | loss: 0.0414191\n",
      "\tspeed: 0.0273s/iter; left time: 549.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0431586 Vali Loss: 0.0521097 Test Loss: 0.0554314\n",
      "Validation loss decreased (0.052307 --> 0.052110).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0400768\n",
      "\tspeed: 0.0488s/iter; left time: 977.7067s\n",
      "\titers: 200, epoch: 12 | loss: 0.0436677\n",
      "\tspeed: 0.0195s/iter; left time: 387.6644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 226 | Train Loss: 0.0429084 Vali Loss: 0.0518410 Test Loss: 0.0551395\n",
      "Validation loss decreased (0.052110 --> 0.051841).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0407224\n",
      "\tspeed: 0.0497s/iter; left time: 982.5913s\n",
      "\titers: 200, epoch: 13 | loss: 0.0394750\n",
      "\tspeed: 0.0295s/iter; left time: 580.2304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0426601 Vali Loss: 0.0517847 Test Loss: 0.0551147\n",
      "Validation loss decreased (0.051841 --> 0.051785).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0423878\n",
      "\tspeed: 0.0554s/iter; left time: 1083.0515s\n",
      "\titers: 200, epoch: 14 | loss: 0.0439840\n",
      "\tspeed: 0.0218s/iter; left time: 424.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 226 | Train Loss: 0.0424838 Vali Loss: 0.0516804 Test Loss: 0.0550191\n",
      "Validation loss decreased (0.051785 --> 0.051680).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0434851\n",
      "\tspeed: 0.0508s/iter; left time: 982.9505s\n",
      "\titers: 200, epoch: 15 | loss: 0.0416624\n",
      "\tspeed: 0.0192s/iter; left time: 368.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 226 | Train Loss: 0.0423361 Vali Loss: 0.0515615 Test Loss: 0.0548344\n",
      "Validation loss decreased (0.051680 --> 0.051562).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0426293\n",
      "\tspeed: 0.0509s/iter; left time: 973.3632s\n",
      "\titers: 200, epoch: 16 | loss: 0.0461580\n",
      "\tspeed: 0.0269s/iter; left time: 510.9818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 226 | Train Loss: 0.0422033 Vali Loss: 0.0514735 Test Loss: 0.0548638\n",
      "Validation loss decreased (0.051562 --> 0.051473).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0383031\n",
      "\tspeed: 0.0477s/iter; left time: 900.5786s\n",
      "\titers: 200, epoch: 17 | loss: 0.0399342\n",
      "\tspeed: 0.0239s/iter; left time: 448.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0421454 Vali Loss: 0.0513158 Test Loss: 0.0547536\n",
      "Validation loss decreased (0.051473 --> 0.051316).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0412194\n",
      "\tspeed: 0.0499s/iter; left time: 931.5355s\n",
      "\titers: 200, epoch: 18 | loss: 0.0429672\n",
      "\tspeed: 0.0252s/iter; left time: 467.8597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0419960 Vali Loss: 0.0514539 Test Loss: 0.0548421\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0393095\n",
      "\tspeed: 0.0492s/iter; left time: 906.4209s\n",
      "\titers: 200, epoch: 19 | loss: 0.0441770\n",
      "\tspeed: 0.0209s/iter; left time: 383.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 226 | Train Loss: 0.0419091 Vali Loss: 0.0512217 Test Loss: 0.0546638\n",
      "Validation loss decreased (0.051316 --> 0.051222).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0420669\n",
      "\tspeed: 0.0570s/iter; left time: 1037.0022s\n",
      "\titers: 200, epoch: 20 | loss: 0.0409727\n",
      "\tspeed: 0.0306s/iter; left time: 553.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.0417591 Vali Loss: 0.0512575 Test Loss: 0.0545752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0456082\n",
      "\tspeed: 0.0517s/iter; left time: 928.8116s\n",
      "\titers: 200, epoch: 21 | loss: 0.0407613\n",
      "\tspeed: 0.0256s/iter; left time: 457.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 226 | Train Loss: 0.0417115 Vali Loss: 0.0513524 Test Loss: 0.0546071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0430730\n",
      "\tspeed: 0.0533s/iter; left time: 947.2073s\n",
      "\titers: 200, epoch: 22 | loss: 0.0423018\n",
      "\tspeed: 0.0247s/iter; left time: 436.9308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 226 | Train Loss: 0.0416839 Vali Loss: 0.0512003 Test Loss: 0.0545036\n",
      "Validation loss decreased (0.051222 --> 0.051200).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0401441\n",
      "\tspeed: 0.0477s/iter; left time: 835.3917s\n",
      "\titers: 200, epoch: 23 | loss: 0.0436835\n",
      "\tspeed: 0.0237s/iter; left time: 413.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0416036 Vali Loss: 0.0512747 Test Loss: 0.0545001\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0411001\n",
      "\tspeed: 0.0452s/iter; left time: 781.6859s\n",
      "\titers: 200, epoch: 24 | loss: 0.0383674\n",
      "\tspeed: 0.0266s/iter; left time: 457.6856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 226 | Train Loss: 0.0415666 Vali Loss: 0.0512336 Test Loss: 0.0545423\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0430113\n",
      "\tspeed: 0.0445s/iter; left time: 759.6149s\n",
      "\titers: 200, epoch: 25 | loss: 0.0411178\n",
      "\tspeed: 0.0244s/iter; left time: 413.5505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 226 | Train Loss: 0.0415223 Vali Loss: 0.0511620 Test Loss: 0.0545256\n",
      "Validation loss decreased (0.051200 --> 0.051162).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0394535\n",
      "\tspeed: 0.0501s/iter; left time: 844.7345s\n",
      "\titers: 200, epoch: 26 | loss: 0.0408899\n",
      "\tspeed: 0.0298s/iter; left time: 499.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 226 | Train Loss: 0.0414990 Vali Loss: 0.0510829 Test Loss: 0.0545045\n",
      "Validation loss decreased (0.051162 --> 0.051083).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0401787\n",
      "\tspeed: 0.0518s/iter; left time: 861.5923s\n",
      "\titers: 200, epoch: 27 | loss: 0.0434536\n",
      "\tspeed: 0.0226s/iter; left time: 374.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 226 | Train Loss: 0.0414874 Vali Loss: 0.0511563 Test Loss: 0.0544282\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0423668\n",
      "\tspeed: 0.0451s/iter; left time: 739.7172s\n",
      "\titers: 200, epoch: 28 | loss: 0.0422014\n",
      "\tspeed: 0.0186s/iter; left time: 303.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0414652 Vali Loss: 0.0510324 Test Loss: 0.0544592\n",
      "Validation loss decreased (0.051083 --> 0.051032).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0407290\n",
      "\tspeed: 0.0492s/iter; left time: 795.3732s\n",
      "\titers: 200, epoch: 29 | loss: 0.0407079\n",
      "\tspeed: 0.0246s/iter; left time: 395.4301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 226 | Train Loss: 0.0413912 Vali Loss: 0.0510565 Test Loss: 0.0544063\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0460965\n",
      "\tspeed: 0.0446s/iter; left time: 711.5648s\n",
      "\titers: 200, epoch: 30 | loss: 0.0401905\n",
      "\tspeed: 0.0221s/iter; left time: 350.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 226 | Train Loss: 0.0414160 Vali Loss: 0.0510849 Test Loss: 0.0543769\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0401029\n",
      "\tspeed: 0.0462s/iter; left time: 725.5853s\n",
      "\titers: 200, epoch: 31 | loss: 0.0418141\n",
      "\tspeed: 0.0265s/iter; left time: 414.2903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0413730 Vali Loss: 0.0510531 Test Loss: 0.0543816\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0405486\n",
      "\tspeed: 0.0467s/iter; left time: 723.0925s\n",
      "\titers: 200, epoch: 32 | loss: 0.0379125\n",
      "\tspeed: 0.0274s/iter; left time: 422.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 226 | Train Loss: 0.0413438 Vali Loss: 0.0510413 Test Loss: 0.0543643\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0401707\n",
      "\tspeed: 0.0492s/iter; left time: 751.4719s\n",
      "\titers: 200, epoch: 33 | loss: 0.0397618\n",
      "\tspeed: 0.0252s/iter; left time: 381.5150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 226 | Train Loss: 0.0412806 Vali Loss: 0.0511042 Test Loss: 0.0544257\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0418254\n",
      "\tspeed: 0.0465s/iter; left time: 699.6537s\n",
      "\titers: 200, epoch: 34 | loss: 0.0396528\n",
      "\tspeed: 0.0255s/iter; left time: 381.6757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 226 | Train Loss: 0.0413203 Vali Loss: 0.0510538 Test Loss: 0.0543853\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0423622\n",
      "\tspeed: 0.0486s/iter; left time: 719.4765s\n",
      "\titers: 200, epoch: 35 | loss: 0.0448219\n",
      "\tspeed: 0.0281s/iter; left time: 413.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 226 | Train Loss: 0.0412818 Vali Loss: 0.0510316 Test Loss: 0.0543432\n",
      "Validation loss decreased (0.051032 --> 0.051032).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0420344\n",
      "\tspeed: 0.0547s/iter; left time: 798.0869s\n",
      "\titers: 200, epoch: 36 | loss: 0.0410500\n",
      "\tspeed: 0.0263s/iter; left time: 381.7396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 226 | Train Loss: 0.0412932 Vali Loss: 0.0510304 Test Loss: 0.0543913\n",
      "Validation loss decreased (0.051032 --> 0.051030).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0428056\n",
      "\tspeed: 0.0535s/iter; left time: 769.0850s\n",
      "\titers: 200, epoch: 37 | loss: 0.0405213\n",
      "\tspeed: 0.0230s/iter; left time: 328.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 226 | Train Loss: 0.0412726 Vali Loss: 0.0510981 Test Loss: 0.0543641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0408890\n",
      "\tspeed: 0.0434s/iter; left time: 613.9895s\n",
      "\titers: 200, epoch: 38 | loss: 0.0412078\n",
      "\tspeed: 0.0234s/iter; left time: 328.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 226 | Train Loss: 0.0412846 Vali Loss: 0.0510122 Test Loss: 0.0544314\n",
      "Validation loss decreased (0.051030 --> 0.051012).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0425402\n",
      "\tspeed: 0.0501s/iter; left time: 696.6970s\n",
      "\titers: 200, epoch: 39 | loss: 0.0458580\n",
      "\tspeed: 0.0236s/iter; left time: 325.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 226 | Train Loss: 0.0412711 Vali Loss: 0.0510318 Test Loss: 0.0543933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0436337\n",
      "\tspeed: 0.0519s/iter; left time: 710.7051s\n",
      "\titers: 200, epoch: 40 | loss: 0.0391848\n",
      "\tspeed: 0.0300s/iter; left time: 407.1539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 226 | Train Loss: 0.0412898 Vali Loss: 0.0510104 Test Loss: 0.0543356\n",
      "Validation loss decreased (0.051012 --> 0.051010).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0438826\n",
      "\tspeed: 0.0456s/iter; left time: 614.2154s\n",
      "\titers: 200, epoch: 41 | loss: 0.0409017\n",
      "\tspeed: 0.0187s/iter; left time: 249.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 226 | Train Loss: 0.0412321 Vali Loss: 0.0510284 Test Loss: 0.0543539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0392837\n",
      "\tspeed: 0.0455s/iter; left time: 602.4075s\n",
      "\titers: 200, epoch: 42 | loss: 0.0423266\n",
      "\tspeed: 0.0228s/iter; left time: 300.0848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 226 | Train Loss: 0.0412172 Vali Loss: 0.0510499 Test Loss: 0.0544103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0420753\n",
      "\tspeed: 0.0577s/iter; left time: 749.9806s\n",
      "\titers: 200, epoch: 43 | loss: 0.0390433\n",
      "\tspeed: 0.0305s/iter; left time: 393.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 226 | Train Loss: 0.0412348 Vali Loss: 0.0509948 Test Loss: 0.0543997\n",
      "Validation loss decreased (0.051010 --> 0.050995).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0427173\n",
      "\tspeed: 0.0566s/iter; left time: 723.5453s\n",
      "\titers: 200, epoch: 44 | loss: 0.0422384\n",
      "\tspeed: 0.0244s/iter; left time: 309.3547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0411777 Vali Loss: 0.0510399 Test Loss: 0.0543750\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0430857\n",
      "\tspeed: 0.0509s/iter; left time: 638.6249s\n",
      "\titers: 200, epoch: 45 | loss: 0.0400429\n",
      "\tspeed: 0.0284s/iter; left time: 353.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 226 | Train Loss: 0.0412277 Vali Loss: 0.0510145 Test Loss: 0.0543994\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0385433\n",
      "\tspeed: 0.0490s/iter; left time: 604.5331s\n",
      "\titers: 200, epoch: 46 | loss: 0.0414090\n",
      "\tspeed: 0.0317s/iter; left time: 387.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 226 | Train Loss: 0.0412204 Vali Loss: 0.0509589 Test Loss: 0.0543231\n",
      "Validation loss decreased (0.050995 --> 0.050959).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0402943\n",
      "\tspeed: 0.0489s/iter; left time: 592.0995s\n",
      "\titers: 200, epoch: 47 | loss: 0.0385111\n",
      "\tspeed: 0.0248s/iter; left time: 298.1152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 226 | Train Loss: 0.0412128 Vali Loss: 0.0509588 Test Loss: 0.0543431\n",
      "Validation loss decreased (0.050959 --> 0.050959).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0420539\n",
      "\tspeed: 0.0471s/iter; left time: 559.4235s\n",
      "\titers: 200, epoch: 48 | loss: 0.0414722\n",
      "\tspeed: 0.0186s/iter; left time: 219.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 226 | Train Loss: 0.0411918 Vali Loss: 0.0509552 Test Loss: 0.0543449\n",
      "Validation loss decreased (0.050959 --> 0.050955).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0404456\n",
      "\tspeed: 0.0518s/iter; left time: 604.1721s\n",
      "\titers: 200, epoch: 49 | loss: 0.0390682\n",
      "\tspeed: 0.0295s/iter; left time: 340.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 226 | Train Loss: 0.0412032 Vali Loss: 0.0510119 Test Loss: 0.0543529\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0413699\n",
      "\tspeed: 0.0543s/iter; left time: 620.2605s\n",
      "\titers: 200, epoch: 50 | loss: 0.0430498\n",
      "\tspeed: 0.0252s/iter; left time: 285.3069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 226 | Train Loss: 0.0411565 Vali Loss: 0.0509348 Test Loss: 0.0543352\n",
      "Validation loss decreased (0.050955 --> 0.050935).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0433248\n",
      "\tspeed: 0.0452s/iter; left time: 506.5995s\n",
      "\titers: 200, epoch: 51 | loss: 0.0433756\n",
      "\tspeed: 0.0254s/iter; left time: 281.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 226 | Train Loss: 0.0412128 Vali Loss: 0.0509672 Test Loss: 0.0543227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0455864\n",
      "\tspeed: 0.0459s/iter; left time: 503.9862s\n",
      "\titers: 200, epoch: 52 | loss: 0.0373759\n",
      "\tspeed: 0.0268s/iter; left time: 291.5502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0412307 Vali Loss: 0.0510274 Test Loss: 0.0543177\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0362533\n",
      "\tspeed: 0.0469s/iter; left time: 503.7876s\n",
      "\titers: 200, epoch: 53 | loss: 0.0392829\n",
      "\tspeed: 0.0276s/iter; left time: 293.7810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 226 | Train Loss: 0.0412029 Vali Loss: 0.0509258 Test Loss: 0.0543313\n",
      "Validation loss decreased (0.050935 --> 0.050926).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0384007\n",
      "\tspeed: 0.0484s/iter; left time: 509.8368s\n",
      "\titers: 200, epoch: 54 | loss: 0.0386209\n",
      "\tspeed: 0.0294s/iter; left time: 306.2205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 226 | Train Loss: 0.0411951 Vali Loss: 0.0510010 Test Loss: 0.0543542\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0395590\n",
      "\tspeed: 0.0477s/iter; left time: 491.3463s\n",
      "\titers: 200, epoch: 55 | loss: 0.0431799\n",
      "\tspeed: 0.0259s/iter; left time: 263.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0411490 Vali Loss: 0.0509527 Test Loss: 0.0543082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0409292\n",
      "\tspeed: 0.0512s/iter; left time: 515.4983s\n",
      "\titers: 200, epoch: 56 | loss: 0.0384964\n",
      "\tspeed: 0.0277s/iter; left time: 276.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 226 | Train Loss: 0.0411532 Vali Loss: 0.0508853 Test Loss: 0.0543533\n",
      "Validation loss decreased (0.050926 --> 0.050885).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0408892\n",
      "\tspeed: 0.0503s/iter; left time: 495.1290s\n",
      "\titers: 200, epoch: 57 | loss: 0.0383844\n",
      "\tspeed: 0.0280s/iter; left time: 273.0488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 226 | Train Loss: 0.0412010 Vali Loss: 0.0509888 Test Loss: 0.0543061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0397936\n",
      "\tspeed: 0.0512s/iter; left time: 492.7793s\n",
      "\titers: 200, epoch: 58 | loss: 0.0405686\n",
      "\tspeed: 0.0279s/iter; left time: 265.3963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0411393 Vali Loss: 0.0508974 Test Loss: 0.0543278\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0416370\n",
      "\tspeed: 0.0476s/iter; left time: 447.1507s\n",
      "\titers: 200, epoch: 59 | loss: 0.0448846\n",
      "\tspeed: 0.0263s/iter; left time: 244.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 226 | Train Loss: 0.0412174 Vali Loss: 0.0509768 Test Loss: 0.0543235\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0410431\n",
      "\tspeed: 0.0477s/iter; left time: 437.0455s\n",
      "\titers: 200, epoch: 60 | loss: 0.0403395\n",
      "\tspeed: 0.0270s/iter; left time: 244.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0412172 Vali Loss: 0.0509386 Test Loss: 0.0543214\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0416200\n",
      "\tspeed: 0.0455s/iter; left time: 406.6081s\n",
      "\titers: 200, epoch: 61 | loss: 0.0424872\n",
      "\tspeed: 0.0223s/iter; left time: 197.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 226 | Train Loss: 0.0411801 Vali Loss: 0.0509546 Test Loss: 0.0543453\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0361256\n",
      "\tspeed: 0.0446s/iter; left time: 388.9664s\n",
      "\titers: 200, epoch: 62 | loss: 0.0402691\n",
      "\tspeed: 0.0269s/iter; left time: 231.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 226 | Train Loss: 0.0411739 Vali Loss: 0.0509681 Test Loss: 0.0543445\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0424508\n",
      "\tspeed: 0.0484s/iter; left time: 410.6147s\n",
      "\titers: 200, epoch: 63 | loss: 0.0425622\n",
      "\tspeed: 0.0201s/iter; left time: 168.3736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 226 | Train Loss: 0.0411551 Vali Loss: 0.0509861 Test Loss: 0.0543499\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0397099\n",
      "\tspeed: 0.0458s/iter; left time: 378.0383s\n",
      "\titers: 200, epoch: 64 | loss: 0.0410833\n",
      "\tspeed: 0.0263s/iter; left time: 214.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 226 | Train Loss: 0.0411703 Vali Loss: 0.0509164 Test Loss: 0.0543010\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0404438\n",
      "\tspeed: 0.0504s/iter; left time: 404.9438s\n",
      "\titers: 200, epoch: 65 | loss: 0.0409320\n",
      "\tspeed: 0.0250s/iter; left time: 198.4187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 226 | Train Loss: 0.0411614 Vali Loss: 0.0509447 Test Loss: 0.0543172\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0451697\n",
      "\tspeed: 0.0468s/iter; left time: 365.8001s\n",
      "\titers: 200, epoch: 66 | loss: 0.0403475\n",
      "\tspeed: 0.0238s/iter; left time: 183.2684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 226 | Train Loss: 0.0411995 Vali Loss: 0.0509420 Test Loss: 0.0543792\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009954087436199188, rmse:0.09977017343044281, mae:0.05435333773493767, rse:0.384910523891449\n",
      "Intermediate time for FR and pred_len 24: 00h:15m:26.60s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1220741\n",
      "\tspeed: 0.0506s/iter; left time: 1132.7418s\n",
      "\titers: 200, epoch: 1 | loss: 0.1146931\n",
      "\tspeed: 0.0247s/iter; left time: 550.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.1229160 Vali Loss: 0.1261277 Test Loss: 0.1432174\n",
      "Validation loss decreased (inf --> 0.126128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0742138\n",
      "\tspeed: 0.0462s/iter; left time: 1025.1202s\n",
      "\titers: 200, epoch: 2 | loss: 0.0697527\n",
      "\tspeed: 0.0254s/iter; left time: 560.4833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 225 | Train Loss: 0.0799607 Vali Loss: 0.0787864 Test Loss: 0.0867982\n",
      "Validation loss decreased (0.126128 --> 0.078786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0669011\n",
      "\tspeed: 0.0531s/iter; left time: 1165.8389s\n",
      "\titers: 200, epoch: 3 | loss: 0.0681493\n",
      "\tspeed: 0.0295s/iter; left time: 645.3308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 225 | Train Loss: 0.0672110 Vali Loss: 0.0753967 Test Loss: 0.0838328\n",
      "Validation loss decreased (0.078786 --> 0.075397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0665823\n",
      "\tspeed: 0.0642s/iter; left time: 1395.3642s\n",
      "\titers: 200, epoch: 4 | loss: 0.0666709\n",
      "\tspeed: 0.0319s/iter; left time: 689.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 225 | Train Loss: 0.0649054 Vali Loss: 0.0735958 Test Loss: 0.0825490\n",
      "Validation loss decreased (0.075397 --> 0.073596).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0616264\n",
      "\tspeed: 0.0541s/iter; left time: 1163.2913s\n",
      "\titers: 200, epoch: 5 | loss: 0.0608241\n",
      "\tspeed: 0.0308s/iter; left time: 659.9078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 225 | Train Loss: 0.0630447 Vali Loss: 0.0720382 Test Loss: 0.0814225\n",
      "Validation loss decreased (0.073596 --> 0.072038).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0619600\n",
      "\tspeed: 0.0512s/iter; left time: 1089.5306s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598352\n",
      "\tspeed: 0.0283s/iter; left time: 599.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 225 | Train Loss: 0.0616488 Vali Loss: 0.0713768 Test Loss: 0.0808180\n",
      "Validation loss decreased (0.072038 --> 0.071377).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0632396\n",
      "\tspeed: 0.0498s/iter; left time: 1047.4369s\n",
      "\titers: 200, epoch: 7 | loss: 0.0662241\n",
      "\tspeed: 0.0253s/iter; left time: 529.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 225 | Train Loss: 0.0608829 Vali Loss: 0.0711699 Test Loss: 0.0803994\n",
      "Validation loss decreased (0.071377 --> 0.071170).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0579971\n",
      "\tspeed: 0.0586s/iter; left time: 1220.6730s\n",
      "\titers: 200, epoch: 8 | loss: 0.0584228\n",
      "\tspeed: 0.0273s/iter; left time: 566.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 225 | Train Loss: 0.0603736 Vali Loss: 0.0708177 Test Loss: 0.0803240\n",
      "Validation loss decreased (0.071170 --> 0.070818).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0604323\n",
      "\tspeed: 0.0503s/iter; left time: 1035.4719s\n",
      "\titers: 200, epoch: 9 | loss: 0.0596516\n",
      "\tspeed: 0.0285s/iter; left time: 584.8081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 225 | Train Loss: 0.0599084 Vali Loss: 0.0707924 Test Loss: 0.0800577\n",
      "Validation loss decreased (0.070818 --> 0.070792).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0582479\n",
      "\tspeed: 0.0528s/iter; left time: 1075.2759s\n",
      "\titers: 200, epoch: 10 | loss: 0.0610579\n",
      "\tspeed: 0.0278s/iter; left time: 563.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0596372 Vali Loss: 0.0706747 Test Loss: 0.0800745\n",
      "Validation loss decreased (0.070792 --> 0.070675).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0596562\n",
      "\tspeed: 0.0558s/iter; left time: 1124.3311s\n",
      "\titers: 200, epoch: 11 | loss: 0.0598316\n",
      "\tspeed: 0.0301s/iter; left time: 602.6839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 225 | Train Loss: 0.0593520 Vali Loss: 0.0706221 Test Loss: 0.0800105\n",
      "Validation loss decreased (0.070675 --> 0.070622).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0540255\n",
      "\tspeed: 0.0559s/iter; left time: 1114.6240s\n",
      "\titers: 200, epoch: 12 | loss: 0.0580481\n",
      "\tspeed: 0.0296s/iter; left time: 586.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0591023 Vali Loss: 0.0705149 Test Loss: 0.0799026\n",
      "Validation loss decreased (0.070622 --> 0.070515).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0586757\n",
      "\tspeed: 0.0499s/iter; left time: 983.4344s\n",
      "\titers: 200, epoch: 13 | loss: 0.0574660\n",
      "\tspeed: 0.0304s/iter; left time: 595.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 225 | Train Loss: 0.0588783 Vali Loss: 0.0703367 Test Loss: 0.0797316\n",
      "Validation loss decreased (0.070515 --> 0.070337).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0603708\n",
      "\tspeed: 0.0524s/iter; left time: 1020.4457s\n",
      "\titers: 200, epoch: 14 | loss: 0.0608521\n",
      "\tspeed: 0.0194s/iter; left time: 375.7931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 225 | Train Loss: 0.0587461 Vali Loss: 0.0703455 Test Loss: 0.0796405\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571587\n",
      "\tspeed: 0.0535s/iter; left time: 1029.8471s\n",
      "\titers: 200, epoch: 15 | loss: 0.0585860\n",
      "\tspeed: 0.0312s/iter; left time: 597.8993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 225 | Train Loss: 0.0585486 Vali Loss: 0.0702861 Test Loss: 0.0797806\n",
      "Validation loss decreased (0.070337 --> 0.070286).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569398\n",
      "\tspeed: 0.0452s/iter; left time: 860.1652s\n",
      "\titers: 200, epoch: 16 | loss: 0.0590494\n",
      "\tspeed: 0.0310s/iter; left time: 586.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 225 | Train Loss: 0.0584513 Vali Loss: 0.0702889 Test Loss: 0.0797580\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0571058\n",
      "\tspeed: 0.0610s/iter; left time: 1146.5135s\n",
      "\titers: 200, epoch: 17 | loss: 0.0555347\n",
      "\tspeed: 0.0322s/iter; left time: 601.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 225 | Train Loss: 0.0583301 Vali Loss: 0.0702149 Test Loss: 0.0796651\n",
      "Validation loss decreased (0.070286 --> 0.070215).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0558115\n",
      "\tspeed: 0.0539s/iter; left time: 1000.5664s\n",
      "\titers: 200, epoch: 18 | loss: 0.0614593\n",
      "\tspeed: 0.0274s/iter; left time: 506.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0582152 Vali Loss: 0.0701965 Test Loss: 0.0797421\n",
      "Validation loss decreased (0.070215 --> 0.070197).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0578019\n",
      "\tspeed: 0.0522s/iter; left time: 958.7890s\n",
      "\titers: 200, epoch: 19 | loss: 0.0571534\n",
      "\tspeed: 0.0249s/iter; left time: 454.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 225 | Train Loss: 0.0581612 Vali Loss: 0.0701740 Test Loss: 0.0796154\n",
      "Validation loss decreased (0.070197 --> 0.070174).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0603194\n",
      "\tspeed: 0.0489s/iter; left time: 886.1364s\n",
      "\titers: 200, epoch: 20 | loss: 0.0608253\n",
      "\tspeed: 0.0273s/iter; left time: 492.8628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 225 | Train Loss: 0.0580238 Vali Loss: 0.0701691 Test Loss: 0.0796968\n",
      "Validation loss decreased (0.070174 --> 0.070169).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0547900\n",
      "\tspeed: 0.0572s/iter; left time: 1023.4929s\n",
      "\titers: 200, epoch: 21 | loss: 0.0575892\n",
      "\tspeed: 0.0322s/iter; left time: 573.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 225 | Train Loss: 0.0579985 Vali Loss: 0.0702100 Test Loss: 0.0796268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0571349\n",
      "\tspeed: 0.0518s/iter; left time: 915.5777s\n",
      "\titers: 200, epoch: 22 | loss: 0.0592960\n",
      "\tspeed: 0.0316s/iter; left time: 555.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 225 | Train Loss: 0.0579128 Vali Loss: 0.0701129 Test Loss: 0.0797642\n",
      "Validation loss decreased (0.070169 --> 0.070113).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0567881\n",
      "\tspeed: 0.0533s/iter; left time: 930.3161s\n",
      "\titers: 200, epoch: 23 | loss: 0.0578356\n",
      "\tspeed: 0.0288s/iter; left time: 500.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 225 | Train Loss: 0.0578414 Vali Loss: 0.0700759 Test Loss: 0.0796640\n",
      "Validation loss decreased (0.070113 --> 0.070076).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0588220\n",
      "\tspeed: 0.0577s/iter; left time: 994.4895s\n",
      "\titers: 200, epoch: 24 | loss: 0.0592831\n",
      "\tspeed: 0.0311s/iter; left time: 532.0358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 225 | Train Loss: 0.0577965 Vali Loss: 0.0700834 Test Loss: 0.0796844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0585203\n",
      "\tspeed: 0.0563s/iter; left time: 957.3886s\n",
      "\titers: 200, epoch: 25 | loss: 0.0556729\n",
      "\tspeed: 0.0304s/iter; left time: 513.2272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 225 | Train Loss: 0.0577600 Vali Loss: 0.0701371 Test Loss: 0.0798421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0540029\n",
      "\tspeed: 0.0559s/iter; left time: 938.3910s\n",
      "\titers: 200, epoch: 26 | loss: 0.0571991\n",
      "\tspeed: 0.0257s/iter; left time: 427.7577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0577176 Vali Loss: 0.0700682 Test Loss: 0.0797211\n",
      "Validation loss decreased (0.070076 --> 0.070068).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0591816\n",
      "\tspeed: 0.0537s/iter; left time: 889.0366s\n",
      "\titers: 200, epoch: 27 | loss: 0.0545728\n",
      "\tspeed: 0.0280s/iter; left time: 460.2271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0576992 Vali Loss: 0.0700617 Test Loss: 0.0797237\n",
      "Validation loss decreased (0.070068 --> 0.070062).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0617053\n",
      "\tspeed: 0.0534s/iter; left time: 871.1085s\n",
      "\titers: 200, epoch: 28 | loss: 0.0574315\n",
      "\tspeed: 0.0274s/iter; left time: 444.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0576387 Vali Loss: 0.0700271 Test Loss: 0.0797314\n",
      "Validation loss decreased (0.070062 --> 0.070027).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0517652\n",
      "\tspeed: 0.0552s/iter; left time: 887.9829s\n",
      "\titers: 200, epoch: 29 | loss: 0.0597316\n",
      "\tspeed: 0.0286s/iter; left time: 456.9283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 225 | Train Loss: 0.0576450 Vali Loss: 0.0700293 Test Loss: 0.0797632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0542691\n",
      "\tspeed: 0.0518s/iter; left time: 822.4959s\n",
      "\titers: 200, epoch: 30 | loss: 0.0595843\n",
      "\tspeed: 0.0253s/iter; left time: 399.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0575834 Vali Loss: 0.0700706 Test Loss: 0.0796918\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0550818\n",
      "\tspeed: 0.0505s/iter; left time: 790.4459s\n",
      "\titers: 200, epoch: 31 | loss: 0.0559612\n",
      "\tspeed: 0.0271s/iter; left time: 420.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0575502 Vali Loss: 0.0700366 Test Loss: 0.0797195\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0598395\n",
      "\tspeed: 0.0529s/iter; left time: 816.2085s\n",
      "\titers: 200, epoch: 32 | loss: 0.0588521\n",
      "\tspeed: 0.0297s/iter; left time: 454.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 225 | Train Loss: 0.0575711 Vali Loss: 0.0700139 Test Loss: 0.0796878\n",
      "Validation loss decreased (0.070027 --> 0.070014).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0565253\n",
      "\tspeed: 0.0533s/iter; left time: 810.5258s\n",
      "\titers: 200, epoch: 33 | loss: 0.0593845\n",
      "\tspeed: 0.0256s/iter; left time: 385.8935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0575217 Vali Loss: 0.0700382 Test Loss: 0.0797146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0580082\n",
      "\tspeed: 0.0488s/iter; left time: 730.6147s\n",
      "\titers: 200, epoch: 34 | loss: 0.0597742\n",
      "\tspeed: 0.0203s/iter; left time: 301.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 225 | Train Loss: 0.0575363 Vali Loss: 0.0700428 Test Loss: 0.0797535\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0547218\n",
      "\tspeed: 0.0572s/iter; left time: 843.9688s\n",
      "\titers: 200, epoch: 35 | loss: 0.0592895\n",
      "\tspeed: 0.0302s/iter; left time: 442.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 225 | Train Loss: 0.0575481 Vali Loss: 0.0700124 Test Loss: 0.0797147\n",
      "Validation loss decreased (0.070014 --> 0.070012).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0589458\n",
      "\tspeed: 0.0492s/iter; left time: 714.6912s\n",
      "\titers: 200, epoch: 36 | loss: 0.0574722\n",
      "\tspeed: 0.0271s/iter; left time: 390.6720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 225 | Train Loss: 0.0574943 Vali Loss: 0.0700254 Test Loss: 0.0796877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0615762\n",
      "\tspeed: 0.0544s/iter; left time: 778.2482s\n",
      "\titers: 200, epoch: 37 | loss: 0.0569741\n",
      "\tspeed: 0.0307s/iter; left time: 436.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 225 | Train Loss: 0.0575015 Vali Loss: 0.0700170 Test Loss: 0.0797144\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0595051\n",
      "\tspeed: 0.0534s/iter; left time: 751.0762s\n",
      "\titers: 200, epoch: 38 | loss: 0.0563165\n",
      "\tspeed: 0.0305s/iter; left time: 426.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 225 | Train Loss: 0.0574755 Vali Loss: 0.0700329 Test Loss: 0.0796785\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0547463\n",
      "\tspeed: 0.0601s/iter; left time: 831.9454s\n",
      "\titers: 200, epoch: 39 | loss: 0.0586968\n",
      "\tspeed: 0.0290s/iter; left time: 399.2635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 225 | Train Loss: 0.0574457 Vali Loss: 0.0700329 Test Loss: 0.0797462\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0591344\n",
      "\tspeed: 0.0483s/iter; left time: 657.5722s\n",
      "\titers: 200, epoch: 40 | loss: 0.0548586\n",
      "\tspeed: 0.0255s/iter; left time: 345.1851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0574429 Vali Loss: 0.0700195 Test Loss: 0.0797313\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0567012\n",
      "\tspeed: 0.0506s/iter; left time: 678.6717s\n",
      "\titers: 200, epoch: 41 | loss: 0.0549469\n",
      "\tspeed: 0.0301s/iter; left time: 400.3929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 225 | Train Loss: 0.0574303 Vali Loss: 0.0700485 Test Loss: 0.0798056\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0558322\n",
      "\tspeed: 0.0493s/iter; left time: 649.7967s\n",
      "\titers: 200, epoch: 42 | loss: 0.0558083\n",
      "\tspeed: 0.0290s/iter; left time: 379.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0574319 Vali Loss: 0.0700218 Test Loss: 0.0797209\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0572975\n",
      "\tspeed: 0.0488s/iter; left time: 631.9960s\n",
      "\titers: 200, epoch: 43 | loss: 0.0564682\n",
      "\tspeed: 0.0298s/iter; left time: 383.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0574159 Vali Loss: 0.0700373 Test Loss: 0.0797657\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0559593\n",
      "\tspeed: 0.0524s/iter; left time: 666.7368s\n",
      "\titers: 200, epoch: 44 | loss: 0.0582130\n",
      "\tspeed: 0.0252s/iter; left time: 317.8728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 225 | Train Loss: 0.0575009 Vali Loss: 0.0700108 Test Loss: 0.0797607\n",
      "Validation loss decreased (0.070012 --> 0.070011).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0571633\n",
      "\tspeed: 0.0543s/iter; left time: 678.7832s\n",
      "\titers: 200, epoch: 45 | loss: 0.0607090\n",
      "\tspeed: 0.0271s/iter; left time: 336.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 225 | Train Loss: 0.0573783 Vali Loss: 0.0700036 Test Loss: 0.0797414\n",
      "Validation loss decreased (0.070011 --> 0.070004).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0591639\n",
      "\tspeed: 0.0495s/iter; left time: 607.8419s\n",
      "\titers: 200, epoch: 46 | loss: 0.0576543\n",
      "\tspeed: 0.0278s/iter; left time: 338.9153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 225 | Train Loss: 0.0574136 Vali Loss: 0.0700246 Test Loss: 0.0797608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0583863\n",
      "\tspeed: 0.0452s/iter; left time: 544.7970s\n",
      "\titers: 200, epoch: 47 | loss: 0.0595122\n",
      "\tspeed: 0.0280s/iter; left time: 334.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 225 | Train Loss: 0.0573917 Vali Loss: 0.0700042 Test Loss: 0.0797391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0520317\n",
      "\tspeed: 0.0527s/iter; left time: 623.2045s\n",
      "\titers: 200, epoch: 48 | loss: 0.0569255\n",
      "\tspeed: 0.0293s/iter; left time: 343.9272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0574080 Vali Loss: 0.0700144 Test Loss: 0.0796876\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0556890\n",
      "\tspeed: 0.0519s/iter; left time: 602.1130s\n",
      "\titers: 200, epoch: 49 | loss: 0.0603984\n",
      "\tspeed: 0.0259s/iter; left time: 298.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 225 | Train Loss: 0.0574180 Vali Loss: 0.0700193 Test Loss: 0.0797447\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0552318\n",
      "\tspeed: 0.0528s/iter; left time: 600.4019s\n",
      "\titers: 200, epoch: 50 | loss: 0.0560904\n",
      "\tspeed: 0.0289s/iter; left time: 326.2247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 225 | Train Loss: 0.0574346 Vali Loss: 0.0700277 Test Loss: 0.0797751\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0584236\n",
      "\tspeed: 0.0511s/iter; left time: 569.8983s\n",
      "\titers: 200, epoch: 51 | loss: 0.0596774\n",
      "\tspeed: 0.0255s/iter; left time: 281.4862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 225 | Train Loss: 0.0573538 Vali Loss: 0.0700491 Test Loss: 0.0797373\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0565288\n",
      "\tspeed: 0.0456s/iter; left time: 498.3488s\n",
      "\titers: 200, epoch: 52 | loss: 0.0591236\n",
      "\tspeed: 0.0250s/iter; left time: 270.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 225 | Train Loss: 0.0573672 Vali Loss: 0.0700128 Test Loss: 0.0797444\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0560007\n",
      "\tspeed: 0.0509s/iter; left time: 544.5816s\n",
      "\titers: 200, epoch: 53 | loss: 0.0553082\n",
      "\tspeed: 0.0247s/iter; left time: 261.8469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 225 | Train Loss: 0.0573963 Vali Loss: 0.0700233 Test Loss: 0.0797055\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0592167\n",
      "\tspeed: 0.0430s/iter; left time: 450.3846s\n",
      "\titers: 200, epoch: 54 | loss: 0.0581175\n",
      "\tspeed: 0.0195s/iter; left time: 202.6372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 225 | Train Loss: 0.0573610 Vali Loss: 0.0700269 Test Loss: 0.0797300\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0579432\n",
      "\tspeed: 0.0521s/iter; left time: 534.3785s\n",
      "\titers: 200, epoch: 55 | loss: 0.0573726\n",
      "\tspeed: 0.0284s/iter; left time: 288.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 225 | Train Loss: 0.0573706 Vali Loss: 0.0700055 Test Loss: 0.0796857\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019379083067178726, rmse:0.13920877873897552, mae:0.07974138855934143, rse:0.5384965538978577\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1284621\n",
      "\tspeed: 0.0301s/iter; left time: 673.6003s\n",
      "\titers: 200, epoch: 1 | loss: 0.1147969\n",
      "\tspeed: 0.0293s/iter; left time: 652.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.1244091 Vali Loss: 0.1269917 Test Loss: 0.1441622\n",
      "Validation loss decreased (inf --> 0.126992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0759071\n",
      "\tspeed: 0.0556s/iter; left time: 1232.0012s\n",
      "\titers: 200, epoch: 2 | loss: 0.0726768\n",
      "\tspeed: 0.0306s/iter; left time: 676.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 225 | Train Loss: 0.0806701 Vali Loss: 0.0787315 Test Loss: 0.0870802\n",
      "Validation loss decreased (0.126992 --> 0.078731).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0691525\n",
      "\tspeed: 0.0518s/iter; left time: 1138.1042s\n",
      "\titers: 200, epoch: 3 | loss: 0.0614118\n",
      "\tspeed: 0.0302s/iter; left time: 659.7355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 225 | Train Loss: 0.0671516 Vali Loss: 0.0750944 Test Loss: 0.0837143\n",
      "Validation loss decreased (0.078731 --> 0.075094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0640854\n",
      "\tspeed: 0.0522s/iter; left time: 1134.8101s\n",
      "\titers: 200, epoch: 4 | loss: 0.0640907\n",
      "\tspeed: 0.0267s/iter; left time: 576.8637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0647488 Vali Loss: 0.0734687 Test Loss: 0.0827292\n",
      "Validation loss decreased (0.075094 --> 0.073469).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0653637\n",
      "\tspeed: 0.0531s/iter; left time: 1142.4148s\n",
      "\titers: 200, epoch: 5 | loss: 0.0636200\n",
      "\tspeed: 0.0277s/iter; left time: 593.6523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 225 | Train Loss: 0.0630474 Vali Loss: 0.0722945 Test Loss: 0.0813779\n",
      "Validation loss decreased (0.073469 --> 0.072295).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0613186\n",
      "\tspeed: 0.0523s/iter; left time: 1113.6826s\n",
      "\titers: 200, epoch: 6 | loss: 0.0656116\n",
      "\tspeed: 0.0230s/iter; left time: 485.9906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0617380 Vali Loss: 0.0719124 Test Loss: 0.0807780\n",
      "Validation loss decreased (0.072295 --> 0.071912).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0582949\n",
      "\tspeed: 0.0482s/iter; left time: 1015.1316s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590653\n",
      "\tspeed: 0.0243s/iter; left time: 509.8308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 225 | Train Loss: 0.0609772 Vali Loss: 0.0714316 Test Loss: 0.0802214\n",
      "Validation loss decreased (0.071912 --> 0.071432).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0644874\n",
      "\tspeed: 0.0540s/iter; left time: 1123.6149s\n",
      "\titers: 200, epoch: 8 | loss: 0.0571645\n",
      "\tspeed: 0.0250s/iter; left time: 518.0083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0604138 Vali Loss: 0.0711555 Test Loss: 0.0802579\n",
      "Validation loss decreased (0.071432 --> 0.071155).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0587581\n",
      "\tspeed: 0.0511s/iter; left time: 1053.6666s\n",
      "\titers: 200, epoch: 9 | loss: 0.0600904\n",
      "\tspeed: 0.0257s/iter; left time: 526.2326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 225 | Train Loss: 0.0599643 Vali Loss: 0.0709659 Test Loss: 0.0799562\n",
      "Validation loss decreased (0.071155 --> 0.070966).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0593112\n",
      "\tspeed: 0.0501s/iter; left time: 1021.1228s\n",
      "\titers: 200, epoch: 10 | loss: 0.0603072\n",
      "\tspeed: 0.0285s/iter; left time: 578.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 225 | Train Loss: 0.0596653 Vali Loss: 0.0708955 Test Loss: 0.0799527\n",
      "Validation loss decreased (0.070966 --> 0.070895).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0589053\n",
      "\tspeed: 0.0753s/iter; left time: 1518.2250s\n",
      "\titers: 200, epoch: 11 | loss: 0.0562900\n",
      "\tspeed: 0.0291s/iter; left time: 583.6261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 225 | Train Loss: 0.0594109 Vali Loss: 0.0705119 Test Loss: 0.0796882\n",
      "Validation loss decreased (0.070895 --> 0.070512).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0573642\n",
      "\tspeed: 0.0528s/iter; left time: 1052.9812s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584696\n",
      "\tspeed: 0.0276s/iter; left time: 547.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 225 | Train Loss: 0.0591482 Vali Loss: 0.0705204 Test Loss: 0.0793874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0638459\n",
      "\tspeed: 0.0578s/iter; left time: 1138.3965s\n",
      "\titers: 200, epoch: 13 | loss: 0.0607723\n",
      "\tspeed: 0.0283s/iter; left time: 554.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 225 | Train Loss: 0.0589823 Vali Loss: 0.0704869 Test Loss: 0.0795223\n",
      "Validation loss decreased (0.070512 --> 0.070487).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0577675\n",
      "\tspeed: 0.0509s/iter; left time: 991.3312s\n",
      "\titers: 200, epoch: 14 | loss: 0.0588133\n",
      "\tspeed: 0.0295s/iter; left time: 570.8101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 225 | Train Loss: 0.0587557 Vali Loss: 0.0704164 Test Loss: 0.0794338\n",
      "Validation loss decreased (0.070487 --> 0.070416).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0598332\n",
      "\tspeed: 0.0492s/iter; left time: 947.8349s\n",
      "\titers: 200, epoch: 15 | loss: 0.0523763\n",
      "\tspeed: 0.0297s/iter; left time: 568.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0586058 Vali Loss: 0.0703930 Test Loss: 0.0794698\n",
      "Validation loss decreased (0.070416 --> 0.070393).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569543\n",
      "\tspeed: 0.0554s/iter; left time: 1053.8308s\n",
      "\titers: 200, epoch: 16 | loss: 0.0575018\n",
      "\tspeed: 0.0263s/iter; left time: 497.3045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0584718 Vali Loss: 0.0702827 Test Loss: 0.0793067\n",
      "Validation loss decreased (0.070393 --> 0.070283).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0598423\n",
      "\tspeed: 0.0545s/iter; left time: 1024.7249s\n",
      "\titers: 200, epoch: 17 | loss: 0.0599144\n",
      "\tspeed: 0.0320s/iter; left time: 597.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 225 | Train Loss: 0.0583535 Vali Loss: 0.0702744 Test Loss: 0.0794939\n",
      "Validation loss decreased (0.070283 --> 0.070274).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0531501\n",
      "\tspeed: 0.0524s/iter; left time: 973.4115s\n",
      "\titers: 200, epoch: 18 | loss: 0.0583698\n",
      "\tspeed: 0.0240s/iter; left time: 443.3663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0582279 Vali Loss: 0.0703069 Test Loss: 0.0795386\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0582662\n",
      "\tspeed: 0.0537s/iter; left time: 986.2555s\n",
      "\titers: 200, epoch: 19 | loss: 0.0538871\n",
      "\tspeed: 0.0289s/iter; left time: 528.2936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 225 | Train Loss: 0.0581021 Vali Loss: 0.0702676 Test Loss: 0.0794995\n",
      "Validation loss decreased (0.070274 --> 0.070268).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0593301\n",
      "\tspeed: 0.0517s/iter; left time: 936.3111s\n",
      "\titers: 200, epoch: 20 | loss: 0.0557304\n",
      "\tspeed: 0.0262s/iter; left time: 473.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0580808 Vali Loss: 0.0702839 Test Loss: 0.0793468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0583406\n",
      "\tspeed: 0.0525s/iter; left time: 939.9182s\n",
      "\titers: 200, epoch: 21 | loss: 0.0572454\n",
      "\tspeed: 0.0188s/iter; left time: 335.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 225 | Train Loss: 0.0579334 Vali Loss: 0.0701692 Test Loss: 0.0793286\n",
      "Validation loss decreased (0.070268 --> 0.070169).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0610274\n",
      "\tspeed: 0.0550s/iter; left time: 972.2716s\n",
      "\titers: 200, epoch: 22 | loss: 0.0577461\n",
      "\tspeed: 0.0284s/iter; left time: 499.9411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 225 | Train Loss: 0.0579323 Vali Loss: 0.0701289 Test Loss: 0.0793362\n",
      "Validation loss decreased (0.070169 --> 0.070129).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0563439\n",
      "\tspeed: 0.0517s/iter; left time: 901.9143s\n",
      "\titers: 200, epoch: 23 | loss: 0.0545914\n",
      "\tspeed: 0.0307s/iter; left time: 533.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0578198 Vali Loss: 0.0702303 Test Loss: 0.0793536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0573807\n",
      "\tspeed: 0.0552s/iter; left time: 951.4206s\n",
      "\titers: 200, epoch: 24 | loss: 0.0569326\n",
      "\tspeed: 0.0321s/iter; left time: 549.2525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 225 | Train Loss: 0.0577844 Vali Loss: 0.0701173 Test Loss: 0.0793296\n",
      "Validation loss decreased (0.070129 --> 0.070117).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0571284\n",
      "\tspeed: 0.0541s/iter; left time: 919.4589s\n",
      "\titers: 200, epoch: 25 | loss: 0.0566554\n",
      "\tspeed: 0.0280s/iter; left time: 473.9388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0577751 Vali Loss: 0.0701227 Test Loss: 0.0793326\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0563635\n",
      "\tspeed: 0.0589s/iter; left time: 988.5113s\n",
      "\titers: 200, epoch: 26 | loss: 0.0566110\n",
      "\tspeed: 0.0304s/iter; left time: 506.4226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 225 | Train Loss: 0.0576640 Vali Loss: 0.0701074 Test Loss: 0.0793666\n",
      "Validation loss decreased (0.070117 --> 0.070107).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0553515\n",
      "\tspeed: 0.0546s/iter; left time: 903.8048s\n",
      "\titers: 200, epoch: 27 | loss: 0.0582195\n",
      "\tspeed: 0.0268s/iter; left time: 440.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0576551 Vali Loss: 0.0701082 Test Loss: 0.0793718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0614190\n",
      "\tspeed: 0.0477s/iter; left time: 779.2414s\n",
      "\titers: 200, epoch: 28 | loss: 0.0561958\n",
      "\tspeed: 0.0244s/iter; left time: 396.5185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 225 | Train Loss: 0.0576140 Vali Loss: 0.0701166 Test Loss: 0.0793634\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0606842\n",
      "\tspeed: 0.0532s/iter; left time: 856.1724s\n",
      "\titers: 200, epoch: 29 | loss: 0.0555556\n",
      "\tspeed: 0.0203s/iter; left time: 325.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 225 | Train Loss: 0.0576270 Vali Loss: 0.0701248 Test Loss: 0.0793313\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0551578\n",
      "\tspeed: 0.0521s/iter; left time: 826.7042s\n",
      "\titers: 200, epoch: 30 | loss: 0.0541448\n",
      "\tspeed: 0.0280s/iter; left time: 442.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 225 | Train Loss: 0.0575290 Vali Loss: 0.0701014 Test Loss: 0.0793224\n",
      "Validation loss decreased (0.070107 --> 0.070101).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0569532\n",
      "\tspeed: 0.0501s/iter; left time: 784.1890s\n",
      "\titers: 200, epoch: 31 | loss: 0.0590402\n",
      "\tspeed: 0.0277s/iter; left time: 431.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 225 | Train Loss: 0.0575341 Vali Loss: 0.0701293 Test Loss: 0.0792899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0571844\n",
      "\tspeed: 0.0447s/iter; left time: 689.1812s\n",
      "\titers: 200, epoch: 32 | loss: 0.0565367\n",
      "\tspeed: 0.0187s/iter; left time: 286.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0574716 Vali Loss: 0.0701118 Test Loss: 0.0792886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0614607\n",
      "\tspeed: 0.0485s/iter; left time: 737.1822s\n",
      "\titers: 200, epoch: 33 | loss: 0.0585503\n",
      "\tspeed: 0.0253s/iter; left time: 382.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 225 | Train Loss: 0.0574797 Vali Loss: 0.0701058 Test Loss: 0.0793323\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0620264\n",
      "\tspeed: 0.0463s/iter; left time: 692.9268s\n",
      "\titers: 200, epoch: 34 | loss: 0.0566741\n",
      "\tspeed: 0.0228s/iter; left time: 339.3732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 225 | Train Loss: 0.0574723 Vali Loss: 0.0701067 Test Loss: 0.0793584\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0640683\n",
      "\tspeed: 0.0486s/iter; left time: 717.0495s\n",
      "\titers: 200, epoch: 35 | loss: 0.0572892\n",
      "\tspeed: 0.0245s/iter; left time: 358.7730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0574351 Vali Loss: 0.0700687 Test Loss: 0.0792865\n",
      "Validation loss decreased (0.070101 --> 0.070069).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0570007\n",
      "\tspeed: 0.0449s/iter; left time: 652.3359s\n",
      "\titers: 200, epoch: 36 | loss: 0.0618043\n",
      "\tspeed: 0.0222s/iter; left time: 319.6043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 225 | Train Loss: 0.0574811 Vali Loss: 0.0700867 Test Loss: 0.0792830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0605867\n",
      "\tspeed: 0.0494s/iter; left time: 706.4138s\n",
      "\titers: 200, epoch: 37 | loss: 0.0583223\n",
      "\tspeed: 0.0269s/iter; left time: 382.2192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0573955 Vali Loss: 0.0701139 Test Loss: 0.0793523\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0590914\n",
      "\tspeed: 0.0483s/iter; left time: 679.5609s\n",
      "\titers: 200, epoch: 38 | loss: 0.0547826\n",
      "\tspeed: 0.0215s/iter; left time: 300.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.0574274 Vali Loss: 0.0700677 Test Loss: 0.0793074\n",
      "Validation loss decreased (0.070069 --> 0.070068).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0589866\n",
      "\tspeed: 0.0537s/iter; left time: 743.1880s\n",
      "\titers: 200, epoch: 39 | loss: 0.0568881\n",
      "\tspeed: 0.0281s/iter; left time: 385.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 225 | Train Loss: 0.0574272 Vali Loss: 0.0700669 Test Loss: 0.0793272\n",
      "Validation loss decreased (0.070068 --> 0.070067).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0543563\n",
      "\tspeed: 0.0558s/iter; left time: 760.0782s\n",
      "\titers: 200, epoch: 40 | loss: 0.0559064\n",
      "\tspeed: 0.0312s/iter; left time: 422.6715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 225 | Train Loss: 0.0573883 Vali Loss: 0.0700760 Test Loss: 0.0793200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0552888\n",
      "\tspeed: 0.0556s/iter; left time: 745.0874s\n",
      "\titers: 200, epoch: 41 | loss: 0.0582908\n",
      "\tspeed: 0.0330s/iter; left time: 438.3193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 225 | Train Loss: 0.0573937 Vali Loss: 0.0700766 Test Loss: 0.0793160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0573349\n",
      "\tspeed: 0.0530s/iter; left time: 697.8380s\n",
      "\titers: 200, epoch: 42 | loss: 0.0566573\n",
      "\tspeed: 0.0235s/iter; left time: 307.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0573726 Vali Loss: 0.0700556 Test Loss: 0.0793327\n",
      "Validation loss decreased (0.070067 --> 0.070056).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0567332\n",
      "\tspeed: 0.0516s/iter; left time: 668.2099s\n",
      "\titers: 200, epoch: 43 | loss: 0.0599545\n",
      "\tspeed: 0.0292s/iter; left time: 375.3033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0574122 Vali Loss: 0.0700747 Test Loss: 0.0793403\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0567316\n",
      "\tspeed: 0.0564s/iter; left time: 717.8145s\n",
      "\titers: 200, epoch: 44 | loss: 0.0537350\n",
      "\tspeed: 0.0276s/iter; left time: 348.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0573724 Vali Loss: 0.0700628 Test Loss: 0.0793382\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0551076\n",
      "\tspeed: 0.0511s/iter; left time: 638.9937s\n",
      "\titers: 200, epoch: 45 | loss: 0.0591606\n",
      "\tspeed: 0.0308s/iter; left time: 382.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0573695 Vali Loss: 0.0700636 Test Loss: 0.0793459\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0604501\n",
      "\tspeed: 0.0471s/iter; left time: 578.1376s\n",
      "\titers: 200, epoch: 46 | loss: 0.0595160\n",
      "\tspeed: 0.0240s/iter; left time: 292.3925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 225 | Train Loss: 0.0574024 Vali Loss: 0.0700707 Test Loss: 0.0793402\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0571790\n",
      "\tspeed: 0.0522s/iter; left time: 628.4848s\n",
      "\titers: 200, epoch: 47 | loss: 0.0627229\n",
      "\tspeed: 0.0254s/iter; left time: 303.2714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0573691 Vali Loss: 0.0700772 Test Loss: 0.0793330\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0578066\n",
      "\tspeed: 0.0527s/iter; left time: 622.7475s\n",
      "\titers: 200, epoch: 48 | loss: 0.0608316\n",
      "\tspeed: 0.0285s/iter; left time: 333.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 225 | Train Loss: 0.0573581 Vali Loss: 0.0700874 Test Loss: 0.0793788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0570433\n",
      "\tspeed: 0.0465s/iter; left time: 538.8687s\n",
      "\titers: 200, epoch: 49 | loss: 0.0553163\n",
      "\tspeed: 0.0188s/iter; left time: 216.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0573690 Vali Loss: 0.0700815 Test Loss: 0.0793844\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0559578\n",
      "\tspeed: 0.0503s/iter; left time: 572.5681s\n",
      "\titers: 200, epoch: 50 | loss: 0.0611283\n",
      "\tspeed: 0.0302s/iter; left time: 340.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 225 | Train Loss: 0.0573608 Vali Loss: 0.0700669 Test Loss: 0.0792996\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0546972\n",
      "\tspeed: 0.0510s/iter; left time: 568.5301s\n",
      "\titers: 200, epoch: 51 | loss: 0.0589048\n",
      "\tspeed: 0.0247s/iter; left time: 273.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0573474 Vali Loss: 0.0700608 Test Loss: 0.0793011\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0557716\n",
      "\tspeed: 0.0488s/iter; left time: 532.8271s\n",
      "\titers: 200, epoch: 52 | loss: 0.0602678\n",
      "\tspeed: 0.0254s/iter; left time: 274.5286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0573041 Vali Loss: 0.0700850 Test Loss: 0.0793761\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018991485238075256, rmse:0.1378096044063568, mae:0.07933271676301956, rse:0.5330842137336731\n",
      "Intermediate time for FR and pred_len 96: 00h:14m:24.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1272520\n",
      "\tspeed: 0.0492s/iter; left time: 1101.5652s\n",
      "\titers: 200, epoch: 1 | loss: 0.1139134\n",
      "\tspeed: 0.0240s/iter; left time: 536.2550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 225 | Train Loss: 0.1276170 Vali Loss: 0.1304395 Test Loss: 0.1474907\n",
      "Validation loss decreased (inf --> 0.130440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0772742\n",
      "\tspeed: 0.0501s/iter; left time: 1111.2304s\n",
      "\titers: 200, epoch: 2 | loss: 0.0683886\n",
      "\tspeed: 0.0213s/iter; left time: 470.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 225 | Train Loss: 0.0839309 Vali Loss: 0.0828477 Test Loss: 0.0916202\n",
      "Validation loss decreased (0.130440 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0726576\n",
      "\tspeed: 0.0470s/iter; left time: 1030.6752s\n",
      "\titers: 200, epoch: 3 | loss: 0.0670449\n",
      "\tspeed: 0.0214s/iter; left time: 466.5992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 225 | Train Loss: 0.0717557 Vali Loss: 0.0794046 Test Loss: 0.0888894\n",
      "Validation loss decreased (0.082848 --> 0.079405).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0673546\n",
      "\tspeed: 0.0447s/iter; left time: 970.9455s\n",
      "\titers: 200, epoch: 4 | loss: 0.0745090\n",
      "\tspeed: 0.0269s/iter; left time: 581.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 225 | Train Loss: 0.0693919 Vali Loss: 0.0777480 Test Loss: 0.0877899\n",
      "Validation loss decreased (0.079405 --> 0.077748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0681390\n",
      "\tspeed: 0.0503s/iter; left time: 1081.6265s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653466\n",
      "\tspeed: 0.0202s/iter; left time: 433.0355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 225 | Train Loss: 0.0677026 Vali Loss: 0.0764982 Test Loss: 0.0866170\n",
      "Validation loss decreased (0.077748 --> 0.076498).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0675271\n",
      "\tspeed: 0.0541s/iter; left time: 1151.7150s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634571\n",
      "\tspeed: 0.0293s/iter; left time: 620.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 225 | Train Loss: 0.0665270 Vali Loss: 0.0759238 Test Loss: 0.0860975\n",
      "Validation loss decreased (0.076498 --> 0.075924).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0627982\n",
      "\tspeed: 0.0459s/iter; left time: 966.3228s\n",
      "\titers: 200, epoch: 7 | loss: 0.0680622\n",
      "\tspeed: 0.0213s/iter; left time: 446.3492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0657958 Vali Loss: 0.0757242 Test Loss: 0.0859290\n",
      "Validation loss decreased (0.075924 --> 0.075724).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0685889\n",
      "\tspeed: 0.0441s/iter; left time: 919.0819s\n",
      "\titers: 200, epoch: 8 | loss: 0.0655987\n",
      "\tspeed: 0.0221s/iter; left time: 458.5884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0653262 Vali Loss: 0.0755243 Test Loss: 0.0856274\n",
      "Validation loss decreased (0.075724 --> 0.075524).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0654939\n",
      "\tspeed: 0.0492s/iter; left time: 1014.3947s\n",
      "\titers: 200, epoch: 9 | loss: 0.0621993\n",
      "\tspeed: 0.0216s/iter; left time: 443.1129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 225 | Train Loss: 0.0648884 Vali Loss: 0.0751519 Test Loss: 0.0856586\n",
      "Validation loss decreased (0.075524 --> 0.075152).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0643409\n",
      "\tspeed: 0.0482s/iter; left time: 982.9063s\n",
      "\titers: 200, epoch: 10 | loss: 0.0636073\n",
      "\tspeed: 0.0191s/iter; left time: 387.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0645998 Vali Loss: 0.0750313 Test Loss: 0.0854118\n",
      "Validation loss decreased (0.075152 --> 0.075031).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0610782\n",
      "\tspeed: 0.0507s/iter; left time: 1020.8416s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642931\n",
      "\tspeed: 0.0244s/iter; left time: 489.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 225 | Train Loss: 0.0643136 Vali Loss: 0.0749084 Test Loss: 0.0854673\n",
      "Validation loss decreased (0.075031 --> 0.074908).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0623670\n",
      "\tspeed: 0.0474s/iter; left time: 944.3121s\n",
      "\titers: 200, epoch: 12 | loss: 0.0672583\n",
      "\tspeed: 0.0233s/iter; left time: 461.5854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 225 | Train Loss: 0.0640396 Vali Loss: 0.0749552 Test Loss: 0.0856013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0622854\n",
      "\tspeed: 0.0489s/iter; left time: 963.3810s\n",
      "\titers: 200, epoch: 13 | loss: 0.0659144\n",
      "\tspeed: 0.0277s/iter; left time: 542.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0638592 Vali Loss: 0.0748083 Test Loss: 0.0855789\n",
      "Validation loss decreased (0.074908 --> 0.074808).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0620585\n",
      "\tspeed: 0.0479s/iter; left time: 932.4632s\n",
      "\titers: 200, epoch: 14 | loss: 0.0654317\n",
      "\tspeed: 0.0222s/iter; left time: 430.8096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 225 | Train Loss: 0.0636821 Vali Loss: 0.0747042 Test Loss: 0.0855131\n",
      "Validation loss decreased (0.074808 --> 0.074704).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0631975\n",
      "\tspeed: 0.0508s/iter; left time: 977.2015s\n",
      "\titers: 200, epoch: 15 | loss: 0.0654471\n",
      "\tspeed: 0.0243s/iter; left time: 465.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 225 | Train Loss: 0.0635583 Vali Loss: 0.0747427 Test Loss: 0.0856473\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0613949\n",
      "\tspeed: 0.0538s/iter; left time: 1022.7058s\n",
      "\titers: 200, epoch: 16 | loss: 0.0665923\n",
      "\tspeed: 0.0234s/iter; left time: 442.3252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0633783 Vali Loss: 0.0747351 Test Loss: 0.0856458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0659078\n",
      "\tspeed: 0.0548s/iter; left time: 1029.4383s\n",
      "\titers: 200, epoch: 17 | loss: 0.0635712\n",
      "\tspeed: 0.0291s/iter; left time: 543.3666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0632849 Vali Loss: 0.0746098 Test Loss: 0.0856807\n",
      "Validation loss decreased (0.074704 --> 0.074610).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0638385\n",
      "\tspeed: 0.0540s/iter; left time: 1003.2143s\n",
      "\titers: 200, epoch: 18 | loss: 0.0646904\n",
      "\tspeed: 0.0318s/iter; left time: 588.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 225 | Train Loss: 0.0632165 Vali Loss: 0.0746178 Test Loss: 0.0858439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0635223\n",
      "\tspeed: 0.0513s/iter; left time: 941.2106s\n",
      "\titers: 200, epoch: 19 | loss: 0.0610002\n",
      "\tspeed: 0.0265s/iter; left time: 483.1220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 225 | Train Loss: 0.0631096 Vali Loss: 0.0746138 Test Loss: 0.0857874\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0613484\n",
      "\tspeed: 0.0492s/iter; left time: 892.2471s\n",
      "\titers: 200, epoch: 20 | loss: 0.0664193\n",
      "\tspeed: 0.0285s/iter; left time: 513.5429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 225 | Train Loss: 0.0630244 Vali Loss: 0.0746466 Test Loss: 0.0857259\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0656793\n",
      "\tspeed: 0.0478s/iter; left time: 856.4265s\n",
      "\titers: 200, epoch: 21 | loss: 0.0620232\n",
      "\tspeed: 0.0270s/iter; left time: 481.2618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 225 | Train Loss: 0.0629531 Vali Loss: 0.0745882 Test Loss: 0.0856962\n",
      "Validation loss decreased (0.074610 --> 0.074588).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0627351\n",
      "\tspeed: 0.0517s/iter; left time: 914.3328s\n",
      "\titers: 200, epoch: 22 | loss: 0.0617253\n",
      "\tspeed: 0.0257s/iter; left time: 451.8136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 225 | Train Loss: 0.0628690 Vali Loss: 0.0744990 Test Loss: 0.0857268\n",
      "Validation loss decreased (0.074588 --> 0.074499).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0635282\n",
      "\tspeed: 0.0510s/iter; left time: 889.9966s\n",
      "\titers: 200, epoch: 23 | loss: 0.0617497\n",
      "\tspeed: 0.0231s/iter; left time: 400.0864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0627902 Vali Loss: 0.0745341 Test Loss: 0.0856929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0596462\n",
      "\tspeed: 0.0512s/iter; left time: 882.2671s\n",
      "\titers: 200, epoch: 24 | loss: 0.0616790\n",
      "\tspeed: 0.0272s/iter; left time: 466.0478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0627450 Vali Loss: 0.0746024 Test Loss: 0.0857222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0621714\n",
      "\tspeed: 0.0543s/iter; left time: 922.7509s\n",
      "\titers: 200, epoch: 25 | loss: 0.0623515\n",
      "\tspeed: 0.0305s/iter; left time: 514.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 225 | Train Loss: 0.0626844 Vali Loss: 0.0744575 Test Loss: 0.0859434\n",
      "Validation loss decreased (0.074499 --> 0.074457).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0606405\n",
      "\tspeed: 0.0497s/iter; left time: 833.4542s\n",
      "\titers: 200, epoch: 26 | loss: 0.0639716\n",
      "\tspeed: 0.0273s/iter; left time: 454.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0626402 Vali Loss: 0.0744846 Test Loss: 0.0857622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0605102\n",
      "\tspeed: 0.0492s/iter; left time: 814.8225s\n",
      "\titers: 200, epoch: 27 | loss: 0.0630375\n",
      "\tspeed: 0.0220s/iter; left time: 362.4909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 225 | Train Loss: 0.0626157 Vali Loss: 0.0744742 Test Loss: 0.0858825\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0621221\n",
      "\tspeed: 0.0460s/iter; left time: 751.6802s\n",
      "\titers: 200, epoch: 28 | loss: 0.0587539\n",
      "\tspeed: 0.0286s/iter; left time: 464.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0625750 Vali Loss: 0.0745418 Test Loss: 0.0858210\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0625541\n",
      "\tspeed: 0.0584s/iter; left time: 940.5929s\n",
      "\titers: 200, epoch: 29 | loss: 0.0623563\n",
      "\tspeed: 0.0256s/iter; left time: 408.8591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0625338 Vali Loss: 0.0744981 Test Loss: 0.0858277\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0661957\n",
      "\tspeed: 0.0467s/iter; left time: 740.7239s\n",
      "\titers: 200, epoch: 30 | loss: 0.0639525\n",
      "\tspeed: 0.0234s/iter; left time: 369.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 225 | Train Loss: 0.0625691 Vali Loss: 0.0744574 Test Loss: 0.0858844\n",
      "Validation loss decreased (0.074457 --> 0.074457).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0596946\n",
      "\tspeed: 0.0532s/iter; left time: 833.3101s\n",
      "\titers: 200, epoch: 31 | loss: 0.0621399\n",
      "\tspeed: 0.0269s/iter; left time: 418.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.0625227 Vali Loss: 0.0745119 Test Loss: 0.0858060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0618315\n",
      "\tspeed: 0.0503s/iter; left time: 775.1976s\n",
      "\titers: 200, epoch: 32 | loss: 0.0648636\n",
      "\tspeed: 0.0241s/iter; left time: 369.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0624774 Vali Loss: 0.0744580 Test Loss: 0.0859242\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0618293\n",
      "\tspeed: 0.0489s/iter; left time: 743.9601s\n",
      "\titers: 200, epoch: 33 | loss: 0.0698456\n",
      "\tspeed: 0.0279s/iter; left time: 421.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0624404 Vali Loss: 0.0744743 Test Loss: 0.0858578\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0602348\n",
      "\tspeed: 0.0474s/iter; left time: 710.4054s\n",
      "\titers: 200, epoch: 34 | loss: 0.0632259\n",
      "\tspeed: 0.0262s/iter; left time: 389.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 225 | Train Loss: 0.0624635 Vali Loss: 0.0745623 Test Loss: 0.0858491\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0614640\n",
      "\tspeed: 0.0456s/iter; left time: 672.8144s\n",
      "\titers: 200, epoch: 35 | loss: 0.0617883\n",
      "\tspeed: 0.0226s/iter; left time: 331.6580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 225 | Train Loss: 0.0624872 Vali Loss: 0.0745251 Test Loss: 0.0858337\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0650040\n",
      "\tspeed: 0.0510s/iter; left time: 740.1499s\n",
      "\titers: 200, epoch: 36 | loss: 0.0643411\n",
      "\tspeed: 0.0277s/iter; left time: 398.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 225 | Train Loss: 0.0624353 Vali Loss: 0.0746154 Test Loss: 0.0858895\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0628083\n",
      "\tspeed: 0.0474s/iter; left time: 678.1016s\n",
      "\titers: 200, epoch: 37 | loss: 0.0638829\n",
      "\tspeed: 0.0210s/iter; left time: 298.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0624339 Vali Loss: 0.0744218 Test Loss: 0.0858261\n",
      "Validation loss decreased (0.074457 --> 0.074422).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0617154\n",
      "\tspeed: 0.0473s/iter; left time: 666.3509s\n",
      "\titers: 200, epoch: 38 | loss: 0.0624265\n",
      "\tspeed: 0.0191s/iter; left time: 267.0454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0623945 Vali Loss: 0.0745134 Test Loss: 0.0858380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0633624\n",
      "\tspeed: 0.0533s/iter; left time: 738.4684s\n",
      "\titers: 200, epoch: 39 | loss: 0.0634164\n",
      "\tspeed: 0.0320s/iter; left time: 440.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 225 | Train Loss: 0.0623897 Vali Loss: 0.0745301 Test Loss: 0.0859188\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0604515\n",
      "\tspeed: 0.0538s/iter; left time: 733.2661s\n",
      "\titers: 200, epoch: 40 | loss: 0.0654750\n",
      "\tspeed: 0.0271s/iter; left time: 366.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 225 | Train Loss: 0.0623177 Vali Loss: 0.0744232 Test Loss: 0.0858311\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0626954\n",
      "\tspeed: 0.0497s/iter; left time: 666.4850s\n",
      "\titers: 200, epoch: 41 | loss: 0.0635799\n",
      "\tspeed: 0.0300s/iter; left time: 398.7194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 225 | Train Loss: 0.0623073 Vali Loss: 0.0744998 Test Loss: 0.0858700\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0620622\n",
      "\tspeed: 0.0491s/iter; left time: 647.1998s\n",
      "\titers: 200, epoch: 42 | loss: 0.0633982\n",
      "\tspeed: 0.0269s/iter; left time: 351.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 225 | Train Loss: 0.0623295 Vali Loss: 0.0744531 Test Loss: 0.0858385\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0635427\n",
      "\tspeed: 0.0539s/iter; left time: 697.7081s\n",
      "\titers: 200, epoch: 43 | loss: 0.0640768\n",
      "\tspeed: 0.0264s/iter; left time: 339.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 225 | Train Loss: 0.0623399 Vali Loss: 0.0745088 Test Loss: 0.0858960\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0627989\n",
      "\tspeed: 0.0455s/iter; left time: 578.7728s\n",
      "\titers: 200, epoch: 44 | loss: 0.0654221\n",
      "\tspeed: 0.0256s/iter; left time: 323.1330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 225 | Train Loss: 0.0623654 Vali Loss: 0.0744741 Test Loss: 0.0858343\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0631965\n",
      "\tspeed: 0.0537s/iter; left time: 671.3306s\n",
      "\titers: 200, epoch: 45 | loss: 0.0595206\n",
      "\tspeed: 0.0276s/iter; left time: 341.8205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0623582 Vali Loss: 0.0745196 Test Loss: 0.0859488\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0618657\n",
      "\tspeed: 0.0501s/iter; left time: 614.9053s\n",
      "\titers: 200, epoch: 46 | loss: 0.0618082\n",
      "\tspeed: 0.0288s/iter; left time: 350.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0623630 Vali Loss: 0.0744667 Test Loss: 0.0858532\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0612222\n",
      "\tspeed: 0.0483s/iter; left time: 582.4565s\n",
      "\titers: 200, epoch: 47 | loss: 0.0634084\n",
      "\tspeed: 0.0282s/iter; left time: 336.6874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 225 | Train Loss: 0.0623304 Vali Loss: 0.0743896 Test Loss: 0.0858907\n",
      "Validation loss decreased (0.074422 --> 0.074390).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0600213\n",
      "\tspeed: 0.0463s/iter; left time: 547.6210s\n",
      "\titers: 200, epoch: 48 | loss: 0.0635485\n",
      "\tspeed: 0.0218s/iter; left time: 255.9984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 225 | Train Loss: 0.0623316 Vali Loss: 0.0745217 Test Loss: 0.0859320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0597138\n",
      "\tspeed: 0.0468s/iter; left time: 543.1816s\n",
      "\titers: 200, epoch: 49 | loss: 0.0602840\n",
      "\tspeed: 0.0246s/iter; left time: 282.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 225 | Train Loss: 0.0622687 Vali Loss: 0.0744689 Test Loss: 0.0859321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0644672\n",
      "\tspeed: 0.0547s/iter; left time: 622.2777s\n",
      "\titers: 200, epoch: 50 | loss: 0.0601074\n",
      "\tspeed: 0.0278s/iter; left time: 313.1249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 225 | Train Loss: 0.0623085 Vali Loss: 0.0744889 Test Loss: 0.0859750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0590142\n",
      "\tspeed: 0.0469s/iter; left time: 522.4444s\n",
      "\titers: 200, epoch: 51 | loss: 0.0604234\n",
      "\tspeed: 0.0206s/iter; left time: 227.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0623346 Vali Loss: 0.0745170 Test Loss: 0.0859061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0625177\n",
      "\tspeed: 0.0490s/iter; left time: 535.5851s\n",
      "\titers: 200, epoch: 52 | loss: 0.0613102\n",
      "\tspeed: 0.0248s/iter; left time: 268.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0623311 Vali Loss: 0.0744508 Test Loss: 0.0859454\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0623345\n",
      "\tspeed: 0.0513s/iter; left time: 548.7204s\n",
      "\titers: 200, epoch: 53 | loss: 0.0620558\n",
      "\tspeed: 0.0272s/iter; left time: 288.3595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0623070 Vali Loss: 0.0744105 Test Loss: 0.0859452\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0626286\n",
      "\tspeed: 0.0458s/iter; left time: 479.8098s\n",
      "\titers: 200, epoch: 54 | loss: 0.0602639\n",
      "\tspeed: 0.0213s/iter; left time: 220.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 225 | Train Loss: 0.0622840 Vali Loss: 0.0744894 Test Loss: 0.0858701\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0637947\n",
      "\tspeed: 0.0510s/iter; left time: 522.4412s\n",
      "\titers: 200, epoch: 55 | loss: 0.0634702\n",
      "\tspeed: 0.0207s/iter; left time: 209.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 225 | Train Loss: 0.0623053 Vali Loss: 0.0744373 Test Loss: 0.0858628\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0606350\n",
      "\tspeed: 0.0500s/iter; left time: 501.1912s\n",
      "\titers: 200, epoch: 56 | loss: 0.0630527\n",
      "\tspeed: 0.0237s/iter; left time: 235.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 225 | Train Loss: 0.0623080 Vali Loss: 0.0744589 Test Loss: 0.0859321\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0608659\n",
      "\tspeed: 0.0516s/iter; left time: 505.3181s\n",
      "\titers: 200, epoch: 57 | loss: 0.0651965\n",
      "\tspeed: 0.0244s/iter; left time: 236.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0622864 Vali Loss: 0.0745124 Test Loss: 0.0859003\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020789824426174164, rmse:0.14418676495552063, mae:0.08589069545269012, rse:0.5584490299224854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1283359\n",
      "\tspeed: 0.0253s/iter; left time: 567.8639s\n",
      "\titers: 200, epoch: 1 | loss: 0.1182079\n",
      "\tspeed: 0.0241s/iter; left time: 536.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 225 | Train Loss: 0.1275120 Vali Loss: 0.1307549 Test Loss: 0.1478369\n",
      "Validation loss decreased (inf --> 0.130755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0830578\n",
      "\tspeed: 0.0536s/iter; left time: 1188.3188s\n",
      "\titers: 200, epoch: 2 | loss: 0.0782976\n",
      "\tspeed: 0.0232s/iter; left time: 513.0921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 225 | Train Loss: 0.0844567 Vali Loss: 0.0833374 Test Loss: 0.0920598\n",
      "Validation loss decreased (0.130755 --> 0.083337).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0738854\n",
      "\tspeed: 0.0475s/iter; left time: 1042.2190s\n",
      "\titers: 200, epoch: 3 | loss: 0.0730405\n",
      "\tspeed: 0.0205s/iter; left time: 448.3451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 225 | Train Loss: 0.0719282 Vali Loss: 0.0796686 Test Loss: 0.0888616\n",
      "Validation loss decreased (0.083337 --> 0.079669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0686242\n",
      "\tspeed: 0.0538s/iter; left time: 1168.8054s\n",
      "\titers: 200, epoch: 4 | loss: 0.0633135\n",
      "\tspeed: 0.0308s/iter; left time: 665.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 225 | Train Loss: 0.0690934 Vali Loss: 0.0779210 Test Loss: 0.0876197\n",
      "Validation loss decreased (0.079669 --> 0.077921).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0696057\n",
      "\tspeed: 0.0542s/iter; left time: 1166.2125s\n",
      "\titers: 200, epoch: 5 | loss: 0.0686394\n",
      "\tspeed: 0.0275s/iter; left time: 588.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 225 | Train Loss: 0.0673277 Vali Loss: 0.0770012 Test Loss: 0.0867868\n",
      "Validation loss decreased (0.077921 --> 0.077001).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0645938\n",
      "\tspeed: 0.0586s/iter; left time: 1247.3115s\n",
      "\titers: 200, epoch: 6 | loss: 0.0635069\n",
      "\tspeed: 0.0252s/iter; left time: 533.0007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 225 | Train Loss: 0.0663026 Vali Loss: 0.0762333 Test Loss: 0.0860183\n",
      "Validation loss decreased (0.077001 --> 0.076233).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0630857\n",
      "\tspeed: 0.0557s/iter; left time: 1172.5905s\n",
      "\titers: 200, epoch: 7 | loss: 0.0592810\n",
      "\tspeed: 0.0300s/iter; left time: 628.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 225 | Train Loss: 0.0656490 Vali Loss: 0.0758989 Test Loss: 0.0859655\n",
      "Validation loss decreased (0.076233 --> 0.075899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0623031\n",
      "\tspeed: 0.0531s/iter; left time: 1106.6912s\n",
      "\titers: 200, epoch: 8 | loss: 0.0678525\n",
      "\tspeed: 0.0237s/iter; left time: 490.8001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0652322 Vali Loss: 0.0758925 Test Loss: 0.0854810\n",
      "Validation loss decreased (0.075899 --> 0.075892).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0667703\n",
      "\tspeed: 0.0525s/iter; left time: 1080.7308s\n",
      "\titers: 200, epoch: 9 | loss: 0.0680243\n",
      "\tspeed: 0.0266s/iter; left time: 546.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0648445 Vali Loss: 0.0756965 Test Loss: 0.0852528\n",
      "Validation loss decreased (0.075892 --> 0.075697).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0628252\n",
      "\tspeed: 0.0517s/iter; left time: 1053.5825s\n",
      "\titers: 200, epoch: 10 | loss: 0.0643737\n",
      "\tspeed: 0.0204s/iter; left time: 414.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 225 | Train Loss: 0.0644856 Vali Loss: 0.0754460 Test Loss: 0.0854238\n",
      "Validation loss decreased (0.075697 --> 0.075446).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0658455\n",
      "\tspeed: 0.0526s/iter; left time: 1060.0858s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642555\n",
      "\tspeed: 0.0284s/iter; left time: 569.6450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 225 | Train Loss: 0.0642728 Vali Loss: 0.0753982 Test Loss: 0.0853674\n",
      "Validation loss decreased (0.075446 --> 0.075398).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0610631\n",
      "\tspeed: 0.0514s/iter; left time: 1023.2376s\n",
      "\titers: 200, epoch: 12 | loss: 0.0644557\n",
      "\tspeed: 0.0273s/iter; left time: 542.0686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 225 | Train Loss: 0.0640375 Vali Loss: 0.0751443 Test Loss: 0.0850488\n",
      "Validation loss decreased (0.075398 --> 0.075144).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0640642\n",
      "\tspeed: 0.0513s/iter; left time: 1010.9889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0608970\n",
      "\tspeed: 0.0247s/iter; left time: 484.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0638459 Vali Loss: 0.0751370 Test Loss: 0.0852346\n",
      "Validation loss decreased (0.075144 --> 0.075137).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0636537\n",
      "\tspeed: 0.0544s/iter; left time: 1059.7232s\n",
      "\titers: 200, epoch: 14 | loss: 0.0641293\n",
      "\tspeed: 0.0259s/iter; left time: 500.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 225 | Train Loss: 0.0636891 Vali Loss: 0.0751352 Test Loss: 0.0852650\n",
      "Validation loss decreased (0.075137 --> 0.075135).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0652704\n",
      "\tspeed: 0.0478s/iter; left time: 921.0010s\n",
      "\titers: 200, epoch: 15 | loss: 0.0603209\n",
      "\tspeed: 0.0259s/iter; left time: 496.3842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 225 | Train Loss: 0.0634916 Vali Loss: 0.0751293 Test Loss: 0.0853076\n",
      "Validation loss decreased (0.075135 --> 0.075129).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0600324\n",
      "\tspeed: 0.0561s/iter; left time: 1066.4254s\n",
      "\titers: 200, epoch: 16 | loss: 0.0660657\n",
      "\tspeed: 0.0233s/iter; left time: 441.8419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 225 | Train Loss: 0.0633372 Vali Loss: 0.0751984 Test Loss: 0.0854423\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0680200\n",
      "\tspeed: 0.0532s/iter; left time: 1000.0359s\n",
      "\titers: 200, epoch: 17 | loss: 0.0648509\n",
      "\tspeed: 0.0287s/iter; left time: 536.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 225 | Train Loss: 0.0632565 Vali Loss: 0.0749803 Test Loss: 0.0854133\n",
      "Validation loss decreased (0.075129 --> 0.074980).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0647032\n",
      "\tspeed: 0.0552s/iter; left time: 1025.1044s\n",
      "\titers: 200, epoch: 18 | loss: 0.0598428\n",
      "\tspeed: 0.0306s/iter; left time: 566.0337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 225 | Train Loss: 0.0631523 Vali Loss: 0.0749387 Test Loss: 0.0854822\n",
      "Validation loss decreased (0.074980 --> 0.074939).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0668046\n",
      "\tspeed: 0.0576s/iter; left time: 1056.8033s\n",
      "\titers: 200, epoch: 19 | loss: 0.0596661\n",
      "\tspeed: 0.0292s/iter; left time: 532.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 225 | Train Loss: 0.0630589 Vali Loss: 0.0750222 Test Loss: 0.0852431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0618846\n",
      "\tspeed: 0.0544s/iter; left time: 985.2407s\n",
      "\titers: 200, epoch: 20 | loss: 0.0643297\n",
      "\tspeed: 0.0274s/iter; left time: 493.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 225 | Train Loss: 0.0629882 Vali Loss: 0.0749454 Test Loss: 0.0854134\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0642228\n",
      "\tspeed: 0.0521s/iter; left time: 932.0568s\n",
      "\titers: 200, epoch: 21 | loss: 0.0603757\n",
      "\tspeed: 0.0299s/iter; left time: 532.6462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 225 | Train Loss: 0.0629317 Vali Loss: 0.0750512 Test Loss: 0.0852952\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0606580\n",
      "\tspeed: 0.0556s/iter; left time: 982.8903s\n",
      "\titers: 200, epoch: 22 | loss: 0.0608251\n",
      "\tspeed: 0.0271s/iter; left time: 476.8428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0628622 Vali Loss: 0.0750110 Test Loss: 0.0853213\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0661985\n",
      "\tspeed: 0.0522s/iter; left time: 911.2059s\n",
      "\titers: 200, epoch: 23 | loss: 0.0606835\n",
      "\tspeed: 0.0288s/iter; left time: 499.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0627658 Vali Loss: 0.0750056 Test Loss: 0.0853894\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0657220\n",
      "\tspeed: 0.0499s/iter; left time: 859.2146s\n",
      "\titers: 200, epoch: 24 | loss: 0.0632927\n",
      "\tspeed: 0.0215s/iter; left time: 368.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 225 | Train Loss: 0.0627181 Vali Loss: 0.0750028 Test Loss: 0.0853932\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0642134\n",
      "\tspeed: 0.0522s/iter; left time: 887.1616s\n",
      "\titers: 200, epoch: 25 | loss: 0.0661637\n",
      "\tspeed: 0.0252s/iter; left time: 425.0814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 225 | Train Loss: 0.0626534 Vali Loss: 0.0749225 Test Loss: 0.0854760\n",
      "Validation loss decreased (0.074939 --> 0.074923).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0633271\n",
      "\tspeed: 0.0608s/iter; left time: 1020.3258s\n",
      "\titers: 200, epoch: 26 | loss: 0.0659848\n",
      "\tspeed: 0.0302s/iter; left time: 504.2699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 225 | Train Loss: 0.0625923 Vali Loss: 0.0750195 Test Loss: 0.0855144\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0615869\n",
      "\tspeed: 0.0571s/iter; left time: 945.8798s\n",
      "\titers: 200, epoch: 27 | loss: 0.0625416\n",
      "\tspeed: 0.0302s/iter; left time: 496.9428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 225 | Train Loss: 0.0625670 Vali Loss: 0.0749205 Test Loss: 0.0854166\n",
      "Validation loss decreased (0.074923 --> 0.074920).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0610086\n",
      "\tspeed: 0.0563s/iter; left time: 919.6652s\n",
      "\titers: 200, epoch: 28 | loss: 0.0594363\n",
      "\tspeed: 0.0270s/iter; left time: 438.3991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0625560 Vali Loss: 0.0749292 Test Loss: 0.0854552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0659877\n",
      "\tspeed: 0.0512s/iter; left time: 824.3693s\n",
      "\titers: 200, epoch: 29 | loss: 0.0670725\n",
      "\tspeed: 0.0267s/iter; left time: 427.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 225 | Train Loss: 0.0625343 Vali Loss: 0.0749282 Test Loss: 0.0854419\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0629614\n",
      "\tspeed: 0.0547s/iter; left time: 867.9643s\n",
      "\titers: 200, epoch: 30 | loss: 0.0623289\n",
      "\tspeed: 0.0320s/iter; left time: 504.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 225 | Train Loss: 0.0625158 Vali Loss: 0.0750068 Test Loss: 0.0855481\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0619467\n",
      "\tspeed: 0.0529s/iter; left time: 827.8931s\n",
      "\titers: 200, epoch: 31 | loss: 0.0611455\n",
      "\tspeed: 0.0338s/iter; left time: 525.0281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 225 | Train Loss: 0.0624699 Vali Loss: 0.0748934 Test Loss: 0.0854585\n",
      "Validation loss decreased (0.074920 --> 0.074893).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0635809\n",
      "\tspeed: 0.0514s/iter; left time: 793.1488s\n",
      "\titers: 200, epoch: 32 | loss: 0.0642294\n",
      "\tspeed: 0.0251s/iter; left time: 384.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 225 | Train Loss: 0.0624576 Vali Loss: 0.0749186 Test Loss: 0.0854044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0611105\n",
      "\tspeed: 0.0558s/iter; left time: 847.7393s\n",
      "\titers: 200, epoch: 33 | loss: 0.0619674\n",
      "\tspeed: 0.0229s/iter; left time: 345.4042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 225 | Train Loss: 0.0623846 Vali Loss: 0.0749059 Test Loss: 0.0854875\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0613588\n",
      "\tspeed: 0.0480s/iter; left time: 719.3883s\n",
      "\titers: 200, epoch: 34 | loss: 0.0637927\n",
      "\tspeed: 0.0273s/iter; left time: 406.7121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0623770 Vali Loss: 0.0749009 Test Loss: 0.0855714\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0653247\n",
      "\tspeed: 0.0487s/iter; left time: 718.1310s\n",
      "\titers: 200, epoch: 35 | loss: 0.0641193\n",
      "\tspeed: 0.0208s/iter; left time: 304.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 225 | Train Loss: 0.0624001 Vali Loss: 0.0749931 Test Loss: 0.0855564\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0618253\n",
      "\tspeed: 0.0563s/iter; left time: 817.7947s\n",
      "\titers: 200, epoch: 36 | loss: 0.0606291\n",
      "\tspeed: 0.0273s/iter; left time: 394.3527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 225 | Train Loss: 0.0624052 Vali Loss: 0.0748966 Test Loss: 0.0855036\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0611519\n",
      "\tspeed: 0.0557s/iter; left time: 797.2574s\n",
      "\titers: 200, epoch: 37 | loss: 0.0656925\n",
      "\tspeed: 0.0257s/iter; left time: 365.1492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0623474 Vali Loss: 0.0749378 Test Loss: 0.0855539\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0610135\n",
      "\tspeed: 0.0491s/iter; left time: 690.7544s\n",
      "\titers: 200, epoch: 38 | loss: 0.0591451\n",
      "\tspeed: 0.0266s/iter; left time: 371.7748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 225 | Train Loss: 0.0623356 Vali Loss: 0.0747937 Test Loss: 0.0855813\n",
      "Validation loss decreased (0.074893 --> 0.074794).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0592215\n",
      "\tspeed: 0.0573s/iter; left time: 792.9953s\n",
      "\titers: 200, epoch: 39 | loss: 0.0593245\n",
      "\tspeed: 0.0242s/iter; left time: 333.3300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 225 | Train Loss: 0.0623109 Vali Loss: 0.0748570 Test Loss: 0.0854844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0583931\n",
      "\tspeed: 0.0539s/iter; left time: 733.9690s\n",
      "\titers: 200, epoch: 40 | loss: 0.0640757\n",
      "\tspeed: 0.0304s/iter; left time: 410.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 225 | Train Loss: 0.0623167 Vali Loss: 0.0748829 Test Loss: 0.0856129\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0629319\n",
      "\tspeed: 0.0576s/iter; left time: 771.7637s\n",
      "\titers: 200, epoch: 41 | loss: 0.0639222\n",
      "\tspeed: 0.0299s/iter; left time: 397.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 225 | Train Loss: 0.0623059 Vali Loss: 0.0749194 Test Loss: 0.0854952\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0605636\n",
      "\tspeed: 0.0492s/iter; left time: 648.6852s\n",
      "\titers: 200, epoch: 42 | loss: 0.0606836\n",
      "\tspeed: 0.0221s/iter; left time: 288.7386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 225 | Train Loss: 0.0622782 Vali Loss: 0.0748565 Test Loss: 0.0855952\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0565898\n",
      "\tspeed: 0.0493s/iter; left time: 638.6200s\n",
      "\titers: 200, epoch: 43 | loss: 0.0611770\n",
      "\tspeed: 0.0267s/iter; left time: 343.0978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 225 | Train Loss: 0.0622456 Vali Loss: 0.0748971 Test Loss: 0.0854784\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0642892\n",
      "\tspeed: 0.0528s/iter; left time: 672.1934s\n",
      "\titers: 200, epoch: 44 | loss: 0.0683638\n",
      "\tspeed: 0.0276s/iter; left time: 348.4717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0622681 Vali Loss: 0.0748256 Test Loss: 0.0855006\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0622593\n",
      "\tspeed: 0.0586s/iter; left time: 732.2586s\n",
      "\titers: 200, epoch: 45 | loss: 0.0605665\n",
      "\tspeed: 0.0210s/iter; left time: 260.8392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 225 | Train Loss: 0.0622936 Vali Loss: 0.0749247 Test Loss: 0.0855703\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0600760\n",
      "\tspeed: 0.0542s/iter; left time: 665.7845s\n",
      "\titers: 200, epoch: 46 | loss: 0.0623929\n",
      "\tspeed: 0.0317s/iter; left time: 385.6824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 225 | Train Loss: 0.0622719 Vali Loss: 0.0749354 Test Loss: 0.0855073\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0639851\n",
      "\tspeed: 0.0575s/iter; left time: 693.2281s\n",
      "\titers: 200, epoch: 47 | loss: 0.0602245\n",
      "\tspeed: 0.0274s/iter; left time: 327.8524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 225 | Train Loss: 0.0622702 Vali Loss: 0.0748706 Test Loss: 0.0856402\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0641665\n",
      "\tspeed: 0.0577s/iter; left time: 682.3878s\n",
      "\titers: 200, epoch: 48 | loss: 0.0633397\n",
      "\tspeed: 0.0325s/iter; left time: 380.8967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 225 | Train Loss: 0.0622914 Vali Loss: 0.0749426 Test Loss: 0.0856176\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02059786766767502, rmse:0.1435195654630661, mae:0.08558127284049988, rse:0.5558649301528931\n",
      "Intermediate time for FR and pred_len 168: 00h:13m:45.48s\n",
      "Intermediate time for FR: 00h:43m:36.30s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1722920\n",
      "\tspeed: 0.0466s/iter; left time: 1047.7932s\n",
      "\titers: 200, epoch: 1 | loss: 0.1587587\n",
      "\tspeed: 0.0224s/iter; left time: 501.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 226 | Train Loss: 0.1734702 Vali Loss: 0.1441364 Test Loss: 0.1518556\n",
      "Validation loss decreased (inf --> 0.144136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0838304\n",
      "\tspeed: 0.0500s/iter; left time: 1114.3519s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688653\n",
      "\tspeed: 0.0273s/iter; left time: 606.4700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0924439 Vali Loss: 0.0667544 Test Loss: 0.0691170\n",
      "Validation loss decreased (0.144136 --> 0.066754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0699428\n",
      "\tspeed: 0.0429s/iter; left time: 945.4149s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663636\n",
      "\tspeed: 0.0254s/iter; left time: 557.5768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 226 | Train Loss: 0.0682073 Vali Loss: 0.0617783 Test Loss: 0.0642480\n",
      "Validation loss decreased (0.066754 --> 0.061778).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0656166\n",
      "\tspeed: 0.0501s/iter; left time: 1093.3949s\n",
      "\titers: 200, epoch: 4 | loss: 0.0616566\n",
      "\tspeed: 0.0250s/iter; left time: 543.5565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 226 | Train Loss: 0.0641598 Vali Loss: 0.0599115 Test Loss: 0.0625490\n",
      "Validation loss decreased (0.061778 --> 0.059912).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0607398\n",
      "\tspeed: 0.0443s/iter; left time: 955.7134s\n",
      "\titers: 200, epoch: 5 | loss: 0.0655872\n",
      "\tspeed: 0.0279s/iter; left time: 598.9986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0618616 Vali Loss: 0.0581040 Test Loss: 0.0608326\n",
      "Validation loss decreased (0.059912 --> 0.058104).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637230\n",
      "\tspeed: 0.0475s/iter; left time: 1015.6593s\n",
      "\titers: 200, epoch: 6 | loss: 0.0615989\n",
      "\tspeed: 0.0289s/iter; left time: 614.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0603513 Vali Loss: 0.0577327 Test Loss: 0.0602143\n",
      "Validation loss decreased (0.058104 --> 0.057733).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0560802\n",
      "\tspeed: 0.0466s/iter; left time: 984.3494s\n",
      "\titers: 200, epoch: 7 | loss: 0.0570829\n",
      "\tspeed: 0.0317s/iter; left time: 667.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 226 | Train Loss: 0.0592524 Vali Loss: 0.0567816 Test Loss: 0.0594649\n",
      "Validation loss decreased (0.057733 --> 0.056782).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0586033\n",
      "\tspeed: 0.0470s/iter; left time: 983.8485s\n",
      "\titers: 200, epoch: 8 | loss: 0.0537227\n",
      "\tspeed: 0.0195s/iter; left time: 406.5318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 226 | Train Loss: 0.0584231 Vali Loss: 0.0563781 Test Loss: 0.0590088\n",
      "Validation loss decreased (0.056782 --> 0.056378).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0586339\n",
      "\tspeed: 0.0498s/iter; left time: 1029.9858s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584896\n",
      "\tspeed: 0.0298s/iter; left time: 614.0062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 226 | Train Loss: 0.0579411 Vali Loss: 0.0559900 Test Loss: 0.0586146\n",
      "Validation loss decreased (0.056378 --> 0.055990).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0551709\n",
      "\tspeed: 0.0517s/iter; left time: 1057.3368s\n",
      "\titers: 200, epoch: 10 | loss: 0.0587578\n",
      "\tspeed: 0.0208s/iter; left time: 424.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 226 | Train Loss: 0.0574679 Vali Loss: 0.0560114 Test Loss: 0.0584769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0585615\n",
      "\tspeed: 0.0438s/iter; left time: 885.7086s\n",
      "\titers: 200, epoch: 11 | loss: 0.0552630\n",
      "\tspeed: 0.0261s/iter; left time: 525.8740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 226 | Train Loss: 0.0570903 Vali Loss: 0.0556922 Test Loss: 0.0582576\n",
      "Validation loss decreased (0.055990 --> 0.055692).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0560762\n",
      "\tspeed: 0.0485s/iter; left time: 971.5498s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558196\n",
      "\tspeed: 0.0290s/iter; left time: 577.8554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 226 | Train Loss: 0.0568057 Vali Loss: 0.0554588 Test Loss: 0.0579993\n",
      "Validation loss decreased (0.055692 --> 0.055459).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0569666\n",
      "\tspeed: 0.0505s/iter; left time: 998.4718s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555747\n",
      "\tspeed: 0.0255s/iter; left time: 502.0816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0565981 Vali Loss: 0.0552518 Test Loss: 0.0578913\n",
      "Validation loss decreased (0.055459 --> 0.055252).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0558258\n",
      "\tspeed: 0.0509s/iter; left time: 996.5387s\n",
      "\titers: 200, epoch: 14 | loss: 0.0579629\n",
      "\tspeed: 0.0196s/iter; left time: 381.3580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 226 | Train Loss: 0.0563426 Vali Loss: 0.0551944 Test Loss: 0.0578140\n",
      "Validation loss decreased (0.055252 --> 0.055194).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0586618\n",
      "\tspeed: 0.0513s/iter; left time: 992.2145s\n",
      "\titers: 200, epoch: 15 | loss: 0.0583563\n",
      "\tspeed: 0.0296s/iter; left time: 568.8735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 226 | Train Loss: 0.0561090 Vali Loss: 0.0550931 Test Loss: 0.0576744\n",
      "Validation loss decreased (0.055194 --> 0.055093).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0574588\n",
      "\tspeed: 0.0494s/iter; left time: 944.9844s\n",
      "\titers: 200, epoch: 16 | loss: 0.0512447\n",
      "\tspeed: 0.0280s/iter; left time: 531.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 226 | Train Loss: 0.0560246 Vali Loss: 0.0552220 Test Loss: 0.0576568\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0553269\n",
      "\tspeed: 0.0545s/iter; left time: 1028.7640s\n",
      "\titers: 200, epoch: 17 | loss: 0.0531824\n",
      "\tspeed: 0.0291s/iter; left time: 546.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 226 | Train Loss: 0.0558568 Vali Loss: 0.0548910 Test Loss: 0.0575386\n",
      "Validation loss decreased (0.055093 --> 0.054891).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0555530\n",
      "\tspeed: 0.0485s/iter; left time: 905.6786s\n",
      "\titers: 200, epoch: 18 | loss: 0.0592249\n",
      "\tspeed: 0.0299s/iter; left time: 554.4153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 226 | Train Loss: 0.0557835 Vali Loss: 0.0549858 Test Loss: 0.0574695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0562326\n",
      "\tspeed: 0.0516s/iter; left time: 951.0332s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540442\n",
      "\tspeed: 0.0234s/iter; left time: 429.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 226 | Train Loss: 0.0556622 Vali Loss: 0.0548263 Test Loss: 0.0574125\n",
      "Validation loss decreased (0.054891 --> 0.054826).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0553453\n",
      "\tspeed: 0.0493s/iter; left time: 896.8754s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546516\n",
      "\tspeed: 0.0309s/iter; left time: 560.4097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 226 | Train Loss: 0.0555707 Vali Loss: 0.0548711 Test Loss: 0.0573735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0602217\n",
      "\tspeed: 0.0543s/iter; left time: 976.2457s\n",
      "\titers: 200, epoch: 21 | loss: 0.0515214\n",
      "\tspeed: 0.0303s/iter; left time: 542.3735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 226 | Train Loss: 0.0555040 Vali Loss: 0.0547479 Test Loss: 0.0572697\n",
      "Validation loss decreased (0.054826 --> 0.054748).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0548368\n",
      "\tspeed: 0.0490s/iter; left time: 869.7081s\n",
      "\titers: 200, epoch: 22 | loss: 0.0516110\n",
      "\tspeed: 0.0297s/iter; left time: 524.4647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0554181 Vali Loss: 0.0548270 Test Loss: 0.0573799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0535216\n",
      "\tspeed: 0.0572s/iter; left time: 1001.8378s\n",
      "\titers: 200, epoch: 23 | loss: 0.0567808\n",
      "\tspeed: 0.0306s/iter; left time: 532.5706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 226 | Train Loss: 0.0553467 Vali Loss: 0.0547003 Test Loss: 0.0572244\n",
      "Validation loss decreased (0.054748 --> 0.054700).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0522848\n",
      "\tspeed: 0.0513s/iter; left time: 886.9823s\n",
      "\titers: 200, epoch: 24 | loss: 0.0531534\n",
      "\tspeed: 0.0287s/iter; left time: 493.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 226 | Train Loss: 0.0552633 Vali Loss: 0.0546938 Test Loss: 0.0571732\n",
      "Validation loss decreased (0.054700 --> 0.054694).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0584335\n",
      "\tspeed: 0.0545s/iter; left time: 931.1691s\n",
      "\titers: 200, epoch: 25 | loss: 0.0563863\n",
      "\tspeed: 0.0304s/iter; left time: 516.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 226 | Train Loss: 0.0552093 Vali Loss: 0.0546483 Test Loss: 0.0571411\n",
      "Validation loss decreased (0.054694 --> 0.054648).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0581013\n",
      "\tspeed: 0.0514s/iter; left time: 865.4150s\n",
      "\titers: 200, epoch: 26 | loss: 0.0515195\n",
      "\tspeed: 0.0283s/iter; left time: 473.6914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 226 | Train Loss: 0.0551662 Vali Loss: 0.0545866 Test Loss: 0.0570727\n",
      "Validation loss decreased (0.054648 --> 0.054587).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0555983\n",
      "\tspeed: 0.0481s/iter; left time: 799.5362s\n",
      "\titers: 200, epoch: 27 | loss: 0.0571013\n",
      "\tspeed: 0.0303s/iter; left time: 501.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 226 | Train Loss: 0.0551253 Vali Loss: 0.0545346 Test Loss: 0.0570563\n",
      "Validation loss decreased (0.054587 --> 0.054535).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0532165\n",
      "\tspeed: 0.0503s/iter; left time: 824.6423s\n",
      "\titers: 200, epoch: 28 | loss: 0.0537188\n",
      "\tspeed: 0.0241s/iter; left time: 393.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 226 | Train Loss: 0.0550665 Vali Loss: 0.0546836 Test Loss: 0.0571266\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0546076\n",
      "\tspeed: 0.0458s/iter; left time: 740.2816s\n",
      "\titers: 200, epoch: 29 | loss: 0.0585144\n",
      "\tspeed: 0.0245s/iter; left time: 393.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 226 | Train Loss: 0.0550691 Vali Loss: 0.0546326 Test Loss: 0.0570762\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0592289\n",
      "\tspeed: 0.0426s/iter; left time: 679.7488s\n",
      "\titers: 200, epoch: 30 | loss: 0.0554572\n",
      "\tspeed: 0.0330s/iter; left time: 522.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 226 | Train Loss: 0.0550708 Vali Loss: 0.0545608 Test Loss: 0.0570226\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0518227\n",
      "\tspeed: 0.0511s/iter; left time: 803.5668s\n",
      "\titers: 200, epoch: 31 | loss: 0.0575283\n",
      "\tspeed: 0.0294s/iter; left time: 459.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 226 | Train Loss: 0.0550102 Vali Loss: 0.0545234 Test Loss: 0.0570084\n",
      "Validation loss decreased (0.054535 --> 0.054523).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0551268\n",
      "\tspeed: 0.0558s/iter; left time: 864.4731s\n",
      "\titers: 200, epoch: 32 | loss: 0.0559603\n",
      "\tspeed: 0.0302s/iter; left time: 464.1937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 226 | Train Loss: 0.0549271 Vali Loss: 0.0546177 Test Loss: 0.0570088\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0536180\n",
      "\tspeed: 0.0521s/iter; left time: 796.1268s\n",
      "\titers: 200, epoch: 33 | loss: 0.0540531\n",
      "\tspeed: 0.0296s/iter; left time: 448.5280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 226 | Train Loss: 0.0549197 Vali Loss: 0.0544921 Test Loss: 0.0569974\n",
      "Validation loss decreased (0.054523 --> 0.054492).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0579632\n",
      "\tspeed: 0.0514s/iter; left time: 773.7752s\n",
      "\titers: 200, epoch: 34 | loss: 0.0566074\n",
      "\tspeed: 0.0262s/iter; left time: 390.8658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 226 | Train Loss: 0.0549317 Vali Loss: 0.0544925 Test Loss: 0.0569959\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0546267\n",
      "\tspeed: 0.0516s/iter; left time: 764.8886s\n",
      "\titers: 200, epoch: 35 | loss: 0.0580821\n",
      "\tspeed: 0.0243s/iter; left time: 358.0230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0549422 Vali Loss: 0.0544724 Test Loss: 0.0569728\n",
      "Validation loss decreased (0.054492 --> 0.054472).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0530931\n",
      "\tspeed: 0.0505s/iter; left time: 736.4218s\n",
      "\titers: 200, epoch: 36 | loss: 0.0523850\n",
      "\tspeed: 0.0223s/iter; left time: 322.4283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 226 | Train Loss: 0.0548634 Vali Loss: 0.0546212 Test Loss: 0.0570231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0563350\n",
      "\tspeed: 0.0461s/iter; left time: 662.9176s\n",
      "\titers: 200, epoch: 37 | loss: 0.0529748\n",
      "\tspeed: 0.0329s/iter; left time: 468.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 226 | Train Loss: 0.0548978 Vali Loss: 0.0544274 Test Loss: 0.0569539\n",
      "Validation loss decreased (0.054472 --> 0.054427).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0526294\n",
      "\tspeed: 0.0495s/iter; left time: 699.7500s\n",
      "\titers: 200, epoch: 38 | loss: 0.0548050\n",
      "\tspeed: 0.0354s/iter; left time: 496.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 226 | Train Loss: 0.0548673 Vali Loss: 0.0545272 Test Loss: 0.0569506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0569979\n",
      "\tspeed: 0.0497s/iter; left time: 691.1512s\n",
      "\titers: 200, epoch: 39 | loss: 0.0576798\n",
      "\tspeed: 0.0314s/iter; left time: 434.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 226 | Train Loss: 0.0548625 Vali Loss: 0.0545892 Test Loss: 0.0569690\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0517860\n",
      "\tspeed: 0.0542s/iter; left time: 741.9817s\n",
      "\titers: 200, epoch: 40 | loss: 0.0570342\n",
      "\tspeed: 0.0272s/iter; left time: 368.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 226 | Train Loss: 0.0549097 Vali Loss: 0.0545502 Test Loss: 0.0569394\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0541265\n",
      "\tspeed: 0.0490s/iter; left time: 659.3394s\n",
      "\titers: 200, epoch: 41 | loss: 0.0543137\n",
      "\tspeed: 0.0264s/iter; left time: 352.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 226 | Train Loss: 0.0548209 Vali Loss: 0.0545009 Test Loss: 0.0569344\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0553848\n",
      "\tspeed: 0.0529s/iter; left time: 700.2816s\n",
      "\titers: 200, epoch: 42 | loss: 0.0538818\n",
      "\tspeed: 0.0264s/iter; left time: 347.2702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 226 | Train Loss: 0.0548243 Vali Loss: 0.0544250 Test Loss: 0.0569128\n",
      "Validation loss decreased (0.054427 --> 0.054425).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0578758\n",
      "\tspeed: 0.0505s/iter; left time: 657.2047s\n",
      "\titers: 200, epoch: 43 | loss: 0.0521547\n",
      "\tspeed: 0.0264s/iter; left time: 341.3297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 226 | Train Loss: 0.0548192 Vali Loss: 0.0545450 Test Loss: 0.0569434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0543596\n",
      "\tspeed: 0.0520s/iter; left time: 664.4097s\n",
      "\titers: 200, epoch: 44 | loss: 0.0613788\n",
      "\tspeed: 0.0302s/iter; left time: 383.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 226 | Train Loss: 0.0548261 Vali Loss: 0.0545051 Test Loss: 0.0569404\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0508029\n",
      "\tspeed: 0.0467s/iter; left time: 586.5224s\n",
      "\titers: 200, epoch: 45 | loss: 0.0506523\n",
      "\tspeed: 0.0215s/iter; left time: 267.8139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 226 | Train Loss: 0.0547926 Vali Loss: 0.0544245 Test Loss: 0.0569008\n",
      "Validation loss decreased (0.054425 --> 0.054424).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0520498\n",
      "\tspeed: 0.0457s/iter; left time: 563.7957s\n",
      "\titers: 200, epoch: 46 | loss: 0.0523044\n",
      "\tspeed: 0.0221s/iter; left time: 269.7657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 226 | Train Loss: 0.0547682 Vali Loss: 0.0545463 Test Loss: 0.0569156\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0574238\n",
      "\tspeed: 0.0451s/iter; left time: 545.7565s\n",
      "\titers: 200, epoch: 47 | loss: 0.0556269\n",
      "\tspeed: 0.0276s/iter; left time: 331.1451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0547832 Vali Loss: 0.0544947 Test Loss: 0.0569419\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0618061\n",
      "\tspeed: 0.0454s/iter; left time: 539.6410s\n",
      "\titers: 200, epoch: 48 | loss: 0.0510770\n",
      "\tspeed: 0.0298s/iter; left time: 351.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0548322 Vali Loss: 0.0544690 Test Loss: 0.0568793\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0573816\n",
      "\tspeed: 0.0459s/iter; left time: 534.9754s\n",
      "\titers: 200, epoch: 49 | loss: 0.0587271\n",
      "\tspeed: 0.0252s/iter; left time: 291.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 226 | Train Loss: 0.0547939 Vali Loss: 0.0544452 Test Loss: 0.0569674\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0538436\n",
      "\tspeed: 0.0431s/iter; left time: 492.2387s\n",
      "\titers: 200, epoch: 50 | loss: 0.0507912\n",
      "\tspeed: 0.0268s/iter; left time: 303.6785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 226 | Train Loss: 0.0547728 Vali Loss: 0.0544759 Test Loss: 0.0569447\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0565758\n",
      "\tspeed: 0.0428s/iter; left time: 479.3246s\n",
      "\titers: 200, epoch: 51 | loss: 0.0539639\n",
      "\tspeed: 0.0260s/iter; left time: 288.3114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 226 | Train Loss: 0.0547863 Vali Loss: 0.0544789 Test Loss: 0.0569067\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0600716\n",
      "\tspeed: 0.0518s/iter; left time: 568.2397s\n",
      "\titers: 200, epoch: 52 | loss: 0.0530268\n",
      "\tspeed: 0.0310s/iter; left time: 337.3292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 226 | Train Loss: 0.0547739 Vali Loss: 0.0543961 Test Loss: 0.0568873\n",
      "Validation loss decreased (0.054424 --> 0.054396).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0557316\n",
      "\tspeed: 0.0501s/iter; left time: 538.2353s\n",
      "\titers: 200, epoch: 53 | loss: 0.0533673\n",
      "\tspeed: 0.0220s/iter; left time: 233.7975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 226 | Train Loss: 0.0547588 Vali Loss: 0.0544179 Test Loss: 0.0568861\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0528737\n",
      "\tspeed: 0.0453s/iter; left time: 477.1364s\n",
      "\titers: 200, epoch: 54 | loss: 0.0514013\n",
      "\tspeed: 0.0207s/iter; left time: 215.5109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 226 | Train Loss: 0.0547772 Vali Loss: 0.0544544 Test Loss: 0.0569195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0569595\n",
      "\tspeed: 0.0494s/iter; left time: 508.9980s\n",
      "\titers: 200, epoch: 55 | loss: 0.0540732\n",
      "\tspeed: 0.0237s/iter; left time: 241.2489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 226 | Train Loss: 0.0547515 Vali Loss: 0.0544371 Test Loss: 0.0569214\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0545762\n",
      "\tspeed: 0.0452s/iter; left time: 454.9849s\n",
      "\titers: 200, epoch: 56 | loss: 0.0546318\n",
      "\tspeed: 0.0221s/iter; left time: 220.3745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 226 | Train Loss: 0.0547518 Vali Loss: 0.0543805 Test Loss: 0.0568706\n",
      "Validation loss decreased (0.054396 --> 0.054381).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0596362\n",
      "\tspeed: 0.0507s/iter; left time: 499.5512s\n",
      "\titers: 200, epoch: 57 | loss: 0.0530986\n",
      "\tspeed: 0.0297s/iter; left time: 289.4891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 226 | Train Loss: 0.0547073 Vali Loss: 0.0545350 Test Loss: 0.0569560\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0566301\n",
      "\tspeed: 0.0502s/iter; left time: 483.0940s\n",
      "\titers: 200, epoch: 58 | loss: 0.0558193\n",
      "\tspeed: 0.0268s/iter; left time: 255.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.0547780 Vali Loss: 0.0544352 Test Loss: 0.0569023\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0588209\n",
      "\tspeed: 0.0423s/iter; left time: 397.2868s\n",
      "\titers: 200, epoch: 59 | loss: 0.0527758\n",
      "\tspeed: 0.0186s/iter; left time: 172.5327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 226 | Train Loss: 0.0547590 Vali Loss: 0.0545020 Test Loss: 0.0569208\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0533794\n",
      "\tspeed: 0.0433s/iter; left time: 396.5315s\n",
      "\titers: 200, epoch: 60 | loss: 0.0580118\n",
      "\tspeed: 0.0199s/iter; left time: 180.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 226 | Train Loss: 0.0547262 Vali Loss: 0.0543509 Test Loss: 0.0568823\n",
      "Validation loss decreased (0.054381 --> 0.054351).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0560286\n",
      "\tspeed: 0.0508s/iter; left time: 454.0303s\n",
      "\titers: 200, epoch: 61 | loss: 0.0526540\n",
      "\tspeed: 0.0268s/iter; left time: 236.6701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 226 | Train Loss: 0.0547945 Vali Loss: 0.0544580 Test Loss: 0.0569107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0547675\n",
      "\tspeed: 0.0444s/iter; left time: 386.6227s\n",
      "\titers: 200, epoch: 62 | loss: 0.0543976\n",
      "\tspeed: 0.0278s/iter; left time: 239.5605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 226 | Train Loss: 0.0547692 Vali Loss: 0.0543560 Test Loss: 0.0568702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0511734\n",
      "\tspeed: 0.0480s/iter; left time: 407.2850s\n",
      "\titers: 200, epoch: 63 | loss: 0.0591709\n",
      "\tspeed: 0.0257s/iter; left time: 215.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 226 | Train Loss: 0.0547693 Vali Loss: 0.0545519 Test Loss: 0.0569671\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0564905\n",
      "\tspeed: 0.0493s/iter; left time: 407.1880s\n",
      "\titers: 200, epoch: 64 | loss: 0.0595020\n",
      "\tspeed: 0.0235s/iter; left time: 192.1071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 226 | Train Loss: 0.0548079 Vali Loss: 0.0545252 Test Loss: 0.0569238\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0577908\n",
      "\tspeed: 0.0478s/iter; left time: 384.2557s\n",
      "\titers: 200, epoch: 65 | loss: 0.0582348\n",
      "\tspeed: 0.0254s/iter; left time: 201.7473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 226 | Train Loss: 0.0547158 Vali Loss: 0.0544442 Test Loss: 0.0568673\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0521134\n",
      "\tspeed: 0.0458s/iter; left time: 357.9288s\n",
      "\titers: 200, epoch: 66 | loss: 0.0571456\n",
      "\tspeed: 0.0281s/iter; left time: 216.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 226 | Train Loss: 0.0547606 Vali Loss: 0.0544804 Test Loss: 0.0569185\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0545808\n",
      "\tspeed: 0.0533s/iter; left time: 404.3548s\n",
      "\titers: 200, epoch: 67 | loss: 0.0523171\n",
      "\tspeed: 0.0185s/iter; left time: 138.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0547814 Vali Loss: 0.0545069 Test Loss: 0.0568956\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0553125\n",
      "\tspeed: 0.0504s/iter; left time: 370.9870s\n",
      "\titers: 200, epoch: 68 | loss: 0.0524824\n",
      "\tspeed: 0.0286s/iter; left time: 207.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 226 | Train Loss: 0.0547916 Vali Loss: 0.0544979 Test Loss: 0.0569650\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0552361\n",
      "\tspeed: 0.0490s/iter; left time: 349.8172s\n",
      "\titers: 200, epoch: 69 | loss: 0.0531105\n",
      "\tspeed: 0.0279s/iter; left time: 196.4785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 226 | Train Loss: 0.0547940 Vali Loss: 0.0545501 Test Loss: 0.0569191\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0555499\n",
      "\tspeed: 0.0491s/iter; left time: 339.4557s\n",
      "\titers: 200, epoch: 70 | loss: 0.0586882\n",
      "\tspeed: 0.0284s/iter; left time: 193.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 226 | Train Loss: 0.0547468 Vali Loss: 0.0544531 Test Loss: 0.0568987\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010126727633178234, rmse:0.10063164681196213, mae:0.056882333010435104, rse:0.3802374303340912\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1671183\n",
      "\tspeed: 0.0261s/iter; left time: 586.3574s\n",
      "\titers: 200, epoch: 1 | loss: 0.1493597\n",
      "\tspeed: 0.0254s/iter; left time: 569.7711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 226 | Train Loss: 0.1708172 Vali Loss: 0.1430496 Test Loss: 0.1509800\n",
      "Validation loss decreased (inf --> 0.143050).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894919\n",
      "\tspeed: 0.0462s/iter; left time: 1029.5477s\n",
      "\titers: 200, epoch: 2 | loss: 0.0741505\n",
      "\tspeed: 0.0246s/iter; left time: 546.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 226 | Train Loss: 0.0934774 Vali Loss: 0.0673926 Test Loss: 0.0698875\n",
      "Validation loss decreased (0.143050 --> 0.067393).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0690908\n",
      "\tspeed: 0.0469s/iter; left time: 1033.7647s\n",
      "\titers: 200, epoch: 3 | loss: 0.0651288\n",
      "\tspeed: 0.0231s/iter; left time: 506.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 226 | Train Loss: 0.0686555 Vali Loss: 0.0616349 Test Loss: 0.0644420\n",
      "Validation loss decreased (0.067393 --> 0.061635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637166\n",
      "\tspeed: 0.0464s/iter; left time: 1013.4318s\n",
      "\titers: 200, epoch: 4 | loss: 0.0618543\n",
      "\tspeed: 0.0244s/iter; left time: 530.8369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 226 | Train Loss: 0.0643276 Vali Loss: 0.0595802 Test Loss: 0.0624841\n",
      "Validation loss decreased (0.061635 --> 0.059580).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620772\n",
      "\tspeed: 0.0497s/iter; left time: 1072.8426s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610805\n",
      "\tspeed: 0.0261s/iter; left time: 560.9989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 226 | Train Loss: 0.0621152 Vali Loss: 0.0583595 Test Loss: 0.0613081\n",
      "Validation loss decreased (0.059580 --> 0.058359).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0622094\n",
      "\tspeed: 0.0528s/iter; left time: 1128.4955s\n",
      "\titers: 200, epoch: 6 | loss: 0.0586622\n",
      "\tspeed: 0.0242s/iter; left time: 515.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 226 | Train Loss: 0.0608144 Vali Loss: 0.0577665 Test Loss: 0.0608487\n",
      "Validation loss decreased (0.058359 --> 0.057767).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0609338\n",
      "\tspeed: 0.0520s/iter; left time: 1098.6852s\n",
      "\titers: 200, epoch: 7 | loss: 0.0570468\n",
      "\tspeed: 0.0278s/iter; left time: 585.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 226 | Train Loss: 0.0597690 Vali Loss: 0.0570377 Test Loss: 0.0599500\n",
      "Validation loss decreased (0.057767 --> 0.057038).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0550718\n",
      "\tspeed: 0.0537s/iter; left time: 1123.7628s\n",
      "\titers: 200, epoch: 8 | loss: 0.0665458\n",
      "\tspeed: 0.0316s/iter; left time: 658.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.0589198 Vali Loss: 0.0561305 Test Loss: 0.0592737\n",
      "Validation loss decreased (0.057038 --> 0.056130).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0612751\n",
      "\tspeed: 0.0578s/iter; left time: 1195.5991s\n",
      "\titers: 200, epoch: 9 | loss: 0.0568842\n",
      "\tspeed: 0.0259s/iter; left time: 533.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 226 | Train Loss: 0.0583483 Vali Loss: 0.0559387 Test Loss: 0.0588987\n",
      "Validation loss decreased (0.056130 --> 0.055939).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0585441\n",
      "\tspeed: 0.0504s/iter; left time: 1032.3465s\n",
      "\titers: 200, epoch: 10 | loss: 0.0598325\n",
      "\tspeed: 0.0311s/iter; left time: 632.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 226 | Train Loss: 0.0578611 Vali Loss: 0.0558667 Test Loss: 0.0586031\n",
      "Validation loss decreased (0.055939 --> 0.055867).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0586685\n",
      "\tspeed: 0.0520s/iter; left time: 1053.2859s\n",
      "\titers: 200, epoch: 11 | loss: 0.0560532\n",
      "\tspeed: 0.0302s/iter; left time: 607.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 226 | Train Loss: 0.0575143 Vali Loss: 0.0555754 Test Loss: 0.0584051\n",
      "Validation loss decreased (0.055867 --> 0.055575).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553717\n",
      "\tspeed: 0.0561s/iter; left time: 1122.0926s\n",
      "\titers: 200, epoch: 12 | loss: 0.0553700\n",
      "\tspeed: 0.0303s/iter; left time: 602.6951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 226 | Train Loss: 0.0572109 Vali Loss: 0.0554275 Test Loss: 0.0582681\n",
      "Validation loss decreased (0.055575 --> 0.055428).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0546830\n",
      "\tspeed: 0.0471s/iter; left time: 932.7866s\n",
      "\titers: 200, epoch: 13 | loss: 0.0599364\n",
      "\tspeed: 0.0243s/iter; left time: 478.1866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 226 | Train Loss: 0.0569612 Vali Loss: 0.0553732 Test Loss: 0.0580842\n",
      "Validation loss decreased (0.055428 --> 0.055373).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0562301\n",
      "\tspeed: 0.0466s/iter; left time: 911.1899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0562018\n",
      "\tspeed: 0.0246s/iter; left time: 479.6203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 226 | Train Loss: 0.0566864 Vali Loss: 0.0550656 Test Loss: 0.0577854\n",
      "Validation loss decreased (0.055373 --> 0.055066).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0606462\n",
      "\tspeed: 0.0469s/iter; left time: 907.4004s\n",
      "\titers: 200, epoch: 15 | loss: 0.0547147\n",
      "\tspeed: 0.0238s/iter; left time: 457.4420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0564601 Vali Loss: 0.0550560 Test Loss: 0.0578406\n",
      "Validation loss decreased (0.055066 --> 0.055056).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0586123\n",
      "\tspeed: 0.0513s/iter; left time: 979.4401s\n",
      "\titers: 200, epoch: 16 | loss: 0.0542631\n",
      "\tspeed: 0.0231s/iter; left time: 439.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0563156 Vali Loss: 0.0549847 Test Loss: 0.0577916\n",
      "Validation loss decreased (0.055056 --> 0.054985).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0525569\n",
      "\tspeed: 0.0496s/iter; left time: 935.9065s\n",
      "\titers: 200, epoch: 17 | loss: 0.0540291\n",
      "\tspeed: 0.0231s/iter; left time: 434.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 226 | Train Loss: 0.0561593 Vali Loss: 0.0548957 Test Loss: 0.0575398\n",
      "Validation loss decreased (0.054985 --> 0.054896).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549057\n",
      "\tspeed: 0.0475s/iter; left time: 887.1360s\n",
      "\titers: 200, epoch: 18 | loss: 0.0582623\n",
      "\tspeed: 0.0250s/iter; left time: 463.6831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 226 | Train Loss: 0.0560078 Vali Loss: 0.0548554 Test Loss: 0.0574899\n",
      "Validation loss decreased (0.054896 --> 0.054855).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0570154\n",
      "\tspeed: 0.0509s/iter; left time: 937.5739s\n",
      "\titers: 200, epoch: 19 | loss: 0.0589034\n",
      "\tspeed: 0.0250s/iter; left time: 457.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.0559835 Vali Loss: 0.0548761 Test Loss: 0.0575250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0533867\n",
      "\tspeed: 0.0475s/iter; left time: 864.4540s\n",
      "\titers: 200, epoch: 20 | loss: 0.0564308\n",
      "\tspeed: 0.0233s/iter; left time: 421.5848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 226 | Train Loss: 0.0559020 Vali Loss: 0.0548729 Test Loss: 0.0574068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0547154\n",
      "\tspeed: 0.0516s/iter; left time: 928.5613s\n",
      "\titers: 200, epoch: 21 | loss: 0.0591372\n",
      "\tspeed: 0.0225s/iter; left time: 402.5486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 226 | Train Loss: 0.0557124 Vali Loss: 0.0547077 Test Loss: 0.0573593\n",
      "Validation loss decreased (0.054855 --> 0.054708).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0538523\n",
      "\tspeed: 0.0493s/iter; left time: 874.8137s\n",
      "\titers: 200, epoch: 22 | loss: 0.0558532\n",
      "\tspeed: 0.0250s/iter; left time: 440.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 226 | Train Loss: 0.0556812 Vali Loss: 0.0545233 Test Loss: 0.0572733\n",
      "Validation loss decreased (0.054708 --> 0.054523).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0537412\n",
      "\tspeed: 0.0435s/iter; left time: 762.9864s\n",
      "\titers: 200, epoch: 23 | loss: 0.0565237\n",
      "\tspeed: 0.0247s/iter; left time: 430.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 226 | Train Loss: 0.0555625 Vali Loss: 0.0545978 Test Loss: 0.0572175\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0569870\n",
      "\tspeed: 0.0462s/iter; left time: 798.5345s\n",
      "\titers: 200, epoch: 24 | loss: 0.0586887\n",
      "\tspeed: 0.0263s/iter; left time: 452.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 226 | Train Loss: 0.0555227 Vali Loss: 0.0545563 Test Loss: 0.0572211\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0559320\n",
      "\tspeed: 0.0506s/iter; left time: 864.7210s\n",
      "\titers: 200, epoch: 25 | loss: 0.0623908\n",
      "\tspeed: 0.0269s/iter; left time: 455.9697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 226 | Train Loss: 0.0554853 Vali Loss: 0.0546439 Test Loss: 0.0572556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0572326\n",
      "\tspeed: 0.0439s/iter; left time: 739.7119s\n",
      "\titers: 200, epoch: 26 | loss: 0.0553266\n",
      "\tspeed: 0.0240s/iter; left time: 402.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 226 | Train Loss: 0.0554122 Vali Loss: 0.0546292 Test Loss: 0.0572165\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0557066\n",
      "\tspeed: 0.0495s/iter; left time: 822.2588s\n",
      "\titers: 200, epoch: 27 | loss: 0.0552947\n",
      "\tspeed: 0.0286s/iter; left time: 473.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0553655 Vali Loss: 0.0545335 Test Loss: 0.0571195\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0536001\n",
      "\tspeed: 0.0491s/iter; left time: 805.8637s\n",
      "\titers: 200, epoch: 28 | loss: 0.0544457\n",
      "\tspeed: 0.0239s/iter; left time: 389.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 226 | Train Loss: 0.0553575 Vali Loss: 0.0545017 Test Loss: 0.0571133\n",
      "Validation loss decreased (0.054523 --> 0.054502).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0525365\n",
      "\tspeed: 0.0543s/iter; left time: 878.0734s\n",
      "\titers: 200, epoch: 29 | loss: 0.0512349\n",
      "\tspeed: 0.0298s/iter; left time: 479.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 226 | Train Loss: 0.0552837 Vali Loss: 0.0545020 Test Loss: 0.0571912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0555779\n",
      "\tspeed: 0.0465s/iter; left time: 741.3302s\n",
      "\titers: 200, epoch: 30 | loss: 0.0550966\n",
      "\tspeed: 0.0264s/iter; left time: 418.0493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 226 | Train Loss: 0.0552685 Vali Loss: 0.0545906 Test Loss: 0.0571831\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0581115\n",
      "\tspeed: 0.0475s/iter; left time: 746.4065s\n",
      "\titers: 200, epoch: 31 | loss: 0.0507683\n",
      "\tspeed: 0.0244s/iter; left time: 381.3370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 226 | Train Loss: 0.0552550 Vali Loss: 0.0545533 Test Loss: 0.0571081\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0543378\n",
      "\tspeed: 0.0421s/iter; left time: 651.6769s\n",
      "\titers: 200, epoch: 32 | loss: 0.0567470\n",
      "\tspeed: 0.0265s/iter; left time: 407.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 226 | Train Loss: 0.0552130 Vali Loss: 0.0544021 Test Loss: 0.0570437\n",
      "Validation loss decreased (0.054502 --> 0.054402).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0533559\n",
      "\tspeed: 0.0460s/iter; left time: 702.7662s\n",
      "\titers: 200, epoch: 33 | loss: 0.0527099\n",
      "\tspeed: 0.0248s/iter; left time: 375.4562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 226 | Train Loss: 0.0551895 Vali Loss: 0.0543914 Test Loss: 0.0570647\n",
      "Validation loss decreased (0.054402 --> 0.054391).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0556570\n",
      "\tspeed: 0.0515s/iter; left time: 775.0225s\n",
      "\titers: 200, epoch: 34 | loss: 0.0527466\n",
      "\tspeed: 0.0312s/iter; left time: 466.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 226 | Train Loss: 0.0552035 Vali Loss: 0.0546156 Test Loss: 0.0571556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0529002\n",
      "\tspeed: 0.0532s/iter; left time: 788.1281s\n",
      "\titers: 200, epoch: 35 | loss: 0.0546057\n",
      "\tspeed: 0.0319s/iter; left time: 469.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 226 | Train Loss: 0.0551364 Vali Loss: 0.0545817 Test Loss: 0.0571406\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0545301\n",
      "\tspeed: 0.0494s/iter; left time: 720.7291s\n",
      "\titers: 200, epoch: 36 | loss: 0.0542963\n",
      "\tspeed: 0.0225s/iter; left time: 326.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 226 | Train Loss: 0.0551355 Vali Loss: 0.0544014 Test Loss: 0.0570049\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0592082\n",
      "\tspeed: 0.0446s/iter; left time: 641.3640s\n",
      "\titers: 200, epoch: 37 | loss: 0.0578923\n",
      "\tspeed: 0.0233s/iter; left time: 332.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 226 | Train Loss: 0.0550899 Vali Loss: 0.0544372 Test Loss: 0.0570175\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0575181\n",
      "\tspeed: 0.0439s/iter; left time: 620.9215s\n",
      "\titers: 200, epoch: 38 | loss: 0.0554402\n",
      "\tspeed: 0.0245s/iter; left time: 344.6493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0551337 Vali Loss: 0.0544084 Test Loss: 0.0569866\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0539549\n",
      "\tspeed: 0.0505s/iter; left time: 703.2806s\n",
      "\titers: 200, epoch: 39 | loss: 0.0599985\n",
      "\tspeed: 0.0298s/iter; left time: 412.0970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 226 | Train Loss: 0.0550835 Vali Loss: 0.0544412 Test Loss: 0.0569934\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0555178\n",
      "\tspeed: 0.0540s/iter; left time: 739.5891s\n",
      "\titers: 200, epoch: 40 | loss: 0.0535621\n",
      "\tspeed: 0.0301s/iter; left time: 408.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 226 | Train Loss: 0.0551042 Vali Loss: 0.0544443 Test Loss: 0.0570305\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0544481\n",
      "\tspeed: 0.0544s/iter; left time: 731.8295s\n",
      "\titers: 200, epoch: 41 | loss: 0.0571609\n",
      "\tspeed: 0.0271s/iter; left time: 361.8683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 226 | Train Loss: 0.0550469 Vali Loss: 0.0544577 Test Loss: 0.0570496\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0541435\n",
      "\tspeed: 0.0496s/iter; left time: 656.0533s\n",
      "\titers: 200, epoch: 42 | loss: 0.0584221\n",
      "\tspeed: 0.0276s/iter; left time: 361.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 226 | Train Loss: 0.0550190 Vali Loss: 0.0543569 Test Loss: 0.0569765\n",
      "Validation loss decreased (0.054391 --> 0.054357).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0570098\n",
      "\tspeed: 0.0517s/iter; left time: 672.3974s\n",
      "\titers: 200, epoch: 43 | loss: 0.0529481\n",
      "\tspeed: 0.0281s/iter; left time: 362.5839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 226 | Train Loss: 0.0550399 Vali Loss: 0.0543499 Test Loss: 0.0569851\n",
      "Validation loss decreased (0.054357 --> 0.054350).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537824\n",
      "\tspeed: 0.0617s/iter; left time: 788.2781s\n",
      "\titers: 200, epoch: 44 | loss: 0.0584286\n",
      "\tspeed: 0.0307s/iter; left time: 389.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 226 | Train Loss: 0.0549981 Vali Loss: 0.0545196 Test Loss: 0.0570577\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0544152\n",
      "\tspeed: 0.0522s/iter; left time: 655.7470s\n",
      "\titers: 200, epoch: 45 | loss: 0.0531305\n",
      "\tspeed: 0.0272s/iter; left time: 339.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 226 | Train Loss: 0.0550469 Vali Loss: 0.0544084 Test Loss: 0.0569764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0552234\n",
      "\tspeed: 0.0528s/iter; left time: 650.7892s\n",
      "\titers: 200, epoch: 46 | loss: 0.0589482\n",
      "\tspeed: 0.0335s/iter; left time: 409.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 226 | Train Loss: 0.0550391 Vali Loss: 0.0543831 Test Loss: 0.0569450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0558735\n",
      "\tspeed: 0.0594s/iter; left time: 719.0240s\n",
      "\titers: 200, epoch: 47 | loss: 0.0562957\n",
      "\tspeed: 0.0300s/iter; left time: 359.6862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.0550245 Vali Loss: 0.0544049 Test Loss: 0.0569942\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0557008\n",
      "\tspeed: 0.0530s/iter; left time: 629.6357s\n",
      "\titers: 200, epoch: 48 | loss: 0.0573912\n",
      "\tspeed: 0.0292s/iter; left time: 344.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 226 | Train Loss: 0.0550281 Vali Loss: 0.0544020 Test Loss: 0.0570180\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0546718\n",
      "\tspeed: 0.0476s/iter; left time: 554.5971s\n",
      "\titers: 200, epoch: 49 | loss: 0.0545007\n",
      "\tspeed: 0.0293s/iter; left time: 337.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 226 | Train Loss: 0.0549733 Vali Loss: 0.0545117 Test Loss: 0.0570557\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0567902\n",
      "\tspeed: 0.0509s/iter; left time: 581.8192s\n",
      "\titers: 200, epoch: 50 | loss: 0.0535607\n",
      "\tspeed: 0.0241s/iter; left time: 272.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 226 | Train Loss: 0.0549857 Vali Loss: 0.0542776 Test Loss: 0.0569479\n",
      "Validation loss decreased (0.054350 --> 0.054278).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0541929\n",
      "\tspeed: 0.0524s/iter; left time: 586.9150s\n",
      "\titers: 200, epoch: 51 | loss: 0.0532043\n",
      "\tspeed: 0.0299s/iter; left time: 331.8213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 226 | Train Loss: 0.0550235 Vali Loss: 0.0544153 Test Loss: 0.0570159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0517970\n",
      "\tspeed: 0.0552s/iter; left time: 605.8079s\n",
      "\titers: 200, epoch: 52 | loss: 0.0561695\n",
      "\tspeed: 0.0317s/iter; left time: 345.0569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.0550057 Vali Loss: 0.0544147 Test Loss: 0.0569938\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0564113\n",
      "\tspeed: 0.0472s/iter; left time: 507.2525s\n",
      "\titers: 200, epoch: 53 | loss: 0.0545869\n",
      "\tspeed: 0.0295s/iter; left time: 314.0962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 226 | Train Loss: 0.0549994 Vali Loss: 0.0542674 Test Loss: 0.0569478\n",
      "Validation loss decreased (0.054278 --> 0.054267).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0558922\n",
      "\tspeed: 0.0502s/iter; left time: 528.1924s\n",
      "\titers: 200, epoch: 54 | loss: 0.0500513\n",
      "\tspeed: 0.0287s/iter; left time: 299.1153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 226 | Train Loss: 0.0549873 Vali Loss: 0.0543921 Test Loss: 0.0569369\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0583103\n",
      "\tspeed: 0.0559s/iter; left time: 575.1348s\n",
      "\titers: 200, epoch: 55 | loss: 0.0526342\n",
      "\tspeed: 0.0314s/iter; left time: 319.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 226 | Train Loss: 0.0549969 Vali Loss: 0.0544587 Test Loss: 0.0570053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0560073\n",
      "\tspeed: 0.0503s/iter; left time: 506.6557s\n",
      "\titers: 200, epoch: 56 | loss: 0.0549848\n",
      "\tspeed: 0.0284s/iter; left time: 283.0088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 226 | Train Loss: 0.0549915 Vali Loss: 0.0544629 Test Loss: 0.0569569\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0586904\n",
      "\tspeed: 0.0553s/iter; left time: 544.0501s\n",
      "\titers: 200, epoch: 57 | loss: 0.0569365\n",
      "\tspeed: 0.0310s/iter; left time: 301.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 226 | Train Loss: 0.0550113 Vali Loss: 0.0543688 Test Loss: 0.0569486\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0548015\n",
      "\tspeed: 0.0467s/iter; left time: 449.1191s\n",
      "\titers: 200, epoch: 58 | loss: 0.0559248\n",
      "\tspeed: 0.0306s/iter; left time: 291.4517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 226 | Train Loss: 0.0550106 Vali Loss: 0.0544411 Test Loss: 0.0570273\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0563634\n",
      "\tspeed: 0.0561s/iter; left time: 526.9429s\n",
      "\titers: 200, epoch: 59 | loss: 0.0529164\n",
      "\tspeed: 0.0298s/iter; left time: 276.8782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 226 | Train Loss: 0.0550187 Vali Loss: 0.0543835 Test Loss: 0.0569421\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0513109\n",
      "\tspeed: 0.0463s/iter; left time: 424.5147s\n",
      "\titers: 200, epoch: 60 | loss: 0.0575434\n",
      "\tspeed: 0.0301s/iter; left time: 273.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 226 | Train Loss: 0.0550089 Vali Loss: 0.0544088 Test Loss: 0.0569655\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0525246\n",
      "\tspeed: 0.0568s/iter; left time: 507.9152s\n",
      "\titers: 200, epoch: 61 | loss: 0.0528906\n",
      "\tspeed: 0.0336s/iter; left time: 297.3657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 226 | Train Loss: 0.0549117 Vali Loss: 0.0544557 Test Loss: 0.0569940\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0564995\n",
      "\tspeed: 0.0593s/iter; left time: 516.9842s\n",
      "\titers: 200, epoch: 62 | loss: 0.0514744\n",
      "\tspeed: 0.0296s/iter; left time: 255.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 226 | Train Loss: 0.0550009 Vali Loss: 0.0542982 Test Loss: 0.0569604\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0603337\n",
      "\tspeed: 0.0545s/iter; left time: 462.6180s\n",
      "\titers: 200, epoch: 63 | loss: 0.0585992\n",
      "\tspeed: 0.0264s/iter; left time: 221.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 226 | Train Loss: 0.0549873 Vali Loss: 0.0543450 Test Loss: 0.0569679\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010085921734571457, rmse:0.10042869299650192, mae:0.05694780498743057, rse:0.379470556974411\n",
      "Intermediate time for IT and pred_len 24: 00h:17m:12.81s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1805620\n",
      "\tspeed: 0.0519s/iter; left time: 1162.8633s\n",
      "\titers: 200, epoch: 1 | loss: 0.1604668\n",
      "\tspeed: 0.0293s/iter; left time: 654.3453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 225 | Train Loss: 0.1799002 Vali Loss: 0.1531601 Test Loss: 0.1623265\n",
      "Validation loss decreased (inf --> 0.153160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1056841\n",
      "\tspeed: 0.0474s/iter; left time: 1051.1115s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949816\n",
      "\tspeed: 0.0230s/iter; left time: 507.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 225 | Train Loss: 0.1107018 Vali Loss: 0.0847156 Test Loss: 0.0898317\n",
      "Validation loss decreased (0.153160 --> 0.084716).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903883\n",
      "\tspeed: 0.0451s/iter; left time: 990.5345s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877064\n",
      "\tspeed: 0.0242s/iter; left time: 529.3414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0886370 Vali Loss: 0.0799162 Test Loss: 0.0851156\n",
      "Validation loss decreased (0.084716 --> 0.079916).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0849233\n",
      "\tspeed: 0.0496s/iter; left time: 1077.2709s\n",
      "\titers: 200, epoch: 4 | loss: 0.0863226\n",
      "\tspeed: 0.0337s/iter; left time: 728.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 225 | Train Loss: 0.0846948 Vali Loss: 0.0781025 Test Loss: 0.0833411\n",
      "Validation loss decreased (0.079916 --> 0.078102).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819032\n",
      "\tspeed: 0.0556s/iter; left time: 1194.4493s\n",
      "\titers: 200, epoch: 5 | loss: 0.0811997\n",
      "\tspeed: 0.0303s/iter; left time: 648.5425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 225 | Train Loss: 0.0823563 Vali Loss: 0.0769063 Test Loss: 0.0825890\n",
      "Validation loss decreased (0.078102 --> 0.076906).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839242\n",
      "\tspeed: 0.0478s/iter; left time: 1017.8120s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821715\n",
      "\tspeed: 0.0244s/iter; left time: 515.9615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0809487 Vali Loss: 0.0761848 Test Loss: 0.0819233\n",
      "Validation loss decreased (0.076906 --> 0.076185).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0793673\n",
      "\tspeed: 0.0451s/iter; left time: 948.5124s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810894\n",
      "\tspeed: 0.0228s/iter; left time: 477.5206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0799971 Vali Loss: 0.0757786 Test Loss: 0.0812300\n",
      "Validation loss decreased (0.076185 --> 0.075779).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0806313\n",
      "\tspeed: 0.0484s/iter; left time: 1007.3201s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806243\n",
      "\tspeed: 0.0210s/iter; left time: 435.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 225 | Train Loss: 0.0793282 Vali Loss: 0.0756721 Test Loss: 0.0810366\n",
      "Validation loss decreased (0.075779 --> 0.075672).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0797274\n",
      "\tspeed: 0.0485s/iter; left time: 998.5841s\n",
      "\titers: 200, epoch: 9 | loss: 0.0800558\n",
      "\tspeed: 0.0332s/iter; left time: 681.5667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 225 | Train Loss: 0.0788017 Vali Loss: 0.0751570 Test Loss: 0.0806254\n",
      "Validation loss decreased (0.075672 --> 0.075157).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0781363\n",
      "\tspeed: 0.0529s/iter; left time: 1078.2643s\n",
      "\titers: 200, epoch: 10 | loss: 0.0821204\n",
      "\tspeed: 0.0295s/iter; left time: 598.1759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 225 | Train Loss: 0.0784086 Vali Loss: 0.0748331 Test Loss: 0.0803863\n",
      "Validation loss decreased (0.075157 --> 0.074833).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773081\n",
      "\tspeed: 0.0506s/iter; left time: 1019.2319s\n",
      "\titers: 200, epoch: 11 | loss: 0.0769340\n",
      "\tspeed: 0.0306s/iter; left time: 613.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 225 | Train Loss: 0.0780557 Vali Loss: 0.0748576 Test Loss: 0.0803838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0739010\n",
      "\tspeed: 0.0428s/iter; left time: 852.3341s\n",
      "\titers: 200, epoch: 12 | loss: 0.0764393\n",
      "\tspeed: 0.0192s/iter; left time: 380.1938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0778147 Vali Loss: 0.0747394 Test Loss: 0.0802362\n",
      "Validation loss decreased (0.074833 --> 0.074739).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0770929\n",
      "\tspeed: 0.0480s/iter; left time: 945.0190s\n",
      "\titers: 200, epoch: 13 | loss: 0.0768943\n",
      "\tspeed: 0.0232s/iter; left time: 454.6449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 225 | Train Loss: 0.0775008 Vali Loss: 0.0745214 Test Loss: 0.0799649\n",
      "Validation loss decreased (0.074739 --> 0.074521).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0770124\n",
      "\tspeed: 0.0580s/iter; left time: 1129.6667s\n",
      "\titers: 200, epoch: 14 | loss: 0.0781280\n",
      "\tspeed: 0.0316s/iter; left time: 611.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 225 | Train Loss: 0.0772693 Vali Loss: 0.0744808 Test Loss: 0.0800061\n",
      "Validation loss decreased (0.074521 --> 0.074481).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0770420\n",
      "\tspeed: 0.0524s/iter; left time: 1008.7737s\n",
      "\titers: 200, epoch: 15 | loss: 0.0778218\n",
      "\tspeed: 0.0299s/iter; left time: 572.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0771457 Vali Loss: 0.0745342 Test Loss: 0.0800457\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0788047\n",
      "\tspeed: 0.0590s/iter; left time: 1121.7168s\n",
      "\titers: 200, epoch: 16 | loss: 0.0733577\n",
      "\tspeed: 0.0333s/iter; left time: 630.8500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 225 | Train Loss: 0.0768803 Vali Loss: 0.0745147 Test Loss: 0.0799389\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0849317\n",
      "\tspeed: 0.0441s/iter; left time: 828.3722s\n",
      "\titers: 200, epoch: 17 | loss: 0.0769682\n",
      "\tspeed: 0.0203s/iter; left time: 379.8736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 225 | Train Loss: 0.0767694 Vali Loss: 0.0743689 Test Loss: 0.0799724\n",
      "Validation loss decreased (0.074481 --> 0.074369).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0740751\n",
      "\tspeed: 0.0533s/iter; left time: 989.6025s\n",
      "\titers: 200, epoch: 18 | loss: 0.0740322\n",
      "\tspeed: 0.0317s/iter; left time: 586.0610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 225 | Train Loss: 0.0765871 Vali Loss: 0.0741889 Test Loss: 0.0799109\n",
      "Validation loss decreased (0.074369 --> 0.074189).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0762765\n",
      "\tspeed: 0.0469s/iter; left time: 860.5855s\n",
      "\titers: 200, epoch: 19 | loss: 0.0740567\n",
      "\tspeed: 0.0296s/iter; left time: 539.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0764642 Vali Loss: 0.0741447 Test Loss: 0.0797611\n",
      "Validation loss decreased (0.074189 --> 0.074145).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0760027\n",
      "\tspeed: 0.0578s/iter; left time: 1048.1331s\n",
      "\titers: 200, epoch: 20 | loss: 0.0772175\n",
      "\tspeed: 0.0346s/iter; left time: 623.4148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 225 | Train Loss: 0.0763880 Vali Loss: 0.0741452 Test Loss: 0.0796693\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0732374\n",
      "\tspeed: 0.0528s/iter; left time: 944.8037s\n",
      "\titers: 200, epoch: 21 | loss: 0.0762790\n",
      "\tspeed: 0.0319s/iter; left time: 567.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 225 | Train Loss: 0.0762697 Vali Loss: 0.0740867 Test Loss: 0.0798120\n",
      "Validation loss decreased (0.074145 --> 0.074087).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756372\n",
      "\tspeed: 0.0530s/iter; left time: 936.4639s\n",
      "\titers: 200, epoch: 22 | loss: 0.0716529\n",
      "\tspeed: 0.0277s/iter; left time: 486.5722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 225 | Train Loss: 0.0761757 Vali Loss: 0.0741539 Test Loss: 0.0797682\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0771927\n",
      "\tspeed: 0.0468s/iter; left time: 816.5573s\n",
      "\titers: 200, epoch: 23 | loss: 0.0765624\n",
      "\tspeed: 0.0259s/iter; left time: 450.0137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0761410 Vali Loss: 0.0740627 Test Loss: 0.0797253\n",
      "Validation loss decreased (0.074087 --> 0.074063).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0768347\n",
      "\tspeed: 0.0519s/iter; left time: 894.4645s\n",
      "\titers: 200, epoch: 24 | loss: 0.0757049\n",
      "\tspeed: 0.0296s/iter; left time: 507.4298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 225 | Train Loss: 0.0760581 Vali Loss: 0.0740495 Test Loss: 0.0796765\n",
      "Validation loss decreased (0.074063 --> 0.074050).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0780853\n",
      "\tspeed: 0.0502s/iter; left time: 852.8996s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782617\n",
      "\tspeed: 0.0296s/iter; left time: 499.6110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 225 | Train Loss: 0.0759656 Vali Loss: 0.0740208 Test Loss: 0.0797114\n",
      "Validation loss decreased (0.074050 --> 0.074021).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0729303\n",
      "\tspeed: 0.0489s/iter; left time: 820.1862s\n",
      "\titers: 200, epoch: 26 | loss: 0.0760167\n",
      "\tspeed: 0.0202s/iter; left time: 337.5871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.0759042 Vali Loss: 0.0740213 Test Loss: 0.0797527\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0779798\n",
      "\tspeed: 0.0469s/iter; left time: 775.9772s\n",
      "\titers: 200, epoch: 27 | loss: 0.0730974\n",
      "\tspeed: 0.0262s/iter; left time: 430.7725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0758558 Vali Loss: 0.0739786 Test Loss: 0.0797341\n",
      "Validation loss decreased (0.074021 --> 0.073979).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0789156\n",
      "\tspeed: 0.0505s/iter; left time: 825.2561s\n",
      "\titers: 200, epoch: 28 | loss: 0.0755482\n",
      "\tspeed: 0.0335s/iter; left time: 543.8115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 225 | Train Loss: 0.0758470 Vali Loss: 0.0740256 Test Loss: 0.0797478\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742041\n",
      "\tspeed: 0.0517s/iter; left time: 832.5813s\n",
      "\titers: 200, epoch: 29 | loss: 0.0770120\n",
      "\tspeed: 0.0298s/iter; left time: 476.3013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 225 | Train Loss: 0.0757809 Vali Loss: 0.0739312 Test Loss: 0.0796134\n",
      "Validation loss decreased (0.073979 --> 0.073931).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0743474\n",
      "\tspeed: 0.0497s/iter; left time: 788.5267s\n",
      "\titers: 200, epoch: 30 | loss: 0.0743649\n",
      "\tspeed: 0.0284s/iter; left time: 448.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 225 | Train Loss: 0.0757547 Vali Loss: 0.0738966 Test Loss: 0.0796489\n",
      "Validation loss decreased (0.073931 --> 0.073897).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0769657\n",
      "\tspeed: 0.0498s/iter; left time: 778.7611s\n",
      "\titers: 200, epoch: 31 | loss: 0.0767465\n",
      "\tspeed: 0.0337s/iter; left time: 523.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 225 | Train Loss: 0.0757479 Vali Loss: 0.0739233 Test Loss: 0.0796932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0746304\n",
      "\tspeed: 0.0539s/iter; left time: 832.0435s\n",
      "\titers: 200, epoch: 32 | loss: 0.0737139\n",
      "\tspeed: 0.0296s/iter; left time: 452.9490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0756927 Vali Loss: 0.0739457 Test Loss: 0.0796888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0774381\n",
      "\tspeed: 0.0541s/iter; left time: 822.5513s\n",
      "\titers: 200, epoch: 33 | loss: 0.0736052\n",
      "\tspeed: 0.0303s/iter; left time: 458.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 225 | Train Loss: 0.0756846 Vali Loss: 0.0738672 Test Loss: 0.0796748\n",
      "Validation loss decreased (0.073897 --> 0.073867).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0778821\n",
      "\tspeed: 0.0536s/iter; left time: 802.0761s\n",
      "\titers: 200, epoch: 34 | loss: 0.0769082\n",
      "\tspeed: 0.0305s/iter; left time: 454.1337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 225 | Train Loss: 0.0755951 Vali Loss: 0.0739160 Test Loss: 0.0796510\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0706455\n",
      "\tspeed: 0.0527s/iter; left time: 777.1290s\n",
      "\titers: 200, epoch: 35 | loss: 0.0743120\n",
      "\tspeed: 0.0266s/iter; left time: 390.3753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0756107 Vali Loss: 0.0738675 Test Loss: 0.0796316\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0757184\n",
      "\tspeed: 0.0533s/iter; left time: 774.1222s\n",
      "\titers: 200, epoch: 36 | loss: 0.0789647\n",
      "\tspeed: 0.0269s/iter; left time: 388.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 225 | Train Loss: 0.0755679 Vali Loss: 0.0738346 Test Loss: 0.0796362\n",
      "Validation loss decreased (0.073867 --> 0.073835).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0823950\n",
      "\tspeed: 0.0466s/iter; left time: 666.2990s\n",
      "\titers: 200, epoch: 37 | loss: 0.0751047\n",
      "\tspeed: 0.0229s/iter; left time: 324.5557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 225 | Train Loss: 0.0755710 Vali Loss: 0.0738364 Test Loss: 0.0796816\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0771139\n",
      "\tspeed: 0.0551s/iter; left time: 775.4749s\n",
      "\titers: 200, epoch: 38 | loss: 0.0795248\n",
      "\tspeed: 0.0294s/iter; left time: 411.1895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 225 | Train Loss: 0.0755763 Vali Loss: 0.0738889 Test Loss: 0.0796442\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0755012\n",
      "\tspeed: 0.0522s/iter; left time: 722.6248s\n",
      "\titers: 200, epoch: 39 | loss: 0.0750739\n",
      "\tspeed: 0.0235s/iter; left time: 322.4778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 225 | Train Loss: 0.0755440 Vali Loss: 0.0738972 Test Loss: 0.0796942\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0786288\n",
      "\tspeed: 0.0462s/iter; left time: 629.4702s\n",
      "\titers: 200, epoch: 40 | loss: 0.0695698\n",
      "\tspeed: 0.0306s/iter; left time: 413.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 225 | Train Loss: 0.0755733 Vali Loss: 0.0738691 Test Loss: 0.0796484\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0762501\n",
      "\tspeed: 0.0490s/iter; left time: 656.8606s\n",
      "\titers: 200, epoch: 41 | loss: 0.0711865\n",
      "\tspeed: 0.0301s/iter; left time: 399.9307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 225 | Train Loss: 0.0755028 Vali Loss: 0.0738545 Test Loss: 0.0796684\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0734441\n",
      "\tspeed: 0.0553s/iter; left time: 728.0576s\n",
      "\titers: 200, epoch: 42 | loss: 0.0758917\n",
      "\tspeed: 0.0311s/iter; left time: 406.3994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 225 | Train Loss: 0.0755312 Vali Loss: 0.0737964 Test Loss: 0.0796481\n",
      "Validation loss decreased (0.073835 --> 0.073796).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0733277\n",
      "\tspeed: 0.0457s/iter; left time: 591.2522s\n",
      "\titers: 200, epoch: 43 | loss: 0.0771407\n",
      "\tspeed: 0.0282s/iter; left time: 362.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 225 | Train Loss: 0.0755338 Vali Loss: 0.0738415 Test Loss: 0.0796714\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0747953\n",
      "\tspeed: 0.0468s/iter; left time: 595.0386s\n",
      "\titers: 200, epoch: 44 | loss: 0.0741519\n",
      "\tspeed: 0.0303s/iter; left time: 382.1021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0754940 Vali Loss: 0.0738805 Test Loss: 0.0796630\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0769906\n",
      "\tspeed: 0.0448s/iter; left time: 560.1053s\n",
      "\titers: 200, epoch: 45 | loss: 0.0761429\n",
      "\tspeed: 0.0195s/iter; left time: 242.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 225 | Train Loss: 0.0754916 Vali Loss: 0.0738032 Test Loss: 0.0796840\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0759332\n",
      "\tspeed: 0.0460s/iter; left time: 565.0444s\n",
      "\titers: 200, epoch: 46 | loss: 0.0706540\n",
      "\tspeed: 0.0232s/iter; left time: 282.0983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0755041 Vali Loss: 0.0738029 Test Loss: 0.0796604\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0753413\n",
      "\tspeed: 0.0510s/iter; left time: 614.8172s\n",
      "\titers: 200, epoch: 47 | loss: 0.0759820\n",
      "\tspeed: 0.0306s/iter; left time: 365.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 225 | Train Loss: 0.0754766 Vali Loss: 0.0738504 Test Loss: 0.0796809\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0736977\n",
      "\tspeed: 0.0478s/iter; left time: 565.0541s\n",
      "\titers: 200, epoch: 48 | loss: 0.0774811\n",
      "\tspeed: 0.0270s/iter; left time: 316.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 225 | Train Loss: 0.0754439 Vali Loss: 0.0738729 Test Loss: 0.0796779\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0742064\n",
      "\tspeed: 0.0489s/iter; left time: 567.2492s\n",
      "\titers: 200, epoch: 49 | loss: 0.0763281\n",
      "\tspeed: 0.0277s/iter; left time: 318.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 225 | Train Loss: 0.0754684 Vali Loss: 0.0738392 Test Loss: 0.0796467\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0738480\n",
      "\tspeed: 0.0457s/iter; left time: 519.6296s\n",
      "\titers: 200, epoch: 50 | loss: 0.0730180\n",
      "\tspeed: 0.0266s/iter; left time: 300.0786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 225 | Train Loss: 0.0754635 Vali Loss: 0.0738703 Test Loss: 0.0796760\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0756818\n",
      "\tspeed: 0.0523s/iter; left time: 583.3631s\n",
      "\titers: 200, epoch: 51 | loss: 0.0794990\n",
      "\tspeed: 0.0300s/iter; left time: 331.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 225 | Train Loss: 0.0754601 Vali Loss: 0.0738453 Test Loss: 0.0796572\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0704052\n",
      "\tspeed: 0.0517s/iter; left time: 564.8042s\n",
      "\titers: 200, epoch: 52 | loss: 0.0758301\n",
      "\tspeed: 0.0205s/iter; left time: 221.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 225 | Train Loss: 0.0754571 Vali Loss: 0.0738097 Test Loss: 0.0796377\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018305838108062744, rmse:0.13529907166957855, mae:0.07964807003736496, rse:0.5115803480148315\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1790881\n",
      "\tspeed: 0.0210s/iter; left time: 470.0092s\n",
      "\titers: 200, epoch: 1 | loss: 0.1657722\n",
      "\tspeed: 0.0274s/iter; left time: 611.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 225 | Train Loss: 0.1823005 Vali Loss: 0.1545539 Test Loss: 0.1640103\n",
      "Validation loss decreased (inf --> 0.154554).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1020215\n",
      "\tspeed: 0.0521s/iter; left time: 1154.9627s\n",
      "\titers: 200, epoch: 2 | loss: 0.0918243\n",
      "\tspeed: 0.0305s/iter; left time: 674.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 225 | Train Loss: 0.1109366 Vali Loss: 0.0847074 Test Loss: 0.0896899\n",
      "Validation loss decreased (0.154554 --> 0.084707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0926616\n",
      "\tspeed: 0.0520s/iter; left time: 1141.4641s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870116\n",
      "\tspeed: 0.0296s/iter; left time: 646.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 225 | Train Loss: 0.0891119 Vali Loss: 0.0801562 Test Loss: 0.0851888\n",
      "Validation loss decreased (0.084707 --> 0.080156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0865172\n",
      "\tspeed: 0.0562s/iter; left time: 1221.6089s\n",
      "\titers: 200, epoch: 4 | loss: 0.0807629\n",
      "\tspeed: 0.0292s/iter; left time: 632.1566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 225 | Train Loss: 0.0852437 Vali Loss: 0.0786048 Test Loss: 0.0836677\n",
      "Validation loss decreased (0.080156 --> 0.078605).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815287\n",
      "\tspeed: 0.0492s/iter; left time: 1058.5932s\n",
      "\titers: 200, epoch: 5 | loss: 0.0852425\n",
      "\tspeed: 0.0248s/iter; left time: 531.5487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0826992 Vali Loss: 0.0771317 Test Loss: 0.0825239\n",
      "Validation loss decreased (0.078605 --> 0.077132).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0855075\n",
      "\tspeed: 0.0451s/iter; left time: 959.7671s\n",
      "\titers: 200, epoch: 6 | loss: 0.0810368\n",
      "\tspeed: 0.0259s/iter; left time: 548.6693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0810929 Vali Loss: 0.0765272 Test Loss: 0.0819078\n",
      "Validation loss decreased (0.077132 --> 0.076527).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770050\n",
      "\tspeed: 0.0461s/iter; left time: 969.9724s\n",
      "\titers: 200, epoch: 7 | loss: 0.0781120\n",
      "\tspeed: 0.0276s/iter; left time: 579.2798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 225 | Train Loss: 0.0800917 Vali Loss: 0.0758637 Test Loss: 0.0813290\n",
      "Validation loss decreased (0.076527 --> 0.075864).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0814507\n",
      "\tspeed: 0.0521s/iter; left time: 1085.3334s\n",
      "\titers: 200, epoch: 8 | loss: 0.0810540\n",
      "\tspeed: 0.0334s/iter; left time: 691.5035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 225 | Train Loss: 0.0794074 Vali Loss: 0.0757473 Test Loss: 0.0809703\n",
      "Validation loss decreased (0.075864 --> 0.075747).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0785709\n",
      "\tspeed: 0.0549s/iter; left time: 1130.6216s\n",
      "\titers: 200, epoch: 9 | loss: 0.0773229\n",
      "\tspeed: 0.0297s/iter; left time: 607.9262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 225 | Train Loss: 0.0788632 Vali Loss: 0.0751910 Test Loss: 0.0805931\n",
      "Validation loss decreased (0.075747 --> 0.075191).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0808593\n",
      "\tspeed: 0.0521s/iter; left time: 1060.7529s\n",
      "\titers: 200, epoch: 10 | loss: 0.0760220\n",
      "\tspeed: 0.0268s/iter; left time: 543.8240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0784034 Vali Loss: 0.0749507 Test Loss: 0.0803177\n",
      "Validation loss decreased (0.075191 --> 0.074951).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0816761\n",
      "\tspeed: 0.0510s/iter; left time: 1028.2459s\n",
      "\titers: 200, epoch: 11 | loss: 0.0758451\n",
      "\tspeed: 0.0308s/iter; left time: 617.6004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0780377 Vali Loss: 0.0748240 Test Loss: 0.0803157\n",
      "Validation loss decreased (0.074951 --> 0.074824).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0733595\n",
      "\tspeed: 0.0603s/iter; left time: 1202.2466s\n",
      "\titers: 200, epoch: 12 | loss: 0.0775170\n",
      "\tspeed: 0.0290s/iter; left time: 575.4367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 225 | Train Loss: 0.0777423 Vali Loss: 0.0747157 Test Loss: 0.0800200\n",
      "Validation loss decreased (0.074824 --> 0.074716).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0778685\n",
      "\tspeed: 0.0527s/iter; left time: 1038.8944s\n",
      "\titers: 200, epoch: 13 | loss: 0.0779369\n",
      "\tspeed: 0.0263s/iter; left time: 515.0068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 225 | Train Loss: 0.0774560 Vali Loss: 0.0745607 Test Loss: 0.0800957\n",
      "Validation loss decreased (0.074716 --> 0.074561).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752640\n",
      "\tspeed: 0.0504s/iter; left time: 980.9766s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772109\n",
      "\tspeed: 0.0243s/iter; left time: 470.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 225 | Train Loss: 0.0771855 Vali Loss: 0.0745269 Test Loss: 0.0799434\n",
      "Validation loss decreased (0.074561 --> 0.074527).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755306\n",
      "\tspeed: 0.0496s/iter; left time: 955.6114s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763766\n",
      "\tspeed: 0.0236s/iter; left time: 452.3277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0770187 Vali Loss: 0.0743560 Test Loss: 0.0797780\n",
      "Validation loss decreased (0.074527 --> 0.074356).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0805588\n",
      "\tspeed: 0.0482s/iter; left time: 917.4913s\n",
      "\titers: 200, epoch: 16 | loss: 0.0789654\n",
      "\tspeed: 0.0208s/iter; left time: 393.3317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 225 | Train Loss: 0.0768375 Vali Loss: 0.0743071 Test Loss: 0.0798205\n",
      "Validation loss decreased (0.074356 --> 0.074307).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0784135\n",
      "\tspeed: 0.0448s/iter; left time: 841.6925s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752202\n",
      "\tspeed: 0.0219s/iter; left time: 409.7830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 225 | Train Loss: 0.0767227 Vali Loss: 0.0742462 Test Loss: 0.0797481\n",
      "Validation loss decreased (0.074307 --> 0.074246).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0782087\n",
      "\tspeed: 0.0528s/iter; left time: 981.6482s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795883\n",
      "\tspeed: 0.0280s/iter; left time: 516.6581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0765944 Vali Loss: 0.0742247 Test Loss: 0.0797466\n",
      "Validation loss decreased (0.074246 --> 0.074225).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0779423\n",
      "\tspeed: 0.0543s/iter; left time: 996.7476s\n",
      "\titers: 200, epoch: 19 | loss: 0.0741632\n",
      "\tspeed: 0.0262s/iter; left time: 478.3752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0764083 Vali Loss: 0.0741696 Test Loss: 0.0796356\n",
      "Validation loss decreased (0.074225 --> 0.074170).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0784153\n",
      "\tspeed: 0.0463s/iter; left time: 840.1191s\n",
      "\titers: 200, epoch: 20 | loss: 0.0784849\n",
      "\tspeed: 0.0253s/iter; left time: 455.2760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 225 | Train Loss: 0.0763808 Vali Loss: 0.0740472 Test Loss: 0.0795232\n",
      "Validation loss decreased (0.074170 --> 0.074047).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0737283\n",
      "\tspeed: 0.0501s/iter; left time: 897.6407s\n",
      "\titers: 200, epoch: 21 | loss: 0.0750930\n",
      "\tspeed: 0.0261s/iter; left time: 464.9249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0762870 Vali Loss: 0.0741221 Test Loss: 0.0796024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0750439\n",
      "\tspeed: 0.0537s/iter; left time: 948.5754s\n",
      "\titers: 200, epoch: 22 | loss: 0.0800672\n",
      "\tspeed: 0.0309s/iter; left time: 543.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 225 | Train Loss: 0.0761221 Vali Loss: 0.0740300 Test Loss: 0.0795310\n",
      "Validation loss decreased (0.074047 --> 0.074030).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740797\n",
      "\tspeed: 0.0544s/iter; left time: 948.6721s\n",
      "\titers: 200, epoch: 23 | loss: 0.0691196\n",
      "\tspeed: 0.0264s/iter; left time: 458.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 225 | Train Loss: 0.0760698 Vali Loss: 0.0740356 Test Loss: 0.0795706\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0743738\n",
      "\tspeed: 0.0540s/iter; left time: 929.5278s\n",
      "\titers: 200, epoch: 24 | loss: 0.0797742\n",
      "\tspeed: 0.0297s/iter; left time: 508.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 225 | Train Loss: 0.0760023 Vali Loss: 0.0739953 Test Loss: 0.0795833\n",
      "Validation loss decreased (0.074030 --> 0.073995).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0774466\n",
      "\tspeed: 0.0435s/iter; left time: 740.1664s\n",
      "\titers: 200, epoch: 25 | loss: 0.0778909\n",
      "\tspeed: 0.0188s/iter; left time: 317.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0759958 Vali Loss: 0.0740413 Test Loss: 0.0795815\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0780001\n",
      "\tspeed: 0.0422s/iter; left time: 707.2411s\n",
      "\titers: 200, epoch: 26 | loss: 0.0763809\n",
      "\tspeed: 0.0254s/iter; left time: 423.2670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 225 | Train Loss: 0.0758109 Vali Loss: 0.0740130 Test Loss: 0.0795372\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0759217\n",
      "\tspeed: 0.0567s/iter; left time: 937.9791s\n",
      "\titers: 200, epoch: 27 | loss: 0.0768139\n",
      "\tspeed: 0.0304s/iter; left time: 500.3218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 225 | Train Loss: 0.0758581 Vali Loss: 0.0739008 Test Loss: 0.0794840\n",
      "Validation loss decreased (0.073995 --> 0.073901).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0809324\n",
      "\tspeed: 0.0438s/iter; left time: 715.3982s\n",
      "\titers: 200, epoch: 28 | loss: 0.0707953\n",
      "\tspeed: 0.0188s/iter; left time: 304.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0758429 Vali Loss: 0.0738786 Test Loss: 0.0794998\n",
      "Validation loss decreased (0.073901 --> 0.073879).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0721506\n",
      "\tspeed: 0.0462s/iter; left time: 744.3248s\n",
      "\titers: 200, epoch: 29 | loss: 0.0742410\n",
      "\tspeed: 0.0302s/iter; left time: 483.5339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 225 | Train Loss: 0.0757575 Vali Loss: 0.0739099 Test Loss: 0.0795173\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0775100\n",
      "\tspeed: 0.0636s/iter; left time: 1009.4665s\n",
      "\titers: 200, epoch: 30 | loss: 0.0723973\n",
      "\tspeed: 0.0365s/iter; left time: 575.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 225 | Train Loss: 0.0757562 Vali Loss: 0.0739307 Test Loss: 0.0795078\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0801369\n",
      "\tspeed: 0.0570s/iter; left time: 892.0156s\n",
      "\titers: 200, epoch: 31 | loss: 0.0784943\n",
      "\tspeed: 0.0268s/iter; left time: 416.8109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 225 | Train Loss: 0.0757115 Vali Loss: 0.0738676 Test Loss: 0.0795069\n",
      "Validation loss decreased (0.073879 --> 0.073868).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0789659\n",
      "\tspeed: 0.0529s/iter; left time: 816.0835s\n",
      "\titers: 200, epoch: 32 | loss: 0.0737221\n",
      "\tspeed: 0.0345s/iter; left time: 528.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 225 | Train Loss: 0.0756342 Vali Loss: 0.0738669 Test Loss: 0.0795308\n",
      "Validation loss decreased (0.073868 --> 0.073867).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0721539\n",
      "\tspeed: 0.0521s/iter; left time: 791.6168s\n",
      "\titers: 200, epoch: 33 | loss: 0.0724874\n",
      "\tspeed: 0.0272s/iter; left time: 410.0313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 225 | Train Loss: 0.0755756 Vali Loss: 0.0738196 Test Loss: 0.0794518\n",
      "Validation loss decreased (0.073867 --> 0.073820).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0746614\n",
      "\tspeed: 0.0570s/iter; left time: 853.1540s\n",
      "\titers: 200, epoch: 34 | loss: 0.0746784\n",
      "\tspeed: 0.0306s/iter; left time: 454.9447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 225 | Train Loss: 0.0756492 Vali Loss: 0.0738246 Test Loss: 0.0794897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0766999\n",
      "\tspeed: 0.0462s/iter; left time: 681.5345s\n",
      "\titers: 200, epoch: 35 | loss: 0.0754725\n",
      "\tspeed: 0.0255s/iter; left time: 373.9855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 225 | Train Loss: 0.0755886 Vali Loss: 0.0738690 Test Loss: 0.0794683\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0751653\n",
      "\tspeed: 0.0511s/iter; left time: 742.1519s\n",
      "\titers: 200, epoch: 36 | loss: 0.0764476\n",
      "\tspeed: 0.0305s/iter; left time: 440.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 225 | Train Loss: 0.0755780 Vali Loss: 0.0738295 Test Loss: 0.0794947\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0764202\n",
      "\tspeed: 0.0550s/iter; left time: 786.9232s\n",
      "\titers: 200, epoch: 37 | loss: 0.0727640\n",
      "\tspeed: 0.0314s/iter; left time: 446.1023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 225 | Train Loss: 0.0755563 Vali Loss: 0.0738518 Test Loss: 0.0794914\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0752195\n",
      "\tspeed: 0.0476s/iter; left time: 670.1916s\n",
      "\titers: 200, epoch: 38 | loss: 0.0756702\n",
      "\tspeed: 0.0291s/iter; left time: 406.6700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0755056 Vali Loss: 0.0738162 Test Loss: 0.0794783\n",
      "Validation loss decreased (0.073820 --> 0.073816).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0771633\n",
      "\tspeed: 0.0480s/iter; left time: 664.7757s\n",
      "\titers: 200, epoch: 39 | loss: 0.0776391\n",
      "\tspeed: 0.0294s/iter; left time: 404.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 225 | Train Loss: 0.0754969 Vali Loss: 0.0738267 Test Loss: 0.0794866\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0803662\n",
      "\tspeed: 0.0568s/iter; left time: 774.3166s\n",
      "\titers: 200, epoch: 40 | loss: 0.0739795\n",
      "\tspeed: 0.0248s/iter; left time: 335.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0754540 Vali Loss: 0.0738386 Test Loss: 0.0794849\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0799819\n",
      "\tspeed: 0.0521s/iter; left time: 698.3912s\n",
      "\titers: 200, epoch: 41 | loss: 0.0724458\n",
      "\tspeed: 0.0280s/iter; left time: 372.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0755010 Vali Loss: 0.0738616 Test Loss: 0.0794929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0770340\n",
      "\tspeed: 0.0449s/iter; left time: 592.0953s\n",
      "\titers: 200, epoch: 42 | loss: 0.0735448\n",
      "\tspeed: 0.0283s/iter; left time: 369.4020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 225 | Train Loss: 0.0755102 Vali Loss: 0.0738463 Test Loss: 0.0794932\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0760082\n",
      "\tspeed: 0.0485s/iter; left time: 628.2887s\n",
      "\titers: 200, epoch: 43 | loss: 0.0749146\n",
      "\tspeed: 0.0307s/iter; left time: 394.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 225 | Train Loss: 0.0754570 Vali Loss: 0.0737946 Test Loss: 0.0794973\n",
      "Validation loss decreased (0.073816 --> 0.073795).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0756610\n",
      "\tspeed: 0.0493s/iter; left time: 627.4488s\n",
      "\titers: 200, epoch: 44 | loss: 0.0774383\n",
      "\tspeed: 0.0303s/iter; left time: 383.1854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 225 | Train Loss: 0.0754674 Vali Loss: 0.0738476 Test Loss: 0.0795091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0734283\n",
      "\tspeed: 0.0564s/iter; left time: 704.6256s\n",
      "\titers: 200, epoch: 45 | loss: 0.0710394\n",
      "\tspeed: 0.0351s/iter; left time: 434.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 225 | Train Loss: 0.0754520 Vali Loss: 0.0738455 Test Loss: 0.0795059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0708159\n",
      "\tspeed: 0.0521s/iter; left time: 639.9318s\n",
      "\titers: 200, epoch: 46 | loss: 0.0780994\n",
      "\tspeed: 0.0256s/iter; left time: 311.2912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0754575 Vali Loss: 0.0738445 Test Loss: 0.0794902\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0724014\n",
      "\tspeed: 0.0518s/iter; left time: 624.2553s\n",
      "\titers: 200, epoch: 47 | loss: 0.0738643\n",
      "\tspeed: 0.0299s/iter; left time: 356.8371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 225 | Train Loss: 0.0754107 Vali Loss: 0.0738300 Test Loss: 0.0794834\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0786052\n",
      "\tspeed: 0.0486s/iter; left time: 574.9446s\n",
      "\titers: 200, epoch: 48 | loss: 0.0770917\n",
      "\tspeed: 0.0221s/iter; left time: 258.6979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 225 | Train Loss: 0.0754408 Vali Loss: 0.0738190 Test Loss: 0.0794723\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0754975\n",
      "\tspeed: 0.0450s/iter; left time: 522.3499s\n",
      "\titers: 200, epoch: 49 | loss: 0.0771508\n",
      "\tspeed: 0.0259s/iter; left time: 298.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0754946 Vali Loss: 0.0738595 Test Loss: 0.0794853\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0757545\n",
      "\tspeed: 0.0557s/iter; left time: 633.3106s\n",
      "\titers: 200, epoch: 50 | loss: 0.0732413\n",
      "\tspeed: 0.0333s/iter; left time: 375.8303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 225 | Train Loss: 0.0754509 Vali Loss: 0.0738343 Test Loss: 0.0794914\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0757393\n",
      "\tspeed: 0.0489s/iter; left time: 545.3981s\n",
      "\titers: 200, epoch: 51 | loss: 0.0788999\n",
      "\tspeed: 0.0268s/iter; left time: 296.4821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 225 | Train Loss: 0.0754437 Vali Loss: 0.0738431 Test Loss: 0.0794810\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0761891\n",
      "\tspeed: 0.0492s/iter; left time: 537.5366s\n",
      "\titers: 200, epoch: 52 | loss: 0.0724254\n",
      "\tspeed: 0.0295s/iter; left time: 319.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 225 | Train Loss: 0.0754188 Vali Loss: 0.0738193 Test Loss: 0.0794760\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0762165\n",
      "\tspeed: 0.0516s/iter; left time: 552.3373s\n",
      "\titers: 200, epoch: 53 | loss: 0.0760677\n",
      "\tspeed: 0.0290s/iter; left time: 306.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 225 | Train Loss: 0.0754509 Vali Loss: 0.0737906 Test Loss: 0.0794727\n",
      "Validation loss decreased (0.073795 --> 0.073791).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0756035\n",
      "\tspeed: 0.0538s/iter; left time: 563.9505s\n",
      "\titers: 200, epoch: 54 | loss: 0.0773814\n",
      "\tspeed: 0.0269s/iter; left time: 279.1261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0754188 Vali Loss: 0.0738212 Test Loss: 0.0794904\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0711235\n",
      "\tspeed: 0.0427s/iter; left time: 437.2315s\n",
      "\titers: 200, epoch: 55 | loss: 0.0735966\n",
      "\tspeed: 0.0189s/iter; left time: 192.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0754077 Vali Loss: 0.0738077 Test Loss: 0.0794723\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0755664\n",
      "\tspeed: 0.0489s/iter; left time: 489.9243s\n",
      "\titers: 200, epoch: 56 | loss: 0.0748949\n",
      "\tspeed: 0.0227s/iter; left time: 225.1873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0754186 Vali Loss: 0.0738800 Test Loss: 0.0795176\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0737460\n",
      "\tspeed: 0.0482s/iter; left time: 472.0786s\n",
      "\titers: 200, epoch: 57 | loss: 0.0724761\n",
      "\tspeed: 0.0295s/iter; left time: 285.9189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 225 | Train Loss: 0.0754397 Vali Loss: 0.0738223 Test Loss: 0.0794878\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0727171\n",
      "\tspeed: 0.0525s/iter; left time: 502.8817s\n",
      "\titers: 200, epoch: 58 | loss: 0.0756273\n",
      "\tspeed: 0.0307s/iter; left time: 290.5225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 225 | Train Loss: 0.0754023 Vali Loss: 0.0737841 Test Loss: 0.0794823\n",
      "Validation loss decreased (0.073791 --> 0.073784).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0730906\n",
      "\tspeed: 0.0515s/iter; left time: 481.7092s\n",
      "\titers: 200, epoch: 59 | loss: 0.0772122\n",
      "\tspeed: 0.0287s/iter; left time: 265.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 225 | Train Loss: 0.0754130 Vali Loss: 0.0738190 Test Loss: 0.0794906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0736467\n",
      "\tspeed: 0.0475s/iter; left time: 433.2226s\n",
      "\titers: 200, epoch: 60 | loss: 0.0755759\n",
      "\tspeed: 0.0248s/iter; left time: 223.8422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 225 | Train Loss: 0.0753993 Vali Loss: 0.0738504 Test Loss: 0.0795066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0751130\n",
      "\tspeed: 0.0498s/iter; left time: 443.0488s\n",
      "\titers: 200, epoch: 61 | loss: 0.0753030\n",
      "\tspeed: 0.0285s/iter; left time: 251.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0753909 Vali Loss: 0.0738311 Test Loss: 0.0794865\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0757755\n",
      "\tspeed: 0.0534s/iter; left time: 463.0460s\n",
      "\titers: 200, epoch: 62 | loss: 0.0695692\n",
      "\tspeed: 0.0285s/iter; left time: 244.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0753604 Vali Loss: 0.0738126 Test Loss: 0.0794836\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0758435\n",
      "\tspeed: 0.0484s/iter; left time: 409.0732s\n",
      "\titers: 200, epoch: 63 | loss: 0.0769937\n",
      "\tspeed: 0.0240s/iter; left time: 200.0368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 225 | Train Loss: 0.0753878 Vali Loss: 0.0738097 Test Loss: 0.0794762\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0750599\n",
      "\tspeed: 0.0480s/iter; left time: 394.6231s\n",
      "\titers: 200, epoch: 64 | loss: 0.0738896\n",
      "\tspeed: 0.0264s/iter; left time: 214.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 225 | Train Loss: 0.0754262 Vali Loss: 0.0738157 Test Loss: 0.0794868\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0800771\n",
      "\tspeed: 0.0418s/iter; left time: 334.2490s\n",
      "\titers: 200, epoch: 65 | loss: 0.0764180\n",
      "\tspeed: 0.0190s/iter; left time: 150.1695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0754034 Vali Loss: 0.0738054 Test Loss: 0.0794848\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0783498\n",
      "\tspeed: 0.0497s/iter; left time: 386.6184s\n",
      "\titers: 200, epoch: 66 | loss: 0.0783960\n",
      "\tspeed: 0.0250s/iter; left time: 191.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 225 | Train Loss: 0.0753819 Vali Loss: 0.0738158 Test Loss: 0.0794879\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0708528\n",
      "\tspeed: 0.0497s/iter; left time: 375.2506s\n",
      "\titers: 200, epoch: 67 | loss: 0.0710542\n",
      "\tspeed: 0.0250s/iter; left time: 186.0742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 225 | Train Loss: 0.0753369 Vali Loss: 0.0738132 Test Loss: 0.0794802\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0730779\n",
      "\tspeed: 0.0515s/iter; left time: 376.9654s\n",
      "\titers: 200, epoch: 68 | loss: 0.0792189\n",
      "\tspeed: 0.0301s/iter; left time: 217.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 225 | Train Loss: 0.0754393 Vali Loss: 0.0738283 Test Loss: 0.0794841\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01832953467965126, rmse:0.1353866159915924, mae:0.0794823169708252, rse:0.5119113922119141\n",
      "Intermediate time for IT and pred_len 96: 00h:15m:47.76s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1870383\n",
      "\tspeed: 0.0530s/iter; left time: 1187.6223s\n",
      "\titers: 200, epoch: 1 | loss: 0.1715603\n",
      "\tspeed: 0.0222s/iter; left time: 494.7917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 225 | Train Loss: 0.1853553 Vali Loss: 0.1568048 Test Loss: 0.1660703\n",
      "Validation loss decreased (inf --> 0.156805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1076143\n",
      "\tspeed: 0.0451s/iter; left time: 1000.7689s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932135\n",
      "\tspeed: 0.0239s/iter; left time: 528.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 225 | Train Loss: 0.1145113 Vali Loss: 0.0890583 Test Loss: 0.0936706\n",
      "Validation loss decreased (0.156805 --> 0.089058).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0969614\n",
      "\tspeed: 0.0477s/iter; left time: 1047.5406s\n",
      "\titers: 200, epoch: 3 | loss: 0.0886289\n",
      "\tspeed: 0.0240s/iter; left time: 524.0215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 225 | Train Loss: 0.0935062 Vali Loss: 0.0845694 Test Loss: 0.0895883\n",
      "Validation loss decreased (0.089058 --> 0.084569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0874625\n",
      "\tspeed: 0.0533s/iter; left time: 1157.1418s\n",
      "\titers: 200, epoch: 4 | loss: 0.0900980\n",
      "\tspeed: 0.0245s/iter; left time: 530.1249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 225 | Train Loss: 0.0895805 Vali Loss: 0.0827342 Test Loss: 0.0878479\n",
      "Validation loss decreased (0.084569 --> 0.082734).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0844901\n",
      "\tspeed: 0.0457s/iter; left time: 982.2682s\n",
      "\titers: 200, epoch: 5 | loss: 0.0865713\n",
      "\tspeed: 0.0191s/iter; left time: 409.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 225 | Train Loss: 0.0872905 Vali Loss: 0.0817755 Test Loss: 0.0867167\n",
      "Validation loss decreased (0.082734 --> 0.081776).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0891566\n",
      "\tspeed: 0.0503s/iter; left time: 1069.9232s\n",
      "\titers: 200, epoch: 6 | loss: 0.0812639\n",
      "\tspeed: 0.0268s/iter; left time: 568.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 225 | Train Loss: 0.0859008 Vali Loss: 0.0814405 Test Loss: 0.0862796\n",
      "Validation loss decreased (0.081776 --> 0.081441).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0801779\n",
      "\tspeed: 0.0553s/iter; left time: 1164.4329s\n",
      "\titers: 200, epoch: 7 | loss: 0.0839427\n",
      "\tspeed: 0.0304s/iter; left time: 637.7103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 225 | Train Loss: 0.0851128 Vali Loss: 0.0811499 Test Loss: 0.0859220\n",
      "Validation loss decreased (0.081441 --> 0.081150).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0855081\n",
      "\tspeed: 0.0531s/iter; left time: 1106.5250s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827369\n",
      "\tspeed: 0.0248s/iter; left time: 513.7592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 225 | Train Loss: 0.0844766 Vali Loss: 0.0809494 Test Loss: 0.0854709\n",
      "Validation loss decreased (0.081150 --> 0.080949).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0828159\n",
      "\tspeed: 0.0535s/iter; left time: 1103.0341s\n",
      "\titers: 200, epoch: 9 | loss: 0.0814609\n",
      "\tspeed: 0.0249s/iter; left time: 509.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 225 | Train Loss: 0.0839091 Vali Loss: 0.0807725 Test Loss: 0.0852282\n",
      "Validation loss decreased (0.080949 --> 0.080772).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850896\n",
      "\tspeed: 0.0492s/iter; left time: 1003.0017s\n",
      "\titers: 200, epoch: 10 | loss: 0.0819488\n",
      "\tspeed: 0.0256s/iter; left time: 518.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 225 | Train Loss: 0.0835141 Vali Loss: 0.0806206 Test Loss: 0.0851980\n",
      "Validation loss decreased (0.080772 --> 0.080621).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0808780\n",
      "\tspeed: 0.0521s/iter; left time: 1050.3959s\n",
      "\titers: 200, epoch: 11 | loss: 0.0832348\n",
      "\tspeed: 0.0334s/iter; left time: 668.7740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0831508 Vali Loss: 0.0803353 Test Loss: 0.0851180\n",
      "Validation loss decreased (0.080621 --> 0.080335).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0817546\n",
      "\tspeed: 0.0523s/iter; left time: 1041.8946s\n",
      "\titers: 200, epoch: 12 | loss: 0.0817587\n",
      "\tspeed: 0.0256s/iter; left time: 507.0842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 225 | Train Loss: 0.0828775 Vali Loss: 0.0803466 Test Loss: 0.0849709\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0832407\n",
      "\tspeed: 0.0564s/iter; left time: 1111.2775s\n",
      "\titers: 200, epoch: 13 | loss: 0.0805905\n",
      "\tspeed: 0.0290s/iter; left time: 568.4872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 225 | Train Loss: 0.0826251 Vali Loss: 0.0803146 Test Loss: 0.0849297\n",
      "Validation loss decreased (0.080335 --> 0.080315).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0825088\n",
      "\tspeed: 0.0543s/iter; left time: 1057.6136s\n",
      "\titers: 200, epoch: 14 | loss: 0.0817128\n",
      "\tspeed: 0.0258s/iter; left time: 499.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0823843 Vali Loss: 0.0803333 Test Loss: 0.0849445\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803306\n",
      "\tspeed: 0.0517s/iter; left time: 995.6271s\n",
      "\titers: 200, epoch: 15 | loss: 0.0829988\n",
      "\tspeed: 0.0265s/iter; left time: 507.9526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0821832 Vali Loss: 0.0801801 Test Loss: 0.0849477\n",
      "Validation loss decreased (0.080315 --> 0.080180).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0843089\n",
      "\tspeed: 0.0529s/iter; left time: 1006.9692s\n",
      "\titers: 200, epoch: 16 | loss: 0.0825813\n",
      "\tspeed: 0.0241s/iter; left time: 455.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0819858 Vali Loss: 0.0800799 Test Loss: 0.0849492\n",
      "Validation loss decreased (0.080180 --> 0.080080).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0866396\n",
      "\tspeed: 0.0473s/iter; left time: 888.9542s\n",
      "\titers: 200, epoch: 17 | loss: 0.0802184\n",
      "\tspeed: 0.0297s/iter; left time: 556.3464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 225 | Train Loss: 0.0818580 Vali Loss: 0.0802803 Test Loss: 0.0850842\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0837353\n",
      "\tspeed: 0.0507s/iter; left time: 942.5106s\n",
      "\titers: 200, epoch: 18 | loss: 0.0844034\n",
      "\tspeed: 0.0250s/iter; left time: 462.1972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 225 | Train Loss: 0.0816901 Vali Loss: 0.0801386 Test Loss: 0.0850110\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0803253\n",
      "\tspeed: 0.0516s/iter; left time: 946.2819s\n",
      "\titers: 200, epoch: 19 | loss: 0.0813744\n",
      "\tspeed: 0.0276s/iter; left time: 503.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 225 | Train Loss: 0.0815585 Vali Loss: 0.0800813 Test Loss: 0.0849962\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0786014\n",
      "\tspeed: 0.0510s/iter; left time: 925.1082s\n",
      "\titers: 200, epoch: 20 | loss: 0.0859499\n",
      "\tspeed: 0.0268s/iter; left time: 483.9495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0814428 Vali Loss: 0.0799977 Test Loss: 0.0849762\n",
      "Validation loss decreased (0.080080 --> 0.079998).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0815522\n",
      "\tspeed: 0.0480s/iter; left time: 859.6618s\n",
      "\titers: 200, epoch: 21 | loss: 0.0823843\n",
      "\tspeed: 0.0241s/iter; left time: 428.7075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 225 | Train Loss: 0.0813704 Vali Loss: 0.0800583 Test Loss: 0.0850808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0800771\n",
      "\tspeed: 0.0472s/iter; left time: 834.5372s\n",
      "\titers: 200, epoch: 22 | loss: 0.0811914\n",
      "\tspeed: 0.0278s/iter; left time: 489.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 225 | Train Loss: 0.0812269 Vali Loss: 0.0800063 Test Loss: 0.0851742\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0807579\n",
      "\tspeed: 0.0457s/iter; left time: 797.1149s\n",
      "\titers: 200, epoch: 23 | loss: 0.0796830\n",
      "\tspeed: 0.0249s/iter; left time: 432.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 225 | Train Loss: 0.0811856 Vali Loss: 0.0799935 Test Loss: 0.0851762\n",
      "Validation loss decreased (0.079998 --> 0.079993).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0824995\n",
      "\tspeed: 0.0489s/iter; left time: 842.3694s\n",
      "\titers: 200, epoch: 24 | loss: 0.0829436\n",
      "\tspeed: 0.0237s/iter; left time: 405.9087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0810849 Vali Loss: 0.0800554 Test Loss: 0.0852059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0845193\n",
      "\tspeed: 0.0484s/iter; left time: 822.2740s\n",
      "\titers: 200, epoch: 25 | loss: 0.0822650\n",
      "\tspeed: 0.0193s/iter; left time: 325.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 225 | Train Loss: 0.0810041 Vali Loss: 0.0799557 Test Loss: 0.0851858\n",
      "Validation loss decreased (0.079993 --> 0.079956).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0829754\n",
      "\tspeed: 0.0541s/iter; left time: 907.8570s\n",
      "\titers: 200, epoch: 26 | loss: 0.0842279\n",
      "\tspeed: 0.0318s/iter; left time: 529.6312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 225 | Train Loss: 0.0809648 Vali Loss: 0.0800002 Test Loss: 0.0852860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0819412\n",
      "\tspeed: 0.0524s/iter; left time: 867.4836s\n",
      "\titers: 200, epoch: 27 | loss: 0.0816244\n",
      "\tspeed: 0.0304s/iter; left time: 500.5583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 225 | Train Loss: 0.0808716 Vali Loss: 0.0799935 Test Loss: 0.0852660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0802033\n",
      "\tspeed: 0.0460s/iter; left time: 750.7496s\n",
      "\titers: 200, epoch: 28 | loss: 0.0804373\n",
      "\tspeed: 0.0320s/iter; left time: 518.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0808384 Vali Loss: 0.0799336 Test Loss: 0.0852661\n",
      "Validation loss decreased (0.079956 --> 0.079934).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0805667\n",
      "\tspeed: 0.0523s/iter; left time: 841.6193s\n",
      "\titers: 200, epoch: 29 | loss: 0.0810601\n",
      "\tspeed: 0.0271s/iter; left time: 434.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 225 | Train Loss: 0.0808041 Vali Loss: 0.0799064 Test Loss: 0.0853089\n",
      "Validation loss decreased (0.079934 --> 0.079906).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0832688\n",
      "\tspeed: 0.0491s/iter; left time: 780.1163s\n",
      "\titers: 200, epoch: 30 | loss: 0.0829474\n",
      "\tspeed: 0.0264s/iter; left time: 416.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0808051 Vali Loss: 0.0798372 Test Loss: 0.0852992\n",
      "Validation loss decreased (0.079906 --> 0.079837).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778924\n",
      "\tspeed: 0.0481s/iter; left time: 752.3475s\n",
      "\titers: 200, epoch: 31 | loss: 0.0805558\n",
      "\tspeed: 0.0266s/iter; left time: 413.0506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0807081 Vali Loss: 0.0799277 Test Loss: 0.0853229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0875428\n",
      "\tspeed: 0.0496s/iter; left time: 764.7145s\n",
      "\titers: 200, epoch: 32 | loss: 0.0801462\n",
      "\tspeed: 0.0224s/iter; left time: 343.4367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0806755 Vali Loss: 0.0800014 Test Loss: 0.0854342\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0822497\n",
      "\tspeed: 0.0459s/iter; left time: 697.9711s\n",
      "\titers: 200, epoch: 33 | loss: 0.0821414\n",
      "\tspeed: 0.0190s/iter; left time: 287.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0806552 Vali Loss: 0.0800011 Test Loss: 0.0853880\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0797373\n",
      "\tspeed: 0.0487s/iter; left time: 729.9735s\n",
      "\titers: 200, epoch: 34 | loss: 0.0793358\n",
      "\tspeed: 0.0218s/iter; left time: 324.4152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0806553 Vali Loss: 0.0800313 Test Loss: 0.0854301\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0819117\n",
      "\tspeed: 0.0466s/iter; left time: 688.0043s\n",
      "\titers: 200, epoch: 35 | loss: 0.0796660\n",
      "\tspeed: 0.0258s/iter; left time: 378.5036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 225 | Train Loss: 0.0806135 Vali Loss: 0.0799569 Test Loss: 0.0854088\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0811039\n",
      "\tspeed: 0.0451s/iter; left time: 654.4638s\n",
      "\titers: 200, epoch: 36 | loss: 0.0808613\n",
      "\tspeed: 0.0247s/iter; left time: 355.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 225 | Train Loss: 0.0805913 Vali Loss: 0.0799412 Test Loss: 0.0854182\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0803814\n",
      "\tspeed: 0.0495s/iter; left time: 707.6192s\n",
      "\titers: 200, epoch: 37 | loss: 0.0787124\n",
      "\tspeed: 0.0282s/iter; left time: 400.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0805685 Vali Loss: 0.0798584 Test Loss: 0.0854245\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0817339\n",
      "\tspeed: 0.0548s/iter; left time: 771.6184s\n",
      "\titers: 200, epoch: 38 | loss: 0.0800650\n",
      "\tspeed: 0.0301s/iter; left time: 420.1460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 225 | Train Loss: 0.0805502 Vali Loss: 0.0798705 Test Loss: 0.0854187\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0804477\n",
      "\tspeed: 0.0451s/iter; left time: 624.7986s\n",
      "\titers: 200, epoch: 39 | loss: 0.0821592\n",
      "\tspeed: 0.0197s/iter; left time: 270.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0805305 Vali Loss: 0.0799363 Test Loss: 0.0854187\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0770451\n",
      "\tspeed: 0.0444s/iter; left time: 604.9656s\n",
      "\titers: 200, epoch: 40 | loss: 0.0820152\n",
      "\tspeed: 0.0255s/iter; left time: 345.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 225 | Train Loss: 0.0805570 Vali Loss: 0.0799209 Test Loss: 0.0854142\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019987324252724648, rmse:0.1413765400648117, mae:0.08529917895793915, rse:0.5350566506385803\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1840543\n",
      "\tspeed: 0.0283s/iter; left time: 635.0111s\n",
      "\titers: 200, epoch: 1 | loss: 0.1685224\n",
      "\tspeed: 0.0254s/iter; left time: 566.3328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 225 | Train Loss: 0.1844982 Vali Loss: 0.1566570 Test Loss: 0.1659417\n",
      "Validation loss decreased (inf --> 0.156657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1132285\n",
      "\tspeed: 0.0527s/iter; left time: 1167.6067s\n",
      "\titers: 200, epoch: 2 | loss: 0.1019533\n",
      "\tspeed: 0.0264s/iter; left time: 583.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.1153133 Vali Loss: 0.0894829 Test Loss: 0.0940419\n",
      "Validation loss decreased (0.156657 --> 0.089483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0906220\n",
      "\tspeed: 0.0489s/iter; left time: 1073.4433s\n",
      "\titers: 200, epoch: 3 | loss: 0.0922002\n",
      "\tspeed: 0.0222s/iter; left time: 484.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 225 | Train Loss: 0.0941500 Vali Loss: 0.0851695 Test Loss: 0.0901265\n",
      "Validation loss decreased (0.089483 --> 0.085170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0905102\n",
      "\tspeed: 0.0485s/iter; left time: 1053.2921s\n",
      "\titers: 200, epoch: 4 | loss: 0.0934588\n",
      "\tspeed: 0.0240s/iter; left time: 519.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 225 | Train Loss: 0.0901883 Vali Loss: 0.0833089 Test Loss: 0.0883095\n",
      "Validation loss decreased (0.085170 --> 0.083309).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0869687\n",
      "\tspeed: 0.0491s/iter; left time: 1054.7985s\n",
      "\titers: 200, epoch: 5 | loss: 0.0852287\n",
      "\tspeed: 0.0283s/iter; left time: 604.6821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0878854 Vali Loss: 0.0824049 Test Loss: 0.0873542\n",
      "Validation loss decreased (0.083309 --> 0.082405).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889387\n",
      "\tspeed: 0.0529s/iter; left time: 1126.1671s\n",
      "\titers: 200, epoch: 6 | loss: 0.0888741\n",
      "\tspeed: 0.0252s/iter; left time: 533.7237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0863424 Vali Loss: 0.0816884 Test Loss: 0.0865861\n",
      "Validation loss decreased (0.082405 --> 0.081688).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891346\n",
      "\tspeed: 0.0596s/iter; left time: 1255.0231s\n",
      "\titers: 200, epoch: 7 | loss: 0.0892126\n",
      "\tspeed: 0.0286s/iter; left time: 599.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 225 | Train Loss: 0.0854523 Vali Loss: 0.0814068 Test Loss: 0.0861835\n",
      "Validation loss decreased (0.081688 --> 0.081407).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0836080\n",
      "\tspeed: 0.0488s/iter; left time: 1016.3865s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833302\n",
      "\tspeed: 0.0244s/iter; left time: 504.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 225 | Train Loss: 0.0847868 Vali Loss: 0.0812494 Test Loss: 0.0859815\n",
      "Validation loss decreased (0.081407 --> 0.081249).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0844111\n",
      "\tspeed: 0.0481s/iter; left time: 991.9269s\n",
      "\titers: 200, epoch: 9 | loss: 0.0839203\n",
      "\tspeed: 0.0276s/iter; left time: 566.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 225 | Train Loss: 0.0842783 Vali Loss: 0.0809623 Test Loss: 0.0856916\n",
      "Validation loss decreased (0.081249 --> 0.080962).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0840827\n",
      "\tspeed: 0.0480s/iter; left time: 979.0573s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833659\n",
      "\tspeed: 0.0253s/iter; left time: 512.9400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 225 | Train Loss: 0.0837914 Vali Loss: 0.0807498 Test Loss: 0.0853891\n",
      "Validation loss decreased (0.080962 --> 0.080750).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844054\n",
      "\tspeed: 0.0503s/iter; left time: 1013.0260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0841210\n",
      "\tspeed: 0.0239s/iter; left time: 478.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 225 | Train Loss: 0.0834776 Vali Loss: 0.0806861 Test Loss: 0.0854105\n",
      "Validation loss decreased (0.080750 --> 0.080686).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0856243\n",
      "\tspeed: 0.0463s/iter; left time: 922.8811s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814999\n",
      "\tspeed: 0.0190s/iter; left time: 376.9476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 225 | Train Loss: 0.0831765 Vali Loss: 0.0805396 Test Loss: 0.0852748\n",
      "Validation loss decreased (0.080686 --> 0.080540).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0823201\n",
      "\tspeed: 0.0491s/iter; left time: 966.7401s\n",
      "\titers: 200, epoch: 13 | loss: 0.0824843\n",
      "\tspeed: 0.0291s/iter; left time: 570.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 225 | Train Loss: 0.0828718 Vali Loss: 0.0806253 Test Loss: 0.0853202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0857025\n",
      "\tspeed: 0.0480s/iter; left time: 935.2010s\n",
      "\titers: 200, epoch: 14 | loss: 0.0842681\n",
      "\tspeed: 0.0264s/iter; left time: 512.2026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0826168 Vali Loss: 0.0805015 Test Loss: 0.0852329\n",
      "Validation loss decreased (0.080540 --> 0.080502).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803370\n",
      "\tspeed: 0.0550s/iter; left time: 1058.3849s\n",
      "\titers: 200, epoch: 15 | loss: 0.0810816\n",
      "\tspeed: 0.0286s/iter; left time: 547.5990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 225 | Train Loss: 0.0824204 Vali Loss: 0.0803796 Test Loss: 0.0851721\n",
      "Validation loss decreased (0.080502 --> 0.080380).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0836899\n",
      "\tspeed: 0.0481s/iter; left time: 914.3237s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845447\n",
      "\tspeed: 0.0247s/iter; left time: 467.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0822336 Vali Loss: 0.0804758 Test Loss: 0.0853276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848320\n",
      "\tspeed: 0.0542s/iter; left time: 1018.5180s\n",
      "\titers: 200, epoch: 17 | loss: 0.0789179\n",
      "\tspeed: 0.0303s/iter; left time: 566.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 225 | Train Loss: 0.0820664 Vali Loss: 0.0803697 Test Loss: 0.0852048\n",
      "Validation loss decreased (0.080380 --> 0.080370).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0851984\n",
      "\tspeed: 0.0490s/iter; left time: 909.3852s\n",
      "\titers: 200, epoch: 18 | loss: 0.0820806\n",
      "\tspeed: 0.0269s/iter; left time: 497.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0819157 Vali Loss: 0.0804346 Test Loss: 0.0851734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0839131\n",
      "\tspeed: 0.0475s/iter; left time: 872.3472s\n",
      "\titers: 200, epoch: 19 | loss: 0.0830659\n",
      "\tspeed: 0.0198s/iter; left time: 362.2307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 225 | Train Loss: 0.0817556 Vali Loss: 0.0803696 Test Loss: 0.0851382\n",
      "Validation loss decreased (0.080370 --> 0.080370).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0845550\n",
      "\tspeed: 0.0535s/iter; left time: 968.8931s\n",
      "\titers: 200, epoch: 20 | loss: 0.0835551\n",
      "\tspeed: 0.0266s/iter; left time: 479.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 225 | Train Loss: 0.0816904 Vali Loss: 0.0804153 Test Loss: 0.0852913\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0853033\n",
      "\tspeed: 0.0560s/iter; left time: 1002.1862s\n",
      "\titers: 200, epoch: 21 | loss: 0.0811036\n",
      "\tspeed: 0.0253s/iter; left time: 450.2199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 225 | Train Loss: 0.0815676 Vali Loss: 0.0803861 Test Loss: 0.0852296\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0832729\n",
      "\tspeed: 0.0571s/iter; left time: 1009.6678s\n",
      "\titers: 200, epoch: 22 | loss: 0.0833033\n",
      "\tspeed: 0.0340s/iter; left time: 597.6241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 225 | Train Loss: 0.0814544 Vali Loss: 0.0803558 Test Loss: 0.0851281\n",
      "Validation loss decreased (0.080370 --> 0.080356).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0812934\n",
      "\tspeed: 0.0559s/iter; left time: 975.0119s\n",
      "\titers: 200, epoch: 23 | loss: 0.0778939\n",
      "\tspeed: 0.0267s/iter; left time: 463.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 225 | Train Loss: 0.0813538 Vali Loss: 0.0803401 Test Loss: 0.0851232\n",
      "Validation loss decreased (0.080356 --> 0.080340).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0798932\n",
      "\tspeed: 0.0542s/iter; left time: 934.5044s\n",
      "\titers: 200, epoch: 24 | loss: 0.0799176\n",
      "\tspeed: 0.0246s/iter; left time: 421.9901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 225 | Train Loss: 0.0813174 Vali Loss: 0.0803973 Test Loss: 0.0851114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0781831\n",
      "\tspeed: 0.0552s/iter; left time: 937.7107s\n",
      "\titers: 200, epoch: 25 | loss: 0.0801677\n",
      "\tspeed: 0.0303s/iter; left time: 512.7122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 225 | Train Loss: 0.0812149 Vali Loss: 0.0803270 Test Loss: 0.0851396\n",
      "Validation loss decreased (0.080340 --> 0.080327).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0842388\n",
      "\tspeed: 0.0513s/iter; left time: 860.3276s\n",
      "\titers: 200, epoch: 26 | loss: 0.0848632\n",
      "\tspeed: 0.0288s/iter; left time: 479.7731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.0811977 Vali Loss: 0.0804594 Test Loss: 0.0851851\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0855992\n",
      "\tspeed: 0.0502s/iter; left time: 831.0068s\n",
      "\titers: 200, epoch: 27 | loss: 0.0824470\n",
      "\tspeed: 0.0261s/iter; left time: 429.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0810765 Vali Loss: 0.0802903 Test Loss: 0.0852222\n",
      "Validation loss decreased (0.080327 --> 0.080290).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0795919\n",
      "\tspeed: 0.0512s/iter; left time: 835.5050s\n",
      "\titers: 200, epoch: 28 | loss: 0.0814527\n",
      "\tspeed: 0.0267s/iter; left time: 432.9729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 225 | Train Loss: 0.0810530 Vali Loss: 0.0803517 Test Loss: 0.0851737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0819565\n",
      "\tspeed: 0.0525s/iter; left time: 845.1188s\n",
      "\titers: 200, epoch: 29 | loss: 0.0810080\n",
      "\tspeed: 0.0291s/iter; left time: 465.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 225 | Train Loss: 0.0810184 Vali Loss: 0.0804359 Test Loss: 0.0852643\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0857717\n",
      "\tspeed: 0.0540s/iter; left time: 857.7606s\n",
      "\titers: 200, epoch: 30 | loss: 0.0759639\n",
      "\tspeed: 0.0271s/iter; left time: 427.2497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0809112 Vali Loss: 0.0804278 Test Loss: 0.0852496\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0843048\n",
      "\tspeed: 0.0494s/iter; left time: 772.7096s\n",
      "\titers: 200, epoch: 31 | loss: 0.0825789\n",
      "\tspeed: 0.0282s/iter; left time: 437.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 225 | Train Loss: 0.0809512 Vali Loss: 0.0802745 Test Loss: 0.0851780\n",
      "Validation loss decreased (0.080290 --> 0.080275).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0817797\n",
      "\tspeed: 0.0573s/iter; left time: 884.3511s\n",
      "\titers: 200, epoch: 32 | loss: 0.0841645\n",
      "\tspeed: 0.0266s/iter; left time: 407.2445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 225 | Train Loss: 0.0808820 Vali Loss: 0.0804246 Test Loss: 0.0852316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0790420\n",
      "\tspeed: 0.0505s/iter; left time: 768.1035s\n",
      "\titers: 200, epoch: 33 | loss: 0.0808264\n",
      "\tspeed: 0.0211s/iter; left time: 318.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0808836 Vali Loss: 0.0803094 Test Loss: 0.0852217\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0813956\n",
      "\tspeed: 0.0495s/iter; left time: 741.3969s\n",
      "\titers: 200, epoch: 34 | loss: 0.0802785\n",
      "\tspeed: 0.0257s/iter; left time: 382.4833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0808873 Vali Loss: 0.0803756 Test Loss: 0.0852348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0820862\n",
      "\tspeed: 0.0477s/iter; left time: 704.0633s\n",
      "\titers: 200, epoch: 35 | loss: 0.0778505\n",
      "\tspeed: 0.0248s/iter; left time: 363.7288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 225 | Train Loss: 0.0807801 Vali Loss: 0.0803882 Test Loss: 0.0852780\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0843533\n",
      "\tspeed: 0.0449s/iter; left time: 651.6178s\n",
      "\titers: 200, epoch: 36 | loss: 0.0829121\n",
      "\tspeed: 0.0245s/iter; left time: 353.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 225 | Train Loss: 0.0807507 Vali Loss: 0.0804198 Test Loss: 0.0852077\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0747861\n",
      "\tspeed: 0.0542s/iter; left time: 775.0166s\n",
      "\titers: 200, epoch: 37 | loss: 0.0831783\n",
      "\tspeed: 0.0299s/iter; left time: 424.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 225 | Train Loss: 0.0807784 Vali Loss: 0.0803491 Test Loss: 0.0852391\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0808313\n",
      "\tspeed: 0.0464s/iter; left time: 653.1537s\n",
      "\titers: 200, epoch: 38 | loss: 0.0774353\n",
      "\tspeed: 0.0224s/iter; left time: 312.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 225 | Train Loss: 0.0807539 Vali Loss: 0.0803463 Test Loss: 0.0851984\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0803528\n",
      "\tspeed: 0.0485s/iter; left time: 672.2164s\n",
      "\titers: 200, epoch: 39 | loss: 0.0773313\n",
      "\tspeed: 0.0223s/iter; left time: 306.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 225 | Train Loss: 0.0807201 Vali Loss: 0.0804620 Test Loss: 0.0852809\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0826981\n",
      "\tspeed: 0.0494s/iter; left time: 672.8553s\n",
      "\titers: 200, epoch: 40 | loss: 0.0803929\n",
      "\tspeed: 0.0264s/iter; left time: 357.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 225 | Train Loss: 0.0807109 Vali Loss: 0.0804412 Test Loss: 0.0852437\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0817502\n",
      "\tspeed: 0.0475s/iter; left time: 636.1647s\n",
      "\titers: 200, epoch: 41 | loss: 0.0825093\n",
      "\tspeed: 0.0288s/iter; left time: 382.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0806799 Vali Loss: 0.0804509 Test Loss: 0.0852655\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019877824932336807, rmse:0.14098873734474182, mae:0.08517807722091675, rse:0.5335890054702759\n",
      "Intermediate time for IT and pred_len 168: 00h:10m:31.71s\n",
      "Intermediate time for IT: 00h:43m:32.29s\n",
      "Total time: 03h:46m:41.65s\n"
     ]
    }
   ],
   "source": [
    "# Here so long because someone started running his 2 processes on my GPU while I was running my code >:( without it, it runs 3-4 hours.\n",
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            if country == \"DE\" and pred_len == 24:\n",
    "                seq_len = 336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "                \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.0852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0213  0.1458  0.0891\n",
       "        96              0.0356  0.1887  0.1254\n",
       "        168             0.0380  0.1950  0.1324\n",
       "ES      24              0.0098  0.0991  0.0595\n",
       "        96              0.0186  0.1364  0.0868\n",
       "        168             0.0212  0.1455  0.0953\n",
       "FR      24              0.0099  0.0995  0.0542\n",
       "        96              0.0192  0.1385  0.0795\n",
       "        168             0.0207  0.1439  0.0857\n",
       "GB      24              0.0257  0.1603  0.1023\n",
       "        96              0.0442  0.2103  0.1428\n",
       "        168             0.0447  0.2114  0.1468\n",
       "IT      24              0.0101  0.1005  0.0569\n",
       "        96              0.0183  0.1353  0.0796\n",
       "        168             0.0199  0.1412  0.0852"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
