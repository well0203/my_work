{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [Standard Scaler](#standard-scaler)\n",
    "  - [1. Informer results](#1-informer-results)\n",
    "  - [2. PatchTST results](#2-patchtst-results)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "Please note, in order to run this script you have to change scaler to **StandardScaler** in data_loader.py of PatchTST_main folder and remove **ReLu** activation function from Informer and PatchTST models, where they generate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Informer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8668807\n",
      "\tspeed: 0.0673s/iter; left time: 603.4237s\n",
      "\titers: 200, epoch: 1 | loss: 0.7329679\n",
      "\tspeed: 0.0405s/iter; left time: 359.0980s\n",
      "\titers: 300, epoch: 1 | loss: 0.5921891\n",
      "\tspeed: 0.0404s/iter; left time: 353.7675s\n",
      "\titers: 400, epoch: 1 | loss: 0.5284466\n",
      "\tspeed: 0.0405s/iter; left time: 350.3841s\n",
      "\titers: 500, epoch: 1 | loss: 0.4583203\n",
      "\tspeed: 0.0400s/iter; left time: 342.6730s\n",
      "\titers: 600, epoch: 1 | loss: 0.4369217\n",
      "\tspeed: 0.0405s/iter; left time: 342.5500s\n",
      "\titers: 700, epoch: 1 | loss: 0.6045229\n",
      "\tspeed: 0.0403s/iter; left time: 337.2507s\n",
      "\titers: 800, epoch: 1 | loss: 0.4428935\n",
      "\tspeed: 0.0402s/iter; left time: 332.0334s\n",
      "\titers: 900, epoch: 1 | loss: 0.3517039\n",
      "\tspeed: 0.0404s/iter; left time: 330.0730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 906 | Train Loss: 0.5982595 Vali Loss: 0.5633035 Test Loss: 0.6410481\n",
      "Validation loss decreased (inf --> 0.563303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2530900\n",
      "\tspeed: 0.0971s/iter; left time: 782.5207s\n",
      "\titers: 200, epoch: 2 | loss: 0.4280434\n",
      "\tspeed: 0.0404s/iter; left time: 321.6280s\n",
      "\titers: 300, epoch: 2 | loss: 0.2945775\n",
      "\tspeed: 0.0403s/iter; left time: 316.1732s\n",
      "\titers: 400, epoch: 2 | loss: 0.3808749\n",
      "\tspeed: 0.0405s/iter; left time: 313.8016s\n",
      "\titers: 500, epoch: 2 | loss: 0.2412574\n",
      "\tspeed: 0.0403s/iter; left time: 308.6059s\n",
      "\titers: 600, epoch: 2 | loss: 0.2762078\n",
      "\tspeed: 0.0406s/iter; left time: 306.3896s\n",
      "\titers: 700, epoch: 2 | loss: 0.2622375\n",
      "\tspeed: 0.0407s/iter; left time: 303.5380s\n",
      "\titers: 800, epoch: 2 | loss: 0.3842992\n",
      "\tspeed: 0.0403s/iter; left time: 296.4802s\n",
      "\titers: 900, epoch: 2 | loss: 0.2897162\n",
      "\tspeed: 0.0404s/iter; left time: 293.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.89s\n",
      "Steps: 906 | Train Loss: 0.3337178 Vali Loss: 0.4458787 Test Loss: 0.5076840\n",
      "Validation loss decreased (0.563303 --> 0.445879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3126185\n",
      "\tspeed: 0.0982s/iter; left time: 701.9712s\n",
      "\titers: 200, epoch: 3 | loss: 0.2431651\n",
      "\tspeed: 0.0405s/iter; left time: 285.5208s\n",
      "\titers: 300, epoch: 3 | loss: 0.2869850\n",
      "\tspeed: 0.0405s/iter; left time: 281.6171s\n",
      "\titers: 400, epoch: 3 | loss: 0.2651891\n",
      "\tspeed: 0.0403s/iter; left time: 275.8240s\n",
      "\titers: 500, epoch: 3 | loss: 0.3693432\n",
      "\tspeed: 0.0402s/iter; left time: 271.3797s\n",
      "\titers: 600, epoch: 3 | loss: 0.3180302\n",
      "\tspeed: 0.0405s/iter; left time: 269.1318s\n",
      "\titers: 700, epoch: 3 | loss: 0.2797669\n",
      "\tspeed: 0.0402s/iter; left time: 263.5501s\n",
      "\titers: 800, epoch: 3 | loss: 0.2634023\n",
      "\tspeed: 0.0406s/iter; left time: 261.9609s\n",
      "\titers: 900, epoch: 3 | loss: 0.2757514\n",
      "\tspeed: 0.0402s/iter; left time: 255.0208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.2798561 Vali Loss: 0.4500093 Test Loss: 0.4852419\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2148001\n",
      "\tspeed: 0.0944s/iter; left time: 589.4222s\n",
      "\titers: 200, epoch: 4 | loss: 0.2167519\n",
      "\tspeed: 0.0405s/iter; left time: 248.5377s\n",
      "\titers: 300, epoch: 4 | loss: 0.2506799\n",
      "\tspeed: 0.0403s/iter; left time: 243.5628s\n",
      "\titers: 400, epoch: 4 | loss: 0.1949622\n",
      "\tspeed: 0.0404s/iter; left time: 239.9481s\n",
      "\titers: 500, epoch: 4 | loss: 0.2937187\n",
      "\tspeed: 0.0404s/iter; left time: 236.1850s\n",
      "\titers: 600, epoch: 4 | loss: 0.2424507\n",
      "\tspeed: 0.0405s/iter; left time: 232.3714s\n",
      "\titers: 700, epoch: 4 | loss: 0.2249872\n",
      "\tspeed: 0.0403s/iter; left time: 227.2137s\n",
      "\titers: 800, epoch: 4 | loss: 0.2772225\n",
      "\tspeed: 0.0405s/iter; left time: 224.2411s\n",
      "\titers: 900, epoch: 4 | loss: 0.2324552\n",
      "\tspeed: 0.0404s/iter; left time: 219.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.2384659 Vali Loss: 0.4899858 Test Loss: 0.5276760\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1861539\n",
      "\tspeed: 0.0940s/iter; left time: 501.9400s\n",
      "\titers: 200, epoch: 5 | loss: 0.2107085\n",
      "\tspeed: 0.0403s/iter; left time: 210.9640s\n",
      "\titers: 300, epoch: 5 | loss: 0.1716803\n",
      "\tspeed: 0.0402s/iter; left time: 206.6052s\n",
      "\titers: 400, epoch: 5 | loss: 0.2353648\n",
      "\tspeed: 0.0404s/iter; left time: 203.5182s\n",
      "\titers: 500, epoch: 5 | loss: 0.1783587\n",
      "\tspeed: 0.0404s/iter; left time: 199.5351s\n",
      "\titers: 600, epoch: 5 | loss: 0.2087311\n",
      "\tspeed: 0.0404s/iter; left time: 195.4852s\n",
      "\titers: 700, epoch: 5 | loss: 0.1905097\n",
      "\tspeed: 0.0405s/iter; left time: 192.0042s\n",
      "\titers: 800, epoch: 5 | loss: 0.2120116\n",
      "\tspeed: 0.0402s/iter; left time: 186.3854s\n",
      "\titers: 900, epoch: 5 | loss: 0.2095568\n",
      "\tspeed: 0.0402s/iter; left time: 182.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.79s\n",
      "Steps: 906 | Train Loss: 0.1973772 Vali Loss: 0.4915508 Test Loss: 0.5555537\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5078262686729431, rmse:0.7126193046569824, mae:0.4996413290500641, rse:0.5639931559562683\n",
      "Original data scale mse:20262616.0, rmse:4501.4013671875, mae:3016.667236328125, rse:0.22381876409053802\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7432261\n",
      "\tspeed: 0.0427s/iter; left time: 382.1884s\n",
      "\titers: 200, epoch: 1 | loss: 0.6501400\n",
      "\tspeed: 0.0404s/iter; left time: 357.8385s\n",
      "\titers: 300, epoch: 1 | loss: 0.6982846\n",
      "\tspeed: 0.0403s/iter; left time: 353.4222s\n",
      "\titers: 400, epoch: 1 | loss: 0.6108430\n",
      "\tspeed: 0.0404s/iter; left time: 350.0209s\n",
      "\titers: 500, epoch: 1 | loss: 0.5608808\n",
      "\tspeed: 0.0403s/iter; left time: 345.2628s\n",
      "\titers: 600, epoch: 1 | loss: 0.4887934\n",
      "\tspeed: 0.0404s/iter; left time: 342.1140s\n",
      "\titers: 700, epoch: 1 | loss: 0.4168018\n",
      "\tspeed: 0.0406s/iter; left time: 339.4105s\n",
      "\titers: 800, epoch: 1 | loss: 0.5055439\n",
      "\tspeed: 0.0404s/iter; left time: 333.8429s\n",
      "\titers: 900, epoch: 1 | loss: 0.4256987\n",
      "\tspeed: 0.0403s/iter; left time: 329.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.90s\n",
      "Steps: 906 | Train Loss: 0.6086861 Vali Loss: 0.5567614 Test Loss: 0.6454746\n",
      "Validation loss decreased (inf --> 0.556761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3540336\n",
      "\tspeed: 0.0972s/iter; left time: 783.0109s\n",
      "\titers: 200, epoch: 2 | loss: 0.3325537\n",
      "\tspeed: 0.0401s/iter; left time: 318.8347s\n",
      "\titers: 300, epoch: 2 | loss: 0.2796101\n",
      "\tspeed: 0.0405s/iter; left time: 317.8302s\n",
      "\titers: 400, epoch: 2 | loss: 0.2513244\n",
      "\tspeed: 0.0404s/iter; left time: 313.1821s\n",
      "\titers: 500, epoch: 2 | loss: 0.3176331\n",
      "\tspeed: 0.0404s/iter; left time: 309.0425s\n",
      "\titers: 600, epoch: 2 | loss: 0.3459046\n",
      "\tspeed: 0.0395s/iter; left time: 298.5772s\n",
      "\titers: 700, epoch: 2 | loss: 0.3034120\n",
      "\tspeed: 0.0404s/iter; left time: 301.2939s\n",
      "\titers: 800, epoch: 2 | loss: 0.2387425\n",
      "\tspeed: 0.0404s/iter; left time: 297.1110s\n",
      "\titers: 900, epoch: 2 | loss: 0.3125600\n",
      "\tspeed: 0.0404s/iter; left time: 293.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3379571 Vali Loss: 0.4827415 Test Loss: 0.5245702\n",
      "Validation loss decreased (0.556761 --> 0.482742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3740808\n",
      "\tspeed: 0.0974s/iter; left time: 695.9911s\n",
      "\titers: 200, epoch: 3 | loss: 0.2651302\n",
      "\tspeed: 0.0399s/iter; left time: 281.5943s\n",
      "\titers: 300, epoch: 3 | loss: 0.2314308\n",
      "\tspeed: 0.0403s/iter; left time: 279.7871s\n",
      "\titers: 400, epoch: 3 | loss: 0.2778544\n",
      "\tspeed: 0.0400s/iter; left time: 274.2782s\n",
      "\titers: 500, epoch: 3 | loss: 0.2816418\n",
      "\tspeed: 0.0399s/iter; left time: 268.9686s\n",
      "\titers: 600, epoch: 3 | loss: 0.2536219\n",
      "\tspeed: 0.0403s/iter; left time: 268.2218s\n",
      "\titers: 700, epoch: 3 | loss: 0.3004388\n",
      "\tspeed: 0.0403s/iter; left time: 263.6812s\n",
      "\titers: 800, epoch: 3 | loss: 0.3086251\n",
      "\tspeed: 0.0405s/iter; left time: 261.0282s\n",
      "\titers: 900, epoch: 3 | loss: 0.2157228\n",
      "\tspeed: 0.0403s/iter; left time: 255.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.70s\n",
      "Steps: 906 | Train Loss: 0.2835519 Vali Loss: 0.4392605 Test Loss: 0.4886339\n",
      "Validation loss decreased (0.482742 --> 0.439261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2430649\n",
      "\tspeed: 0.0986s/iter; left time: 615.6682s\n",
      "\titers: 200, epoch: 4 | loss: 0.2590898\n",
      "\tspeed: 0.0405s/iter; left time: 248.6634s\n",
      "\titers: 300, epoch: 4 | loss: 0.3631294\n",
      "\tspeed: 0.0404s/iter; left time: 244.4230s\n",
      "\titers: 400, epoch: 4 | loss: 0.2209840\n",
      "\tspeed: 0.0404s/iter; left time: 240.3825s\n",
      "\titers: 500, epoch: 4 | loss: 0.2981814\n",
      "\tspeed: 0.0405s/iter; left time: 236.5645s\n",
      "\titers: 600, epoch: 4 | loss: 0.2587925\n",
      "\tspeed: 0.0403s/iter; left time: 231.2822s\n",
      "\titers: 700, epoch: 4 | loss: 0.2709548\n",
      "\tspeed: 0.0404s/iter; left time: 228.1746s\n",
      "\titers: 800, epoch: 4 | loss: 0.1581628\n",
      "\tspeed: 0.0405s/iter; left time: 224.4186s\n",
      "\titers: 900, epoch: 4 | loss: 0.1487662\n",
      "\tspeed: 0.0403s/iter; left time: 219.5000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.89s\n",
      "Steps: 906 | Train Loss: 0.2429381 Vali Loss: 0.4431614 Test Loss: 0.4938792\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2189480\n",
      "\tspeed: 0.0947s/iter; left time: 505.5520s\n",
      "\titers: 200, epoch: 5 | loss: 0.1875956\n",
      "\tspeed: 0.0402s/iter; left time: 210.5467s\n",
      "\titers: 300, epoch: 5 | loss: 0.1857948\n",
      "\tspeed: 0.0403s/iter; left time: 207.2118s\n",
      "\titers: 400, epoch: 5 | loss: 0.2114488\n",
      "\tspeed: 0.0402s/iter; left time: 202.6285s\n",
      "\titers: 500, epoch: 5 | loss: 0.1357018\n",
      "\tspeed: 0.0402s/iter; left time: 198.7106s\n",
      "\titers: 600, epoch: 5 | loss: 0.2276186\n",
      "\tspeed: 0.0402s/iter; left time: 194.3955s\n",
      "\titers: 700, epoch: 5 | loss: 0.1714303\n",
      "\tspeed: 0.0403s/iter; left time: 191.0944s\n",
      "\titers: 800, epoch: 5 | loss: 0.2150388\n",
      "\tspeed: 0.0403s/iter; left time: 187.0156s\n",
      "\titers: 900, epoch: 5 | loss: 0.1828143\n",
      "\tspeed: 0.0404s/iter; left time: 183.3194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.74s\n",
      "Steps: 906 | Train Loss: 0.1994748 Vali Loss: 0.4670032 Test Loss: 0.5031238\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1696045\n",
      "\tspeed: 0.0942s/iter; left time: 417.4865s\n",
      "\titers: 200, epoch: 6 | loss: 0.1791843\n",
      "\tspeed: 0.0404s/iter; left time: 175.1407s\n",
      "\titers: 300, epoch: 6 | loss: 0.2508294\n",
      "\tspeed: 0.0399s/iter; left time: 169.0108s\n",
      "\titers: 400, epoch: 6 | loss: 0.1741999\n",
      "\tspeed: 0.0403s/iter; left time: 166.6140s\n",
      "\titers: 500, epoch: 6 | loss: 0.1608908\n",
      "\tspeed: 0.0404s/iter; left time: 162.8106s\n",
      "\titers: 600, epoch: 6 | loss: 0.1402602\n",
      "\tspeed: 0.0403s/iter; left time: 158.4520s\n",
      "\titers: 700, epoch: 6 | loss: 0.1637850\n",
      "\tspeed: 0.0404s/iter; left time: 154.6559s\n",
      "\titers: 800, epoch: 6 | loss: 0.1464395\n",
      "\tspeed: 0.0402s/iter; left time: 150.1100s\n",
      "\titers: 900, epoch: 6 | loss: 0.1418985\n",
      "\tspeed: 0.0404s/iter; left time: 146.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.75s\n",
      "Steps: 906 | Train Loss: 0.1654440 Vali Loss: 0.5088816 Test Loss: 0.5175062\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.48783740401268005, rmse:0.6984536051750183, mae:0.47903192043304443, rse:0.552781879901886\n",
      "Original data scale mse:19436216.0, rmse:4408.65234375, mae:2875.55859375, rse:0.21920709311962128\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0522838\n",
      "\tspeed: 0.0698s/iter; left time: 624.4904s\n",
      "\titers: 200, epoch: 1 | loss: 0.9666416\n",
      "\tspeed: 0.0442s/iter; left time: 390.4553s\n",
      "\titers: 300, epoch: 1 | loss: 0.9245752\n",
      "\tspeed: 0.0456s/iter; left time: 398.5042s\n",
      "\titers: 400, epoch: 1 | loss: 0.7863439\n",
      "\tspeed: 0.0382s/iter; left time: 329.8482s\n",
      "\titers: 500, epoch: 1 | loss: 0.7835494\n",
      "\tspeed: 0.0354s/iter; left time: 302.2317s\n",
      "\titers: 600, epoch: 1 | loss: 0.6639153\n",
      "\tspeed: 0.0396s/iter; left time: 334.2323s\n",
      "\titers: 700, epoch: 1 | loss: 0.6276757\n",
      "\tspeed: 0.0459s/iter; left time: 382.7436s\n",
      "\titers: 800, epoch: 1 | loss: 0.6528488\n",
      "\tspeed: 0.0470s/iter; left time: 387.5212s\n",
      "\titers: 900, epoch: 1 | loss: 0.6513734\n",
      "\tspeed: 0.0399s/iter; left time: 325.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 904 | Train Loss: 0.8170802 Vali Loss: 0.8335947 Test Loss: 1.0375565\n",
      "Validation loss decreased (inf --> 0.833595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5232227\n",
      "\tspeed: 0.1169s/iter; left time: 939.6959s\n",
      "\titers: 200, epoch: 2 | loss: 0.5794776\n",
      "\tspeed: 0.0451s/iter; left time: 357.6566s\n",
      "\titers: 300, epoch: 2 | loss: 0.5255210\n",
      "\tspeed: 0.0450s/iter; left time: 352.9295s\n",
      "\titers: 400, epoch: 2 | loss: 0.4926725\n",
      "\tspeed: 0.0455s/iter; left time: 351.8337s\n",
      "\titers: 500, epoch: 2 | loss: 0.4981970\n",
      "\tspeed: 0.0445s/iter; left time: 339.8742s\n",
      "\titers: 600, epoch: 2 | loss: 0.5888463\n",
      "\tspeed: 0.0439s/iter; left time: 330.8992s\n",
      "\titers: 700, epoch: 2 | loss: 0.4668635\n",
      "\tspeed: 0.0460s/iter; left time: 342.0554s\n",
      "\titers: 800, epoch: 2 | loss: 0.5131143\n",
      "\tspeed: 0.0455s/iter; left time: 333.7505s\n",
      "\titers: 900, epoch: 2 | loss: 0.4530048\n",
      "\tspeed: 0.0448s/iter; left time: 323.9715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.07s\n",
      "Steps: 904 | Train Loss: 0.5329359 Vali Loss: 0.6914768 Test Loss: 0.8287142\n",
      "Validation loss decreased (0.833595 --> 0.691477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5407680\n",
      "\tspeed: 0.1172s/iter; left time: 835.8656s\n",
      "\titers: 200, epoch: 3 | loss: 0.3946598\n",
      "\tspeed: 0.0452s/iter; left time: 318.2069s\n",
      "\titers: 300, epoch: 3 | loss: 0.3622131\n",
      "\tspeed: 0.0449s/iter; left time: 310.9466s\n",
      "\titers: 400, epoch: 3 | loss: 0.3672664\n",
      "\tspeed: 0.0455s/iter; left time: 310.6133s\n",
      "\titers: 500, epoch: 3 | loss: 0.4548235\n",
      "\tspeed: 0.0453s/iter; left time: 304.7398s\n",
      "\titers: 600, epoch: 3 | loss: 0.4472606\n",
      "\tspeed: 0.0451s/iter; left time: 299.3724s\n",
      "\titers: 700, epoch: 3 | loss: 0.3666580\n",
      "\tspeed: 0.0452s/iter; left time: 294.9799s\n",
      "\titers: 800, epoch: 3 | loss: 0.4022273\n",
      "\tspeed: 0.0458s/iter; left time: 294.3637s\n",
      "\titers: 900, epoch: 3 | loss: 0.4221560\n",
      "\tspeed: 0.0457s/iter; left time: 289.3724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.28s\n",
      "Steps: 904 | Train Loss: 0.4274466 Vali Loss: 0.7251076 Test Loss: 0.8448725\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3476723\n",
      "\tspeed: 0.1126s/iter; left time: 701.1141s\n",
      "\titers: 200, epoch: 4 | loss: 0.3722265\n",
      "\tspeed: 0.0443s/iter; left time: 271.4568s\n",
      "\titers: 300, epoch: 4 | loss: 0.3409472\n",
      "\tspeed: 0.0443s/iter; left time: 267.2037s\n",
      "\titers: 400, epoch: 4 | loss: 0.3054693\n",
      "\tspeed: 0.0448s/iter; left time: 265.7834s\n",
      "\titers: 500, epoch: 4 | loss: 0.4120376\n",
      "\tspeed: 0.0445s/iter; left time: 259.1972s\n",
      "\titers: 600, epoch: 4 | loss: 0.3229454\n",
      "\tspeed: 0.0447s/iter; left time: 256.2150s\n",
      "\titers: 700, epoch: 4 | loss: 0.3860872\n",
      "\tspeed: 0.0449s/iter; left time: 253.0150s\n",
      "\titers: 800, epoch: 4 | loss: 0.3114266\n",
      "\tspeed: 0.0449s/iter; left time: 248.0279s\n",
      "\titers: 900, epoch: 4 | loss: 0.3609830\n",
      "\tspeed: 0.0449s/iter; left time: 243.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.71s\n",
      "Steps: 904 | Train Loss: 0.3587939 Vali Loss: 0.7235217 Test Loss: 0.9472639\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2992413\n",
      "\tspeed: 0.1118s/iter; left time: 595.4424s\n",
      "\titers: 200, epoch: 5 | loss: 0.3733294\n",
      "\tspeed: 0.0458s/iter; left time: 239.1042s\n",
      "\titers: 300, epoch: 5 | loss: 0.3371202\n",
      "\tspeed: 0.0456s/iter; left time: 233.7635s\n",
      "\titers: 400, epoch: 5 | loss: 0.3143236\n",
      "\tspeed: 0.0449s/iter; left time: 225.8197s\n",
      "\titers: 500, epoch: 5 | loss: 0.2918294\n",
      "\tspeed: 0.0457s/iter; left time: 225.0412s\n",
      "\titers: 600, epoch: 5 | loss: 0.2968202\n",
      "\tspeed: 0.0449s/iter; left time: 216.8685s\n",
      "\titers: 700, epoch: 5 | loss: 0.2790029\n",
      "\tspeed: 0.0450s/iter; left time: 212.7395s\n",
      "\titers: 800, epoch: 5 | loss: 0.2449622\n",
      "\tspeed: 0.0455s/iter; left time: 210.4294s\n",
      "\titers: 900, epoch: 5 | loss: 0.2711503\n",
      "\tspeed: 0.0448s/iter; left time: 202.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.20s\n",
      "Steps: 904 | Train Loss: 0.2995826 Vali Loss: 0.7070563 Test Loss: 0.9387065\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8277999758720398, rmse:0.909835159778595, mae:0.6767523288726807, rse:0.7216113805770874\n",
      "Original data scale mse:35706256.0, rmse:5975.47119140625, mae:4163.154296875, rse:0.2975805997848511\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9143165\n",
      "\tspeed: 0.0474s/iter; left time: 423.6445s\n",
      "\titers: 200, epoch: 1 | loss: 0.8231269\n",
      "\tspeed: 0.0449s/iter; left time: 397.0791s\n",
      "\titers: 300, epoch: 1 | loss: 0.8590661\n",
      "\tspeed: 0.0444s/iter; left time: 388.3046s\n",
      "\titers: 400, epoch: 1 | loss: 0.8273649\n",
      "\tspeed: 0.0451s/iter; left time: 389.4325s\n",
      "\titers: 500, epoch: 1 | loss: 0.8597592\n",
      "\tspeed: 0.0454s/iter; left time: 387.8899s\n",
      "\titers: 600, epoch: 1 | loss: 0.6699688\n",
      "\tspeed: 0.0458s/iter; left time: 386.4275s\n",
      "\titers: 700, epoch: 1 | loss: 0.9264821\n",
      "\tspeed: 0.0456s/iter; left time: 380.5722s\n",
      "\titers: 800, epoch: 1 | loss: 0.6948530\n",
      "\tspeed: 0.0447s/iter; left time: 368.6162s\n",
      "\titers: 900, epoch: 1 | loss: 0.7380019\n",
      "\tspeed: 0.0456s/iter; left time: 371.4912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.14s\n",
      "Steps: 904 | Train Loss: 0.8259976 Vali Loss: 0.8315275 Test Loss: 1.0468974\n",
      "Validation loss decreased (inf --> 0.831528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6546626\n",
      "\tspeed: 0.1156s/iter; left time: 929.4644s\n",
      "\titers: 200, epoch: 2 | loss: 0.6274150\n",
      "\tspeed: 0.0459s/iter; left time: 364.3706s\n",
      "\titers: 300, epoch: 2 | loss: 0.5482291\n",
      "\tspeed: 0.0455s/iter; left time: 356.7141s\n",
      "\titers: 400, epoch: 2 | loss: 0.4350376\n",
      "\tspeed: 0.0458s/iter; left time: 354.2404s\n",
      "\titers: 500, epoch: 2 | loss: 0.4925019\n",
      "\tspeed: 0.0459s/iter; left time: 350.4855s\n",
      "\titers: 600, epoch: 2 | loss: 0.6154686\n",
      "\tspeed: 0.0447s/iter; left time: 336.8049s\n",
      "\titers: 700, epoch: 2 | loss: 0.5049326\n",
      "\tspeed: 0.0456s/iter; left time: 339.4462s\n",
      "\titers: 800, epoch: 2 | loss: 0.5443966\n",
      "\tspeed: 0.0460s/iter; left time: 337.8572s\n",
      "\titers: 900, epoch: 2 | loss: 0.4095918\n",
      "\tspeed: 0.0453s/iter; left time: 328.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.45s\n",
      "Steps: 904 | Train Loss: 0.5347245 Vali Loss: 0.6814697 Test Loss: 0.8716580\n",
      "Validation loss decreased (0.831528 --> 0.681470).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4723068\n",
      "\tspeed: 0.1160s/iter; left time: 827.3761s\n",
      "\titers: 200, epoch: 3 | loss: 0.5130894\n",
      "\tspeed: 0.0438s/iter; left time: 308.1525s\n",
      "\titers: 300, epoch: 3 | loss: 0.3773848\n",
      "\tspeed: 0.0456s/iter; left time: 316.1904s\n",
      "\titers: 400, epoch: 3 | loss: 0.3935299\n",
      "\tspeed: 0.0460s/iter; left time: 314.1429s\n",
      "\titers: 500, epoch: 3 | loss: 0.4303985\n",
      "\tspeed: 0.0460s/iter; left time: 309.9916s\n",
      "\titers: 600, epoch: 3 | loss: 0.4050925\n",
      "\tspeed: 0.0412s/iter; left time: 273.4273s\n",
      "\titers: 700, epoch: 3 | loss: 0.4072495\n",
      "\tspeed: 0.0398s/iter; left time: 260.2072s\n",
      "\titers: 800, epoch: 3 | loss: 0.4411655\n",
      "\tspeed: 0.0458s/iter; left time: 294.5232s\n",
      "\titers: 900, epoch: 3 | loss: 0.4036132\n",
      "\tspeed: 0.0434s/iter; left time: 275.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.15s\n",
      "Steps: 904 | Train Loss: 0.4316325 Vali Loss: 0.7312940 Test Loss: 0.8559389\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3354936\n",
      "\tspeed: 0.1115s/iter; left time: 694.7992s\n",
      "\titers: 200, epoch: 4 | loss: 0.3472808\n",
      "\tspeed: 0.0454s/iter; left time: 278.1378s\n",
      "\titers: 300, epoch: 4 | loss: 0.3451594\n",
      "\tspeed: 0.0450s/iter; left time: 271.2775s\n",
      "\titers: 400, epoch: 4 | loss: 0.3125092\n",
      "\tspeed: 0.0454s/iter; left time: 269.4098s\n",
      "\titers: 500, epoch: 4 | loss: 0.3426646\n",
      "\tspeed: 0.0457s/iter; left time: 266.5422s\n",
      "\titers: 600, epoch: 4 | loss: 0.3740831\n",
      "\tspeed: 0.0455s/iter; left time: 260.7447s\n",
      "\titers: 700, epoch: 4 | loss: 0.3379540\n",
      "\tspeed: 0.0458s/iter; left time: 257.8905s\n",
      "\titers: 800, epoch: 4 | loss: 0.3604316\n",
      "\tspeed: 0.0454s/iter; left time: 251.0800s\n",
      "\titers: 900, epoch: 4 | loss: 0.3078305\n",
      "\tspeed: 0.0457s/iter; left time: 248.3649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.21s\n",
      "Steps: 904 | Train Loss: 0.3627788 Vali Loss: 0.7563289 Test Loss: 0.9437141\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2672817\n",
      "\tspeed: 0.1122s/iter; left time: 597.6646s\n",
      "\titers: 200, epoch: 5 | loss: 0.3515173\n",
      "\tspeed: 0.0447s/iter; left time: 233.5756s\n",
      "\titers: 300, epoch: 5 | loss: 0.3082839\n",
      "\tspeed: 0.0458s/iter; left time: 234.6070s\n",
      "\titers: 400, epoch: 5 | loss: 0.3019142\n",
      "\tspeed: 0.0457s/iter; left time: 229.6109s\n",
      "\titers: 500, epoch: 5 | loss: 0.3102745\n",
      "\tspeed: 0.0458s/iter; left time: 225.5325s\n",
      "\titers: 600, epoch: 5 | loss: 0.2675474\n",
      "\tspeed: 0.0449s/iter; left time: 216.4237s\n",
      "\titers: 700, epoch: 5 | loss: 0.3005226\n",
      "\tspeed: 0.0455s/iter; left time: 215.0300s\n",
      "\titers: 800, epoch: 5 | loss: 0.3071508\n",
      "\tspeed: 0.0455s/iter; left time: 210.5575s\n",
      "\titers: 900, epoch: 5 | loss: 0.2667807\n",
      "\tspeed: 0.0458s/iter; left time: 207.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.33s\n",
      "Steps: 904 | Train Loss: 0.3004628 Vali Loss: 0.7473243 Test Loss: 0.9708486\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8711569905281067, rmse:0.9333578944206238, mae:0.6843037009239197, rse:0.740267813205719\n",
      "Original data scale mse:38053568.0, rmse:6168.75732421875, mae:4203.2880859375, rse:0.30720630288124084\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8996492\n",
      "\tspeed: 0.0787s/iter; left time: 701.9904s\n",
      "\titers: 200, epoch: 1 | loss: 0.9759548\n",
      "\tspeed: 0.0517s/iter; left time: 456.1258s\n",
      "\titers: 300, epoch: 1 | loss: 0.8695518\n",
      "\tspeed: 0.0520s/iter; left time: 453.8458s\n",
      "\titers: 400, epoch: 1 | loss: 0.8800810\n",
      "\tspeed: 0.0522s/iter; left time: 450.3441s\n",
      "\titers: 500, epoch: 1 | loss: 0.8453556\n",
      "\tspeed: 0.0518s/iter; left time: 441.3187s\n",
      "\titers: 600, epoch: 1 | loss: 0.8907446\n",
      "\tspeed: 0.0518s/iter; left time: 435.9889s\n",
      "\titers: 700, epoch: 1 | loss: 0.8326300\n",
      "\tspeed: 0.0516s/iter; left time: 429.5459s\n",
      "\titers: 800, epoch: 1 | loss: 0.7673663\n",
      "\tspeed: 0.0517s/iter; left time: 424.6406s\n",
      "\titers: 900, epoch: 1 | loss: 0.8367926\n",
      "\tspeed: 0.0520s/iter; left time: 422.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.48s\n",
      "Steps: 902 | Train Loss: 0.8779309 Vali Loss: 0.9823749 Test Loss: 1.2618978\n",
      "Validation loss decreased (inf --> 0.982375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8131427\n",
      "\tspeed: 0.1326s/iter; left time: 1063.6001s\n",
      "\titers: 200, epoch: 2 | loss: 0.7040696\n",
      "\tspeed: 0.0497s/iter; left time: 393.6481s\n",
      "\titers: 300, epoch: 2 | loss: 0.7396861\n",
      "\tspeed: 0.0428s/iter; left time: 334.6602s\n",
      "\titers: 400, epoch: 2 | loss: 0.6244543\n",
      "\tspeed: 0.0430s/iter; left time: 331.9070s\n",
      "\titers: 500, epoch: 2 | loss: 0.6054553\n",
      "\tspeed: 0.0463s/iter; left time: 353.0298s\n",
      "\titers: 600, epoch: 2 | loss: 0.4985499\n",
      "\tspeed: 0.0519s/iter; left time: 390.1802s\n",
      "\titers: 700, epoch: 2 | loss: 0.5293226\n",
      "\tspeed: 0.0530s/iter; left time: 393.2366s\n",
      "\titers: 800, epoch: 2 | loss: 0.6061723\n",
      "\tspeed: 0.0533s/iter; left time: 390.2025s\n",
      "\titers: 900, epoch: 2 | loss: 0.4838333\n",
      "\tspeed: 0.0534s/iter; left time: 385.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.94s\n",
      "Steps: 902 | Train Loss: 0.6046631 Vali Loss: 0.7293260 Test Loss: 0.8842466\n",
      "Validation loss decreased (0.982375 --> 0.729326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5083361\n",
      "\tspeed: 0.1365s/iter; left time: 971.3485s\n",
      "\titers: 200, epoch: 3 | loss: 0.4712097\n",
      "\tspeed: 0.0533s/iter; left time: 374.3270s\n",
      "\titers: 300, epoch: 3 | loss: 0.4754631\n",
      "\tspeed: 0.0532s/iter; left time: 367.9887s\n",
      "\titers: 400, epoch: 3 | loss: 0.5324599\n",
      "\tspeed: 0.0530s/iter; left time: 361.3296s\n",
      "\titers: 500, epoch: 3 | loss: 0.4271317\n",
      "\tspeed: 0.0535s/iter; left time: 359.1055s\n",
      "\titers: 600, epoch: 3 | loss: 0.4579096\n",
      "\tspeed: 0.0533s/iter; left time: 352.4637s\n",
      "\titers: 700, epoch: 3 | loss: 0.4870133\n",
      "\tspeed: 0.0531s/iter; left time: 346.2658s\n",
      "\titers: 800, epoch: 3 | loss: 0.4459608\n",
      "\tspeed: 0.0530s/iter; left time: 340.3506s\n",
      "\titers: 900, epoch: 3 | loss: 0.4197437\n",
      "\tspeed: 0.0531s/iter; left time: 335.6652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.29s\n",
      "Steps: 902 | Train Loss: 0.4552675 Vali Loss: 0.7132370 Test Loss: 0.9254080\n",
      "Validation loss decreased (0.729326 --> 0.713237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3725089\n",
      "\tspeed: 0.1332s/iter; left time: 827.6934s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399079\n",
      "\tspeed: 0.0520s/iter; left time: 317.9541s\n",
      "\titers: 300, epoch: 4 | loss: 0.4262986\n",
      "\tspeed: 0.0521s/iter; left time: 313.3517s\n",
      "\titers: 400, epoch: 4 | loss: 0.3951728\n",
      "\tspeed: 0.0520s/iter; left time: 307.5650s\n",
      "\titers: 500, epoch: 4 | loss: 0.4273083\n",
      "\tspeed: 0.0522s/iter; left time: 303.7103s\n",
      "\titers: 600, epoch: 4 | loss: 0.3536602\n",
      "\tspeed: 0.0521s/iter; left time: 297.7363s\n",
      "\titers: 700, epoch: 4 | loss: 0.3747369\n",
      "\tspeed: 0.0522s/iter; left time: 293.0590s\n",
      "\titers: 800, epoch: 4 | loss: 0.3719158\n",
      "\tspeed: 0.0519s/iter; left time: 286.4453s\n",
      "\titers: 900, epoch: 4 | loss: 0.3601287\n",
      "\tspeed: 0.0517s/iter; left time: 279.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.3793745 Vali Loss: 0.7713831 Test Loss: 0.9924561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3638352\n",
      "\tspeed: 0.1206s/iter; left time: 640.5111s\n",
      "\titers: 200, epoch: 5 | loss: 0.3390375\n",
      "\tspeed: 0.0483s/iter; left time: 251.7989s\n",
      "\titers: 300, epoch: 5 | loss: 0.3258272\n",
      "\tspeed: 0.0535s/iter; left time: 273.2921s\n",
      "\titers: 400, epoch: 5 | loss: 0.3470738\n",
      "\tspeed: 0.0525s/iter; left time: 263.0954s\n",
      "\titers: 500, epoch: 5 | loss: 0.2690118\n",
      "\tspeed: 0.0520s/iter; left time: 255.2782s\n",
      "\titers: 600, epoch: 5 | loss: 0.3021259\n",
      "\tspeed: 0.0523s/iter; left time: 251.6927s\n",
      "\titers: 700, epoch: 5 | loss: 0.3265553\n",
      "\tspeed: 0.0522s/iter; left time: 245.9541s\n",
      "\titers: 800, epoch: 5 | loss: 0.2861528\n",
      "\tspeed: 0.0524s/iter; left time: 241.7455s\n",
      "\titers: 900, epoch: 5 | loss: 0.2557895\n",
      "\tspeed: 0.0521s/iter; left time: 235.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.14s\n",
      "Steps: 902 | Train Loss: 0.3167043 Vali Loss: 0.7697710 Test Loss: 0.9987172\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2949107\n",
      "\tspeed: 0.1321s/iter; left time: 582.7862s\n",
      "\titers: 200, epoch: 6 | loss: 0.3065024\n",
      "\tspeed: 0.0516s/iter; left time: 222.5171s\n",
      "\titers: 300, epoch: 6 | loss: 0.2583741\n",
      "\tspeed: 0.0517s/iter; left time: 217.6677s\n",
      "\titers: 400, epoch: 6 | loss: 0.3096471\n",
      "\tspeed: 0.0524s/iter; left time: 215.2572s\n",
      "\titers: 500, epoch: 6 | loss: 0.2568293\n",
      "\tspeed: 0.0522s/iter; left time: 209.2352s\n",
      "\titers: 600, epoch: 6 | loss: 0.2391598\n",
      "\tspeed: 0.0520s/iter; left time: 203.5548s\n",
      "\titers: 700, epoch: 6 | loss: 0.2993651\n",
      "\tspeed: 0.0520s/iter; left time: 198.0717s\n",
      "\titers: 800, epoch: 6 | loss: 0.2426711\n",
      "\tspeed: 0.0518s/iter; left time: 192.2212s\n",
      "\titers: 900, epoch: 6 | loss: 0.2972760\n",
      "\tspeed: 0.0521s/iter; left time: 188.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.14s\n",
      "Steps: 902 | Train Loss: 0.2691092 Vali Loss: 0.8078781 Test Loss: 1.0506176\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9250379204750061, rmse:0.9617888927459717, mae:0.7022790908813477, rse:0.7619071006774902\n",
      "Original data scale mse:41039112.0, rmse:6406.177734375, mae:4328.85498046875, rse:0.3191865384578705\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0736581\n",
      "\tspeed: 0.0547s/iter; left time: 487.7330s\n",
      "\titers: 200, epoch: 1 | loss: 0.8831307\n",
      "\tspeed: 0.0522s/iter; left time: 460.6206s\n",
      "\titers: 300, epoch: 1 | loss: 0.8966042\n",
      "\tspeed: 0.0523s/iter; left time: 455.8479s\n",
      "\titers: 400, epoch: 1 | loss: 0.7405317\n",
      "\tspeed: 0.0521s/iter; left time: 449.3282s\n",
      "\titers: 500, epoch: 1 | loss: 0.9314477\n",
      "\tspeed: 0.0521s/iter; left time: 443.8902s\n",
      "\titers: 600, epoch: 1 | loss: 0.7962927\n",
      "\tspeed: 0.0525s/iter; left time: 441.8787s\n",
      "\titers: 700, epoch: 1 | loss: 0.7819531\n",
      "\tspeed: 0.0524s/iter; left time: 435.6598s\n",
      "\titers: 800, epoch: 1 | loss: 0.7549212\n",
      "\tspeed: 0.0521s/iter; left time: 428.0254s\n",
      "\titers: 900, epoch: 1 | loss: 0.7729616\n",
      "\tspeed: 0.0524s/iter; left time: 425.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.47s\n",
      "Steps: 902 | Train Loss: 0.8827498 Vali Loss: 0.9831725 Test Loss: 1.2678595\n",
      "Validation loss decreased (inf --> 0.983173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6917587\n",
      "\tspeed: 0.1354s/iter; left time: 1085.6047s\n",
      "\titers: 200, epoch: 2 | loss: 0.6385450\n",
      "\tspeed: 0.0521s/iter; left time: 412.4727s\n",
      "\titers: 300, epoch: 2 | loss: 0.6272208\n",
      "\tspeed: 0.0523s/iter; left time: 408.7638s\n",
      "\titers: 400, epoch: 2 | loss: 0.5154302\n",
      "\tspeed: 0.0522s/iter; left time: 402.9912s\n",
      "\titers: 500, epoch: 2 | loss: 0.5767449\n",
      "\tspeed: 0.0520s/iter; left time: 396.1645s\n",
      "\titers: 600, epoch: 2 | loss: 0.5526741\n",
      "\tspeed: 0.0521s/iter; left time: 391.6103s\n",
      "\titers: 700, epoch: 2 | loss: 0.5340019\n",
      "\tspeed: 0.0524s/iter; left time: 388.6995s\n",
      "\titers: 800, epoch: 2 | loss: 0.4381602\n",
      "\tspeed: 0.0523s/iter; left time: 382.7091s\n",
      "\titers: 900, epoch: 2 | loss: 0.4901657\n",
      "\tspeed: 0.0520s/iter; left time: 375.2212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.30s\n",
      "Steps: 902 | Train Loss: 0.6127766 Vali Loss: 0.7626251 Test Loss: 0.8730339\n",
      "Validation loss decreased (0.983173 --> 0.762625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4595468\n",
      "\tspeed: 0.1350s/iter; left time: 961.0225s\n",
      "\titers: 200, epoch: 3 | loss: 0.5015832\n",
      "\tspeed: 0.0525s/iter; left time: 368.0779s\n",
      "\titers: 300, epoch: 3 | loss: 0.5812056\n",
      "\tspeed: 0.0535s/iter; left time: 370.0502s\n",
      "\titers: 400, epoch: 3 | loss: 0.4741263\n",
      "\tspeed: 0.0535s/iter; left time: 365.0458s\n",
      "\titers: 500, epoch: 3 | loss: 0.4783198\n",
      "\tspeed: 0.0526s/iter; left time: 353.2985s\n",
      "\titers: 600, epoch: 3 | loss: 0.4453655\n",
      "\tspeed: 0.0523s/iter; left time: 346.2737s\n",
      "\titers: 700, epoch: 3 | loss: 0.4122199\n",
      "\tspeed: 0.0524s/iter; left time: 341.2192s\n",
      "\titers: 800, epoch: 3 | loss: 0.3615236\n",
      "\tspeed: 0.0523s/iter; left time: 335.7206s\n",
      "\titers: 900, epoch: 3 | loss: 0.4355072\n",
      "\tspeed: 0.0524s/iter; left time: 330.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.75s\n",
      "Steps: 902 | Train Loss: 0.4525444 Vali Loss: 0.7806315 Test Loss: 0.9514728\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4056771\n",
      "\tspeed: 0.1313s/iter; left time: 815.7809s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399343\n",
      "\tspeed: 0.0524s/iter; left time: 320.5630s\n",
      "\titers: 300, epoch: 4 | loss: 0.3804121\n",
      "\tspeed: 0.0523s/iter; left time: 314.8131s\n",
      "\titers: 400, epoch: 4 | loss: 0.3706331\n",
      "\tspeed: 0.0521s/iter; left time: 308.2799s\n",
      "\titers: 500, epoch: 4 | loss: 0.3810227\n",
      "\tspeed: 0.0521s/iter; left time: 302.8650s\n",
      "\titers: 600, epoch: 4 | loss: 0.3974872\n",
      "\tspeed: 0.0520s/iter; left time: 297.2622s\n",
      "\titers: 700, epoch: 4 | loss: 0.3429693\n",
      "\tspeed: 0.0518s/iter; left time: 290.8053s\n",
      "\titers: 800, epoch: 4 | loss: 0.3861212\n",
      "\tspeed: 0.0523s/iter; left time: 288.6178s\n",
      "\titers: 900, epoch: 4 | loss: 0.3614337\n",
      "\tspeed: 0.0526s/iter; left time: 284.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.43s\n",
      "Steps: 902 | Train Loss: 0.3713848 Vali Loss: 0.7981377 Test Loss: 0.9633971\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2858317\n",
      "\tspeed: 0.1316s/iter; left time: 699.2135s\n",
      "\titers: 200, epoch: 5 | loss: 0.3296789\n",
      "\tspeed: 0.0520s/iter; left time: 271.1108s\n",
      "\titers: 300, epoch: 5 | loss: 0.3004401\n",
      "\tspeed: 0.0526s/iter; left time: 268.9181s\n",
      "\titers: 400, epoch: 5 | loss: 0.3365834\n",
      "\tspeed: 0.0523s/iter; left time: 262.1584s\n",
      "\titers: 500, epoch: 5 | loss: 0.3448044\n",
      "\tspeed: 0.0525s/iter; left time: 257.8601s\n",
      "\titers: 600, epoch: 5 | loss: 0.2779492\n",
      "\tspeed: 0.0523s/iter; left time: 251.4926s\n",
      "\titers: 700, epoch: 5 | loss: 0.2858480\n",
      "\tspeed: 0.0521s/iter; left time: 245.5894s\n",
      "\titers: 800, epoch: 5 | loss: 0.2892428\n",
      "\tspeed: 0.0517s/iter; left time: 238.6400s\n",
      "\titers: 900, epoch: 5 | loss: 0.2999575\n",
      "\tspeed: 0.0521s/iter; left time: 235.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.3065489 Vali Loss: 0.8347104 Test Loss: 1.0182045\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8725519180297852, rmse:0.934104859828949, mae:0.6941571831703186, rse:0.7399765253067017\n",
      "Original data scale mse:37693112.0, rmse:6139.4716796875, mae:4274.00537109375, rse:0.30589795112609863\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9276407\n",
      "\tspeed: 0.0690s/iter; left time: 618.4279s\n",
      "\titers: 200, epoch: 1 | loss: 0.8493971\n",
      "\tspeed: 0.0404s/iter; left time: 357.9302s\n",
      "\titers: 300, epoch: 1 | loss: 0.7614538\n",
      "\tspeed: 0.0404s/iter; left time: 354.0471s\n",
      "\titers: 400, epoch: 1 | loss: 0.7148305\n",
      "\tspeed: 0.0404s/iter; left time: 350.0871s\n",
      "\titers: 500, epoch: 1 | loss: 0.6615688\n",
      "\tspeed: 0.0404s/iter; left time: 346.2570s\n",
      "\titers: 600, epoch: 1 | loss: 0.6439044\n",
      "\tspeed: 0.0405s/iter; left time: 343.0893s\n",
      "\titers: 700, epoch: 1 | loss: 0.7704166\n",
      "\tspeed: 0.0404s/iter; left time: 338.1821s\n",
      "\titers: 800, epoch: 1 | loss: 0.6550638\n",
      "\tspeed: 0.0402s/iter; left time: 332.3747s\n",
      "\titers: 900, epoch: 1 | loss: 0.5864573\n",
      "\tspeed: 0.0403s/iter; left time: 328.5380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.7567487 Vali Loss: 0.5543883 Test Loss: 0.6288404\n",
      "Validation loss decreased (inf --> 0.554388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4949431\n",
      "\tspeed: 0.1025s/iter; left time: 825.6501s\n",
      "\titers: 200, epoch: 2 | loss: 0.6551993\n",
      "\tspeed: 0.0405s/iter; left time: 322.4152s\n",
      "\titers: 300, epoch: 2 | loss: 0.5400851\n",
      "\tspeed: 0.0405s/iter; left time: 317.9089s\n",
      "\titers: 400, epoch: 2 | loss: 0.6192174\n",
      "\tspeed: 0.0417s/iter; left time: 323.4003s\n",
      "\titers: 500, epoch: 2 | loss: 0.4943135\n",
      "\tspeed: 0.0404s/iter; left time: 309.2832s\n",
      "\titers: 600, epoch: 2 | loss: 0.5266612\n",
      "\tspeed: 0.0417s/iter; left time: 314.9911s\n",
      "\titers: 700, epoch: 2 | loss: 0.5126165\n",
      "\tspeed: 0.0412s/iter; left time: 307.2258s\n",
      "\titers: 800, epoch: 2 | loss: 0.6232010\n",
      "\tspeed: 0.0410s/iter; left time: 301.8661s\n",
      "\titers: 900, epoch: 2 | loss: 0.5411612\n",
      "\tspeed: 0.0313s/iter; left time: 227.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.50s\n",
      "Steps: 906 | Train Loss: 0.5740920 Vali Loss: 0.4399104 Test Loss: 0.5069085\n",
      "Validation loss decreased (0.554388 --> 0.439910).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5629239\n",
      "\tspeed: 0.0861s/iter; left time: 615.5732s\n",
      "\titers: 200, epoch: 3 | loss: 0.4941055\n",
      "\tspeed: 0.0284s/iter; left time: 200.1739s\n",
      "\titers: 300, epoch: 3 | loss: 0.5275605\n",
      "\tspeed: 0.0284s/iter; left time: 197.1906s\n",
      "\titers: 400, epoch: 3 | loss: 0.5161560\n",
      "\tspeed: 0.0287s/iter; left time: 196.5274s\n",
      "\titers: 500, epoch: 3 | loss: 0.5798593\n",
      "\tspeed: 0.0284s/iter; left time: 191.6995s\n",
      "\titers: 600, epoch: 3 | loss: 0.5651723\n",
      "\tspeed: 0.0283s/iter; left time: 188.4044s\n",
      "\titers: 700, epoch: 3 | loss: 0.5228499\n",
      "\tspeed: 0.0283s/iter; left time: 185.3295s\n",
      "\titers: 800, epoch: 3 | loss: 0.5283095\n",
      "\tspeed: 0.0317s/iter; left time: 204.2019s\n",
      "\titers: 900, epoch: 3 | loss: 0.5182760\n",
      "\tspeed: 0.0404s/iter; left time: 256.8012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.66s\n",
      "Steps: 906 | Train Loss: 0.5248068 Vali Loss: 0.4539682 Test Loss: 0.4925095\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4896143\n",
      "\tspeed: 0.0975s/iter; left time: 608.7913s\n",
      "\titers: 200, epoch: 4 | loss: 0.4587334\n",
      "\tspeed: 0.0402s/iter; left time: 246.8511s\n",
      "\titers: 300, epoch: 4 | loss: 0.4971539\n",
      "\tspeed: 0.0404s/iter; left time: 244.3505s\n",
      "\titers: 400, epoch: 4 | loss: 0.4374260\n",
      "\tspeed: 0.0402s/iter; left time: 239.0255s\n",
      "\titers: 500, epoch: 4 | loss: 0.5398332\n",
      "\tspeed: 0.0404s/iter; left time: 235.8719s\n",
      "\titers: 600, epoch: 4 | loss: 0.5343698\n",
      "\tspeed: 0.0401s/iter; left time: 230.5465s\n",
      "\titers: 700, epoch: 4 | loss: 0.4609941\n",
      "\tspeed: 0.0410s/iter; left time: 231.2501s\n",
      "\titers: 800, epoch: 4 | loss: 0.5253209\n",
      "\tspeed: 0.0403s/iter; left time: 223.4947s\n",
      "\titers: 900, epoch: 4 | loss: 0.4564810\n",
      "\tspeed: 0.0403s/iter; left time: 219.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.98s\n",
      "Steps: 906 | Train Loss: 0.4849790 Vali Loss: 0.4594938 Test Loss: 0.5241997\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4823216\n",
      "\tspeed: 0.0956s/iter; left time: 510.4286s\n",
      "\titers: 200, epoch: 5 | loss: 0.4644124\n",
      "\tspeed: 0.0403s/iter; left time: 211.0284s\n",
      "\titers: 300, epoch: 5 | loss: 0.4214824\n",
      "\tspeed: 0.0405s/iter; left time: 207.9915s\n",
      "\titers: 400, epoch: 5 | loss: 0.4996223\n",
      "\tspeed: 0.0423s/iter; left time: 213.2056s\n",
      "\titers: 500, epoch: 5 | loss: 0.4287166\n",
      "\tspeed: 0.0421s/iter; left time: 207.7844s\n",
      "\titers: 600, epoch: 5 | loss: 0.4123247\n",
      "\tspeed: 0.0414s/iter; left time: 200.4523s\n",
      "\titers: 700, epoch: 5 | loss: 0.4194843\n",
      "\tspeed: 0.0418s/iter; left time: 197.8673s\n",
      "\titers: 800, epoch: 5 | loss: 0.4636900\n",
      "\tspeed: 0.0417s/iter; left time: 193.1668s\n",
      "\titers: 900, epoch: 5 | loss: 0.4432615\n",
      "\tspeed: 0.0418s/iter; left time: 189.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 906 | Train Loss: 0.4400303 Vali Loss: 0.4821237 Test Loss: 0.5637830\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5070682764053345, rmse:0.7120872735977173, mae:0.49827083945274353, rse:0.563572108745575\n",
      "Original data scale mse:20156686.0, rmse:4489.61962890625, mae:2999.142578125, rse:0.2232329547405243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8588779\n",
      "\tspeed: 0.0433s/iter; left time: 387.6552s\n",
      "\titers: 200, epoch: 1 | loss: 0.7982945\n",
      "\tspeed: 0.0404s/iter; left time: 358.2111s\n",
      "\titers: 300, epoch: 1 | loss: 0.8250256\n",
      "\tspeed: 0.0410s/iter; left time: 359.5281s\n",
      "\titers: 400, epoch: 1 | loss: 0.7691973\n",
      "\tspeed: 0.0404s/iter; left time: 349.9992s\n",
      "\titers: 500, epoch: 1 | loss: 0.7309195\n",
      "\tspeed: 0.0403s/iter; left time: 345.1850s\n",
      "\titers: 600, epoch: 1 | loss: 0.6879429\n",
      "\tspeed: 0.0405s/iter; left time: 342.4561s\n",
      "\titers: 700, epoch: 1 | loss: 0.6365433\n",
      "\tspeed: 0.0412s/iter; left time: 344.1932s\n",
      "\titers: 800, epoch: 1 | loss: 0.7065768\n",
      "\tspeed: 0.0418s/iter; left time: 344.9825s\n",
      "\titers: 900, epoch: 1 | loss: 0.6446868\n",
      "\tspeed: 0.0414s/iter; left time: 338.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.33s\n",
      "Steps: 906 | Train Loss: 0.7622878 Vali Loss: 0.5469300 Test Loss: 0.6323155\n",
      "Validation loss decreased (inf --> 0.546930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5923141\n",
      "\tspeed: 0.1011s/iter; left time: 814.6983s\n",
      "\titers: 200, epoch: 2 | loss: 0.5748015\n",
      "\tspeed: 0.0420s/iter; left time: 333.9280s\n",
      "\titers: 300, epoch: 2 | loss: 0.5269984\n",
      "\tspeed: 0.0399s/iter; left time: 313.5864s\n",
      "\titers: 400, epoch: 2 | loss: 0.5026063\n",
      "\tspeed: 0.0410s/iter; left time: 318.2473s\n",
      "\titers: 500, epoch: 2 | loss: 0.5611269\n",
      "\tspeed: 0.0407s/iter; left time: 311.9162s\n",
      "\titers: 600, epoch: 2 | loss: 0.5893219\n",
      "\tspeed: 0.0404s/iter; left time: 305.4282s\n",
      "\titers: 700, epoch: 2 | loss: 0.5543723\n",
      "\tspeed: 0.0404s/iter; left time: 301.4301s\n",
      "\titers: 800, epoch: 2 | loss: 0.4901477\n",
      "\tspeed: 0.0404s/iter; left time: 297.1698s\n",
      "\titers: 900, epoch: 2 | loss: 0.5559916\n",
      "\tspeed: 0.0376s/iter; left time: 272.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.90s\n",
      "Steps: 906 | Train Loss: 0.5776560 Vali Loss: 0.4851062 Test Loss: 0.5314170\n",
      "Validation loss decreased (0.546930 --> 0.485106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6048454\n",
      "\tspeed: 0.1000s/iter; left time: 714.5903s\n",
      "\titers: 200, epoch: 3 | loss: 0.5126129\n",
      "\tspeed: 0.0424s/iter; left time: 298.7109s\n",
      "\titers: 300, epoch: 3 | loss: 0.4772909\n",
      "\tspeed: 0.0429s/iter; left time: 297.8391s\n",
      "\titers: 400, epoch: 3 | loss: 0.5289421\n",
      "\tspeed: 0.0432s/iter; left time: 295.9513s\n",
      "\titers: 500, epoch: 3 | loss: 0.5147277\n",
      "\tspeed: 0.0422s/iter; left time: 284.7096s\n",
      "\titers: 600, epoch: 3 | loss: 0.5077899\n",
      "\tspeed: 0.0414s/iter; left time: 275.1727s\n",
      "\titers: 700, epoch: 3 | loss: 0.5518087\n",
      "\tspeed: 0.0421s/iter; left time: 275.8539s\n",
      "\titers: 800, epoch: 3 | loss: 0.5423992\n",
      "\tspeed: 0.0410s/iter; left time: 264.1897s\n",
      "\titers: 900, epoch: 3 | loss: 0.4665054\n",
      "\tspeed: 0.0404s/iter; left time: 256.5214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 906 | Train Loss: 0.5296453 Vali Loss: 0.4397265 Test Loss: 0.4830378\n",
      "Validation loss decreased (0.485106 --> 0.439726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4773476\n",
      "\tspeed: 0.0981s/iter; left time: 612.4550s\n",
      "\titers: 200, epoch: 4 | loss: 0.5036800\n",
      "\tspeed: 0.0403s/iter; left time: 247.8418s\n",
      "\titers: 300, epoch: 4 | loss: 0.6146199\n",
      "\tspeed: 0.0402s/iter; left time: 242.8053s\n",
      "\titers: 400, epoch: 4 | loss: 0.4577895\n",
      "\tspeed: 0.0403s/iter; left time: 239.5538s\n",
      "\titers: 500, epoch: 4 | loss: 0.5661929\n",
      "\tspeed: 0.0423s/iter; left time: 247.0214s\n",
      "\titers: 600, epoch: 4 | loss: 0.5100247\n",
      "\tspeed: 0.0294s/iter; left time: 168.6019s\n",
      "\titers: 700, epoch: 4 | loss: 0.4980476\n",
      "\tspeed: 0.0284s/iter; left time: 160.3477s\n",
      "\titers: 800, epoch: 4 | loss: 0.3978939\n",
      "\tspeed: 0.0342s/iter; left time: 189.6379s\n",
      "\titers: 900, epoch: 4 | loss: 0.3861069\n",
      "\tspeed: 0.0421s/iter; left time: 229.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.31s\n",
      "Steps: 906 | Train Loss: 0.4899198 Vali Loss: 0.4603651 Test Loss: 0.5041409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4936487\n",
      "\tspeed: 0.0963s/iter; left time: 513.7432s\n",
      "\titers: 200, epoch: 5 | loss: 0.4334660\n",
      "\tspeed: 0.0403s/iter; left time: 211.2733s\n",
      "\titers: 300, epoch: 5 | loss: 0.4235884\n",
      "\tspeed: 0.0405s/iter; left time: 207.8465s\n",
      "\titers: 400, epoch: 5 | loss: 0.4626411\n",
      "\tspeed: 0.0403s/iter; left time: 202.8950s\n",
      "\titers: 500, epoch: 5 | loss: 0.3728518\n",
      "\tspeed: 0.0401s/iter; left time: 198.0847s\n",
      "\titers: 600, epoch: 5 | loss: 0.4660599\n",
      "\tspeed: 0.0404s/iter; left time: 195.5429s\n",
      "\titers: 700, epoch: 5 | loss: 0.4180226\n",
      "\tspeed: 0.0403s/iter; left time: 191.1128s\n",
      "\titers: 800, epoch: 5 | loss: 0.4556598\n",
      "\tspeed: 0.0403s/iter; left time: 187.0751s\n",
      "\titers: 900, epoch: 5 | loss: 0.4162793\n",
      "\tspeed: 0.0403s/iter; left time: 183.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.4432991 Vali Loss: 0.4867482 Test Loss: 0.5200544\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3990616\n",
      "\tspeed: 0.0965s/iter; left time: 427.6229s\n",
      "\titers: 200, epoch: 6 | loss: 0.4005626\n",
      "\tspeed: 0.0425s/iter; left time: 183.9177s\n",
      "\titers: 300, epoch: 6 | loss: 0.4957956\n",
      "\tspeed: 0.0409s/iter; left time: 173.1962s\n",
      "\titers: 400, epoch: 6 | loss: 0.4094400\n",
      "\tspeed: 0.0404s/iter; left time: 166.8591s\n",
      "\titers: 500, epoch: 6 | loss: 0.3923487\n",
      "\tspeed: 0.0403s/iter; left time: 162.5584s\n",
      "\titers: 600, epoch: 6 | loss: 0.3940423\n",
      "\tspeed: 0.0402s/iter; left time: 158.1706s\n",
      "\titers: 700, epoch: 6 | loss: 0.3931371\n",
      "\tspeed: 0.0405s/iter; left time: 155.0205s\n",
      "\titers: 800, epoch: 6 | loss: 0.3574754\n",
      "\tspeed: 0.0405s/iter; left time: 151.0988s\n",
      "\titers: 900, epoch: 6 | loss: 0.3599356\n",
      "\tspeed: 0.0404s/iter; left time: 146.7777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.25s\n",
      "Steps: 906 | Train Loss: 0.4004315 Vali Loss: 0.5209612 Test Loss: 0.5491917\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4826447069644928, rmse:0.6947263479232788, mae:0.4775684177875519, rse:0.5498320460319519\n",
      "Original data scale mse:19259186.0, rmse:4388.52880859375, mae:2873.763671875, rse:0.2182064950466156\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0252380\n",
      "\tspeed: 0.0727s/iter; left time: 650.2127s\n",
      "\titers: 200, epoch: 1 | loss: 0.9821252\n",
      "\tspeed: 0.0447s/iter; left time: 395.0234s\n",
      "\titers: 300, epoch: 1 | loss: 0.9594889\n",
      "\tspeed: 0.0457s/iter; left time: 399.8409s\n",
      "\titers: 400, epoch: 1 | loss: 0.8844653\n",
      "\tspeed: 0.0465s/iter; left time: 402.1781s\n",
      "\titers: 500, epoch: 1 | loss: 0.8824679\n",
      "\tspeed: 0.0460s/iter; left time: 392.6459s\n",
      "\titers: 600, epoch: 1 | loss: 0.8055439\n",
      "\tspeed: 0.0464s/iter; left time: 391.3131s\n",
      "\titers: 700, epoch: 1 | loss: 0.7853126\n",
      "\tspeed: 0.0462s/iter; left time: 385.5317s\n",
      "\titers: 800, epoch: 1 | loss: 0.8030834\n",
      "\tspeed: 0.0449s/iter; left time: 369.9513s\n",
      "\titers: 900, epoch: 1 | loss: 0.8041261\n",
      "\tspeed: 0.0460s/iter; left time: 374.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.13s\n",
      "Steps: 904 | Train Loss: 0.8981916 Vali Loss: 0.8284516 Test Loss: 1.0307974\n",
      "Validation loss decreased (inf --> 0.828452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7219144\n",
      "\tspeed: 0.1162s/iter; left time: 933.5109s\n",
      "\titers: 200, epoch: 2 | loss: 0.7597279\n",
      "\tspeed: 0.0388s/iter; left time: 307.9228s\n",
      "\titers: 300, epoch: 2 | loss: 0.7219747\n",
      "\tspeed: 0.0365s/iter; left time: 285.6860s\n",
      "\titers: 400, epoch: 2 | loss: 0.6980771\n",
      "\tspeed: 0.0419s/iter; left time: 324.3215s\n",
      "\titers: 500, epoch: 2 | loss: 0.6995429\n",
      "\tspeed: 0.0356s/iter; left time: 271.7289s\n",
      "\titers: 600, epoch: 2 | loss: 0.7647797\n",
      "\tspeed: 0.0459s/iter; left time: 345.9599s\n",
      "\titers: 700, epoch: 2 | loss: 0.6916636\n",
      "\tspeed: 0.0439s/iter; left time: 326.1169s\n",
      "\titers: 800, epoch: 2 | loss: 0.7342687\n",
      "\tspeed: 0.0460s/iter; left time: 337.8506s\n",
      "\titers: 900, epoch: 2 | loss: 0.6819095\n",
      "\tspeed: 0.0459s/iter; left time: 331.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 904 | Train Loss: 0.7261729 Vali Loss: 0.6847084 Test Loss: 0.8025894\n",
      "Validation loss decreased (0.828452 --> 0.684708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7336022\n",
      "\tspeed: 0.1145s/iter; left time: 816.6285s\n",
      "\titers: 200, epoch: 3 | loss: 0.6408885\n",
      "\tspeed: 0.0441s/iter; left time: 309.9571s\n",
      "\titers: 300, epoch: 3 | loss: 0.6044647\n",
      "\tspeed: 0.0454s/iter; left time: 315.0128s\n",
      "\titers: 400, epoch: 3 | loss: 0.6270521\n",
      "\tspeed: 0.0447s/iter; left time: 305.4366s\n",
      "\titers: 500, epoch: 3 | loss: 0.6593441\n",
      "\tspeed: 0.0440s/iter; left time: 296.5289s\n",
      "\titers: 600, epoch: 3 | loss: 0.6727517\n",
      "\tspeed: 0.0430s/iter; left time: 285.1041s\n",
      "\titers: 700, epoch: 3 | loss: 0.6100384\n",
      "\tspeed: 0.0460s/iter; left time: 300.4643s\n",
      "\titers: 800, epoch: 3 | loss: 0.6660968\n",
      "\tspeed: 0.0431s/iter; left time: 277.5065s\n",
      "\titers: 900, epoch: 3 | loss: 0.6544979\n",
      "\tspeed: 0.0452s/iter; left time: 286.3006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.61s\n",
      "Steps: 904 | Train Loss: 0.6540388 Vali Loss: 0.6982146 Test Loss: 0.8181267\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5878187\n",
      "\tspeed: 0.1091s/iter; left time: 679.7784s\n",
      "\titers: 200, epoch: 4 | loss: 0.5915712\n",
      "\tspeed: 0.0465s/iter; left time: 285.2739s\n",
      "\titers: 300, epoch: 4 | loss: 0.5916324\n",
      "\tspeed: 0.0463s/iter; left time: 279.2914s\n",
      "\titers: 400, epoch: 4 | loss: 0.5480406\n",
      "\tspeed: 0.0460s/iter; left time: 272.6906s\n",
      "\titers: 500, epoch: 4 | loss: 0.6060248\n",
      "\tspeed: 0.0463s/iter; left time: 269.8163s\n",
      "\titers: 600, epoch: 4 | loss: 0.5727869\n",
      "\tspeed: 0.0453s/iter; left time: 259.6532s\n",
      "\titers: 700, epoch: 4 | loss: 0.6088339\n",
      "\tspeed: 0.0368s/iter; left time: 207.3894s\n",
      "\titers: 800, epoch: 4 | loss: 0.5749963\n",
      "\tspeed: 0.0362s/iter; left time: 200.1660s\n",
      "\titers: 900, epoch: 4 | loss: 0.5974422\n",
      "\tspeed: 0.0355s/iter; left time: 192.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 904 | Train Loss: 0.5986204 Vali Loss: 0.7151270 Test Loss: 0.9077851\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5486233\n",
      "\tspeed: 0.1095s/iter; left time: 583.3356s\n",
      "\titers: 200, epoch: 5 | loss: 0.6009266\n",
      "\tspeed: 0.0460s/iter; left time: 240.1314s\n",
      "\titers: 300, epoch: 5 | loss: 0.5961829\n",
      "\tspeed: 0.0449s/iter; left time: 230.2508s\n",
      "\titers: 400, epoch: 5 | loss: 0.5412604\n",
      "\tspeed: 0.0461s/iter; left time: 231.8430s\n",
      "\titers: 500, epoch: 5 | loss: 0.5200085\n",
      "\tspeed: 0.0455s/iter; left time: 224.3296s\n",
      "\titers: 600, epoch: 5 | loss: 0.5370143\n",
      "\tspeed: 0.0458s/iter; left time: 220.8870s\n",
      "\titers: 700, epoch: 5 | loss: 0.5396135\n",
      "\tspeed: 0.0441s/iter; left time: 208.4676s\n",
      "\titers: 800, epoch: 5 | loss: 0.4846662\n",
      "\tspeed: 0.0460s/iter; left time: 212.9798s\n",
      "\titers: 900, epoch: 5 | loss: 0.5213868\n",
      "\tspeed: 0.0459s/iter; left time: 207.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.33s\n",
      "Steps: 904 | Train Loss: 0.5498217 Vali Loss: 0.7051411 Test Loss: 0.8774026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8018559813499451, rmse:0.8954641222953796, mae:0.6662679314613342, rse:0.7102134227752686\n",
      "Original data scale mse:34543984.0, rmse:5877.4130859375, mae:4100.0751953125, rse:0.2926972508430481\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9545566\n",
      "\tspeed: 0.0472s/iter; left time: 421.8077s\n",
      "\titers: 200, epoch: 1 | loss: 0.9046481\n",
      "\tspeed: 0.0445s/iter; left time: 393.6427s\n",
      "\titers: 300, epoch: 1 | loss: 0.9244955\n",
      "\tspeed: 0.0442s/iter; left time: 386.5066s\n",
      "\titers: 400, epoch: 1 | loss: 0.9064289\n",
      "\tspeed: 0.0455s/iter; left time: 392.9535s\n",
      "\titers: 500, epoch: 1 | loss: 0.9243618\n",
      "\tspeed: 0.0457s/iter; left time: 390.5690s\n",
      "\titers: 600, epoch: 1 | loss: 0.8122278\n",
      "\tspeed: 0.0456s/iter; left time: 384.9384s\n",
      "\titers: 700, epoch: 1 | loss: 0.9583504\n",
      "\tspeed: 0.0456s/iter; left time: 380.6832s\n",
      "\titers: 800, epoch: 1 | loss: 0.8278310\n",
      "\tspeed: 0.0456s/iter; left time: 375.5682s\n",
      "\titers: 900, epoch: 1 | loss: 0.8535752\n",
      "\tspeed: 0.0450s/iter; left time: 366.4541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.15s\n",
      "Steps: 904 | Train Loss: 0.9020157 Vali Loss: 0.8226253 Test Loss: 1.0339608\n",
      "Validation loss decreased (inf --> 0.822625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8071152\n",
      "\tspeed: 0.1209s/iter; left time: 971.3800s\n",
      "\titers: 200, epoch: 2 | loss: 0.7878410\n",
      "\tspeed: 0.0450s/iter; left time: 357.1174s\n",
      "\titers: 300, epoch: 2 | loss: 0.7395509\n",
      "\tspeed: 0.0463s/iter; left time: 362.9254s\n",
      "\titers: 400, epoch: 2 | loss: 0.6591961\n",
      "\tspeed: 0.0456s/iter; left time: 352.9293s\n",
      "\titers: 500, epoch: 2 | loss: 0.6968939\n",
      "\tspeed: 0.0446s/iter; left time: 340.5841s\n",
      "\titers: 600, epoch: 2 | loss: 0.7799301\n",
      "\tspeed: 0.0356s/iter; left time: 268.4588s\n",
      "\titers: 700, epoch: 2 | loss: 0.7029775\n",
      "\tspeed: 0.0412s/iter; left time: 306.4490s\n",
      "\titers: 800, epoch: 2 | loss: 0.7345486\n",
      "\tspeed: 0.0355s/iter; left time: 260.6145s\n",
      "\titers: 900, epoch: 2 | loss: 0.6330129\n",
      "\tspeed: 0.0355s/iter; left time: 257.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 904 | Train Loss: 0.7273200 Vali Loss: 0.6909656 Test Loss: 0.8539773\n",
      "Validation loss decreased (0.822625 --> 0.690966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6829980\n",
      "\tspeed: 0.1193s/iter; left time: 850.7608s\n",
      "\titers: 200, epoch: 3 | loss: 0.6691113\n",
      "\tspeed: 0.0464s/iter; left time: 326.3224s\n",
      "\titers: 300, epoch: 3 | loss: 0.6194271\n",
      "\tspeed: 0.0461s/iter; left time: 319.5583s\n",
      "\titers: 400, epoch: 3 | loss: 0.6320899\n",
      "\tspeed: 0.0460s/iter; left time: 314.0888s\n",
      "\titers: 500, epoch: 3 | loss: 0.6391604\n",
      "\tspeed: 0.0459s/iter; left time: 308.9528s\n",
      "\titers: 600, epoch: 3 | loss: 0.6362435\n",
      "\tspeed: 0.0460s/iter; left time: 304.9596s\n",
      "\titers: 700, epoch: 3 | loss: 0.6481073\n",
      "\tspeed: 0.0460s/iter; left time: 300.3485s\n",
      "\titers: 800, epoch: 3 | loss: 0.6707047\n",
      "\tspeed: 0.0455s/iter; left time: 292.7730s\n",
      "\titers: 900, epoch: 3 | loss: 0.6414825\n",
      "\tspeed: 0.0452s/iter; left time: 286.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.67s\n",
      "Steps: 904 | Train Loss: 0.6500887 Vali Loss: 0.7310898 Test Loss: 0.8651748\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5668097\n",
      "\tspeed: 0.1118s/iter; left time: 696.5705s\n",
      "\titers: 200, epoch: 4 | loss: 0.6010278\n",
      "\tspeed: 0.0453s/iter; left time: 277.9286s\n",
      "\titers: 300, epoch: 4 | loss: 0.5805757\n",
      "\tspeed: 0.0424s/iter; left time: 255.4812s\n",
      "\titers: 400, epoch: 4 | loss: 0.5756222\n",
      "\tspeed: 0.0451s/iter; left time: 267.4973s\n",
      "\titers: 500, epoch: 4 | loss: 0.6019570\n",
      "\tspeed: 0.0453s/iter; left time: 263.8164s\n",
      "\titers: 600, epoch: 4 | loss: 0.5867005\n",
      "\tspeed: 0.0454s/iter; left time: 259.9270s\n",
      "\titers: 700, epoch: 4 | loss: 0.5590611\n",
      "\tspeed: 0.0456s/iter; left time: 256.4669s\n",
      "\titers: 800, epoch: 4 | loss: 0.5786862\n",
      "\tspeed: 0.0455s/iter; left time: 251.4199s\n",
      "\titers: 900, epoch: 4 | loss: 0.5570041\n",
      "\tspeed: 0.0444s/iter; left time: 241.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.91s\n",
      "Steps: 904 | Train Loss: 0.5954686 Vali Loss: 0.7804562 Test Loss: 0.9499455\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5297164\n",
      "\tspeed: 0.1113s/iter; left time: 592.6540s\n",
      "\titers: 200, epoch: 5 | loss: 0.5754976\n",
      "\tspeed: 0.0462s/iter; left time: 241.3270s\n",
      "\titers: 300, epoch: 5 | loss: 0.5536209\n",
      "\tspeed: 0.0453s/iter; left time: 231.9430s\n",
      "\titers: 400, epoch: 5 | loss: 0.5372819\n",
      "\tspeed: 0.0444s/iter; left time: 223.3453s\n",
      "\titers: 500, epoch: 5 | loss: 0.5717360\n",
      "\tspeed: 0.0448s/iter; left time: 220.8070s\n",
      "\titers: 600, epoch: 5 | loss: 0.5239812\n",
      "\tspeed: 0.0450s/iter; left time: 217.0033s\n",
      "\titers: 700, epoch: 5 | loss: 0.5715138\n",
      "\tspeed: 0.0447s/iter; left time: 211.2791s\n",
      "\titers: 800, epoch: 5 | loss: 0.5439026\n",
      "\tspeed: 0.0429s/iter; left time: 198.5007s\n",
      "\titers: 900, epoch: 5 | loss: 0.5221722\n",
      "\tspeed: 0.0443s/iter; left time: 200.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.73s\n",
      "Steps: 904 | Train Loss: 0.5448839 Vali Loss: 0.7546401 Test Loss: 0.9773735\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8537888526916504, rmse:0.9240069389343262, mae:0.6723426580429077, rse:0.7328513860702515\n",
      "Original data scale mse:36986492.0, rmse:6081.65185546875, mae:4114.8583984375, rse:0.30286842584609985\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9471332\n",
      "\tspeed: 0.0750s/iter; left time: 669.4482s\n",
      "\titers: 200, epoch: 1 | loss: 0.9861875\n",
      "\tspeed: 0.0431s/iter; left time: 379.7759s\n",
      "\titers: 300, epoch: 1 | loss: 0.9315915\n",
      "\tspeed: 0.0427s/iter; left time: 372.5412s\n",
      "\titers: 400, epoch: 1 | loss: 0.9368693\n",
      "\tspeed: 0.0461s/iter; left time: 397.2905s\n",
      "\titers: 500, epoch: 1 | loss: 0.9175271\n",
      "\tspeed: 0.0515s/iter; left time: 439.2397s\n",
      "\titers: 600, epoch: 1 | loss: 0.9426318\n",
      "\tspeed: 0.0520s/iter; left time: 437.9744s\n",
      "\titers: 700, epoch: 1 | loss: 0.9106294\n",
      "\tspeed: 0.0517s/iter; left time: 429.8472s\n",
      "\titers: 800, epoch: 1 | loss: 0.8740443\n",
      "\tspeed: 0.0524s/iter; left time: 430.4814s\n",
      "\titers: 900, epoch: 1 | loss: 0.9128570\n",
      "\tspeed: 0.0523s/iter; left time: 424.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.88s\n",
      "Steps: 902 | Train Loss: 0.9340369 Vali Loss: 0.9780082 Test Loss: 1.2568091\n",
      "Validation loss decreased (inf --> 0.978008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9008682\n",
      "\tspeed: 0.1365s/iter; left time: 1094.7834s\n",
      "\titers: 200, epoch: 2 | loss: 0.8331870\n",
      "\tspeed: 0.0528s/iter; left time: 417.9698s\n",
      "\titers: 300, epoch: 2 | loss: 0.8587946\n",
      "\tspeed: 0.0521s/iter; left time: 407.5985s\n",
      "\titers: 400, epoch: 2 | loss: 0.7877640\n",
      "\tspeed: 0.0528s/iter; left time: 407.4444s\n",
      "\titers: 500, epoch: 2 | loss: 0.7759214\n",
      "\tspeed: 0.0531s/iter; left time: 404.8446s\n",
      "\titers: 600, epoch: 2 | loss: 0.7217450\n",
      "\tspeed: 0.0452s/iter; left time: 339.7906s\n",
      "\titers: 700, epoch: 2 | loss: 0.7161107\n",
      "\tspeed: 0.0443s/iter; left time: 328.8212s\n",
      "\titers: 800, epoch: 2 | loss: 0.7566212\n",
      "\tspeed: 0.0443s/iter; left time: 324.1969s\n",
      "\titers: 900, epoch: 2 | loss: 0.7012705\n",
      "\tspeed: 0.0448s/iter; left time: 323.3678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.54s\n",
      "Steps: 902 | Train Loss: 0.7724640 Vali Loss: 0.7328678 Test Loss: 0.8932632\n",
      "Validation loss decreased (0.978008 --> 0.732868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7165682\n",
      "\tspeed: 0.1299s/iter; left time: 924.3434s\n",
      "\titers: 200, epoch: 3 | loss: 0.6870352\n",
      "\tspeed: 0.0523s/iter; left time: 366.7779s\n",
      "\titers: 300, epoch: 3 | loss: 0.6787533\n",
      "\tspeed: 0.0447s/iter; left time: 309.2308s\n",
      "\titers: 400, epoch: 3 | loss: 0.7236806\n",
      "\tspeed: 0.0518s/iter; left time: 353.0435s\n",
      "\titers: 500, epoch: 3 | loss: 0.6608443\n",
      "\tspeed: 0.0518s/iter; left time: 347.8509s\n",
      "\titers: 600, epoch: 3 | loss: 0.6809654\n",
      "\tspeed: 0.0532s/iter; left time: 351.8889s\n",
      "\titers: 700, epoch: 3 | loss: 0.6834272\n",
      "\tspeed: 0.0532s/iter; left time: 346.6506s\n",
      "\titers: 800, epoch: 3 | loss: 0.6417248\n",
      "\tspeed: 0.0532s/iter; left time: 341.4206s\n",
      "\titers: 900, epoch: 3 | loss: 0.6610432\n",
      "\tspeed: 0.0523s/iter; left time: 330.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.48s\n",
      "Steps: 902 | Train Loss: 0.6721240 Vali Loss: 0.7346251 Test Loss: 0.9027070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6154931\n",
      "\tspeed: 0.1322s/iter; left time: 821.6586s\n",
      "\titers: 200, epoch: 4 | loss: 0.5788427\n",
      "\tspeed: 0.0528s/iter; left time: 322.7613s\n",
      "\titers: 300, epoch: 4 | loss: 0.6534283\n",
      "\tspeed: 0.0525s/iter; left time: 315.9795s\n",
      "\titers: 400, epoch: 4 | loss: 0.6317046\n",
      "\tspeed: 0.0522s/iter; left time: 308.4753s\n",
      "\titers: 500, epoch: 4 | loss: 0.6388951\n",
      "\tspeed: 0.0520s/iter; left time: 302.5895s\n",
      "\titers: 600, epoch: 4 | loss: 0.5904660\n",
      "\tspeed: 0.0517s/iter; left time: 295.4779s\n",
      "\titers: 700, epoch: 4 | loss: 0.6414444\n",
      "\tspeed: 0.0520s/iter; left time: 292.1687s\n",
      "\titers: 800, epoch: 4 | loss: 0.6158543\n",
      "\tspeed: 0.0519s/iter; left time: 286.1611s\n",
      "\titers: 900, epoch: 4 | loss: 0.5860508\n",
      "\tspeed: 0.0521s/iter; left time: 281.9420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.33s\n",
      "Steps: 902 | Train Loss: 0.6109018 Vali Loss: 0.7862337 Test Loss: 1.0190303\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6108308\n",
      "\tspeed: 0.1307s/iter; left time: 694.2721s\n",
      "\titers: 200, epoch: 5 | loss: 0.5784037\n",
      "\tspeed: 0.0488s/iter; left time: 254.2279s\n",
      "\titers: 300, epoch: 5 | loss: 0.5641100\n",
      "\tspeed: 0.0428s/iter; left time: 218.9904s\n",
      "\titers: 400, epoch: 5 | loss: 0.5748665\n",
      "\tspeed: 0.0502s/iter; left time: 251.4644s\n",
      "\titers: 500, epoch: 5 | loss: 0.5016975\n",
      "\tspeed: 0.0509s/iter; left time: 250.0087s\n",
      "\titers: 600, epoch: 5 | loss: 0.5542794\n",
      "\tspeed: 0.0491s/iter; left time: 236.2583s\n",
      "\titers: 700, epoch: 5 | loss: 0.5704201\n",
      "\tspeed: 0.0516s/iter; left time: 243.2973s\n",
      "\titers: 800, epoch: 5 | loss: 0.5250012\n",
      "\tspeed: 0.0518s/iter; left time: 239.0809s\n",
      "\titers: 900, epoch: 5 | loss: 0.4947276\n",
      "\tspeed: 0.0521s/iter; left time: 235.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.29s\n",
      "Steps: 902 | Train Loss: 0.5555994 Vali Loss: 0.8196364 Test Loss: 1.0833149\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8934528827667236, rmse:0.9452263712882996, mae:0.6883419156074524, rse:0.7487866282463074\n",
      "Original data scale mse:38815100.0, rmse:6230.1767578125, mae:4220.97314453125, rse:0.3104173243045807\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0656863\n",
      "\tspeed: 0.0543s/iter; left time: 484.7678s\n",
      "\titers: 200, epoch: 1 | loss: 0.9557311\n",
      "\tspeed: 0.0526s/iter; left time: 464.1785s\n",
      "\titers: 300, epoch: 1 | loss: 0.8678913\n",
      "\tspeed: 0.0522s/iter; left time: 455.6580s\n",
      "\titers: 400, epoch: 1 | loss: 0.9394004\n",
      "\tspeed: 0.0521s/iter; left time: 448.8405s\n",
      "\titers: 500, epoch: 1 | loss: 0.9029401\n",
      "\tspeed: 0.0523s/iter; left time: 445.5772s\n",
      "\titers: 600, epoch: 1 | loss: 0.9282050\n",
      "\tspeed: 0.0522s/iter; left time: 439.9808s\n",
      "\titers: 700, epoch: 1 | loss: 0.9335796\n",
      "\tspeed: 0.0519s/iter; left time: 431.8473s\n",
      "\titers: 800, epoch: 1 | loss: 0.8777130\n",
      "\tspeed: 0.0521s/iter; left time: 427.9090s\n",
      "\titers: 900, epoch: 1 | loss: 0.8798903\n",
      "\tspeed: 0.0525s/iter; left time: 425.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.9323759 Vali Loss: 0.9880757 Test Loss: 1.2649819\n",
      "Validation loss decreased (inf --> 0.988076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8998638\n",
      "\tspeed: 0.1343s/iter; left time: 1077.0462s\n",
      "\titers: 200, epoch: 2 | loss: 0.8122976\n",
      "\tspeed: 0.0527s/iter; left time: 417.2423s\n",
      "\titers: 300, epoch: 2 | loss: 0.8411333\n",
      "\tspeed: 0.0521s/iter; left time: 407.6871s\n",
      "\titers: 400, epoch: 2 | loss: 0.7060408\n",
      "\tspeed: 0.0523s/iter; left time: 403.3191s\n",
      "\titers: 500, epoch: 2 | loss: 0.7866837\n",
      "\tspeed: 0.0519s/iter; left time: 395.6479s\n",
      "\titers: 600, epoch: 2 | loss: 0.7293652\n",
      "\tspeed: 0.0519s/iter; left time: 390.3976s\n",
      "\titers: 700, epoch: 2 | loss: 0.7686659\n",
      "\tspeed: 0.0517s/iter; left time: 383.3041s\n",
      "\titers: 800, epoch: 2 | loss: 0.7129799\n",
      "\tspeed: 0.0517s/iter; left time: 378.1765s\n",
      "\titers: 900, epoch: 2 | loss: 0.6920627\n",
      "\tspeed: 0.0516s/iter; left time: 372.5100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.21s\n",
      "Steps: 902 | Train Loss: 0.7832593 Vali Loss: 0.7692808 Test Loss: 0.8737599\n",
      "Validation loss decreased (0.988076 --> 0.769281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6975249\n",
      "\tspeed: 0.1343s/iter; left time: 955.7271s\n",
      "\titers: 200, epoch: 3 | loss: 0.6490678\n",
      "\tspeed: 0.0519s/iter; left time: 363.9434s\n",
      "\titers: 300, epoch: 3 | loss: 0.6470399\n",
      "\tspeed: 0.0517s/iter; left time: 357.4043s\n",
      "\titers: 400, epoch: 3 | loss: 0.6277720\n",
      "\tspeed: 0.0521s/iter; left time: 355.2912s\n",
      "\titers: 500, epoch: 3 | loss: 0.6651936\n",
      "\tspeed: 0.0522s/iter; left time: 350.5084s\n",
      "\titers: 600, epoch: 3 | loss: 0.6629560\n",
      "\tspeed: 0.0519s/iter; left time: 343.2412s\n",
      "\titers: 700, epoch: 3 | loss: 0.6748104\n",
      "\tspeed: 0.0523s/iter; left time: 340.7852s\n",
      "\titers: 800, epoch: 3 | loss: 0.6037708\n",
      "\tspeed: 0.0519s/iter; left time: 332.7354s\n",
      "\titers: 900, epoch: 3 | loss: 0.6436216\n",
      "\tspeed: 0.0519s/iter; left time: 328.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.17s\n",
      "Steps: 902 | Train Loss: 0.6772264 Vali Loss: 0.7475495 Test Loss: 0.9241825\n",
      "Validation loss decreased (0.769281 --> 0.747550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5969893\n",
      "\tspeed: 0.1340s/iter; left time: 832.8541s\n",
      "\titers: 200, epoch: 4 | loss: 0.6450239\n",
      "\tspeed: 0.0521s/iter; left time: 318.7881s\n",
      "\titers: 300, epoch: 4 | loss: 0.6595438\n",
      "\tspeed: 0.0520s/iter; left time: 312.5023s\n",
      "\titers: 400, epoch: 4 | loss: 0.6280913\n",
      "\tspeed: 0.0519s/iter; left time: 306.9417s\n",
      "\titers: 500, epoch: 4 | loss: 0.6201030\n",
      "\tspeed: 0.0519s/iter; left time: 301.8731s\n",
      "\titers: 600, epoch: 4 | loss: 0.6041957\n",
      "\tspeed: 0.0519s/iter; left time: 296.5162s\n",
      "\titers: 700, epoch: 4 | loss: 0.5926436\n",
      "\tspeed: 0.0520s/iter; left time: 291.7249s\n",
      "\titers: 800, epoch: 4 | loss: 0.5527857\n",
      "\tspeed: 0.0520s/iter; left time: 286.5435s\n",
      "\titers: 900, epoch: 4 | loss: 0.6230676\n",
      "\tspeed: 0.0516s/iter; left time: 279.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 902 | Train Loss: 0.6172915 Vali Loss: 0.7728670 Test Loss: 0.9370694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5788156\n",
      "\tspeed: 0.1312s/iter; left time: 696.8861s\n",
      "\titers: 200, epoch: 5 | loss: 0.5334616\n",
      "\tspeed: 0.0519s/iter; left time: 270.3192s\n",
      "\titers: 300, epoch: 5 | loss: 0.5742775\n",
      "\tspeed: 0.0521s/iter; left time: 266.4607s\n",
      "\titers: 400, epoch: 5 | loss: 0.5482292\n",
      "\tspeed: 0.0518s/iter; left time: 259.7512s\n",
      "\titers: 500, epoch: 5 | loss: 0.5712826\n",
      "\tspeed: 0.0518s/iter; left time: 254.5735s\n",
      "\titers: 600, epoch: 5 | loss: 0.5743529\n",
      "\tspeed: 0.0519s/iter; left time: 249.8590s\n",
      "\titers: 700, epoch: 5 | loss: 0.5463770\n",
      "\tspeed: 0.0520s/iter; left time: 245.2405s\n",
      "\titers: 800, epoch: 5 | loss: 0.5580187\n",
      "\tspeed: 0.0519s/iter; left time: 239.6292s\n",
      "\titers: 900, epoch: 5 | loss: 0.5339939\n",
      "\tspeed: 0.0519s/iter; left time: 234.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.14s\n",
      "Steps: 902 | Train Loss: 0.5604885 Vali Loss: 0.8126694 Test Loss: 0.9670021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5250809\n",
      "\tspeed: 0.1316s/iter; left time: 580.5166s\n",
      "\titers: 200, epoch: 6 | loss: 0.5023152\n",
      "\tspeed: 0.0521s/iter; left time: 224.4430s\n",
      "\titers: 300, epoch: 6 | loss: 0.4989885\n",
      "\tspeed: 0.0518s/iter; left time: 218.0522s\n",
      "\titers: 400, epoch: 6 | loss: 0.5178986\n",
      "\tspeed: 0.0521s/iter; left time: 214.1746s\n",
      "\titers: 500, epoch: 6 | loss: 0.5457343\n",
      "\tspeed: 0.0521s/iter; left time: 208.9197s\n",
      "\titers: 600, epoch: 6 | loss: 0.5038822\n",
      "\tspeed: 0.0523s/iter; left time: 204.4324s\n",
      "\titers: 700, epoch: 6 | loss: 0.5238547\n",
      "\tspeed: 0.0521s/iter; left time: 198.5567s\n",
      "\titers: 800, epoch: 6 | loss: 0.4924663\n",
      "\tspeed: 0.0520s/iter; left time: 192.9889s\n",
      "\titers: 900, epoch: 6 | loss: 0.5068249\n",
      "\tspeed: 0.0520s/iter; left time: 187.6723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.23s\n",
      "Steps: 902 | Train Loss: 0.5112046 Vali Loss: 0.8424274 Test Loss: 1.0782026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9231351613998413, rmse:0.9607992172241211, mae:0.6902961134910583, rse:0.7611231207847595\n",
      "Original data scale mse:40210260.0, rmse:6341.15625, mae:4216.42529296875, rse:0.3159468472003937\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7215695\n",
      "\tspeed: 0.0676s/iter; left time: 605.6234s\n",
      "\titers: 200, epoch: 1 | loss: 0.6677415\n",
      "\tspeed: 0.0403s/iter; left time: 357.1693s\n",
      "\titers: 300, epoch: 1 | loss: 0.5992011\n",
      "\tspeed: 0.0404s/iter; left time: 354.3081s\n",
      "\titers: 400, epoch: 1 | loss: 0.5512000\n",
      "\tspeed: 0.0404s/iter; left time: 350.1840s\n",
      "\titers: 500, epoch: 1 | loss: 0.5238050\n",
      "\tspeed: 0.0407s/iter; left time: 348.1493s\n",
      "\titers: 600, epoch: 1 | loss: 0.5131288\n",
      "\tspeed: 0.0403s/iter; left time: 341.0431s\n",
      "\titers: 700, epoch: 1 | loss: 0.6015207\n",
      "\tspeed: 0.0404s/iter; left time: 338.0246s\n",
      "\titers: 800, epoch: 1 | loss: 0.5066000\n",
      "\tspeed: 0.0404s/iter; left time: 334.0162s\n",
      "\titers: 900, epoch: 1 | loss: 0.4471631\n",
      "\tspeed: 0.0403s/iter; left time: 328.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.29s\n",
      "Steps: 906 | Train Loss: 0.5917037 Vali Loss: 0.5611537 Test Loss: 0.5962256\n",
      "Validation loss decreased (inf --> 0.561154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3709538\n",
      "\tspeed: 0.0998s/iter; left time: 803.8099s\n",
      "\titers: 200, epoch: 2 | loss: 0.4661245\n",
      "\tspeed: 0.0403s/iter; left time: 320.8957s\n",
      "\titers: 300, epoch: 2 | loss: 0.3768515\n",
      "\tspeed: 0.0414s/iter; left time: 325.4341s\n",
      "\titers: 400, epoch: 2 | loss: 0.4144876\n",
      "\tspeed: 0.0414s/iter; left time: 320.6941s\n",
      "\titers: 500, epoch: 2 | loss: 0.3443320\n",
      "\tspeed: 0.0412s/iter; left time: 315.6911s\n",
      "\titers: 600, epoch: 2 | loss: 0.3588921\n",
      "\tspeed: 0.0416s/iter; left time: 313.9284s\n",
      "\titers: 700, epoch: 2 | loss: 0.3583628\n",
      "\tspeed: 0.0415s/iter; left time: 309.5012s\n",
      "\titers: 800, epoch: 2 | loss: 0.4166490\n",
      "\tspeed: 0.0421s/iter; left time: 309.3772s\n",
      "\titers: 900, epoch: 2 | loss: 0.3890607\n",
      "\tspeed: 0.0417s/iter; left time: 302.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.69s\n",
      "Steps: 906 | Train Loss: 0.4025906 Vali Loss: 0.4453301 Test Loss: 0.4756032\n",
      "Validation loss decreased (0.561154 --> 0.445330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3711495\n",
      "\tspeed: 0.1017s/iter; left time: 726.7510s\n",
      "\titers: 200, epoch: 3 | loss: 0.3322031\n",
      "\tspeed: 0.0404s/iter; left time: 284.6412s\n",
      "\titers: 300, epoch: 3 | loss: 0.3484581\n",
      "\tspeed: 0.0405s/iter; left time: 281.5820s\n",
      "\titers: 400, epoch: 3 | loss: 0.3441037\n",
      "\tspeed: 0.0402s/iter; left time: 275.0127s\n",
      "\titers: 500, epoch: 3 | loss: 0.4129507\n",
      "\tspeed: 0.0404s/iter; left time: 272.6077s\n",
      "\titers: 600, epoch: 3 | loss: 0.3717259\n",
      "\tspeed: 0.0409s/iter; left time: 271.7203s\n",
      "\titers: 700, epoch: 3 | loss: 0.3695573\n",
      "\tspeed: 0.0425s/iter; left time: 278.1878s\n",
      "\titers: 800, epoch: 3 | loss: 0.3394932\n",
      "\tspeed: 0.0404s/iter; left time: 260.8040s\n",
      "\titers: 900, epoch: 3 | loss: 0.3480455\n",
      "\tspeed: 0.0408s/iter; left time: 259.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.24s\n",
      "Steps: 906 | Train Loss: 0.3552150 Vali Loss: 0.4405829 Test Loss: 0.4628681\n",
      "Validation loss decreased (0.445330 --> 0.440583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3240797\n",
      "\tspeed: 0.1041s/iter; left time: 649.8309s\n",
      "\titers: 200, epoch: 4 | loss: 0.3329988\n",
      "\tspeed: 0.0403s/iter; left time: 247.4741s\n",
      "\titers: 300, epoch: 4 | loss: 0.3138479\n",
      "\tspeed: 0.0405s/iter; left time: 244.4778s\n",
      "\titers: 400, epoch: 4 | loss: 0.2903596\n",
      "\tspeed: 0.0405s/iter; left time: 240.5618s\n",
      "\titers: 500, epoch: 4 | loss: 0.3638243\n",
      "\tspeed: 0.0403s/iter; left time: 235.5489s\n",
      "\titers: 600, epoch: 4 | loss: 0.3209779\n",
      "\tspeed: 0.0404s/iter; left time: 232.1537s\n",
      "\titers: 700, epoch: 4 | loss: 0.3025450\n",
      "\tspeed: 0.0404s/iter; left time: 227.8519s\n",
      "\titers: 800, epoch: 4 | loss: 0.3539144\n",
      "\tspeed: 0.0405s/iter; left time: 224.2824s\n",
      "\titers: 900, epoch: 4 | loss: 0.3243295\n",
      "\tspeed: 0.0404s/iter; left time: 220.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.91s\n",
      "Steps: 906 | Train Loss: 0.3304306 Vali Loss: 0.4461254 Test Loss: 0.4630463\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3200391\n",
      "\tspeed: 0.0964s/iter; left time: 514.6072s\n",
      "\titers: 200, epoch: 5 | loss: 0.3002499\n",
      "\tspeed: 0.0403s/iter; left time: 211.1595s\n",
      "\titers: 300, epoch: 5 | loss: 0.2781452\n",
      "\tspeed: 0.0403s/iter; left time: 207.1676s\n",
      "\titers: 400, epoch: 5 | loss: 0.3169612\n",
      "\tspeed: 0.0404s/iter; left time: 203.3963s\n",
      "\titers: 500, epoch: 5 | loss: 0.3001828\n",
      "\tspeed: 0.0402s/iter; left time: 198.4693s\n",
      "\titers: 600, epoch: 5 | loss: 0.3253998\n",
      "\tspeed: 0.0402s/iter; left time: 194.3856s\n",
      "\titers: 700, epoch: 5 | loss: 0.2686165\n",
      "\tspeed: 0.0419s/iter; left time: 198.3927s\n",
      "\titers: 800, epoch: 5 | loss: 0.3044296\n",
      "\tspeed: 0.0419s/iter; left time: 194.1877s\n",
      "\titers: 900, epoch: 5 | loss: 0.3225136\n",
      "\tspeed: 0.0427s/iter; left time: 193.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.35s\n",
      "Steps: 906 | Train Loss: 0.3035686 Vali Loss: 0.4407153 Test Loss: 0.4767428\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2985508\n",
      "\tspeed: 0.0975s/iter; left time: 431.8793s\n",
      "\titers: 200, epoch: 6 | loss: 0.2633336\n",
      "\tspeed: 0.0419s/iter; left time: 181.3550s\n",
      "\titers: 300, epoch: 6 | loss: 0.2996624\n",
      "\tspeed: 0.0356s/iter; left time: 150.6507s\n",
      "\titers: 400, epoch: 6 | loss: 0.2697504\n",
      "\tspeed: 0.0285s/iter; left time: 117.5411s\n",
      "\titers: 500, epoch: 6 | loss: 0.3121417\n",
      "\tspeed: 0.0285s/iter; left time: 114.7979s\n",
      "\titers: 600, epoch: 6 | loss: 0.2498942\n",
      "\tspeed: 0.0414s/iter; left time: 162.7062s\n",
      "\titers: 700, epoch: 6 | loss: 0.2871542\n",
      "\tspeed: 0.0398s/iter; left time: 152.4365s\n",
      "\titers: 800, epoch: 6 | loss: 0.2544069\n",
      "\tspeed: 0.0413s/iter; left time: 154.1128s\n",
      "\titers: 900, epoch: 6 | loss: 0.2554080\n",
      "\tspeed: 0.0418s/iter; left time: 151.7555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.52s\n",
      "Steps: 906 | Train Loss: 0.2803099 Vali Loss: 0.4469062 Test Loss: 0.4820318\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.49489977955818176, rmse:0.7034911513328552, mae:0.4627796411514282, rse:0.5567687749862671\n",
      "Original data scale mse:19648216.0, rmse:4432.630859375, mae:2762.43359375, rse:0.22039934992790222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6933636\n",
      "\tspeed: 0.0429s/iter; left time: 384.4640s\n",
      "\titers: 200, epoch: 1 | loss: 0.6457908\n",
      "\tspeed: 0.0403s/iter; left time: 356.8804s\n",
      "\titers: 300, epoch: 1 | loss: 0.5454914\n",
      "\tspeed: 0.0405s/iter; left time: 354.7308s\n",
      "\titers: 400, epoch: 1 | loss: 0.5511503\n",
      "\tspeed: 0.0403s/iter; left time: 349.2656s\n",
      "\titers: 500, epoch: 1 | loss: 0.5786752\n",
      "\tspeed: 0.0404s/iter; left time: 346.1729s\n",
      "\titers: 600, epoch: 1 | loss: 0.5497690\n",
      "\tspeed: 0.0404s/iter; left time: 341.6487s\n",
      "\titers: 700, epoch: 1 | loss: 0.5148432\n",
      "\tspeed: 0.0404s/iter; left time: 337.7848s\n",
      "\titers: 800, epoch: 1 | loss: 0.5002761\n",
      "\tspeed: 0.0404s/iter; left time: 334.0917s\n",
      "\titers: 900, epoch: 1 | loss: 0.5042391\n",
      "\tspeed: 0.0405s/iter; left time: 330.6473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.92s\n",
      "Steps: 906 | Train Loss: 0.5909449 Vali Loss: 0.5603049 Test Loss: 0.6012501\n",
      "Validation loss decreased (inf --> 0.560305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4975006\n",
      "\tspeed: 0.1002s/iter; left time: 807.2858s\n",
      "\titers: 200, epoch: 2 | loss: 0.4123350\n",
      "\tspeed: 0.0416s/iter; left time: 330.7193s\n",
      "\titers: 300, epoch: 2 | loss: 0.3612792\n",
      "\tspeed: 0.0412s/iter; left time: 323.8013s\n",
      "\titers: 400, epoch: 2 | loss: 0.3984689\n",
      "\tspeed: 0.0402s/iter; left time: 311.8624s\n",
      "\titers: 500, epoch: 2 | loss: 0.3699860\n",
      "\tspeed: 0.0404s/iter; left time: 309.0337s\n",
      "\titers: 600, epoch: 2 | loss: 0.3737260\n",
      "\tspeed: 0.0402s/iter; left time: 303.8557s\n",
      "\titers: 700, epoch: 2 | loss: 0.4142011\n",
      "\tspeed: 0.0406s/iter; left time: 302.4482s\n",
      "\titers: 800, epoch: 2 | loss: 0.3857327\n",
      "\tspeed: 0.0407s/iter; left time: 299.3756s\n",
      "\titers: 900, epoch: 2 | loss: 0.3409123\n",
      "\tspeed: 0.0420s/iter; left time: 304.8924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.4034030 Vali Loss: 0.4392297 Test Loss: 0.4641765\n",
      "Validation loss decreased (0.560305 --> 0.439230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3298930\n",
      "\tspeed: 0.1011s/iter; left time: 723.0670s\n",
      "\titers: 200, epoch: 3 | loss: 0.3437467\n",
      "\tspeed: 0.0403s/iter; left time: 284.2172s\n",
      "\titers: 300, epoch: 3 | loss: 0.4309845\n",
      "\tspeed: 0.0404s/iter; left time: 280.7889s\n",
      "\titers: 400, epoch: 3 | loss: 0.3171408\n",
      "\tspeed: 0.0403s/iter; left time: 276.3169s\n",
      "\titers: 500, epoch: 3 | loss: 0.3937010\n",
      "\tspeed: 0.0402s/iter; left time: 271.4885s\n",
      "\titers: 600, epoch: 3 | loss: 0.3775530\n",
      "\tspeed: 0.0402s/iter; left time: 267.5785s\n",
      "\titers: 700, epoch: 3 | loss: 0.3584513\n",
      "\tspeed: 0.0404s/iter; left time: 264.7731s\n",
      "\titers: 800, epoch: 3 | loss: 0.2602788\n",
      "\tspeed: 0.0405s/iter; left time: 260.8643s\n",
      "\titers: 900, epoch: 3 | loss: 0.2889211\n",
      "\tspeed: 0.0401s/iter; left time: 254.7054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.3539314 Vali Loss: 0.4312690 Test Loss: 0.4557568\n",
      "Validation loss decreased (0.439230 --> 0.431269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3537179\n",
      "\tspeed: 0.0984s/iter; left time: 614.4327s\n",
      "\titers: 200, epoch: 4 | loss: 0.3129574\n",
      "\tspeed: 0.0396s/iter; left time: 243.4234s\n",
      "\titers: 300, epoch: 4 | loss: 0.2914827\n",
      "\tspeed: 0.0404s/iter; left time: 244.4321s\n",
      "\titers: 400, epoch: 4 | loss: 0.3527328\n",
      "\tspeed: 0.0405s/iter; left time: 240.5491s\n",
      "\titers: 500, epoch: 4 | loss: 0.2786991\n",
      "\tspeed: 0.0405s/iter; left time: 236.4983s\n",
      "\titers: 600, epoch: 4 | loss: 0.3483981\n",
      "\tspeed: 0.0404s/iter; left time: 232.0143s\n",
      "\titers: 700, epoch: 4 | loss: 0.3014231\n",
      "\tspeed: 0.0403s/iter; left time: 227.4200s\n",
      "\titers: 800, epoch: 4 | loss: 0.3250557\n",
      "\tspeed: 0.0404s/iter; left time: 224.1115s\n",
      "\titers: 900, epoch: 4 | loss: 0.3409735\n",
      "\tspeed: 0.0406s/iter; left time: 221.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3276601 Vali Loss: 0.4329171 Test Loss: 0.4587655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2832368\n",
      "\tspeed: 0.0956s/iter; left time: 510.4611s\n",
      "\titers: 200, epoch: 5 | loss: 0.3461204\n",
      "\tspeed: 0.0404s/iter; left time: 211.7525s\n",
      "\titers: 300, epoch: 5 | loss: 0.3221009\n",
      "\tspeed: 0.0406s/iter; left time: 208.6126s\n",
      "\titers: 400, epoch: 5 | loss: 0.3311023\n",
      "\tspeed: 0.0403s/iter; left time: 203.1041s\n",
      "\titers: 500, epoch: 5 | loss: 0.2930217\n",
      "\tspeed: 0.0405s/iter; left time: 199.9273s\n",
      "\titers: 600, epoch: 5 | loss: 0.2887761\n",
      "\tspeed: 0.0404s/iter; left time: 195.6071s\n",
      "\titers: 700, epoch: 5 | loss: 0.3053557\n",
      "\tspeed: 0.0405s/iter; left time: 191.6294s\n",
      "\titers: 800, epoch: 5 | loss: 0.2880615\n",
      "\tspeed: 0.0404s/iter; left time: 187.4509s\n",
      "\titers: 900, epoch: 5 | loss: 0.3189270\n",
      "\tspeed: 0.0405s/iter; left time: 183.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.95s\n",
      "Steps: 906 | Train Loss: 0.3014971 Vali Loss: 0.4485994 Test Loss: 0.4587874\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3184680\n",
      "\tspeed: 0.0970s/iter; left time: 429.6966s\n",
      "\titers: 200, epoch: 6 | loss: 0.2596821\n",
      "\tspeed: 0.0405s/iter; left time: 175.2120s\n",
      "\titers: 300, epoch: 6 | loss: 0.2904953\n",
      "\tspeed: 0.0405s/iter; left time: 171.1642s\n",
      "\titers: 400, epoch: 6 | loss: 0.3148658\n",
      "\tspeed: 0.0405s/iter; left time: 167.2058s\n",
      "\titers: 500, epoch: 6 | loss: 0.3033264\n",
      "\tspeed: 0.0403s/iter; left time: 162.5886s\n",
      "\titers: 600, epoch: 6 | loss: 0.3050017\n",
      "\tspeed: 0.0405s/iter; left time: 159.3655s\n",
      "\titers: 700, epoch: 6 | loss: 0.2470572\n",
      "\tspeed: 0.0404s/iter; left time: 154.8099s\n",
      "\titers: 800, epoch: 6 | loss: 0.2386658\n",
      "\tspeed: 0.0405s/iter; left time: 151.0734s\n",
      "\titers: 900, epoch: 6 | loss: 0.2651795\n",
      "\tspeed: 0.0402s/iter; left time: 146.0021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.91s\n",
      "Steps: 906 | Train Loss: 0.2773427 Vali Loss: 0.4407897 Test Loss: 0.4618565\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.49027326703071594, rmse:0.7001951932907104, mae:0.45565664768218994, rse:0.5541602373123169\n",
      "Original data scale mse:19207616.0, rmse:4382.6494140625, mae:2741.959716796875, rse:0.2179141640663147\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8046664\n",
      "\tspeed: 0.0724s/iter; left time: 647.0906s\n",
      "\titers: 200, epoch: 1 | loss: 0.7705905\n",
      "\tspeed: 0.0457s/iter; left time: 404.1486s\n",
      "\titers: 300, epoch: 1 | loss: 0.7503831\n",
      "\tspeed: 0.0457s/iter; left time: 399.8191s\n",
      "\titers: 400, epoch: 1 | loss: 0.7038482\n",
      "\tspeed: 0.0458s/iter; left time: 396.1757s\n",
      "\titers: 500, epoch: 1 | loss: 0.6970635\n",
      "\tspeed: 0.0459s/iter; left time: 391.6310s\n",
      "\titers: 600, epoch: 1 | loss: 0.6281009\n",
      "\tspeed: 0.0455s/iter; left time: 384.3609s\n",
      "\titers: 700, epoch: 1 | loss: 0.6151747\n",
      "\tspeed: 0.0460s/iter; left time: 383.4296s\n",
      "\titers: 800, epoch: 1 | loss: 0.6306651\n",
      "\tspeed: 0.0459s/iter; left time: 377.9225s\n",
      "\titers: 900, epoch: 1 | loss: 0.6298555\n",
      "\tspeed: 0.0459s/iter; left time: 373.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 904 | Train Loss: 0.7062457 Vali Loss: 0.7044919 Test Loss: 0.7897239\n",
      "Validation loss decreased (inf --> 0.704492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5724813\n",
      "\tspeed: 0.1154s/iter; left time: 927.8498s\n",
      "\titers: 200, epoch: 2 | loss: 0.5583884\n",
      "\tspeed: 0.0458s/iter; left time: 363.6226s\n",
      "\titers: 300, epoch: 2 | loss: 0.5384585\n",
      "\tspeed: 0.0458s/iter; left time: 358.8274s\n",
      "\titers: 400, epoch: 2 | loss: 0.5218018\n",
      "\tspeed: 0.0459s/iter; left time: 355.4223s\n",
      "\titers: 500, epoch: 2 | loss: 0.4906337\n",
      "\tspeed: 0.0457s/iter; left time: 349.3348s\n",
      "\titers: 600, epoch: 2 | loss: 0.5179666\n",
      "\tspeed: 0.0458s/iter; left time: 344.9001s\n",
      "\titers: 700, epoch: 2 | loss: 0.4819083\n",
      "\tspeed: 0.0458s/iter; left time: 340.8807s\n",
      "\titers: 800, epoch: 2 | loss: 0.5324076\n",
      "\tspeed: 0.0459s/iter; left time: 336.6639s\n",
      "\titers: 900, epoch: 2 | loss: 0.4802623\n",
      "\tspeed: 0.0458s/iter; left time: 331.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.68s\n",
      "Steps: 904 | Train Loss: 0.5296305 Vali Loss: 0.5895641 Test Loss: 0.6527810\n",
      "Validation loss decreased (0.704492 --> 0.589564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5235303\n",
      "\tspeed: 0.1110s/iter; left time: 791.5479s\n",
      "\titers: 200, epoch: 3 | loss: 0.4529510\n",
      "\tspeed: 0.0354s/iter; left time: 248.6696s\n",
      "\titers: 300, epoch: 3 | loss: 0.4261545\n",
      "\tspeed: 0.0354s/iter; left time: 245.0847s\n",
      "\titers: 400, epoch: 3 | loss: 0.4284749\n",
      "\tspeed: 0.0355s/iter; left time: 242.4088s\n",
      "\titers: 500, epoch: 3 | loss: 0.4677834\n",
      "\tspeed: 0.0354s/iter; left time: 238.3191s\n",
      "\titers: 600, epoch: 3 | loss: 0.4825233\n",
      "\tspeed: 0.0354s/iter; left time: 234.6645s\n",
      "\titers: 700, epoch: 3 | loss: 0.4077120\n",
      "\tspeed: 0.0354s/iter; left time: 231.4083s\n",
      "\titers: 800, epoch: 3 | loss: 0.4685313\n",
      "\tspeed: 0.0356s/iter; left time: 228.7521s\n",
      "\titers: 900, epoch: 3 | loss: 0.4599987\n",
      "\tspeed: 0.0354s/iter; left time: 224.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 904 | Train Loss: 0.4619799 Vali Loss: 0.5771369 Test Loss: 0.6438022\n",
      "Validation loss decreased (0.589564 --> 0.577137).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4089474\n",
      "\tspeed: 0.1143s/iter; left time: 711.7381s\n",
      "\titers: 200, epoch: 4 | loss: 0.4214315\n",
      "\tspeed: 0.0454s/iter; left time: 278.4686s\n",
      "\titers: 300, epoch: 4 | loss: 0.4180072\n",
      "\tspeed: 0.0445s/iter; left time: 268.2094s\n",
      "\titers: 400, epoch: 4 | loss: 0.3611583\n",
      "\tspeed: 0.0457s/iter; left time: 270.9289s\n",
      "\titers: 500, epoch: 4 | loss: 0.4712610\n",
      "\tspeed: 0.0449s/iter; left time: 261.5814s\n",
      "\titers: 600, epoch: 4 | loss: 0.3901211\n",
      "\tspeed: 0.0459s/iter; left time: 262.8894s\n",
      "\titers: 700, epoch: 4 | loss: 0.4416049\n",
      "\tspeed: 0.0457s/iter; left time: 256.9995s\n",
      "\titers: 800, epoch: 4 | loss: 0.4008536\n",
      "\tspeed: 0.0459s/iter; left time: 253.6396s\n",
      "\titers: 900, epoch: 4 | loss: 0.4347542\n",
      "\tspeed: 0.0439s/iter; left time: 238.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.14s\n",
      "Steps: 904 | Train Loss: 0.4246630 Vali Loss: 0.5828032 Test Loss: 0.6657495\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3883911\n",
      "\tspeed: 0.1116s/iter; left time: 594.3719s\n",
      "\titers: 200, epoch: 5 | loss: 0.4428380\n",
      "\tspeed: 0.0461s/iter; left time: 241.1116s\n",
      "\titers: 300, epoch: 5 | loss: 0.4127674\n",
      "\tspeed: 0.0454s/iter; left time: 232.7100s\n",
      "\titers: 400, epoch: 5 | loss: 0.3990879\n",
      "\tspeed: 0.0456s/iter; left time: 228.9784s\n",
      "\titers: 500, epoch: 5 | loss: 0.3641529\n",
      "\tspeed: 0.0459s/iter; left time: 226.0345s\n",
      "\titers: 600, epoch: 5 | loss: 0.3592767\n",
      "\tspeed: 0.0459s/iter; left time: 221.2863s\n",
      "\titers: 700, epoch: 5 | loss: 0.3591104\n",
      "\tspeed: 0.0461s/iter; left time: 217.8790s\n",
      "\titers: 800, epoch: 5 | loss: 0.3547353\n",
      "\tspeed: 0.0460s/iter; left time: 212.9269s\n",
      "\titers: 900, epoch: 5 | loss: 0.3660108\n",
      "\tspeed: 0.0459s/iter; left time: 207.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.73s\n",
      "Steps: 904 | Train Loss: 0.3870160 Vali Loss: 0.5739987 Test Loss: 0.6677375\n",
      "Validation loss decreased (0.577137 --> 0.573999).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3589998\n",
      "\tspeed: 0.1151s/iter; left time: 508.6784s\n",
      "\titers: 200, epoch: 6 | loss: 0.3397861\n",
      "\tspeed: 0.0461s/iter; left time: 199.2801s\n",
      "\titers: 300, epoch: 6 | loss: 0.3761511\n",
      "\tspeed: 0.0461s/iter; left time: 194.7237s\n",
      "\titers: 400, epoch: 6 | loss: 0.3682893\n",
      "\tspeed: 0.0459s/iter; left time: 189.0696s\n",
      "\titers: 500, epoch: 6 | loss: 0.3682757\n",
      "\tspeed: 0.0458s/iter; left time: 184.2603s\n",
      "\titers: 600, epoch: 6 | loss: 0.3621927\n",
      "\tspeed: 0.0458s/iter; left time: 179.5531s\n",
      "\titers: 700, epoch: 6 | loss: 0.3596643\n",
      "\tspeed: 0.0458s/iter; left time: 174.8186s\n",
      "\titers: 800, epoch: 6 | loss: 0.3902473\n",
      "\tspeed: 0.0457s/iter; left time: 169.9050s\n",
      "\titers: 900, epoch: 6 | loss: 0.3462842\n",
      "\tspeed: 0.0459s/iter; left time: 166.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 904 | Train Loss: 0.3578898 Vali Loss: 0.5850427 Test Loss: 0.6497733\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3130277\n",
      "\tspeed: 0.1132s/iter; left time: 398.0754s\n",
      "\titers: 200, epoch: 7 | loss: 0.3050972\n",
      "\tspeed: 0.0461s/iter; left time: 157.6356s\n",
      "\titers: 300, epoch: 7 | loss: 0.3185982\n",
      "\tspeed: 0.0450s/iter; left time: 149.1561s\n",
      "\titers: 400, epoch: 7 | loss: 0.3193868\n",
      "\tspeed: 0.0423s/iter; left time: 135.9714s\n",
      "\titers: 500, epoch: 7 | loss: 0.3336236\n",
      "\tspeed: 0.0476s/iter; left time: 148.3270s\n",
      "\titers: 600, epoch: 7 | loss: 0.3138655\n",
      "\tspeed: 0.0461s/iter; left time: 139.0312s\n",
      "\titers: 700, epoch: 7 | loss: 0.3336879\n",
      "\tspeed: 0.0470s/iter; left time: 137.2171s\n",
      "\titers: 800, epoch: 7 | loss: 0.3205555\n",
      "\tspeed: 0.0457s/iter; left time: 128.7554s\n",
      "\titers: 900, epoch: 7 | loss: 0.3355069\n",
      "\tspeed: 0.0458s/iter; left time: 124.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.67s\n",
      "Steps: 904 | Train Loss: 0.3297362 Vali Loss: 0.5939113 Test Loss: 0.6703900\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3147684\n",
      "\tspeed: 0.1118s/iter; left time: 292.0150s\n",
      "\titers: 200, epoch: 8 | loss: 0.3183024\n",
      "\tspeed: 0.0460s/iter; left time: 115.4913s\n",
      "\titers: 300, epoch: 8 | loss: 0.3203939\n",
      "\tspeed: 0.0452s/iter; left time: 108.9698s\n",
      "\titers: 400, epoch: 8 | loss: 0.2972348\n",
      "\tspeed: 0.0459s/iter; left time: 106.1980s\n",
      "\titers: 500, epoch: 8 | loss: 0.3417727\n",
      "\tspeed: 0.0457s/iter; left time: 101.2255s\n",
      "\titers: 600, epoch: 8 | loss: 0.3158745\n",
      "\tspeed: 0.0458s/iter; left time: 96.8003s\n",
      "\titers: 700, epoch: 8 | loss: 0.3234260\n",
      "\tspeed: 0.0461s/iter; left time: 92.8591s\n",
      "\titers: 800, epoch: 8 | loss: 0.3083707\n",
      "\tspeed: 0.0458s/iter; left time: 87.6825s\n",
      "\titers: 900, epoch: 8 | loss: 0.3016308\n",
      "\tspeed: 0.0458s/iter; left time: 83.0175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.64s\n",
      "Steps: 904 | Train Loss: 0.3082505 Vali Loss: 0.5874403 Test Loss: 0.6553872\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9519941806793213, rmse:0.9757018685340881, mae:0.6666859984397888, rse:0.7738518118858337\n",
      "Original data scale mse:41247308.0, rmse:6422.40673828125, mae:4063.66357421875, rse:0.31983813643455505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8010994\n",
      "\tspeed: 0.0477s/iter; left time: 426.1691s\n",
      "\titers: 200, epoch: 1 | loss: 0.7328934\n",
      "\tspeed: 0.0455s/iter; left time: 402.6452s\n",
      "\titers: 300, epoch: 1 | loss: 0.6795613\n",
      "\tspeed: 0.0457s/iter; left time: 399.6043s\n",
      "\titers: 400, epoch: 1 | loss: 0.6432170\n",
      "\tspeed: 0.0457s/iter; left time: 394.9619s\n",
      "\titers: 500, epoch: 1 | loss: 0.6418213\n",
      "\tspeed: 0.0447s/iter; left time: 381.7209s\n",
      "\titers: 600, epoch: 1 | loss: 0.6962131\n",
      "\tspeed: 0.0459s/iter; left time: 387.0834s\n",
      "\titers: 700, epoch: 1 | loss: 0.6652902\n",
      "\tspeed: 0.0455s/iter; left time: 379.7670s\n",
      "\titers: 800, epoch: 1 | loss: 0.6485575\n",
      "\tspeed: 0.0461s/iter; left time: 379.7909s\n",
      "\titers: 900, epoch: 1 | loss: 0.6165783\n",
      "\tspeed: 0.0458s/iter; left time: 373.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.51s\n",
      "Steps: 904 | Train Loss: 0.7043722 Vali Loss: 0.7044099 Test Loss: 0.7934921\n",
      "Validation loss decreased (inf --> 0.704410).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5258688\n",
      "\tspeed: 0.1161s/iter; left time: 933.3058s\n",
      "\titers: 200, epoch: 2 | loss: 0.5637795\n",
      "\tspeed: 0.0460s/iter; left time: 364.8862s\n",
      "\titers: 300, epoch: 2 | loss: 0.4972985\n",
      "\tspeed: 0.0458s/iter; left time: 359.2056s\n",
      "\titers: 400, epoch: 2 | loss: 0.5150353\n",
      "\tspeed: 0.0459s/iter; left time: 355.4718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4983087\n",
      "\tspeed: 0.0458s/iter; left time: 349.9889s\n",
      "\titers: 600, epoch: 2 | loss: 0.5076133\n",
      "\tspeed: 0.0459s/iter; left time: 345.9691s\n",
      "\titers: 700, epoch: 2 | loss: 0.5290806\n",
      "\tspeed: 0.0455s/iter; left time: 338.6768s\n",
      "\titers: 800, epoch: 2 | loss: 0.4902735\n",
      "\tspeed: 0.0457s/iter; left time: 335.0613s\n",
      "\titers: 900, epoch: 2 | loss: 0.4747526\n",
      "\tspeed: 0.0454s/iter; left time: 328.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.64s\n",
      "Steps: 904 | Train Loss: 0.5341266 Vali Loss: 0.6049233 Test Loss: 0.6428112\n",
      "Validation loss decreased (0.704410 --> 0.604923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4757680\n",
      "\tspeed: 0.1175s/iter; left time: 837.9578s\n",
      "\titers: 200, epoch: 3 | loss: 0.5231443\n",
      "\tspeed: 0.0461s/iter; left time: 324.1669s\n",
      "\titers: 300, epoch: 3 | loss: 0.4881614\n",
      "\tspeed: 0.0458s/iter; left time: 317.6889s\n",
      "\titers: 400, epoch: 3 | loss: 0.4571269\n",
      "\tspeed: 0.0461s/iter; left time: 314.8910s\n",
      "\titers: 500, epoch: 3 | loss: 0.4369162\n",
      "\tspeed: 0.0459s/iter; left time: 309.1930s\n",
      "\titers: 600, epoch: 3 | loss: 0.4874011\n",
      "\tspeed: 0.0461s/iter; left time: 306.0271s\n",
      "\titers: 700, epoch: 3 | loss: 0.4290618\n",
      "\tspeed: 0.0459s/iter; left time: 300.1230s\n",
      "\titers: 800, epoch: 3 | loss: 0.4576441\n",
      "\tspeed: 0.0458s/iter; left time: 294.5411s\n",
      "\titers: 900, epoch: 3 | loss: 0.4671273\n",
      "\tspeed: 0.0458s/iter; left time: 290.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.81s\n",
      "Steps: 904 | Train Loss: 0.4611585 Vali Loss: 0.6028454 Test Loss: 0.6184371\n",
      "Validation loss decreased (0.604923 --> 0.602845).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3998677\n",
      "\tspeed: 0.1148s/iter; left time: 715.1837s\n",
      "\titers: 200, epoch: 4 | loss: 0.4132229\n",
      "\tspeed: 0.0461s/iter; left time: 282.7738s\n",
      "\titers: 300, epoch: 4 | loss: 0.4334919\n",
      "\tspeed: 0.0457s/iter; left time: 275.8183s\n",
      "\titers: 400, epoch: 4 | loss: 0.4044308\n",
      "\tspeed: 0.0457s/iter; left time: 270.9796s\n",
      "\titers: 500, epoch: 4 | loss: 0.4421014\n",
      "\tspeed: 0.0456s/iter; left time: 265.8166s\n",
      "\titers: 600, epoch: 4 | loss: 0.3875317\n",
      "\tspeed: 0.0456s/iter; left time: 261.1960s\n",
      "\titers: 700, epoch: 4 | loss: 0.4230910\n",
      "\tspeed: 0.0460s/iter; left time: 258.8495s\n",
      "\titers: 800, epoch: 4 | loss: 0.3707693\n",
      "\tspeed: 0.0463s/iter; left time: 255.8662s\n",
      "\titers: 900, epoch: 4 | loss: 0.3769258\n",
      "\tspeed: 0.0459s/iter; left time: 249.1135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.62s\n",
      "Steps: 904 | Train Loss: 0.4218997 Vali Loss: 0.5859396 Test Loss: 0.6591363\n",
      "Validation loss decreased (0.602845 --> 0.585940).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3925479\n",
      "\tspeed: 0.1153s/iter; left time: 613.7240s\n",
      "\titers: 200, epoch: 5 | loss: 0.4102021\n",
      "\tspeed: 0.0457s/iter; left time: 238.5659s\n",
      "\titers: 300, epoch: 5 | loss: 0.3620060\n",
      "\tspeed: 0.0458s/iter; left time: 234.5876s\n",
      "\titers: 400, epoch: 5 | loss: 0.3668549\n",
      "\tspeed: 0.0461s/iter; left time: 231.8310s\n",
      "\titers: 500, epoch: 5 | loss: 0.3692132\n",
      "\tspeed: 0.0455s/iter; left time: 224.2338s\n",
      "\titers: 600, epoch: 5 | loss: 0.4087869\n",
      "\tspeed: 0.0459s/iter; left time: 221.3830s\n",
      "\titers: 700, epoch: 5 | loss: 0.4011775\n",
      "\tspeed: 0.0453s/iter; left time: 213.9217s\n",
      "\titers: 800, epoch: 5 | loss: 0.3626934\n",
      "\tspeed: 0.0453s/iter; left time: 209.4461s\n",
      "\titers: 900, epoch: 5 | loss: 0.3683335\n",
      "\tspeed: 0.0457s/iter; left time: 206.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.52s\n",
      "Steps: 904 | Train Loss: 0.3884230 Vali Loss: 0.5717269 Test Loss: 0.6363498\n",
      "Validation loss decreased (0.585940 --> 0.571727).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3924609\n",
      "\tspeed: 0.1149s/iter; left time: 507.9962s\n",
      "\titers: 200, epoch: 6 | loss: 0.3637329\n",
      "\tspeed: 0.0453s/iter; left time: 195.7473s\n",
      "\titers: 300, epoch: 6 | loss: 0.3533712\n",
      "\tspeed: 0.0459s/iter; left time: 193.7855s\n",
      "\titers: 400, epoch: 6 | loss: 0.3886940\n",
      "\tspeed: 0.0461s/iter; left time: 189.7898s\n",
      "\titers: 500, epoch: 6 | loss: 0.3682318\n",
      "\tspeed: 0.0457s/iter; left time: 183.7717s\n",
      "\titers: 600, epoch: 6 | loss: 0.3522940\n",
      "\tspeed: 0.0459s/iter; left time: 179.9156s\n",
      "\titers: 700, epoch: 6 | loss: 0.3701428\n",
      "\tspeed: 0.0457s/iter; left time: 174.6223s\n",
      "\titers: 800, epoch: 6 | loss: 0.3493035\n",
      "\tspeed: 0.0457s/iter; left time: 170.0025s\n",
      "\titers: 900, epoch: 6 | loss: 0.3459255\n",
      "\tspeed: 0.0456s/iter; left time: 165.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.58s\n",
      "Steps: 904 | Train Loss: 0.3607185 Vali Loss: 0.5945458 Test Loss: 0.6467904\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3271553\n",
      "\tspeed: 0.1123s/iter; left time: 394.9102s\n",
      "\titers: 200, epoch: 7 | loss: 0.3415232\n",
      "\tspeed: 0.0483s/iter; left time: 165.0600s\n",
      "\titers: 300, epoch: 7 | loss: 0.3429954\n",
      "\tspeed: 0.0365s/iter; left time: 121.1208s\n",
      "\titers: 400, epoch: 7 | loss: 0.3336126\n",
      "\tspeed: 0.0354s/iter; left time: 113.9251s\n",
      "\titers: 500, epoch: 7 | loss: 0.3125392\n",
      "\tspeed: 0.0355s/iter; left time: 110.6653s\n",
      "\titers: 600, epoch: 7 | loss: 0.3629393\n",
      "\tspeed: 0.0355s/iter; left time: 106.9565s\n",
      "\titers: 700, epoch: 7 | loss: 0.3249076\n",
      "\tspeed: 0.0354s/iter; left time: 103.3208s\n",
      "\titers: 800, epoch: 7 | loss: 0.3575486\n",
      "\tspeed: 0.0354s/iter; left time: 99.7238s\n",
      "\titers: 900, epoch: 7 | loss: 0.3155114\n",
      "\tspeed: 0.0356s/iter; left time: 96.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.80s\n",
      "Steps: 904 | Train Loss: 0.3354452 Vali Loss: 0.5961151 Test Loss: 0.6505117\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3284198\n",
      "\tspeed: 0.1122s/iter; left time: 293.1909s\n",
      "\titers: 200, epoch: 8 | loss: 0.2889812\n",
      "\tspeed: 0.0462s/iter; left time: 116.0487s\n",
      "\titers: 300, epoch: 8 | loss: 0.3065237\n",
      "\tspeed: 0.0462s/iter; left time: 111.4147s\n",
      "\titers: 400, epoch: 8 | loss: 0.3156983\n",
      "\tspeed: 0.0464s/iter; left time: 107.3252s\n",
      "\titers: 500, epoch: 8 | loss: 0.3216363\n",
      "\tspeed: 0.0462s/iter; left time: 102.2223s\n",
      "\titers: 600, epoch: 8 | loss: 0.2931251\n",
      "\tspeed: 0.0459s/iter; left time: 96.9334s\n",
      "\titers: 700, epoch: 8 | loss: 0.3140359\n",
      "\tspeed: 0.0459s/iter; left time: 92.4110s\n",
      "\titers: 800, epoch: 8 | loss: 0.3071438\n",
      "\tspeed: 0.0459s/iter; left time: 87.7276s\n",
      "\titers: 900, epoch: 8 | loss: 0.3071236\n",
      "\tspeed: 0.0458s/iter; left time: 82.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 904 | Train Loss: 0.3142988 Vali Loss: 0.5842171 Test Loss: 0.6662861\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8675479292869568, rmse:0.9314225316047668, mae:0.6356421113014221, rse:0.7387328743934631\n",
      "Original data scale mse:37667352.0, rmse:6137.37353515625, mae:3862.161865234375, rse:0.3056434094905853\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7432280\n",
      "\tspeed: 0.0807s/iter; left time: 719.8680s\n",
      "\titers: 200, epoch: 1 | loss: 0.7924978\n",
      "\tspeed: 0.0537s/iter; left time: 473.3559s\n",
      "\titers: 300, epoch: 1 | loss: 0.7319275\n",
      "\tspeed: 0.0536s/iter; left time: 467.3100s\n",
      "\titers: 400, epoch: 1 | loss: 0.7333213\n",
      "\tspeed: 0.0523s/iter; left time: 451.1451s\n",
      "\titers: 500, epoch: 1 | loss: 0.7180915\n",
      "\tspeed: 0.0519s/iter; left time: 442.4606s\n",
      "\titers: 600, epoch: 1 | loss: 0.7430111\n",
      "\tspeed: 0.0518s/iter; left time: 436.2132s\n",
      "\titers: 700, epoch: 1 | loss: 0.7065840\n",
      "\tspeed: 0.0520s/iter; left time: 432.7969s\n",
      "\titers: 800, epoch: 1 | loss: 0.6746759\n",
      "\tspeed: 0.0523s/iter; left time: 429.5860s\n",
      "\titers: 900, epoch: 1 | loss: 0.7036165\n",
      "\tspeed: 0.0520s/iter; left time: 422.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.09s\n",
      "Steps: 902 | Train Loss: 0.7345527 Vali Loss: 0.7737989 Test Loss: 0.8803952\n",
      "Validation loss decreased (inf --> 0.773799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6868786\n",
      "\tspeed: 0.1342s/iter; left time: 1075.7972s\n",
      "\titers: 200, epoch: 2 | loss: 0.6350537\n",
      "\tspeed: 0.0522s/iter; left time: 413.4198s\n",
      "\titers: 300, epoch: 2 | loss: 0.6338754\n",
      "\tspeed: 0.0516s/iter; left time: 403.4469s\n",
      "\titers: 400, epoch: 2 | loss: 0.5741463\n",
      "\tspeed: 0.0517s/iter; left time: 398.8507s\n",
      "\titers: 500, epoch: 2 | loss: 0.5673126\n",
      "\tspeed: 0.0514s/iter; left time: 391.7749s\n",
      "\titers: 600, epoch: 2 | loss: 0.5258488\n",
      "\tspeed: 0.0516s/iter; left time: 388.2298s\n",
      "\titers: 700, epoch: 2 | loss: 0.5364168\n",
      "\tspeed: 0.0517s/iter; left time: 383.9168s\n",
      "\titers: 800, epoch: 2 | loss: 0.5658613\n",
      "\tspeed: 0.0514s/iter; left time: 376.3875s\n",
      "\titers: 900, epoch: 2 | loss: 0.4998148\n",
      "\tspeed: 0.0514s/iter; left time: 370.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 902 | Train Loss: 0.5770481 Vali Loss: 0.6151103 Test Loss: 0.6770754\n",
      "Validation loss decreased (0.773799 --> 0.615110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5180974\n",
      "\tspeed: 0.1333s/iter; left time: 949.0086s\n",
      "\titers: 200, epoch: 3 | loss: 0.4734910\n",
      "\tspeed: 0.0516s/iter; left time: 361.8154s\n",
      "\titers: 300, epoch: 3 | loss: 0.4999493\n",
      "\tspeed: 0.0518s/iter; left time: 358.1624s\n",
      "\titers: 400, epoch: 3 | loss: 0.5183615\n",
      "\tspeed: 0.0511s/iter; left time: 348.1803s\n",
      "\titers: 500, epoch: 3 | loss: 0.4752620\n",
      "\tspeed: 0.0426s/iter; left time: 286.2387s\n",
      "\titers: 600, epoch: 3 | loss: 0.4819514\n",
      "\tspeed: 0.0515s/iter; left time: 340.5576s\n",
      "\titers: 700, epoch: 3 | loss: 0.5015286\n",
      "\tspeed: 0.0524s/iter; left time: 341.5130s\n",
      "\titers: 800, epoch: 3 | loss: 0.4726277\n",
      "\tspeed: 0.0519s/iter; left time: 333.1788s\n",
      "\titers: 900, epoch: 3 | loss: 0.4481099\n",
      "\tspeed: 0.0521s/iter; left time: 329.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.4826820 Vali Loss: 0.6081653 Test Loss: 0.6789765\n",
      "Validation loss decreased (0.615110 --> 0.608165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4161480\n",
      "\tspeed: 0.1344s/iter; left time: 835.2701s\n",
      "\titers: 200, epoch: 4 | loss: 0.4256495\n",
      "\tspeed: 0.0519s/iter; left time: 317.5265s\n",
      "\titers: 300, epoch: 4 | loss: 0.4600742\n",
      "\tspeed: 0.0520s/iter; left time: 312.4819s\n",
      "\titers: 400, epoch: 4 | loss: 0.4594116\n",
      "\tspeed: 0.0516s/iter; left time: 305.1571s\n",
      "\titers: 500, epoch: 4 | loss: 0.4682472\n",
      "\tspeed: 0.0518s/iter; left time: 301.3343s\n",
      "\titers: 600, epoch: 4 | loss: 0.4279153\n",
      "\tspeed: 0.0517s/iter; left time: 295.3216s\n",
      "\titers: 700, epoch: 4 | loss: 0.4593164\n",
      "\tspeed: 0.0516s/iter; left time: 289.9734s\n",
      "\titers: 800, epoch: 4 | loss: 0.4496114\n",
      "\tspeed: 0.0521s/iter; left time: 287.3274s\n",
      "\titers: 900, epoch: 4 | loss: 0.4105683\n",
      "\tspeed: 0.0517s/iter; left time: 279.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.08s\n",
      "Steps: 902 | Train Loss: 0.4414160 Vali Loss: 0.6163542 Test Loss: 0.6771622\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4379938\n",
      "\tspeed: 0.1297s/iter; left time: 689.1495s\n",
      "\titers: 200, epoch: 5 | loss: 0.4133421\n",
      "\tspeed: 0.0525s/iter; left time: 273.4757s\n",
      "\titers: 300, epoch: 5 | loss: 0.4182612\n",
      "\tspeed: 0.0522s/iter; left time: 266.8148s\n",
      "\titers: 400, epoch: 5 | loss: 0.4328923\n",
      "\tspeed: 0.0520s/iter; left time: 260.7970s\n",
      "\titers: 500, epoch: 5 | loss: 0.3644622\n",
      "\tspeed: 0.0518s/iter; left time: 254.5846s\n",
      "\titers: 600, epoch: 5 | loss: 0.4028292\n",
      "\tspeed: 0.0517s/iter; left time: 248.8532s\n",
      "\titers: 700, epoch: 5 | loss: 0.4268283\n",
      "\tspeed: 0.0518s/iter; left time: 244.0483s\n",
      "\titers: 800, epoch: 5 | loss: 0.3848646\n",
      "\tspeed: 0.0520s/iter; left time: 239.9750s\n",
      "\titers: 900, epoch: 5 | loss: 0.3503802\n",
      "\tspeed: 0.0516s/iter; left time: 232.6932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.11s\n",
      "Steps: 902 | Train Loss: 0.4047783 Vali Loss: 0.6162719 Test Loss: 0.7085742\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3884669\n",
      "\tspeed: 0.1305s/iter; left time: 575.4842s\n",
      "\titers: 200, epoch: 6 | loss: 0.3919015\n",
      "\tspeed: 0.0521s/iter; left time: 224.6280s\n",
      "\titers: 300, epoch: 6 | loss: 0.3709927\n",
      "\tspeed: 0.0523s/iter; left time: 220.4367s\n",
      "\titers: 400, epoch: 6 | loss: 0.4029219\n",
      "\tspeed: 0.0521s/iter; left time: 214.2599s\n",
      "\titers: 500, epoch: 6 | loss: 0.3664319\n",
      "\tspeed: 0.0522s/iter; left time: 209.3621s\n",
      "\titers: 600, epoch: 6 | loss: 0.3598861\n",
      "\tspeed: 0.0518s/iter; left time: 202.7663s\n",
      "\titers: 700, epoch: 6 | loss: 0.3954958\n",
      "\tspeed: 0.0520s/iter; left time: 198.1453s\n",
      "\titers: 800, epoch: 6 | loss: 0.3583177\n",
      "\tspeed: 0.0514s/iter; left time: 190.6933s\n",
      "\titers: 900, epoch: 6 | loss: 0.3972457\n",
      "\tspeed: 0.0518s/iter; left time: 187.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.3720988 Vali Loss: 0.6230050 Test Loss: 0.7020154\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9181895852088928, rmse:0.9582220911979675, mae:0.6792442202568054, rse:0.7590816020965576\n",
      "Original data scale mse:39692484.0, rmse:6300.197265625, mae:4161.8623046875, rse:0.31390610337257385\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8304041\n",
      "\tspeed: 0.0544s/iter; left time: 485.0321s\n",
      "\titers: 200, epoch: 1 | loss: 0.7432838\n",
      "\tspeed: 0.0519s/iter; left time: 457.4525s\n",
      "\titers: 300, epoch: 1 | loss: 0.7456986\n",
      "\tspeed: 0.0520s/iter; left time: 453.1677s\n",
      "\titers: 400, epoch: 1 | loss: 0.6537443\n",
      "\tspeed: 0.0519s/iter; left time: 447.2635s\n",
      "\titers: 500, epoch: 1 | loss: 0.7623785\n",
      "\tspeed: 0.0518s/iter; left time: 441.0954s\n",
      "\titers: 600, epoch: 1 | loss: 0.6968405\n",
      "\tspeed: 0.0517s/iter; left time: 435.0291s\n",
      "\titers: 700, epoch: 1 | loss: 0.6879818\n",
      "\tspeed: 0.0513s/iter; left time: 426.7210s\n",
      "\titers: 800, epoch: 1 | loss: 0.6725203\n",
      "\tspeed: 0.0470s/iter; left time: 386.5256s\n",
      "\titers: 900, epoch: 1 | loss: 0.6846584\n",
      "\tspeed: 0.0431s/iter; left time: 349.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.65s\n",
      "Steps: 902 | Train Loss: 0.7359149 Vali Loss: 0.7748347 Test Loss: 0.8825503\n",
      "Validation loss decreased (inf --> 0.774835).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6500419\n",
      "\tspeed: 0.1331s/iter; left time: 1067.5603s\n",
      "\titers: 200, epoch: 2 | loss: 0.6053997\n",
      "\tspeed: 0.0523s/iter; left time: 414.5433s\n",
      "\titers: 300, epoch: 2 | loss: 0.5713702\n",
      "\tspeed: 0.0520s/iter; left time: 406.7352s\n",
      "\titers: 400, epoch: 2 | loss: 0.5136937\n",
      "\tspeed: 0.0524s/iter; left time: 404.3244s\n",
      "\titers: 500, epoch: 2 | loss: 0.5401712\n",
      "\tspeed: 0.0520s/iter; left time: 395.8869s\n",
      "\titers: 600, epoch: 2 | loss: 0.5388100\n",
      "\tspeed: 0.0517s/iter; left time: 388.9994s\n",
      "\titers: 700, epoch: 2 | loss: 0.5284830\n",
      "\tspeed: 0.0515s/iter; left time: 382.2624s\n",
      "\titers: 800, epoch: 2 | loss: 0.4723913\n",
      "\tspeed: 0.0515s/iter; left time: 376.6242s\n",
      "\titers: 900, epoch: 2 | loss: 0.4965907\n",
      "\tspeed: 0.0517s/iter; left time: 373.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.13s\n",
      "Steps: 902 | Train Loss: 0.5826588 Vali Loss: 0.6296505 Test Loss: 0.6879032\n",
      "Validation loss decreased (0.774835 --> 0.629650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4773910\n",
      "\tspeed: 0.1347s/iter; left time: 958.8615s\n",
      "\titers: 200, epoch: 3 | loss: 0.5161944\n",
      "\tspeed: 0.0520s/iter; left time: 364.6570s\n",
      "\titers: 300, epoch: 3 | loss: 0.5555186\n",
      "\tspeed: 0.0518s/iter; left time: 357.9759s\n",
      "\titers: 400, epoch: 3 | loss: 0.4888589\n",
      "\tspeed: 0.0513s/iter; left time: 349.9013s\n",
      "\titers: 500, epoch: 3 | loss: 0.4900426\n",
      "\tspeed: 0.0520s/iter; left time: 349.4163s\n",
      "\titers: 600, epoch: 3 | loss: 0.4695053\n",
      "\tspeed: 0.0516s/iter; left time: 341.2672s\n",
      "\titers: 700, epoch: 3 | loss: 0.4767488\n",
      "\tspeed: 0.0516s/iter; left time: 336.1538s\n",
      "\titers: 800, epoch: 3 | loss: 0.4401937\n",
      "\tspeed: 0.0515s/iter; left time: 330.2252s\n",
      "\titers: 900, epoch: 3 | loss: 0.4702183\n",
      "\tspeed: 0.0519s/iter; left time: 328.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.05s\n",
      "Steps: 902 | Train Loss: 0.4825615 Vali Loss: 0.6113480 Test Loss: 0.6961012\n",
      "Validation loss decreased (0.629650 --> 0.611348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4552673\n",
      "\tspeed: 0.1341s/iter; left time: 833.5766s\n",
      "\titers: 200, epoch: 4 | loss: 0.4182002\n",
      "\tspeed: 0.0519s/iter; left time: 317.2629s\n",
      "\titers: 300, epoch: 4 | loss: 0.4482407\n",
      "\tspeed: 0.0518s/iter; left time: 311.4085s\n",
      "\titers: 400, epoch: 4 | loss: 0.4379449\n",
      "\tspeed: 0.0520s/iter; left time: 307.3957s\n",
      "\titers: 500, epoch: 4 | loss: 0.4325068\n",
      "\tspeed: 0.0521s/iter; left time: 302.9142s\n",
      "\titers: 600, epoch: 4 | loss: 0.4607576\n",
      "\tspeed: 0.0521s/iter; left time: 297.8501s\n",
      "\titers: 700, epoch: 4 | loss: 0.4113523\n",
      "\tspeed: 0.0522s/iter; left time: 292.8557s\n",
      "\titers: 800, epoch: 4 | loss: 0.4501538\n",
      "\tspeed: 0.0517s/iter; left time: 285.1297s\n",
      "\titers: 900, epoch: 4 | loss: 0.4170002\n",
      "\tspeed: 0.0521s/iter; left time: 282.1998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.4399437 Vali Loss: 0.6030498 Test Loss: 0.6659666\n",
      "Validation loss decreased (0.611348 --> 0.603050).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3798306\n",
      "\tspeed: 0.1334s/iter; left time: 708.6417s\n",
      "\titers: 200, epoch: 5 | loss: 0.4068514\n",
      "\tspeed: 0.0518s/iter; left time: 270.1549s\n",
      "\titers: 300, epoch: 5 | loss: 0.4011664\n",
      "\tspeed: 0.0518s/iter; left time: 265.0765s\n",
      "\titers: 400, epoch: 5 | loss: 0.4041094\n",
      "\tspeed: 0.0516s/iter; left time: 258.8148s\n",
      "\titers: 500, epoch: 5 | loss: 0.4307121\n",
      "\tspeed: 0.0517s/iter; left time: 253.8068s\n",
      "\titers: 600, epoch: 5 | loss: 0.3717445\n",
      "\tspeed: 0.0520s/iter; left time: 250.4080s\n",
      "\titers: 700, epoch: 5 | loss: 0.3898468\n",
      "\tspeed: 0.0532s/iter; left time: 250.7959s\n",
      "\titers: 800, epoch: 5 | loss: 0.3740286\n",
      "\tspeed: 0.0531s/iter; left time: 245.0274s\n",
      "\titers: 900, epoch: 5 | loss: 0.4056983\n",
      "\tspeed: 0.0531s/iter; left time: 239.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.44s\n",
      "Steps: 902 | Train Loss: 0.3987529 Vali Loss: 0.6140500 Test Loss: 0.6948121\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3816989\n",
      "\tspeed: 0.1301s/iter; left time: 573.7769s\n",
      "\titers: 200, epoch: 6 | loss: 0.3667590\n",
      "\tspeed: 0.0521s/iter; left time: 224.5628s\n",
      "\titers: 300, epoch: 6 | loss: 0.3843067\n",
      "\tspeed: 0.0518s/iter; left time: 218.3376s\n",
      "\titers: 400, epoch: 6 | loss: 0.3731487\n",
      "\tspeed: 0.0520s/iter; left time: 213.7879s\n",
      "\titers: 500, epoch: 6 | loss: 0.3392414\n",
      "\tspeed: 0.0518s/iter; left time: 207.5796s\n",
      "\titers: 600, epoch: 6 | loss: 0.3976587\n",
      "\tspeed: 0.0521s/iter; left time: 203.6888s\n",
      "\titers: 700, epoch: 6 | loss: 0.3745137\n",
      "\tspeed: 0.0516s/iter; left time: 196.7519s\n",
      "\titers: 800, epoch: 6 | loss: 0.3319488\n",
      "\tspeed: 0.0515s/iter; left time: 191.2482s\n",
      "\titers: 900, epoch: 6 | loss: 0.3574228\n",
      "\tspeed: 0.0516s/iter; left time: 186.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.06s\n",
      "Steps: 902 | Train Loss: 0.3675826 Vali Loss: 0.6191680 Test Loss: 0.6964089\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3543683\n",
      "\tspeed: 0.1299s/iter; left time: 455.9251s\n",
      "\titers: 200, epoch: 7 | loss: 0.3584929\n",
      "\tspeed: 0.0523s/iter; left time: 178.2602s\n",
      "\titers: 300, epoch: 7 | loss: 0.3529427\n",
      "\tspeed: 0.0521s/iter; left time: 172.4137s\n",
      "\titers: 400, epoch: 7 | loss: 0.3259368\n",
      "\tspeed: 0.0520s/iter; left time: 166.8200s\n",
      "\titers: 500, epoch: 7 | loss: 0.3047194\n",
      "\tspeed: 0.0522s/iter; left time: 162.1372s\n",
      "\titers: 600, epoch: 7 | loss: 0.3544034\n",
      "\tspeed: 0.0520s/iter; left time: 156.5334s\n",
      "\titers: 700, epoch: 7 | loss: 0.3244225\n",
      "\tspeed: 0.0523s/iter; left time: 152.1703s\n",
      "\titers: 800, epoch: 7 | loss: 0.3500791\n",
      "\tspeed: 0.0520s/iter; left time: 145.9934s\n",
      "\titers: 900, epoch: 7 | loss: 0.3353058\n",
      "\tspeed: 0.0528s/iter; left time: 142.9216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.36s\n",
      "Steps: 902 | Train Loss: 0.3403212 Vali Loss: 0.6217956 Test Loss: 0.7023885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9471843242645264, rmse:0.9732339382171631, mae:0.6660405993461609, rse:0.7709736227989197\n",
      "Original data scale mse:40591140.0, rmse:6371.11767578125, mae:4053.178955078125, rse:0.3174396753311157\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.5640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.5528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.7216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.4776</td>\n",
       "      <td>0.5498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>0.7102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5078  0.7126  0.4996  0.5640\n",
       "              2         24        0.4878  0.6985  0.4790  0.5528\n",
       "              1         96        0.8278  0.9098  0.6768  0.7216\n",
       "              2         96        0.8712  0.9334  0.6843  0.7403\n",
       "              1         168       0.9250  0.9618  0.7023  0.7619\n",
       "              2         168       0.8726  0.9341  0.6942  0.7400\n",
       "RMSE          1         24        0.5071  0.7121  0.4983  0.5636\n",
       "              2         24        0.4826  0.6947  0.4776  0.5498\n",
       "              1         96        0.8019  0.8955  0.6663  0.7102\n",
       "              2         96        0.8538  0.9240  0.6723  0.7329\n",
       "              1         168       0.8935  0.9452  0.6883  0.7488\n",
       "              2         168       0.9231  0.9608  0.6903  0.7611\n",
       "MAE           1         24        0.4949  0.7035  0.4628  0.5568\n",
       "              2         24        0.4903  0.7002  0.4557  0.5542\n",
       "              1         96        0.9520  0.9757  0.6667  0.7739\n",
       "              2         96        0.8675  0.9314  0.6356  0.7387\n",
       "              1         168       0.9182  0.9582  0.6792  0.7591\n",
       "              2         168       0.9472  0.9732  0.6660  0.7710"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20262616.0</td>\n",
       "      <td>4501.4014</td>\n",
       "      <td>3016.6672</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19436216.0</td>\n",
       "      <td>4408.6523</td>\n",
       "      <td>2875.5586</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35706256.0</td>\n",
       "      <td>5975.4712</td>\n",
       "      <td>4163.1543</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38053568.0</td>\n",
       "      <td>6168.7573</td>\n",
       "      <td>4203.2881</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41039112.0</td>\n",
       "      <td>6406.1777</td>\n",
       "      <td>4328.8550</td>\n",
       "      <td>0.3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>37693112.0</td>\n",
       "      <td>6139.4717</td>\n",
       "      <td>4274.0054</td>\n",
       "      <td>0.3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20156686.0</td>\n",
       "      <td>4489.6196</td>\n",
       "      <td>2999.1426</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19259186.0</td>\n",
       "      <td>4388.5288</td>\n",
       "      <td>2873.7637</td>\n",
       "      <td>0.2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>34543984.0</td>\n",
       "      <td>5877.4131</td>\n",
       "      <td>4100.0752</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36986492.0</td>\n",
       "      <td>6081.6519</td>\n",
       "      <td>4114.8584</td>\n",
       "      <td>0.3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38815100.0</td>\n",
       "      <td>6230.1768</td>\n",
       "      <td>4220.9731</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40210260.0</td>\n",
       "      <td>6341.1562</td>\n",
       "      <td>4216.4253</td>\n",
       "      <td>0.3159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19648216.0</td>\n",
       "      <td>4432.6309</td>\n",
       "      <td>2762.4336</td>\n",
       "      <td>0.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19207616.0</td>\n",
       "      <td>4382.6494</td>\n",
       "      <td>2741.9597</td>\n",
       "      <td>0.2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>41247308.0</td>\n",
       "      <td>6422.4067</td>\n",
       "      <td>4063.6636</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37667352.0</td>\n",
       "      <td>6137.3735</td>\n",
       "      <td>3862.1619</td>\n",
       "      <td>0.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39692484.0</td>\n",
       "      <td>6300.1973</td>\n",
       "      <td>4161.8623</td>\n",
       "      <td>0.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40591140.0</td>\n",
       "      <td>6371.1177</td>\n",
       "      <td>4053.1790</td>\n",
       "      <td>0.3174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20262616.0  4501.4014  3016.6672  0.2238\n",
       "              2         24        19436216.0  4408.6523  2875.5586  0.2192\n",
       "              1         96        35706256.0  5975.4712  4163.1543  0.2976\n",
       "              2         96        38053568.0  6168.7573  4203.2881  0.3072\n",
       "              1         168       41039112.0  6406.1777  4328.8550  0.3192\n",
       "              2         168       37693112.0  6139.4717  4274.0054  0.3059\n",
       "RMSE          1         24        20156686.0  4489.6196  2999.1426  0.2232\n",
       "              2         24        19259186.0  4388.5288  2873.7637  0.2182\n",
       "              1         96        34543984.0  5877.4131  4100.0752  0.2927\n",
       "              2         96        36986492.0  6081.6519  4114.8584  0.3029\n",
       "              1         168       38815100.0  6230.1768  4220.9731  0.3104\n",
       "              2         168       40210260.0  6341.1562  4216.4253  0.3159\n",
       "MAE           1         24        19648216.0  4432.6309  2762.4336  0.2204\n",
       "              2         24        19207616.0  4382.6494  2741.9597  0.2179\n",
       "              1         96        41247308.0  6422.4067  4063.6636  0.3198\n",
       "              2         96        37667352.0  6137.3735  3862.1619  0.3056\n",
       "              1         168       39692484.0  6300.1973  4161.8623  0.3139\n",
       "              2         168       40591140.0  6371.1177  4053.1790  0.3174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.4893</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>0.4879</td>\n",
       "      <td>0.5567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.7563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8495</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.7309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6693</td>\n",
       "      <td>0.7215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.7509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.7550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4926  0.7018  0.4592  0.5555\n",
       "         MSE            0.4978  0.7055  0.4893  0.5584\n",
       "         RMSE           0.4949  0.7034  0.4879  0.5567\n",
       "96       MAE            0.9098  0.9536  0.6512  0.7563\n",
       "         MSE            0.8495  0.9216  0.6805  0.7309\n",
       "         RMSE           0.8278  0.9097  0.6693  0.7215\n",
       "168      MAE            0.9327  0.9657  0.6726  0.7650\n",
       "         MSE            0.8988  0.9479  0.6982  0.7509\n",
       "         RMSE           0.9083  0.9530  0.6893  0.7550"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>19427916.0</td>\n",
       "      <td>4407.6401</td>\n",
       "      <td>2752.1967</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19849416.0</td>\n",
       "      <td>4455.0269</td>\n",
       "      <td>2946.1129</td>\n",
       "      <td>0.2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19707936.0</td>\n",
       "      <td>4439.0742</td>\n",
       "      <td>2936.4531</td>\n",
       "      <td>0.2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39457330.0</td>\n",
       "      <td>6279.8901</td>\n",
       "      <td>3962.9127</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36879912.0</td>\n",
       "      <td>6072.1143</td>\n",
       "      <td>4183.2212</td>\n",
       "      <td>0.3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>35765238.0</td>\n",
       "      <td>5979.5325</td>\n",
       "      <td>4107.4668</td>\n",
       "      <td>0.2978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40141812.0</td>\n",
       "      <td>6335.6575</td>\n",
       "      <td>4107.5206</td>\n",
       "      <td>0.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39366112.0</td>\n",
       "      <td>6272.8247</td>\n",
       "      <td>4301.4302</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>39512680.0</td>\n",
       "      <td>6285.6665</td>\n",
       "      <td>4218.6992</td>\n",
       "      <td>0.3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            19427916.0  4407.6401  2752.1967  0.2192\n",
       "         MSE            19849416.0  4455.0269  2946.1129  0.2215\n",
       "         RMSE           19707936.0  4439.0742  2936.4531  0.2207\n",
       "96       MAE            39457330.0  6279.8901  3962.9127  0.3127\n",
       "         MSE            36879912.0  6072.1143  4183.2212  0.3024\n",
       "         RMSE           35765238.0  5979.5325  4107.4668  0.2978\n",
       "168      MAE            40141812.0  6335.6575  4107.5206  0.3157\n",
       "         MSE            39366112.0  6272.8247  4301.4302  0.3125\n",
       "         RMSE           39512680.0  6285.6665  4218.6992  0.3132"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PatchTST results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4062752\n",
      "\tspeed: 0.0679s/iter; left time: 599.2427s\n",
      "\titers: 200, epoch: 1 | loss: 0.4490731\n",
      "\tspeed: 0.0423s/iter; left time: 369.6214s\n",
      "\titers: 300, epoch: 1 | loss: 0.3447189\n",
      "\tspeed: 0.0423s/iter; left time: 364.8243s\n",
      "\titers: 400, epoch: 1 | loss: 0.4202814\n",
      "\tspeed: 0.0423s/iter; left time: 360.7949s\n",
      "\titers: 500, epoch: 1 | loss: 0.3825126\n",
      "\tspeed: 0.0423s/iter; left time: 356.3038s\n",
      "\titers: 600, epoch: 1 | loss: 0.4463949\n",
      "\tspeed: 0.0423s/iter; left time: 352.4487s\n",
      "\titers: 700, epoch: 1 | loss: 0.3554860\n",
      "\tspeed: 0.0424s/iter; left time: 348.7190s\n",
      "\titers: 800, epoch: 1 | loss: 0.3329375\n",
      "\tspeed: 0.0423s/iter; left time: 344.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 893 | Train Loss: 0.3779395 Vali Loss: 0.4368218 Test Loss: 0.4749455\n",
      "Validation loss decreased (inf --> 0.436822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4321591\n",
      "\tspeed: 0.1555s/iter; left time: 1234.0575s\n",
      "\titers: 200, epoch: 2 | loss: 0.3975809\n",
      "\tspeed: 0.0425s/iter; left time: 333.0563s\n",
      "\titers: 300, epoch: 2 | loss: 0.2834045\n",
      "\tspeed: 0.0423s/iter; left time: 327.4289s\n",
      "\titers: 400, epoch: 2 | loss: 0.2936918\n",
      "\tspeed: 0.0423s/iter; left time: 323.1378s\n",
      "\titers: 500, epoch: 2 | loss: 0.2714845\n",
      "\tspeed: 0.0424s/iter; left time: 319.3444s\n",
      "\titers: 600, epoch: 2 | loss: 0.2872095\n",
      "\tspeed: 0.0424s/iter; left time: 315.6703s\n",
      "\titers: 700, epoch: 2 | loss: 0.3408362\n",
      "\tspeed: 0.0424s/iter; left time: 311.3674s\n",
      "\titers: 800, epoch: 2 | loss: 0.2582404\n",
      "\tspeed: 0.0424s/iter; left time: 306.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3092715 Vali Loss: 0.4199357 Test Loss: 0.4742230\n",
      "Validation loss decreased (0.436822 --> 0.419936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2012810\n",
      "\tspeed: 0.1529s/iter; left time: 1076.8527s\n",
      "\titers: 200, epoch: 3 | loss: 0.2745693\n",
      "\tspeed: 0.0423s/iter; left time: 293.8910s\n",
      "\titers: 300, epoch: 3 | loss: 0.2421604\n",
      "\tspeed: 0.0423s/iter; left time: 289.8235s\n",
      "\titers: 400, epoch: 3 | loss: 0.2551808\n",
      "\tspeed: 0.0423s/iter; left time: 285.4184s\n",
      "\titers: 500, epoch: 3 | loss: 0.2312551\n",
      "\tspeed: 0.0423s/iter; left time: 281.0323s\n",
      "\titers: 600, epoch: 3 | loss: 0.2817569\n",
      "\tspeed: 0.0424s/iter; left time: 277.5837s\n",
      "\titers: 700, epoch: 3 | loss: 0.1640334\n",
      "\tspeed: 0.0424s/iter; left time: 273.0298s\n",
      "\titers: 800, epoch: 3 | loss: 0.3372894\n",
      "\tspeed: 0.0424s/iter; left time: 268.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2761120 Vali Loss: 0.4101853 Test Loss: 0.4503999\n",
      "Validation loss decreased (0.419936 --> 0.410185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2537383\n",
      "\tspeed: 0.1525s/iter; left time: 938.3432s\n",
      "\titers: 200, epoch: 4 | loss: 0.2325063\n",
      "\tspeed: 0.0424s/iter; left time: 256.4355s\n",
      "\titers: 300, epoch: 4 | loss: 0.2676595\n",
      "\tspeed: 0.0424s/iter; left time: 252.0785s\n",
      "\titers: 400, epoch: 4 | loss: 0.2086366\n",
      "\tspeed: 0.0424s/iter; left time: 248.0409s\n",
      "\titers: 500, epoch: 4 | loss: 0.3853133\n",
      "\tspeed: 0.0424s/iter; left time: 243.6700s\n",
      "\titers: 600, epoch: 4 | loss: 0.2249607\n",
      "\tspeed: 0.0422s/iter; left time: 238.5343s\n",
      "\titers: 700, epoch: 4 | loss: 0.2668764\n",
      "\tspeed: 0.0423s/iter; left time: 234.8522s\n",
      "\titers: 800, epoch: 4 | loss: 0.2927850\n",
      "\tspeed: 0.0424s/iter; left time: 231.2456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2687885 Vali Loss: 0.4336080 Test Loss: 0.4734263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2390144\n",
      "\tspeed: 0.1502s/iter; left time: 790.1390s\n",
      "\titers: 200, epoch: 5 | loss: 0.1977134\n",
      "\tspeed: 0.0423s/iter; left time: 218.3652s\n",
      "\titers: 300, epoch: 5 | loss: 0.2724915\n",
      "\tspeed: 0.0423s/iter; left time: 214.0501s\n",
      "\titers: 400, epoch: 5 | loss: 0.2195267\n",
      "\tspeed: 0.0424s/iter; left time: 210.1197s\n",
      "\titers: 500, epoch: 5 | loss: 0.2479026\n",
      "\tspeed: 0.0423s/iter; left time: 205.4403s\n",
      "\titers: 600, epoch: 5 | loss: 0.2113601\n",
      "\tspeed: 0.0424s/iter; left time: 201.8271s\n",
      "\titers: 700, epoch: 5 | loss: 0.2392982\n",
      "\tspeed: 0.0424s/iter; left time: 197.5442s\n",
      "\titers: 800, epoch: 5 | loss: 0.2210716\n",
      "\tspeed: 0.0424s/iter; left time: 193.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.2557502 Vali Loss: 0.4083221 Test Loss: 0.4551176\n",
      "Validation loss decreased (0.410185 --> 0.408322).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2018318\n",
      "\tspeed: 0.1536s/iter; left time: 670.6467s\n",
      "\titers: 200, epoch: 6 | loss: 0.2799388\n",
      "\tspeed: 0.0424s/iter; left time: 181.0247s\n",
      "\titers: 300, epoch: 6 | loss: 0.1967447\n",
      "\tspeed: 0.0425s/iter; left time: 177.0979s\n",
      "\titers: 400, epoch: 6 | loss: 0.2135415\n",
      "\tspeed: 0.0423s/iter; left time: 172.0800s\n",
      "\titers: 500, epoch: 6 | loss: 0.2062024\n",
      "\tspeed: 0.0423s/iter; left time: 167.8923s\n",
      "\titers: 600, epoch: 6 | loss: 0.2476224\n",
      "\tspeed: 0.0424s/iter; left time: 163.9357s\n",
      "\titers: 700, epoch: 6 | loss: 0.1791212\n",
      "\tspeed: 0.0425s/iter; left time: 160.0147s\n",
      "\titers: 800, epoch: 6 | loss: 0.2224586\n",
      "\tspeed: 0.0424s/iter; left time: 155.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.2370440 Vali Loss: 0.4499719 Test Loss: 0.4937295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2283527\n",
      "\tspeed: 0.1506s/iter; left time: 522.9856s\n",
      "\titers: 200, epoch: 7 | loss: 0.2216568\n",
      "\tspeed: 0.0424s/iter; left time: 142.8875s\n",
      "\titers: 300, epoch: 7 | loss: 0.2187734\n",
      "\tspeed: 0.0423s/iter; left time: 138.5007s\n",
      "\titers: 400, epoch: 7 | loss: 0.2077828\n",
      "\tspeed: 0.0423s/iter; left time: 134.1586s\n",
      "\titers: 500, epoch: 7 | loss: 0.1985875\n",
      "\tspeed: 0.0423s/iter; left time: 129.8508s\n",
      "\titers: 600, epoch: 7 | loss: 0.2054232\n",
      "\tspeed: 0.0423s/iter; left time: 125.7131s\n",
      "\titers: 700, epoch: 7 | loss: 0.1703641\n",
      "\tspeed: 0.0423s/iter; left time: 121.5996s\n",
      "\titers: 800, epoch: 7 | loss: 0.1733078\n",
      "\tspeed: 0.0423s/iter; left time: 117.3378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 893 | Train Loss: 0.2119504 Vali Loss: 0.4550525 Test Loss: 0.5188643\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2100210\n",
      "\tspeed: 0.1507s/iter; left time: 388.9244s\n",
      "\titers: 200, epoch: 8 | loss: 0.1868386\n",
      "\tspeed: 0.0424s/iter; left time: 105.2177s\n",
      "\titers: 300, epoch: 8 | loss: 0.1724563\n",
      "\tspeed: 0.0423s/iter; left time: 100.7432s\n",
      "\titers: 400, epoch: 8 | loss: 0.2129223\n",
      "\tspeed: 0.0423s/iter; left time: 96.5167s\n",
      "\titers: 500, epoch: 8 | loss: 0.2158544\n",
      "\tspeed: 0.0424s/iter; left time: 92.4012s\n",
      "\titers: 600, epoch: 8 | loss: 0.1620623\n",
      "\tspeed: 0.0425s/iter; left time: 88.3637s\n",
      "\titers: 700, epoch: 8 | loss: 0.1801844\n",
      "\tspeed: 0.0424s/iter; left time: 83.9291s\n",
      "\titers: 800, epoch: 8 | loss: 0.2255919\n",
      "\tspeed: 0.0424s/iter; left time: 79.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.1881337 Vali Loss: 0.4813017 Test Loss: 0.5380040\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45511767268180847, rmse:0.6746240854263306, mae:0.4416392743587494, rse:0.5339223742485046\n",
      "Original data scale mse:17261680.0, rmse:4154.7177734375, mae:2581.17822265625, rse:0.20658095180988312\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3967359\n",
      "\tspeed: 0.0443s/iter; left time: 391.4396s\n",
      "\titers: 200, epoch: 1 | loss: 0.4064189\n",
      "\tspeed: 0.0424s/iter; left time: 370.5603s\n",
      "\titers: 300, epoch: 1 | loss: 0.2779341\n",
      "\tspeed: 0.0424s/iter; left time: 366.0447s\n",
      "\titers: 400, epoch: 1 | loss: 0.2643839\n",
      "\tspeed: 0.0424s/iter; left time: 362.0700s\n",
      "\titers: 500, epoch: 1 | loss: 0.2900892\n",
      "\tspeed: 0.0423s/iter; left time: 356.8179s\n",
      "\titers: 600, epoch: 1 | loss: 0.3112502\n",
      "\tspeed: 0.0425s/iter; left time: 353.7496s\n",
      "\titers: 700, epoch: 1 | loss: 0.2473065\n",
      "\tspeed: 0.0423s/iter; left time: 347.9740s\n",
      "\titers: 800, epoch: 1 | loss: 0.2575147\n",
      "\tspeed: 0.0423s/iter; left time: 344.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3743255 Vali Loss: 0.4390815 Test Loss: 0.4765824\n",
      "Validation loss decreased (inf --> 0.439081).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3144976\n",
      "\tspeed: 0.1532s/iter; left time: 1216.0693s\n",
      "\titers: 200, epoch: 2 | loss: 0.2808562\n",
      "\tspeed: 0.0424s/iter; left time: 332.0637s\n",
      "\titers: 300, epoch: 2 | loss: 0.2744709\n",
      "\tspeed: 0.0425s/iter; left time: 328.6438s\n",
      "\titers: 400, epoch: 2 | loss: 0.3588106\n",
      "\tspeed: 0.0424s/iter; left time: 323.6192s\n",
      "\titers: 500, epoch: 2 | loss: 0.3180828\n",
      "\tspeed: 0.0423s/iter; left time: 318.8200s\n",
      "\titers: 600, epoch: 2 | loss: 0.2916528\n",
      "\tspeed: 0.0424s/iter; left time: 315.2543s\n",
      "\titers: 700, epoch: 2 | loss: 0.2639987\n",
      "\tspeed: 0.0425s/iter; left time: 311.7480s\n",
      "\titers: 800, epoch: 2 | loss: 0.3295977\n",
      "\tspeed: 0.0425s/iter; left time: 307.3230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.3134294 Vali Loss: 0.4065219 Test Loss: 0.4498437\n",
      "Validation loss decreased (0.439081 --> 0.406522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2422723\n",
      "\tspeed: 0.1536s/iter; left time: 1082.1756s\n",
      "\titers: 200, epoch: 3 | loss: 0.2763481\n",
      "\tspeed: 0.0423s/iter; left time: 293.5784s\n",
      "\titers: 300, epoch: 3 | loss: 0.2693237\n",
      "\tspeed: 0.0423s/iter; left time: 289.8415s\n",
      "\titers: 400, epoch: 3 | loss: 0.3108239\n",
      "\tspeed: 0.0424s/iter; left time: 286.2577s\n",
      "\titers: 500, epoch: 3 | loss: 0.1933685\n",
      "\tspeed: 0.0425s/iter; left time: 282.6698s\n",
      "\titers: 600, epoch: 3 | loss: 0.2856435\n",
      "\tspeed: 0.0425s/iter; left time: 278.2216s\n",
      "\titers: 700, epoch: 3 | loss: 0.2616338\n",
      "\tspeed: 0.0425s/iter; left time: 273.5982s\n",
      "\titers: 800, epoch: 3 | loss: 0.2869773\n",
      "\tspeed: 0.0424s/iter; left time: 268.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.2774806 Vali Loss: 0.4149170 Test Loss: 0.4646415\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3248570\n",
      "\tspeed: 0.1508s/iter; left time: 928.0265s\n",
      "\titers: 200, epoch: 4 | loss: 0.2699777\n",
      "\tspeed: 0.0423s/iter; left time: 255.9761s\n",
      "\titers: 300, epoch: 4 | loss: 0.2988690\n",
      "\tspeed: 0.0424s/iter; left time: 252.1062s\n",
      "\titers: 400, epoch: 4 | loss: 0.2862901\n",
      "\tspeed: 0.0424s/iter; left time: 248.3990s\n",
      "\titers: 500, epoch: 4 | loss: 0.2651158\n",
      "\tspeed: 0.0423s/iter; left time: 243.5503s\n",
      "\titers: 600, epoch: 4 | loss: 0.2613765\n",
      "\tspeed: 0.0423s/iter; left time: 239.0812s\n",
      "\titers: 700, epoch: 4 | loss: 0.2783110\n",
      "\tspeed: 0.0424s/iter; left time: 235.2375s\n",
      "\titers: 800, epoch: 4 | loss: 0.2053535\n",
      "\tspeed: 0.0423s/iter; left time: 230.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2820289 Vali Loss: 0.4095885 Test Loss: 0.4661101\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2652097\n",
      "\tspeed: 0.1515s/iter; left time: 796.8502s\n",
      "\titers: 200, epoch: 5 | loss: 0.2383111\n",
      "\tspeed: 0.0423s/iter; left time: 218.2376s\n",
      "\titers: 300, epoch: 5 | loss: 0.2541043\n",
      "\tspeed: 0.0423s/iter; left time: 214.1389s\n",
      "\titers: 400, epoch: 5 | loss: 0.2939530\n",
      "\tspeed: 0.0423s/iter; left time: 209.8434s\n",
      "\titers: 500, epoch: 5 | loss: 0.3624977\n",
      "\tspeed: 0.0423s/iter; left time: 205.5906s\n",
      "\titers: 600, epoch: 5 | loss: 0.2916973\n",
      "\tspeed: 0.0424s/iter; left time: 201.8669s\n",
      "\titers: 700, epoch: 5 | loss: 0.2681513\n",
      "\tspeed: 0.0423s/iter; left time: 197.2126s\n",
      "\titers: 800, epoch: 5 | loss: 0.2681236\n",
      "\tspeed: 0.0424s/iter; left time: 193.1918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.2520440 Vali Loss: 0.4063278 Test Loss: 0.4664033\n",
      "Validation loss decreased (0.406522 --> 0.406328).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3188669\n",
      "\tspeed: 0.1528s/iter; left time: 667.0724s\n",
      "\titers: 200, epoch: 6 | loss: 0.2008031\n",
      "\tspeed: 0.0423s/iter; left time: 180.4956s\n",
      "\titers: 300, epoch: 6 | loss: 0.2052909\n",
      "\tspeed: 0.0423s/iter; left time: 176.3804s\n",
      "\titers: 400, epoch: 6 | loss: 0.2591189\n",
      "\tspeed: 0.0423s/iter; left time: 172.0109s\n",
      "\titers: 500, epoch: 6 | loss: 0.1943497\n",
      "\tspeed: 0.0422s/iter; left time: 167.1677s\n",
      "\titers: 600, epoch: 6 | loss: 0.2352947\n",
      "\tspeed: 0.0422s/iter; left time: 163.0949s\n",
      "\titers: 700, epoch: 6 | loss: 0.2489737\n",
      "\tspeed: 0.0420s/iter; left time: 158.3054s\n",
      "\titers: 800, epoch: 6 | loss: 0.2547600\n",
      "\tspeed: 0.0420s/iter; left time: 153.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 893 | Train Loss: 0.2338442 Vali Loss: 0.4190404 Test Loss: 0.4860373\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2307729\n",
      "\tspeed: 0.1512s/iter; left time: 525.1738s\n",
      "\titers: 200, epoch: 7 | loss: 0.3084017\n",
      "\tspeed: 0.0423s/iter; left time: 142.6637s\n",
      "\titers: 300, epoch: 7 | loss: 0.2080216\n",
      "\tspeed: 0.0423s/iter; left time: 138.4167s\n",
      "\titers: 400, epoch: 7 | loss: 0.2292389\n",
      "\tspeed: 0.0423s/iter; left time: 134.1549s\n",
      "\titers: 500, epoch: 7 | loss: 0.1513019\n",
      "\tspeed: 0.0423s/iter; left time: 130.1379s\n",
      "\titers: 600, epoch: 7 | loss: 0.1729813\n",
      "\tspeed: 0.0423s/iter; left time: 125.8568s\n",
      "\titers: 700, epoch: 7 | loss: 0.1880350\n",
      "\tspeed: 0.0424s/iter; left time: 121.7990s\n",
      "\titers: 800, epoch: 7 | loss: 0.1786184\n",
      "\tspeed: 0.0423s/iter; left time: 117.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.2103385 Vali Loss: 0.4527536 Test Loss: 0.5490917\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1798774\n",
      "\tspeed: 0.1514s/iter; left time: 390.7379s\n",
      "\titers: 200, epoch: 8 | loss: 0.1682350\n",
      "\tspeed: 0.0423s/iter; left time: 105.0200s\n",
      "\titers: 300, epoch: 8 | loss: 0.1307397\n",
      "\tspeed: 0.0425s/iter; left time: 101.0480s\n",
      "\titers: 400, epoch: 8 | loss: 0.2033289\n",
      "\tspeed: 0.0423s/iter; left time: 96.4256s\n",
      "\titers: 500, epoch: 8 | loss: 0.1776353\n",
      "\tspeed: 0.0423s/iter; left time: 92.1877s\n",
      "\titers: 600, epoch: 8 | loss: 0.1967961\n",
      "\tspeed: 0.0423s/iter; left time: 88.0449s\n",
      "\titers: 700, epoch: 8 | loss: 0.1893690\n",
      "\tspeed: 0.0423s/iter; left time: 83.8084s\n",
      "\titers: 800, epoch: 8 | loss: 0.1618215\n",
      "\tspeed: 0.0423s/iter; left time: 79.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.1851797 Vali Loss: 0.4516812 Test Loss: 0.5370039\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4664033055305481, rmse:0.6829372644424438, mae:0.4505856931209564, rse:0.5405017137527466\n",
      "Original data scale mse:17762658.0, rmse:4214.57666015625, mae:2639.203857421875, rse:0.20955726504325867\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7372616\n",
      "\tspeed: 0.0670s/iter; left time: 590.5372s\n",
      "\titers: 200, epoch: 1 | loss: 0.5333896\n",
      "\tspeed: 0.0427s/iter; left time: 371.7987s\n",
      "\titers: 300, epoch: 1 | loss: 0.5598907\n",
      "\tspeed: 0.0429s/iter; left time: 369.0281s\n",
      "\titers: 400, epoch: 1 | loss: 0.4729436\n",
      "\tspeed: 0.0427s/iter; left time: 363.5738s\n",
      "\titers: 500, epoch: 1 | loss: 0.5560483\n",
      "\tspeed: 0.0428s/iter; left time: 359.5714s\n",
      "\titers: 600, epoch: 1 | loss: 0.4819749\n",
      "\tspeed: 0.0427s/iter; left time: 355.0414s\n",
      "\titers: 700, epoch: 1 | loss: 0.5415132\n",
      "\tspeed: 0.0427s/iter; left time: 350.7844s\n",
      "\titers: 800, epoch: 1 | loss: 0.6243510\n",
      "\tspeed: 0.0428s/iter; left time: 347.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.47s\n",
      "Steps: 891 | Train Loss: 0.5668236 Vali Loss: 0.6507477 Test Loss: 0.7603212\n",
      "Validation loss decreased (inf --> 0.650748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5540779\n",
      "\tspeed: 0.1520s/iter; left time: 1203.6075s\n",
      "\titers: 200, epoch: 2 | loss: 0.4847487\n",
      "\tspeed: 0.0428s/iter; left time: 334.7597s\n",
      "\titers: 300, epoch: 2 | loss: 0.4586814\n",
      "\tspeed: 0.0428s/iter; left time: 330.5472s\n",
      "\titers: 400, epoch: 2 | loss: 0.5438913\n",
      "\tspeed: 0.0427s/iter; left time: 325.4002s\n",
      "\titers: 500, epoch: 2 | loss: 0.4111202\n",
      "\tspeed: 0.0428s/iter; left time: 321.4945s\n",
      "\titers: 600, epoch: 2 | loss: 0.3895184\n",
      "\tspeed: 0.0427s/iter; left time: 316.8562s\n",
      "\titers: 700, epoch: 2 | loss: 0.3883051\n",
      "\tspeed: 0.0427s/iter; left time: 312.7519s\n",
      "\titers: 800, epoch: 2 | loss: 0.5433491\n",
      "\tspeed: 0.0427s/iter; left time: 308.4782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.5033157 Vali Loss: 0.6297555 Test Loss: 0.7439358\n",
      "Validation loss decreased (0.650748 --> 0.629755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4145484\n",
      "\tspeed: 0.1531s/iter; left time: 1076.0209s\n",
      "\titers: 200, epoch: 3 | loss: 0.4595998\n",
      "\tspeed: 0.0428s/iter; left time: 296.6672s\n",
      "\titers: 300, epoch: 3 | loss: 0.4619078\n",
      "\tspeed: 0.0427s/iter; left time: 291.7835s\n",
      "\titers: 400, epoch: 3 | loss: 0.4526187\n",
      "\tspeed: 0.0427s/iter; left time: 287.4733s\n",
      "\titers: 500, epoch: 3 | loss: 0.4454547\n",
      "\tspeed: 0.0428s/iter; left time: 283.4371s\n",
      "\titers: 600, epoch: 3 | loss: 0.3692695\n",
      "\tspeed: 0.0426s/iter; left time: 278.4322s\n",
      "\titers: 700, epoch: 3 | loss: 0.4703220\n",
      "\tspeed: 0.0427s/iter; left time: 274.5120s\n",
      "\titers: 800, epoch: 3 | loss: 0.3812272\n",
      "\tspeed: 0.0428s/iter; left time: 270.8899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.4455938 Vali Loss: 0.6881084 Test Loss: 0.8548705\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4174319\n",
      "\tspeed: 0.1502s/iter; left time: 921.8349s\n",
      "\titers: 200, epoch: 4 | loss: 0.4014978\n",
      "\tspeed: 0.0426s/iter; left time: 257.2844s\n",
      "\titers: 300, epoch: 4 | loss: 0.4054119\n",
      "\tspeed: 0.0427s/iter; left time: 253.3398s\n",
      "\titers: 400, epoch: 4 | loss: 0.3589748\n",
      "\tspeed: 0.0427s/iter; left time: 249.2604s\n",
      "\titers: 500, epoch: 4 | loss: 0.3653719\n",
      "\tspeed: 0.0427s/iter; left time: 245.0993s\n",
      "\titers: 600, epoch: 4 | loss: 0.3618014\n",
      "\tspeed: 0.0427s/iter; left time: 240.9776s\n",
      "\titers: 700, epoch: 4 | loss: 0.3188422\n",
      "\tspeed: 0.0427s/iter; left time: 236.5605s\n",
      "\titers: 800, epoch: 4 | loss: 0.2926117\n",
      "\tspeed: 0.0427s/iter; left time: 232.2316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 891 | Train Loss: 0.3568448 Vali Loss: 0.7477230 Test Loss: 0.9618957\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2811221\n",
      "\tspeed: 0.1508s/iter; left time: 791.3091s\n",
      "\titers: 200, epoch: 5 | loss: 0.2773483\n",
      "\tspeed: 0.0427s/iter; left time: 219.8007s\n",
      "\titers: 300, epoch: 5 | loss: 0.3285968\n",
      "\tspeed: 0.0427s/iter; left time: 215.6158s\n",
      "\titers: 400, epoch: 5 | loss: 0.2673545\n",
      "\tspeed: 0.0427s/iter; left time: 211.2512s\n",
      "\titers: 500, epoch: 5 | loss: 0.2493921\n",
      "\tspeed: 0.0427s/iter; left time: 207.0348s\n",
      "\titers: 600, epoch: 5 | loss: 0.2386115\n",
      "\tspeed: 0.0427s/iter; left time: 202.6892s\n",
      "\titers: 700, epoch: 5 | loss: 0.2263911\n",
      "\tspeed: 0.0427s/iter; left time: 198.4134s\n",
      "\titers: 800, epoch: 5 | loss: 0.1957354\n",
      "\tspeed: 0.0427s/iter; left time: 194.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 891 | Train Loss: 0.2605241 Vali Loss: 0.8050478 Test Loss: 0.9919707\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7439358234405518, rmse:0.8625171184539795, mae:0.6113150119781494, rse:0.6840823292732239\n",
      "Original data scale mse:30875704.0, rmse:5556.5908203125, mae:3633.89697265625, rse:0.27672022581100464\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5473459\n",
      "\tspeed: 0.0440s/iter; left time: 387.7336s\n",
      "\titers: 200, epoch: 1 | loss: 0.4877608\n",
      "\tspeed: 0.0428s/iter; left time: 372.4392s\n",
      "\titers: 300, epoch: 1 | loss: 0.6598209\n",
      "\tspeed: 0.0428s/iter; left time: 368.2271s\n",
      "\titers: 400, epoch: 1 | loss: 0.6614044\n",
      "\tspeed: 0.0429s/iter; left time: 364.7257s\n",
      "\titers: 500, epoch: 1 | loss: 0.4741346\n",
      "\tspeed: 0.0427s/iter; left time: 359.2832s\n",
      "\titers: 600, epoch: 1 | loss: 0.6109210\n",
      "\tspeed: 0.0428s/iter; left time: 355.6680s\n",
      "\titers: 700, epoch: 1 | loss: 0.5352585\n",
      "\tspeed: 0.0427s/iter; left time: 350.3490s\n",
      "\titers: 800, epoch: 1 | loss: 0.5013155\n",
      "\tspeed: 0.0427s/iter; left time: 346.3452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.5658269 Vali Loss: 0.6509469 Test Loss: 0.7612176\n",
      "Validation loss decreased (inf --> 0.650947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5183153\n",
      "\tspeed: 0.1529s/iter; left time: 1211.1457s\n",
      "\titers: 200, epoch: 2 | loss: 0.4526019\n",
      "\tspeed: 0.0427s/iter; left time: 333.8961s\n",
      "\titers: 300, epoch: 2 | loss: 0.5071620\n",
      "\tspeed: 0.0427s/iter; left time: 329.6108s\n",
      "\titers: 400, epoch: 2 | loss: 0.4839136\n",
      "\tspeed: 0.0426s/iter; left time: 324.8442s\n",
      "\titers: 500, epoch: 2 | loss: 0.3920006\n",
      "\tspeed: 0.0427s/iter; left time: 321.1203s\n",
      "\titers: 600, epoch: 2 | loss: 0.4868114\n",
      "\tspeed: 0.0428s/iter; left time: 317.5724s\n",
      "\titers: 700, epoch: 2 | loss: 0.5634870\n",
      "\tspeed: 0.0427s/iter; left time: 312.2350s\n",
      "\titers: 800, epoch: 2 | loss: 0.4724952\n",
      "\tspeed: 0.0427s/iter; left time: 308.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.5043234 Vali Loss: 0.6191998 Test Loss: 0.7726130\n",
      "Validation loss decreased (0.650947 --> 0.619200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5086631\n",
      "\tspeed: 0.1538s/iter; left time: 1081.2978s\n",
      "\titers: 200, epoch: 3 | loss: 0.4055051\n",
      "\tspeed: 0.0427s/iter; left time: 295.7305s\n",
      "\titers: 300, epoch: 3 | loss: 0.3720219\n",
      "\tspeed: 0.0427s/iter; left time: 291.4443s\n",
      "\titers: 400, epoch: 3 | loss: 0.4331014\n",
      "\tspeed: 0.0427s/iter; left time: 287.2703s\n",
      "\titers: 500, epoch: 3 | loss: 0.3976127\n",
      "\tspeed: 0.0426s/iter; left time: 282.6995s\n",
      "\titers: 600, epoch: 3 | loss: 0.4022872\n",
      "\tspeed: 0.0427s/iter; left time: 278.8334s\n",
      "\titers: 700, epoch: 3 | loss: 0.4675071\n",
      "\tspeed: 0.0427s/iter; left time: 274.2666s\n",
      "\titers: 800, epoch: 3 | loss: 0.3814891\n",
      "\tspeed: 0.0427s/iter; left time: 269.9880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.4320488 Vali Loss: 0.6841762 Test Loss: 0.8737969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3273250\n",
      "\tspeed: 0.1505s/iter; left time: 923.9212s\n",
      "\titers: 200, epoch: 4 | loss: 0.3400194\n",
      "\tspeed: 0.0427s/iter; left time: 257.7144s\n",
      "\titers: 300, epoch: 4 | loss: 0.3161496\n",
      "\tspeed: 0.0426s/iter; left time: 253.1537s\n",
      "\titers: 400, epoch: 4 | loss: 0.3390466\n",
      "\tspeed: 0.0427s/iter; left time: 249.2543s\n",
      "\titers: 500, epoch: 4 | loss: 0.2879927\n",
      "\tspeed: 0.0427s/iter; left time: 244.7857s\n",
      "\titers: 600, epoch: 4 | loss: 0.3149875\n",
      "\tspeed: 0.0430s/iter; left time: 242.4409s\n",
      "\titers: 700, epoch: 4 | loss: 0.3463651\n",
      "\tspeed: 0.0427s/iter; left time: 236.6177s\n",
      "\titers: 800, epoch: 4 | loss: 0.2761787\n",
      "\tspeed: 0.0427s/iter; left time: 232.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.3297124 Vali Loss: 0.7400400 Test Loss: 0.9315168\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2692976\n",
      "\tspeed: 0.1504s/iter; left time: 789.1331s\n",
      "\titers: 200, epoch: 5 | loss: 0.2221422\n",
      "\tspeed: 0.0427s/iter; left time: 220.0111s\n",
      "\titers: 300, epoch: 5 | loss: 0.2397722\n",
      "\tspeed: 0.0427s/iter; left time: 215.6517s\n",
      "\titers: 400, epoch: 5 | loss: 0.2549823\n",
      "\tspeed: 0.0427s/iter; left time: 211.1870s\n",
      "\titers: 500, epoch: 5 | loss: 0.2158701\n",
      "\tspeed: 0.0427s/iter; left time: 206.9031s\n",
      "\titers: 600, epoch: 5 | loss: 0.2114049\n",
      "\tspeed: 0.0427s/iter; left time: 202.8592s\n",
      "\titers: 700, epoch: 5 | loss: 0.2200302\n",
      "\tspeed: 0.0428s/iter; left time: 198.8283s\n",
      "\titers: 800, epoch: 5 | loss: 0.2109580\n",
      "\tspeed: 0.0426s/iter; left time: 193.8754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.2433385 Vali Loss: 0.7909078 Test Loss: 1.0188278\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7726126909255981, rmse:0.8789839148521423, mae:0.6244558691978455, rse:0.6971425414085388\n",
      "Original data scale mse:32792920.0, rmse:5726.51025390625, mae:3746.37841796875, rse:0.28518226742744446\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7546027\n",
      "\tspeed: 0.0685s/iter; left time: 601.9188s\n",
      "\titers: 200, epoch: 1 | loss: 0.6000124\n",
      "\tspeed: 0.0434s/iter; left time: 377.0916s\n",
      "\titers: 300, epoch: 1 | loss: 0.6143029\n",
      "\tspeed: 0.0434s/iter; left time: 373.0299s\n",
      "\titers: 400, epoch: 1 | loss: 0.7047151\n",
      "\tspeed: 0.0432s/iter; left time: 367.0263s\n",
      "\titers: 500, epoch: 1 | loss: 0.6804361\n",
      "\tspeed: 0.0433s/iter; left time: 363.1118s\n",
      "\titers: 600, epoch: 1 | loss: 0.5855610\n",
      "\tspeed: 0.0432s/iter; left time: 358.4246s\n",
      "\titers: 700, epoch: 1 | loss: 0.5702372\n",
      "\tspeed: 0.0433s/iter; left time: 354.2754s\n",
      "\titers: 800, epoch: 1 | loss: 0.5958639\n",
      "\tspeed: 0.0433s/iter; left time: 350.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.6097435 Vali Loss: 0.6800801 Test Loss: 0.8067515\n",
      "Validation loss decreased (inf --> 0.680080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6113356\n",
      "\tspeed: 0.1570s/iter; left time: 1240.7043s\n",
      "\titers: 200, epoch: 2 | loss: 0.4996085\n",
      "\tspeed: 0.0434s/iter; left time: 338.6026s\n",
      "\titers: 300, epoch: 2 | loss: 0.6496976\n",
      "\tspeed: 0.0434s/iter; left time: 334.2431s\n",
      "\titers: 400, epoch: 2 | loss: 0.5307702\n",
      "\tspeed: 0.0434s/iter; left time: 329.8440s\n",
      "\titers: 500, epoch: 2 | loss: 0.5256283\n",
      "\tspeed: 0.0433s/iter; left time: 324.4753s\n",
      "\titers: 600, epoch: 2 | loss: 0.5327381\n",
      "\tspeed: 0.0432s/iter; left time: 319.7562s\n",
      "\titers: 700, epoch: 2 | loss: 0.4570733\n",
      "\tspeed: 0.0432s/iter; left time: 315.7967s\n",
      "\titers: 800, epoch: 2 | loss: 0.5451870\n",
      "\tspeed: 0.0433s/iter; left time: 311.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.5431589 Vali Loss: 0.6531566 Test Loss: 0.8226323\n",
      "Validation loss decreased (0.680080 --> 0.653157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4712646\n",
      "\tspeed: 0.1560s/iter; left time: 1094.2592s\n",
      "\titers: 200, epoch: 3 | loss: 0.4011992\n",
      "\tspeed: 0.0432s/iter; left time: 298.3359s\n",
      "\titers: 300, epoch: 3 | loss: 0.4421045\n",
      "\tspeed: 0.0432s/iter; left time: 294.0255s\n",
      "\titers: 400, epoch: 3 | loss: 0.4903741\n",
      "\tspeed: 0.0431s/iter; left time: 289.5582s\n",
      "\titers: 500, epoch: 3 | loss: 0.4915803\n",
      "\tspeed: 0.0431s/iter; left time: 285.1769s\n",
      "\titers: 600, epoch: 3 | loss: 0.4369896\n",
      "\tspeed: 0.0431s/iter; left time: 280.9883s\n",
      "\titers: 700, epoch: 3 | loss: 0.4332677\n",
      "\tspeed: 0.0432s/iter; left time: 276.8598s\n",
      "\titers: 800, epoch: 3 | loss: 0.3947041\n",
      "\tspeed: 0.0432s/iter; left time: 272.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.4362630 Vali Loss: 0.7709182 Test Loss: 1.0190653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3152215\n",
      "\tspeed: 0.1524s/iter; left time: 933.1655s\n",
      "\titers: 200, epoch: 4 | loss: 0.3043053\n",
      "\tspeed: 0.0432s/iter; left time: 260.4047s\n",
      "\titers: 300, epoch: 4 | loss: 0.3607482\n",
      "\tspeed: 0.0431s/iter; left time: 255.6109s\n",
      "\titers: 400, epoch: 4 | loss: 0.3158475\n",
      "\tspeed: 0.0432s/iter; left time: 251.3440s\n",
      "\titers: 500, epoch: 4 | loss: 0.3114798\n",
      "\tspeed: 0.0432s/iter; left time: 247.1892s\n",
      "\titers: 600, epoch: 4 | loss: 0.2569940\n",
      "\tspeed: 0.0432s/iter; left time: 243.1016s\n",
      "\titers: 700, epoch: 4 | loss: 0.2990108\n",
      "\tspeed: 0.0433s/iter; left time: 239.1715s\n",
      "\titers: 800, epoch: 4 | loss: 0.2757485\n",
      "\tspeed: 0.0432s/iter; left time: 234.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 889 | Train Loss: 0.3139915 Vali Loss: 0.8249027 Test Loss: 1.1139140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2653311\n",
      "\tspeed: 0.1534s/iter; left time: 803.1848s\n",
      "\titers: 200, epoch: 5 | loss: 0.2252893\n",
      "\tspeed: 0.0432s/iter; left time: 221.7956s\n",
      "\titers: 300, epoch: 5 | loss: 0.2340532\n",
      "\tspeed: 0.0432s/iter; left time: 217.7169s\n",
      "\titers: 400, epoch: 5 | loss: 0.2358732\n",
      "\tspeed: 0.0432s/iter; left time: 213.0039s\n",
      "\titers: 500, epoch: 5 | loss: 0.2421527\n",
      "\tspeed: 0.0431s/iter; left time: 208.5055s\n",
      "\titers: 600, epoch: 5 | loss: 0.2229267\n",
      "\tspeed: 0.0431s/iter; left time: 204.2013s\n",
      "\titers: 700, epoch: 5 | loss: 0.2323525\n",
      "\tspeed: 0.0432s/iter; left time: 200.3228s\n",
      "\titers: 800, epoch: 5 | loss: 0.1996585\n",
      "\tspeed: 0.0432s/iter; left time: 195.7359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.2229739 Vali Loss: 0.8824634 Test Loss: 1.1303844\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8226325511932373, rmse:0.9069909453392029, mae:0.6497392058372498, rse:0.7184973955154419\n",
      "Original data scale mse:35247892.0, rmse:5936.99365234375, mae:3905.610107421875, rse:0.2958095371723175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7979063\n",
      "\tspeed: 0.0451s/iter; left time: 396.8241s\n",
      "\titers: 200, epoch: 1 | loss: 0.6841452\n",
      "\tspeed: 0.0432s/iter; left time: 375.3620s\n",
      "\titers: 300, epoch: 1 | loss: 0.7397766\n",
      "\tspeed: 0.0432s/iter; left time: 370.8872s\n",
      "\titers: 400, epoch: 1 | loss: 0.6866934\n",
      "\tspeed: 0.0431s/iter; left time: 366.3169s\n",
      "\titers: 500, epoch: 1 | loss: 0.6043772\n",
      "\tspeed: 0.0433s/iter; left time: 363.0868s\n",
      "\titers: 600, epoch: 1 | loss: 0.4847449\n",
      "\tspeed: 0.0434s/iter; left time: 359.8004s\n",
      "\titers: 700, epoch: 1 | loss: 0.5677136\n",
      "\tspeed: 0.0432s/iter; left time: 354.1416s\n",
      "\titers: 800, epoch: 1 | loss: 0.5065239\n",
      "\tspeed: 0.0434s/iter; left time: 351.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.6112015 Vali Loss: 0.6771722 Test Loss: 0.8046841\n",
      "Validation loss decreased (inf --> 0.677172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6040920\n",
      "\tspeed: 0.1561s/iter; left time: 1233.4365s\n",
      "\titers: 200, epoch: 2 | loss: 0.5640650\n",
      "\tspeed: 0.0432s/iter; left time: 336.7035s\n",
      "\titers: 300, epoch: 2 | loss: 0.5824279\n",
      "\tspeed: 0.0433s/iter; left time: 333.2817s\n",
      "\titers: 400, epoch: 2 | loss: 0.5516443\n",
      "\tspeed: 0.0432s/iter; left time: 328.2858s\n",
      "\titers: 500, epoch: 2 | loss: 0.5464745\n",
      "\tspeed: 0.0432s/iter; left time: 324.1682s\n",
      "\titers: 600, epoch: 2 | loss: 0.5696195\n",
      "\tspeed: 0.0432s/iter; left time: 319.6071s\n",
      "\titers: 700, epoch: 2 | loss: 0.4997825\n",
      "\tspeed: 0.0432s/iter; left time: 315.3826s\n",
      "\titers: 800, epoch: 2 | loss: 0.4807952\n",
      "\tspeed: 0.0432s/iter; left time: 310.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.5430961 Vali Loss: 0.6961910 Test Loss: 0.8720690\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4384274\n",
      "\tspeed: 0.1543s/iter; left time: 1081.8186s\n",
      "\titers: 200, epoch: 3 | loss: 0.4003488\n",
      "\tspeed: 0.0434s/iter; left time: 299.8521s\n",
      "\titers: 300, epoch: 3 | loss: 0.5147206\n",
      "\tspeed: 0.0432s/iter; left time: 294.4050s\n",
      "\titers: 400, epoch: 3 | loss: 0.5407557\n",
      "\tspeed: 0.0432s/iter; left time: 290.0289s\n",
      "\titers: 500, epoch: 3 | loss: 0.4383535\n",
      "\tspeed: 0.0432s/iter; left time: 285.9180s\n",
      "\titers: 600, epoch: 3 | loss: 0.4661134\n",
      "\tspeed: 0.0433s/iter; left time: 282.1961s\n",
      "\titers: 700, epoch: 3 | loss: 0.4150949\n",
      "\tspeed: 0.0433s/iter; left time: 277.7682s\n",
      "\titers: 800, epoch: 3 | loss: 0.4085022\n",
      "\tspeed: 0.0432s/iter; left time: 272.7991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4439213 Vali Loss: 0.7267453 Test Loss: 0.9541050\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3798918\n",
      "\tspeed: 0.1547s/iter; left time: 947.2197s\n",
      "\titers: 200, epoch: 4 | loss: 0.3046944\n",
      "\tspeed: 0.0432s/iter; left time: 260.1293s\n",
      "\titers: 300, epoch: 4 | loss: 0.3279685\n",
      "\tspeed: 0.0432s/iter; left time: 255.9744s\n",
      "\titers: 400, epoch: 4 | loss: 0.3203649\n",
      "\tspeed: 0.0432s/iter; left time: 251.5670s\n",
      "\titers: 500, epoch: 4 | loss: 0.3229451\n",
      "\tspeed: 0.0430s/iter; left time: 246.2402s\n",
      "\titers: 600, epoch: 4 | loss: 0.2853895\n",
      "\tspeed: 0.0430s/iter; left time: 241.6585s\n",
      "\titers: 700, epoch: 4 | loss: 0.3258071\n",
      "\tspeed: 0.0430s/iter; left time: 237.3710s\n",
      "\titers: 800, epoch: 4 | loss: 0.3050725\n",
      "\tspeed: 0.0430s/iter; left time: 233.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 889 | Train Loss: 0.3247702 Vali Loss: 0.8104095 Test Loss: 1.0395817\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8046845197677612, rmse:0.8970420956611633, mae:0.64595627784729, rse:0.7106161713600159\n",
      "Original data scale mse:34226872.0, rmse:5850.37353515625, mae:3899.109619140625, rse:0.2914937138557434\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6304526\n",
      "\tspeed: 0.0683s/iter; left time: 602.9611s\n",
      "\titers: 200, epoch: 1 | loss: 0.6647899\n",
      "\tspeed: 0.0426s/iter; left time: 371.7983s\n",
      "\titers: 300, epoch: 1 | loss: 0.5844824\n",
      "\tspeed: 0.0424s/iter; left time: 365.9783s\n",
      "\titers: 400, epoch: 1 | loss: 0.6426585\n",
      "\tspeed: 0.0424s/iter; left time: 361.7525s\n",
      "\titers: 500, epoch: 1 | loss: 0.6155174\n",
      "\tspeed: 0.0425s/iter; left time: 358.2786s\n",
      "\titers: 600, epoch: 1 | loss: 0.6662328\n",
      "\tspeed: 0.0425s/iter; left time: 353.9473s\n",
      "\titers: 700, epoch: 1 | loss: 0.5895321\n",
      "\tspeed: 0.0424s/iter; left time: 349.1764s\n",
      "\titers: 800, epoch: 1 | loss: 0.5740807\n",
      "\tspeed: 0.0424s/iter; left time: 344.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 893 | Train Loss: 0.6036704 Vali Loss: 0.4339436 Test Loss: 0.4720358\n",
      "Validation loss decreased (inf --> 0.433944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6498488\n",
      "\tspeed: 0.1531s/iter; left time: 1215.5868s\n",
      "\titers: 200, epoch: 2 | loss: 0.6380902\n",
      "\tspeed: 0.0425s/iter; left time: 332.7322s\n",
      "\titers: 300, epoch: 2 | loss: 0.5367553\n",
      "\tspeed: 0.0424s/iter; left time: 328.2144s\n",
      "\titers: 400, epoch: 2 | loss: 0.5489156\n",
      "\tspeed: 0.0424s/iter; left time: 323.6393s\n",
      "\titers: 500, epoch: 2 | loss: 0.5260842\n",
      "\tspeed: 0.0425s/iter; left time: 320.3660s\n",
      "\titers: 600, epoch: 2 | loss: 0.5337558\n",
      "\tspeed: 0.0423s/iter; left time: 314.5709s\n",
      "\titers: 700, epoch: 2 | loss: 0.5897491\n",
      "\tspeed: 0.0424s/iter; left time: 311.4112s\n",
      "\titers: 800, epoch: 2 | loss: 0.5088241\n",
      "\tspeed: 0.0425s/iter; left time: 307.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.5554133 Vali Loss: 0.4260295 Test Loss: 0.4780068\n",
      "Validation loss decreased (0.433944 --> 0.426029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4309910\n",
      "\tspeed: 0.1533s/iter; left time: 1079.7285s\n",
      "\titers: 200, epoch: 3 | loss: 0.5291359\n",
      "\tspeed: 0.0423s/iter; left time: 293.7864s\n",
      "\titers: 300, epoch: 3 | loss: 0.4883050\n",
      "\tspeed: 0.0423s/iter; left time: 289.7883s\n",
      "\titers: 400, epoch: 3 | loss: 0.4879614\n",
      "\tspeed: 0.0424s/iter; left time: 286.2550s\n",
      "\titers: 500, epoch: 3 | loss: 0.4847891\n",
      "\tspeed: 0.0424s/iter; left time: 282.0516s\n",
      "\titers: 600, epoch: 3 | loss: 0.5293490\n",
      "\tspeed: 0.0424s/iter; left time: 277.6713s\n",
      "\titers: 700, epoch: 3 | loss: 0.4065211\n",
      "\tspeed: 0.0424s/iter; left time: 273.1066s\n",
      "\titers: 800, epoch: 3 | loss: 0.5855716\n",
      "\tspeed: 0.0424s/iter; left time: 269.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.5231845 Vali Loss: 0.4079853 Test Loss: 0.4513101\n",
      "Validation loss decreased (0.426029 --> 0.407985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5018351\n",
      "\tspeed: 0.1527s/iter; left time: 939.2845s\n",
      "\titers: 200, epoch: 4 | loss: 0.4895697\n",
      "\tspeed: 0.0424s/iter; left time: 256.6275s\n",
      "\titers: 300, epoch: 4 | loss: 0.5145022\n",
      "\tspeed: 0.0424s/iter; left time: 252.0868s\n",
      "\titers: 400, epoch: 4 | loss: 0.4483052\n",
      "\tspeed: 0.0424s/iter; left time: 248.3293s\n",
      "\titers: 500, epoch: 4 | loss: 0.6109250\n",
      "\tspeed: 0.0424s/iter; left time: 243.7719s\n",
      "\titers: 600, epoch: 4 | loss: 0.4802767\n",
      "\tspeed: 0.0424s/iter; left time: 239.4784s\n",
      "\titers: 700, epoch: 4 | loss: 0.5246813\n",
      "\tspeed: 0.0424s/iter; left time: 235.4710s\n",
      "\titers: 800, epoch: 4 | loss: 0.5321484\n",
      "\tspeed: 0.0423s/iter; left time: 230.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5150838 Vali Loss: 0.4270419 Test Loss: 0.4700336\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4871208\n",
      "\tspeed: 0.1525s/iter; left time: 801.8416s\n",
      "\titers: 200, epoch: 5 | loss: 0.4352125\n",
      "\tspeed: 0.0425s/iter; left time: 219.2843s\n",
      "\titers: 300, epoch: 5 | loss: 0.5049165\n",
      "\tspeed: 0.0424s/iter; left time: 214.2495s\n",
      "\titers: 400, epoch: 5 | loss: 0.4666814\n",
      "\tspeed: 0.0424s/iter; left time: 210.3353s\n",
      "\titers: 500, epoch: 5 | loss: 0.5018875\n",
      "\tspeed: 0.0426s/iter; left time: 206.7576s\n",
      "\titers: 600, epoch: 5 | loss: 0.4701836\n",
      "\tspeed: 0.0425s/iter; left time: 202.3015s\n",
      "\titers: 700, epoch: 5 | loss: 0.5009473\n",
      "\tspeed: 0.0424s/iter; left time: 197.7662s\n",
      "\titers: 800, epoch: 5 | loss: 0.4748931\n",
      "\tspeed: 0.0424s/iter; left time: 193.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.5074182 Vali Loss: 0.4152391 Test Loss: 0.4634299\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4203286\n",
      "\tspeed: 0.1519s/iter; left time: 663.1395s\n",
      "\titers: 200, epoch: 6 | loss: 0.5329765\n",
      "\tspeed: 0.0424s/iter; left time: 180.8140s\n",
      "\titers: 300, epoch: 6 | loss: 0.4321128\n",
      "\tspeed: 0.0422s/iter; left time: 175.9150s\n",
      "\titers: 400, epoch: 6 | loss: 0.4385991\n",
      "\tspeed: 0.0424s/iter; left time: 172.3634s\n",
      "\titers: 500, epoch: 6 | loss: 0.4512403\n",
      "\tspeed: 0.0424s/iter; left time: 168.1754s\n",
      "\titers: 600, epoch: 6 | loss: 0.4838388\n",
      "\tspeed: 0.0425s/iter; left time: 164.1365s\n",
      "\titers: 700, epoch: 6 | loss: 0.4213574\n",
      "\tspeed: 0.0424s/iter; left time: 159.6564s\n",
      "\titers: 800, epoch: 6 | loss: 0.4768175\n",
      "\tspeed: 0.0425s/iter; left time: 155.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.4807680 Vali Loss: 0.4451250 Test Loss: 0.4856848\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45131009817123413, rmse:0.6717962026596069, mae:0.44347333908081055, rse:0.5316842198371887\n",
      "Original data scale mse:17305828.0, rmse:4160.02734375, mae:2609.172119140625, rse:0.20684495568275452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7208875\n",
      "\tspeed: 0.0446s/iter; left time: 394.2604s\n",
      "\titers: 200, epoch: 1 | loss: 0.5653324\n",
      "\tspeed: 0.0424s/iter; left time: 370.4031s\n",
      "\titers: 300, epoch: 1 | loss: 0.5747016\n",
      "\tspeed: 0.0424s/iter; left time: 366.2074s\n",
      "\titers: 400, epoch: 1 | loss: 0.5493563\n",
      "\tspeed: 0.0424s/iter; left time: 362.0482s\n",
      "\titers: 500, epoch: 1 | loss: 0.5951235\n",
      "\tspeed: 0.0424s/iter; left time: 357.8883s\n",
      "\titers: 600, epoch: 1 | loss: 0.5839962\n",
      "\tspeed: 0.0424s/iter; left time: 353.3596s\n",
      "\titers: 700, epoch: 1 | loss: 0.5883811\n",
      "\tspeed: 0.0426s/iter; left time: 350.4200s\n",
      "\titers: 800, epoch: 1 | loss: 0.6175978\n",
      "\tspeed: 0.0425s/iter; left time: 345.2648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.6029870 Vali Loss: 0.4296014 Test Loss: 0.4724245\n",
      "Validation loss decreased (inf --> 0.429601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5956693\n",
      "\tspeed: 0.1548s/iter; left time: 1228.5427s\n",
      "\titers: 200, epoch: 2 | loss: 0.6147557\n",
      "\tspeed: 0.0424s/iter; left time: 332.5428s\n",
      "\titers: 300, epoch: 2 | loss: 0.5424049\n",
      "\tspeed: 0.0425s/iter; left time: 328.9423s\n",
      "\titers: 400, epoch: 2 | loss: 0.5658551\n",
      "\tspeed: 0.0424s/iter; left time: 323.7582s\n",
      "\titers: 500, epoch: 2 | loss: 0.5137780\n",
      "\tspeed: 0.0424s/iter; left time: 319.8523s\n",
      "\titers: 600, epoch: 2 | loss: 0.5194274\n",
      "\tspeed: 0.0426s/iter; left time: 316.5765s\n",
      "\titers: 700, epoch: 2 | loss: 0.4312453\n",
      "\tspeed: 0.0424s/iter; left time: 311.0337s\n",
      "\titers: 800, epoch: 2 | loss: 0.5377391\n",
      "\tspeed: 0.0425s/iter; left time: 307.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.5573271 Vali Loss: 0.4067231 Test Loss: 0.4517895\n",
      "Validation loss decreased (0.429601 --> 0.406723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4817174\n",
      "\tspeed: 0.1552s/iter; left time: 1093.4068s\n",
      "\titers: 200, epoch: 3 | loss: 0.5098557\n",
      "\tspeed: 0.0424s/iter; left time: 294.5240s\n",
      "\titers: 300, epoch: 3 | loss: 0.4692909\n",
      "\tspeed: 0.0425s/iter; left time: 290.6536s\n",
      "\titers: 400, epoch: 3 | loss: 0.4773871\n",
      "\tspeed: 0.0425s/iter; left time: 286.4687s\n",
      "\titers: 500, epoch: 3 | loss: 0.5546513\n",
      "\tspeed: 0.0426s/iter; left time: 282.9506s\n",
      "\titers: 600, epoch: 3 | loss: 0.5032052\n",
      "\tspeed: 0.0422s/iter; left time: 276.2888s\n",
      "\titers: 700, epoch: 3 | loss: 0.4395917\n",
      "\tspeed: 0.0428s/iter; left time: 275.6103s\n",
      "\titers: 800, epoch: 3 | loss: 0.5026121\n",
      "\tspeed: 0.0424s/iter; left time: 269.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.5239807 Vali Loss: 0.4195922 Test Loss: 0.4513127\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5083061\n",
      "\tspeed: 0.1526s/iter; left time: 938.8968s\n",
      "\titers: 200, epoch: 4 | loss: 0.4650363\n",
      "\tspeed: 0.0425s/iter; left time: 256.9514s\n",
      "\titers: 300, epoch: 4 | loss: 0.4765425\n",
      "\tspeed: 0.0424s/iter; left time: 252.5899s\n",
      "\titers: 400, epoch: 4 | loss: 0.5530409\n",
      "\tspeed: 0.0426s/iter; left time: 249.0418s\n",
      "\titers: 500, epoch: 4 | loss: 0.5370450\n",
      "\tspeed: 0.0425s/iter; left time: 244.3009s\n",
      "\titers: 600, epoch: 4 | loss: 0.6664306\n",
      "\tspeed: 0.0425s/iter; left time: 240.1234s\n",
      "\titers: 700, epoch: 4 | loss: 0.4789167\n",
      "\tspeed: 0.0425s/iter; left time: 235.7937s\n",
      "\titers: 800, epoch: 4 | loss: 0.5579545\n",
      "\tspeed: 0.0425s/iter; left time: 231.5205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.5211855 Vali Loss: 0.4197213 Test Loss: 0.4598895\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4809563\n",
      "\tspeed: 0.1527s/iter; left time: 802.9587s\n",
      "\titers: 200, epoch: 5 | loss: 0.4911440\n",
      "\tspeed: 0.0425s/iter; left time: 219.3020s\n",
      "\titers: 300, epoch: 5 | loss: 0.4891045\n",
      "\tspeed: 0.0425s/iter; left time: 214.8820s\n",
      "\titers: 400, epoch: 5 | loss: 0.5189811\n",
      "\tspeed: 0.0425s/iter; left time: 210.5983s\n",
      "\titers: 500, epoch: 5 | loss: 0.4235159\n",
      "\tspeed: 0.0424s/iter; left time: 206.1090s\n",
      "\titers: 600, epoch: 5 | loss: 0.5044044\n",
      "\tspeed: 0.0424s/iter; left time: 201.8627s\n",
      "\titers: 700, epoch: 5 | loss: 0.4964522\n",
      "\tspeed: 0.0425s/iter; left time: 198.0154s\n",
      "\titers: 800, epoch: 5 | loss: 0.5055836\n",
      "\tspeed: 0.0427s/iter; left time: 194.4971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.4999788 Vali Loss: 0.4229821 Test Loss: 0.4707361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4517894387245178, rmse:0.6721528172492981, mae:0.44926226139068604, rse:0.531966507434845\n",
      "Original data scale mse:17345650.0, rmse:4164.81103515625, mae:2657.558349609375, rse:0.20708277821540833\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8564085\n",
      "\tspeed: 0.0680s/iter; left time: 598.7694s\n",
      "\titers: 200, epoch: 1 | loss: 0.7276816\n",
      "\tspeed: 0.0427s/iter; left time: 372.1279s\n",
      "\titers: 300, epoch: 1 | loss: 0.7469753\n",
      "\tspeed: 0.0428s/iter; left time: 368.4669s\n",
      "\titers: 400, epoch: 1 | loss: 0.6862437\n",
      "\tspeed: 0.0428s/iter; left time: 363.9586s\n",
      "\titers: 500, epoch: 1 | loss: 0.7447299\n",
      "\tspeed: 0.0428s/iter; left time: 359.6042s\n",
      "\titers: 600, epoch: 1 | loss: 0.6932904\n",
      "\tspeed: 0.0428s/iter; left time: 355.4343s\n",
      "\titers: 700, epoch: 1 | loss: 0.7336010\n",
      "\tspeed: 0.0428s/iter; left time: 351.2675s\n",
      "\titers: 800, epoch: 1 | loss: 0.7876992\n",
      "\tspeed: 0.0427s/iter; left time: 346.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.7489301 Vali Loss: 0.6496119 Test Loss: 0.7595298\n",
      "Validation loss decreased (inf --> 0.649612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7455665\n",
      "\tspeed: 0.1529s/iter; left time: 1211.0281s\n",
      "\titers: 200, epoch: 2 | loss: 0.6923752\n",
      "\tspeed: 0.0428s/iter; left time: 334.4074s\n",
      "\titers: 300, epoch: 2 | loss: 0.6735732\n",
      "\tspeed: 0.0428s/iter; left time: 330.3872s\n",
      "\titers: 400, epoch: 2 | loss: 0.7412770\n",
      "\tspeed: 0.0428s/iter; left time: 326.0852s\n",
      "\titers: 500, epoch: 2 | loss: 0.6404418\n",
      "\tspeed: 0.0428s/iter; left time: 321.7587s\n",
      "\titers: 600, epoch: 2 | loss: 0.6246042\n",
      "\tspeed: 0.0428s/iter; left time: 317.6922s\n",
      "\titers: 700, epoch: 2 | loss: 0.6204208\n",
      "\tspeed: 0.0428s/iter; left time: 313.1966s\n",
      "\titers: 800, epoch: 2 | loss: 0.7364731\n",
      "\tspeed: 0.0428s/iter; left time: 309.1296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.7072706 Vali Loss: 0.6384751 Test Loss: 0.7534525\n",
      "Validation loss decreased (0.649612 --> 0.638475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6394007\n",
      "\tspeed: 0.1540s/iter; left time: 1082.3165s\n",
      "\titers: 200, epoch: 3 | loss: 0.6838906\n",
      "\tspeed: 0.0427s/iter; left time: 296.1545s\n",
      "\titers: 300, epoch: 3 | loss: 0.6923274\n",
      "\tspeed: 0.0427s/iter; left time: 291.7429s\n",
      "\titers: 400, epoch: 3 | loss: 0.6940130\n",
      "\tspeed: 0.0427s/iter; left time: 287.3802s\n",
      "\titers: 500, epoch: 3 | loss: 0.6825750\n",
      "\tspeed: 0.0428s/iter; left time: 283.4176s\n",
      "\titers: 600, epoch: 3 | loss: 0.6074114\n",
      "\tspeed: 0.0428s/iter; left time: 279.4834s\n",
      "\titers: 700, epoch: 3 | loss: 0.6975672\n",
      "\tspeed: 0.0427s/iter; left time: 274.6385s\n",
      "\titers: 800, epoch: 3 | loss: 0.5953272\n",
      "\tspeed: 0.0429s/iter; left time: 271.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.6643052 Vali Loss: 0.6965610 Test Loss: 0.8775428\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6318092\n",
      "\tspeed: 0.1515s/iter; left time: 929.6129s\n",
      "\titers: 200, epoch: 4 | loss: 0.6489524\n",
      "\tspeed: 0.0428s/iter; left time: 258.2389s\n",
      "\titers: 300, epoch: 4 | loss: 0.6114253\n",
      "\tspeed: 0.0428s/iter; left time: 254.2544s\n",
      "\titers: 400, epoch: 4 | loss: 0.6083454\n",
      "\tspeed: 0.0428s/iter; left time: 250.0377s\n",
      "\titers: 500, epoch: 4 | loss: 0.5923827\n",
      "\tspeed: 0.0428s/iter; left time: 245.5615s\n",
      "\titers: 600, epoch: 4 | loss: 0.6142623\n",
      "\tspeed: 0.0428s/iter; left time: 241.5447s\n",
      "\titers: 700, epoch: 4 | loss: 0.5633094\n",
      "\tspeed: 0.0428s/iter; left time: 237.1731s\n",
      "\titers: 800, epoch: 4 | loss: 0.5035748\n",
      "\tspeed: 0.0427s/iter; left time: 232.4046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 891 | Train Loss: 0.5925956 Vali Loss: 0.7727130 Test Loss: 0.9328302\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5578295\n",
      "\tspeed: 0.1509s/iter; left time: 792.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.5414807\n",
      "\tspeed: 0.0427s/iter; left time: 219.8039s\n",
      "\titers: 300, epoch: 5 | loss: 0.5636502\n",
      "\tspeed: 0.0427s/iter; left time: 215.6220s\n",
      "\titers: 400, epoch: 5 | loss: 0.5362424\n",
      "\tspeed: 0.0427s/iter; left time: 211.3051s\n",
      "\titers: 500, epoch: 5 | loss: 0.4829004\n",
      "\tspeed: 0.0427s/iter; left time: 207.0390s\n",
      "\titers: 600, epoch: 5 | loss: 0.4771944\n",
      "\tspeed: 0.0428s/iter; left time: 203.1562s\n",
      "\titers: 700, epoch: 5 | loss: 0.4571800\n",
      "\tspeed: 0.0428s/iter; left time: 199.0780s\n",
      "\titers: 800, epoch: 5 | loss: 0.4408690\n",
      "\tspeed: 0.0428s/iter; left time: 194.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.5061452 Vali Loss: 0.8498826 Test Loss: 0.9658751\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7534525394439697, rmse:0.8680164217948914, mae:0.6171937584877014, rse:0.6884440183639526\n",
      "Original data scale mse:31262294.0, rmse:5591.26953125, mae:3673.384033203125, rse:0.2784472107887268\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7373669\n",
      "\tspeed: 0.0446s/iter; left time: 392.8948s\n",
      "\titers: 200, epoch: 1 | loss: 0.6961303\n",
      "\tspeed: 0.0427s/iter; left time: 372.2155s\n",
      "\titers: 300, epoch: 1 | loss: 0.8107926\n",
      "\tspeed: 0.0427s/iter; left time: 367.3601s\n",
      "\titers: 400, epoch: 1 | loss: 0.8115740\n",
      "\tspeed: 0.0425s/iter; left time: 361.4023s\n",
      "\titers: 500, epoch: 1 | loss: 0.6878027\n",
      "\tspeed: 0.0426s/iter; left time: 358.4285s\n",
      "\titers: 600, epoch: 1 | loss: 0.7807432\n",
      "\tspeed: 0.0428s/iter; left time: 355.4065s\n",
      "\titers: 700, epoch: 1 | loss: 0.7302145\n",
      "\tspeed: 0.0427s/iter; left time: 350.7357s\n",
      "\titers: 800, epoch: 1 | loss: 0.7058792\n",
      "\tspeed: 0.0428s/iter; left time: 347.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.7482038 Vali Loss: 0.6501760 Test Loss: 0.7607240\n",
      "Validation loss decreased (inf --> 0.650176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7201242\n",
      "\tspeed: 0.1530s/iter; left time: 1211.3649s\n",
      "\titers: 200, epoch: 2 | loss: 0.6755181\n",
      "\tspeed: 0.0427s/iter; left time: 334.0633s\n",
      "\titers: 300, epoch: 2 | loss: 0.7100089\n",
      "\tspeed: 0.0428s/iter; left time: 330.0868s\n",
      "\titers: 400, epoch: 2 | loss: 0.6997021\n",
      "\tspeed: 0.0428s/iter; left time: 325.8922s\n",
      "\titers: 500, epoch: 2 | loss: 0.6204954\n",
      "\tspeed: 0.0428s/iter; left time: 321.5709s\n",
      "\titers: 600, epoch: 2 | loss: 0.6984884\n",
      "\tspeed: 0.0427s/iter; left time: 316.7871s\n",
      "\titers: 700, epoch: 2 | loss: 0.7466449\n",
      "\tspeed: 0.0427s/iter; left time: 312.8736s\n",
      "\titers: 800, epoch: 2 | loss: 0.6878006\n",
      "\tspeed: 0.0428s/iter; left time: 308.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.7087464 Vali Loss: 0.6216077 Test Loss: 0.7755335\n",
      "Validation loss decreased (0.650176 --> 0.621608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7080504\n",
      "\tspeed: 0.1542s/iter; left time: 1083.7248s\n",
      "\titers: 200, epoch: 3 | loss: 0.6345065\n",
      "\tspeed: 0.0427s/iter; left time: 296.0350s\n",
      "\titers: 300, epoch: 3 | loss: 0.6015949\n",
      "\tspeed: 0.0427s/iter; left time: 291.8595s\n",
      "\titers: 400, epoch: 3 | loss: 0.6569807\n",
      "\tspeed: 0.0428s/iter; left time: 287.9846s\n",
      "\titers: 500, epoch: 3 | loss: 0.6287000\n",
      "\tspeed: 0.0429s/iter; left time: 284.1811s\n",
      "\titers: 600, epoch: 3 | loss: 0.6277207\n",
      "\tspeed: 0.0428s/iter; left time: 279.3057s\n",
      "\titers: 700, epoch: 3 | loss: 0.6814144\n",
      "\tspeed: 0.0428s/iter; left time: 275.0404s\n",
      "\titers: 800, epoch: 3 | loss: 0.6294596\n",
      "\tspeed: 0.0428s/iter; left time: 270.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.6558177 Vali Loss: 0.6887955 Test Loss: 0.8492430\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6006249\n",
      "\tspeed: 0.1517s/iter; left time: 931.1551s\n",
      "\titers: 200, epoch: 4 | loss: 0.5826002\n",
      "\tspeed: 0.0428s/iter; left time: 258.2005s\n",
      "\titers: 300, epoch: 4 | loss: 0.5727263\n",
      "\tspeed: 0.0428s/iter; left time: 254.3509s\n",
      "\titers: 400, epoch: 4 | loss: 0.5923206\n",
      "\tspeed: 0.0428s/iter; left time: 249.8124s\n",
      "\titers: 500, epoch: 4 | loss: 0.5391967\n",
      "\tspeed: 0.0427s/iter; left time: 245.1838s\n",
      "\titers: 600, epoch: 4 | loss: 0.5598037\n",
      "\tspeed: 0.0427s/iter; left time: 240.8971s\n",
      "\titers: 700, epoch: 4 | loss: 0.5872183\n",
      "\tspeed: 0.0427s/iter; left time: 236.5888s\n",
      "\titers: 800, epoch: 4 | loss: 0.5201843\n",
      "\tspeed: 0.0428s/iter; left time: 232.7306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.5749528 Vali Loss: 0.7418606 Test Loss: 0.9283234\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5154231\n",
      "\tspeed: 0.1517s/iter; left time: 795.9826s\n",
      "\titers: 200, epoch: 5 | loss: 0.4713488\n",
      "\tspeed: 0.0427s/iter; left time: 219.9947s\n",
      "\titers: 300, epoch: 5 | loss: 0.4894331\n",
      "\tspeed: 0.0428s/iter; left time: 215.8808s\n",
      "\titers: 400, epoch: 5 | loss: 0.4998905\n",
      "\tspeed: 0.0427s/iter; left time: 211.4325s\n",
      "\titers: 500, epoch: 5 | loss: 0.4573486\n",
      "\tspeed: 0.0428s/iter; left time: 207.3145s\n",
      "\titers: 600, epoch: 5 | loss: 0.4486329\n",
      "\tspeed: 0.0428s/iter; left time: 202.9889s\n",
      "\titers: 700, epoch: 5 | loss: 0.4750489\n",
      "\tspeed: 0.0428s/iter; left time: 198.6629s\n",
      "\titers: 800, epoch: 5 | loss: 0.4578401\n",
      "\tspeed: 0.0427s/iter; left time: 194.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.4898551 Vali Loss: 0.7914582 Test Loss: 0.9788902\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7755337357521057, rmse:0.880643904209137, mae:0.6255269646644592, rse:0.6984591484069824\n",
      "Original data scale mse:33044252.0, rmse:5748.4130859375, mae:3757.29541015625, rse:0.2862730324268341\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8679006\n",
      "\tspeed: 0.0679s/iter; left time: 597.0260s\n",
      "\titers: 200, epoch: 1 | loss: 0.7743645\n",
      "\tspeed: 0.0433s/iter; left time: 376.1120s\n",
      "\titers: 300, epoch: 1 | loss: 0.7822117\n",
      "\tspeed: 0.0432s/iter; left time: 371.4445s\n",
      "\titers: 400, epoch: 1 | loss: 0.8378281\n",
      "\tspeed: 0.0435s/iter; left time: 369.2035s\n",
      "\titers: 500, epoch: 1 | loss: 0.8232630\n",
      "\tspeed: 0.0433s/iter; left time: 363.1095s\n",
      "\titers: 600, epoch: 1 | loss: 0.7636237\n",
      "\tspeed: 0.0433s/iter; left time: 358.8792s\n",
      "\titers: 700, epoch: 1 | loss: 0.7548945\n",
      "\tspeed: 0.0433s/iter; left time: 354.7984s\n",
      "\titers: 800, epoch: 1 | loss: 0.7713766\n",
      "\tspeed: 0.0433s/iter; left time: 350.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.7772274 Vali Loss: 0.6790550 Test Loss: 0.8057779\n",
      "Validation loss decreased (inf --> 0.679055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7821077\n",
      "\tspeed: 0.1550s/iter; left time: 1224.7803s\n",
      "\titers: 200, epoch: 2 | loss: 0.7020079\n",
      "\tspeed: 0.0434s/iter; left time: 338.3973s\n",
      "\titers: 300, epoch: 2 | loss: 0.8012208\n",
      "\tspeed: 0.0435s/iter; left time: 334.7136s\n",
      "\titers: 400, epoch: 2 | loss: 0.7271333\n",
      "\tspeed: 0.0433s/iter; left time: 329.0446s\n",
      "\titers: 500, epoch: 2 | loss: 0.7285502\n",
      "\tspeed: 0.0433s/iter; left time: 325.2045s\n",
      "\titers: 600, epoch: 2 | loss: 0.7326428\n",
      "\tspeed: 0.0433s/iter; left time: 320.4505s\n",
      "\titers: 700, epoch: 2 | loss: 0.6793472\n",
      "\tspeed: 0.0433s/iter; left time: 316.2541s\n",
      "\titers: 800, epoch: 2 | loss: 0.7332686\n",
      "\tspeed: 0.0433s/iter; left time: 311.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.7356485 Vali Loss: 0.6576813 Test Loss: 0.8276157\n",
      "Validation loss decreased (0.679055 --> 0.657681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6861941\n",
      "\tspeed: 0.1559s/iter; left time: 1093.2852s\n",
      "\titers: 200, epoch: 3 | loss: 0.6369764\n",
      "\tspeed: 0.0434s/iter; left time: 300.2822s\n",
      "\titers: 300, epoch: 3 | loss: 0.6813426\n",
      "\tspeed: 0.0433s/iter; left time: 295.1944s\n",
      "\titers: 400, epoch: 3 | loss: 0.6887080\n",
      "\tspeed: 0.0434s/iter; left time: 291.2259s\n",
      "\titers: 500, epoch: 3 | loss: 0.7160903\n",
      "\tspeed: 0.0433s/iter; left time: 286.5825s\n",
      "\titers: 600, epoch: 3 | loss: 0.6524235\n",
      "\tspeed: 0.0433s/iter; left time: 282.3045s\n",
      "\titers: 700, epoch: 3 | loss: 0.6551255\n",
      "\tspeed: 0.0433s/iter; left time: 277.3797s\n",
      "\titers: 800, epoch: 3 | loss: 0.6208397\n",
      "\tspeed: 0.0432s/iter; left time: 273.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.6604352 Vali Loss: 0.7732214 Test Loss: 0.9868738\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5560720\n",
      "\tspeed: 0.1521s/iter; left time: 931.1967s\n",
      "\titers: 200, epoch: 4 | loss: 0.5402793\n",
      "\tspeed: 0.0433s/iter; left time: 260.7411s\n",
      "\titers: 300, epoch: 4 | loss: 0.6283324\n",
      "\tspeed: 0.0433s/iter; left time: 256.3194s\n",
      "\titers: 400, epoch: 4 | loss: 0.5678048\n",
      "\tspeed: 0.0433s/iter; left time: 252.1106s\n",
      "\titers: 500, epoch: 4 | loss: 0.5673718\n",
      "\tspeed: 0.0433s/iter; left time: 247.9093s\n",
      "\titers: 600, epoch: 4 | loss: 0.5018236\n",
      "\tspeed: 0.0433s/iter; left time: 243.5630s\n",
      "\titers: 700, epoch: 4 | loss: 0.5377899\n",
      "\tspeed: 0.0433s/iter; left time: 239.4047s\n",
      "\titers: 800, epoch: 4 | loss: 0.5352262\n",
      "\tspeed: 0.0434s/iter; left time: 235.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.5602547 Vali Loss: 0.7991609 Test Loss: 1.1161594\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5087005\n",
      "\tspeed: 0.1530s/iter; left time: 800.7100s\n",
      "\titers: 200, epoch: 5 | loss: 0.4705424\n",
      "\tspeed: 0.0433s/iter; left time: 222.3024s\n",
      "\titers: 300, epoch: 5 | loss: 0.4730842\n",
      "\tspeed: 0.0434s/iter; left time: 218.5353s\n",
      "\titers: 400, epoch: 5 | loss: 0.4877660\n",
      "\tspeed: 0.0433s/iter; left time: 213.8698s\n",
      "\titers: 500, epoch: 5 | loss: 0.4700000\n",
      "\tspeed: 0.0434s/iter; left time: 209.7451s\n",
      "\titers: 600, epoch: 5 | loss: 0.4700326\n",
      "\tspeed: 0.0433s/iter; left time: 204.9263s\n",
      "\titers: 700, epoch: 5 | loss: 0.4628400\n",
      "\tspeed: 0.0434s/iter; left time: 201.0596s\n",
      "\titers: 800, epoch: 5 | loss: 0.4603879\n",
      "\tspeed: 0.0433s/iter; left time: 196.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4696992 Vali Loss: 0.8641824 Test Loss: 1.1385818\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8276155591011047, rmse:0.909733772277832, mae:0.6518822908401489, rse:0.7206702828407288\n",
      "Original data scale mse:35287100.0, rmse:5940.29443359375, mae:3912.64697265625, rse:0.2959740161895752\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8919598\n",
      "\tspeed: 0.0449s/iter; left time: 394.7934s\n",
      "\titers: 200, epoch: 1 | loss: 0.8255026\n",
      "\tspeed: 0.0432s/iter; left time: 375.7960s\n",
      "\titers: 300, epoch: 1 | loss: 0.8588480\n",
      "\tspeed: 0.0432s/iter; left time: 371.0216s\n",
      "\titers: 400, epoch: 1 | loss: 0.8268682\n",
      "\tspeed: 0.0433s/iter; left time: 367.3549s\n",
      "\titers: 500, epoch: 1 | loss: 0.7757027\n",
      "\tspeed: 0.0433s/iter; left time: 362.9946s\n",
      "\titers: 600, epoch: 1 | loss: 0.6946961\n",
      "\tspeed: 0.0433s/iter; left time: 359.0086s\n",
      "\titers: 700, epoch: 1 | loss: 0.7522021\n",
      "\tspeed: 0.0433s/iter; left time: 354.6110s\n",
      "\titers: 800, epoch: 1 | loss: 0.7110764\n",
      "\tspeed: 0.0433s/iter; left time: 350.2308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.7784579 Vali Loss: 0.6762899 Test Loss: 0.8039310\n",
      "Validation loss decreased (inf --> 0.676290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7776949\n",
      "\tspeed: 0.1558s/iter; left time: 1230.8541s\n",
      "\titers: 200, epoch: 2 | loss: 0.7495913\n",
      "\tspeed: 0.0433s/iter; left time: 338.1045s\n",
      "\titers: 300, epoch: 2 | loss: 0.7632322\n",
      "\tspeed: 0.0432s/iter; left time: 333.0286s\n",
      "\titers: 400, epoch: 2 | loss: 0.7406695\n",
      "\tspeed: 0.0433s/iter; left time: 329.1651s\n",
      "\titers: 500, epoch: 2 | loss: 0.7516730\n",
      "\tspeed: 0.0432s/iter; left time: 324.3799s\n",
      "\titers: 600, epoch: 2 | loss: 0.7519017\n",
      "\tspeed: 0.0433s/iter; left time: 320.4085s\n",
      "\titers: 700, epoch: 2 | loss: 0.7013571\n",
      "\tspeed: 0.0433s/iter; left time: 316.3720s\n",
      "\titers: 800, epoch: 2 | loss: 0.6977748\n",
      "\tspeed: 0.0433s/iter; left time: 311.8371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.7361888 Vali Loss: 0.6949371 Test Loss: 0.8629977\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6662261\n",
      "\tspeed: 0.1525s/iter; left time: 1069.2643s\n",
      "\titers: 200, epoch: 3 | loss: 0.6339747\n",
      "\tspeed: 0.0433s/iter; left time: 299.5387s\n",
      "\titers: 300, epoch: 3 | loss: 0.7117482\n",
      "\tspeed: 0.0433s/iter; left time: 294.7726s\n",
      "\titers: 400, epoch: 3 | loss: 0.7264873\n",
      "\tspeed: 0.0433s/iter; left time: 290.5272s\n",
      "\titers: 500, epoch: 3 | loss: 0.6518920\n",
      "\tspeed: 0.0434s/iter; left time: 286.7612s\n",
      "\titers: 600, epoch: 3 | loss: 0.6870541\n",
      "\tspeed: 0.0433s/iter; left time: 282.0510s\n",
      "\titers: 700, epoch: 3 | loss: 0.6374604\n",
      "\tspeed: 0.0434s/iter; left time: 278.2254s\n",
      "\titers: 800, epoch: 3 | loss: 0.6561266\n",
      "\tspeed: 0.0434s/iter; left time: 273.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.6618887 Vali Loss: 0.7081003 Test Loss: 0.9726987\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6204436\n",
      "\tspeed: 0.1539s/iter; left time: 942.5101s\n",
      "\titers: 200, epoch: 4 | loss: 0.5560814\n",
      "\tspeed: 0.0433s/iter; left time: 260.8545s\n",
      "\titers: 300, epoch: 4 | loss: 0.5717813\n",
      "\tspeed: 0.0432s/iter; left time: 256.1611s\n",
      "\titers: 400, epoch: 4 | loss: 0.5512108\n",
      "\tspeed: 0.0433s/iter; left time: 251.9285s\n",
      "\titers: 500, epoch: 4 | loss: 0.5558363\n",
      "\tspeed: 0.0435s/iter; left time: 248.7970s\n",
      "\titers: 600, epoch: 4 | loss: 0.5101167\n",
      "\tspeed: 0.0433s/iter; left time: 243.5595s\n",
      "\titers: 700, epoch: 4 | loss: 0.5733330\n",
      "\tspeed: 0.0433s/iter; left time: 239.1401s\n",
      "\titers: 800, epoch: 4 | loss: 0.5397598\n",
      "\tspeed: 0.0433s/iter; left time: 234.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.5612400 Vali Loss: 0.7595485 Test Loss: 1.0782422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8039314150810242, rmse:0.8966222405433655, mae:0.6451408863067627, rse:0.7102835774421692\n",
      "Original data scale mse:34170808.0, rmse:5845.580078125, mae:3891.957763671875, rse:0.2912548780441284\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4695036\n",
      "\tspeed: 0.0677s/iter; left time: 597.7402s\n",
      "\titers: 200, epoch: 1 | loss: 0.4849952\n",
      "\tspeed: 0.0426s/iter; left time: 371.9770s\n",
      "\titers: 300, epoch: 1 | loss: 0.4187118\n",
      "\tspeed: 0.0427s/iter; left time: 368.5911s\n",
      "\titers: 400, epoch: 1 | loss: 0.4342759\n",
      "\tspeed: 0.0424s/iter; left time: 362.0456s\n",
      "\titers: 500, epoch: 1 | loss: 0.4137512\n",
      "\tspeed: 0.0424s/iter; left time: 357.4461s\n",
      "\titers: 600, epoch: 1 | loss: 0.4539363\n",
      "\tspeed: 0.0424s/iter; left time: 352.9844s\n",
      "\titers: 700, epoch: 1 | loss: 0.4049172\n",
      "\tspeed: 0.0424s/iter; left time: 349.1495s\n",
      "\titers: 800, epoch: 1 | loss: 0.3974779\n",
      "\tspeed: 0.0426s/iter; left time: 346.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 893 | Train Loss: 0.4296926 Vali Loss: 0.4422245 Test Loss: 0.4514492\n",
      "Validation loss decreased (inf --> 0.442224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4751551\n",
      "\tspeed: 0.1525s/iter; left time: 1210.6738s\n",
      "\titers: 200, epoch: 2 | loss: 0.4530021\n",
      "\tspeed: 0.0424s/iter; left time: 332.3615s\n",
      "\titers: 300, epoch: 2 | loss: 0.3882786\n",
      "\tspeed: 0.0424s/iter; left time: 327.8379s\n",
      "\titers: 400, epoch: 2 | loss: 0.4140501\n",
      "\tspeed: 0.0424s/iter; left time: 323.5683s\n",
      "\titers: 500, epoch: 2 | loss: 0.3746513\n",
      "\tspeed: 0.0424s/iter; left time: 319.7359s\n",
      "\titers: 600, epoch: 2 | loss: 0.3730287\n",
      "\tspeed: 0.0423s/iter; left time: 314.9048s\n",
      "\titers: 700, epoch: 2 | loss: 0.4009704\n",
      "\tspeed: 0.0424s/iter; left time: 311.0437s\n",
      "\titers: 800, epoch: 2 | loss: 0.3358727\n",
      "\tspeed: 0.0424s/iter; left time: 307.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.3956892 Vali Loss: 0.4311240 Test Loss: 0.4466510\n",
      "Validation loss decreased (0.442224 --> 0.431124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2904167\n",
      "\tspeed: 0.1537s/iter; left time: 1082.8511s\n",
      "\titers: 200, epoch: 3 | loss: 0.3576709\n",
      "\tspeed: 0.0424s/iter; left time: 294.3742s\n",
      "\titers: 300, epoch: 3 | loss: 0.3403774\n",
      "\tspeed: 0.0423s/iter; left time: 289.4606s\n",
      "\titers: 400, epoch: 3 | loss: 0.3329291\n",
      "\tspeed: 0.0424s/iter; left time: 285.7193s\n",
      "\titers: 500, epoch: 3 | loss: 0.3230645\n",
      "\tspeed: 0.0424s/iter; left time: 281.5820s\n",
      "\titers: 600, epoch: 3 | loss: 0.3635491\n",
      "\tspeed: 0.0424s/iter; left time: 277.2735s\n",
      "\titers: 700, epoch: 3 | loss: 0.2835732\n",
      "\tspeed: 0.0423s/iter; left time: 272.9224s\n",
      "\titers: 800, epoch: 3 | loss: 0.3851331\n",
      "\tspeed: 0.0424s/iter; left time: 269.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3495539 Vali Loss: 0.4219367 Test Loss: 0.4352997\n",
      "Validation loss decreased (0.431124 --> 0.421937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3447823\n",
      "\tspeed: 0.1539s/iter; left time: 946.7996s\n",
      "\titers: 200, epoch: 4 | loss: 0.3190766\n",
      "\tspeed: 0.0424s/iter; left time: 256.7966s\n",
      "\titers: 300, epoch: 4 | loss: 0.3549941\n",
      "\tspeed: 0.0424s/iter; left time: 252.1900s\n",
      "\titers: 400, epoch: 4 | loss: 0.2950929\n",
      "\tspeed: 0.0423s/iter; left time: 247.8224s\n",
      "\titers: 500, epoch: 4 | loss: 0.4276862\n",
      "\tspeed: 0.0423s/iter; left time: 243.5792s\n",
      "\titers: 600, epoch: 4 | loss: 0.3246305\n",
      "\tspeed: 0.0424s/iter; left time: 239.7012s\n",
      "\titers: 700, epoch: 4 | loss: 0.3205589\n",
      "\tspeed: 0.0424s/iter; left time: 235.2304s\n",
      "\titers: 800, epoch: 4 | loss: 0.3858584\n",
      "\tspeed: 0.0424s/iter; left time: 231.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.3416200 Vali Loss: 0.4134573 Test Loss: 0.4247172\n",
      "Validation loss decreased (0.421937 --> 0.413457).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3319281\n",
      "\tspeed: 0.1539s/iter; left time: 809.3437s\n",
      "\titers: 200, epoch: 5 | loss: 0.2934890\n",
      "\tspeed: 0.0424s/iter; left time: 218.5093s\n",
      "\titers: 300, epoch: 5 | loss: 0.3355778\n",
      "\tspeed: 0.0423s/iter; left time: 214.0601s\n",
      "\titers: 400, epoch: 5 | loss: 0.3117720\n",
      "\tspeed: 0.0424s/iter; left time: 210.0868s\n",
      "\titers: 500, epoch: 5 | loss: 0.3203244\n",
      "\tspeed: 0.0424s/iter; left time: 205.8614s\n",
      "\titers: 600, epoch: 5 | loss: 0.2914104\n",
      "\tspeed: 0.0424s/iter; left time: 201.7048s\n",
      "\titers: 700, epoch: 5 | loss: 0.3308161\n",
      "\tspeed: 0.0424s/iter; left time: 197.4604s\n",
      "\titers: 800, epoch: 5 | loss: 0.3173711\n",
      "\tspeed: 0.0425s/iter; left time: 193.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3343107 Vali Loss: 0.4109769 Test Loss: 0.4230208\n",
      "Validation loss decreased (0.413457 --> 0.410977).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2896678\n",
      "\tspeed: 0.1526s/iter; left time: 666.3155s\n",
      "\titers: 200, epoch: 6 | loss: 0.3515523\n",
      "\tspeed: 0.0424s/iter; left time: 180.7143s\n",
      "\titers: 300, epoch: 6 | loss: 0.3070067\n",
      "\tspeed: 0.0423s/iter; left time: 176.3146s\n",
      "\titers: 400, epoch: 6 | loss: 0.2854919\n",
      "\tspeed: 0.0424s/iter; left time: 172.3742s\n",
      "\titers: 500, epoch: 6 | loss: 0.3352777\n",
      "\tspeed: 0.0423s/iter; left time: 167.9545s\n",
      "\titers: 600, epoch: 6 | loss: 0.3287666\n",
      "\tspeed: 0.0424s/iter; left time: 163.8867s\n",
      "\titers: 700, epoch: 6 | loss: 0.2857096\n",
      "\tspeed: 0.0424s/iter; left time: 159.7712s\n",
      "\titers: 800, epoch: 6 | loss: 0.3255485\n",
      "\tspeed: 0.0424s/iter; left time: 155.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.3294495 Vali Loss: 0.4255356 Test Loss: 0.4324502\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3365586\n",
      "\tspeed: 0.1510s/iter; left time: 524.5512s\n",
      "\titers: 200, epoch: 7 | loss: 0.3124640\n",
      "\tspeed: 0.0425s/iter; left time: 143.2186s\n",
      "\titers: 300, epoch: 7 | loss: 0.3412698\n",
      "\tspeed: 0.0423s/iter; left time: 138.4806s\n",
      "\titers: 400, epoch: 7 | loss: 0.3270743\n",
      "\tspeed: 0.0424s/iter; left time: 134.5114s\n",
      "\titers: 500, epoch: 7 | loss: 0.3453423\n",
      "\tspeed: 0.0421s/iter; left time: 129.4667s\n",
      "\titers: 600, epoch: 7 | loss: 0.3201989\n",
      "\tspeed: 0.0421s/iter; left time: 125.1563s\n",
      "\titers: 700, epoch: 7 | loss: 0.2999701\n",
      "\tspeed: 0.0424s/iter; left time: 121.8284s\n",
      "\titers: 800, epoch: 7 | loss: 0.3040497\n",
      "\tspeed: 0.0425s/iter; left time: 117.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3237632 Vali Loss: 0.4205632 Test Loss: 0.4347714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3042686\n",
      "\tspeed: 0.1510s/iter; left time: 389.6832s\n",
      "\titers: 200, epoch: 8 | loss: 0.3169928\n",
      "\tspeed: 0.0423s/iter; left time: 105.0182s\n",
      "\titers: 300, epoch: 8 | loss: 0.2797357\n",
      "\tspeed: 0.0423s/iter; left time: 100.7148s\n",
      "\titers: 400, epoch: 8 | loss: 0.3393894\n",
      "\tspeed: 0.0423s/iter; left time: 96.5069s\n",
      "\titers: 500, epoch: 8 | loss: 0.3562687\n",
      "\tspeed: 0.0423s/iter; left time: 92.1845s\n",
      "\titers: 600, epoch: 8 | loss: 0.2649100\n",
      "\tspeed: 0.0423s/iter; left time: 88.0785s\n",
      "\titers: 700, epoch: 8 | loss: 0.3125881\n",
      "\tspeed: 0.0424s/iter; left time: 83.9210s\n",
      "\titers: 800, epoch: 8 | loss: 0.3596777\n",
      "\tspeed: 0.0424s/iter; left time: 79.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.3133540 Vali Loss: 0.4209787 Test Loss: 0.4364639\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4612430930137634, rmse:0.67914879322052, mae:0.42302075028419495, rse:0.5375033617019653\n",
      "Original data scale mse:17183404.0, rmse:4145.287109375, mae:2456.189453125, rse:0.20611201226711273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4739339\n",
      "\tspeed: 0.0440s/iter; left time: 388.8090s\n",
      "\titers: 200, epoch: 1 | loss: 0.4540531\n",
      "\tspeed: 0.0424s/iter; left time: 369.7961s\n",
      "\titers: 300, epoch: 1 | loss: 0.3691141\n",
      "\tspeed: 0.0424s/iter; left time: 365.9028s\n",
      "\titers: 400, epoch: 1 | loss: 0.3733300\n",
      "\tspeed: 0.0423s/iter; left time: 361.0668s\n",
      "\titers: 500, epoch: 1 | loss: 0.3640547\n",
      "\tspeed: 0.0424s/iter; left time: 357.5223s\n",
      "\titers: 600, epoch: 1 | loss: 0.3699769\n",
      "\tspeed: 0.0424s/iter; left time: 353.0969s\n",
      "\titers: 700, epoch: 1 | loss: 0.3467535\n",
      "\tspeed: 0.0424s/iter; left time: 348.8939s\n",
      "\titers: 800, epoch: 1 | loss: 0.3464169\n",
      "\tspeed: 0.0424s/iter; left time: 344.4607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.4279929 Vali Loss: 0.4427081 Test Loss: 0.4532785\n",
      "Validation loss decreased (inf --> 0.442708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4089020\n",
      "\tspeed: 0.1550s/iter; left time: 1230.0104s\n",
      "\titers: 200, epoch: 2 | loss: 0.3849083\n",
      "\tspeed: 0.0425s/iter; left time: 332.7663s\n",
      "\titers: 300, epoch: 2 | loss: 0.3607240\n",
      "\tspeed: 0.0426s/iter; left time: 329.8853s\n",
      "\titers: 400, epoch: 2 | loss: 0.4332860\n",
      "\tspeed: 0.0426s/iter; left time: 325.0105s\n",
      "\titers: 500, epoch: 2 | loss: 0.3553748\n",
      "\tspeed: 0.0426s/iter; left time: 321.0306s\n",
      "\titers: 600, epoch: 2 | loss: 0.3558212\n",
      "\tspeed: 0.0426s/iter; left time: 316.4920s\n",
      "\titers: 700, epoch: 2 | loss: 0.3483924\n",
      "\tspeed: 0.0425s/iter; left time: 311.8307s\n",
      "\titers: 800, epoch: 2 | loss: 0.3718648\n",
      "\tspeed: 0.0424s/iter; left time: 307.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 893 | Train Loss: 0.3910895 Vali Loss: 0.4320702 Test Loss: 0.4399559\n",
      "Validation loss decreased (0.442708 --> 0.432070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3337142\n",
      "\tspeed: 0.1540s/iter; left time: 1084.9239s\n",
      "\titers: 200, epoch: 3 | loss: 0.3450969\n",
      "\tspeed: 0.0424s/iter; left time: 294.5996s\n",
      "\titers: 300, epoch: 3 | loss: 0.3313186\n",
      "\tspeed: 0.0424s/iter; left time: 290.4464s\n",
      "\titers: 400, epoch: 3 | loss: 0.3627611\n",
      "\tspeed: 0.0426s/iter; left time: 287.5233s\n",
      "\titers: 500, epoch: 3 | loss: 0.3072940\n",
      "\tspeed: 0.0426s/iter; left time: 282.9629s\n",
      "\titers: 600, epoch: 3 | loss: 0.3159499\n",
      "\tspeed: 0.0424s/iter; left time: 277.3633s\n",
      "\titers: 700, epoch: 3 | loss: 0.3433414\n",
      "\tspeed: 0.0425s/iter; left time: 273.7528s\n",
      "\titers: 800, epoch: 3 | loss: 0.3504495\n",
      "\tspeed: 0.0424s/iter; left time: 268.8622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3478101 Vali Loss: 0.4106736 Test Loss: 0.4247069\n",
      "Validation loss decreased (0.432070 --> 0.410674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3664916\n",
      "\tspeed: 0.1534s/iter; left time: 943.9890s\n",
      "\titers: 200, epoch: 4 | loss: 0.3556045\n",
      "\tspeed: 0.0425s/iter; left time: 257.0485s\n",
      "\titers: 300, epoch: 4 | loss: 0.3436058\n",
      "\tspeed: 0.0424s/iter; left time: 252.1175s\n",
      "\titers: 400, epoch: 4 | loss: 0.3065186\n",
      "\tspeed: 0.0424s/iter; left time: 248.2914s\n",
      "\titers: 500, epoch: 4 | loss: 0.3289182\n",
      "\tspeed: 0.0423s/iter; left time: 243.5285s\n",
      "\titers: 600, epoch: 4 | loss: 0.3316960\n",
      "\tspeed: 0.0424s/iter; left time: 239.5950s\n",
      "\titers: 700, epoch: 4 | loss: 0.3341659\n",
      "\tspeed: 0.0425s/iter; left time: 235.9053s\n",
      "\titers: 800, epoch: 4 | loss: 0.2980278\n",
      "\tspeed: 0.0425s/iter; left time: 231.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.3400171 Vali Loss: 0.4142010 Test Loss: 0.4281743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3242514\n",
      "\tspeed: 0.1518s/iter; left time: 798.4761s\n",
      "\titers: 200, epoch: 5 | loss: 0.3074272\n",
      "\tspeed: 0.0426s/iter; left time: 219.9973s\n",
      "\titers: 300, epoch: 5 | loss: 0.3388836\n",
      "\tspeed: 0.0426s/iter; left time: 215.2733s\n",
      "\titers: 400, epoch: 5 | loss: 0.3729826\n",
      "\tspeed: 0.0425s/iter; left time: 210.7732s\n",
      "\titers: 500, epoch: 5 | loss: 0.4128991\n",
      "\tspeed: 0.0426s/iter; left time: 207.0960s\n",
      "\titers: 600, epoch: 5 | loss: 0.3496001\n",
      "\tspeed: 0.0427s/iter; left time: 203.1897s\n",
      "\titers: 700, epoch: 5 | loss: 0.3578146\n",
      "\tspeed: 0.0426s/iter; left time: 198.5819s\n",
      "\titers: 800, epoch: 5 | loss: 0.3022088\n",
      "\tspeed: 0.0426s/iter; left time: 194.3290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 893 | Train Loss: 0.3320721 Vali Loss: 0.4036397 Test Loss: 0.4186656\n",
      "Validation loss decreased (0.410674 --> 0.403640).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3790839\n",
      "\tspeed: 0.1552s/iter; left time: 677.4648s\n",
      "\titers: 200, epoch: 6 | loss: 0.2824487\n",
      "\tspeed: 0.0424s/iter; left time: 180.9843s\n",
      "\titers: 300, epoch: 6 | loss: 0.3130301\n",
      "\tspeed: 0.0425s/iter; left time: 177.2606s\n",
      "\titers: 400, epoch: 6 | loss: 0.3765152\n",
      "\tspeed: 0.0424s/iter; left time: 172.3570s\n",
      "\titers: 500, epoch: 6 | loss: 0.2899759\n",
      "\tspeed: 0.0425s/iter; left time: 168.5191s\n",
      "\titers: 600, epoch: 6 | loss: 0.3341354\n",
      "\tspeed: 0.0425s/iter; left time: 164.1625s\n",
      "\titers: 700, epoch: 6 | loss: 0.3467826\n",
      "\tspeed: 0.0425s/iter; left time: 160.1688s\n",
      "\titers: 800, epoch: 6 | loss: 0.3329554\n",
      "\tspeed: 0.0425s/iter; left time: 155.9498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 893 | Train Loss: 0.3288571 Vali Loss: 0.4075786 Test Loss: 0.4223005\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3471135\n",
      "\tspeed: 0.1524s/iter; left time: 529.1976s\n",
      "\titers: 200, epoch: 7 | loss: 0.3624613\n",
      "\tspeed: 0.0425s/iter; left time: 143.2853s\n",
      "\titers: 300, epoch: 7 | loss: 0.3461682\n",
      "\tspeed: 0.0425s/iter; left time: 138.9486s\n",
      "\titers: 400, epoch: 7 | loss: 0.3192582\n",
      "\tspeed: 0.0426s/iter; left time: 135.0798s\n",
      "\titers: 500, epoch: 7 | loss: 0.2862870\n",
      "\tspeed: 0.0427s/iter; left time: 131.3159s\n",
      "\titers: 600, epoch: 7 | loss: 0.3154697\n",
      "\tspeed: 0.0427s/iter; left time: 126.8909s\n",
      "\titers: 700, epoch: 7 | loss: 0.3064333\n",
      "\tspeed: 0.0427s/iter; left time: 122.6409s\n",
      "\titers: 800, epoch: 7 | loss: 0.3354075\n",
      "\tspeed: 0.0425s/iter; left time: 117.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 893 | Train Loss: 0.3221708 Vali Loss: 0.4098179 Test Loss: 0.4235730\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2890800\n",
      "\tspeed: 0.1522s/iter; left time: 392.7008s\n",
      "\titers: 200, epoch: 8 | loss: 0.3243214\n",
      "\tspeed: 0.0427s/iter; left time: 106.0005s\n",
      "\titers: 300, epoch: 8 | loss: 0.2589266\n",
      "\tspeed: 0.0425s/iter; left time: 101.1173s\n",
      "\titers: 400, epoch: 8 | loss: 0.3333530\n",
      "\tspeed: 0.0423s/iter; left time: 96.4767s\n",
      "\titers: 500, epoch: 8 | loss: 0.2846834\n",
      "\tspeed: 0.0424s/iter; left time: 92.4178s\n",
      "\titers: 600, epoch: 8 | loss: 0.3179591\n",
      "\tspeed: 0.0424s/iter; left time: 88.2907s\n",
      "\titers: 700, epoch: 8 | loss: 0.3226090\n",
      "\tspeed: 0.0425s/iter; left time: 84.2358s\n",
      "\titers: 800, epoch: 8 | loss: 0.3119867\n",
      "\tspeed: 0.0425s/iter; left time: 79.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.3134166 Vali Loss: 0.4092242 Test Loss: 0.4205885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.44546520709991455, rmse:0.6674317717552185, mae:0.41866567730903625, rse:0.5282301306724548\n",
      "Original data scale mse:16678795.0, rmse:4083.968017578125, mae:2431.303955078125, rse:0.20306311547756195\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6374813\n",
      "\tspeed: 0.0668s/iter; left time: 588.6268s\n",
      "\titers: 200, epoch: 1 | loss: 0.5262504\n",
      "\tspeed: 0.0429s/iter; left time: 373.6804s\n",
      "\titers: 300, epoch: 1 | loss: 0.5496212\n",
      "\tspeed: 0.0425s/iter; left time: 366.3395s\n",
      "\titers: 400, epoch: 1 | loss: 0.4834964\n",
      "\tspeed: 0.0427s/iter; left time: 363.0046s\n",
      "\titers: 500, epoch: 1 | loss: 0.5325756\n",
      "\tspeed: 0.0426s/iter; left time: 358.4012s\n",
      "\titers: 600, epoch: 1 | loss: 0.4872109\n",
      "\tspeed: 0.0427s/iter; left time: 354.5742s\n",
      "\titers: 700, epoch: 1 | loss: 0.5237520\n",
      "\tspeed: 0.0429s/iter; left time: 352.3595s\n",
      "\titers: 800, epoch: 1 | loss: 0.5554903\n",
      "\tspeed: 0.0428s/iter; left time: 347.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.5397429 Vali Loss: 0.5700328 Test Loss: 0.6036903\n",
      "Validation loss decreased (inf --> 0.570033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5374577\n",
      "\tspeed: 0.1534s/iter; left time: 1214.5876s\n",
      "\titers: 200, epoch: 2 | loss: 0.5270962\n",
      "\tspeed: 0.0428s/iter; left time: 334.9445s\n",
      "\titers: 300, epoch: 2 | loss: 0.4995303\n",
      "\tspeed: 0.0427s/iter; left time: 329.8634s\n",
      "\titers: 400, epoch: 2 | loss: 0.5156381\n",
      "\tspeed: 0.0428s/iter; left time: 325.8718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4754504\n",
      "\tspeed: 0.0428s/iter; left time: 321.6876s\n",
      "\titers: 600, epoch: 2 | loss: 0.4311262\n",
      "\tspeed: 0.0427s/iter; left time: 316.6085s\n",
      "\titers: 700, epoch: 2 | loss: 0.4329669\n",
      "\tspeed: 0.0429s/iter; left time: 314.0876s\n",
      "\titers: 800, epoch: 2 | loss: 0.5162832\n",
      "\tspeed: 0.0427s/iter; left time: 308.0701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 891 | Train Loss: 0.5097087 Vali Loss: 0.5559564 Test Loss: 0.5963426\n",
      "Validation loss decreased (0.570033 --> 0.555956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4553922\n",
      "\tspeed: 0.1539s/iter; left time: 1081.4243s\n",
      "\titers: 200, epoch: 3 | loss: 0.4781276\n",
      "\tspeed: 0.0428s/iter; left time: 296.3413s\n",
      "\titers: 300, epoch: 3 | loss: 0.5148327\n",
      "\tspeed: 0.0427s/iter; left time: 291.8887s\n",
      "\titers: 400, epoch: 3 | loss: 0.4678192\n",
      "\tspeed: 0.0428s/iter; left time: 287.7050s\n",
      "\titers: 500, epoch: 3 | loss: 0.4578561\n",
      "\tspeed: 0.0428s/iter; left time: 283.4134s\n",
      "\titers: 600, epoch: 3 | loss: 0.4424357\n",
      "\tspeed: 0.0427s/iter; left time: 278.8488s\n",
      "\titers: 700, epoch: 3 | loss: 0.4751456\n",
      "\tspeed: 0.0427s/iter; left time: 274.5151s\n",
      "\titers: 800, epoch: 3 | loss: 0.4236996\n",
      "\tspeed: 0.0427s/iter; left time: 270.0678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4665015 Vali Loss: 0.5722540 Test Loss: 0.6234865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4868843\n",
      "\tspeed: 0.1518s/iter; left time: 932.0490s\n",
      "\titers: 200, epoch: 4 | loss: 0.4776935\n",
      "\tspeed: 0.0428s/iter; left time: 258.3937s\n",
      "\titers: 300, epoch: 4 | loss: 0.4831240\n",
      "\tspeed: 0.0428s/iter; left time: 253.9956s\n",
      "\titers: 400, epoch: 4 | loss: 0.4405861\n",
      "\tspeed: 0.0427s/iter; left time: 249.4328s\n",
      "\titers: 500, epoch: 4 | loss: 0.4349448\n",
      "\tspeed: 0.0428s/iter; left time: 245.3025s\n",
      "\titers: 600, epoch: 4 | loss: 0.4479438\n",
      "\tspeed: 0.0429s/iter; left time: 241.9157s\n",
      "\titers: 700, epoch: 4 | loss: 0.4399997\n",
      "\tspeed: 0.0429s/iter; left time: 237.6722s\n",
      "\titers: 800, epoch: 4 | loss: 0.3783943\n",
      "\tspeed: 0.0429s/iter; left time: 233.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.4382588 Vali Loss: 0.5783772 Test Loss: 0.6318021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4318333\n",
      "\tspeed: 0.1513s/iter; left time: 793.8737s\n",
      "\titers: 200, epoch: 5 | loss: 0.3880471\n",
      "\tspeed: 0.0427s/iter; left time: 219.6857s\n",
      "\titers: 300, epoch: 5 | loss: 0.4674024\n",
      "\tspeed: 0.0428s/iter; left time: 216.0979s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704361\n",
      "\tspeed: 0.0430s/iter; left time: 212.4841s\n",
      "\titers: 500, epoch: 5 | loss: 0.3912926\n",
      "\tspeed: 0.0428s/iter; left time: 207.3283s\n",
      "\titers: 600, epoch: 5 | loss: 0.3840115\n",
      "\tspeed: 0.0427s/iter; left time: 202.6971s\n",
      "\titers: 700, epoch: 5 | loss: 0.3629414\n",
      "\tspeed: 0.0427s/iter; left time: 198.4789s\n",
      "\titers: 800, epoch: 5 | loss: 0.3453966\n",
      "\tspeed: 0.0427s/iter; left time: 194.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.3968851 Vali Loss: 0.5949938 Test Loss: 0.6539372\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7655912637710571, rmse:0.8749807476997375, mae:0.5963423848152161, rse:0.6939675807952881\n",
      "Original data scale mse:31555720.0, rmse:5617.44775390625, mae:3527.80322265625, rse:0.27975091338157654\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5567461\n",
      "\tspeed: 0.0443s/iter; left time: 390.7184s\n",
      "\titers: 200, epoch: 1 | loss: 0.5131473\n",
      "\tspeed: 0.0427s/iter; left time: 372.0392s\n",
      "\titers: 300, epoch: 1 | loss: 0.5688336\n",
      "\tspeed: 0.0427s/iter; left time: 367.3527s\n",
      "\titers: 400, epoch: 1 | loss: 0.5851882\n",
      "\tspeed: 0.0426s/iter; left time: 362.9409s\n",
      "\titers: 500, epoch: 1 | loss: 0.4940234\n",
      "\tspeed: 0.0427s/iter; left time: 359.3432s\n",
      "\titers: 600, epoch: 1 | loss: 0.5569887\n",
      "\tspeed: 0.0427s/iter; left time: 355.1089s\n",
      "\titers: 700, epoch: 1 | loss: 0.5020673\n",
      "\tspeed: 0.0427s/iter; left time: 350.4669s\n",
      "\titers: 800, epoch: 1 | loss: 0.5009230\n",
      "\tspeed: 0.0427s/iter; left time: 346.4349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.5401562 Vali Loss: 0.5691482 Test Loss: 0.6024293\n",
      "Validation loss decreased (inf --> 0.569148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5425625\n",
      "\tspeed: 0.1539s/iter; left time: 1219.0067s\n",
      "\titers: 200, epoch: 2 | loss: 0.5092666\n",
      "\tspeed: 0.0427s/iter; left time: 333.6463s\n",
      "\titers: 300, epoch: 2 | loss: 0.5347412\n",
      "\tspeed: 0.0427s/iter; left time: 329.3097s\n",
      "\titers: 400, epoch: 2 | loss: 0.5148687\n",
      "\tspeed: 0.0427s/iter; left time: 325.4797s\n",
      "\titers: 500, epoch: 2 | loss: 0.4511907\n",
      "\tspeed: 0.0427s/iter; left time: 321.2890s\n",
      "\titers: 600, epoch: 2 | loss: 0.4812346\n",
      "\tspeed: 0.0427s/iter; left time: 316.8765s\n",
      "\titers: 700, epoch: 2 | loss: 0.5175083\n",
      "\tspeed: 0.0427s/iter; left time: 312.3264s\n",
      "\titers: 800, epoch: 2 | loss: 0.4783387\n",
      "\tspeed: 0.0427s/iter; left time: 308.0100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.5104276 Vali Loss: 0.5632515 Test Loss: 0.6076972\n",
      "Validation loss decreased (0.569148 --> 0.563251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4891643\n",
      "\tspeed: 0.1538s/iter; left time: 1080.8924s\n",
      "\titers: 200, epoch: 3 | loss: 0.4391293\n",
      "\tspeed: 0.0427s/iter; left time: 295.9464s\n",
      "\titers: 300, epoch: 3 | loss: 0.4282694\n",
      "\tspeed: 0.0427s/iter; left time: 291.3648s\n",
      "\titers: 400, epoch: 3 | loss: 0.4537349\n",
      "\tspeed: 0.0424s/iter; left time: 285.3786s\n",
      "\titers: 500, epoch: 3 | loss: 0.4212231\n",
      "\tspeed: 0.0428s/iter; left time: 283.9576s\n",
      "\titers: 600, epoch: 3 | loss: 0.4614433\n",
      "\tspeed: 0.0427s/iter; left time: 278.6681s\n",
      "\titers: 700, epoch: 3 | loss: 0.5231907\n",
      "\tspeed: 0.0427s/iter; left time: 274.5001s\n",
      "\titers: 800, epoch: 3 | loss: 0.4524678\n",
      "\tspeed: 0.0428s/iter; left time: 270.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.4641792 Vali Loss: 0.5592130 Test Loss: 0.6112368\n",
      "Validation loss decreased (0.563251 --> 0.559213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4562828\n",
      "\tspeed: 0.1539s/iter; left time: 944.6766s\n",
      "\titers: 200, epoch: 4 | loss: 0.4032119\n",
      "\tspeed: 0.0427s/iter; left time: 258.0062s\n",
      "\titers: 300, epoch: 4 | loss: 0.4174506\n",
      "\tspeed: 0.0427s/iter; left time: 253.6510s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366000\n",
      "\tspeed: 0.0426s/iter; left time: 248.9802s\n",
      "\titers: 500, epoch: 4 | loss: 0.3799008\n",
      "\tspeed: 0.0426s/iter; left time: 244.6381s\n",
      "\titers: 600, epoch: 4 | loss: 0.4402491\n",
      "\tspeed: 0.0427s/iter; left time: 240.5559s\n",
      "\titers: 700, epoch: 4 | loss: 0.4542446\n",
      "\tspeed: 0.0427s/iter; left time: 236.7406s\n",
      "\titers: 800, epoch: 4 | loss: 0.4093605\n",
      "\tspeed: 0.0427s/iter; left time: 232.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.4341894 Vali Loss: 0.5747357 Test Loss: 0.6246487\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3754254\n",
      "\tspeed: 0.1526s/iter; left time: 800.5439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3966073\n",
      "\tspeed: 0.0427s/iter; left time: 219.6991s\n",
      "\titers: 300, epoch: 5 | loss: 0.3927452\n",
      "\tspeed: 0.0427s/iter; left time: 215.6141s\n",
      "\titers: 400, epoch: 5 | loss: 0.4006265\n",
      "\tspeed: 0.0428s/iter; left time: 211.5692s\n",
      "\titers: 500, epoch: 5 | loss: 0.3565641\n",
      "\tspeed: 0.0427s/iter; left time: 207.1230s\n",
      "\titers: 600, epoch: 5 | loss: 0.3645180\n",
      "\tspeed: 0.0427s/iter; left time: 202.7275s\n",
      "\titers: 700, epoch: 5 | loss: 0.3615814\n",
      "\tspeed: 0.0426s/iter; left time: 198.0965s\n",
      "\titers: 800, epoch: 5 | loss: 0.3716194\n",
      "\tspeed: 0.0428s/iter; left time: 194.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.3956859 Vali Loss: 0.5881065 Test Loss: 0.6395448\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3419645\n",
      "\tspeed: 0.1518s/iter; left time: 661.4252s\n",
      "\titers: 200, epoch: 6 | loss: 0.3649749\n",
      "\tspeed: 0.0425s/iter; left time: 181.0643s\n",
      "\titers: 300, epoch: 6 | loss: 0.3397926\n",
      "\tspeed: 0.0425s/iter; left time: 176.5243s\n",
      "\titers: 400, epoch: 6 | loss: 0.3800455\n",
      "\tspeed: 0.0427s/iter; left time: 173.1685s\n",
      "\titers: 500, epoch: 6 | loss: 0.3381722\n",
      "\tspeed: 0.0427s/iter; left time: 168.8047s\n",
      "\titers: 600, epoch: 6 | loss: 0.3673343\n",
      "\tspeed: 0.0427s/iter; left time: 164.7808s\n",
      "\titers: 700, epoch: 6 | loss: 0.3715284\n",
      "\tspeed: 0.0427s/iter; left time: 160.3121s\n",
      "\titers: 800, epoch: 6 | loss: 0.3510702\n",
      "\tspeed: 0.0427s/iter; left time: 156.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.3557695 Vali Loss: 0.5995966 Test Loss: 0.6508650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8202449083328247, rmse:0.9056737422943115, mae:0.6112369298934937, rse:0.7183108925819397\n",
      "Original data scale mse:34537172.0, rmse:5876.83349609375, mae:3631.940673828125, rse:0.2926684021949768\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6454177\n",
      "\tspeed: 0.0676s/iter; left time: 594.5601s\n",
      "\titers: 200, epoch: 1 | loss: 0.5544594\n",
      "\tspeed: 0.0434s/iter; left time: 377.3446s\n",
      "\titers: 300, epoch: 1 | loss: 0.5635941\n",
      "\tspeed: 0.0434s/iter; left time: 372.8728s\n",
      "\titers: 400, epoch: 1 | loss: 0.6180624\n",
      "\tspeed: 0.0434s/iter; left time: 368.1762s\n",
      "\titers: 500, epoch: 1 | loss: 0.5999923\n",
      "\tspeed: 0.0432s/iter; left time: 362.8958s\n",
      "\titers: 600, epoch: 1 | loss: 0.5538129\n",
      "\tspeed: 0.0433s/iter; left time: 359.3278s\n",
      "\titers: 700, epoch: 1 | loss: 0.5393959\n",
      "\tspeed: 0.0433s/iter; left time: 354.2748s\n",
      "\titers: 800, epoch: 1 | loss: 0.5381173\n",
      "\tspeed: 0.0433s/iter; left time: 350.0561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.95s\n",
      "Steps: 889 | Train Loss: 0.5633903 Vali Loss: 0.5876741 Test Loss: 0.6291287\n",
      "Validation loss decreased (inf --> 0.587674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5834135\n",
      "\tspeed: 0.1545s/iter; left time: 1221.0624s\n",
      "\titers: 200, epoch: 2 | loss: 0.5220478\n",
      "\tspeed: 0.0434s/iter; left time: 338.3012s\n",
      "\titers: 300, epoch: 2 | loss: 0.5758332\n",
      "\tspeed: 0.0433s/iter; left time: 333.5033s\n",
      "\titers: 400, epoch: 2 | loss: 0.5207759\n",
      "\tspeed: 0.0434s/iter; left time: 329.8133s\n",
      "\titers: 500, epoch: 2 | loss: 0.5079741\n",
      "\tspeed: 0.0433s/iter; left time: 324.9222s\n",
      "\titers: 600, epoch: 2 | loss: 0.5090077\n",
      "\tspeed: 0.0432s/iter; left time: 320.0888s\n",
      "\titers: 700, epoch: 2 | loss: 0.4622243\n",
      "\tspeed: 0.0434s/iter; left time: 317.2569s\n",
      "\titers: 800, epoch: 2 | loss: 0.5246297\n",
      "\tspeed: 0.0433s/iter; left time: 312.1196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5286044 Vali Loss: 0.5791647 Test Loss: 0.6255860\n",
      "Validation loss decreased (0.587674 --> 0.579165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4951027\n",
      "\tspeed: 0.1555s/iter; left time: 1090.4638s\n",
      "\titers: 200, epoch: 3 | loss: 0.4212805\n",
      "\tspeed: 0.0433s/iter; left time: 299.4308s\n",
      "\titers: 300, epoch: 3 | loss: 0.4809437\n",
      "\tspeed: 0.0433s/iter; left time: 294.8038s\n",
      "\titers: 400, epoch: 3 | loss: 0.5490001\n",
      "\tspeed: 0.0433s/iter; left time: 290.3509s\n",
      "\titers: 500, epoch: 3 | loss: 0.5272199\n",
      "\tspeed: 0.0433s/iter; left time: 286.4257s\n",
      "\titers: 600, epoch: 3 | loss: 0.4973647\n",
      "\tspeed: 0.0433s/iter; left time: 281.9563s\n",
      "\titers: 700, epoch: 3 | loss: 0.4791625\n",
      "\tspeed: 0.0433s/iter; left time: 277.8630s\n",
      "\titers: 800, epoch: 3 | loss: 0.4444051\n",
      "\tspeed: 0.0434s/iter; left time: 273.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4811308 Vali Loss: 0.5916529 Test Loss: 0.6518676\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4643247\n",
      "\tspeed: 0.1514s/iter; left time: 927.3796s\n",
      "\titers: 200, epoch: 4 | loss: 0.4047467\n",
      "\tspeed: 0.0433s/iter; left time: 260.8542s\n",
      "\titers: 300, epoch: 4 | loss: 0.5270584\n",
      "\tspeed: 0.0433s/iter; left time: 256.4785s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366706\n",
      "\tspeed: 0.0433s/iter; left time: 252.2116s\n",
      "\titers: 500, epoch: 4 | loss: 0.4361570\n",
      "\tspeed: 0.0433s/iter; left time: 247.5898s\n",
      "\titers: 600, epoch: 4 | loss: 0.3978770\n",
      "\tspeed: 0.0433s/iter; left time: 243.4390s\n",
      "\titers: 700, epoch: 4 | loss: 0.4258873\n",
      "\tspeed: 0.0432s/iter; left time: 238.8988s\n",
      "\titers: 800, epoch: 4 | loss: 0.4317477\n",
      "\tspeed: 0.0432s/iter; left time: 234.4671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.4384420 Vali Loss: 0.5988257 Test Loss: 0.6685336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3967570\n",
      "\tspeed: 0.1522s/iter; left time: 796.9504s\n",
      "\titers: 200, epoch: 5 | loss: 0.3766952\n",
      "\tspeed: 0.0434s/iter; left time: 222.8755s\n",
      "\titers: 300, epoch: 5 | loss: 0.3889566\n",
      "\tspeed: 0.0434s/iter; left time: 218.2767s\n",
      "\titers: 400, epoch: 5 | loss: 0.4054741\n",
      "\tspeed: 0.0433s/iter; left time: 213.4839s\n",
      "\titers: 500, epoch: 5 | loss: 0.4088733\n",
      "\tspeed: 0.0434s/iter; left time: 209.7270s\n",
      "\titers: 600, epoch: 5 | loss: 0.3773878\n",
      "\tspeed: 0.0433s/iter; left time: 204.8636s\n",
      "\titers: 700, epoch: 5 | loss: 0.3832667\n",
      "\tspeed: 0.0433s/iter; left time: 200.6077s\n",
      "\titers: 800, epoch: 5 | loss: 0.3715691\n",
      "\tspeed: 0.0433s/iter; left time: 196.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.3870841 Vali Loss: 0.6039886 Test Loss: 0.6716257\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8244243860244751, rmse:0.9079781770706177, mae:0.6255861520767212, rse:0.7192794680595398\n",
      "Original data scale mse:35018344.0, rmse:5917.6298828125, mae:3745.188720703125, rse:0.29484474658966064\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6611432\n",
      "\tspeed: 0.0448s/iter; left time: 394.1709s\n",
      "\titers: 200, epoch: 1 | loss: 0.5944821\n",
      "\tspeed: 0.0433s/iter; left time: 376.1663s\n",
      "\titers: 300, epoch: 1 | loss: 0.6297670\n",
      "\tspeed: 0.0434s/iter; left time: 372.9207s\n",
      "\titers: 400, epoch: 1 | loss: 0.6077808\n",
      "\tspeed: 0.0434s/iter; left time: 368.4377s\n",
      "\titers: 500, epoch: 1 | loss: 0.5648095\n",
      "\tspeed: 0.0433s/iter; left time: 363.7158s\n",
      "\titers: 600, epoch: 1 | loss: 0.4902555\n",
      "\tspeed: 0.0434s/iter; left time: 359.6220s\n",
      "\titers: 700, epoch: 1 | loss: 0.5395623\n",
      "\tspeed: 0.0433s/iter; left time: 354.3923s\n",
      "\titers: 800, epoch: 1 | loss: 0.5115961\n",
      "\tspeed: 0.0433s/iter; left time: 350.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5642094 Vali Loss: 0.5857942 Test Loss: 0.6274691\n",
      "Validation loss decreased (inf --> 0.585794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5886168\n",
      "\tspeed: 0.1535s/iter; left time: 1212.7097s\n",
      "\titers: 200, epoch: 2 | loss: 0.5624777\n",
      "\tspeed: 0.0433s/iter; left time: 337.5492s\n",
      "\titers: 300, epoch: 2 | loss: 0.5613257\n",
      "\tspeed: 0.0434s/iter; left time: 334.1199s\n",
      "\titers: 400, epoch: 2 | loss: 0.5375162\n",
      "\tspeed: 0.0434s/iter; left time: 329.5467s\n",
      "\titers: 500, epoch: 2 | loss: 0.5497366\n",
      "\tspeed: 0.0433s/iter; left time: 324.5267s\n",
      "\titers: 600, epoch: 2 | loss: 0.5392722\n",
      "\tspeed: 0.0433s/iter; left time: 320.3824s\n",
      "\titers: 700, epoch: 2 | loss: 0.4927635\n",
      "\tspeed: 0.0433s/iter; left time: 316.4743s\n",
      "\titers: 800, epoch: 2 | loss: 0.4971849\n",
      "\tspeed: 0.0434s/iter; left time: 312.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.5316510 Vali Loss: 0.5887495 Test Loss: 0.6355409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4743690\n",
      "\tspeed: 0.1516s/iter; left time: 1063.4614s\n",
      "\titers: 200, epoch: 3 | loss: 0.4684273\n",
      "\tspeed: 0.0434s/iter; left time: 299.8641s\n",
      "\titers: 300, epoch: 3 | loss: 0.5384349\n",
      "\tspeed: 0.0434s/iter; left time: 295.6602s\n",
      "\titers: 400, epoch: 3 | loss: 0.5281529\n",
      "\tspeed: 0.0433s/iter; left time: 290.6836s\n",
      "\titers: 500, epoch: 3 | loss: 0.4912407\n",
      "\tspeed: 0.0433s/iter; left time: 286.2018s\n",
      "\titers: 600, epoch: 3 | loss: 0.5095457\n",
      "\tspeed: 0.0433s/iter; left time: 282.3354s\n",
      "\titers: 700, epoch: 3 | loss: 0.4622054\n",
      "\tspeed: 0.0433s/iter; left time: 277.5876s\n",
      "\titers: 800, epoch: 3 | loss: 0.4754922\n",
      "\tspeed: 0.0433s/iter; left time: 273.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.4833817 Vali Loss: 0.5937650 Test Loss: 0.6408314\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4836038\n",
      "\tspeed: 0.1509s/iter; left time: 924.0996s\n",
      "\titers: 200, epoch: 4 | loss: 0.4296790\n",
      "\tspeed: 0.0434s/iter; left time: 261.1547s\n",
      "\titers: 300, epoch: 4 | loss: 0.4317384\n",
      "\tspeed: 0.0434s/iter; left time: 256.8122s\n",
      "\titers: 400, epoch: 4 | loss: 0.3970349\n",
      "\tspeed: 0.0433s/iter; left time: 252.3072s\n",
      "\titers: 500, epoch: 4 | loss: 0.4507579\n",
      "\tspeed: 0.0435s/iter; left time: 248.7202s\n",
      "\titers: 600, epoch: 4 | loss: 0.4092776\n",
      "\tspeed: 0.0434s/iter; left time: 244.0600s\n",
      "\titers: 700, epoch: 4 | loss: 0.4983984\n",
      "\tspeed: 0.0432s/iter; left time: 238.8728s\n",
      "\titers: 800, epoch: 4 | loss: 0.4482481\n",
      "\tspeed: 0.0433s/iter; left time: 234.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4415455 Vali Loss: 0.6122530 Test Loss: 0.6604525\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8160760402679443, rmse:0.9033692479133606, mae:0.6274691224098206, rse:0.715628445148468\n",
      "Original data scale mse:33935912.0, rmse:5825.45361328125, mae:3740.77783203125, rse:0.29025208950042725\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4551</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>0.5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4664</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.6113</td>\n",
       "      <td>0.6841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.6971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8226</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.4435</td>\n",
       "      <td>0.5317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>0.7207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8039</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.7103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.4230</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.4187</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>0.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.7183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.7156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4551  0.6746  0.4416  0.5339\n",
       "              2         24        0.4664  0.6829  0.4506  0.5405\n",
       "              1         96        0.7439  0.8625  0.6113  0.6841\n",
       "              2         96        0.7726  0.8790  0.6245  0.6971\n",
       "              1         168       0.8226  0.9070  0.6497  0.7185\n",
       "              2         168       0.8047  0.8970  0.6460  0.7106\n",
       "RMSE          1         24        0.4513  0.6718  0.4435  0.5317\n",
       "              2         24        0.4518  0.6722  0.4493  0.5320\n",
       "              1         96        0.7535  0.8680  0.6172  0.6884\n",
       "              2         96        0.7755  0.8806  0.6255  0.6985\n",
       "              1         168       0.8276  0.9097  0.6519  0.7207\n",
       "              2         168       0.8039  0.8966  0.6451  0.7103\n",
       "MAE           1         24        0.4612  0.6791  0.4230  0.5375\n",
       "              2         24        0.4455  0.6674  0.4187  0.5282\n",
       "              1         96        0.7656  0.8750  0.5963  0.6940\n",
       "              2         96        0.8202  0.9057  0.6112  0.7183\n",
       "              1         168       0.8244  0.9080  0.6256  0.7193\n",
       "              2         168       0.8161  0.9034  0.6275  0.7156"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17261680.0</td>\n",
       "      <td>4154.7178</td>\n",
       "      <td>2581.1782</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17762658.0</td>\n",
       "      <td>4214.5767</td>\n",
       "      <td>2639.2039</td>\n",
       "      <td>0.2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>30875704.0</td>\n",
       "      <td>5556.5908</td>\n",
       "      <td>3633.8970</td>\n",
       "      <td>0.2767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32792920.0</td>\n",
       "      <td>5726.5103</td>\n",
       "      <td>3746.3784</td>\n",
       "      <td>0.2852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35247892.0</td>\n",
       "      <td>5936.9937</td>\n",
       "      <td>3905.6101</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34226872.0</td>\n",
       "      <td>5850.3735</td>\n",
       "      <td>3899.1096</td>\n",
       "      <td>0.2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17305828.0</td>\n",
       "      <td>4160.0273</td>\n",
       "      <td>2609.1721</td>\n",
       "      <td>0.2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17345650.0</td>\n",
       "      <td>4164.8110</td>\n",
       "      <td>2657.5583</td>\n",
       "      <td>0.2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31262294.0</td>\n",
       "      <td>5591.2695</td>\n",
       "      <td>3673.3840</td>\n",
       "      <td>0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33044252.0</td>\n",
       "      <td>5748.4131</td>\n",
       "      <td>3757.2954</td>\n",
       "      <td>0.2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35287100.0</td>\n",
       "      <td>5940.2944</td>\n",
       "      <td>3912.6470</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34170808.0</td>\n",
       "      <td>5845.5801</td>\n",
       "      <td>3891.9578</td>\n",
       "      <td>0.2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17183404.0</td>\n",
       "      <td>4145.2871</td>\n",
       "      <td>2456.1895</td>\n",
       "      <td>0.2061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16678795.0</td>\n",
       "      <td>4083.9680</td>\n",
       "      <td>2431.3040</td>\n",
       "      <td>0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31555720.0</td>\n",
       "      <td>5617.4478</td>\n",
       "      <td>3527.8032</td>\n",
       "      <td>0.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34537172.0</td>\n",
       "      <td>5876.8335</td>\n",
       "      <td>3631.9407</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35018344.0</td>\n",
       "      <td>5917.6299</td>\n",
       "      <td>3745.1887</td>\n",
       "      <td>0.2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33935912.0</td>\n",
       "      <td>5825.4536</td>\n",
       "      <td>3740.7778</td>\n",
       "      <td>0.2903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17261680.0  4154.7178  2581.1782  0.2066\n",
       "              2         24        17762658.0  4214.5767  2639.2039  0.2096\n",
       "              1         96        30875704.0  5556.5908  3633.8970  0.2767\n",
       "              2         96        32792920.0  5726.5103  3746.3784  0.2852\n",
       "              1         168       35247892.0  5936.9937  3905.6101  0.2958\n",
       "              2         168       34226872.0  5850.3735  3899.1096  0.2915\n",
       "RMSE          1         24        17305828.0  4160.0273  2609.1721  0.2068\n",
       "              2         24        17345650.0  4164.8110  2657.5583  0.2071\n",
       "              1         96        31262294.0  5591.2695  3673.3840  0.2784\n",
       "              2         96        33044252.0  5748.4131  3757.2954  0.2863\n",
       "              1         168       35287100.0  5940.2944  3912.6470  0.2960\n",
       "              2         168       34170808.0  5845.5801  3891.9578  0.2913\n",
       "MAE           1         24        17183404.0  4145.2871  2456.1895  0.2061\n",
       "              2         24        16678795.0  4083.9680  2431.3040  0.2031\n",
       "              1         96        31555720.0  5617.4478  3527.8032  0.2798\n",
       "              2         96        34537172.0  5876.8335  3631.9407  0.2927\n",
       "              1         168       35018344.0  5917.6299  3745.1887  0.2948\n",
       "              2         168       33935912.0  5825.4536  3740.7778  0.2903"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.4208</td>\n",
       "      <td>0.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4608</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.4461</td>\n",
       "      <td>0.5372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.6038</td>\n",
       "      <td>0.7061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.6906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>0.6935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.7146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8158</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.7155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4534  0.6733  0.4208  0.5329\n",
       "         MSE            0.4608  0.6788  0.4461  0.5372\n",
       "         RMSE           0.4515  0.6720  0.4464  0.5318\n",
       "96       MAE            0.7929  0.8903  0.6038  0.7061\n",
       "         MSE            0.7583  0.8708  0.6179  0.6906\n",
       "         RMSE           0.7645  0.8743  0.6214  0.6935\n",
       "168      MAE            0.8203  0.9057  0.6265  0.7175\n",
       "         MSE            0.8137  0.9020  0.6478  0.7146\n",
       "         RMSE           0.8158  0.9032  0.6485  0.7155"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16931099.5</td>\n",
       "      <td>4114.6276</td>\n",
       "      <td>2443.7467</td>\n",
       "      <td>0.2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17512169.0</td>\n",
       "      <td>4184.6472</td>\n",
       "      <td>2610.1910</td>\n",
       "      <td>0.2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17325739.0</td>\n",
       "      <td>4162.4192</td>\n",
       "      <td>2633.3652</td>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>33046446.0</td>\n",
       "      <td>5747.1406</td>\n",
       "      <td>3579.8719</td>\n",
       "      <td>0.2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31834312.0</td>\n",
       "      <td>5641.5505</td>\n",
       "      <td>3690.1377</td>\n",
       "      <td>0.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32153273.0</td>\n",
       "      <td>5669.8413</td>\n",
       "      <td>3715.3397</td>\n",
       "      <td>0.2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34477128.0</td>\n",
       "      <td>5871.5417</td>\n",
       "      <td>3742.9833</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34737382.0</td>\n",
       "      <td>5893.6836</td>\n",
       "      <td>3902.3599</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34728954.0</td>\n",
       "      <td>5892.9373</td>\n",
       "      <td>3902.3024</td>\n",
       "      <td>0.2936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16931099.5  4114.6276  2443.7467  0.2046\n",
       "         MSE            17512169.0  4184.6472  2610.1910  0.2081\n",
       "         RMSE           17325739.0  4162.4192  2633.3652  0.2070\n",
       "96       MAE            33046446.0  5747.1406  3579.8719  0.2862\n",
       "         MSE            31834312.0  5641.5505  3690.1377  0.2810\n",
       "         RMSE           32153273.0  5669.8413  3715.3397  0.2824\n",
       "168      MAE            34477128.0  5871.5417  3742.9833  0.2925\n",
       "         MSE            34737382.0  5893.6836  3902.3599  0.2937\n",
       "         RMSE           34728954.0  5892.9373  3902.3024  0.2936"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
