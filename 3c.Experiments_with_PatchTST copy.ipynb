{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No Patching](#3-no-patching)\n",
    "- [4. Time series decomposition](#4-ts-decomposition)\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = [512, 512, 336, 168, 168]\n",
    "\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2499919\n",
      "\tspeed: 0.0658s/iter; left time: 1460.8138s\n",
      "\titers: 200, epoch: 1 | loss: 0.2436910\n",
      "\tspeed: 0.0406s/iter; left time: 898.0765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.2587705 Vali Loss: 0.2142105 Test Loss: 0.2142683\n",
      "Validation loss decreased (inf --> 0.214210).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1444289\n",
      "\tspeed: 0.0730s/iter; left time: 1604.8517s\n",
      "\titers: 200, epoch: 2 | loss: 0.1144736\n",
      "\tspeed: 0.0406s/iter; left time: 888.4407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.1504814 Vali Loss: 0.1128043 Test Loss: 0.1141900\n",
      "Validation loss decreased (0.214210 --> 0.112804).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0981728\n",
      "\tspeed: 0.0739s/iter; left time: 1607.4491s\n",
      "\titers: 200, epoch: 3 | loss: 0.0966857\n",
      "\tspeed: 0.0407s/iter; left time: 881.5327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.1023327 Vali Loss: 0.1024211 Test Loss: 0.1045258\n",
      "Validation loss decreased (0.112804 --> 0.102421).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0986164\n",
      "\tspeed: 0.0731s/iter; left time: 1574.1318s\n",
      "\titers: 200, epoch: 4 | loss: 0.0926824\n",
      "\tspeed: 0.0405s/iter; left time: 868.4345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0923211 Vali Loss: 0.0976600 Test Loss: 0.1011424\n",
      "Validation loss decreased (0.102421 --> 0.097660).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0845721\n",
      "\tspeed: 0.0730s/iter; left time: 1556.1748s\n",
      "\titers: 200, epoch: 5 | loss: 0.0823605\n",
      "\tspeed: 0.0407s/iter; left time: 862.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0869272 Vali Loss: 0.0991358 Test Loss: 0.1009714\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0904725\n",
      "\tspeed: 0.0726s/iter; left time: 1531.8614s\n",
      "\titers: 200, epoch: 6 | loss: 0.0837727\n",
      "\tspeed: 0.0405s/iter; left time: 850.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0847074 Vali Loss: 0.0954096 Test Loss: 0.0982914\n",
      "Validation loss decreased (0.097660 --> 0.095410).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0801862\n",
      "\tspeed: 0.0734s/iter; left time: 1531.9617s\n",
      "\titers: 200, epoch: 7 | loss: 0.0803515\n",
      "\tspeed: 0.0408s/iter; left time: 846.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0832287 Vali Loss: 0.0951605 Test Loss: 0.0972525\n",
      "Validation loss decreased (0.095410 --> 0.095161).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0804220\n",
      "\tspeed: 0.0736s/iter; left time: 1518.7944s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831103\n",
      "\tspeed: 0.0406s/iter; left time: 834.1243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0819955 Vali Loss: 0.0937350 Test Loss: 0.0955580\n",
      "Validation loss decreased (0.095161 --> 0.093735).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0793873\n",
      "\tspeed: 0.0733s/iter; left time: 1496.4164s\n",
      "\titers: 200, epoch: 9 | loss: 0.0803101\n",
      "\tspeed: 0.0407s/iter; left time: 827.1249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0811540 Vali Loss: 0.0927585 Test Loss: 0.0953479\n",
      "Validation loss decreased (0.093735 --> 0.092758).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0782375\n",
      "\tspeed: 0.0731s/iter; left time: 1475.5020s\n",
      "\titers: 200, epoch: 10 | loss: 0.0773353\n",
      "\tspeed: 0.0405s/iter; left time: 814.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0800262 Vali Loss: 0.0921328 Test Loss: 0.0946891\n",
      "Validation loss decreased (0.092758 --> 0.092133).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0823820\n",
      "\tspeed: 0.0737s/iter; left time: 1471.4809s\n",
      "\titers: 200, epoch: 11 | loss: 0.0817686\n",
      "\tspeed: 0.0408s/iter; left time: 810.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0796635 Vali Loss: 0.0937218 Test Loss: 0.0953466\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0754142\n",
      "\tspeed: 0.0732s/iter; left time: 1445.2342s\n",
      "\titers: 200, epoch: 12 | loss: 0.0828499\n",
      "\tspeed: 0.0407s/iter; left time: 799.6367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0791359 Vali Loss: 0.0927852 Test Loss: 0.0945764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757163\n",
      "\tspeed: 0.0730s/iter; left time: 1425.1292s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751605\n",
      "\tspeed: 0.0406s/iter; left time: 789.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0785484 Vali Loss: 0.0908916 Test Loss: 0.0931771\n",
      "Validation loss decreased (0.092133 --> 0.090892).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0783123\n",
      "\tspeed: 0.0738s/iter; left time: 1424.8674s\n",
      "\titers: 200, epoch: 14 | loss: 0.0730657\n",
      "\tspeed: 0.0408s/iter; left time: 782.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0783134 Vali Loss: 0.0914211 Test Loss: 0.0944387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0774497\n",
      "\tspeed: 0.0729s/iter; left time: 1390.6462s\n",
      "\titers: 200, epoch: 15 | loss: 0.0728654\n",
      "\tspeed: 0.0407s/iter; left time: 772.6495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0776525 Vali Loss: 0.0905649 Test Loss: 0.0927544\n",
      "Validation loss decreased (0.090892 --> 0.090565).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0790887\n",
      "\tspeed: 0.0738s/iter; left time: 1391.1247s\n",
      "\titers: 200, epoch: 16 | loss: 0.0848109\n",
      "\tspeed: 0.0408s/iter; left time: 764.5445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0773813 Vali Loss: 0.0902008 Test Loss: 0.0929217\n",
      "Validation loss decreased (0.090565 --> 0.090201).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0758974\n",
      "\tspeed: 0.0733s/iter; left time: 1365.3199s\n",
      "\titers: 200, epoch: 17 | loss: 0.0838227\n",
      "\tspeed: 0.0408s/iter; left time: 756.0861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0771536 Vali Loss: 0.0904575 Test Loss: 0.0925641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0757755\n",
      "\tspeed: 0.0737s/iter; left time: 1355.9004s\n",
      "\titers: 200, epoch: 18 | loss: 0.0695810\n",
      "\tspeed: 0.0406s/iter; left time: 743.9856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0770377 Vali Loss: 0.0901770 Test Loss: 0.0923888\n",
      "Validation loss decreased (0.090201 --> 0.090177).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788964\n",
      "\tspeed: 0.0735s/iter; left time: 1336.5116s\n",
      "\titers: 200, epoch: 19 | loss: 0.0844894\n",
      "\tspeed: 0.0407s/iter; left time: 735.8726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0769240 Vali Loss: 0.0897702 Test Loss: 0.0919861\n",
      "Validation loss decreased (0.090177 --> 0.089770).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0775444\n",
      "\tspeed: 0.0737s/iter; left time: 1324.1760s\n",
      "\titers: 200, epoch: 20 | loss: 0.0746429\n",
      "\tspeed: 0.0407s/iter; left time: 727.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0764474 Vali Loss: 0.0902695 Test Loss: 0.0922728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0802677\n",
      "\tspeed: 0.0740s/iter; left time: 1313.1684s\n",
      "\titers: 200, epoch: 21 | loss: 0.0794932\n",
      "\tspeed: 0.0412s/iter; left time: 726.6119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0762567 Vali Loss: 0.0901378 Test Loss: 0.0922254\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0770537\n",
      "\tspeed: 0.0729s/iter; left time: 1277.6140s\n",
      "\titers: 200, epoch: 22 | loss: 0.0755091\n",
      "\tspeed: 0.0406s/iter; left time: 707.7604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0761860 Vali Loss: 0.0894913 Test Loss: 0.0918291\n",
      "Validation loss decreased (0.089770 --> 0.089491).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0777771\n",
      "\tspeed: 0.0741s/iter; left time: 1281.5458s\n",
      "\titers: 200, epoch: 23 | loss: 0.0789890\n",
      "\tspeed: 0.0406s/iter; left time: 698.1924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0762359 Vali Loss: 0.0894669 Test Loss: 0.0919503\n",
      "Validation loss decreased (0.089491 --> 0.089467).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0799321\n",
      "\tspeed: 0.0741s/iter; left time: 1265.6626s\n",
      "\titers: 200, epoch: 24 | loss: 0.0719270\n",
      "\tspeed: 0.0409s/iter; left time: 694.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0760288 Vali Loss: 0.0891843 Test Loss: 0.0916291\n",
      "Validation loss decreased (0.089467 --> 0.089184).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0755746\n",
      "\tspeed: 0.0747s/iter; left time: 1257.9010s\n",
      "\titers: 200, epoch: 25 | loss: 0.0722538\n",
      "\tspeed: 0.0406s/iter; left time: 680.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0758618 Vali Loss: 0.0900205 Test Loss: 0.0921426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0737276\n",
      "\tspeed: 0.0731s/iter; left time: 1215.3027s\n",
      "\titers: 200, epoch: 26 | loss: 0.0673043\n",
      "\tspeed: 0.0408s/iter; left time: 674.2375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0758111 Vali Loss: 0.0891910 Test Loss: 0.0915482\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0730214\n",
      "\tspeed: 0.0733s/iter; left time: 1202.0108s\n",
      "\titers: 200, epoch: 27 | loss: 0.0759810\n",
      "\tspeed: 0.0406s/iter; left time: 661.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0757108 Vali Loss: 0.0891556 Test Loss: 0.0914952\n",
      "Validation loss decreased (0.089184 --> 0.089156).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0771012\n",
      "\tspeed: 0.0735s/iter; left time: 1189.8955s\n",
      "\titers: 200, epoch: 28 | loss: 0.0760731\n",
      "\tspeed: 0.0406s/iter; left time: 652.8488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0756882 Vali Loss: 0.0890177 Test Loss: 0.0914545\n",
      "Validation loss decreased (0.089156 --> 0.089018).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0769613\n",
      "\tspeed: 0.0737s/iter; left time: 1175.7426s\n",
      "\titers: 200, epoch: 29 | loss: 0.0793866\n",
      "\tspeed: 0.0405s/iter; left time: 642.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0755070 Vali Loss: 0.0891815 Test Loss: 0.0915899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0799019\n",
      "\tspeed: 0.0724s/iter; left time: 1138.8449s\n",
      "\titers: 200, epoch: 30 | loss: 0.0709466\n",
      "\tspeed: 0.0407s/iter; left time: 636.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0754872 Vali Loss: 0.0889884 Test Loss: 0.0913857\n",
      "Validation loss decreased (0.089018 --> 0.088988).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0772122\n",
      "\tspeed: 0.0734s/iter; left time: 1137.9824s\n",
      "\titers: 200, epoch: 31 | loss: 0.0749073\n",
      "\tspeed: 0.0407s/iter; left time: 627.4633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0756048 Vali Loss: 0.0890902 Test Loss: 0.0914594\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0750521\n",
      "\tspeed: 0.0730s/iter; left time: 1116.4423s\n",
      "\titers: 200, epoch: 32 | loss: 0.0714288\n",
      "\tspeed: 0.0405s/iter; left time: 615.0117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0753802 Vali Loss: 0.0892077 Test Loss: 0.0914487\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0754758\n",
      "\tspeed: 0.0731s/iter; left time: 1100.5299s\n",
      "\titers: 200, epoch: 33 | loss: 0.0736746\n",
      "\tspeed: 0.0408s/iter; left time: 610.0020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0753398 Vali Loss: 0.0888427 Test Loss: 0.0911820\n",
      "Validation loss decreased (0.088988 --> 0.088843).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0780085\n",
      "\tspeed: 0.0736s/iter; left time: 1092.1198s\n",
      "\titers: 200, epoch: 34 | loss: 0.0827072\n",
      "\tspeed: 0.0407s/iter; left time: 599.8373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0754376 Vali Loss: 0.0886854 Test Loss: 0.0912371\n",
      "Validation loss decreased (0.088843 --> 0.088685).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0754874\n",
      "\tspeed: 0.0739s/iter; left time: 1080.0398s\n",
      "\titers: 200, epoch: 35 | loss: 0.0765214\n",
      "\tspeed: 0.0406s/iter; left time: 589.1172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0751991 Vali Loss: 0.0887921 Test Loss: 0.0912284\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0704297\n",
      "\tspeed: 0.0735s/iter; left time: 1057.7101s\n",
      "\titers: 200, epoch: 36 | loss: 0.0678000\n",
      "\tspeed: 0.0408s/iter; left time: 582.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0752452 Vali Loss: 0.0890741 Test Loss: 0.0913816\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0751649\n",
      "\tspeed: 0.0740s/iter; left time: 1048.2918s\n",
      "\titers: 200, epoch: 37 | loss: 0.0667919\n",
      "\tspeed: 0.0407s/iter; left time: 572.2563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0751544 Vali Loss: 0.0895227 Test Loss: 0.0917092\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0733178\n",
      "\tspeed: 0.0728s/iter; left time: 1016.0476s\n",
      "\titers: 200, epoch: 38 | loss: 0.0748011\n",
      "\tspeed: 0.0407s/iter; left time: 564.0559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0752542 Vali Loss: 0.0889293 Test Loss: 0.0913233\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0749977\n",
      "\tspeed: 0.0728s/iter; left time: 999.0728s\n",
      "\titers: 200, epoch: 39 | loss: 0.0753593\n",
      "\tspeed: 0.0408s/iter; left time: 555.3169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0751538 Vali Loss: 0.0889531 Test Loss: 0.0914155\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0715109\n",
      "\tspeed: 0.0732s/iter; left time: 988.9210s\n",
      "\titers: 200, epoch: 40 | loss: 0.0728657\n",
      "\tspeed: 0.0406s/iter; left time: 544.0460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0750966 Vali Loss: 0.0888149 Test Loss: 0.0912853\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0752533\n",
      "\tspeed: 0.0726s/iter; left time: 964.3129s\n",
      "\titers: 200, epoch: 41 | loss: 0.0700043\n",
      "\tspeed: 0.0405s/iter; left time: 534.0720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0750710 Vali Loss: 0.0891853 Test Loss: 0.0914680\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0787514\n",
      "\tspeed: 0.0721s/iter; left time: 941.1671s\n",
      "\titers: 200, epoch: 42 | loss: 0.0725864\n",
      "\tspeed: 0.0406s/iter; left time: 525.5893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0751097 Vali Loss: 0.0889587 Test Loss: 0.0911660\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0719825\n",
      "\tspeed: 0.0727s/iter; left time: 933.3287s\n",
      "\titers: 200, epoch: 43 | loss: 0.0771057\n",
      "\tspeed: 0.0406s/iter; left time: 517.3801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0751448 Vali Loss: 0.0888525 Test Loss: 0.0911740\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0768098\n",
      "\tspeed: 0.0723s/iter; left time: 912.4304s\n",
      "\titers: 200, epoch: 44 | loss: 0.0772383\n",
      "\tspeed: 0.0405s/iter; left time: 507.0488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0750597 Vali Loss: 0.0886218 Test Loss: 0.0911328\n",
      "Validation loss decreased (0.088685 --> 0.088622).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0779737\n",
      "\tspeed: 0.0741s/iter; left time: 917.4950s\n",
      "\titers: 200, epoch: 45 | loss: 0.0755863\n",
      "\tspeed: 0.0407s/iter; left time: 500.7758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0750743 Vali Loss: 0.0887918 Test Loss: 0.0912314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0722934\n",
      "\tspeed: 0.0728s/iter; left time: 885.1862s\n",
      "\titers: 200, epoch: 46 | loss: 0.0699959\n",
      "\tspeed: 0.0407s/iter; left time: 490.9774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0749830 Vali Loss: 0.0889013 Test Loss: 0.0912362\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0759183\n",
      "\tspeed: 0.0736s/iter; left time: 878.5527s\n",
      "\titers: 200, epoch: 47 | loss: 0.0749620\n",
      "\tspeed: 0.0406s/iter; left time: 480.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0749101 Vali Loss: 0.0888265 Test Loss: 0.0911309\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0698817\n",
      "\tspeed: 0.0726s/iter; left time: 851.1191s\n",
      "\titers: 200, epoch: 48 | loss: 0.0821849\n",
      "\tspeed: 0.0411s/iter; left time: 477.1904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0750398 Vali Loss: 0.0890523 Test Loss: 0.0912561\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0728214\n",
      "\tspeed: 0.0735s/iter; left time: 844.5457s\n",
      "\titers: 200, epoch: 49 | loss: 0.0714761\n",
      "\tspeed: 0.0408s/iter; left time: 464.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0750492 Vali Loss: 0.0888740 Test Loss: 0.0912737\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0724019\n",
      "\tspeed: 0.0730s/iter; left time: 822.9129s\n",
      "\titers: 200, epoch: 50 | loss: 0.0741286\n",
      "\tspeed: 0.0406s/iter; left time: 453.3994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0750670 Vali Loss: 0.0887359 Test Loss: 0.0911868\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0787290\n",
      "\tspeed: 0.0725s/iter; left time: 801.3948s\n",
      "\titers: 200, epoch: 51 | loss: 0.0753462\n",
      "\tspeed: 0.0404s/iter; left time: 442.7808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0749521 Vali Loss: 0.0887865 Test Loss: 0.0912171\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0740552\n",
      "\tspeed: 0.0723s/iter; left time: 783.1845s\n",
      "\titers: 200, epoch: 52 | loss: 0.0765331\n",
      "\tspeed: 0.0404s/iter; left time: 433.8159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 223 | Train Loss: 0.0749272 Vali Loss: 0.0887596 Test Loss: 0.0911566\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0752389\n",
      "\tspeed: 0.0730s/iter; left time: 774.3844s\n",
      "\titers: 200, epoch: 53 | loss: 0.0749326\n",
      "\tspeed: 0.0406s/iter; left time: 426.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0749209 Vali Loss: 0.0891328 Test Loss: 0.0914290\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0763818\n",
      "\tspeed: 0.0723s/iter; left time: 750.4049s\n",
      "\titers: 200, epoch: 54 | loss: 0.0732591\n",
      "\tspeed: 0.0404s/iter; left time: 415.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 223 | Train Loss: 0.0749576 Vali Loss: 0.0889539 Test Loss: 0.0911720\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021490950137376785, rmse:0.14659792184829712, mae:0.09113281220197678, rse:0.5173643827438354\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2490839\n",
      "\tspeed: 0.0424s/iter; left time: 940.5830s\n",
      "\titers: 200, epoch: 1 | loss: 0.2472512\n",
      "\tspeed: 0.0404s/iter; left time: 893.8779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.2592057 Vali Loss: 0.2150097 Test Loss: 0.2137868\n",
      "Validation loss decreased (inf --> 0.215010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1459719\n",
      "\tspeed: 0.0749s/iter; left time: 1647.1686s\n",
      "\titers: 200, epoch: 2 | loss: 0.1184580\n",
      "\tspeed: 0.0405s/iter; left time: 885.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.1509299 Vali Loss: 0.1149763 Test Loss: 0.1172944\n",
      "Validation loss decreased (0.215010 --> 0.114976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1085657\n",
      "\tspeed: 0.0739s/iter; left time: 1608.4739s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910014\n",
      "\tspeed: 0.0405s/iter; left time: 876.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.1019505 Vali Loss: 0.1020273 Test Loss: 0.1047064\n",
      "Validation loss decreased (0.114976 --> 0.102027).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0922076\n",
      "\tspeed: 0.0742s/iter; left time: 1598.6307s\n",
      "\titers: 200, epoch: 4 | loss: 0.0915935\n",
      "\tspeed: 0.0405s/iter; left time: 867.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0911547 Vali Loss: 0.0988794 Test Loss: 0.1018604\n",
      "Validation loss decreased (0.102027 --> 0.098879).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0869290\n",
      "\tspeed: 0.0738s/iter; left time: 1573.3247s\n",
      "\titers: 200, epoch: 5 | loss: 0.0920424\n",
      "\tspeed: 0.0404s/iter; left time: 857.3965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0867149 Vali Loss: 0.0959272 Test Loss: 0.0990677\n",
      "Validation loss decreased (0.098879 --> 0.095927).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0805324\n",
      "\tspeed: 0.0740s/iter; left time: 1559.9050s\n",
      "\titers: 200, epoch: 6 | loss: 0.0808611\n",
      "\tspeed: 0.0409s/iter; left time: 857.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0846302 Vali Loss: 0.0953569 Test Loss: 0.0985537\n",
      "Validation loss decreased (0.095927 --> 0.095357).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0785462\n",
      "\tspeed: 0.0739s/iter; left time: 1541.7431s\n",
      "\titers: 200, epoch: 7 | loss: 0.0870119\n",
      "\tspeed: 0.0404s/iter; left time: 839.4817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0828189 Vali Loss: 0.0946173 Test Loss: 0.0970928\n",
      "Validation loss decreased (0.095357 --> 0.094617).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0830550\n",
      "\tspeed: 0.0743s/iter; left time: 1533.9439s\n",
      "\titers: 200, epoch: 8 | loss: 0.0783509\n",
      "\tspeed: 0.0405s/iter; left time: 830.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0819139 Vali Loss: 0.0929983 Test Loss: 0.0954704\n",
      "Validation loss decreased (0.094617 --> 0.092998).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0828439\n",
      "\tspeed: 0.0738s/iter; left time: 1506.3108s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793067\n",
      "\tspeed: 0.0405s/iter; left time: 823.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0810855 Vali Loss: 0.0931124 Test Loss: 0.0957941\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0794291\n",
      "\tspeed: 0.0738s/iter; left time: 1491.0702s\n",
      "\titers: 200, epoch: 10 | loss: 0.0810912\n",
      "\tspeed: 0.0405s/iter; left time: 813.5412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0799131 Vali Loss: 0.0918286 Test Loss: 0.0939341\n",
      "Validation loss decreased (0.092998 --> 0.091829).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0799937\n",
      "\tspeed: 0.0739s/iter; left time: 1476.1767s\n",
      "\titers: 200, epoch: 11 | loss: 0.0784184\n",
      "\tspeed: 0.0404s/iter; left time: 802.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0799298 Vali Loss: 0.0915549 Test Loss: 0.0937229\n",
      "Validation loss decreased (0.091829 --> 0.091555).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0813086\n",
      "\tspeed: 0.0744s/iter; left time: 1468.5366s\n",
      "\titers: 200, epoch: 12 | loss: 0.0809460\n",
      "\tspeed: 0.0405s/iter; left time: 795.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0788708 Vali Loss: 0.0908034 Test Loss: 0.0935894\n",
      "Validation loss decreased (0.091555 --> 0.090803).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783942\n",
      "\tspeed: 0.0741s/iter; left time: 1447.0675s\n",
      "\titers: 200, epoch: 13 | loss: 0.0777297\n",
      "\tspeed: 0.0404s/iter; left time: 785.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0781689 Vali Loss: 0.0904064 Test Loss: 0.0931068\n",
      "Validation loss decreased (0.090803 --> 0.090406).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0749564\n",
      "\tspeed: 0.0740s/iter; left time: 1428.0823s\n",
      "\titers: 200, epoch: 14 | loss: 0.0798429\n",
      "\tspeed: 0.0404s/iter; left time: 775.9453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0777671 Vali Loss: 0.0901483 Test Loss: 0.0928477\n",
      "Validation loss decreased (0.090406 --> 0.090148).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0729283\n",
      "\tspeed: 0.0744s/iter; left time: 1419.9873s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799183\n",
      "\tspeed: 0.0408s/iter; left time: 773.7138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0773314 Vali Loss: 0.0902604 Test Loss: 0.0926346\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0805474\n",
      "\tspeed: 0.0739s/iter; left time: 1394.0597s\n",
      "\titers: 200, epoch: 16 | loss: 0.0798859\n",
      "\tspeed: 0.0405s/iter; left time: 758.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0775261 Vali Loss: 0.0915505 Test Loss: 0.0935391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0801417\n",
      "\tspeed: 0.0743s/iter; left time: 1383.7399s\n",
      "\titers: 200, epoch: 17 | loss: 0.0805798\n",
      "\tspeed: 0.0410s/iter; left time: 760.6452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0773038 Vali Loss: 0.0897665 Test Loss: 0.0923034\n",
      "Validation loss decreased (0.090148 --> 0.089767).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0717844\n",
      "\tspeed: 0.0740s/iter; left time: 1362.0225s\n",
      "\titers: 200, epoch: 18 | loss: 0.0810524\n",
      "\tspeed: 0.0404s/iter; left time: 740.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0767832 Vali Loss: 0.0896475 Test Loss: 0.0923133\n",
      "Validation loss decreased (0.089767 --> 0.089647).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0745617\n",
      "\tspeed: 0.0744s/iter; left time: 1353.3911s\n",
      "\titers: 200, epoch: 19 | loss: 0.0777391\n",
      "\tspeed: 0.0404s/iter; left time: 731.3619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0767936 Vali Loss: 0.0906551 Test Loss: 0.0926315\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0831475\n",
      "\tspeed: 0.0750s/iter; left time: 1346.4112s\n",
      "\titers: 200, epoch: 20 | loss: 0.0784714\n",
      "\tspeed: 0.0407s/iter; left time: 726.4181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0763930 Vali Loss: 0.0905861 Test Loss: 0.0925194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0737767\n",
      "\tspeed: 0.0739s/iter; left time: 1311.7471s\n",
      "\titers: 200, epoch: 21 | loss: 0.0791329\n",
      "\tspeed: 0.0411s/iter; left time: 725.2459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0762994 Vali Loss: 0.0893644 Test Loss: 0.0919495\n",
      "Validation loss decreased (0.089647 --> 0.089364).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0721182\n",
      "\tspeed: 0.0740s/iter; left time: 1296.3618s\n",
      "\titers: 200, epoch: 22 | loss: 0.0774618\n",
      "\tspeed: 0.0404s/iter; left time: 704.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0760505 Vali Loss: 0.0894501 Test Loss: 0.0918606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0720288\n",
      "\tspeed: 0.0733s/iter; left time: 1268.2947s\n",
      "\titers: 200, epoch: 23 | loss: 0.0820614\n",
      "\tspeed: 0.0409s/iter; left time: 702.9506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0760261 Vali Loss: 0.0895003 Test Loss: 0.0916805\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0764086\n",
      "\tspeed: 0.0743s/iter; left time: 1268.0780s\n",
      "\titers: 200, epoch: 24 | loss: 0.0725959\n",
      "\tspeed: 0.0406s/iter; left time: 689.2166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0760008 Vali Loss: 0.0896566 Test Loss: 0.0917640\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0786116\n",
      "\tspeed: 0.0742s/iter; left time: 1250.0979s\n",
      "\titers: 200, epoch: 25 | loss: 0.0806988\n",
      "\tspeed: 0.0406s/iter; left time: 679.1920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0759024 Vali Loss: 0.0898015 Test Loss: 0.0920800\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0746573\n",
      "\tspeed: 0.0742s/iter; left time: 1233.6015s\n",
      "\titers: 200, epoch: 26 | loss: 0.0807535\n",
      "\tspeed: 0.0404s/iter; left time: 668.4374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0757923 Vali Loss: 0.0896346 Test Loss: 0.0917760\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722282\n",
      "\tspeed: 0.0739s/iter; left time: 1212.1805s\n",
      "\titers: 200, epoch: 27 | loss: 0.0755098\n",
      "\tspeed: 0.0409s/iter; left time: 666.1233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0757295 Vali Loss: 0.0904972 Test Loss: 0.0922839\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0760738\n",
      "\tspeed: 0.0738s/iter; left time: 1194.1319s\n",
      "\titers: 200, epoch: 28 | loss: 0.0779437\n",
      "\tspeed: 0.0405s/iter; left time: 650.6543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0756201 Vali Loss: 0.0896967 Test Loss: 0.0918662\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0767091\n",
      "\tspeed: 0.0736s/iter; left time: 1174.1355s\n",
      "\titers: 200, epoch: 29 | loss: 0.0785072\n",
      "\tspeed: 0.0405s/iter; left time: 641.4380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0755951 Vali Loss: 0.0890588 Test Loss: 0.0913929\n",
      "Validation loss decreased (0.089364 --> 0.089059).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0739342\n",
      "\tspeed: 0.0740s/iter; left time: 1163.6194s\n",
      "\titers: 200, epoch: 30 | loss: 0.0765195\n",
      "\tspeed: 0.0404s/iter; left time: 632.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0755656 Vali Loss: 0.0892964 Test Loss: 0.0915140\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0735635\n",
      "\tspeed: 0.0735s/iter; left time: 1139.7656s\n",
      "\titers: 200, epoch: 31 | loss: 0.0765849\n",
      "\tspeed: 0.0404s/iter; left time: 622.7313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0752674 Vali Loss: 0.0891411 Test Loss: 0.0913493\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0837285\n",
      "\tspeed: 0.0734s/iter; left time: 1121.9148s\n",
      "\titers: 200, epoch: 32 | loss: 0.0738451\n",
      "\tspeed: 0.0407s/iter; left time: 617.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0752781 Vali Loss: 0.0888913 Test Loss: 0.0913681\n",
      "Validation loss decreased (0.089059 --> 0.088891).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0746147\n",
      "\tspeed: 0.0743s/iter; left time: 1119.3678s\n",
      "\titers: 200, epoch: 33 | loss: 0.0797450\n",
      "\tspeed: 0.0404s/iter; left time: 605.2894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0753205 Vali Loss: 0.0897216 Test Loss: 0.0917012\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0774863\n",
      "\tspeed: 0.0737s/iter; left time: 1093.7600s\n",
      "\titers: 200, epoch: 34 | loss: 0.0765698\n",
      "\tspeed: 0.0404s/iter; left time: 596.2525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0752888 Vali Loss: 0.0890659 Test Loss: 0.0913897\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0722521\n",
      "\tspeed: 0.0736s/iter; left time: 1076.5117s\n",
      "\titers: 200, epoch: 35 | loss: 0.0744749\n",
      "\tspeed: 0.0404s/iter; left time: 587.1158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0752661 Vali Loss: 0.0889065 Test Loss: 0.0914638\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0719926\n",
      "\tspeed: 0.0733s/iter; left time: 1055.9039s\n",
      "\titers: 200, epoch: 36 | loss: 0.0778509\n",
      "\tspeed: 0.0426s/iter; left time: 608.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0751457 Vali Loss: 0.0891029 Test Loss: 0.0912891\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752357\n",
      "\tspeed: 0.0736s/iter; left time: 1043.4570s\n",
      "\titers: 200, epoch: 37 | loss: 0.0760674\n",
      "\tspeed: 0.0410s/iter; left time: 576.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0751595 Vali Loss: 0.0890321 Test Loss: 0.0913641\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0730760\n",
      "\tspeed: 0.0738s/iter; left time: 1029.5801s\n",
      "\titers: 200, epoch: 38 | loss: 0.0733152\n",
      "\tspeed: 0.0405s/iter; left time: 560.4740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 223 | Train Loss: 0.0750889 Vali Loss: 0.0892685 Test Loss: 0.0913550\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0731313\n",
      "\tspeed: 0.0740s/iter; left time: 1016.0448s\n",
      "\titers: 200, epoch: 39 | loss: 0.0802235\n",
      "\tspeed: 0.0406s/iter; left time: 552.8457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0751633 Vali Loss: 0.0890973 Test Loss: 0.0913351\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0782451\n",
      "\tspeed: 0.0738s/iter; left time: 997.0832s\n",
      "\titers: 200, epoch: 40 | loss: 0.0770663\n",
      "\tspeed: 0.0405s/iter; left time: 543.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0750894 Vali Loss: 0.0888284 Test Loss: 0.0911175\n",
      "Validation loss decreased (0.088891 --> 0.088828).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0729259\n",
      "\tspeed: 0.0745s/iter; left time: 988.7966s\n",
      "\titers: 200, epoch: 41 | loss: 0.0800762\n",
      "\tspeed: 0.0407s/iter; left time: 536.8266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0751201 Vali Loss: 0.0890968 Test Loss: 0.0913125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0744944\n",
      "\tspeed: 0.0739s/iter; left time: 964.4323s\n",
      "\titers: 200, epoch: 42 | loss: 0.0714591\n",
      "\tspeed: 0.0404s/iter; left time: 524.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 223 | Train Loss: 0.0750512 Vali Loss: 0.0891539 Test Loss: 0.0913914\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0745371\n",
      "\tspeed: 0.0740s/iter; left time: 950.2899s\n",
      "\titers: 200, epoch: 43 | loss: 0.0727399\n",
      "\tspeed: 0.0409s/iter; left time: 520.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 223 | Train Loss: 0.0750380 Vali Loss: 0.0888861 Test Loss: 0.0912264\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0763964\n",
      "\tspeed: 0.0738s/iter; left time: 930.8001s\n",
      "\titers: 200, epoch: 44 | loss: 0.0757533\n",
      "\tspeed: 0.0405s/iter; left time: 506.4672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 223 | Train Loss: 0.0750093 Vali Loss: 0.0889866 Test Loss: 0.0912434\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0779515\n",
      "\tspeed: 0.0744s/iter; left time: 921.3173s\n",
      "\titers: 200, epoch: 45 | loss: 0.0768006\n",
      "\tspeed: 0.0405s/iter; left time: 497.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0749965 Vali Loss: 0.0889191 Test Loss: 0.0911606\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0754055\n",
      "\tspeed: 0.0738s/iter; left time: 898.3389s\n",
      "\titers: 200, epoch: 46 | loss: 0.0713660\n",
      "\tspeed: 0.0405s/iter; left time: 488.1449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 223 | Train Loss: 0.0750679 Vali Loss: 0.0890442 Test Loss: 0.0913261\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0809722\n",
      "\tspeed: 0.0740s/iter; left time: 883.5226s\n",
      "\titers: 200, epoch: 47 | loss: 0.0759240\n",
      "\tspeed: 0.0405s/iter; left time: 479.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0749856 Vali Loss: 0.0891433 Test Loss: 0.0912630\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0784684\n",
      "\tspeed: 0.0736s/iter; left time: 862.9615s\n",
      "\titers: 200, epoch: 48 | loss: 0.0805372\n",
      "\tspeed: 0.0406s/iter; left time: 471.4583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0749227 Vali Loss: 0.0891498 Test Loss: 0.0913095\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0751135\n",
      "\tspeed: 0.0739s/iter; left time: 850.0897s\n",
      "\titers: 200, epoch: 49 | loss: 0.0722965\n",
      "\tspeed: 0.0405s/iter; left time: 461.0816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0750630 Vali Loss: 0.0889131 Test Loss: 0.0911809\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0758723\n",
      "\tspeed: 0.0741s/iter; left time: 835.0764s\n",
      "\titers: 200, epoch: 50 | loss: 0.0768833\n",
      "\tspeed: 0.0405s/iter; left time: 452.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0749795 Vali Loss: 0.0890788 Test Loss: 0.0912218\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021613840013742447, rmse:0.1470164656639099, mae:0.09111756086349487, rse:0.5188414454460144\n",
      "Intermediate time for DE and pred_len 24: 00h:20m:00.30s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2567174\n",
      "\tspeed: 0.0648s/iter; left time: 1432.0993s\n",
      "\titers: 200, epoch: 1 | loss: 0.2369715\n",
      "\tspeed: 0.0406s/iter; left time: 893.8286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.2615639 Vali Loss: 0.2209979 Test Loss: 0.2222324\n",
      "Validation loss decreased (inf --> 0.220998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1564926\n",
      "\tspeed: 0.0745s/iter; left time: 1630.5161s\n",
      "\titers: 200, epoch: 2 | loss: 0.1341260\n",
      "\tspeed: 0.0406s/iter; left time: 884.3588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1608338 Vali Loss: 0.1363482 Test Loss: 0.1418259\n",
      "Validation loss decreased (0.220998 --> 0.136348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1162611\n",
      "\tspeed: 0.0748s/iter; left time: 1619.6686s\n",
      "\titers: 200, epoch: 3 | loss: 0.1177480\n",
      "\tspeed: 0.0406s/iter; left time: 874.7976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1208445 Vali Loss: 0.1277944 Test Loss: 0.1374204\n",
      "Validation loss decreased (0.136348 --> 0.127794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1102845\n",
      "\tspeed: 0.0747s/iter; left time: 1601.3925s\n",
      "\titers: 200, epoch: 4 | loss: 0.1140750\n",
      "\tspeed: 0.0406s/iter; left time: 866.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1129174 Vali Loss: 0.1251605 Test Loss: 0.1341668\n",
      "Validation loss decreased (0.127794 --> 0.125161).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1166949\n",
      "\tspeed: 0.0747s/iter; left time: 1583.5849s\n",
      "\titers: 200, epoch: 5 | loss: 0.1081393\n",
      "\tspeed: 0.0406s/iter; left time: 857.7306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1103549 Vali Loss: 0.1227886 Test Loss: 0.1303220\n",
      "Validation loss decreased (0.125161 --> 0.122789).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062442\n",
      "\tspeed: 0.0738s/iter; left time: 1549.4482s\n",
      "\titers: 200, epoch: 6 | loss: 0.1072186\n",
      "\tspeed: 0.0407s/iter; left time: 850.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1078670 Vali Loss: 0.1219471 Test Loss: 0.1291881\n",
      "Validation loss decreased (0.122789 --> 0.121947).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1061169\n",
      "\tspeed: 0.0746s/iter; left time: 1549.9471s\n",
      "\titers: 200, epoch: 7 | loss: 0.1112051\n",
      "\tspeed: 0.0407s/iter; left time: 840.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1068713 Vali Loss: 0.1213121 Test Loss: 0.1290444\n",
      "Validation loss decreased (0.121947 --> 0.121312).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1057692\n",
      "\tspeed: 0.0750s/iter; left time: 1541.0175s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068326\n",
      "\tspeed: 0.0407s/iter; left time: 832.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1059914 Vali Loss: 0.1224635 Test Loss: 0.1298995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1034219\n",
      "\tspeed: 0.0740s/iter; left time: 1503.2741s\n",
      "\titers: 200, epoch: 9 | loss: 0.0999100\n",
      "\tspeed: 0.0407s/iter; left time: 823.7152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1050044 Vali Loss: 0.1230605 Test Loss: 0.1317926\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1093468\n",
      "\tspeed: 0.0740s/iter; left time: 1486.9577s\n",
      "\titers: 200, epoch: 10 | loss: 0.1081782\n",
      "\tspeed: 0.0406s/iter; left time: 812.3368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1045642 Vali Loss: 0.1219349 Test Loss: 0.1301681\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1027195\n",
      "\tspeed: 0.0738s/iter; left time: 1467.1678s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048118\n",
      "\tspeed: 0.0407s/iter; left time: 805.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.23s\n",
      "Steps: 222 | Train Loss: 0.1038951 Vali Loss: 0.1220826 Test Loss: 0.1309490\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1036500\n",
      "\tspeed: 0.0741s/iter; left time: 1456.2813s\n",
      "\titers: 200, epoch: 12 | loss: 0.0967905\n",
      "\tspeed: 0.0407s/iter; left time: 796.7972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1036535 Vali Loss: 0.1236033 Test Loss: 0.1331385\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1004048\n",
      "\tspeed: 0.0737s/iter; left time: 1432.3356s\n",
      "\titers: 200, epoch: 13 | loss: 0.0993740\n",
      "\tspeed: 0.0406s/iter; left time: 784.7658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 222 | Train Loss: 0.1033556 Vali Loss: 0.1226675 Test Loss: 0.1322711\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1005409\n",
      "\tspeed: 0.0739s/iter; left time: 1420.1313s\n",
      "\titers: 200, epoch: 14 | loss: 0.1024006\n",
      "\tspeed: 0.0406s/iter; left time: 775.8794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.20s\n",
      "Steps: 222 | Train Loss: 0.1029066 Vali Loss: 0.1230128 Test Loss: 0.1320505\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1068955\n",
      "\tspeed: 0.0734s/iter; left time: 1393.3702s\n",
      "\titers: 200, epoch: 15 | loss: 0.1093898\n",
      "\tspeed: 0.0407s/iter; left time: 769.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 222 | Train Loss: 0.1028959 Vali Loss: 0.1227752 Test Loss: 0.1326943\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1076504\n",
      "\tspeed: 0.0761s/iter; left time: 1427.9437s\n",
      "\titers: 200, epoch: 16 | loss: 0.0938831\n",
      "\tspeed: 0.0417s/iter; left time: 779.5070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.1022091 Vali Loss: 0.1224919 Test Loss: 0.1329917\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1013022\n",
      "\tspeed: 0.0749s/iter; left time: 1389.7856s\n",
      "\titers: 200, epoch: 17 | loss: 0.1030388\n",
      "\tspeed: 0.0407s/iter; left time: 750.2474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 222 | Train Loss: 0.1022000 Vali Loss: 0.1220423 Test Loss: 0.1307992\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03688869625329971, rmse:0.1920643001794815, mae:0.12904435396194458, rse:0.6801385283470154\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2674383\n",
      "\tspeed: 0.0427s/iter; left time: 943.7735s\n",
      "\titers: 200, epoch: 1 | loss: 0.2461667\n",
      "\tspeed: 0.0406s/iter; left time: 893.2663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 222 | Train Loss: 0.2638501 Vali Loss: 0.2226131 Test Loss: 0.2216158\n",
      "Validation loss decreased (inf --> 0.222613).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1543895\n",
      "\tspeed: 0.0757s/iter; left time: 1656.3967s\n",
      "\titers: 200, epoch: 2 | loss: 0.1398169\n",
      "\tspeed: 0.0407s/iter; left time: 886.8301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1605066 Vali Loss: 0.1367813 Test Loss: 0.1428790\n",
      "Validation loss decreased (0.222613 --> 0.136781).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1166887\n",
      "\tspeed: 0.0768s/iter; left time: 1663.7442s\n",
      "\titers: 200, epoch: 3 | loss: 0.1116634\n",
      "\tspeed: 0.0408s/iter; left time: 879.9609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1194075 Vali Loss: 0.1278751 Test Loss: 0.1380406\n",
      "Validation loss decreased (0.136781 --> 0.127875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1114147\n",
      "\tspeed: 0.0758s/iter; left time: 1625.6180s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107357\n",
      "\tspeed: 0.0408s/iter; left time: 869.5598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1119658 Vali Loss: 0.1239229 Test Loss: 0.1325669\n",
      "Validation loss decreased (0.127875 --> 0.123923).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1104820\n",
      "\tspeed: 0.0762s/iter; left time: 1616.7930s\n",
      "\titers: 200, epoch: 5 | loss: 0.1076826\n",
      "\tspeed: 0.0406s/iter; left time: 857.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 222 | Train Loss: 0.1088037 Vali Loss: 0.1234485 Test Loss: 0.1317335\n",
      "Validation loss decreased (0.123923 --> 0.123449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1043967\n",
      "\tspeed: 0.0761s/iter; left time: 1596.8855s\n",
      "\titers: 200, epoch: 6 | loss: 0.1043626\n",
      "\tspeed: 0.0407s/iter; left time: 849.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1072132 Vali Loss: 0.1251106 Test Loss: 0.1335774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1115653\n",
      "\tspeed: 0.0770s/iter; left time: 1599.2377s\n",
      "\titers: 200, epoch: 7 | loss: 0.1044515\n",
      "\tspeed: 0.0406s/iter; left time: 838.6782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1065478 Vali Loss: 0.1222214 Test Loss: 0.1305019\n",
      "Validation loss decreased (0.123449 --> 0.122221).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1077851\n",
      "\tspeed: 0.0769s/iter; left time: 1579.0798s\n",
      "\titers: 200, epoch: 8 | loss: 0.1084414\n",
      "\tspeed: 0.0414s/iter; left time: 847.1744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 222 | Train Loss: 0.1052958 Vali Loss: 0.1238670 Test Loss: 0.1318427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1064024\n",
      "\tspeed: 0.0758s/iter; left time: 1541.4378s\n",
      "\titers: 200, epoch: 9 | loss: 0.1059458\n",
      "\tspeed: 0.0407s/iter; left time: 823.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 222 | Train Loss: 0.1049578 Vali Loss: 0.1226378 Test Loss: 0.1321362\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1027817\n",
      "\tspeed: 0.0769s/iter; left time: 1545.3618s\n",
      "\titers: 200, epoch: 10 | loss: 0.1018352\n",
      "\tspeed: 0.0408s/iter; left time: 815.8975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 222 | Train Loss: 0.1040832 Vali Loss: 0.1221598 Test Loss: 0.1312657\n",
      "Validation loss decreased (0.122221 --> 0.122160).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1044997\n",
      "\tspeed: 0.0762s/iter; left time: 1515.3054s\n",
      "\titers: 200, epoch: 11 | loss: 0.1089497\n",
      "\tspeed: 0.0410s/iter; left time: 810.5174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 222 | Train Loss: 0.1037177 Vali Loss: 0.1224726 Test Loss: 0.1325074\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1011573\n",
      "\tspeed: 0.0752s/iter; left time: 1479.2674s\n",
      "\titers: 200, epoch: 12 | loss: 0.1064023\n",
      "\tspeed: 0.0407s/iter; left time: 795.6882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 222 | Train Loss: 0.1033040 Vali Loss: 0.1231317 Test Loss: 0.1332391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020794\n",
      "\tspeed: 0.0748s/iter; left time: 1453.4621s\n",
      "\titers: 200, epoch: 13 | loss: 0.1041973\n",
      "\tspeed: 0.0413s/iter; left time: 798.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1027258 Vali Loss: 0.1206543 Test Loss: 0.1306935\n",
      "Validation loss decreased (0.122160 --> 0.120654).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1010036\n",
      "\tspeed: 0.0763s/iter; left time: 1465.2096s\n",
      "\titers: 200, epoch: 14 | loss: 0.1005691\n",
      "\tspeed: 0.0412s/iter; left time: 787.3859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1023238 Vali Loss: 0.1209531 Test Loss: 0.1310647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1021855\n",
      "\tspeed: 0.0771s/iter; left time: 1463.6128s\n",
      "\titers: 200, epoch: 15 | loss: 0.1030579\n",
      "\tspeed: 0.0409s/iter; left time: 773.2408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1019652 Vali Loss: 0.1216964 Test Loss: 0.1336367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990499\n",
      "\tspeed: 0.0760s/iter; left time: 1426.1772s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013082\n",
      "\tspeed: 0.0411s/iter; left time: 768.1412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1017566 Vali Loss: 0.1207150 Test Loss: 0.1311256\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0989789\n",
      "\tspeed: 0.0756s/iter; left time: 1402.1427s\n",
      "\titers: 200, epoch: 17 | loss: 0.1032420\n",
      "\tspeed: 0.0408s/iter; left time: 752.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1016855 Vali Loss: 0.1216641 Test Loss: 0.1335739\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1009876\n",
      "\tspeed: 0.0770s/iter; left time: 1412.0166s\n",
      "\titers: 200, epoch: 18 | loss: 0.0992788\n",
      "\tspeed: 0.0409s/iter; left time: 745.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1016551 Vali Loss: 0.1225416 Test Loss: 0.1356461\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0994656\n",
      "\tspeed: 0.0760s/iter; left time: 1375.1815s\n",
      "\titers: 200, epoch: 19 | loss: 0.1023100\n",
      "\tspeed: 0.0406s/iter; left time: 731.8847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1011918 Vali Loss: 0.1226855 Test Loss: 0.1347964\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1051435\n",
      "\tspeed: 0.0752s/iter; left time: 1344.7277s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025466\n",
      "\tspeed: 0.0408s/iter; left time: 725.4539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1011156 Vali Loss: 0.1218346 Test Loss: 0.1332678\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033999\n",
      "\tspeed: 0.0756s/iter; left time: 1335.3309s\n",
      "\titers: 200, epoch: 21 | loss: 0.1037384\n",
      "\tspeed: 0.0410s/iter; left time: 719.5225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 222 | Train Loss: 0.1009183 Vali Loss: 0.1211568 Test Loss: 0.1323556\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1021763\n",
      "\tspeed: 0.0752s/iter; left time: 1311.0473s\n",
      "\titers: 200, epoch: 22 | loss: 0.0984414\n",
      "\tspeed: 0.0408s/iter; left time: 707.8167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 222 | Train Loss: 0.1006230 Vali Loss: 0.1213428 Test Loss: 0.1328119\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0972030\n",
      "\tspeed: 0.0762s/iter; left time: 1312.4213s\n",
      "\titers: 200, epoch: 23 | loss: 0.0972501\n",
      "\tspeed: 0.0409s/iter; left time: 700.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.1005551 Vali Loss: 0.1217129 Test Loss: 0.1332923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03879741579294205, rmse:0.196970596909523, mae:0.1306934952735901, rse:0.6975127458572388\n",
      "Intermediate time for DE and pred_len 96: 00h:07m:58.46s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2547011\n",
      "\tspeed: 0.0649s/iter; left time: 1434.3913s\n",
      "\titers: 200, epoch: 1 | loss: 0.2446538\n",
      "\tspeed: 0.0413s/iter; left time: 909.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.2621706 Vali Loss: 0.2210747 Test Loss: 0.2229995\n",
      "Validation loss decreased (inf --> 0.221075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1477357\n",
      "\tspeed: 0.0753s/iter; left time: 1646.9532s\n",
      "\titers: 200, epoch: 2 | loss: 0.1341442\n",
      "\tspeed: 0.0414s/iter; left time: 901.3195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 222 | Train Loss: 0.1630918 Vali Loss: 0.1387679 Test Loss: 0.1472351\n",
      "Validation loss decreased (0.221075 --> 0.138768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1283511\n",
      "\tspeed: 0.0773s/iter; left time: 1673.2325s\n",
      "\titers: 200, epoch: 3 | loss: 0.1233076\n",
      "\tspeed: 0.0415s/iter; left time: 894.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1242776 Vali Loss: 0.1343270 Test Loss: 0.1477458\n",
      "Validation loss decreased (0.138768 --> 0.134327).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1228040\n",
      "\tspeed: 0.0763s/iter; left time: 1636.0119s\n",
      "\titers: 200, epoch: 4 | loss: 0.1145430\n",
      "\tspeed: 0.0415s/iter; left time: 884.3793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 222 | Train Loss: 0.1177692 Vali Loss: 0.1332793 Test Loss: 0.1471356\n",
      "Validation loss decreased (0.134327 --> 0.133279).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1108847\n",
      "\tspeed: 0.0759s/iter; left time: 1609.3516s\n",
      "\titers: 200, epoch: 5 | loss: 0.1184591\n",
      "\tspeed: 0.0414s/iter; left time: 873.9368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1150895 Vali Loss: 0.1292599 Test Loss: 0.1394582\n",
      "Validation loss decreased (0.133279 --> 0.129260).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1109404\n",
      "\tspeed: 0.0769s/iter; left time: 1614.6553s\n",
      "\titers: 200, epoch: 6 | loss: 0.1151391\n",
      "\tspeed: 0.0413s/iter; left time: 863.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.1130198 Vali Loss: 0.1282362 Test Loss: 0.1374332\n",
      "Validation loss decreased (0.129260 --> 0.128236).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1107276\n",
      "\tspeed: 0.0772s/iter; left time: 1603.9556s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117783\n",
      "\tspeed: 0.0416s/iter; left time: 859.2919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 222 | Train Loss: 0.1117408 Vali Loss: 0.1297795 Test Loss: 0.1401883\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1098032\n",
      "\tspeed: 0.0757s/iter; left time: 1555.5269s\n",
      "\titers: 200, epoch: 8 | loss: 0.1121785\n",
      "\tspeed: 0.0416s/iter; left time: 849.6746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1110236 Vali Loss: 0.1291916 Test Loss: 0.1372601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1095344\n",
      "\tspeed: 0.0752s/iter; left time: 1527.6213s\n",
      "\titers: 200, epoch: 9 | loss: 0.1124224\n",
      "\tspeed: 0.0416s/iter; left time: 841.2329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 222 | Train Loss: 0.1099584 Vali Loss: 0.1276474 Test Loss: 0.1373459\n",
      "Validation loss decreased (0.128236 --> 0.127647).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1069649\n",
      "\tspeed: 0.0766s/iter; left time: 1540.7017s\n",
      "\titers: 200, epoch: 10 | loss: 0.1128789\n",
      "\tspeed: 0.0415s/iter; left time: 829.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.1094869 Vali Loss: 0.1279376 Test Loss: 0.1391968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1130599\n",
      "\tspeed: 0.0759s/iter; left time: 1508.8837s\n",
      "\titers: 200, epoch: 11 | loss: 0.1103044\n",
      "\tspeed: 0.0414s/iter; left time: 818.9556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1087799 Vali Loss: 0.1274702 Test Loss: 0.1376306\n",
      "Validation loss decreased (0.127647 --> 0.127470).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1128469\n",
      "\tspeed: 0.0758s/iter; left time: 1490.2098s\n",
      "\titers: 200, epoch: 12 | loss: 0.1105351\n",
      "\tspeed: 0.0411s/iter; left time: 804.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 222 | Train Loss: 0.1082214 Vali Loss: 0.1273075 Test Loss: 0.1389605\n",
      "Validation loss decreased (0.127470 --> 0.127308).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1044768\n",
      "\tspeed: 0.0755s/iter; left time: 1467.1021s\n",
      "\titers: 200, epoch: 13 | loss: 0.1075517\n",
      "\tspeed: 0.0413s/iter; left time: 798.0555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 222 | Train Loss: 0.1078091 Vali Loss: 0.1270512 Test Loss: 0.1373295\n",
      "Validation loss decreased (0.127308 --> 0.127051).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1049805\n",
      "\tspeed: 0.0767s/iter; left time: 1473.9038s\n",
      "\titers: 200, epoch: 14 | loss: 0.1062305\n",
      "\tspeed: 0.0414s/iter; left time: 790.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.40s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     63\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 64\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len = 336\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len[i]}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len[i]} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>0.1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.0881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1473  0.0914\n",
       "        96        0.0405  0.2013  0.1320\n",
       "        168       0.0450  0.2121  0.1408\n",
       "ES      24        0.0128  0.1130  0.0728\n",
       "        96        0.0330  0.1801  0.1138\n",
       "        168       0.0306  0.1748  0.1165\n",
       "FR      24        0.0107  0.1033  0.0598\n",
       "        96        0.0197  0.1402  0.0822\n",
       "        168       0.0228  0.1511  0.0891\n",
       "GB      24        0.0261  0.1616  0.1045\n",
       "        96        0.0457  0.2137  0.1464\n",
       "        168       0.0485  0.2201  0.1532\n",
       "IT      24        0.0107  0.1032  0.0610\n",
       "        96        0.0185  0.1360  0.0831\n",
       "        168       0.0203  0.1424  0.0881"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)\n",
    "\n",
    "It is a channel mixing model, and therefore it needs more dimension of embeddings to capture complex patterns between features. \n",
    "\n",
    "Therefore, it is not fair to keep same d_model and d_ff as in channel mixing. In this regard, we scale them based on number of input features.\n",
    "\n",
    "In other words, for DE data with 5 columns, d_model = 128 x 5, and d_ff = 256 x 5.\n",
    "\n",
    "For ES: d_model = 128 x 3 and d_ff = 256 x 3, etc. It is adjusted automatically in code.\n",
    "\n",
    "Since it converges fast, we reduced max number of epochs and patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1112533\n",
      "\tspeed: 0.1231s/iter; left time: 2746.3413s\n",
      "\titers: 200, epoch: 1 | loss: 0.0947237\n",
      "\tspeed: 0.0979s/iter; left time: 2173.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.40s\n",
      "Steps: 224 | Train Loss: 0.1155480 Vali Loss: 0.1083674 Test Loss: 0.1112919\n",
      "Validation loss decreased (inf --> 0.108367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0854550\n",
      "\tspeed: 0.1683s/iter; left time: 3716.6007s\n",
      "\titers: 200, epoch: 2 | loss: 0.0782319\n",
      "\tspeed: 0.0980s/iter; left time: 2154.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0869274 Vali Loss: 0.0998944 Test Loss: 0.1056200\n",
      "Validation loss decreased (0.108367 --> 0.099894).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0739933\n",
      "\tspeed: 0.1672s/iter; left time: 3654.3358s\n",
      "\titers: 200, epoch: 3 | loss: 0.0765578\n",
      "\tspeed: 0.0978s/iter; left time: 2128.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0778407 Vali Loss: 0.0991285 Test Loss: 0.1069202\n",
      "Validation loss decreased (0.099894 --> 0.099128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0697385\n",
      "\tspeed: 0.1682s/iter; left time: 3639.0088s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638608\n",
      "\tspeed: 0.0980s/iter; left time: 2109.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0693531 Vali Loss: 0.1024066 Test Loss: 0.1129898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582502\n",
      "\tspeed: 0.1631s/iter; left time: 3491.8476s\n",
      "\titers: 200, epoch: 5 | loss: 0.0585040\n",
      "\tspeed: 0.0979s/iter; left time: 2084.8564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0609865 Vali Loss: 0.1040621 Test Loss: 0.1140443\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0572859\n",
      "\tspeed: 0.1637s/iter; left time: 3467.9959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0524833\n",
      "\tspeed: 0.0980s/iter; left time: 2065.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.16s\n",
      "Steps: 224 | Train Loss: 0.0544637 Vali Loss: 0.1054772 Test Loss: 0.1150894\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0504480\n",
      "\tspeed: 0.1630s/iter; left time: 3416.3312s\n",
      "\titers: 200, epoch: 7 | loss: 0.0498273\n",
      "\tspeed: 0.0979s/iter; left time: 2042.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0495332 Vali Loss: 0.1044851 Test Loss: 0.1146997\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0444115\n",
      "\tspeed: 0.1638s/iter; left time: 3396.4821s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440660\n",
      "\tspeed: 0.0981s/iter; left time: 2025.0327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.21s\n",
      "Steps: 224 | Train Loss: 0.0461323 Vali Loss: 0.1038223 Test Loss: 0.1127458\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0430763\n",
      "\tspeed: 0.1640s/iter; left time: 3363.6509s\n",
      "\titers: 200, epoch: 9 | loss: 0.0425591\n",
      "\tspeed: 0.0983s/iter; left time: 2006.6833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.23s\n",
      "Steps: 224 | Train Loss: 0.0430833 Vali Loss: 0.1051498 Test Loss: 0.1131369\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0384030\n",
      "\tspeed: 0.1642s/iter; left time: 3330.5913s\n",
      "\titers: 200, epoch: 10 | loss: 0.0380151\n",
      "\tspeed: 0.0982s/iter; left time: 1982.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.21s\n",
      "Steps: 224 | Train Loss: 0.0405867 Vali Loss: 0.1042476 Test Loss: 0.1118535\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0366854\n",
      "\tspeed: 0.1636s/iter; left time: 3281.5571s\n",
      "\titers: 200, epoch: 11 | loss: 0.0389781\n",
      "\tspeed: 0.0985s/iter; left time: 1966.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.21s\n",
      "Steps: 224 | Train Loss: 0.0386601 Vali Loss: 0.1039293 Test Loss: 0.1120706\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0360011\n",
      "\tspeed: 0.1641s/iter; left time: 3256.1169s\n",
      "\titers: 200, epoch: 12 | loss: 0.0358986\n",
      "\tspeed: 0.0978s/iter; left time: 1930.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.14s\n",
      "Steps: 224 | Train Loss: 0.0366836 Vali Loss: 0.1034238 Test Loss: 0.1116644\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0363298\n",
      "\tspeed: 0.1635s/iter; left time: 3207.4983s\n",
      "\titers: 200, epoch: 13 | loss: 0.0352150\n",
      "\tspeed: 0.0983s/iter; left time: 1918.8538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0354312 Vali Loss: 0.1032293 Test Loss: 0.1111846\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027056831866502762, rmse:0.16448961198329926, mae:0.10692021995782852, rse:0.5805065631866455\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1104277\n",
      "\tspeed: 0.1006s/iter; left time: 2242.6529s\n",
      "\titers: 200, epoch: 1 | loss: 0.0958888\n",
      "\tspeed: 0.0982s/iter; left time: 2179.2152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.30s\n",
      "Steps: 224 | Train Loss: 0.1144290 Vali Loss: 0.1079746 Test Loss: 0.1105221\n",
      "Validation loss decreased (inf --> 0.107975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0823085\n",
      "\tspeed: 0.1691s/iter; left time: 3732.9607s\n",
      "\titers: 200, epoch: 2 | loss: 0.0799549\n",
      "\tspeed: 0.0987s/iter; left time: 2168.7480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.26s\n",
      "Steps: 224 | Train Loss: 0.0861994 Vali Loss: 0.1006127 Test Loss: 0.1039980\n",
      "Validation loss decreased (0.107975 --> 0.100613).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0805682\n",
      "\tspeed: 0.1707s/iter; left time: 3731.1330s\n",
      "\titers: 200, epoch: 3 | loss: 0.0741031\n",
      "\tspeed: 0.0986s/iter; left time: 2145.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.38s\n",
      "Steps: 224 | Train Loss: 0.0781434 Vali Loss: 0.1008413 Test Loss: 0.1066661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0722199\n",
      "\tspeed: 0.1649s/iter; left time: 3566.4820s\n",
      "\titers: 200, epoch: 4 | loss: 0.0663662\n",
      "\tspeed: 0.0986s/iter; left time: 2123.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.35s\n",
      "Steps: 224 | Train Loss: 0.0701794 Vali Loss: 0.1043894 Test Loss: 0.1115258\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600862\n",
      "\tspeed: 0.1654s/iter; left time: 3541.1986s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605440\n",
      "\tspeed: 0.0992s/iter; left time: 2112.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0612372 Vali Loss: 0.1049034 Test Loss: 0.1115060\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0573480\n",
      "\tspeed: 0.1641s/iter; left time: 3475.4696s\n",
      "\titers: 200, epoch: 6 | loss: 0.0534590\n",
      "\tspeed: 0.0984s/iter; left time: 2073.4958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.20s\n",
      "Steps: 224 | Train Loss: 0.0543473 Vali Loss: 0.1030101 Test Loss: 0.1130545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0521577\n",
      "\tspeed: 0.1650s/iter; left time: 3458.9430s\n",
      "\titers: 200, epoch: 7 | loss: 0.0499089\n",
      "\tspeed: 0.0994s/iter; left time: 2074.1525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.40s\n",
      "Steps: 224 | Train Loss: 0.0494745 Vali Loss: 0.1061422 Test Loss: 0.1134916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0478449\n",
      "\tspeed: 0.1653s/iter; left time: 3426.7520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0461110\n",
      "\tspeed: 0.0986s/iter; left time: 2034.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.33s\n",
      "Steps: 224 | Train Loss: 0.0460226 Vali Loss: 0.1054480 Test Loss: 0.1134600\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0442130\n",
      "\tspeed: 0.1655s/iter; left time: 3394.3082s\n",
      "\titers: 200, epoch: 9 | loss: 0.0409993\n",
      "\tspeed: 0.0995s/iter; left time: 2030.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0430741 Vali Loss: 0.1049370 Test Loss: 0.1139135\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0401310\n",
      "\tspeed: 0.1664s/iter; left time: 3374.7413s\n",
      "\titers: 200, epoch: 10 | loss: 0.0397451\n",
      "\tspeed: 0.0986s/iter; left time: 1990.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.40s\n",
      "Steps: 224 | Train Loss: 0.0407757 Vali Loss: 0.1058690 Test Loss: 0.1138797\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0401663\n",
      "\tspeed: 0.1662s/iter; left time: 3334.1508s\n",
      "\titers: 200, epoch: 11 | loss: 0.0379177\n",
      "\tspeed: 0.0999s/iter; left time: 1993.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0388926 Vali Loss: 0.1049644 Test Loss: 0.1126991\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0368711\n",
      "\tspeed: 0.1670s/iter; left time: 3312.3730s\n",
      "\titers: 200, epoch: 12 | loss: 0.0373080\n",
      "\tspeed: 0.0985s/iter; left time: 1943.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.34s\n",
      "Steps: 224 | Train Loss: 0.0372816 Vali Loss: 0.1046643 Test Loss: 0.1133890\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025797396898269653, rmse:0.1606156826019287, mae:0.10399806499481201, rse:0.5668349862098694\n",
      "Intermediate time for DE and pred_len 24: 00h:11m:15.14s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1223163\n",
      "\tspeed: 0.1264s/iter; left time: 2817.8532s\n",
      "\titers: 200, epoch: 1 | loss: 0.1179984\n",
      "\tspeed: 0.1009s/iter; left time: 2240.6734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.04s\n",
      "Steps: 224 | Train Loss: 0.1299141 Vali Loss: 0.1308546 Test Loss: 0.1396497\n",
      "Validation loss decreased (inf --> 0.130855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1022252\n",
      "\tspeed: 0.1756s/iter; left time: 3876.1657s\n",
      "\titers: 200, epoch: 2 | loss: 0.0907339\n",
      "\tspeed: 0.1000s/iter; left time: 2198.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.1030955 Vali Loss: 0.1370220 Test Loss: 0.1497822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0787314\n",
      "\tspeed: 0.1667s/iter; left time: 3642.4992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0721129\n",
      "\tspeed: 0.1003s/iter; left time: 2182.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.59s\n",
      "Steps: 224 | Train Loss: 0.0795147 Vali Loss: 0.1362003 Test Loss: 0.1498653\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0672994\n",
      "\tspeed: 0.1667s/iter; left time: 3606.0938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0617716\n",
      "\tspeed: 0.0997s/iter; left time: 2146.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0662196 Vali Loss: 0.1312884 Test Loss: 0.1464415\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0554917\n",
      "\tspeed: 0.1673s/iter; left time: 3580.1698s\n",
      "\titers: 200, epoch: 5 | loss: 0.0537446\n",
      "\tspeed: 0.1049s/iter; left time: 2235.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:23.00s\n",
      "Steps: 224 | Train Loss: 0.0566004 Vali Loss: 0.1303605 Test Loss: 0.1468938\n",
      "Validation loss decreased (0.130855 --> 0.130360).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0494789\n",
      "\tspeed: 0.1903s/iter; left time: 4030.1447s\n",
      "\titers: 200, epoch: 6 | loss: 0.0491216\n",
      "\tspeed: 0.0998s/iter; left time: 2104.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0503385 Vali Loss: 0.1282276 Test Loss: 0.1452809\n",
      "Validation loss decreased (0.130360 --> 0.128228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0476965\n",
      "\tspeed: 0.1740s/iter; left time: 3646.4895s\n",
      "\titers: 200, epoch: 7 | loss: 0.0456673\n",
      "\tspeed: 0.1014s/iter; left time: 2114.5851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 224 | Train Loss: 0.0460990 Vali Loss: 0.1284869 Test Loss: 0.1437094\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0409390\n",
      "\tspeed: 0.1675s/iter; left time: 3472.7147s\n",
      "\titers: 200, epoch: 8 | loss: 0.0420192\n",
      "\tspeed: 0.1000s/iter; left time: 2063.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.58s\n",
      "Steps: 224 | Train Loss: 0.0428764 Vali Loss: 0.1284564 Test Loss: 0.1440781\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0444956\n",
      "\tspeed: 0.1685s/iter; left time: 3455.6580s\n",
      "\titers: 200, epoch: 9 | loss: 0.0387594\n",
      "\tspeed: 0.1016s/iter; left time: 2074.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 224 | Train Loss: 0.0407125 Vali Loss: 0.1305699 Test Loss: 0.1438922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0374829\n",
      "\tspeed: 0.1671s/iter; left time: 3390.4842s\n",
      "\titers: 200, epoch: 10 | loss: 0.0365280\n",
      "\tspeed: 0.0998s/iter; left time: 2015.1867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.0390599 Vali Loss: 0.1287085 Test Loss: 0.1438078\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0362832\n",
      "\tspeed: 0.1683s/iter; left time: 3375.8092s\n",
      "\titers: 200, epoch: 11 | loss: 0.0386881\n",
      "\tspeed: 0.1010s/iter; left time: 2016.5076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 224 | Train Loss: 0.0373755 Vali Loss: 0.1280792 Test Loss: 0.1441514\n",
      "Validation loss decreased (0.128228 --> 0.128079).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0369315\n",
      "\tspeed: 0.1853s/iter; left time: 3675.4814s\n",
      "\titers: 200, epoch: 12 | loss: 0.0343455\n",
      "\tspeed: 0.0998s/iter; left time: 1970.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0356504 Vali Loss: 0.1269628 Test Loss: 0.1420918\n",
      "Validation loss decreased (0.128079 --> 0.126963).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0335403\n",
      "\tspeed: 0.1778s/iter; left time: 3487.3644s\n",
      "\titers: 200, epoch: 13 | loss: 0.0352450\n",
      "\tspeed: 0.1012s/iter; left time: 1974.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 224 | Train Loss: 0.0349691 Vali Loss: 0.1272836 Test Loss: 0.1418213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0318428\n",
      "\tspeed: 0.1702s/iter; left time: 3300.6497s\n",
      "\titers: 200, epoch: 14 | loss: 0.0324326\n",
      "\tspeed: 0.0997s/iter; left time: 1923.8570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:22.60s\n",
      "Steps: 224 | Train Loss: 0.0338992 Vali Loss: 0.1269519 Test Loss: 0.1416352\n",
      "Validation loss decreased (0.126963 --> 0.126952).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0320864\n",
      "\tspeed: 0.1923s/iter; left time: 3684.7328s\n",
      "\titers: 200, epoch: 15 | loss: 0.0322615\n",
      "\tspeed: 0.0999s/iter; left time: 1904.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.63s\n",
      "Steps: 224 | Train Loss: 0.0333974 Vali Loss: 0.1274366 Test Loss: 0.1414319\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0321085\n",
      "\tspeed: 0.1708s/iter; left time: 3234.3843s\n",
      "\titers: 200, epoch: 16 | loss: 0.0311919\n",
      "\tspeed: 0.1000s/iter; left time: 1884.7500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.65s\n",
      "Steps: 224 | Train Loss: 0.0323608 Vali Loss: 0.1268734 Test Loss: 0.1406729\n",
      "Validation loss decreased (0.126952 --> 0.126873).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0328568\n",
      "\tspeed: 0.1755s/iter; left time: 3285.6408s\n",
      "\titers: 200, epoch: 17 | loss: 0.0315784\n",
      "\tspeed: 0.1003s/iter; left time: 1867.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.65s\n",
      "Steps: 224 | Train Loss: 0.0319499 Vali Loss: 0.1269051 Test Loss: 0.1413284\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0313548\n",
      "\tspeed: 0.1698s/iter; left time: 3140.1900s\n",
      "\titers: 200, epoch: 18 | loss: 0.0328749\n",
      "\tspeed: 0.0998s/iter; left time: 1835.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.59s\n",
      "Steps: 224 | Train Loss: 0.0316611 Vali Loss: 0.1266844 Test Loss: 0.1419162\n",
      "Validation loss decreased (0.126873 --> 0.126684).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0298367\n",
      "\tspeed: 0.2082s/iter; left time: 3804.1620s\n",
      "\titers: 200, epoch: 19 | loss: 0.0298126\n",
      "\tspeed: 0.0998s/iter; left time: 1812.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:22.56s\n",
      "Steps: 224 | Train Loss: 0.0311329 Vali Loss: 0.1270447 Test Loss: 0.1420292\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0311288\n",
      "\tspeed: 0.1699s/iter; left time: 3065.0701s\n",
      "\titers: 200, epoch: 20 | loss: 0.0301998\n",
      "\tspeed: 0.1005s/iter; left time: 1803.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 224 | Train Loss: 0.0312470 Vali Loss: 0.1267967 Test Loss: 0.1413040\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0298048\n",
      "\tspeed: 0.1671s/iter; left time: 2978.3748s\n",
      "\titers: 200, epoch: 21 | loss: 0.0307570\n",
      "\tspeed: 0.0997s/iter; left time: 1767.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0303649 Vali Loss: 0.1261611 Test Loss: 0.1411284\n",
      "Validation loss decreased (0.126684 --> 0.126161).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0304579\n",
      "\tspeed: 0.1768s/iter; left time: 3110.2793s\n",
      "\titers: 200, epoch: 22 | loss: 0.0297905\n",
      "\tspeed: 0.1002s/iter; left time: 1753.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 224 | Train Loss: 0.0304837 Vali Loss: 0.1264128 Test Loss: 0.1408116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0307272\n",
      "\tspeed: 0.1681s/iter; left time: 2919.5898s\n",
      "\titers: 200, epoch: 23 | loss: 0.0295572\n",
      "\tspeed: 0.1003s/iter; left time: 1733.1509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:22.62s\n",
      "Steps: 224 | Train Loss: 0.0297434 Vali Loss: 0.1263970 Test Loss: 0.1411095\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0314769\n",
      "\tspeed: 0.1684s/iter; left time: 2888.2314s\n",
      "\titers: 200, epoch: 24 | loss: 0.0295095\n",
      "\tspeed: 0.1005s/iter; left time: 1713.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:22.72s\n",
      "Steps: 224 | Train Loss: 0.0295767 Vali Loss: 0.1259887 Test Loss: 0.1408765\n",
      "Validation loss decreased (0.126161 --> 0.125989).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0312430\n",
      "\tspeed: 0.1914s/iter; left time: 3239.6202s\n",
      "\titers: 200, epoch: 25 | loss: 0.0308773\n",
      "\tspeed: 0.0998s/iter; left time: 1679.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.0291316 Vali Loss: 0.1260642 Test Loss: 0.1408389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0319661\n",
      "\tspeed: 0.1692s/iter; left time: 2826.4961s\n",
      "\titers: 200, epoch: 26 | loss: 0.0286000\n",
      "\tspeed: 0.1011s/iter; left time: 1678.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:22.82s\n",
      "Steps: 224 | Train Loss: 0.0289346 Vali Loss: 0.1262054 Test Loss: 0.1407005\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0285632\n",
      "\tspeed: 0.1670s/iter; left time: 2750.8384s\n",
      "\titers: 200, epoch: 27 | loss: 0.0289748\n",
      "\tspeed: 0.0996s/iter; left time: 1630.7464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0287466 Vali Loss: 0.1262713 Test Loss: 0.1408920\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0290055\n",
      "\tspeed: 0.1689s/iter; left time: 2744.3283s\n",
      "\titers: 200, epoch: 28 | loss: 0.0277826\n",
      "\tspeed: 0.1010s/iter; left time: 1632.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:22.85s\n",
      "Steps: 224 | Train Loss: 0.0286593 Vali Loss: 0.1261419 Test Loss: 0.1399771\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0292756\n",
      "\tspeed: 0.1674s/iter; left time: 2683.1799s\n",
      "\titers: 200, epoch: 29 | loss: 0.0283121\n",
      "\tspeed: 0.1000s/iter; left time: 1593.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.0285146 Vali Loss: 0.1261241 Test Loss: 0.1406155\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0271864\n",
      "\tspeed: 0.1694s/iter; left time: 2677.2505s\n",
      "\titers: 200, epoch: 30 | loss: 0.0279842\n",
      "\tspeed: 0.1019s/iter; left time: 1600.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:22.96s\n",
      "Steps: 224 | Train Loss: 0.0283375 Vali Loss: 0.1260011 Test Loss: 0.1401229\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0279219\n",
      "\tspeed: 0.1690s/iter; left time: 2632.6991s\n",
      "\titers: 200, epoch: 31 | loss: 0.0284825\n",
      "\tspeed: 0.0994s/iter; left time: 1539.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.0281008 Vali Loss: 0.1260184 Test Loss: 0.1401648\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0274448\n",
      "\tspeed: 0.1668s/iter; left time: 2561.8487s\n",
      "\titers: 200, epoch: 32 | loss: 0.0278788\n",
      "\tspeed: 0.0994s/iter; left time: 1517.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0280171 Vali Loss: 0.1261915 Test Loss: 0.1406342\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0274708\n",
      "\tspeed: 0.1667s/iter; left time: 2522.5358s\n",
      "\titers: 200, epoch: 33 | loss: 0.0282368\n",
      "\tspeed: 0.0995s/iter; left time: 1495.5036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0280225 Vali Loss: 0.1261243 Test Loss: 0.1408214\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0286569\n",
      "\tspeed: 0.1671s/iter; left time: 2490.5578s\n",
      "\titers: 200, epoch: 34 | loss: 0.0280261\n",
      "\tspeed: 0.0994s/iter; left time: 1471.3830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0278311 Vali Loss: 0.1261183 Test Loss: 0.1404821\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04204396903514862, rmse:0.20504626631736755, mae:0.14087654650211334, rse:0.7261102199554443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1242477\n",
      "\tspeed: 0.1012s/iter; left time: 2257.2450s\n",
      "\titers: 200, epoch: 1 | loss: 0.1171697\n",
      "\tspeed: 0.0997s/iter; left time: 2213.0749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.1299392 Vali Loss: 0.1311586 Test Loss: 0.1394444\n",
      "Validation loss decreased (inf --> 0.131159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1039839\n",
      "\tspeed: 0.1771s/iter; left time: 3910.7070s\n",
      "\titers: 200, epoch: 2 | loss: 0.0935863\n",
      "\tspeed: 0.0994s/iter; left time: 2183.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.1030212 Vali Loss: 0.1342872 Test Loss: 0.1477258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0777247\n",
      "\tspeed: 0.1686s/iter; left time: 3684.1362s\n",
      "\titers: 200, epoch: 3 | loss: 0.0737206\n",
      "\tspeed: 0.0994s/iter; left time: 2161.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0787656 Vali Loss: 0.1355689 Test Loss: 0.1499120\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0638760\n",
      "\tspeed: 0.1678s/iter; left time: 3628.4389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635152\n",
      "\tspeed: 0.0993s/iter; left time: 2138.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0655781 Vali Loss: 0.1333372 Test Loss: 0.1491168\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0555358\n",
      "\tspeed: 0.1679s/iter; left time: 3593.6052s\n",
      "\titers: 200, epoch: 5 | loss: 0.0573160\n",
      "\tspeed: 0.0993s/iter; left time: 2115.3512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.0570693 Vali Loss: 0.1329813 Test Loss: 0.1468537\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0531334\n",
      "\tspeed: 0.1681s/iter; left time: 3561.4293s\n",
      "\titers: 200, epoch: 6 | loss: 0.0529571\n",
      "\tspeed: 0.0997s/iter; left time: 2101.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0510583 Vali Loss: 0.1324312 Test Loss: 0.1463843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0469876\n",
      "\tspeed: 0.1686s/iter; left time: 3532.4185s\n",
      "\titers: 200, epoch: 7 | loss: 0.0458747\n",
      "\tspeed: 0.0994s/iter; left time: 2072.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0464710 Vali Loss: 0.1307112 Test Loss: 0.1434968\n",
      "Validation loss decreased (0.131159 --> 0.130711).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0451981\n",
      "\tspeed: 0.1938s/iter; left time: 4018.4328s\n",
      "\titers: 200, epoch: 8 | loss: 0.0411316\n",
      "\tspeed: 0.0996s/iter; left time: 2055.2660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0429134 Vali Loss: 0.1289652 Test Loss: 0.1438801\n",
      "Validation loss decreased (0.130711 --> 0.128965).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0396862\n",
      "\tspeed: 0.1764s/iter; left time: 3617.1161s\n",
      "\titers: 200, epoch: 9 | loss: 0.0396968\n",
      "\tspeed: 0.0991s/iter; left time: 2023.5205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0406364 Vali Loss: 0.1287583 Test Loss: 0.1428453\n",
      "Validation loss decreased (0.128965 --> 0.128758).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0372063\n",
      "\tspeed: 0.1759s/iter; left time: 3567.7333s\n",
      "\titers: 200, epoch: 10 | loss: 0.0396097\n",
      "\tspeed: 0.0993s/iter; left time: 2004.9709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0382141 Vali Loss: 0.1289230 Test Loss: 0.1427508\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0397195\n",
      "\tspeed: 0.1671s/iter; left time: 3352.7139s\n",
      "\titers: 200, epoch: 11 | loss: 0.0351189\n",
      "\tspeed: 0.0993s/iter; left time: 1982.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0368077 Vali Loss: 0.1288192 Test Loss: 0.1422276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0337716\n",
      "\tspeed: 0.1684s/iter; left time: 3340.3024s\n",
      "\titers: 200, epoch: 12 | loss: 0.0348658\n",
      "\tspeed: 0.0992s/iter; left time: 1958.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0356215 Vali Loss: 0.1283011 Test Loss: 0.1428052\n",
      "Validation loss decreased (0.128758 --> 0.128301).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0344515\n",
      "\tspeed: 0.1825s/iter; left time: 3578.4759s\n",
      "\titers: 200, epoch: 13 | loss: 0.0332311\n",
      "\tspeed: 0.0994s/iter; left time: 1939.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0347675 Vali Loss: 0.1277235 Test Loss: 0.1420104\n",
      "Validation loss decreased (0.128301 --> 0.127723).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0325857\n",
      "\tspeed: 0.1761s/iter; left time: 3414.2019s\n",
      "\titers: 200, epoch: 14 | loss: 0.0326958\n",
      "\tspeed: 0.0993s/iter; left time: 1916.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0337991 Vali Loss: 0.1276056 Test Loss: 0.1410959\n",
      "Validation loss decreased (0.127723 --> 0.127606).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0332377\n",
      "\tspeed: 0.1800s/iter; left time: 3448.8690s\n",
      "\titers: 200, epoch: 15 | loss: 0.0326112\n",
      "\tspeed: 0.0993s/iter; left time: 1893.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0331643 Vali Loss: 0.1276101 Test Loss: 0.1415685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0317841\n",
      "\tspeed: 0.1677s/iter; left time: 3177.3019s\n",
      "\titers: 200, epoch: 16 | loss: 0.0336634\n",
      "\tspeed: 0.1000s/iter; left time: 1883.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.58s\n",
      "Steps: 224 | Train Loss: 0.0319262 Vali Loss: 0.1273212 Test Loss: 0.1411992\n",
      "Validation loss decreased (0.127606 --> 0.127321).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0315294\n",
      "\tspeed: 0.1766s/iter; left time: 3306.3062s\n",
      "\titers: 200, epoch: 17 | loss: 0.0402153\n",
      "\tspeed: 0.0992s/iter; left time: 1847.0172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0316037 Vali Loss: 0.1274369 Test Loss: 0.1422841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0310733\n",
      "\tspeed: 0.1675s/iter; left time: 3096.9075s\n",
      "\titers: 200, epoch: 18 | loss: 0.0316665\n",
      "\tspeed: 0.0992s/iter; left time: 1825.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0310502 Vali Loss: 0.1270434 Test Loss: 0.1407711\n",
      "Validation loss decreased (0.127321 --> 0.127043).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0287771\n",
      "\tspeed: 0.1760s/iter; left time: 3216.1727s\n",
      "\titers: 200, epoch: 19 | loss: 0.0305514\n",
      "\tspeed: 0.0992s/iter; left time: 1802.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0303930 Vali Loss: 0.1270769 Test Loss: 0.1405970\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0289193\n",
      "\tspeed: 0.1678s/iter; left time: 3027.4632s\n",
      "\titers: 200, epoch: 20 | loss: 0.0286493\n",
      "\tspeed: 0.0992s/iter; left time: 1779.5013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0299198 Vali Loss: 0.1268112 Test Loss: 0.1410203\n",
      "Validation loss decreased (0.127043 --> 0.126811).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0310301\n",
      "\tspeed: 0.1729s/iter; left time: 3080.7583s\n",
      "\titers: 200, epoch: 21 | loss: 0.0276777\n",
      "\tspeed: 0.0992s/iter; left time: 1758.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:22.42s\n",
      "Steps: 224 | Train Loss: 0.0296345 Vali Loss: 0.1268980 Test Loss: 0.1419411\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0292942\n",
      "\tspeed: 0.1676s/iter; left time: 2949.2473s\n",
      "\titers: 200, epoch: 22 | loss: 0.0303327\n",
      "\tspeed: 0.0996s/iter; left time: 1742.0906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.0295196 Vali Loss: 0.1270390 Test Loss: 0.1411565\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0279907\n",
      "\tspeed: 0.1675s/iter; left time: 2909.5327s\n",
      "\titers: 200, epoch: 23 | loss: 0.0285120\n",
      "\tspeed: 0.0996s/iter; left time: 1719.5872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0291036 Vali Loss: 0.1268217 Test Loss: 0.1409847\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0285618\n",
      "\tspeed: 0.1670s/iter; left time: 2864.0232s\n",
      "\titers: 200, epoch: 24 | loss: 0.0295330\n",
      "\tspeed: 0.0991s/iter; left time: 1690.1665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:22.41s\n",
      "Steps: 224 | Train Loss: 0.0287539 Vali Loss: 0.1268914 Test Loss: 0.1410079\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0284254\n",
      "\tspeed: 0.1687s/iter; left time: 2854.9025s\n",
      "\titers: 200, epoch: 25 | loss: 0.0317466\n",
      "\tspeed: 0.0992s/iter; left time: 1669.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0286661 Vali Loss: 0.1269969 Test Loss: 0.1407455\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0279723\n",
      "\tspeed: 0.1670s/iter; left time: 2789.8496s\n",
      "\titers: 200, epoch: 26 | loss: 0.0280906\n",
      "\tspeed: 0.0995s/iter; left time: 1651.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0282482 Vali Loss: 0.1268042 Test Loss: 0.1406889\n",
      "Validation loss decreased (0.126811 --> 0.126804).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0271803\n",
      "\tspeed: 0.1742s/iter; left time: 2871.0541s\n",
      "\titers: 200, epoch: 27 | loss: 0.0277322\n",
      "\tspeed: 0.0992s/iter; left time: 1624.5659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0281096 Vali Loss: 0.1267876 Test Loss: 0.1410657\n",
      "Validation loss decreased (0.126804 --> 0.126788).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0290098\n",
      "\tspeed: 0.1758s/iter; left time: 2856.5209s\n",
      "\titers: 200, epoch: 28 | loss: 0.0280983\n",
      "\tspeed: 0.1004s/iter; left time: 1621.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:22.63s\n",
      "Steps: 224 | Train Loss: 0.0280412 Vali Loss: 0.1270118 Test Loss: 0.1409286\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0277480\n",
      "\tspeed: 0.1673s/iter; left time: 2681.9287s\n",
      "\titers: 200, epoch: 29 | loss: 0.0283032\n",
      "\tspeed: 0.0996s/iter; left time: 1586.6668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0277198 Vali Loss: 0.1267704 Test Loss: 0.1407932\n",
      "Validation loss decreased (0.126788 --> 0.126770).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0269211\n",
      "\tspeed: 0.1756s/iter; left time: 2775.2859s\n",
      "\titers: 200, epoch: 30 | loss: 0.0287858\n",
      "\tspeed: 0.0996s/iter; left time: 1563.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.0275932 Vali Loss: 0.1266454 Test Loss: 0.1408675\n",
      "Validation loss decreased (0.126770 --> 0.126645).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0289489\n",
      "\tspeed: 0.1765s/iter; left time: 2750.1467s\n",
      "\titers: 200, epoch: 31 | loss: 0.0269842\n",
      "\tspeed: 0.0995s/iter; left time: 1540.1791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0275068 Vali Loss: 0.1267893 Test Loss: 0.1410453\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0268948\n",
      "\tspeed: 0.1672s/iter; left time: 2568.2920s\n",
      "\titers: 200, epoch: 32 | loss: 0.0275908\n",
      "\tspeed: 0.0994s/iter; left time: 1517.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0272988 Vali Loss: 0.1267322 Test Loss: 0.1409021\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0268456\n",
      "\tspeed: 0.1672s/iter; left time: 2529.4851s\n",
      "\titers: 200, epoch: 33 | loss: 0.0273315\n",
      "\tspeed: 0.0992s/iter; left time: 1491.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.42s\n",
      "Steps: 224 | Train Loss: 0.0273786 Vali Loss: 0.1266959 Test Loss: 0.1406758\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0265508\n",
      "\tspeed: 0.1676s/iter; left time: 2498.8035s\n",
      "\titers: 200, epoch: 34 | loss: 0.0265951\n",
      "\tspeed: 0.0992s/iter; left time: 1469.4282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0271909 Vali Loss: 0.1265954 Test Loss: 0.1406779\n",
      "Validation loss decreased (0.126645 --> 0.126595).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0265231\n",
      "\tspeed: 0.1753s/iter; left time: 2574.9398s\n",
      "\titers: 200, epoch: 35 | loss: 0.0273827\n",
      "\tspeed: 0.0992s/iter; left time: 1446.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0273014 Vali Loss: 0.1266384 Test Loss: 0.1406149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0272715\n",
      "\tspeed: 0.1679s/iter; left time: 2427.9285s\n",
      "\titers: 200, epoch: 36 | loss: 0.0263559\n",
      "\tspeed: 0.0992s/iter; left time: 1425.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0269461 Vali Loss: 0.1266462 Test Loss: 0.1410074\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0273352\n",
      "\tspeed: 0.1672s/iter; left time: 2380.9293s\n",
      "\titers: 200, epoch: 37 | loss: 0.0265992\n",
      "\tspeed: 0.0993s/iter; left time: 1403.3173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0268802 Vali Loss: 0.1267088 Test Loss: 0.1409060\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0262193\n",
      "\tspeed: 0.1681s/iter; left time: 2356.0506s\n",
      "\titers: 200, epoch: 38 | loss: 0.0269825\n",
      "\tspeed: 0.0990s/iter; left time: 1376.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0269931 Vali Loss: 0.1266754 Test Loss: 0.1408476\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0283489\n",
      "\tspeed: 0.1672s/iter; left time: 2305.8184s\n",
      "\titers: 200, epoch: 39 | loss: 0.0262878\n",
      "\tspeed: 0.0992s/iter; left time: 1358.1670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:22.43s\n",
      "Steps: 224 | Train Loss: 0.0268186 Vali Loss: 0.1266399 Test Loss: 0.1409293\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0266380\n",
      "\tspeed: 0.1672s/iter; left time: 2268.1683s\n",
      "\titers: 200, epoch: 40 | loss: 0.0259960\n",
      "\tspeed: 0.0993s/iter; left time: 1336.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:22.43s\n",
      "Steps: 224 | Train Loss: 0.0267726 Vali Loss: 0.1267287 Test Loss: 0.1406187\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0269313\n",
      "\tspeed: 0.1679s/iter; left time: 2240.0805s\n",
      "\titers: 200, epoch: 41 | loss: 0.0265634\n",
      "\tspeed: 0.0995s/iter; left time: 1317.8384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0268338 Vali Loss: 0.1266552 Test Loss: 0.1407018\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0262663\n",
      "\tspeed: 0.1695s/iter; left time: 2222.7706s\n",
      "\titers: 200, epoch: 42 | loss: 0.0278459\n",
      "\tspeed: 0.0993s/iter; left time: 1291.9458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0267926 Vali Loss: 0.1266343 Test Loss: 0.1407602\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0261751\n",
      "\tspeed: 0.1680s/iter; left time: 2166.1836s\n",
      "\titers: 200, epoch: 43 | loss: 0.0273091\n",
      "\tspeed: 0.0995s/iter; left time: 1273.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0268088 Vali Loss: 0.1266787 Test Loss: 0.1408890\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0276403\n",
      "\tspeed: 0.1675s/iter; left time: 2121.9633s\n",
      "\titers: 200, epoch: 44 | loss: 0.0258890\n",
      "\tspeed: 0.0988s/iter; left time: 1242.3966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:22.37s\n",
      "Steps: 224 | Train Loss: 0.0266744 Vali Loss: 0.1265327 Test Loss: 0.1406834\n",
      "Validation loss decreased (0.126595 --> 0.126533).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0271499\n",
      "\tspeed: 0.1774s/iter; left time: 2207.2382s\n",
      "\titers: 200, epoch: 45 | loss: 0.0256475\n",
      "\tspeed: 0.0997s/iter; left time: 1230.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0265942 Vali Loss: 0.1266127 Test Loss: 0.1406820\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0264941\n",
      "\tspeed: 0.1676s/iter; left time: 2047.6383s\n",
      "\titers: 200, epoch: 46 | loss: 0.0259737\n",
      "\tspeed: 0.0993s/iter; left time: 1203.2065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0265642 Vali Loss: 0.1265820 Test Loss: 0.1407245\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0254731\n",
      "\tspeed: 0.1670s/iter; left time: 2003.3742s\n",
      "\titers: 200, epoch: 47 | loss: 0.0265677\n",
      "\tspeed: 0.0996s/iter; left time: 1184.6251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0265836 Vali Loss: 0.1266140 Test Loss: 0.1408633\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0276974\n",
      "\tspeed: 0.1670s/iter; left time: 1966.5134s\n",
      "\titers: 200, epoch: 48 | loss: 0.0270967\n",
      "\tspeed: 0.0991s/iter; left time: 1157.2851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0265990 Vali Loss: 0.1265998 Test Loss: 0.1405815\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0262738\n",
      "\tspeed: 0.1675s/iter; left time: 1934.4115s\n",
      "\titers: 200, epoch: 49 | loss: 0.0273522\n",
      "\tspeed: 0.0996s/iter; left time: 1139.8608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:22.52s\n",
      "Steps: 224 | Train Loss: 0.0265748 Vali Loss: 0.1264659 Test Loss: 0.1406672\n",
      "Validation loss decreased (0.126533 --> 0.126466).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0260855\n",
      "\tspeed: 0.1769s/iter; left time: 2003.1773s\n",
      "\titers: 200, epoch: 50 | loss: 0.0267769\n",
      "\tspeed: 0.0992s/iter; left time: 1113.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0264955 Vali Loss: 0.1264177 Test Loss: 0.1403963\n",
      "Validation loss decreased (0.126466 --> 0.126418).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0259825\n",
      "\tspeed: 0.1780s/iter; left time: 1975.9628s\n",
      "\titers: 200, epoch: 51 | loss: 0.0265678\n",
      "\tspeed: 0.0995s/iter; left time: 1094.8766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0265601 Vali Loss: 0.1264171 Test Loss: 0.1407261\n",
      "Validation loss decreased (0.126418 --> 0.126417).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0255395\n",
      "\tspeed: 0.1752s/iter; left time: 1905.7906s\n",
      "\titers: 200, epoch: 52 | loss: 0.0261697\n",
      "\tspeed: 0.0994s/iter; left time: 1071.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0265688 Vali Loss: 0.1265205 Test Loss: 0.1405940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0261250\n",
      "\tspeed: 0.1681s/iter; left time: 1791.1259s\n",
      "\titers: 200, epoch: 53 | loss: 0.0263986\n",
      "\tspeed: 0.0994s/iter; left time: 1049.0406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0264487 Vali Loss: 0.1265929 Test Loss: 0.1407698\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0263977\n",
      "\tspeed: 0.1674s/iter; left time: 1746.1420s\n",
      "\titers: 200, epoch: 54 | loss: 0.0268512\n",
      "\tspeed: 0.0993s/iter; left time: 1026.0156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0264494 Vali Loss: 0.1265761 Test Loss: 0.1408572\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0282792\n",
      "\tspeed: 0.1675s/iter; left time: 1709.2491s\n",
      "\titers: 200, epoch: 55 | loss: 0.0252980\n",
      "\tspeed: 0.0992s/iter; left time: 1002.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0264651 Vali Loss: 0.1266173 Test Loss: 0.1409407\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0268920\n",
      "\tspeed: 0.1676s/iter; left time: 1672.7793s\n",
      "\titers: 200, epoch: 56 | loss: 0.0262528\n",
      "\tspeed: 0.0995s/iter; left time: 982.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0263788 Vali Loss: 0.1266261 Test Loss: 0.1407852\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0261843\n",
      "\tspeed: 0.1681s/iter; left time: 1639.8427s\n",
      "\titers: 200, epoch: 57 | loss: 0.0265339\n",
      "\tspeed: 0.0994s/iter; left time: 959.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.0264286 Vali Loss: 0.1265251 Test Loss: 0.1406273\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0257913\n",
      "\tspeed: 0.1670s/iter; left time: 1591.8488s\n",
      "\titers: 200, epoch: 58 | loss: 0.0256953\n",
      "\tspeed: 0.0995s/iter; left time: 938.6728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0265050 Vali Loss: 0.1264443 Test Loss: 0.1406734\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0269404\n",
      "\tspeed: 0.1679s/iter; left time: 1563.2571s\n",
      "\titers: 200, epoch: 59 | loss: 0.0263439\n",
      "\tspeed: 0.0993s/iter; left time: 914.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0264420 Vali Loss: 0.1266005 Test Loss: 0.1408871\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0265904\n",
      "\tspeed: 0.1681s/iter; left time: 1527.2104s\n",
      "\titers: 200, epoch: 60 | loss: 0.0249333\n",
      "\tspeed: 0.0996s/iter; left time: 894.6528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:22.54s\n",
      "Steps: 224 | Train Loss: 0.0263893 Vali Loss: 0.1265873 Test Loss: 0.1406013\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0261007\n",
      "\tspeed: 0.1683s/iter; left time: 1491.6577s\n",
      "\titers: 200, epoch: 61 | loss: 0.0266510\n",
      "\tspeed: 0.0993s/iter; left time: 869.7511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0264167 Vali Loss: 0.1265362 Test Loss: 0.1407479\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04155511409044266, rmse:0.20385071635246277, mae:0.14072604477405548, rse:0.7218766212463379\n",
      "Intermediate time for DE and pred_len 96: 00h:43m:13.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1261648\n",
      "\tspeed: 0.1298s/iter; left time: 2880.7539s\n",
      "\titers: 200, epoch: 1 | loss: 0.1190995\n",
      "\tspeed: 0.1011s/iter; left time: 2235.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.04s\n",
      "Steps: 223 | Train Loss: 0.1339292 Vali Loss: 0.1335317 Test Loss: 0.1439572\n",
      "Validation loss decreased (inf --> 0.133532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1051248\n",
      "\tspeed: 0.1748s/iter; left time: 3840.6729s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949041\n",
      "\tspeed: 0.1009s/iter; left time: 2207.4692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.70s\n",
      "Steps: 223 | Train Loss: 0.1056621 Vali Loss: 0.1374970 Test Loss: 0.1528661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0788745\n",
      "\tspeed: 0.1684s/iter; left time: 3663.2307s\n",
      "\titers: 200, epoch: 3 | loss: 0.0743790\n",
      "\tspeed: 0.1009s/iter; left time: 2185.6150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0800766 Vali Loss: 0.1391651 Test Loss: 0.1580985\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0654544\n",
      "\tspeed: 0.1691s/iter; left time: 3641.0910s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631503\n",
      "\tspeed: 0.1010s/iter; left time: 2165.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.0666773 Vali Loss: 0.1346968 Test Loss: 0.1523327\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0569980\n",
      "\tspeed: 0.1691s/iter; left time: 3603.2151s\n",
      "\titers: 200, epoch: 5 | loss: 0.0533941\n",
      "\tspeed: 0.1011s/iter; left time: 2143.7986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.0580855 Vali Loss: 0.1348484 Test Loss: 0.1486578\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0516111\n",
      "\tspeed: 0.1696s/iter; left time: 3576.4654s\n",
      "\titers: 200, epoch: 6 | loss: 0.0490716\n",
      "\tspeed: 0.1009s/iter; left time: 2118.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.75s\n",
      "Steps: 223 | Train Loss: 0.0514214 Vali Loss: 0.1381943 Test Loss: 0.1528778\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0464494\n",
      "\tspeed: 0.1686s/iter; left time: 3516.9433s\n",
      "\titers: 200, epoch: 7 | loss: 0.0477641\n",
      "\tspeed: 0.1010s/iter; left time: 2096.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0472122 Vali Loss: 0.1324671 Test Loss: 0.1473247\n",
      "Validation loss decreased (0.133532 --> 0.132467).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0425316\n",
      "\tspeed: 0.1749s/iter; left time: 3609.7500s\n",
      "\titers: 200, epoch: 8 | loss: 0.0432509\n",
      "\tspeed: 0.1009s/iter; left time: 2073.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.72s\n",
      "Steps: 223 | Train Loss: 0.0445452 Vali Loss: 0.1312808 Test Loss: 0.1476530\n",
      "Validation loss decreased (0.132467 --> 0.131281).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0425568\n",
      "\tspeed: 0.1777s/iter; left time: 3627.8907s\n",
      "\titers: 200, epoch: 9 | loss: 0.0417050\n",
      "\tspeed: 0.1020s/iter; left time: 2072.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:23.00s\n",
      "Steps: 223 | Train Loss: 0.0420848 Vali Loss: 0.1306852 Test Loss: 0.1460166\n",
      "Validation loss decreased (0.131281 --> 0.130685).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0378647\n",
      "\tspeed: 0.1766s/iter; left time: 3567.0309s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402136\n",
      "\tspeed: 0.1026s/iter; left time: 2062.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:23.01s\n",
      "Steps: 223 | Train Loss: 0.0400473 Vali Loss: 0.1308217 Test Loss: 0.1454586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0374846\n",
      "\tspeed: 0.1708s/iter; left time: 3410.6057s\n",
      "\titers: 200, epoch: 11 | loss: 0.0383585\n",
      "\tspeed: 0.1024s/iter; left time: 2035.1479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:23.04s\n",
      "Steps: 223 | Train Loss: 0.0382027 Vali Loss: 0.1303351 Test Loss: 0.1458236\n",
      "Validation loss decreased (0.130685 --> 0.130335).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0374159\n",
      "\tspeed: 0.1788s/iter; left time: 3531.5616s\n",
      "\titers: 200, epoch: 12 | loss: 0.0373506\n",
      "\tspeed: 0.1012s/iter; left time: 1988.8510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0376595 Vali Loss: 0.1295768 Test Loss: 0.1450953\n",
      "Validation loss decreased (0.130335 --> 0.129577).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0358182\n",
      "\tspeed: 0.1874s/iter; left time: 3659.5721s\n",
      "\titers: 200, epoch: 13 | loss: 0.0358183\n",
      "\tspeed: 0.1017s/iter; left time: 1975.6172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:23.04s\n",
      "Steps: 223 | Train Loss: 0.0360024 Vali Loss: 0.1304294 Test Loss: 0.1469097\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0353733\n",
      "\tspeed: 0.1710s/iter; left time: 3301.2346s\n",
      "\titers: 200, epoch: 14 | loss: 0.0349147\n",
      "\tspeed: 0.1022s/iter; left time: 1961.7360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:23.05s\n",
      "Steps: 223 | Train Loss: 0.0355296 Vali Loss: 0.1294342 Test Loss: 0.1449126\n",
      "Validation loss decreased (0.129577 --> 0.129434).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0354217\n",
      "\tspeed: 0.1826s/iter; left time: 3483.0609s\n",
      "\titers: 200, epoch: 15 | loss: 0.0349589\n",
      "\tspeed: 0.1029s/iter; left time: 1953.2095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:23.23s\n",
      "Steps: 223 | Train Loss: 0.0346953 Vali Loss: 0.1293914 Test Loss: 0.1447888\n",
      "Validation loss decreased (0.129434 --> 0.129391).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0353416\n",
      "\tspeed: 0.1784s/iter; left time: 3364.5301s\n",
      "\titers: 200, epoch: 16 | loss: 0.0330689\n",
      "\tspeed: 0.1011s/iter; left time: 1896.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0347494 Vali Loss: 0.1293732 Test Loss: 0.1447825\n",
      "Validation loss decreased (0.129391 --> 0.129373).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0339002\n",
      "\tspeed: 0.1782s/iter; left time: 3320.3985s\n",
      "\titers: 200, epoch: 17 | loss: 0.0314987\n",
      "\tspeed: 0.1019s/iter; left time: 1888.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.96s\n",
      "Steps: 223 | Train Loss: 0.0332876 Vali Loss: 0.1293050 Test Loss: 0.1444554\n",
      "Validation loss decreased (0.129373 --> 0.129305).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0325020\n",
      "\tspeed: 0.1765s/iter; left time: 3249.8851s\n",
      "\titers: 200, epoch: 18 | loss: 0.0317712\n",
      "\tspeed: 0.1010s/iter; left time: 1850.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.84s\n",
      "Steps: 223 | Train Loss: 0.0327897 Vali Loss: 0.1290222 Test Loss: 0.1443444\n",
      "Validation loss decreased (0.129305 --> 0.129022).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0323275\n",
      "\tspeed: 0.1878s/iter; left time: 3415.4863s\n",
      "\titers: 200, epoch: 19 | loss: 0.0306696\n",
      "\tspeed: 0.1024s/iter; left time: 1851.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:23.07s\n",
      "Steps: 223 | Train Loss: 0.0321643 Vali Loss: 0.1289278 Test Loss: 0.1446663\n",
      "Validation loss decreased (0.129022 --> 0.128928).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0317876\n",
      "\tspeed: 0.1973s/iter; left time: 3544.8125s\n",
      "\titers: 200, epoch: 20 | loss: 0.0313587\n",
      "\tspeed: 0.1014s/iter; left time: 1811.5416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.91s\n",
      "Steps: 223 | Train Loss: 0.0316554 Vali Loss: 0.1286264 Test Loss: 0.1439690\n",
      "Validation loss decreased (0.128928 --> 0.128626).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0304738\n",
      "\tspeed: 0.1830s/iter; left time: 3246.3841s\n",
      "\titers: 200, epoch: 21 | loss: 0.0327107\n",
      "\tspeed: 0.1028s/iter; left time: 1813.0271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:23.22s\n",
      "Steps: 223 | Train Loss: 0.0315763 Vali Loss: 0.1285892 Test Loss: 0.1445394\n",
      "Validation loss decreased (0.128626 --> 0.128589).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0316087\n",
      "\tspeed: 0.1925s/iter; left time: 3371.8919s\n",
      "\titers: 200, epoch: 22 | loss: 0.0318276\n",
      "\tspeed: 0.1010s/iter; left time: 1759.2516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:22.85s\n",
      "Steps: 223 | Train Loss: 0.0310572 Vali Loss: 0.1286587 Test Loss: 0.1445479\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0302220\n",
      "\tspeed: 0.1707s/iter; left time: 2951.9827s\n",
      "\titers: 200, epoch: 23 | loss: 0.0304300\n",
      "\tspeed: 0.1021s/iter; left time: 1755.7046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:23.07s\n",
      "Steps: 223 | Train Loss: 0.0307635 Vali Loss: 0.1284783 Test Loss: 0.1442952\n",
      "Validation loss decreased (0.128589 --> 0.128478).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0304984\n",
      "\tspeed: 0.1763s/iter; left time: 3009.3992s\n",
      "\titers: 200, epoch: 24 | loss: 0.0302245\n",
      "\tspeed: 0.1016s/iter; left time: 1724.5909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:22.82s\n",
      "Steps: 223 | Train Loss: 0.0307209 Vali Loss: 0.1284794 Test Loss: 0.1443956\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0304130\n",
      "\tspeed: 0.1709s/iter; left time: 2880.2588s\n",
      "\titers: 200, epoch: 25 | loss: 0.0304252\n",
      "\tspeed: 0.1025s/iter; left time: 1716.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:23.06s\n",
      "Steps: 223 | Train Loss: 0.0305077 Vali Loss: 0.1283769 Test Loss: 0.1444592\n",
      "Validation loss decreased (0.128478 --> 0.128377).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0312527\n",
      "\tspeed: 0.1832s/iter; left time: 3046.0227s\n",
      "\titers: 200, epoch: 26 | loss: 0.0312282\n",
      "\tspeed: 0.1019s/iter; left time: 1684.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:22.88s\n",
      "Steps: 223 | Train Loss: 0.0302471 Vali Loss: 0.1284113 Test Loss: 0.1442370\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0307134\n",
      "\tspeed: 0.1700s/iter; left time: 2788.0699s\n",
      "\titers: 200, epoch: 27 | loss: 0.0288876\n",
      "\tspeed: 0.1026s/iter; left time: 1673.4250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:22.92s\n",
      "Steps: 223 | Train Loss: 0.0298442 Vali Loss: 0.1283943 Test Loss: 0.1446010\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0302495\n",
      "\tspeed: 0.1689s/iter; left time: 2733.5069s\n",
      "\titers: 200, epoch: 28 | loss: 0.0294432\n",
      "\tspeed: 0.1016s/iter; left time: 1633.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:22.87s\n",
      "Steps: 223 | Train Loss: 0.0296582 Vali Loss: 0.1284400 Test Loss: 0.1444808\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0289791\n",
      "\tspeed: 0.1686s/iter; left time: 2689.7123s\n",
      "\titers: 200, epoch: 29 | loss: 0.0302416\n",
      "\tspeed: 0.1021s/iter; left time: 1618.8666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:22.87s\n",
      "Steps: 223 | Train Loss: 0.0295461 Vali Loss: 0.1284262 Test Loss: 0.1441522\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0299884\n",
      "\tspeed: 0.1717s/iter; left time: 2702.0460s\n",
      "\titers: 200, epoch: 30 | loss: 0.0282255\n",
      "\tspeed: 0.1018s/iter; left time: 1591.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:22.90s\n",
      "Steps: 223 | Train Loss: 0.0294263 Vali Loss: 0.1284449 Test Loss: 0.1445789\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0307204\n",
      "\tspeed: 0.1689s/iter; left time: 2619.1072s\n",
      "\titers: 200, epoch: 31 | loss: 0.0296950\n",
      "\tspeed: 0.1019s/iter; left time: 1570.7813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.82s\n",
      "Steps: 223 | Train Loss: 0.0292683 Vali Loss: 0.1281265 Test Loss: 0.1442216\n",
      "Validation loss decreased (0.128377 --> 0.128127).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0292686\n",
      "\tspeed: 0.1794s/iter; left time: 2741.9895s\n",
      "\titers: 200, epoch: 32 | loss: 0.0289746\n",
      "\tspeed: 0.1011s/iter; left time: 1536.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0290840 Vali Loss: 0.1284545 Test Loss: 0.1444478\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0279634\n",
      "\tspeed: 0.1701s/iter; left time: 2563.0027s\n",
      "\titers: 200, epoch: 33 | loss: 0.0291580\n",
      "\tspeed: 0.1025s/iter; left time: 1533.6054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.99s\n",
      "Steps: 223 | Train Loss: 0.0290805 Vali Loss: 0.1283684 Test Loss: 0.1443674\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0277546\n",
      "\tspeed: 0.1707s/iter; left time: 2533.4751s\n",
      "\titers: 200, epoch: 34 | loss: 0.0292509\n",
      "\tspeed: 0.1015s/iter; left time: 1496.9823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0289610 Vali Loss: 0.1284619 Test Loss: 0.1445035\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0279095\n",
      "\tspeed: 0.1706s/iter; left time: 2493.7406s\n",
      "\titers: 200, epoch: 35 | loss: 0.0283519\n",
      "\tspeed: 0.1015s/iter; left time: 1473.0447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:22.91s\n",
      "Steps: 223 | Train Loss: 0.0288164 Vali Loss: 0.1283115 Test Loss: 0.1441863\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0276260\n",
      "\tspeed: 0.1719s/iter; left time: 2473.9977s\n",
      "\titers: 200, epoch: 36 | loss: 0.0282516\n",
      "\tspeed: 0.1017s/iter; left time: 1454.0066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:22.91s\n",
      "Steps: 223 | Train Loss: 0.0287018 Vali Loss: 0.1282796 Test Loss: 0.1444267\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0282841\n",
      "\tspeed: 0.1702s/iter; left time: 2412.9425s\n",
      "\titers: 200, epoch: 37 | loss: 0.0275572\n",
      "\tspeed: 0.1017s/iter; left time: 1431.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:22.93s\n",
      "Steps: 223 | Train Loss: 0.0287441 Vali Loss: 0.1285490 Test Loss: 0.1445745\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0285645\n",
      "\tspeed: 0.1708s/iter; left time: 2382.3946s\n",
      "\titers: 200, epoch: 38 | loss: 0.0292528\n",
      "\tspeed: 0.1020s/iter; left time: 1413.0801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:22.90s\n",
      "Steps: 223 | Train Loss: 0.0286795 Vali Loss: 0.1284727 Test Loss: 0.1444877\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0287385\n",
      "\tspeed: 0.1696s/iter; left time: 2327.4948s\n",
      "\titers: 200, epoch: 39 | loss: 0.0279627\n",
      "\tspeed: 0.1016s/iter; left time: 1384.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:22.86s\n",
      "Steps: 223 | Train Loss: 0.0284555 Vali Loss: 0.1285705 Test Loss: 0.1444850\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0289875\n",
      "\tspeed: 0.1722s/iter; left time: 2325.6854s\n",
      "\titers: 200, epoch: 40 | loss: 0.0288850\n",
      "\tspeed: 0.1024s/iter; left time: 1372.6636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:23.09s\n",
      "Steps: 223 | Train Loss: 0.0284726 Vali Loss: 0.1283926 Test Loss: 0.1443235\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0283259\n",
      "\tspeed: 0.1705s/iter; left time: 2263.9987s\n",
      "\titers: 200, epoch: 41 | loss: 0.0278825\n",
      "\tspeed: 0.1027s/iter; left time: 1353.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:22.93s\n",
      "Steps: 223 | Train Loss: 0.0285104 Vali Loss: 0.1286705 Test Loss: 0.1444085\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.043613020330667496, rmse:0.20883730053901672, mae:0.14422158896923065, rse:0.7397185564041138\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1338459\n",
      "\tspeed: 0.1034s/iter; left time: 2294.7097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1213693\n",
      "\tspeed: 0.1014s/iter; left time: 2241.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.85s\n",
      "Steps: 223 | Train Loss: 0.1337232 Vali Loss: 0.1337726 Test Loss: 0.1441684\n",
      "Validation loss decreased (inf --> 0.133773).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1043951\n",
      "\tspeed: 0.1813s/iter; left time: 3984.8829s\n",
      "\titers: 200, epoch: 2 | loss: 0.0920857\n",
      "\tspeed: 0.1024s/iter; left time: 2240.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.96s\n",
      "Steps: 223 | Train Loss: 0.1057510 Vali Loss: 0.1365143 Test Loss: 0.1516177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0821584\n",
      "\tspeed: 0.1726s/iter; left time: 3755.3538s\n",
      "\titers: 200, epoch: 3 | loss: 0.0746673\n",
      "\tspeed: 0.1011s/iter; left time: 2188.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.89s\n",
      "Steps: 223 | Train Loss: 0.0797383 Vali Loss: 0.1378467 Test Loss: 0.1510403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0667732\n",
      "\tspeed: 0.1697s/iter; left time: 3653.9238s\n",
      "\titers: 200, epoch: 4 | loss: 0.0627262\n",
      "\tspeed: 0.1010s/iter; left time: 2164.0259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0662417 Vali Loss: 0.1371741 Test Loss: 0.1498331\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0562829\n",
      "\tspeed: 0.1699s/iter; left time: 3620.2836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0550903\n",
      "\tspeed: 0.1010s/iter; left time: 2143.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0572172 Vali Loss: 0.1346277 Test Loss: 0.1484157\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0504830\n",
      "\tspeed: 0.1704s/iter; left time: 3592.5173s\n",
      "\titers: 200, epoch: 6 | loss: 0.0477005\n",
      "\tspeed: 0.1012s/iter; left time: 2123.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.82s\n",
      "Steps: 223 | Train Loss: 0.0506504 Vali Loss: 0.1318472 Test Loss: 0.1444080\n",
      "Validation loss decreased (0.133773 --> 0.131847).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0474096\n",
      "\tspeed: 0.1955s/iter; left time: 4078.2914s\n",
      "\titers: 200, epoch: 7 | loss: 0.0459429\n",
      "\tspeed: 0.1011s/iter; left time: 2099.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 223 | Train Loss: 0.0467058 Vali Loss: 0.1315055 Test Loss: 0.1430237\n",
      "Validation loss decreased (0.131847 --> 0.131506).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0485883\n",
      "\tspeed: 0.1798s/iter; left time: 3711.2370s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448056\n",
      "\tspeed: 0.1011s/iter; left time: 2077.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.86s\n",
      "Steps: 223 | Train Loss: 0.0443797 Vali Loss: 0.1315295 Test Loss: 0.1430706\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0408929\n",
      "\tspeed: 0.1705s/iter; left time: 3480.7831s\n",
      "\titers: 200, epoch: 9 | loss: 0.0445887\n",
      "\tspeed: 0.1010s/iter; left time: 2052.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0419238 Vali Loss: 0.1313425 Test Loss: 0.1432481\n",
      "Validation loss decreased (0.131506 --> 0.131342).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0368652\n",
      "\tspeed: 0.1805s/iter; left time: 3644.0987s\n",
      "\titers: 200, epoch: 10 | loss: 0.0413611\n",
      "\tspeed: 0.1011s/iter; left time: 2032.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 223 | Train Loss: 0.0396389 Vali Loss: 0.1304631 Test Loss: 0.1420865\n",
      "Validation loss decreased (0.131342 --> 0.130463).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0378972\n",
      "\tspeed: 0.1792s/iter; left time: 3578.5187s\n",
      "\titers: 200, epoch: 11 | loss: 0.0404556\n",
      "\tspeed: 0.1011s/iter; left time: 2008.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.0381702 Vali Loss: 0.1310368 Test Loss: 0.1427826\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0374863\n",
      "\tspeed: 0.1685s/iter; left time: 3328.1501s\n",
      "\titers: 200, epoch: 12 | loss: 0.0395534\n",
      "\tspeed: 0.1010s/iter; left time: 1983.7960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 223 | Train Loss: 0.0372254 Vali Loss: 0.1305252 Test Loss: 0.1424272\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0391716\n",
      "\tspeed: 0.1692s/iter; left time: 3303.8621s\n",
      "\titers: 200, epoch: 13 | loss: 0.0361170\n",
      "\tspeed: 0.1010s/iter; left time: 1961.0588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0358281 Vali Loss: 0.1303129 Test Loss: 0.1430231\n",
      "Validation loss decreased (0.130463 --> 0.130313).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0342916\n",
      "\tspeed: 0.1812s/iter; left time: 3498.0966s\n",
      "\titers: 200, epoch: 14 | loss: 0.0359754\n",
      "\tspeed: 0.1012s/iter; left time: 1943.6959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:22.84s\n",
      "Steps: 223 | Train Loss: 0.0349007 Vali Loss: 0.1301288 Test Loss: 0.1417290\n",
      "Validation loss decreased (0.130313 --> 0.130129).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0340790\n",
      "\tspeed: 0.1858s/iter; left time: 3544.9399s\n",
      "\titers: 200, epoch: 15 | loss: 0.0339541\n",
      "\tspeed: 0.1009s/iter; left time: 1915.6930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0348570 Vali Loss: 0.1305743 Test Loss: 0.1419227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0337586\n",
      "\tspeed: 0.1697s/iter; left time: 3200.0545s\n",
      "\titers: 200, epoch: 16 | loss: 0.0331303\n",
      "\tspeed: 0.1010s/iter; left time: 1894.9020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0335450 Vali Loss: 0.1298782 Test Loss: 0.1412999\n",
      "Validation loss decreased (0.130129 --> 0.129878).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0318183\n",
      "\tspeed: 0.1851s/iter; left time: 3449.1933s\n",
      "\titers: 200, epoch: 17 | loss: 0.0328143\n",
      "\tspeed: 0.1009s/iter; left time: 1869.8226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.72s\n",
      "Steps: 223 | Train Loss: 0.0329707 Vali Loss: 0.1298787 Test Loss: 0.1423763\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0320255\n",
      "\tspeed: 0.1696s/iter; left time: 3122.4738s\n",
      "\titers: 200, epoch: 18 | loss: 0.0310955\n",
      "\tspeed: 0.1009s/iter; left time: 1847.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0324296 Vali Loss: 0.1296944 Test Loss: 0.1420973\n",
      "Validation loss decreased (0.129878 --> 0.129694).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0331034\n",
      "\tspeed: 0.1784s/iter; left time: 3244.0197s\n",
      "\titers: 200, epoch: 19 | loss: 0.0322973\n",
      "\tspeed: 0.1009s/iter; left time: 1825.6029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:22.75s\n",
      "Steps: 223 | Train Loss: 0.0317739 Vali Loss: 0.1300072 Test Loss: 0.1421231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0312252\n",
      "\tspeed: 0.1686s/iter; left time: 3029.1912s\n",
      "\titers: 200, epoch: 20 | loss: 0.0306236\n",
      "\tspeed: 0.1011s/iter; left time: 1805.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.75s\n",
      "Steps: 223 | Train Loss: 0.0313309 Vali Loss: 0.1296711 Test Loss: 0.1417137\n",
      "Validation loss decreased (0.129694 --> 0.129671).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0304254\n",
      "\tspeed: 0.1912s/iter; left time: 3392.9331s\n",
      "\titers: 200, epoch: 21 | loss: 0.0311199\n",
      "\tspeed: 0.1009s/iter; left time: 1780.1910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:22.84s\n",
      "Steps: 223 | Train Loss: 0.0310391 Vali Loss: 0.1295275 Test Loss: 0.1416109\n",
      "Validation loss decreased (0.129671 --> 0.129527).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0298874\n",
      "\tspeed: 0.1842s/iter; left time: 3227.2307s\n",
      "\titers: 200, epoch: 22 | loss: 0.0302612\n",
      "\tspeed: 0.1010s/iter; left time: 1759.9667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0310310 Vali Loss: 0.1297438 Test Loss: 0.1420938\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0294712\n",
      "\tspeed: 0.1701s/iter; left time: 2941.6373s\n",
      "\titers: 200, epoch: 23 | loss: 0.0311504\n",
      "\tspeed: 0.1010s/iter; left time: 1736.6523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:22.74s\n",
      "Steps: 223 | Train Loss: 0.0306204 Vali Loss: 0.1293175 Test Loss: 0.1416340\n",
      "Validation loss decreased (0.129527 --> 0.129318).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0306717\n",
      "\tspeed: 0.1754s/iter; left time: 2993.8695s\n",
      "\titers: 200, epoch: 24 | loss: 0.0326125\n",
      "\tspeed: 0.1013s/iter; left time: 1718.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0301517 Vali Loss: 0.1295908 Test Loss: 0.1415685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0294771\n",
      "\tspeed: 0.1693s/iter; left time: 2852.5034s\n",
      "\titers: 200, epoch: 25 | loss: 0.0290208\n",
      "\tspeed: 0.1009s/iter; left time: 1689.8492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:22.75s\n",
      "Steps: 223 | Train Loss: 0.0300518 Vali Loss: 0.1294771 Test Loss: 0.1413270\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0310628\n",
      "\tspeed: 0.1686s/iter; left time: 2803.7500s\n",
      "\titers: 200, epoch: 26 | loss: 0.0298298\n",
      "\tspeed: 0.1009s/iter; left time: 1667.7063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0298269 Vali Loss: 0.1297811 Test Loss: 0.1419676\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0308892\n",
      "\tspeed: 0.1693s/iter; left time: 2777.2208s\n",
      "\titers: 200, epoch: 27 | loss: 0.0297598\n",
      "\tspeed: 0.1009s/iter; left time: 1645.6515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0296573 Vali Loss: 0.1293213 Test Loss: 0.1413701\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0298229\n",
      "\tspeed: 0.1707s/iter; left time: 2762.2213s\n",
      "\titers: 200, epoch: 28 | loss: 0.0291561\n",
      "\tspeed: 0.1009s/iter; left time: 1622.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0293908 Vali Loss: 0.1292067 Test Loss: 0.1414965\n",
      "Validation loss decreased (0.129318 --> 0.129207).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0295447\n",
      "\tspeed: 0.1762s/iter; left time: 2812.1745s\n",
      "\titers: 200, epoch: 29 | loss: 0.0289325\n",
      "\tspeed: 0.1018s/iter; left time: 1613.6423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 223 | Train Loss: 0.0292231 Vali Loss: 0.1293714 Test Loss: 0.1416098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0297523\n",
      "\tspeed: 0.1696s/iter; left time: 2668.8141s\n",
      "\titers: 200, epoch: 30 | loss: 0.0293122\n",
      "\tspeed: 0.1010s/iter; left time: 1578.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 223 | Train Loss: 0.0291896 Vali Loss: 0.1295614 Test Loss: 0.1418938\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0294015\n",
      "\tspeed: 0.1690s/iter; left time: 2620.6202s\n",
      "\titers: 200, epoch: 31 | loss: 0.0278125\n",
      "\tspeed: 0.1011s/iter; left time: 1557.7221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:22.78s\n",
      "Steps: 223 | Train Loss: 0.0289900 Vali Loss: 0.1293283 Test Loss: 0.1413058\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0296534\n",
      "\tspeed: 0.1684s/iter; left time: 2574.1649s\n",
      "\titers: 200, epoch: 32 | loss: 0.0288739\n",
      "\tspeed: 0.1010s/iter; left time: 1534.5276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.0287816 Vali Loss: 0.1293303 Test Loss: 0.1414459\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0288480\n",
      "\tspeed: 0.1698s/iter; left time: 2557.5053s\n",
      "\titers: 200, epoch: 33 | loss: 0.0295896\n",
      "\tspeed: 0.1011s/iter; left time: 1512.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 223 | Train Loss: 0.0287548 Vali Loss: 0.1292268 Test Loss: 0.1410291\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0292089\n",
      "\tspeed: 0.1695s/iter; left time: 2515.1648s\n",
      "\titers: 200, epoch: 34 | loss: 0.0275612\n",
      "\tspeed: 0.1013s/iter; left time: 1493.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 223 | Train Loss: 0.0285835 Vali Loss: 0.1293273 Test Loss: 0.1415049\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0284292\n",
      "\tspeed: 0.1692s/iter; left time: 2473.1380s\n",
      "\titers: 200, epoch: 35 | loss: 0.0274603\n",
      "\tspeed: 0.1011s/iter; left time: 1468.4696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0285293 Vali Loss: 0.1294487 Test Loss: 0.1417609\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0283691\n",
      "\tspeed: 0.1711s/iter; left time: 2462.4770s\n",
      "\titers: 200, epoch: 36 | loss: 0.0281101\n",
      "\tspeed: 0.1013s/iter; left time: 1448.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:22.87s\n",
      "Steps: 223 | Train Loss: 0.0283747 Vali Loss: 0.1292968 Test Loss: 0.1414106\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0297436\n",
      "\tspeed: 0.1698s/iter; left time: 2405.9788s\n",
      "\titers: 200, epoch: 37 | loss: 0.0285179\n",
      "\tspeed: 0.1012s/iter; left time: 1424.3143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0285509 Vali Loss: 0.1293069 Test Loss: 0.1414223\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0277756\n",
      "\tspeed: 0.1697s/iter; left time: 2367.4064s\n",
      "\titers: 200, epoch: 38 | loss: 0.0290327\n",
      "\tspeed: 0.1012s/iter; left time: 1401.3622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0283419 Vali Loss: 0.1292873 Test Loss: 0.1415935\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04234959930181503, rmse:0.205790176987648, mae:0.14149640500545502, rse:0.7289254069328308\n",
      "Intermediate time for DE and pred_len 168: 00h:36m:38.08s\n",
      "Intermediate time for DE: 01h:31m:06.35s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1000400\n",
      "\tspeed: 0.1256s/iter; left time: 2800.9754s\n",
      "\titers: 200, epoch: 1 | loss: 0.0889657\n",
      "\tspeed: 0.0978s/iter; left time: 2172.2554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.1082130 Vali Loss: 0.1031816 Test Loss: 0.1152446\n",
      "Validation loss decreased (inf --> 0.103182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0845666\n",
      "\tspeed: 0.1743s/iter; left time: 3847.0460s\n",
      "\titers: 200, epoch: 2 | loss: 0.0818039\n",
      "\tspeed: 0.0982s/iter; left time: 2157.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.16s\n",
      "Steps: 224 | Train Loss: 0.0857477 Vali Loss: 0.0982765 Test Loss: 0.1124934\n",
      "Validation loss decreased (0.103182 --> 0.098277).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0732861\n",
      "\tspeed: 0.1698s/iter; left time: 3709.8877s\n",
      "\titers: 200, epoch: 3 | loss: 0.0766309\n",
      "\tspeed: 0.0978s/iter; left time: 2127.9760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.11s\n",
      "Steps: 224 | Train Loss: 0.0785921 Vali Loss: 0.1015784 Test Loss: 0.1143293\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0728939\n",
      "\tspeed: 0.1620s/iter; left time: 3503.8179s\n",
      "\titers: 200, epoch: 4 | loss: 0.0681023\n",
      "\tspeed: 0.0990s/iter; left time: 2131.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.18s\n",
      "Steps: 224 | Train Loss: 0.0711089 Vali Loss: 0.1054293 Test Loss: 0.1163301\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639224\n",
      "\tspeed: 0.1627s/iter; left time: 3482.3726s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605066\n",
      "\tspeed: 0.0981s/iter; left time: 2089.2166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.12s\n",
      "Steps: 224 | Train Loss: 0.0622334 Vali Loss: 0.1083525 Test Loss: 0.1197059\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0546447\n",
      "\tspeed: 0.1631s/iter; left time: 3453.5807s\n",
      "\titers: 200, epoch: 6 | loss: 0.0536140\n",
      "\tspeed: 0.0979s/iter; left time: 2064.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.12s\n",
      "Steps: 224 | Train Loss: 0.0555567 Vali Loss: 0.1104376 Test Loss: 0.1198921\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0516678\n",
      "\tspeed: 0.1625s/iter; left time: 3405.3044s\n",
      "\titers: 200, epoch: 7 | loss: 0.0488077\n",
      "\tspeed: 0.0980s/iter; left time: 2043.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.10s\n",
      "Steps: 224 | Train Loss: 0.0507787 Vali Loss: 0.1112424 Test Loss: 0.1215639\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0464973\n",
      "\tspeed: 0.1635s/iter; left time: 3390.0308s\n",
      "\titers: 200, epoch: 8 | loss: 0.0490609\n",
      "\tspeed: 0.0980s/iter; left time: 2021.5279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.19s\n",
      "Steps: 224 | Train Loss: 0.0473406 Vali Loss: 0.1101312 Test Loss: 0.1211495\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0439890\n",
      "\tspeed: 0.1631s/iter; left time: 3346.0291s\n",
      "\titers: 200, epoch: 9 | loss: 0.0441779\n",
      "\tspeed: 0.0982s/iter; left time: 2004.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.0442485 Vali Loss: 0.1090659 Test Loss: 0.1218175\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0418965\n",
      "\tspeed: 0.1634s/iter; left time: 3315.0499s\n",
      "\titers: 200, epoch: 10 | loss: 0.0423168\n",
      "\tspeed: 0.0981s/iter; left time: 1979.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0417639 Vali Loss: 0.1084580 Test Loss: 0.1203145\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0392470\n",
      "\tspeed: 0.1630s/iter; left time: 3270.8621s\n",
      "\titers: 200, epoch: 11 | loss: 0.0400443\n",
      "\tspeed: 0.0989s/iter; left time: 1974.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0399939 Vali Loss: 0.1085082 Test Loss: 0.1204979\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0389502\n",
      "\tspeed: 0.1628s/iter; left time: 3230.0995s\n",
      "\titers: 200, epoch: 12 | loss: 0.0355284\n",
      "\tspeed: 0.0979s/iter; left time: 1931.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.09s\n",
      "Steps: 224 | Train Loss: 0.0382218 Vali Loss: 0.1076079 Test Loss: 0.1214052\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029199549928307533, rmse:0.17087875306606293, mae:0.11249343305826187, rse:0.5894832611083984\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1040811\n",
      "\tspeed: 0.0996s/iter; left time: 2221.4734s\n",
      "\titers: 200, epoch: 1 | loss: 0.0935913\n",
      "\tspeed: 0.0979s/iter; left time: 2172.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.1089075 Vali Loss: 0.1033798 Test Loss: 0.1159112\n",
      "Validation loss decreased (inf --> 0.103380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0797644\n",
      "\tspeed: 0.1745s/iter; left time: 3851.9621s\n",
      "\titers: 200, epoch: 2 | loss: 0.0804092\n",
      "\tspeed: 0.0981s/iter; left time: 2155.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.20s\n",
      "Steps: 224 | Train Loss: 0.0856039 Vali Loss: 0.0979992 Test Loss: 0.1111437\n",
      "Validation loss decreased (0.103380 --> 0.097999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0766721\n",
      "\tspeed: 0.1760s/iter; left time: 3845.5997s\n",
      "\titers: 200, epoch: 3 | loss: 0.0783876\n",
      "\tspeed: 0.0981s/iter; left time: 2133.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.19s\n",
      "Steps: 224 | Train Loss: 0.0784792 Vali Loss: 0.0983647 Test Loss: 0.1096302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729389\n",
      "\tspeed: 0.1636s/iter; left time: 3538.1950s\n",
      "\titers: 200, epoch: 4 | loss: 0.0714793\n",
      "\tspeed: 0.0980s/iter; left time: 2109.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.0713042 Vali Loss: 0.1074160 Test Loss: 0.1172837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0637151\n",
      "\tspeed: 0.1629s/iter; left time: 3487.4557s\n",
      "\titers: 200, epoch: 5 | loss: 0.0599574\n",
      "\tspeed: 0.0979s/iter; left time: 2086.3567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.09s\n",
      "Steps: 224 | Train Loss: 0.0628277 Vali Loss: 0.1088988 Test Loss: 0.1203743\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0548561\n",
      "\tspeed: 0.1635s/iter; left time: 3463.8681s\n",
      "\titers: 200, epoch: 6 | loss: 0.0529555\n",
      "\tspeed: 0.0980s/iter; left time: 2065.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.19s\n",
      "Steps: 224 | Train Loss: 0.0561751 Vali Loss: 0.1093509 Test Loss: 0.1232503\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0568765\n",
      "\tspeed: 0.1625s/iter; left time: 3405.3661s\n",
      "\titers: 200, epoch: 7 | loss: 0.0484834\n",
      "\tspeed: 0.0975s/iter; left time: 2032.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.04s\n",
      "Steps: 224 | Train Loss: 0.0508114 Vali Loss: 0.1082517 Test Loss: 0.1216338\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0478964\n",
      "\tspeed: 0.1640s/iter; left time: 3401.0924s\n",
      "\titers: 200, epoch: 8 | loss: 0.0458303\n",
      "\tspeed: 0.0979s/iter; left time: 2020.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.0471401 Vali Loss: 0.1078706 Test Loss: 0.1242654\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0449760\n",
      "\tspeed: 0.1644s/iter; left time: 3370.9944s\n",
      "\titers: 200, epoch: 9 | loss: 0.0443707\n",
      "\tspeed: 0.0982s/iter; left time: 2003.2677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.23s\n",
      "Steps: 224 | Train Loss: 0.0438777 Vali Loss: 0.1064936 Test Loss: 0.1229029\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0417951\n",
      "\tspeed: 0.1627s/iter; left time: 3301.1427s\n",
      "\titers: 200, epoch: 10 | loss: 0.0405808\n",
      "\tspeed: 0.0979s/iter; left time: 1976.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.10s\n",
      "Steps: 224 | Train Loss: 0.0417294 Vali Loss: 0.1068690 Test Loss: 0.1220882\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0396463\n",
      "\tspeed: 0.1632s/iter; left time: 3273.3391s\n",
      "\titers: 200, epoch: 11 | loss: 0.0384465\n",
      "\tspeed: 0.0979s/iter; left time: 1954.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.13s\n",
      "Steps: 224 | Train Loss: 0.0397610 Vali Loss: 0.1065472 Test Loss: 0.1219878\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0375036\n",
      "\tspeed: 0.1628s/iter; left time: 3229.6234s\n",
      "\titers: 200, epoch: 12 | loss: 0.0383344\n",
      "\tspeed: 0.0979s/iter; left time: 1932.0174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:22.11s\n",
      "Steps: 224 | Train Loss: 0.0381573 Vali Loss: 0.1053996 Test Loss: 0.1228065\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028552530333399773, rmse:0.16897493600845337, mae:0.11114371567964554, rse:0.5829156041145325\n",
      "Intermediate time for GB and pred_len 24: 00h:10m:46.68s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1210458\n",
      "\tspeed: 0.1269s/iter; left time: 2830.2620s\n",
      "\titers: 200, epoch: 1 | loss: 0.1112605\n",
      "\tspeed: 0.0995s/iter; left time: 2209.8410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.81s\n",
      "Steps: 224 | Train Loss: 0.1222008 Vali Loss: 0.1245735 Test Loss: 0.1466682\n",
      "Validation loss decreased (inf --> 0.124573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1038702\n",
      "\tspeed: 0.1772s/iter; left time: 3911.0823s\n",
      "\titers: 200, epoch: 2 | loss: 0.0924622\n",
      "\tspeed: 0.0996s/iter; left time: 2189.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.59s\n",
      "Steps: 224 | Train Loss: 0.1059021 Vali Loss: 0.1332862 Test Loss: 0.1500637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0808003\n",
      "\tspeed: 0.1660s/iter; left time: 3626.9603s\n",
      "\titers: 200, epoch: 3 | loss: 0.0736129\n",
      "\tspeed: 0.0995s/iter; left time: 2164.7561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0828622 Vali Loss: 0.1415045 Test Loss: 0.1570451\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0686038\n",
      "\tspeed: 0.1689s/iter; left time: 3653.0037s\n",
      "\titers: 200, epoch: 4 | loss: 0.0656218\n",
      "\tspeed: 0.1005s/iter; left time: 2162.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 224 | Train Loss: 0.0670727 Vali Loss: 0.1425244 Test Loss: 0.1607312\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0593092\n",
      "\tspeed: 0.1673s/iter; left time: 3581.4297s\n",
      "\titers: 200, epoch: 5 | loss: 0.0538448\n",
      "\tspeed: 0.0994s/iter; left time: 2117.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0584418 Vali Loss: 0.1416681 Test Loss: 0.1574435\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0527765\n",
      "\tspeed: 0.1669s/iter; left time: 3535.6931s\n",
      "\titers: 200, epoch: 6 | loss: 0.0497815\n",
      "\tspeed: 0.0998s/iter; left time: 2104.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0519867 Vali Loss: 0.1407373 Test Loss: 0.1585691\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0489115\n",
      "\tspeed: 0.1663s/iter; left time: 3485.4344s\n",
      "\titers: 200, epoch: 7 | loss: 0.0484653\n",
      "\tspeed: 0.0994s/iter; left time: 2073.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0475200 Vali Loss: 0.1369800 Test Loss: 0.1548225\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0409547\n",
      "\tspeed: 0.1668s/iter; left time: 3457.4731s\n",
      "\titers: 200, epoch: 8 | loss: 0.0426313\n",
      "\tspeed: 0.0996s/iter; left time: 2055.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0440538 Vali Loss: 0.1374608 Test Loss: 0.1542663\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0407711\n",
      "\tspeed: 0.1667s/iter; left time: 3419.2583s\n",
      "\titers: 200, epoch: 9 | loss: 0.0403957\n",
      "\tspeed: 0.0995s/iter; left time: 2031.3795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0417281 Vali Loss: 0.1348568 Test Loss: 0.1534370\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0386112\n",
      "\tspeed: 0.1665s/iter; left time: 3377.1250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402503\n",
      "\tspeed: 0.0995s/iter; left time: 2008.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.0405633 Vali Loss: 0.1359578 Test Loss: 0.1525046\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0384958\n",
      "\tspeed: 0.1657s/iter; left time: 3324.6472s\n",
      "\titers: 200, epoch: 11 | loss: 0.0376746\n",
      "\tspeed: 0.0994s/iter; left time: 1984.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0389795 Vali Loss: 0.1339630 Test Loss: 0.1529814\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04464218392968178, rmse:0.2112869769334793, mae:0.1466681808233261, rse:0.7306598424911499\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1185862\n",
      "\tspeed: 0.1007s/iter; left time: 2246.7355s\n",
      "\titers: 200, epoch: 1 | loss: 0.1120367\n",
      "\tspeed: 0.0995s/iter; left time: 2208.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.1219711 Vali Loss: 0.1247018 Test Loss: 0.1465372\n",
      "Validation loss decreased (inf --> 0.124702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1071755\n",
      "\tspeed: 0.1783s/iter; left time: 3935.7838s\n",
      "\titers: 200, epoch: 2 | loss: 0.0921484\n",
      "\tspeed: 0.0996s/iter; left time: 2189.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.57s\n",
      "Steps: 224 | Train Loss: 0.1046357 Vali Loss: 0.1321889 Test Loss: 0.1508403\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0789659\n",
      "\tspeed: 0.1683s/iter; left time: 3678.3543s\n",
      "\titers: 200, epoch: 3 | loss: 0.0739356\n",
      "\tspeed: 0.0994s/iter; left time: 2161.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0799068 Vali Loss: 0.1397098 Test Loss: 0.1557169\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0647016\n",
      "\tspeed: 0.1667s/iter; left time: 3605.9977s\n",
      "\titers: 200, epoch: 4 | loss: 0.0596794\n",
      "\tspeed: 0.0995s/iter; left time: 2141.1073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0650651 Vali Loss: 0.1369236 Test Loss: 0.1548756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0552947\n",
      "\tspeed: 0.1667s/iter; left time: 3568.3970s\n",
      "\titers: 200, epoch: 5 | loss: 0.0535644\n",
      "\tspeed: 0.0994s/iter; left time: 2117.3180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.48s\n",
      "Steps: 224 | Train Loss: 0.0560993 Vali Loss: 0.1345373 Test Loss: 0.1530709\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0523013\n",
      "\tspeed: 0.1669s/iter; left time: 3534.0539s\n",
      "\titers: 200, epoch: 6 | loss: 0.0488983\n",
      "\tspeed: 0.0994s/iter; left time: 2095.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0505612 Vali Loss: 0.1308149 Test Loss: 0.1535134\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0531405\n",
      "\tspeed: 0.1667s/iter; left time: 3493.7993s\n",
      "\titers: 200, epoch: 7 | loss: 0.0464522\n",
      "\tspeed: 0.0994s/iter; left time: 2072.3212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.45s\n",
      "Steps: 224 | Train Loss: 0.0472376 Vali Loss: 0.1320213 Test Loss: 0.1530477\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0429615\n",
      "\tspeed: 0.1662s/iter; left time: 3445.9405s\n",
      "\titers: 200, epoch: 8 | loss: 0.0425697\n",
      "\tspeed: 0.0994s/iter; left time: 2051.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.44s\n",
      "Steps: 224 | Train Loss: 0.0434822 Vali Loss: 0.1306199 Test Loss: 0.1524510\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0411477\n",
      "\tspeed: 0.1665s/iter; left time: 3415.7583s\n",
      "\titers: 200, epoch: 9 | loss: 0.0385973\n",
      "\tspeed: 0.0994s/iter; left time: 2028.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.47s\n",
      "Steps: 224 | Train Loss: 0.0412297 Vali Loss: 0.1286369 Test Loss: 0.1519012\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0394646\n",
      "\tspeed: 0.1683s/iter; left time: 3414.0083s\n",
      "\titers: 200, epoch: 10 | loss: 0.0407799\n",
      "\tspeed: 0.0995s/iter; left time: 2008.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.53s\n",
      "Steps: 224 | Train Loss: 0.0394865 Vali Loss: 0.1282582 Test Loss: 0.1509731\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0409676\n",
      "\tspeed: 0.1672s/iter; left time: 3354.0731s\n",
      "\titers: 200, epoch: 11 | loss: 0.0372345\n",
      "\tspeed: 0.0995s/iter; left time: 1986.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.51s\n",
      "Steps: 224 | Train Loss: 0.0393302 Vali Loss: 0.1287157 Test Loss: 0.1511781\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.044634852558374405, rmse:0.21126961708068848, mae:0.14653731882572174, rse:0.7305997610092163\n",
      "Intermediate time for GB and pred_len 96: 00h:10m:06.07s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1212218\n",
      "\tspeed: 0.1264s/iter; left time: 2807.3061s\n",
      "\titers: 200, epoch: 1 | loss: 0.1139713\n",
      "\tspeed: 0.1011s/iter; left time: 2234.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.00s\n",
      "Steps: 223 | Train Loss: 0.1252046 Vali Loss: 0.1282504 Test Loss: 0.1520317\n",
      "Validation loss decreased (inf --> 0.128250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1078130\n",
      "\tspeed: 0.1820s/iter; left time: 3999.9323s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011755\n",
      "\tspeed: 0.1011s/iter; left time: 2211.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 223 | Train Loss: 0.1077820 Vali Loss: 0.1364171 Test Loss: 0.1541169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831033\n",
      "\tspeed: 0.1681s/iter; left time: 3657.9561s\n",
      "\titers: 200, epoch: 3 | loss: 0.0750316\n",
      "\tspeed: 0.1008s/iter; left time: 2182.1408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.73s\n",
      "Steps: 223 | Train Loss: 0.0813860 Vali Loss: 0.1430847 Test Loss: 0.1601447\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659564\n",
      "\tspeed: 0.1663s/iter; left time: 3581.3312s\n",
      "\titers: 200, epoch: 4 | loss: 0.0617063\n",
      "\tspeed: 0.1010s/iter; left time: 2163.9277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.68s\n",
      "Steps: 223 | Train Loss: 0.0664012 Vali Loss: 0.1409647 Test Loss: 0.1582429\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0551478\n",
      "\tspeed: 0.1661s/iter; left time: 3538.7871s\n",
      "\titers: 200, epoch: 5 | loss: 0.0538402\n",
      "\tspeed: 0.1009s/iter; left time: 2139.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.65s\n",
      "Steps: 223 | Train Loss: 0.0568825 Vali Loss: 0.1416528 Test Loss: 0.1601245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0496445\n",
      "\tspeed: 0.1661s/iter; left time: 3502.8575s\n",
      "\titers: 200, epoch: 6 | loss: 0.0504231\n",
      "\tspeed: 0.1011s/iter; left time: 2121.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.70s\n",
      "Steps: 223 | Train Loss: 0.0519403 Vali Loss: 0.1357887 Test Loss: 0.1577356\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0514954\n",
      "\tspeed: 0.1673s/iter; left time: 3490.1665s\n",
      "\titers: 200, epoch: 7 | loss: 0.0473062\n",
      "\tspeed: 0.1011s/iter; left time: 2098.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0473768 Vali Loss: 0.1372073 Test Loss: 0.1573528\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0422178\n",
      "\tspeed: 0.1665s/iter; left time: 3437.4536s\n",
      "\titers: 200, epoch: 8 | loss: 0.0432705\n",
      "\tspeed: 0.1010s/iter; left time: 2075.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 223 | Train Loss: 0.0447079 Vali Loss: 0.1335165 Test Loss: 0.1570952\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0454519\n",
      "\tspeed: 0.1654s/iter; left time: 3376.6563s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439654\n",
      "\tspeed: 0.1012s/iter; left time: 2055.4241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 223 | Train Loss: 0.0434310 Vali Loss: 0.1341390 Test Loss: 0.1555370\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0399883\n",
      "\tspeed: 0.1669s/iter; left time: 3370.8261s\n",
      "\titers: 200, epoch: 10 | loss: 0.0389427\n",
      "\tspeed: 0.1010s/iter; left time: 2029.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.66s\n",
      "Steps: 223 | Train Loss: 0.0405045 Vali Loss: 0.1328685 Test Loss: 0.1561904\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0404393\n",
      "\tspeed: 0.1657s/iter; left time: 3309.0078s\n",
      "\titers: 200, epoch: 11 | loss: 0.0401293\n",
      "\tspeed: 0.1009s/iter; left time: 2004.3886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.68s\n",
      "Steps: 223 | Train Loss: 0.0393156 Vali Loss: 0.1367602 Test Loss: 0.1561167\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.047135237604379654, rmse:0.21710650622844696, mae:0.15203170478343964, rse:0.752739429473877\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1246958\n",
      "\tspeed: 0.1027s/iter; left time: 2280.7693s\n",
      "\titers: 200, epoch: 1 | loss: 0.1193848\n",
      "\tspeed: 0.1010s/iter; left time: 2232.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:22.76s\n",
      "Steps: 223 | Train Loss: 0.1251033 Vali Loss: 0.1285281 Test Loss: 0.1520350\n",
      "Validation loss decreased (inf --> 0.128528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1079517\n",
      "\tspeed: 0.1846s/iter; left time: 4056.5247s\n",
      "\titers: 200, epoch: 2 | loss: 0.0979819\n",
      "\tspeed: 0.1013s/iter; left time: 2215.9539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:22.86s\n",
      "Steps: 223 | Train Loss: 0.1067287 Vali Loss: 0.1381765 Test Loss: 0.1558307\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0806419\n",
      "\tspeed: 0.1688s/iter; left time: 3672.0790s\n",
      "\titers: 200, epoch: 3 | loss: 0.0722020\n",
      "\tspeed: 0.1009s/iter; left time: 2185.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:22.68s\n",
      "Steps: 223 | Train Loss: 0.0795303 Vali Loss: 0.1408413 Test Loss: 0.1584047\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0665133\n",
      "\tspeed: 0.1695s/iter; left time: 3649.7260s\n",
      "\titers: 200, epoch: 4 | loss: 0.0628806\n",
      "\tspeed: 0.1010s/iter; left time: 2164.3039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.80s\n",
      "Steps: 223 | Train Loss: 0.0655871 Vali Loss: 0.1403571 Test Loss: 0.1598811\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0583973\n",
      "\tspeed: 0.1679s/iter; left time: 3577.5676s\n",
      "\titers: 200, epoch: 5 | loss: 0.0529059\n",
      "\tspeed: 0.1009s/iter; left time: 2139.0980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.68s\n",
      "Steps: 223 | Train Loss: 0.0570187 Vali Loss: 0.1381003 Test Loss: 0.1594655\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0521242\n",
      "\tspeed: 0.1683s/iter; left time: 3547.9760s\n",
      "\titers: 200, epoch: 6 | loss: 0.0498817\n",
      "\tspeed: 0.1013s/iter; left time: 2126.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:22.79s\n",
      "Steps: 223 | Train Loss: 0.0517209 Vali Loss: 0.1397730 Test Loss: 0.1600732\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0468313\n",
      "\tspeed: 0.1696s/iter; left time: 3539.3593s\n",
      "\titers: 200, epoch: 7 | loss: 0.0480323\n",
      "\tspeed: 0.1010s/iter; left time: 2096.3652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.77s\n",
      "Steps: 223 | Train Loss: 0.0474814 Vali Loss: 0.1360781 Test Loss: 0.1613502\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0461521\n",
      "\tspeed: 0.1694s/iter; left time: 3495.6213s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448193\n",
      "\tspeed: 0.1010s/iter; left time: 2074.4310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:22.74s\n",
      "Steps: 223 | Train Loss: 0.0448962 Vali Loss: 0.1352690 Test Loss: 0.1596699\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0418778\n",
      "\tspeed: 0.1680s/iter; left time: 3430.8513s\n",
      "\titers: 200, epoch: 9 | loss: 0.0405838\n",
      "\tspeed: 0.1009s/iter; left time: 2050.0136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:22.69s\n",
      "Steps: 223 | Train Loss: 0.0422619 Vali Loss: 0.1348368 Test Loss: 0.1576244\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0396611\n",
      "\tspeed: 0.1692s/iter; left time: 3415.9756s\n",
      "\titers: 200, epoch: 10 | loss: 0.0392483\n",
      "\tspeed: 0.1009s/iter; left time: 2027.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:22.70s\n",
      "Steps: 223 | Train Loss: 0.0415109 Vali Loss: 0.1355973 Test Loss: 0.1582328\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0386109\n",
      "\tspeed: 0.1681s/iter; left time: 3357.6595s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408022\n",
      "\tspeed: 0.1010s/iter; left time: 2006.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:22.71s\n",
      "Steps: 223 | Train Loss: 0.0391746 Vali Loss: 0.1352939 Test Loss: 0.1572801\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04724753275513649, rmse:0.21736498177051544, mae:0.1520349681377411, rse:0.7536356449127197\n",
      "Intermediate time for GB and pred_len 168: 00h:10m:13.64s\n",
      "Intermediate time for GB: 00h:31m:06.39s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1083394\n",
      "\tspeed: 0.0564s/iter; left time: 1257.0853s\n",
      "\titers: 200, epoch: 1 | loss: 0.0949330\n",
      "\tspeed: 0.0322s/iter; left time: 715.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.1146521 Vali Loss: 0.0854233 Test Loss: 0.0978887\n",
      "Validation loss decreased (inf --> 0.085423).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0694569\n",
      "\tspeed: 0.0609s/iter; left time: 1344.2013s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682702\n",
      "\tspeed: 0.0323s/iter; left time: 710.5164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0716935 Vali Loss: 0.0656114 Test Loss: 0.0731752\n",
      "Validation loss decreased (0.085423 --> 0.065611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638887\n",
      "\tspeed: 0.0623s/iter; left time: 1361.0037s\n",
      "\titers: 200, epoch: 3 | loss: 0.0625745\n",
      "\tspeed: 0.0321s/iter; left time: 698.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0642866 Vali Loss: 0.0630241 Test Loss: 0.0710565\n",
      "Validation loss decreased (0.065611 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611238\n",
      "\tspeed: 0.0613s/iter; left time: 1325.6060s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643910\n",
      "\tspeed: 0.0324s/iter; left time: 696.8565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0619596 Vali Loss: 0.0643963 Test Loss: 0.0716253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0614629\n",
      "\tspeed: 0.0601s/iter; left time: 1286.6637s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591143\n",
      "\tspeed: 0.0323s/iter; left time: 687.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0598301 Vali Loss: 0.0612322 Test Loss: 0.0694189\n",
      "Validation loss decreased (0.063024 --> 0.061232).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568408\n",
      "\tspeed: 0.0638s/iter; left time: 1350.7376s\n",
      "\titers: 200, epoch: 6 | loss: 0.0567278\n",
      "\tspeed: 0.0321s/iter; left time: 676.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0577446 Vali Loss: 0.0609693 Test Loss: 0.0682407\n",
      "Validation loss decreased (0.061232 --> 0.060969).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562621\n",
      "\tspeed: 0.0607s/iter; left time: 1271.2555s\n",
      "\titers: 200, epoch: 7 | loss: 0.0554868\n",
      "\tspeed: 0.0322s/iter; left time: 672.5456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0561681 Vali Loss: 0.0597783 Test Loss: 0.0675127\n",
      "Validation loss decreased (0.060969 --> 0.059778).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569908\n",
      "\tspeed: 0.0609s/iter; left time: 1262.2103s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577169\n",
      "\tspeed: 0.0321s/iter; left time: 662.8541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0544420 Vali Loss: 0.0602443 Test Loss: 0.0683316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521781\n",
      "\tspeed: 0.0592s/iter; left time: 1214.7410s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503141\n",
      "\tspeed: 0.0326s/iter; left time: 666.2345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0526811 Vali Loss: 0.0609316 Test Loss: 0.0681847\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0519583\n",
      "\tspeed: 0.0586s/iter; left time: 1188.8725s\n",
      "\titers: 200, epoch: 10 | loss: 0.0487051\n",
      "\tspeed: 0.0322s/iter; left time: 649.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0512578 Vali Loss: 0.0613501 Test Loss: 0.0695660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517822\n",
      "\tspeed: 0.0595s/iter; left time: 1193.3900s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482223\n",
      "\tspeed: 0.0322s/iter; left time: 643.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0498223 Vali Loss: 0.0620379 Test Loss: 0.0702392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494305\n",
      "\tspeed: 0.0583s/iter; left time: 1156.3769s\n",
      "\titers: 200, epoch: 12 | loss: 0.0481998\n",
      "\tspeed: 0.0327s/iter; left time: 645.6910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0483653 Vali Loss: 0.0612045 Test Loss: 0.0701841\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0462038\n",
      "\tspeed: 0.0580s/iter; left time: 1136.6627s\n",
      "\titers: 200, epoch: 13 | loss: 0.0461890\n",
      "\tspeed: 0.0321s/iter; left time: 626.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0470476 Vali Loss: 0.0618377 Test Loss: 0.0701277\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0474969\n",
      "\tspeed: 0.0581s/iter; left time: 1125.8177s\n",
      "\titers: 200, epoch: 14 | loss: 0.0462358\n",
      "\tspeed: 0.0323s/iter; left time: 622.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0460021 Vali Loss: 0.0619138 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0441642\n",
      "\tspeed: 0.0589s/iter; left time: 1128.4667s\n",
      "\titers: 200, epoch: 15 | loss: 0.0437523\n",
      "\tspeed: 0.0321s/iter; left time: 611.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0449358 Vali Loss: 0.0615214 Test Loss: 0.0704811\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0440189\n",
      "\tspeed: 0.0582s/iter; left time: 1101.4306s\n",
      "\titers: 200, epoch: 16 | loss: 0.0432764\n",
      "\tspeed: 0.0322s/iter; left time: 607.3002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0439870 Vali Loss: 0.0616211 Test Loss: 0.0707664\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0423084\n",
      "\tspeed: 0.0582s/iter; left time: 1090.1792s\n",
      "\titers: 200, epoch: 17 | loss: 0.0415025\n",
      "\tspeed: 0.0323s/iter; left time: 601.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0431494 Vali Loss: 0.0620262 Test Loss: 0.0715410\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01133799646049738, rmse:0.10648002475500107, mae:0.06751272827386856, rse:0.3133578300476074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1059176\n",
      "\tspeed: 0.0344s/iter; left time: 766.7583s\n",
      "\titers: 200, epoch: 1 | loss: 0.0954594\n",
      "\tspeed: 0.0326s/iter; left time: 722.8007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.1132807 Vali Loss: 0.0858611 Test Loss: 0.0978220\n",
      "Validation loss decreased (inf --> 0.085861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0672946\n",
      "\tspeed: 0.0650s/iter; left time: 1435.0460s\n",
      "\titers: 200, epoch: 2 | loss: 0.0662497\n",
      "\tspeed: 0.0323s/iter; left time: 709.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0716624 Vali Loss: 0.0645302 Test Loss: 0.0728868\n",
      "Validation loss decreased (0.085861 --> 0.064530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636461\n",
      "\tspeed: 0.0631s/iter; left time: 1379.3753s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644167\n",
      "\tspeed: 0.0320s/iter; left time: 697.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0639991 Vali Loss: 0.0630432 Test Loss: 0.0709006\n",
      "Validation loss decreased (0.064530 --> 0.063043).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0621769\n",
      "\tspeed: 0.0615s/iter; left time: 1330.3933s\n",
      "\titers: 200, epoch: 4 | loss: 0.0600844\n",
      "\tspeed: 0.0322s/iter; left time: 693.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0615069 Vali Loss: 0.0610647 Test Loss: 0.0695123\n",
      "Validation loss decreased (0.063043 --> 0.061065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0606961\n",
      "\tspeed: 0.0618s/iter; left time: 1322.3372s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597096\n",
      "\tspeed: 0.0320s/iter; left time: 682.2039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0594661 Vali Loss: 0.0604619 Test Loss: 0.0694347\n",
      "Validation loss decreased (0.061065 --> 0.060462).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0590119\n",
      "\tspeed: 0.0600s/iter; left time: 1271.2708s\n",
      "\titers: 200, epoch: 6 | loss: 0.0569254\n",
      "\tspeed: 0.0320s/iter; left time: 674.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0579130 Vali Loss: 0.0610369 Test Loss: 0.0684163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0548901\n",
      "\tspeed: 0.0585s/iter; left time: 1226.6705s\n",
      "\titers: 200, epoch: 7 | loss: 0.0539524\n",
      "\tspeed: 0.0321s/iter; left time: 668.6249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0559329 Vali Loss: 0.0594218 Test Loss: 0.0678336\n",
      "Validation loss decreased (0.060462 --> 0.059422).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0538018\n",
      "\tspeed: 0.0622s/iter; left time: 1288.9799s\n",
      "\titers: 200, epoch: 8 | loss: 0.0530818\n",
      "\tspeed: 0.0327s/iter; left time: 675.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0542583 Vali Loss: 0.0599612 Test Loss: 0.0689581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552536\n",
      "\tspeed: 0.0589s/iter; left time: 1207.6644s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516640\n",
      "\tspeed: 0.0324s/iter; left time: 662.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0527426 Vali Loss: 0.0591997 Test Loss: 0.0679362\n",
      "Validation loss decreased (0.059422 --> 0.059200).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536080\n",
      "\tspeed: 0.0609s/iter; left time: 1235.1285s\n",
      "\titers: 200, epoch: 10 | loss: 0.0499571\n",
      "\tspeed: 0.0322s/iter; left time: 649.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0512842 Vali Loss: 0.0599653 Test Loss: 0.0687808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517187\n",
      "\tspeed: 0.0595s/iter; left time: 1194.0080s\n",
      "\titers: 200, epoch: 11 | loss: 0.0499973\n",
      "\tspeed: 0.0321s/iter; left time: 640.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0497935 Vali Loss: 0.0604572 Test Loss: 0.0696274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0468627\n",
      "\tspeed: 0.0593s/iter; left time: 1176.0288s\n",
      "\titers: 200, epoch: 12 | loss: 0.0489540\n",
      "\tspeed: 0.0325s/iter; left time: 641.9414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0483913 Vali Loss: 0.0602030 Test Loss: 0.0697745\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0496078\n",
      "\tspeed: 0.0592s/iter; left time: 1161.9942s\n",
      "\titers: 200, epoch: 13 | loss: 0.0476634\n",
      "\tspeed: 0.0324s/iter; left time: 632.8809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0473625 Vali Loss: 0.0604081 Test Loss: 0.0700828\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0464205\n",
      "\tspeed: 0.0592s/iter; left time: 1147.5243s\n",
      "\titers: 200, epoch: 14 | loss: 0.0435993\n",
      "\tspeed: 0.0323s/iter; left time: 623.3370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0461338 Vali Loss: 0.0605141 Test Loss: 0.0701649\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0460268\n",
      "\tspeed: 0.0616s/iter; left time: 1180.3255s\n",
      "\titers: 200, epoch: 15 | loss: 0.0453027\n",
      "\tspeed: 0.0329s/iter; left time: 627.0169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0451875 Vali Loss: 0.0609419 Test Loss: 0.0697475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0459039\n",
      "\tspeed: 0.0612s/iter; left time: 1159.3341s\n",
      "\titers: 200, epoch: 16 | loss: 0.0434766\n",
      "\tspeed: 0.0322s/iter; left time: 605.7834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0443061 Vali Loss: 0.0615374 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0443573\n",
      "\tspeed: 0.0596s/iter; left time: 1114.8255s\n",
      "\titers: 200, epoch: 17 | loss: 0.0425250\n",
      "\tspeed: 0.0321s/iter; left time: 598.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0435606 Vali Loss: 0.0604851 Test Loss: 0.0707585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0413324\n",
      "\tspeed: 0.0595s/iter; left time: 1100.8525s\n",
      "\titers: 200, epoch: 18 | loss: 0.0445203\n",
      "\tspeed: 0.0322s/iter; left time: 591.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0428060 Vali Loss: 0.0611732 Test Loss: 0.0707645\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0436631\n",
      "\tspeed: 0.0591s/iter; left time: 1080.1691s\n",
      "\titers: 200, epoch: 19 | loss: 0.0429139\n",
      "\tspeed: 0.0322s/iter; left time: 584.5549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0421968 Vali Loss: 0.0612346 Test Loss: 0.0706914\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011598608456552029, rmse:0.10769683867692947, mae:0.06793618202209473, rse:0.31693875789642334\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:44.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1167209\n",
      "\tspeed: 0.0575s/iter; left time: 1282.5565s\n",
      "\titers: 200, epoch: 1 | loss: 0.1056875\n",
      "\tspeed: 0.0337s/iter; left time: 747.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1227398 Vali Loss: 0.0988195 Test Loss: 0.1124716\n",
      "Validation loss decreased (inf --> 0.098819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888136\n",
      "\tspeed: 0.0705s/iter; left time: 1555.6215s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841860\n",
      "\tspeed: 0.0332s/iter; left time: 729.7375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0888445 Vali Loss: 0.0866662 Test Loss: 0.0969930\n",
      "Validation loss decreased (0.098819 --> 0.086666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0807913\n",
      "\tspeed: 0.0705s/iter; left time: 1541.6938s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785247\n",
      "\tspeed: 0.0334s/iter; left time: 726.6489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0809936 Vali Loss: 0.0850435 Test Loss: 0.0962780\n",
      "Validation loss decreased (0.086666 --> 0.085044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0752124\n",
      "\tspeed: 0.0654s/iter; left time: 1415.3897s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712232\n",
      "\tspeed: 0.0331s/iter; left time: 711.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0751077 Vali Loss: 0.0873182 Test Loss: 0.0995040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689497\n",
      "\tspeed: 0.0620s/iter; left time: 1326.5338s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683093\n",
      "\tspeed: 0.0338s/iter; left time: 719.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 224 | Train Loss: 0.0684474 Vali Loss: 0.0864051 Test Loss: 0.1003118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0626845\n",
      "\tspeed: 0.0618s/iter; left time: 1309.1709s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603980\n",
      "\tspeed: 0.0334s/iter; left time: 705.0497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0631113 Vali Loss: 0.0877236 Test Loss: 0.1011920\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590933\n",
      "\tspeed: 0.0625s/iter; left time: 1308.7874s\n",
      "\titers: 200, epoch: 7 | loss: 0.0597084\n",
      "\tspeed: 0.0343s/iter; left time: 715.6098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0589081 Vali Loss: 0.0872310 Test Loss: 0.1004953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0552450\n",
      "\tspeed: 0.0615s/iter; left time: 1275.5372s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551953\n",
      "\tspeed: 0.0330s/iter; left time: 681.7645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0555059 Vali Loss: 0.0881087 Test Loss: 0.1008888\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0524991\n",
      "\tspeed: 0.0613s/iter; left time: 1258.2121s\n",
      "\titers: 200, epoch: 9 | loss: 0.0530768\n",
      "\tspeed: 0.0335s/iter; left time: 684.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0527471 Vali Loss: 0.0886423 Test Loss: 0.1020612\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0515361\n",
      "\tspeed: 0.0615s/iter; left time: 1248.5369s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495522\n",
      "\tspeed: 0.0333s/iter; left time: 672.2791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0506641 Vali Loss: 0.0878667 Test Loss: 0.1018857\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0495449\n",
      "\tspeed: 0.0623s/iter; left time: 1250.3964s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484085\n",
      "\tspeed: 0.0335s/iter; left time: 669.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0487303 Vali Loss: 0.0874963 Test Loss: 0.1018826\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0460823\n",
      "\tspeed: 0.0617s/iter; left time: 1223.9532s\n",
      "\titers: 200, epoch: 12 | loss: 0.0487627\n",
      "\tspeed: 0.0336s/iter; left time: 663.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0472277 Vali Loss: 0.0875905 Test Loss: 0.1023017\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0471489\n",
      "\tspeed: 0.0633s/iter; left time: 1242.2478s\n",
      "\titers: 200, epoch: 13 | loss: 0.0454935\n",
      "\tspeed: 0.0338s/iter; left time: 658.8136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0459133 Vali Loss: 0.0874007 Test Loss: 0.1019594\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021271303296089172, rmse:0.14584684371948242, mae:0.09627804905176163, rse:0.4284541606903076\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1204117\n",
      "\tspeed: 0.0358s/iter; left time: 798.9261s\n",
      "\titers: 200, epoch: 1 | loss: 0.1046546\n",
      "\tspeed: 0.0334s/iter; left time: 741.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.1222082 Vali Loss: 0.0986339 Test Loss: 0.1127096\n",
      "Validation loss decreased (inf --> 0.098634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892475\n",
      "\tspeed: 0.0657s/iter; left time: 1450.8334s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875973\n",
      "\tspeed: 0.0336s/iter; left time: 737.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0889160 Vali Loss: 0.0860521 Test Loss: 0.0965959\n",
      "Validation loss decreased (0.098634 --> 0.086052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820314\n",
      "\tspeed: 0.0665s/iter; left time: 1452.5428s\n",
      "\titers: 200, epoch: 3 | loss: 0.0766245\n",
      "\tspeed: 0.0333s/iter; left time: 724.2658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0810734 Vali Loss: 0.0846253 Test Loss: 0.0976963\n",
      "Validation loss decreased (0.086052 --> 0.084625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731675\n",
      "\tspeed: 0.0650s/iter; left time: 1405.0739s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741658\n",
      "\tspeed: 0.0334s/iter; left time: 718.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0754243 Vali Loss: 0.0878123 Test Loss: 0.1005267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0716164\n",
      "\tspeed: 0.0627s/iter; left time: 1342.0038s\n",
      "\titers: 200, epoch: 5 | loss: 0.0671426\n",
      "\tspeed: 0.0338s/iter; left time: 719.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0690027 Vali Loss: 0.0878285 Test Loss: 0.1006422\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641997\n",
      "\tspeed: 0.0646s/iter; left time: 1367.6287s\n",
      "\titers: 200, epoch: 6 | loss: 0.0674796\n",
      "\tspeed: 0.0337s/iter; left time: 710.7980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0635019 Vali Loss: 0.0878592 Test Loss: 0.1024417\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0591606\n",
      "\tspeed: 0.0641s/iter; left time: 1344.1498s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583029\n",
      "\tspeed: 0.0334s/iter; left time: 697.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0588996 Vali Loss: 0.0877868 Test Loss: 0.1020480\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0553827\n",
      "\tspeed: 0.0635s/iter; left time: 1316.4154s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554482\n",
      "\tspeed: 0.0342s/iter; left time: 705.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0554791 Vali Loss: 0.0881074 Test Loss: 0.1035934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0541625\n",
      "\tspeed: 0.0631s/iter; left time: 1294.9886s\n",
      "\titers: 200, epoch: 9 | loss: 0.0502246\n",
      "\tspeed: 0.0337s/iter; left time: 687.3242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0527017 Vali Loss: 0.0881722 Test Loss: 0.1024241\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0498284\n",
      "\tspeed: 0.0627s/iter; left time: 1270.8746s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489367\n",
      "\tspeed: 0.0336s/iter; left time: 678.9365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 224 | Train Loss: 0.0506088 Vali Loss: 0.0888529 Test Loss: 0.1031139\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0476753\n",
      "\tspeed: 0.0635s/iter; left time: 1273.9747s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481353\n",
      "\tspeed: 0.0333s/iter; left time: 665.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0486823 Vali Loss: 0.0881064 Test Loss: 0.1029631\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0461587\n",
      "\tspeed: 0.0642s/iter; left time: 1272.9597s\n",
      "\titers: 200, epoch: 12 | loss: 0.0474565\n",
      "\tspeed: 0.0335s/iter; left time: 661.5125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0471709 Vali Loss: 0.0887941 Test Loss: 0.1031620\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465209\n",
      "\tspeed: 0.0635s/iter; left time: 1245.9409s\n",
      "\titers: 200, epoch: 13 | loss: 0.0457823\n",
      "\tspeed: 0.0337s/iter; left time: 657.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0457775 Vali Loss: 0.0880506 Test Loss: 0.1036356\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021871840581297874, rmse:0.1478913128376007, mae:0.09769626706838608, rse:0.4344601631164551\n",
      "Intermediate time for ES and pred_len 96: 00h:04m:25.68s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163252\n",
      "\tspeed: 0.0581s/iter; left time: 1290.1549s\n",
      "\titers: 200, epoch: 1 | loss: 0.1111509\n",
      "\tspeed: 0.0341s/iter; left time: 754.0277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1248032 Vali Loss: 0.1023557 Test Loss: 0.1157608\n",
      "Validation loss decreased (inf --> 0.102356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0920324\n",
      "\tspeed: 0.0796s/iter; left time: 1748.3776s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905396\n",
      "\tspeed: 0.0341s/iter; left time: 745.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 223 | Train Loss: 0.0927347 Vali Loss: 0.0911596 Test Loss: 0.1026373\n",
      "Validation loss decreased (0.102356 --> 0.091160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0813993\n",
      "\tspeed: 0.0668s/iter; left time: 1454.1653s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804934\n",
      "\tspeed: 0.0344s/iter; left time: 745.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0837477 Vali Loss: 0.0901361 Test Loss: 0.1034494\n",
      "Validation loss decreased (0.091160 --> 0.090136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0745005\n",
      "\tspeed: 0.0733s/iter; left time: 1577.2343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0743757\n",
      "\tspeed: 0.0343s/iter; left time: 735.7188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0773343 Vali Loss: 0.0920163 Test Loss: 0.1045371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0717543\n",
      "\tspeed: 0.0647s/iter; left time: 1377.6613s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683926\n",
      "\tspeed: 0.0343s/iter; left time: 728.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0706961 Vali Loss: 0.0927095 Test Loss: 0.1056051\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0635267\n",
      "\tspeed: 0.0641s/iter; left time: 1352.1299s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626201\n",
      "\tspeed: 0.0338s/iter; left time: 710.1386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 223 | Train Loss: 0.0648583 Vali Loss: 0.0928507 Test Loss: 0.1066073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0594731\n",
      "\tspeed: 0.0642s/iter; left time: 1339.7372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0574201\n",
      "\tspeed: 0.0343s/iter; left time: 712.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0604445 Vali Loss: 0.0937179 Test Loss: 0.1071184\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0578186\n",
      "\tspeed: 0.0639s/iter; left time: 1319.0169s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562383\n",
      "\tspeed: 0.0342s/iter; left time: 702.3669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0571987 Vali Loss: 0.0920181 Test Loss: 0.1071269\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552342\n",
      "\tspeed: 0.0663s/iter; left time: 1352.9714s\n",
      "\titers: 200, epoch: 9 | loss: 0.0548123\n",
      "\tspeed: 0.0342s/iter; left time: 694.4682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0545950 Vali Loss: 0.0930666 Test Loss: 0.1075234\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0529762\n",
      "\tspeed: 0.0646s/iter; left time: 1303.6571s\n",
      "\titers: 200, epoch: 10 | loss: 0.0518859\n",
      "\tspeed: 0.0340s/iter; left time: 684.1808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 223 | Train Loss: 0.0524777 Vali Loss: 0.0920488 Test Loss: 0.1072294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0511605\n",
      "\tspeed: 0.0643s/iter; left time: 1283.3830s\n",
      "\titers: 200, epoch: 11 | loss: 0.0511627\n",
      "\tspeed: 0.0342s/iter; left time: 678.9603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 223 | Train Loss: 0.0506818 Vali Loss: 0.0927317 Test Loss: 0.1083499\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0496722\n",
      "\tspeed: 0.0636s/iter; left time: 1256.5535s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484021\n",
      "\tspeed: 0.0342s/iter; left time: 672.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 223 | Train Loss: 0.0491604 Vali Loss: 0.0922555 Test Loss: 0.1075642\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0480842\n",
      "\tspeed: 0.0637s/iter; left time: 1243.6095s\n",
      "\titers: 200, epoch: 13 | loss: 0.0480131\n",
      "\tspeed: 0.0340s/iter; left time: 659.7875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0478748 Vali Loss: 0.0920726 Test Loss: 0.1082650\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0238569937646389, rmse:0.15445709228515625, mae:0.10344940423965454, rse:0.45378103852272034\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1175357\n",
      "\tspeed: 0.0366s/iter; left time: 812.7469s\n",
      "\titers: 200, epoch: 1 | loss: 0.1085309\n",
      "\tspeed: 0.0348s/iter; left time: 768.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.1244877 Vali Loss: 0.1024658 Test Loss: 0.1162681\n",
      "Validation loss decreased (inf --> 0.102466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892978\n",
      "\tspeed: 0.0710s/iter; left time: 1559.3727s\n",
      "\titers: 200, epoch: 2 | loss: 0.0858404\n",
      "\tspeed: 0.0338s/iter; left time: 739.1676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0925368 Vali Loss: 0.0931649 Test Loss: 0.1041178\n",
      "Validation loss decreased (0.102466 --> 0.093165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0832203\n",
      "\tspeed: 0.0715s/iter; left time: 1555.9789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824200\n",
      "\tspeed: 0.0342s/iter; left time: 740.3014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0840002 Vali Loss: 0.0918773 Test Loss: 0.1027539\n",
      "Validation loss decreased (0.093165 --> 0.091877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755718\n",
      "\tspeed: 0.0702s/iter; left time: 1511.5730s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789680\n",
      "\tspeed: 0.0343s/iter; left time: 734.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0778846 Vali Loss: 0.0915824 Test Loss: 0.1033742\n",
      "Validation loss decreased (0.091877 --> 0.091582).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740893\n",
      "\tspeed: 0.0685s/iter; left time: 1460.2654s\n",
      "\titers: 200, epoch: 5 | loss: 0.0704942\n",
      "\tspeed: 0.0340s/iter; left time: 721.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0719597 Vali Loss: 0.0934459 Test Loss: 0.1050283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0674252\n",
      "\tspeed: 0.0654s/iter; left time: 1378.6719s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634718\n",
      "\tspeed: 0.0340s/iter; left time: 712.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0659032 Vali Loss: 0.0927102 Test Loss: 0.1051720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0629653\n",
      "\tspeed: 0.0657s/iter; left time: 1371.1388s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605651\n",
      "\tspeed: 0.0342s/iter; left time: 709.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0613759 Vali Loss: 0.0924244 Test Loss: 0.1051302\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563948\n",
      "\tspeed: 0.0668s/iter; left time: 1379.2055s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562144\n",
      "\tspeed: 0.0339s/iter; left time: 696.2432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 223 | Train Loss: 0.0577199 Vali Loss: 0.0931844 Test Loss: 0.1064090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559244\n",
      "\tspeed: 0.0656s/iter; left time: 1339.6380s\n",
      "\titers: 200, epoch: 9 | loss: 0.0532067\n",
      "\tspeed: 0.0341s/iter; left time: 691.9724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0549016 Vali Loss: 0.0936035 Test Loss: 0.1066466\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514232\n",
      "\tspeed: 0.0648s/iter; left time: 1309.3887s\n",
      "\titers: 200, epoch: 10 | loss: 0.0512180\n",
      "\tspeed: 0.0341s/iter; left time: 686.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0526190 Vali Loss: 0.0929514 Test Loss: 0.1060959\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0514014\n",
      "\tspeed: 0.0655s/iter; left time: 1307.3120s\n",
      "\titers: 200, epoch: 11 | loss: 0.0494085\n",
      "\tspeed: 0.0343s/iter; left time: 682.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0508202 Vali Loss: 0.0938980 Test Loss: 0.1071277\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0495044\n",
      "\tspeed: 0.0658s/iter; left time: 1299.7733s\n",
      "\titers: 200, epoch: 12 | loss: 0.0483764\n",
      "\tspeed: 0.0352s/iter; left time: 690.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0491536 Vali Loss: 0.0933724 Test Loss: 0.1070942\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0487324\n",
      "\tspeed: 0.0668s/iter; left time: 1304.0319s\n",
      "\titers: 200, epoch: 13 | loss: 0.0466656\n",
      "\tspeed: 0.0350s/iter; left time: 680.1999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0478594 Vali Loss: 0.0935658 Test Loss: 0.1077204\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0470098\n",
      "\tspeed: 0.0657s/iter; left time: 1267.9379s\n",
      "\titers: 200, epoch: 14 | loss: 0.0454411\n",
      "\tspeed: 0.0341s/iter; left time: 654.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0467149 Vali Loss: 0.0932253 Test Loss: 0.1074122\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023433756083250046, rmse:0.15308088064193726, mae:0.10337422043085098, rse:0.44973787665367126\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:45.14s\n",
      "Intermediate time for ES: 00h:14m:55.41s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0776064\n",
      "\tspeed: 0.0587s/iter; left time: 1309.0773s\n",
      "\titers: 200, epoch: 1 | loss: 0.0689711\n",
      "\tspeed: 0.0323s/iter; left time: 716.3089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0842278 Vali Loss: 0.0746167 Test Loss: 0.0815443\n",
      "Validation loss decreased (inf --> 0.074617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0531533\n",
      "\tspeed: 0.0614s/iter; left time: 1354.6684s\n",
      "\titers: 200, epoch: 2 | loss: 0.0528795\n",
      "\tspeed: 0.0324s/iter; left time: 711.4069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0527035 Vali Loss: 0.0587939 Test Loss: 0.0632445\n",
      "Validation loss decreased (0.074617 --> 0.058794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0471682\n",
      "\tspeed: 0.0660s/iter; left time: 1441.7854s\n",
      "\titers: 200, epoch: 3 | loss: 0.0457505\n",
      "\tspeed: 0.0327s/iter; left time: 712.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0473227 Vali Loss: 0.0575117 Test Loss: 0.0627745\n",
      "Validation loss decreased (0.058794 --> 0.057512).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0463470\n",
      "\tspeed: 0.0664s/iter; left time: 1435.6515s\n",
      "\titers: 200, epoch: 4 | loss: 0.0481664\n",
      "\tspeed: 0.0332s/iter; left time: 714.0555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0455139 Vali Loss: 0.0574781 Test Loss: 0.0624749\n",
      "Validation loss decreased (0.057512 --> 0.057478).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0467309\n",
      "\tspeed: 0.0657s/iter; left time: 1406.4669s\n",
      "\titers: 200, epoch: 5 | loss: 0.0446282\n",
      "\tspeed: 0.0326s/iter; left time: 694.6811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0437584 Vali Loss: 0.0551695 Test Loss: 0.0619991\n",
      "Validation loss decreased (0.057478 --> 0.055170).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0407794\n",
      "\tspeed: 0.0623s/iter; left time: 1318.7658s\n",
      "\titers: 200, epoch: 6 | loss: 0.0384185\n",
      "\tspeed: 0.0331s/iter; left time: 697.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0419962 Vali Loss: 0.0557887 Test Loss: 0.0628854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0402396\n",
      "\tspeed: 0.0595s/iter; left time: 1247.8860s\n",
      "\titers: 200, epoch: 7 | loss: 0.0402509\n",
      "\tspeed: 0.0325s/iter; left time: 676.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0402307 Vali Loss: 0.0556562 Test Loss: 0.0631281\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0379331\n",
      "\tspeed: 0.0613s/iter; left time: 1270.0383s\n",
      "\titers: 200, epoch: 8 | loss: 0.0385543\n",
      "\tspeed: 0.0325s/iter; left time: 671.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0386213 Vali Loss: 0.0560320 Test Loss: 0.0646798\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0364931\n",
      "\tspeed: 0.0598s/iter; left time: 1226.0757s\n",
      "\titers: 200, epoch: 9 | loss: 0.0386902\n",
      "\tspeed: 0.0324s/iter; left time: 661.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0371513 Vali Loss: 0.0557153 Test Loss: 0.0647850\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0368047\n",
      "\tspeed: 0.0609s/iter; left time: 1234.9129s\n",
      "\titers: 200, epoch: 10 | loss: 0.0341395\n",
      "\tspeed: 0.0327s/iter; left time: 661.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0357683 Vali Loss: 0.0568122 Test Loss: 0.0655629\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0343697\n",
      "\tspeed: 0.0615s/iter; left time: 1233.2480s\n",
      "\titers: 200, epoch: 11 | loss: 0.0357826\n",
      "\tspeed: 0.0324s/iter; left time: 646.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0344320 Vali Loss: 0.0567076 Test Loss: 0.0657521\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0327125\n",
      "\tspeed: 0.0596s/iter; left time: 1182.0525s\n",
      "\titers: 200, epoch: 12 | loss: 0.0331983\n",
      "\tspeed: 0.0325s/iter; left time: 640.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0332904 Vali Loss: 0.0569363 Test Loss: 0.0662714\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0341434\n",
      "\tspeed: 0.0609s/iter; left time: 1193.9434s\n",
      "\titers: 200, epoch: 13 | loss: 0.0316493\n",
      "\tspeed: 0.0325s/iter; left time: 635.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0322657 Vali Loss: 0.0569743 Test Loss: 0.0673161\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0335650\n",
      "\tspeed: 0.0616s/iter; left time: 1194.7385s\n",
      "\titers: 200, epoch: 14 | loss: 0.0316226\n",
      "\tspeed: 0.0325s/iter; left time: 626.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0313672 Vali Loss: 0.0569273 Test Loss: 0.0670634\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0285776\n",
      "\tspeed: 0.0607s/iter; left time: 1162.9691s\n",
      "\titers: 200, epoch: 15 | loss: 0.0301777\n",
      "\tspeed: 0.0325s/iter; left time: 618.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0306123 Vali Loss: 0.0578428 Test Loss: 0.0671806\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011569960042834282, rmse:0.10756374895572662, mae:0.06199907511472702, rse:0.4149779677391052\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0765755\n",
      "\tspeed: 0.0347s/iter; left time: 773.8502s\n",
      "\titers: 200, epoch: 1 | loss: 0.0715873\n",
      "\tspeed: 0.0323s/iter; left time: 716.8266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0848132 Vali Loss: 0.0750400 Test Loss: 0.0822929\n",
      "Validation loss decreased (inf --> 0.075040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0532299\n",
      "\tspeed: 0.0637s/iter; left time: 1405.6653s\n",
      "\titers: 200, epoch: 2 | loss: 0.0497959\n",
      "\tspeed: 0.0327s/iter; left time: 719.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0526962 Vali Loss: 0.0586718 Test Loss: 0.0637208\n",
      "Validation loss decreased (0.075040 --> 0.058672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0449452\n",
      "\tspeed: 0.0619s/iter; left time: 1352.4978s\n",
      "\titers: 200, epoch: 3 | loss: 0.0478727\n",
      "\tspeed: 0.0326s/iter; left time: 708.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0474259 Vali Loss: 0.0574775 Test Loss: 0.0623785\n",
      "Validation loss decreased (0.058672 --> 0.057478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0479655\n",
      "\tspeed: 0.0632s/iter; left time: 1366.7544s\n",
      "\titers: 200, epoch: 4 | loss: 0.0423369\n",
      "\tspeed: 0.0328s/iter; left time: 706.3410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0456964 Vali Loss: 0.0566878 Test Loss: 0.0617239\n",
      "Validation loss decreased (0.057478 --> 0.056688).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0443972\n",
      "\tspeed: 0.0628s/iter; left time: 1344.7824s\n",
      "\titers: 200, epoch: 5 | loss: 0.0437183\n",
      "\tspeed: 0.0326s/iter; left time: 694.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0440220 Vali Loss: 0.0561451 Test Loss: 0.0622689\n",
      "Validation loss decreased (0.056688 --> 0.056145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0417378\n",
      "\tspeed: 0.0650s/iter; left time: 1376.4881s\n",
      "\titers: 200, epoch: 6 | loss: 0.0425886\n",
      "\tspeed: 0.0330s/iter; left time: 695.7715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0423362 Vali Loss: 0.0566242 Test Loss: 0.0636812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0408028\n",
      "\tspeed: 0.0630s/iter; left time: 1319.6563s\n",
      "\titers: 200, epoch: 7 | loss: 0.0407621\n",
      "\tspeed: 0.0327s/iter; left time: 682.4362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0406709 Vali Loss: 0.0558169 Test Loss: 0.0628909\n",
      "Validation loss decreased (0.056145 --> 0.055817).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0415118\n",
      "\tspeed: 0.0623s/iter; left time: 1291.6641s\n",
      "\titers: 200, epoch: 8 | loss: 0.0397285\n",
      "\tspeed: 0.0323s/iter; left time: 667.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0390934 Vali Loss: 0.0559703 Test Loss: 0.0631211\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0359722\n",
      "\tspeed: 0.0603s/iter; left time: 1237.2548s\n",
      "\titers: 200, epoch: 9 | loss: 0.0355636\n",
      "\tspeed: 0.0324s/iter; left time: 661.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0375667 Vali Loss: 0.0563328 Test Loss: 0.0643593\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0364585\n",
      "\tspeed: 0.0623s/iter; left time: 1262.7730s\n",
      "\titers: 200, epoch: 10 | loss: 0.0347073\n",
      "\tspeed: 0.0330s/iter; left time: 665.5518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0361043 Vali Loss: 0.0561320 Test Loss: 0.0643679\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0359929\n",
      "\tspeed: 0.0612s/iter; left time: 1228.5221s\n",
      "\titers: 200, epoch: 11 | loss: 0.0343686\n",
      "\tspeed: 0.0323s/iter; left time: 644.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0348943 Vali Loss: 0.0568348 Test Loss: 0.0645087\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0346736\n",
      "\tspeed: 0.0605s/iter; left time: 1200.1561s\n",
      "\titers: 200, epoch: 12 | loss: 0.0335486\n",
      "\tspeed: 0.0327s/iter; left time: 646.1497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0338053 Vali Loss: 0.0570722 Test Loss: 0.0656173\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0334411\n",
      "\tspeed: 0.0618s/iter; left time: 1212.0180s\n",
      "\titers: 200, epoch: 13 | loss: 0.0322468\n",
      "\tspeed: 0.0328s/iter; left time: 639.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0328119 Vali Loss: 0.0568148 Test Loss: 0.0648483\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0326624\n",
      "\tspeed: 0.0606s/iter; left time: 1175.6832s\n",
      "\titers: 200, epoch: 14 | loss: 0.0324357\n",
      "\tspeed: 0.0329s/iter; left time: 635.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0318300 Vali Loss: 0.0576550 Test Loss: 0.0659730\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0302384\n",
      "\tspeed: 0.0606s/iter; left time: 1160.5533s\n",
      "\titers: 200, epoch: 15 | loss: 0.0335285\n",
      "\tspeed: 0.0324s/iter; left time: 618.0723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0310831 Vali Loss: 0.0576739 Test Loss: 0.0659032\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0316819\n",
      "\tspeed: 0.0602s/iter; left time: 1140.3543s\n",
      "\titers: 200, epoch: 16 | loss: 0.0300952\n",
      "\tspeed: 0.0323s/iter; left time: 608.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0304891 Vali Loss: 0.0578517 Test Loss: 0.0663014\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0300540\n",
      "\tspeed: 0.0626s/iter; left time: 1172.3508s\n",
      "\titers: 200, epoch: 17 | loss: 0.0303118\n",
      "\tspeed: 0.0323s/iter; left time: 601.8689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0299137 Vali Loss: 0.0575964 Test Loss: 0.0659298\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012248861603438854, rmse:0.11067457497119904, mae:0.0628909021615982, rse:0.4269794225692749\n",
      "Intermediate time for FR and pred_len 24: 00h:05m:14.86s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0862475\n",
      "\tspeed: 0.0585s/iter; left time: 1305.5679s\n",
      "\titers: 200, epoch: 1 | loss: 0.0789353\n",
      "\tspeed: 0.0334s/iter; left time: 741.2368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0918407 Vali Loss: 0.0848530 Test Loss: 0.0949307\n",
      "Validation loss decreased (inf --> 0.084853).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0645173\n",
      "\tspeed: 0.0730s/iter; left time: 1611.9318s\n",
      "\titers: 200, epoch: 2 | loss: 0.0630785\n",
      "\tspeed: 0.0332s/iter; left time: 729.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0665209 Vali Loss: 0.0769489 Test Loss: 0.0858871\n",
      "Validation loss decreased (0.084853 --> 0.076949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0585615\n",
      "\tspeed: 0.0677s/iter; left time: 1480.2264s\n",
      "\titers: 200, epoch: 3 | loss: 0.0544285\n",
      "\tspeed: 0.0334s/iter; left time: 725.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0585479 Vali Loss: 0.0776967 Test Loss: 0.0911700\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0547643\n",
      "\tspeed: 0.0635s/iter; left time: 1374.2713s\n",
      "\titers: 200, epoch: 4 | loss: 0.0521349\n",
      "\tspeed: 0.0333s/iter; left time: 717.6269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 224 | Train Loss: 0.0523000 Vali Loss: 0.0776609 Test Loss: 0.0917702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0467123\n",
      "\tspeed: 0.0641s/iter; left time: 1372.1629s\n",
      "\titers: 200, epoch: 5 | loss: 0.0436993\n",
      "\tspeed: 0.0333s/iter; left time: 710.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 224 | Train Loss: 0.0471033 Vali Loss: 0.0789060 Test Loss: 0.0933320\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0454650\n",
      "\tspeed: 0.0631s/iter; left time: 1336.3567s\n",
      "\titers: 200, epoch: 6 | loss: 0.0418738\n",
      "\tspeed: 0.0342s/iter; left time: 721.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0433095 Vali Loss: 0.0802796 Test Loss: 0.0966435\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0411551\n",
      "\tspeed: 0.0650s/iter; left time: 1361.8377s\n",
      "\titers: 200, epoch: 7 | loss: 0.0411320\n",
      "\tspeed: 0.0340s/iter; left time: 709.9935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0405892 Vali Loss: 0.0795505 Test Loss: 0.0968952\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0395948\n",
      "\tspeed: 0.0634s/iter; left time: 1314.8204s\n",
      "\titers: 200, epoch: 8 | loss: 0.0366879\n",
      "\tspeed: 0.0334s/iter; left time: 688.6133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0383602 Vali Loss: 0.0795767 Test Loss: 0.0967200\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0365589\n",
      "\tspeed: 0.0642s/iter; left time: 1316.7185s\n",
      "\titers: 200, epoch: 9 | loss: 0.0354121\n",
      "\tspeed: 0.0334s/iter; left time: 681.1768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0365612 Vali Loss: 0.0798155 Test Loss: 0.0960024\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0347551\n",
      "\tspeed: 0.0645s/iter; left time: 1308.1237s\n",
      "\titers: 200, epoch: 10 | loss: 0.0357937\n",
      "\tspeed: 0.0334s/iter; left time: 675.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0351166 Vali Loss: 0.0796748 Test Loss: 0.0970269\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0328615\n",
      "\tspeed: 0.0638s/iter; left time: 1280.0189s\n",
      "\titers: 200, epoch: 11 | loss: 0.0321747\n",
      "\tspeed: 0.0334s/iter; left time: 666.0426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0338496 Vali Loss: 0.0797598 Test Loss: 0.0963629\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0320179\n",
      "\tspeed: 0.0644s/iter; left time: 1277.9659s\n",
      "\titers: 200, epoch: 12 | loss: 0.0319372\n",
      "\tspeed: 0.0336s/iter; left time: 664.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0327725 Vali Loss: 0.0793384 Test Loss: 0.0966827\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020557139068841934, rmse:0.1433776170015335, mae:0.0858871340751648, rse:0.5546227097511292\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0868272\n",
      "\tspeed: 0.0359s/iter; left time: 800.3377s\n",
      "\titers: 200, epoch: 1 | loss: 0.0793261\n",
      "\tspeed: 0.0333s/iter; left time: 740.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0914667 Vali Loss: 0.0848870 Test Loss: 0.0946935\n",
      "Validation loss decreased (inf --> 0.084887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0672989\n",
      "\tspeed: 0.0671s/iter; left time: 1480.3526s\n",
      "\titers: 200, epoch: 2 | loss: 0.0643385\n",
      "\tspeed: 0.0337s/iter; left time: 740.9082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0665327 Vali Loss: 0.0759749 Test Loss: 0.0862460\n",
      "Validation loss decreased (0.084887 --> 0.075975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0572134\n",
      "\tspeed: 0.0704s/iter; left time: 1537.4687s\n",
      "\titers: 200, epoch: 3 | loss: 0.0561207\n",
      "\tspeed: 0.0333s/iter; left time: 725.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0591155 Vali Loss: 0.0771875 Test Loss: 0.0894880\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0540748\n",
      "\tspeed: 0.0646s/iter; left time: 1398.0343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0516426\n",
      "\tspeed: 0.0333s/iter; left time: 716.7366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0531906 Vali Loss: 0.0777607 Test Loss: 0.0927518\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0487083\n",
      "\tspeed: 0.0646s/iter; left time: 1383.6796s\n",
      "\titers: 200, epoch: 5 | loss: 0.0476975\n",
      "\tspeed: 0.0334s/iter; left time: 711.2979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0481023 Vali Loss: 0.0778513 Test Loss: 0.0919247\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0438590\n",
      "\tspeed: 0.0664s/iter; left time: 1407.3779s\n",
      "\titers: 200, epoch: 6 | loss: 0.0438163\n",
      "\tspeed: 0.0340s/iter; left time: 716.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0444282 Vali Loss: 0.0778370 Test Loss: 0.0944785\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0434413\n",
      "\tspeed: 0.0637s/iter; left time: 1335.7837s\n",
      "\titers: 200, epoch: 7 | loss: 0.0407474\n",
      "\tspeed: 0.0333s/iter; left time: 693.8728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0413640 Vali Loss: 0.0781349 Test Loss: 0.0949088\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0380688\n",
      "\tspeed: 0.0650s/iter; left time: 1347.8890s\n",
      "\titers: 200, epoch: 8 | loss: 0.0378286\n",
      "\tspeed: 0.0335s/iter; left time: 690.8053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0390794 Vali Loss: 0.0777945 Test Loss: 0.0954822\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0375700\n",
      "\tspeed: 0.0648s/iter; left time: 1329.4683s\n",
      "\titers: 200, epoch: 9 | loss: 0.0364217\n",
      "\tspeed: 0.0334s/iter; left time: 680.7501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0372009 Vali Loss: 0.0778999 Test Loss: 0.0945588\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0352148\n",
      "\tspeed: 0.0638s/iter; left time: 1295.1439s\n",
      "\titers: 200, epoch: 10 | loss: 0.0341083\n",
      "\tspeed: 0.0335s/iter; left time: 677.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0356917 Vali Loss: 0.0790417 Test Loss: 0.0960830\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0338370\n",
      "\tspeed: 0.0646s/iter; left time: 1295.8137s\n",
      "\titers: 200, epoch: 11 | loss: 0.0333588\n",
      "\tspeed: 0.0339s/iter; left time: 675.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0343948 Vali Loss: 0.0780501 Test Loss: 0.0963719\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0330616\n",
      "\tspeed: 0.0653s/iter; left time: 1295.9105s\n",
      "\titers: 200, epoch: 12 | loss: 0.0332803\n",
      "\tspeed: 0.0339s/iter; left time: 669.2013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0333036 Vali Loss: 0.0783700 Test Loss: 0.0960959\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021034399047493935, rmse:0.14503240585327148, mae:0.08624604344367981, rse:0.5610238909721375\n",
      "Intermediate time for FR and pred_len 96: 00h:04m:10.55s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0884569\n",
      "\tspeed: 0.0585s/iter; left time: 1299.3233s\n",
      "\titers: 200, epoch: 1 | loss: 0.0808866\n",
      "\tspeed: 0.0337s/iter; left time: 744.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0938542 Vali Loss: 0.0877504 Test Loss: 0.0973185\n",
      "Validation loss decreased (inf --> 0.087750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0651276\n",
      "\tspeed: 0.0940s/iter; left time: 2065.7458s\n",
      "\titers: 200, epoch: 2 | loss: 0.0672713\n",
      "\tspeed: 0.0339s/iter; left time: 742.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 223 | Train Loss: 0.0701975 Vali Loss: 0.0814480 Test Loss: 0.0920999\n",
      "Validation loss decreased (0.087750 --> 0.081448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0625057\n",
      "\tspeed: 0.1012s/iter; left time: 2201.0929s\n",
      "\titers: 200, epoch: 3 | loss: 0.0557836\n",
      "\tspeed: 0.0350s/iter; left time: 758.6544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0607981 Vali Loss: 0.0819982 Test Loss: 0.0934285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0535417\n",
      "\tspeed: 0.0656s/iter; left time: 1412.4035s\n",
      "\titers: 200, epoch: 4 | loss: 0.0509764\n",
      "\tspeed: 0.0344s/iter; left time: 737.1936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0534699 Vali Loss: 0.0824004 Test Loss: 0.0964533\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0492397\n",
      "\tspeed: 0.0652s/iter; left time: 1389.0673s\n",
      "\titers: 200, epoch: 5 | loss: 0.0452260\n",
      "\tspeed: 0.0341s/iter; left time: 723.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0479584 Vali Loss: 0.0834585 Test Loss: 0.0963291\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0442968\n",
      "\tspeed: 0.0631s/iter; left time: 1330.9333s\n",
      "\titers: 200, epoch: 6 | loss: 0.0427738\n",
      "\tspeed: 0.0335s/iter; left time: 703.4274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 223 | Train Loss: 0.0441876 Vali Loss: 0.0830720 Test Loss: 0.0960464\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0400089\n",
      "\tspeed: 0.0633s/iter; left time: 1320.4161s\n",
      "\titers: 200, epoch: 7 | loss: 0.0401345\n",
      "\tspeed: 0.0334s/iter; left time: 694.4201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 223 | Train Loss: 0.0413019 Vali Loss: 0.0828756 Test Loss: 0.0959889\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0403139\n",
      "\tspeed: 0.0635s/iter; left time: 1309.8995s\n",
      "\titers: 200, epoch: 8 | loss: 0.0387559\n",
      "\tspeed: 0.0335s/iter; left time: 688.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0391119 Vali Loss: 0.0828041 Test Loss: 0.0960062\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0369264\n",
      "\tspeed: 0.0639s/iter; left time: 1304.7621s\n",
      "\titers: 200, epoch: 9 | loss: 0.0361813\n",
      "\tspeed: 0.0338s/iter; left time: 686.2694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 223 | Train Loss: 0.0373108 Vali Loss: 0.0828253 Test Loss: 0.0964746\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0361604\n",
      "\tspeed: 0.0644s/iter; left time: 1301.1673s\n",
      "\titers: 200, epoch: 10 | loss: 0.0344419\n",
      "\tspeed: 0.0337s/iter; left time: 677.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0358161 Vali Loss: 0.0833129 Test Loss: 0.0963833\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0343810\n",
      "\tspeed: 0.0637s/iter; left time: 1272.4359s\n",
      "\titers: 200, epoch: 11 | loss: 0.0339394\n",
      "\tspeed: 0.0335s/iter; left time: 666.3024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0345840 Vali Loss: 0.0826738 Test Loss: 0.0961679\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0336313\n",
      "\tspeed: 0.0637s/iter; left time: 1258.9254s\n",
      "\titers: 200, epoch: 12 | loss: 0.0324802\n",
      "\tspeed: 0.0333s/iter; left time: 655.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 223 | Train Loss: 0.0335197 Vali Loss: 0.0831679 Test Loss: 0.0963215\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02259443700313568, rmse:0.15031446516513824, mae:0.09209997206926346, rse:0.5821821093559265\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0894092\n",
      "\tspeed: 0.0361s/iter; left time: 800.5101s\n",
      "\titers: 200, epoch: 1 | loss: 0.0825871\n",
      "\tspeed: 0.0336s/iter; left time: 742.0978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 223 | Train Loss: 0.0932287 Vali Loss: 0.0877802 Test Loss: 0.0973582\n",
      "Validation loss decreased (inf --> 0.087780).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0690800\n",
      "\tspeed: 0.0697s/iter; left time: 1531.7156s\n",
      "\titers: 200, epoch: 2 | loss: 0.0640077\n",
      "\tspeed: 0.0335s/iter; left time: 733.1942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0702661 Vali Loss: 0.0803683 Test Loss: 0.0915588\n",
      "Validation loss decreased (0.087780 --> 0.080368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638850\n",
      "\tspeed: 0.0665s/iter; left time: 1446.7912s\n",
      "\titers: 200, epoch: 3 | loss: 0.0567797\n",
      "\tspeed: 0.0335s/iter; left time: 724.5556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0612572 Vali Loss: 0.0804416 Test Loss: 0.0938794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0542146\n",
      "\tspeed: 0.0632s/iter; left time: 1360.5697s\n",
      "\titers: 200, epoch: 4 | loss: 0.0533359\n",
      "\tspeed: 0.0336s/iter; left time: 720.3123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 223 | Train Loss: 0.0544359 Vali Loss: 0.0820984 Test Loss: 0.0975414\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0482048\n",
      "\tspeed: 0.0633s/iter; left time: 1349.6828s\n",
      "\titers: 200, epoch: 5 | loss: 0.0485607\n",
      "\tspeed: 0.0343s/iter; left time: 726.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0490092 Vali Loss: 0.0828655 Test Loss: 0.0976705\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0460692\n",
      "\tspeed: 0.0646s/iter; left time: 1361.7513s\n",
      "\titers: 200, epoch: 6 | loss: 0.0440988\n",
      "\tspeed: 0.0335s/iter; left time: 703.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0451625 Vali Loss: 0.0829948 Test Loss: 0.0985005\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0410739\n",
      "\tspeed: 0.0637s/iter; left time: 1329.6645s\n",
      "\titers: 200, epoch: 7 | loss: 0.0414795\n",
      "\tspeed: 0.0335s/iter; left time: 695.1018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0421384 Vali Loss: 0.0837119 Test Loss: 0.0984630\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0402316\n",
      "\tspeed: 0.0634s/iter; left time: 1307.8705s\n",
      "\titers: 200, epoch: 8 | loss: 0.0391680\n",
      "\tspeed: 0.0336s/iter; left time: 689.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0398440 Vali Loss: 0.0833129 Test Loss: 0.0983980\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0374279\n",
      "\tspeed: 0.0633s/iter; left time: 1292.6745s\n",
      "\titers: 200, epoch: 9 | loss: 0.0369868\n",
      "\tspeed: 0.0335s/iter; left time: 680.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0379773 Vali Loss: 0.0829931 Test Loss: 0.0977898\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0371010\n",
      "\tspeed: 0.0647s/iter; left time: 1306.6680s\n",
      "\titers: 200, epoch: 10 | loss: 0.0362111\n",
      "\tspeed: 0.0339s/iter; left time: 681.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 223 | Train Loss: 0.0364681 Vali Loss: 0.0829628 Test Loss: 0.0973047\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0354411\n",
      "\tspeed: 0.0638s/iter; left time: 1274.4820s\n",
      "\titers: 200, epoch: 11 | loss: 0.0354721\n",
      "\tspeed: 0.0336s/iter; left time: 667.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0351750 Vali Loss: 0.0829564 Test Loss: 0.0978901\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0346587\n",
      "\tspeed: 0.0632s/iter; left time: 1248.7402s\n",
      "\titers: 200, epoch: 12 | loss: 0.0330839\n",
      "\tspeed: 0.0335s/iter; left time: 658.2219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0340922 Vali Loss: 0.0831059 Test Loss: 0.0969260\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023193681612610817, rmse:0.15229472517967224, mae:0.09155873954296112, rse:0.5898519158363342\n",
      "Intermediate time for FR and pred_len 168: 00h:04m:15.03s\n",
      "Intermediate time for FR: 00h:13m:40.44s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1052240\n",
      "\tspeed: 0.0593s/iter; left time: 1322.3394s\n",
      "\titers: 200, epoch: 1 | loss: 0.0995200\n",
      "\tspeed: 0.0324s/iter; left time: 718.6741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.1188541 Vali Loss: 0.0861337 Test Loss: 0.0891670\n",
      "Validation loss decreased (inf --> 0.086134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0668029\n",
      "\tspeed: 0.0639s/iter; left time: 1409.7165s\n",
      "\titers: 200, epoch: 2 | loss: 0.0655162\n",
      "\tspeed: 0.0322s/iter; left time: 708.1180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0720778 Vali Loss: 0.0639649 Test Loss: 0.0668498\n",
      "Validation loss decreased (0.086134 --> 0.063965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670426\n",
      "\tspeed: 0.0627s/iter; left time: 1369.7477s\n",
      "\titers: 200, epoch: 3 | loss: 0.0649540\n",
      "\tspeed: 0.0323s/iter; left time: 703.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0645235 Vali Loss: 0.0623632 Test Loss: 0.0646318\n",
      "Validation loss decreased (0.063965 --> 0.062363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615188\n",
      "\tspeed: 0.0631s/iter; left time: 1364.2213s\n",
      "\titers: 200, epoch: 4 | loss: 0.0651470\n",
      "\tspeed: 0.0322s/iter; left time: 693.4935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0623022 Vali Loss: 0.0613726 Test Loss: 0.0651140\n",
      "Validation loss decreased (0.062363 --> 0.061373).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0610557\n",
      "\tspeed: 0.0632s/iter; left time: 1352.2947s\n",
      "\titers: 200, epoch: 5 | loss: 0.0604981\n",
      "\tspeed: 0.0324s/iter; left time: 689.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0607665 Vali Loss: 0.0618560 Test Loss: 0.0650788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569930\n",
      "\tspeed: 0.0619s/iter; left time: 1310.1207s\n",
      "\titers: 200, epoch: 6 | loss: 0.0620100\n",
      "\tspeed: 0.0326s/iter; left time: 686.9783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0583740 Vali Loss: 0.0603924 Test Loss: 0.0641359\n",
      "Validation loss decreased (0.061373 --> 0.060392).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0534668\n",
      "\tspeed: 0.0649s/iter; left time: 1359.5353s\n",
      "\titers: 200, epoch: 7 | loss: 0.0552543\n",
      "\tspeed: 0.0325s/iter; left time: 677.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0567980 Vali Loss: 0.0595051 Test Loss: 0.0627162\n",
      "Validation loss decreased (0.060392 --> 0.059505).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0539588\n",
      "\tspeed: 0.0638s/iter; left time: 1323.3991s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549810\n",
      "\tspeed: 0.0322s/iter; left time: 663.5912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0549697 Vali Loss: 0.0608740 Test Loss: 0.0637390\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0538474\n",
      "\tspeed: 0.0603s/iter; left time: 1236.8981s\n",
      "\titers: 200, epoch: 9 | loss: 0.0502654\n",
      "\tspeed: 0.0323s/iter; left time: 660.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0530986 Vali Loss: 0.0604585 Test Loss: 0.0635977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0519460\n",
      "\tspeed: 0.0612s/iter; left time: 1241.8916s\n",
      "\titers: 200, epoch: 10 | loss: 0.0463895\n",
      "\tspeed: 0.0330s/iter; left time: 665.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0514600 Vali Loss: 0.0600744 Test Loss: 0.0641934\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0518249\n",
      "\tspeed: 0.0612s/iter; left time: 1227.1669s\n",
      "\titers: 200, epoch: 11 | loss: 0.0491804\n",
      "\tspeed: 0.0323s/iter; left time: 644.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0500287 Vali Loss: 0.0611684 Test Loss: 0.0645865\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0503090\n",
      "\tspeed: 0.0597s/iter; left time: 1184.4776s\n",
      "\titers: 200, epoch: 12 | loss: 0.0513023\n",
      "\tspeed: 0.0321s/iter; left time: 633.3577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0486316 Vali Loss: 0.0609906 Test Loss: 0.0643800\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0467671\n",
      "\tspeed: 0.0608s/iter; left time: 1193.2976s\n",
      "\titers: 200, epoch: 13 | loss: 0.0463996\n",
      "\tspeed: 0.0325s/iter; left time: 633.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0472041 Vali Loss: 0.0615323 Test Loss: 0.0650614\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0485981\n",
      "\tspeed: 0.0612s/iter; left time: 1186.2148s\n",
      "\titers: 200, epoch: 14 | loss: 0.0465529\n",
      "\tspeed: 0.0323s/iter; left time: 622.9980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0459658 Vali Loss: 0.0623372 Test Loss: 0.0648194\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0431688\n",
      "\tspeed: 0.0611s/iter; left time: 1171.0140s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447366\n",
      "\tspeed: 0.0328s/iter; left time: 626.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0449380 Vali Loss: 0.0626743 Test Loss: 0.0651143\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0431246\n",
      "\tspeed: 0.0615s/iter; left time: 1165.6164s\n",
      "\titers: 200, epoch: 16 | loss: 0.0459317\n",
      "\tspeed: 0.0321s/iter; left time: 604.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0439346 Vali Loss: 0.0624681 Test Loss: 0.0658006\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0437078\n",
      "\tspeed: 0.0598s/iter; left time: 1118.7880s\n",
      "\titers: 200, epoch: 17 | loss: 0.0450082\n",
      "\tspeed: 0.0325s/iter; left time: 604.3312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0430947 Vali Loss: 0.0630289 Test Loss: 0.0656900\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011220804415643215, rmse:0.10592830181121826, mae:0.06271616369485855, rse:0.4002508819103241\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1160403\n",
      "\tspeed: 0.0343s/iter; left time: 765.5966s\n",
      "\titers: 200, epoch: 1 | loss: 0.0940983\n",
      "\tspeed: 0.0322s/iter; left time: 714.2124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.1176875 Vali Loss: 0.0858559 Test Loss: 0.0892095\n",
      "Validation loss decreased (inf --> 0.085856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0703001\n",
      "\tspeed: 0.0618s/iter; left time: 1364.3592s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682917\n",
      "\tspeed: 0.0327s/iter; left time: 718.0935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0718768 Vali Loss: 0.0640197 Test Loss: 0.0671154\n",
      "Validation loss decreased (0.085856 --> 0.064020).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675953\n",
      "\tspeed: 0.0645s/iter; left time: 1410.0610s\n",
      "\titers: 200, epoch: 3 | loss: 0.0618320\n",
      "\tspeed: 0.0321s/iter; left time: 699.1615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0647467 Vali Loss: 0.0626417 Test Loss: 0.0650419\n",
      "Validation loss decreased (0.064020 --> 0.062642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0653759\n",
      "\tspeed: 0.0627s/iter; left time: 1356.2144s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638989\n",
      "\tspeed: 0.0322s/iter; left time: 692.4842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0623659 Vali Loss: 0.0610645 Test Loss: 0.0640131\n",
      "Validation loss decreased (0.062642 --> 0.061065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0575085\n",
      "\tspeed: 0.0623s/iter; left time: 1334.1177s\n",
      "\titers: 200, epoch: 5 | loss: 0.0587094\n",
      "\tspeed: 0.0321s/iter; left time: 684.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0601151 Vali Loss: 0.0610883 Test Loss: 0.0636876\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577437\n",
      "\tspeed: 0.0599s/iter; left time: 1268.1228s\n",
      "\titers: 200, epoch: 6 | loss: 0.0556418\n",
      "\tspeed: 0.0322s/iter; left time: 678.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0580983 Vali Loss: 0.0604166 Test Loss: 0.0639995\n",
      "Validation loss decreased (0.061065 --> 0.060417).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0561289\n",
      "\tspeed: 0.0621s/iter; left time: 1302.1858s\n",
      "\titers: 200, epoch: 7 | loss: 0.0562709\n",
      "\tspeed: 0.0325s/iter; left time: 677.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0565202 Vali Loss: 0.0604680 Test Loss: 0.0635442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0581985\n",
      "\tspeed: 0.0603s/iter; left time: 1250.4228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0544954\n",
      "\tspeed: 0.0321s/iter; left time: 662.6251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0545067 Vali Loss: 0.0608139 Test Loss: 0.0642482\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0527575\n",
      "\tspeed: 0.0617s/iter; left time: 1265.7564s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503566\n",
      "\tspeed: 0.0324s/iter; left time: 660.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0529972 Vali Loss: 0.0604772 Test Loss: 0.0637462\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0521386\n",
      "\tspeed: 0.0621s/iter; left time: 1260.5590s\n",
      "\titers: 200, epoch: 10 | loss: 0.0501020\n",
      "\tspeed: 0.0323s/iter; left time: 652.5405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0513403 Vali Loss: 0.0607974 Test Loss: 0.0645847\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0499747\n",
      "\tspeed: 0.0611s/iter; left time: 1225.9885s\n",
      "\titers: 200, epoch: 11 | loss: 0.0474736\n",
      "\tspeed: 0.0321s/iter; left time: 640.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0495997 Vali Loss: 0.0612057 Test Loss: 0.0651089\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0470874\n",
      "\tspeed: 0.0611s/iter; left time: 1212.8747s\n",
      "\titers: 200, epoch: 12 | loss: 0.0499756\n",
      "\tspeed: 0.0321s/iter; left time: 633.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0482302 Vali Loss: 0.0611211 Test Loss: 0.0649221\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0500659\n",
      "\tspeed: 0.0601s/iter; left time: 1178.1560s\n",
      "\titers: 200, epoch: 13 | loss: 0.0463377\n",
      "\tspeed: 0.0322s/iter; left time: 627.9842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0468275 Vali Loss: 0.0616577 Test Loss: 0.0657040\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0437683\n",
      "\tspeed: 0.0599s/iter; left time: 1161.6980s\n",
      "\titers: 200, epoch: 14 | loss: 0.0452077\n",
      "\tspeed: 0.0321s/iter; left time: 619.3575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0456268 Vali Loss: 0.0622756 Test Loss: 0.0657823\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0445578\n",
      "\tspeed: 0.0620s/iter; left time: 1188.7984s\n",
      "\titers: 200, epoch: 15 | loss: 0.0429793\n",
      "\tspeed: 0.0324s/iter; left time: 617.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0444806 Vali Loss: 0.0620232 Test Loss: 0.0653317\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0447943\n",
      "\tspeed: 0.0622s/iter; left time: 1179.0772s\n",
      "\titers: 200, epoch: 16 | loss: 0.0439081\n",
      "\tspeed: 0.0331s/iter; left time: 624.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0435288 Vali Loss: 0.0623529 Test Loss: 0.0663972\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01142948679625988, rmse:0.10690877586603165, mae:0.06399953365325928, rse:0.4039556086063385\n",
      "Intermediate time for IT and pred_len 24: 00h:05m:23.04s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1181966\n",
      "\tspeed: 0.0595s/iter; left time: 1326.4071s\n",
      "\titers: 200, epoch: 1 | loss: 0.1096394\n",
      "\tspeed: 0.0328s/iter; left time: 728.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.1280400 Vali Loss: 0.0973109 Test Loss: 0.1012016\n",
      "Validation loss decreased (inf --> 0.097311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0877090\n",
      "\tspeed: 0.0656s/iter; left time: 1449.2473s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852547\n",
      "\tspeed: 0.0327s/iter; left time: 719.0761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0902369 Vali Loss: 0.0833138 Test Loss: 0.0876840\n",
      "Validation loss decreased (0.097311 --> 0.083314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0796998\n",
      "\tspeed: 0.0637s/iter; left time: 1392.6980s\n",
      "\titers: 200, epoch: 3 | loss: 0.0754760\n",
      "\tspeed: 0.0330s/iter; left time: 718.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0821896 Vali Loss: 0.0847121 Test Loss: 0.0885704\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0757821\n",
      "\tspeed: 0.0636s/iter; left time: 1375.0338s\n",
      "\titers: 200, epoch: 4 | loss: 0.0727580\n",
      "\tspeed: 0.0330s/iter; left time: 710.4566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0758136 Vali Loss: 0.0868573 Test Loss: 0.0913092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0687613\n",
      "\tspeed: 0.0616s/iter; left time: 1319.5185s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685968\n",
      "\tspeed: 0.0328s/iter; left time: 697.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0689663 Vali Loss: 0.0893411 Test Loss: 0.0935924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0651921\n",
      "\tspeed: 0.0615s/iter; left time: 1301.9021s\n",
      "\titers: 200, epoch: 6 | loss: 0.0632846\n",
      "\tspeed: 0.0329s/iter; left time: 692.8142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0631031 Vali Loss: 0.0897252 Test Loss: 0.0937936\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562681\n",
      "\tspeed: 0.0623s/iter; left time: 1306.4249s\n",
      "\titers: 200, epoch: 7 | loss: 0.0584004\n",
      "\tspeed: 0.0328s/iter; left time: 683.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0586738 Vali Loss: 0.0891313 Test Loss: 0.0927569\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0594843\n",
      "\tspeed: 0.0632s/iter; left time: 1310.5403s\n",
      "\titers: 200, epoch: 8 | loss: 0.0533358\n",
      "\tspeed: 0.0333s/iter; left time: 686.7450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0551203 Vali Loss: 0.0891207 Test Loss: 0.0943138\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0506663\n",
      "\tspeed: 0.0621s/iter; left time: 1274.4806s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516839\n",
      "\tspeed: 0.0329s/iter; left time: 671.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0524840 Vali Loss: 0.0899251 Test Loss: 0.0945375\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0502532\n",
      "\tspeed: 0.0617s/iter; left time: 1252.1771s\n",
      "\titers: 200, epoch: 10 | loss: 0.0516907\n",
      "\tspeed: 0.0329s/iter; left time: 663.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0503486 Vali Loss: 0.0897381 Test Loss: 0.0947718\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0476377\n",
      "\tspeed: 0.0618s/iter; left time: 1240.4583s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482675\n",
      "\tspeed: 0.0328s/iter; left time: 655.2572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0485826 Vali Loss: 0.0897575 Test Loss: 0.0946977\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0458898\n",
      "\tspeed: 0.0616s/iter; left time: 1222.0938s\n",
      "\titers: 200, epoch: 12 | loss: 0.0471257\n",
      "\tspeed: 0.0333s/iter; left time: 657.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0471242 Vali Loss: 0.0901863 Test Loss: 0.0944600\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02016986720263958, rmse:0.14202065765857697, mae:0.08768393099308014, rse:0.5369954109191895\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1255154\n",
      "\tspeed: 0.0352s/iter; left time: 784.3829s\n",
      "\titers: 200, epoch: 1 | loss: 0.1049256\n",
      "\tspeed: 0.0328s/iter; left time: 727.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.1278330 Vali Loss: 0.0975431 Test Loss: 0.1014083\n",
      "Validation loss decreased (inf --> 0.097543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0899003\n",
      "\tspeed: 0.0656s/iter; left time: 1448.8317s\n",
      "\titers: 200, epoch: 2 | loss: 0.0846541\n",
      "\tspeed: 0.0330s/iter; left time: 726.2181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0901421 Vali Loss: 0.0825803 Test Loss: 0.0863189\n",
      "Validation loss decreased (0.097543 --> 0.082580).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0845014\n",
      "\tspeed: 0.0644s/iter; left time: 1408.1594s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811608\n",
      "\tspeed: 0.0330s/iter; left time: 717.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0826669 Vali Loss: 0.0844429 Test Loss: 0.0884733\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0779427\n",
      "\tspeed: 0.0631s/iter; left time: 1364.3807s\n",
      "\titers: 200, epoch: 4 | loss: 0.0703318\n",
      "\tspeed: 0.0333s/iter; left time: 716.9152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 224 | Train Loss: 0.0767097 Vali Loss: 0.0885497 Test Loss: 0.0904577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0702917\n",
      "\tspeed: 0.0637s/iter; left time: 1364.4786s\n",
      "\titers: 200, epoch: 5 | loss: 0.0693786\n",
      "\tspeed: 0.0327s/iter; left time: 696.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0701658 Vali Loss: 0.0881929 Test Loss: 0.0910864\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0627403\n",
      "\tspeed: 0.0625s/iter; left time: 1323.8462s\n",
      "\titers: 200, epoch: 6 | loss: 0.0628337\n",
      "\tspeed: 0.0328s/iter; left time: 692.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0642376 Vali Loss: 0.0915709 Test Loss: 0.0943422\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0589409\n",
      "\tspeed: 0.0625s/iter; left time: 1310.2335s\n",
      "\titers: 200, epoch: 7 | loss: 0.0613292\n",
      "\tspeed: 0.0327s/iter; left time: 681.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0597377 Vali Loss: 0.0914882 Test Loss: 0.0947146\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0582752\n",
      "\tspeed: 0.0619s/iter; left time: 1282.9689s\n",
      "\titers: 200, epoch: 8 | loss: 0.0556407\n",
      "\tspeed: 0.0327s/iter; left time: 673.7276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0564200 Vali Loss: 0.0915248 Test Loss: 0.0945174\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0531261\n",
      "\tspeed: 0.0613s/iter; left time: 1257.0216s\n",
      "\titers: 200, epoch: 9 | loss: 0.0556055\n",
      "\tspeed: 0.0328s/iter; left time: 669.8923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0534906 Vali Loss: 0.0919397 Test Loss: 0.0957770\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536001\n",
      "\tspeed: 0.0626s/iter; left time: 1268.8658s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489793\n",
      "\tspeed: 0.0330s/iter; left time: 665.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0513367 Vali Loss: 0.0924511 Test Loss: 0.0954170\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0486944\n",
      "\tspeed: 0.0618s/iter; left time: 1240.4935s\n",
      "\titers: 200, epoch: 11 | loss: 0.0491078\n",
      "\tspeed: 0.0328s/iter; left time: 654.9085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0493445 Vali Loss: 0.0925241 Test Loss: 0.0958952\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0473603\n",
      "\tspeed: 0.0622s/iter; left time: 1233.9804s\n",
      "\titers: 200, epoch: 12 | loss: 0.0451833\n",
      "\tspeed: 0.0331s/iter; left time: 653.1351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0478553 Vali Loss: 0.0918346 Test Loss: 0.0957100\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01941889151930809, rmse:0.13935168087482452, mae:0.08631888031959534, rse:0.5269036889076233\n",
      "Intermediate time for IT and pred_len 96: 00h:04m:02.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1198918\n",
      "\tspeed: 0.0602s/iter; left time: 1335.4515s\n",
      "\titers: 200, epoch: 1 | loss: 0.1119531\n",
      "\tspeed: 0.0335s/iter; left time: 739.9478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1296531 Vali Loss: 0.0998805 Test Loss: 0.1030402\n",
      "Validation loss decreased (inf --> 0.099880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0907918\n",
      "\tspeed: 0.0724s/iter; left time: 1591.1121s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905884\n",
      "\tspeed: 0.0334s/iter; left time: 731.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 223 | Train Loss: 0.0942718 Vali Loss: 0.0888983 Test Loss: 0.0913404\n",
      "Validation loss decreased (0.099880 --> 0.088898).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0858455\n",
      "\tspeed: 0.0693s/iter; left time: 1506.8082s\n",
      "\titers: 200, epoch: 3 | loss: 0.0790434\n",
      "\tspeed: 0.0334s/iter; left time: 724.3479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0845714 Vali Loss: 0.0910256 Test Loss: 0.0931149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0759794\n",
      "\tspeed: 0.0621s/iter; left time: 1336.2590s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741858\n",
      "\tspeed: 0.0336s/iter; left time: 720.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 223 | Train Loss: 0.0770820 Vali Loss: 0.0927773 Test Loss: 0.0950808\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0691015\n",
      "\tspeed: 0.0650s/iter; left time: 1386.1147s\n",
      "\titers: 200, epoch: 5 | loss: 0.0647586\n",
      "\tspeed: 0.0348s/iter; left time: 737.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0700328 Vali Loss: 0.0943000 Test Loss: 0.0950744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640472\n",
      "\tspeed: 0.0640s/iter; left time: 1350.1069s\n",
      "\titers: 200, epoch: 6 | loss: 0.0612911\n",
      "\tspeed: 0.0336s/iter; left time: 704.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0645894 Vali Loss: 0.0963655 Test Loss: 0.0991898\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0610605\n",
      "\tspeed: 0.0640s/iter; left time: 1335.5354s\n",
      "\titers: 200, epoch: 7 | loss: 0.0579671\n",
      "\tspeed: 0.0335s/iter; left time: 696.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0603602 Vali Loss: 0.0950874 Test Loss: 0.0973007\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0567950\n",
      "\tspeed: 0.0644s/iter; left time: 1330.2366s\n",
      "\titers: 200, epoch: 8 | loss: 0.0570818\n",
      "\tspeed: 0.0336s/iter; left time: 689.7922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0570988 Vali Loss: 0.0949548 Test Loss: 0.0956630\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0546112\n",
      "\tspeed: 0.0634s/iter; left time: 1294.7920s\n",
      "\titers: 200, epoch: 9 | loss: 0.0524339\n",
      "\tspeed: 0.0335s/iter; left time: 680.3682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0544873 Vali Loss: 0.0957294 Test Loss: 0.0976520\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0508264\n",
      "\tspeed: 0.0644s/iter; left time: 1300.9257s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543244\n",
      "\tspeed: 0.0338s/iter; left time: 678.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0524037 Vali Loss: 0.0946522 Test Loss: 0.0974682\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0509232\n",
      "\tspeed: 0.0635s/iter; left time: 1268.2480s\n",
      "\titers: 200, epoch: 11 | loss: 0.0519942\n",
      "\tspeed: 0.0335s/iter; left time: 666.4533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0505157 Vali Loss: 0.0947079 Test Loss: 0.0967350\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0484439\n",
      "\tspeed: 0.0637s/iter; left time: 1258.3883s\n",
      "\titers: 200, epoch: 12 | loss: 0.0475559\n",
      "\tspeed: 0.0336s/iter; left time: 659.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 223 | Train Loss: 0.0490816 Vali Loss: 0.0940101 Test Loss: 0.0961627\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021067097783088684, rmse:0.14514508843421936, mae:0.09134043753147125, rse:0.5493192076683044\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1244710\n",
      "\tspeed: 0.0360s/iter; left time: 799.8840s\n",
      "\titers: 200, epoch: 1 | loss: 0.1170316\n",
      "\tspeed: 0.0336s/iter; left time: 743.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 223 | Train Loss: 0.1287358 Vali Loss: 0.0999947 Test Loss: 0.1031152\n",
      "Validation loss decreased (inf --> 0.099995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0887262\n",
      "\tspeed: 0.0713s/iter; left time: 1566.0629s\n",
      "\titers: 200, epoch: 2 | loss: 0.0913494\n",
      "\tspeed: 0.0341s/iter; left time: 746.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0940741 Vali Loss: 0.0886703 Test Loss: 0.0908009\n",
      "Validation loss decreased (0.099995 --> 0.088670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0876927\n",
      "\tspeed: 0.0767s/iter; left time: 1668.1872s\n",
      "\titers: 200, epoch: 3 | loss: 0.0828235\n",
      "\tspeed: 0.0335s/iter; left time: 726.3285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 223 | Train Loss: 0.0851875 Vali Loss: 0.0917103 Test Loss: 0.0935745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0786623\n",
      "\tspeed: 0.0643s/iter; left time: 1384.5670s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741892\n",
      "\tspeed: 0.0336s/iter; left time: 719.5788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0777442 Vali Loss: 0.0918386 Test Loss: 0.0967076\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0694645\n",
      "\tspeed: 0.0639s/iter; left time: 1361.7622s\n",
      "\titers: 200, epoch: 5 | loss: 0.0682284\n",
      "\tspeed: 0.0335s/iter; left time: 710.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0704027 Vali Loss: 0.0935241 Test Loss: 0.0960906\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0646602\n",
      "\tspeed: 0.0650s/iter; left time: 1371.0488s\n",
      "\titers: 200, epoch: 6 | loss: 0.0633540\n",
      "\tspeed: 0.0336s/iter; left time: 704.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0650664 Vali Loss: 0.0929157 Test Loss: 0.0990988\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0606141\n",
      "\tspeed: 0.0643s/iter; left time: 1341.6915s\n",
      "\titers: 200, epoch: 7 | loss: 0.0587380\n",
      "\tspeed: 0.0336s/iter; left time: 697.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0609457 Vali Loss: 0.0932918 Test Loss: 0.0978042\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0581316\n",
      "\tspeed: 0.0635s/iter; left time: 1311.4885s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562303\n",
      "\tspeed: 0.0335s/iter; left time: 688.7392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 223 | Train Loss: 0.0575464 Vali Loss: 0.0935499 Test Loss: 0.0977738\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0535778\n",
      "\tspeed: 0.0644s/iter; left time: 1314.3718s\n",
      "\titers: 200, epoch: 9 | loss: 0.0549186\n",
      "\tspeed: 0.0337s/iter; left time: 685.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0548766 Vali Loss: 0.0944758 Test Loss: 0.0985249\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0527458\n",
      "\tspeed: 0.0639s/iter; left time: 1289.7448s\n",
      "\titers: 200, epoch: 10 | loss: 0.0528382\n",
      "\tspeed: 0.0343s/iter; left time: 689.3945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 223 | Train Loss: 0.0526781 Vali Loss: 0.0944073 Test Loss: 0.0979464\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0520308\n",
      "\tspeed: 0.0647s/iter; left time: 1292.4631s\n",
      "\titers: 200, epoch: 11 | loss: 0.0492344\n",
      "\tspeed: 0.0336s/iter; left time: 667.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0509229 Vali Loss: 0.0946541 Test Loss: 0.0983658\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0504324\n",
      "\tspeed: 0.0635s/iter; left time: 1254.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0474441\n",
      "\tspeed: 0.0335s/iter; left time: 657.8061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0494031 Vali Loss: 0.0943606 Test Loss: 0.0970964\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020650984719395638, rmse:0.14370450377464294, mae:0.0908009260892868, rse:0.5438671112060547\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:11.04s\n",
      "Intermediate time for IT: 00h:13m:36.74s\n",
      "Total time: 02h:44m:25.33s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_MIX_FEATURES.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>0.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.0624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.0911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0264  0.1626  0.1055\n",
       "        96        0.0418  0.2044  0.1408\n",
       "        168       0.0430  0.2073  0.1429\n",
       "ES      24        0.0115  0.1071  0.0677\n",
       "        96        0.0216  0.1469  0.0970\n",
       "        168       0.0236  0.1538  0.1034\n",
       "FR      24        0.0119  0.1091  0.0624\n",
       "        96        0.0208  0.1442  0.0861\n",
       "        168       0.0229  0.1513  0.0918\n",
       "GB      24        0.0289  0.1699  0.1118\n",
       "        96        0.0446  0.2113  0.1466\n",
       "        168       0.0472  0.2172  0.1520\n",
       "IT      24        0.0113  0.1064  0.0634\n",
       "        96        0.0198  0.1407  0.0870\n",
       "        168       0.0209  0.1444  0.0911"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_MIX_FEATURES.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD, PROBABLY NOT REALLY CHANNEL MIXING (APPROACH 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1288347\n",
      "\tspeed: 0.0621s/iter; left time: 271.8497s\n",
      "\titers: 200, epoch: 1 | loss: 0.1153558\n",
      "\tspeed: 0.0434s/iter; left time: 185.6252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 224 | Train Loss: 0.1386400 Vali Loss: 0.1264737 Test Loss: 0.1306201\n",
      "Validation loss decreased (inf --> 0.126474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0790193\n",
      "\tspeed: 0.0814s/iter; left time: 338.4901s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790826\n",
      "\tspeed: 0.0434s/iter; left time: 176.1489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0848311 Vali Loss: 0.0908782 Test Loss: 0.0928910\n",
      "Validation loss decreased (0.126474 --> 0.090878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0733861\n",
      "\tspeed: 0.0806s/iter; left time: 317.1256s\n",
      "\titers: 200, epoch: 3 | loss: 0.0763236\n",
      "\tspeed: 0.0433s/iter; left time: 166.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0745720 Vali Loss: 0.0889853 Test Loss: 0.0914121\n",
      "Validation loss decreased (0.090878 --> 0.088985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0697485\n",
      "\tspeed: 0.0788s/iter; left time: 292.3043s\n",
      "\titers: 200, epoch: 4 | loss: 0.0646489\n",
      "\tspeed: 0.0434s/iter; left time: 156.7062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0712106 Vali Loss: 0.0887275 Test Loss: 0.0919944\n",
      "Validation loss decreased (0.088985 --> 0.088728).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0703026\n",
      "\tspeed: 0.0788s/iter; left time: 274.5695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0676346\n",
      "\tspeed: 0.0435s/iter; left time: 147.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0672696 Vali Loss: 0.0913164 Test Loss: 0.0948952\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0655603\n",
      "\tspeed: 0.0766s/iter; left time: 249.7891s\n",
      "\titers: 200, epoch: 6 | loss: 0.0588298\n",
      "\tspeed: 0.0435s/iter; left time: 137.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0624329 Vali Loss: 0.0931622 Test Loss: 0.0983253\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0566716\n",
      "\tspeed: 0.0771s/iter; left time: 234.2919s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535484\n",
      "\tspeed: 0.0436s/iter; left time: 127.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0572146 Vali Loss: 0.0963221 Test Loss: 0.1005249\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0505644\n",
      "\tspeed: 0.0771s/iter; left time: 216.7448s\n",
      "\titers: 200, epoch: 8 | loss: 0.0515958\n",
      "\tspeed: 0.0436s/iter; left time: 118.1570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0530652 Vali Loss: 0.0984603 Test Loss: 0.1033134\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0509193\n",
      "\tspeed: 0.0771s/iter; left time: 199.6553s\n",
      "\titers: 200, epoch: 9 | loss: 0.0492906\n",
      "\tspeed: 0.0436s/iter; left time: 108.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0496132 Vali Loss: 0.0986490 Test Loss: 0.1038890\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021372228860855103, rmse:0.14619243144989014, mae:0.09199438244104385, rse:0.5159333348274231\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1415286\n",
      "\tspeed: 0.0455s/iter; left time: 199.4477s\n",
      "\titers: 200, epoch: 1 | loss: 0.1177186\n",
      "\tspeed: 0.0435s/iter; left time: 186.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.1398765 Vali Loss: 0.1292176 Test Loss: 0.1340619\n",
      "Validation loss decreased (inf --> 0.129218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0836441\n",
      "\tspeed: 0.0835s/iter; left time: 347.2026s\n",
      "\titers: 200, epoch: 2 | loss: 0.0809262\n",
      "\tspeed: 0.0435s/iter; left time: 176.6243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.46s\n",
      "Steps: 224 | Train Loss: 0.0844209 Vali Loss: 0.0905276 Test Loss: 0.0925714\n",
      "Validation loss decreased (0.129218 --> 0.090528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0768631\n",
      "\tspeed: 0.0790s/iter; left time: 310.6964s\n",
      "\titers: 200, epoch: 3 | loss: 0.0733880\n",
      "\tspeed: 0.0436s/iter; left time: 167.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0744031 Vali Loss: 0.0889989 Test Loss: 0.0919095\n",
      "Validation loss decreased (0.090528 --> 0.088999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0692604\n",
      "\tspeed: 0.0788s/iter; left time: 292.2920s\n",
      "\titers: 200, epoch: 4 | loss: 0.0709451\n",
      "\tspeed: 0.0436s/iter; left time: 157.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0706481 Vali Loss: 0.0892855 Test Loss: 0.0918443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620473\n",
      "\tspeed: 0.0770s/iter; left time: 268.2856s\n",
      "\titers: 200, epoch: 5 | loss: 0.0703997\n",
      "\tspeed: 0.0436s/iter; left time: 147.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0662776 Vali Loss: 0.0921095 Test Loss: 0.0963930\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0618102\n",
      "\tspeed: 0.0768s/iter; left time: 250.5855s\n",
      "\titers: 200, epoch: 6 | loss: 0.0612112\n",
      "\tspeed: 0.0435s/iter; left time: 137.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0609258 Vali Loss: 0.0947462 Test Loss: 0.0991559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0528752\n",
      "\tspeed: 0.0777s/iter; left time: 236.0680s\n",
      "\titers: 200, epoch: 7 | loss: 0.0571331\n",
      "\tspeed: 0.0435s/iter; left time: 127.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0557489 Vali Loss: 0.0972916 Test Loss: 0.1027085\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0492335\n",
      "\tspeed: 0.0782s/iter; left time: 219.8889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0513884\n",
      "\tspeed: 0.0436s/iter; left time: 118.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.0512173 Vali Loss: 0.0977964 Test Loss: 0.1046530\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02161523513495922, rmse:0.14702120423316956, mae:0.0919095128774643, rse:0.5188581943511963\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:37.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1431927\n",
      "\tspeed: 0.0619s/iter; left time: 271.3939s\n",
      "\titers: 200, epoch: 1 | loss: 0.1289140\n",
      "\tspeed: 0.0437s/iter; left time: 186.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 224 | Train Loss: 0.1487396 Vali Loss: 0.1405490 Test Loss: 0.1488965\n",
      "Validation loss decreased (inf --> 0.140549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1077801\n",
      "\tspeed: 0.0797s/iter; left time: 331.2474s\n",
      "\titers: 200, epoch: 2 | loss: 0.0963636\n",
      "\tspeed: 0.0437s/iter; left time: 177.2322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.1068755 Vali Loss: 0.1224208 Test Loss: 0.1325869\n",
      "Validation loss decreased (0.140549 --> 0.122421).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0926780\n",
      "\tspeed: 0.0803s/iter; left time: 315.7715s\n",
      "\titers: 200, epoch: 3 | loss: 0.0843681\n",
      "\tspeed: 0.0437s/iter; left time: 167.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0893946 Vali Loss: 0.1247966 Test Loss: 0.1377297\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0736906\n",
      "\tspeed: 0.0782s/iter; left time: 289.9745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0699906\n",
      "\tspeed: 0.0438s/iter; left time: 157.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0746758 Vali Loss: 0.1276431 Test Loss: 0.1399731\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639692\n",
      "\tspeed: 0.0775s/iter; left time: 270.0486s\n",
      "\titers: 200, epoch: 5 | loss: 0.0590412\n",
      "\tspeed: 0.0438s/iter; left time: 148.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0646408 Vali Loss: 0.1299467 Test Loss: 0.1427322\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569997\n",
      "\tspeed: 0.0782s/iter; left time: 255.0126s\n",
      "\titers: 200, epoch: 6 | loss: 0.0539131\n",
      "\tspeed: 0.0439s/iter; left time: 138.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0580533 Vali Loss: 0.1302402 Test Loss: 0.1435865\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0529144\n",
      "\tspeed: 0.0785s/iter; left time: 238.5008s\n",
      "\titers: 200, epoch: 7 | loss: 0.0503044\n",
      "\tspeed: 0.0440s/iter; left time: 129.0835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0534348 Vali Loss: 0.1301299 Test Loss: 0.1424773\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04040202498435974, rmse:0.2010025531053543, mae:0.13258694112300873, rse:0.7117906808853149\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1446730\n",
      "\tspeed: 0.0495s/iter; left time: 216.8344s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379150\n",
      "\tspeed: 0.0437s/iter; left time: 187.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.41s\n",
      "Steps: 224 | Train Loss: 0.1482707 Vali Loss: 0.1405652 Test Loss: 0.1491016\n",
      "Validation loss decreased (inf --> 0.140565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1060695\n",
      "\tspeed: 0.0804s/iter; left time: 334.4022s\n",
      "\titers: 200, epoch: 2 | loss: 0.0933992\n",
      "\tspeed: 0.0439s/iter; left time: 178.1298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.1067035 Vali Loss: 0.1217589 Test Loss: 0.1363821\n",
      "Validation loss decreased (0.140565 --> 0.121759).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0944410\n",
      "\tspeed: 0.0800s/iter; left time: 314.5728s\n",
      "\titers: 200, epoch: 3 | loss: 0.0786479\n",
      "\tspeed: 0.0437s/iter; left time: 167.6827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.0873720 Vali Loss: 0.1261233 Test Loss: 0.1370733\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0743208\n",
      "\tspeed: 0.0786s/iter; left time: 291.3874s\n",
      "\titers: 200, epoch: 4 | loss: 0.0682476\n",
      "\tspeed: 0.0438s/iter; left time: 157.9232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0722580 Vali Loss: 0.1309307 Test Loss: 0.1429823\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630023\n",
      "\tspeed: 0.0780s/iter; left time: 271.8135s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619667\n",
      "\tspeed: 0.0437s/iter; left time: 147.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0632695 Vali Loss: 0.1294827 Test Loss: 0.1430689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0583094\n",
      "\tspeed: 0.0784s/iter; left time: 255.6968s\n",
      "\titers: 200, epoch: 6 | loss: 0.0569461\n",
      "\tspeed: 0.0437s/iter; left time: 138.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0574156 Vali Loss: 0.1289199 Test Loss: 0.1438109\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0540976\n",
      "\tspeed: 0.0786s/iter; left time: 238.7198s\n",
      "\titers: 200, epoch: 7 | loss: 0.0510037\n",
      "\tspeed: 0.0437s/iter; left time: 128.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0531317 Vali Loss: 0.1288909 Test Loss: 0.1443605\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043257858604192734, rmse:0.20798523724079132, mae:0.1363820880651474, rse:0.7365177869796753\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:02.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1518797\n",
      "\tspeed: 0.0609s/iter; left time: 265.7029s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341218\n",
      "\tspeed: 0.0438s/iter; left time: 186.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1515815 Vali Loss: 0.1431780 Test Loss: 0.1525715\n",
      "Validation loss decreased (inf --> 0.143178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1105171\n",
      "\tspeed: 0.0810s/iter; left time: 335.2319s\n",
      "\titers: 200, epoch: 2 | loss: 0.1020385\n",
      "\tspeed: 0.0439s/iter; left time: 177.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.1109439 Vali Loss: 0.1256638 Test Loss: 0.1443070\n",
      "Validation loss decreased (0.143178 --> 0.125664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0909588\n",
      "\tspeed: 0.0809s/iter; left time: 316.8799s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823636\n",
      "\tspeed: 0.0439s/iter; left time: 167.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.0895617 Vali Loss: 0.1273583 Test Loss: 0.1470855\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744034\n",
      "\tspeed: 0.0785s/iter; left time: 289.7581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0707802\n",
      "\tspeed: 0.0440s/iter; left time: 157.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.0744996 Vali Loss: 0.1302383 Test Loss: 0.1442910\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0646706\n",
      "\tspeed: 0.0779s/iter; left time: 270.2656s\n",
      "\titers: 200, epoch: 5 | loss: 0.0608316\n",
      "\tspeed: 0.0441s/iter; left time: 148.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0651669 Vali Loss: 0.1310407 Test Loss: 0.1438465\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0574107\n",
      "\tspeed: 0.0790s/iter; left time: 256.3127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0584476\n",
      "\tspeed: 0.0440s/iter; left time: 138.2686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.0592617 Vali Loss: 0.1324312 Test Loss: 0.1442218\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0558157\n",
      "\tspeed: 0.0785s/iter; left time: 237.2210s\n",
      "\titers: 200, epoch: 7 | loss: 0.0557166\n",
      "\tspeed: 0.0440s/iter; left time: 128.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 223 | Train Loss: 0.0549841 Vali Loss: 0.1323213 Test Loss: 0.1434522\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04741961508989334, rmse:0.21776045858860016, mae:0.14430703222751617, rse:0.7713250517845154\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1513522\n",
      "\tspeed: 0.0464s/iter; left time: 202.2887s\n",
      "\titers: 200, epoch: 1 | loss: 0.1385211\n",
      "\tspeed: 0.0439s/iter; left time: 187.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 223 | Train Loss: 0.1521855 Vali Loss: 0.1438601 Test Loss: 0.1531233\n",
      "Validation loss decreased (inf --> 0.143860).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1064229\n",
      "\tspeed: 0.0815s/iter; left time: 337.4412s\n",
      "\titers: 200, epoch: 2 | loss: 0.1020931\n",
      "\tspeed: 0.0440s/iter; left time: 177.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.1112131 Vali Loss: 0.1247842 Test Loss: 0.1412956\n",
      "Validation loss decreased (0.143860 --> 0.124784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0937691\n",
      "\tspeed: 0.0820s/iter; left time: 321.1670s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833023\n",
      "\tspeed: 0.0439s/iter; left time: 167.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.0891496 Vali Loss: 0.1302273 Test Loss: 0.1467150\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755298\n",
      "\tspeed: 0.0787s/iter; left time: 290.5388s\n",
      "\titers: 200, epoch: 4 | loss: 0.0678074\n",
      "\tspeed: 0.0440s/iter; left time: 158.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0731834 Vali Loss: 0.1329896 Test Loss: 0.1487310\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0666101\n",
      "\tspeed: 0.0788s/iter; left time: 273.4192s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610430\n",
      "\tspeed: 0.0440s/iter; left time: 148.1712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.0643469 Vali Loss: 0.1333733 Test Loss: 0.1499041\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0585870\n",
      "\tspeed: 0.0789s/iter; left time: 256.0959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0568665\n",
      "\tspeed: 0.0440s/iter; left time: 138.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.0583537 Vali Loss: 0.1314956 Test Loss: 0.1464267\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0525444\n",
      "\tspeed: 0.0790s/iter; left time: 238.9590s\n",
      "\titers: 200, epoch: 7 | loss: 0.0518316\n",
      "\tspeed: 0.0439s/iter; left time: 128.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0540509 Vali Loss: 0.1317015 Test Loss: 0.1481518\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04486357793211937, rmse:0.21181024610996246, mae:0.14129573106765747, rse:0.7502489686012268\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:04.36s\n",
      "Intermediate time for DE: 00h:09m:44.80s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1249031\n",
      "\tspeed: 0.0601s/iter; left time: 263.2734s\n",
      "\titers: 200, epoch: 1 | loss: 0.1127680\n",
      "\tspeed: 0.0432s/iter; left time: 184.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.1274041 Vali Loss: 0.1188559 Test Loss: 0.1365499\n",
      "Validation loss decreased (inf --> 0.118856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0752068\n",
      "\tspeed: 0.0804s/iter; left time: 334.0770s\n",
      "\titers: 200, epoch: 2 | loss: 0.0756959\n",
      "\tspeed: 0.0433s/iter; left time: 175.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0829447 Vali Loss: 0.0909307 Test Loss: 0.1030746\n",
      "Validation loss decreased (0.118856 --> 0.090931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0754961\n",
      "\tspeed: 0.0784s/iter; left time: 308.3153s\n",
      "\titers: 200, epoch: 3 | loss: 0.0801942\n",
      "\tspeed: 0.0433s/iter; left time: 166.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0758008 Vali Loss: 0.0894891 Test Loss: 0.1017765\n",
      "Validation loss decreased (0.090931 --> 0.089489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0749308\n",
      "\tspeed: 0.0787s/iter; left time: 291.7423s\n",
      "\titers: 200, epoch: 4 | loss: 0.0664703\n",
      "\tspeed: 0.0433s/iter; left time: 156.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0732703 Vali Loss: 0.0913262 Test Loss: 0.1023002\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0723235\n",
      "\tspeed: 0.0758s/iter; left time: 264.2858s\n",
      "\titers: 200, epoch: 5 | loss: 0.0701183\n",
      "\tspeed: 0.0433s/iter; left time: 146.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0703901 Vali Loss: 0.0899382 Test Loss: 0.1038470\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0694546\n",
      "\tspeed: 0.0756s/iter; left time: 246.6922s\n",
      "\titers: 200, epoch: 6 | loss: 0.0659585\n",
      "\tspeed: 0.0433s/iter; left time: 136.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0664127 Vali Loss: 0.0935771 Test Loss: 0.1056621\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577669\n",
      "\tspeed: 0.0760s/iter; left time: 230.8019s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580327\n",
      "\tspeed: 0.0434s/iter; left time: 127.3561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0617652 Vali Loss: 0.0964528 Test Loss: 0.1120393\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0580244\n",
      "\tspeed: 0.0781s/iter; left time: 219.7505s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549745\n",
      "\tspeed: 0.0434s/iter; left time: 117.6108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0575566 Vali Loss: 0.0996388 Test Loss: 0.1158492\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025332890450954437, rmse:0.15916308760643005, mae:0.10177655518054962, rse:0.5490675568580627\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1193750\n",
      "\tspeed: 0.0450s/iter; left time: 197.2874s\n",
      "\titers: 200, epoch: 1 | loss: 0.1060155\n",
      "\tspeed: 0.0434s/iter; left time: 185.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.1250374 Vali Loss: 0.1174057 Test Loss: 0.1348697\n",
      "Validation loss decreased (inf --> 0.117406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0799368\n",
      "\tspeed: 0.0782s/iter; left time: 325.0579s\n",
      "\titers: 200, epoch: 2 | loss: 0.0795878\n",
      "\tspeed: 0.0434s/iter; left time: 176.0104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0825805 Vali Loss: 0.0911475 Test Loss: 0.1029994\n",
      "Validation loss decreased (0.117406 --> 0.091147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0756929\n",
      "\tspeed: 0.0784s/iter; left time: 308.3488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774784\n",
      "\tspeed: 0.0434s/iter; left time: 166.2460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0757685 Vali Loss: 0.0891861 Test Loss: 0.1012558\n",
      "Validation loss decreased (0.091147 --> 0.089186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0707852\n",
      "\tspeed: 0.0825s/iter; left time: 306.1245s\n",
      "\titers: 200, epoch: 4 | loss: 0.0715328\n",
      "\tspeed: 0.0434s/iter; left time: 156.7667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0732520 Vali Loss: 0.0898914 Test Loss: 0.1021442\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689220\n",
      "\tspeed: 0.0771s/iter; left time: 268.8159s\n",
      "\titers: 200, epoch: 5 | loss: 0.0702394\n",
      "\tspeed: 0.0435s/iter; left time: 147.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0703283 Vali Loss: 0.0914296 Test Loss: 0.1033106\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0662516\n",
      "\tspeed: 0.0764s/iter; left time: 249.0542s\n",
      "\titers: 200, epoch: 6 | loss: 0.0679668\n",
      "\tspeed: 0.0434s/iter; left time: 137.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0663290 Vali Loss: 0.0943815 Test Loss: 0.1062462\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0596283\n",
      "\tspeed: 0.0761s/iter; left time: 231.1431s\n",
      "\titers: 200, epoch: 7 | loss: 0.0606526\n",
      "\tspeed: 0.0434s/iter; left time: 127.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0616254 Vali Loss: 0.0968927 Test Loss: 0.1100579\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0565274\n",
      "\tspeed: 0.0763s/iter; left time: 214.5441s\n",
      "\titers: 200, epoch: 8 | loss: 0.0578602\n",
      "\tspeed: 0.0434s/iter; left time: 117.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0571208 Vali Loss: 0.1001299 Test Loss: 0.1126765\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02496434934437275, rmse:0.158001109957695, mae:0.10125575959682465, rse:0.5450590252876282\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:23.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1300309\n",
      "\tspeed: 0.0619s/iter; left time: 271.1114s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175259\n",
      "\tspeed: 0.0437s/iter; left time: 187.1140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 224 | Train Loss: 0.1356121 Vali Loss: 0.1320696 Test Loss: 0.1547136\n",
      "Validation loss decreased (inf --> 0.132070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1107192\n",
      "\tspeed: 0.0793s/iter; left time: 329.5753s\n",
      "\titers: 200, epoch: 2 | loss: 0.0974107\n",
      "\tspeed: 0.0437s/iter; left time: 177.3589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.1059472 Vali Loss: 0.1207289 Test Loss: 0.1423227\n",
      "Validation loss decreased (0.132070 --> 0.120729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921785\n",
      "\tspeed: 0.0789s/iter; left time: 310.4888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906572\n",
      "\tspeed: 0.0436s/iter; left time: 167.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0932772 Vali Loss: 0.1250454 Test Loss: 0.1396944\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0780643\n",
      "\tspeed: 0.0772s/iter; left time: 286.1969s\n",
      "\titers: 200, epoch: 4 | loss: 0.0736055\n",
      "\tspeed: 0.0436s/iter; left time: 157.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0790285 Vali Loss: 0.1302246 Test Loss: 0.1424275\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0678155\n",
      "\tspeed: 0.0771s/iter; left time: 268.8162s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652552\n",
      "\tspeed: 0.0435s/iter; left time: 147.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0684898 Vali Loss: 0.1330113 Test Loss: 0.1475625\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0595127\n",
      "\tspeed: 0.0765s/iter; left time: 249.4589s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599183\n",
      "\tspeed: 0.0436s/iter; left time: 137.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0620094 Vali Loss: 0.1328093 Test Loss: 0.1456130\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590672\n",
      "\tspeed: 0.0760s/iter; left time: 230.7722s\n",
      "\titers: 200, epoch: 7 | loss: 0.0578840\n",
      "\tspeed: 0.0436s/iter; left time: 128.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0574334 Vali Loss: 0.1333681 Test Loss: 0.1477004\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04291878640651703, rmse:0.20716850459575653, mae:0.14232265949249268, rse:0.7164175510406494\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1369909\n",
      "\tspeed: 0.0452s/iter; left time: 198.1251s\n",
      "\titers: 200, epoch: 1 | loss: 0.1235660\n",
      "\tspeed: 0.0436s/iter; left time: 186.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.1355126 Vali Loss: 0.1321635 Test Loss: 0.1548172\n",
      "Validation loss decreased (inf --> 0.132164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1024315\n",
      "\tspeed: 0.0822s/iter; left time: 341.8837s\n",
      "\titers: 200, epoch: 2 | loss: 0.0971463\n",
      "\tspeed: 0.0436s/iter; left time: 176.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.1058134 Vali Loss: 0.1206499 Test Loss: 0.1399352\n",
      "Validation loss decreased (0.132164 --> 0.120650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0939326\n",
      "\tspeed: 0.0953s/iter; left time: 374.8068s\n",
      "\titers: 200, epoch: 3 | loss: 0.0851375\n",
      "\tspeed: 0.0436s/iter; left time: 166.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0934879 Vali Loss: 0.1276292 Test Loss: 0.1426655\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788433\n",
      "\tspeed: 0.0770s/iter; left time: 285.4099s\n",
      "\titers: 200, epoch: 4 | loss: 0.0714974\n",
      "\tspeed: 0.0435s/iter; left time: 157.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0783464 Vali Loss: 0.1301064 Test Loss: 0.1484889\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0670597\n",
      "\tspeed: 0.0768s/iter; left time: 267.4897s\n",
      "\titers: 200, epoch: 5 | loss: 0.0632937\n",
      "\tspeed: 0.1556s/iter; left time: 526.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.12s\n",
      "Steps: 224 | Train Loss: 0.0674435 Vali Loss: 0.1301742 Test Loss: 0.1560793\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0597854\n",
      "\tspeed: 0.0763s/iter; left time: 248.9769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592995\n",
      "\tspeed: 0.0435s/iter; left time: 137.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0609915 Vali Loss: 0.1312574 Test Loss: 0.1548149\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571895\n",
      "\tspeed: 0.0767s/iter; left time: 233.0420s\n",
      "\titers: 200, epoch: 7 | loss: 0.0534755\n",
      "\tspeed: 0.0437s/iter; left time: 128.4914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0563500 Vali Loss: 0.1323618 Test Loss: 0.1562927\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042682863771915436, rmse:0.20659831166267395, mae:0.1399351954460144, rse:0.7144457697868347\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:13.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1341277\n",
      "\tspeed: 0.0614s/iter; left time: 267.8026s\n",
      "\titers: 200, epoch: 1 | loss: 0.1240424\n",
      "\tspeed: 0.0436s/iter; left time: 185.8316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 223 | Train Loss: 0.1377349 Vali Loss: 0.1347460 Test Loss: 0.1585737\n",
      "Validation loss decreased (inf --> 0.134746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1115550\n",
      "\tspeed: 0.0794s/iter; left time: 328.6687s\n",
      "\titers: 200, epoch: 2 | loss: 0.1019396\n",
      "\tspeed: 0.0439s/iter; left time: 177.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.1095999 Vali Loss: 0.1251576 Test Loss: 0.1528900\n",
      "Validation loss decreased (0.134746 --> 0.125158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0949040\n",
      "\tspeed: 0.0798s/iter; left time: 312.4155s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896047\n",
      "\tspeed: 0.0439s/iter; left time: 167.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0943391 Vali Loss: 0.1325155 Test Loss: 0.1532334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0794888\n",
      "\tspeed: 0.0785s/iter; left time: 289.9586s\n",
      "\titers: 200, epoch: 4 | loss: 0.0751732\n",
      "\tspeed: 0.0439s/iter; left time: 157.7071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 223 | Train Loss: 0.0793516 Vali Loss: 0.1352002 Test Loss: 0.1513123\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0718923\n",
      "\tspeed: 0.0780s/iter; left time: 270.5778s\n",
      "\titers: 200, epoch: 5 | loss: 0.0654820\n",
      "\tspeed: 0.0440s/iter; left time: 148.1064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 223 | Train Loss: 0.0696418 Vali Loss: 0.1345929 Test Loss: 0.1558284\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637268\n",
      "\tspeed: 0.0777s/iter; left time: 252.2374s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619536\n",
      "\tspeed: 0.0440s/iter; left time: 138.4949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0636521 Vali Loss: 0.1361301 Test Loss: 0.1573202\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0584776\n",
      "\tspeed: 0.0777s/iter; left time: 234.7740s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590519\n",
      "\tspeed: 0.0440s/iter; left time: 128.6523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0592529 Vali Loss: 0.1356159 Test Loss: 0.1559382\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.052469152957201004, rmse:0.22906145453453064, mae:0.15288984775543213, rse:0.7941889762878418\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1340767\n",
      "\tspeed: 0.0507s/iter; left time: 221.1755s\n",
      "\titers: 200, epoch: 1 | loss: 0.1268893\n",
      "\tspeed: 0.0439s/iter; left time: 187.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 223 | Train Loss: 0.1382299 Vali Loss: 0.1351098 Test Loss: 0.1589990\n",
      "Validation loss decreased (inf --> 0.135110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1089100\n",
      "\tspeed: 0.0820s/iter; left time: 339.4382s\n",
      "\titers: 200, epoch: 2 | loss: 0.1047608\n",
      "\tspeed: 0.0439s/iter; left time: 177.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.1098012 Vali Loss: 0.1272498 Test Loss: 0.1492751\n",
      "Validation loss decreased (0.135110 --> 0.127250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0957372\n",
      "\tspeed: 0.0820s/iter; left time: 321.1154s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877633\n",
      "\tspeed: 0.0440s/iter; left time: 167.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.0951678 Vali Loss: 0.1317861 Test Loss: 0.1500311\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0815844\n",
      "\tspeed: 0.0793s/iter; left time: 292.7075s\n",
      "\titers: 200, epoch: 4 | loss: 0.0720776\n",
      "\tspeed: 0.0440s/iter; left time: 157.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.0793402 Vali Loss: 0.1376163 Test Loss: 0.1564661\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0674153\n",
      "\tspeed: 0.0795s/iter; left time: 275.6132s\n",
      "\titers: 200, epoch: 5 | loss: 0.0677345\n",
      "\tspeed: 0.0440s/iter; left time: 148.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 223 | Train Loss: 0.0688048 Vali Loss: 0.1402889 Test Loss: 0.1571947\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0602527\n",
      "\tspeed: 0.0797s/iter; left time: 258.7197s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598245\n",
      "\tspeed: 0.0441s/iter; left time: 138.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.0624292 Vali Loss: 0.1399303 Test Loss: 0.1577230\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0568240\n",
      "\tspeed: 0.0793s/iter; left time: 239.7509s\n",
      "\titers: 200, epoch: 7 | loss: 0.0553108\n",
      "\tspeed: 0.0441s/iter; left time: 128.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 223 | Train Loss: 0.0579504 Vali Loss: 0.1376240 Test Loss: 0.1562205\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.047632455825805664, rmse:0.21824860572814941, mae:0.1492750644683838, rse:0.75669926404953\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:05.15s\n",
      "Intermediate time for GB: 00h:09m:41.67s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1197053\n",
      "\tspeed: 0.0389s/iter; left time: 170.4659s\n",
      "\titers: 200, epoch: 1 | loss: 0.1074361\n",
      "\tspeed: 0.0220s/iter; left time: 94.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.1288011 Vali Loss: 0.0958644 Test Loss: 0.1084929\n",
      "Validation loss decreased (inf --> 0.095864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0743673\n",
      "\tspeed: 0.0438s/iter; left time: 181.9416s\n",
      "\titers: 200, epoch: 2 | loss: 0.0671951\n",
      "\tspeed: 0.0220s/iter; left time: 89.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0732195 Vali Loss: 0.0619111 Test Loss: 0.0689737\n",
      "Validation loss decreased (0.095864 --> 0.061911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636132\n",
      "\tspeed: 0.0443s/iter; left time: 174.4196s\n",
      "\titers: 200, epoch: 3 | loss: 0.0605463\n",
      "\tspeed: 0.0220s/iter; left time: 84.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0620891 Vali Loss: 0.0585566 Test Loss: 0.0651297\n",
      "Validation loss decreased (0.061911 --> 0.058557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0559345\n",
      "\tspeed: 0.0444s/iter; left time: 164.5139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0574044\n",
      "\tspeed: 0.0220s/iter; left time: 79.4318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0591701 Vali Loss: 0.0568301 Test Loss: 0.0641761\n",
      "Validation loss decreased (0.058557 --> 0.056830).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0585900\n",
      "\tspeed: 0.0441s/iter; left time: 153.7485s\n",
      "\titers: 200, epoch: 5 | loss: 0.0586798\n",
      "\tspeed: 0.0220s/iter; left time: 74.5159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0574670 Vali Loss: 0.0560226 Test Loss: 0.0631666\n",
      "Validation loss decreased (0.056830 --> 0.056023).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0571813\n",
      "\tspeed: 0.0442s/iter; left time: 143.9950s\n",
      "\titers: 200, epoch: 6 | loss: 0.0582810\n",
      "\tspeed: 0.0220s/iter; left time: 69.6702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0561205 Vali Loss: 0.0555882 Test Loss: 0.0626708\n",
      "Validation loss decreased (0.056023 --> 0.055588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0552973\n",
      "\tspeed: 0.0447s/iter; left time: 135.8377s\n",
      "\titers: 200, epoch: 7 | loss: 0.0541853\n",
      "\tspeed: 0.0221s/iter; left time: 64.7821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0551273 Vali Loss: 0.0547986 Test Loss: 0.0620969\n",
      "Validation loss decreased (0.055588 --> 0.054799).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0540874\n",
      "\tspeed: 0.0443s/iter; left time: 124.6580s\n",
      "\titers: 200, epoch: 8 | loss: 0.0545249\n",
      "\tspeed: 0.0221s/iter; left time: 59.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0540969 Vali Loss: 0.0546852 Test Loss: 0.0622704\n",
      "Validation loss decreased (0.054799 --> 0.054685).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0535808\n",
      "\tspeed: 0.0438s/iter; left time: 113.4066s\n",
      "\titers: 200, epoch: 9 | loss: 0.0510668\n",
      "\tspeed: 0.0220s/iter; left time: 54.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0533764 Vali Loss: 0.0539643 Test Loss: 0.0610771\n",
      "Validation loss decreased (0.054685 --> 0.053964).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0544953\n",
      "\tspeed: 0.0444s/iter; left time: 105.0310s\n",
      "\titers: 200, epoch: 10 | loss: 0.0548255\n",
      "\tspeed: 0.0220s/iter; left time: 49.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0525270 Vali Loss: 0.0542821 Test Loss: 0.0614841\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0498544\n",
      "\tspeed: 0.0431s/iter; left time: 92.3523s\n",
      "\titers: 200, epoch: 11 | loss: 0.0507155\n",
      "\tspeed: 0.0220s/iter; left time: 44.9447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0518580 Vali Loss: 0.0541489 Test Loss: 0.0618145\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0490863\n",
      "\tspeed: 0.0439s/iter; left time: 84.2093s\n",
      "\titers: 200, epoch: 12 | loss: 0.0500919\n",
      "\tspeed: 0.0221s/iter; left time: 40.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0512090 Vali Loss: 0.0545745 Test Loss: 0.0619080\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0565618\n",
      "\tspeed: 0.0441s/iter; left time: 74.6360s\n",
      "\titers: 200, epoch: 13 | loss: 0.0477618\n",
      "\tspeed: 0.0221s/iter; left time: 35.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0505550 Vali Loss: 0.0545160 Test Loss: 0.0619966\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0485411\n",
      "\tspeed: 0.0446s/iter; left time: 65.5215s\n",
      "\titers: 200, epoch: 14 | loss: 0.0494428\n",
      "\tspeed: 0.0221s/iter; left time: 30.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0499811 Vali Loss: 0.0538818 Test Loss: 0.0613545\n",
      "Validation loss decreased (0.053964 --> 0.053882).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0486182\n",
      "\tspeed: 0.0441s/iter; left time: 54.9210s\n",
      "\titers: 200, epoch: 15 | loss: 0.0522056\n",
      "\tspeed: 0.0220s/iter; left time: 25.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0493475 Vali Loss: 0.0540712 Test Loss: 0.0617006\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0517759\n",
      "\tspeed: 0.0428s/iter; left time: 43.6968s\n",
      "\titers: 200, epoch: 16 | loss: 0.0503656\n",
      "\tspeed: 0.0220s/iter; left time: 20.2887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0488575 Vali Loss: 0.0544644 Test Loss: 0.0622188\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0497399\n",
      "\tspeed: 0.0442s/iter; left time: 35.2565s\n",
      "\titers: 200, epoch: 17 | loss: 0.0500861\n",
      "\tspeed: 0.0221s/iter; left time: 15.3767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0484129 Vali Loss: 0.0545549 Test Loss: 0.0625807\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0462332\n",
      "\tspeed: 0.0443s/iter; left time: 25.4011s\n",
      "\titers: 200, epoch: 18 | loss: 0.0489886\n",
      "\tspeed: 0.0221s/iter; left time: 10.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0480003 Vali Loss: 0.0545118 Test Loss: 0.0624015\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0488784\n",
      "\tspeed: 0.0429s/iter; left time: 14.9608s\n",
      "\titers: 200, epoch: 19 | loss: 0.0505258\n",
      "\tspeed: 0.0220s/iter; left time: 5.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0475646 Vali Loss: 0.0548550 Test Loss: 0.0625891\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00992313027381897, rmse:0.09961491078138351, mae:0.06135452166199684, rse:0.29315462708473206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1214782\n",
      "\tspeed: 0.0264s/iter; left time: 115.7879s\n",
      "\titers: 200, epoch: 1 | loss: 0.1079467\n",
      "\tspeed: 0.0220s/iter; left time: 94.2519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.1318527 Vali Loss: 0.0977142 Test Loss: 0.1096083\n",
      "Validation loss decreased (inf --> 0.097714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0695145\n",
      "\tspeed: 0.0431s/iter; left time: 179.1939s\n",
      "\titers: 200, epoch: 2 | loss: 0.0641104\n",
      "\tspeed: 0.0221s/iter; left time: 89.4813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0732974 Vali Loss: 0.0619658 Test Loss: 0.0686749\n",
      "Validation loss decreased (0.097714 --> 0.061966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0587519\n",
      "\tspeed: 0.0433s/iter; left time: 170.3049s\n",
      "\titers: 200, epoch: 3 | loss: 0.0618919\n",
      "\tspeed: 0.0220s/iter; left time: 84.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0621301 Vali Loss: 0.0587658 Test Loss: 0.0654708\n",
      "Validation loss decreased (0.061966 --> 0.058766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0594057\n",
      "\tspeed: 0.0432s/iter; left time: 160.3581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0569952\n",
      "\tspeed: 0.0220s/iter; left time: 79.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0592448 Vali Loss: 0.0570653 Test Loss: 0.0638682\n",
      "Validation loss decreased (0.058766 --> 0.057065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0583459\n",
      "\tspeed: 0.0432s/iter; left time: 150.4146s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606583\n",
      "\tspeed: 0.0220s/iter; left time: 74.4017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0573962 Vali Loss: 0.0562197 Test Loss: 0.0633890\n",
      "Validation loss decreased (0.057065 --> 0.056220).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0551197\n",
      "\tspeed: 0.0432s/iter; left time: 140.8077s\n",
      "\titers: 200, epoch: 6 | loss: 0.0542481\n",
      "\tspeed: 0.0221s/iter; left time: 69.7244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0560827 Vali Loss: 0.0551677 Test Loss: 0.0620240\n",
      "Validation loss decreased (0.056220 --> 0.055168).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0546338\n",
      "\tspeed: 0.0433s/iter; left time: 131.3840s\n",
      "\titers: 200, epoch: 7 | loss: 0.0557244\n",
      "\tspeed: 0.0220s/iter; left time: 64.6994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0550370 Vali Loss: 0.0549158 Test Loss: 0.0618460\n",
      "Validation loss decreased (0.055168 --> 0.054916).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0533591\n",
      "\tspeed: 0.0432s/iter; left time: 121.5712s\n",
      "\titers: 200, epoch: 8 | loss: 0.0514893\n",
      "\tspeed: 0.0221s/iter; left time: 59.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0541582 Vali Loss: 0.0542985 Test Loss: 0.0613999\n",
      "Validation loss decreased (0.054916 --> 0.054299).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0519505\n",
      "\tspeed: 0.0448s/iter; left time: 116.0249s\n",
      "\titers: 200, epoch: 9 | loss: 0.0505060\n",
      "\tspeed: 0.0221s/iter; left time: 54.9988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0532708 Vali Loss: 0.0543194 Test Loss: 0.0613890\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0501624\n",
      "\tspeed: 0.0442s/iter; left time: 104.6277s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489627\n",
      "\tspeed: 0.0220s/iter; left time: 49.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0524889 Vali Loss: 0.0542982 Test Loss: 0.0611642\n",
      "Validation loss decreased (0.054299 --> 0.054298).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0491599\n",
      "\tspeed: 0.0436s/iter; left time: 93.2524s\n",
      "\titers: 200, epoch: 11 | loss: 0.0504890\n",
      "\tspeed: 0.0220s/iter; left time: 44.9858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0518310 Vali Loss: 0.0544719 Test Loss: 0.0615248\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0504733\n",
      "\tspeed: 0.0420s/iter; left time: 80.4454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0517810\n",
      "\tspeed: 0.0220s/iter; left time: 39.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0511032 Vali Loss: 0.0544304 Test Loss: 0.0618145\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0491990\n",
      "\tspeed: 0.0424s/iter; left time: 71.7644s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494348\n",
      "\tspeed: 0.0221s/iter; left time: 35.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0505439 Vali Loss: 0.0546408 Test Loss: 0.0613864\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0487825\n",
      "\tspeed: 0.0423s/iter; left time: 62.0977s\n",
      "\titers: 200, epoch: 14 | loss: 0.0486977\n",
      "\tspeed: 0.0220s/iter; left time: 30.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0499626 Vali Loss: 0.0548986 Test Loss: 0.0617785\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0492183\n",
      "\tspeed: 0.0421s/iter; left time: 52.4408s\n",
      "\titers: 200, epoch: 15 | loss: 0.0466172\n",
      "\tspeed: 0.0221s/iter; left time: 25.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0494497 Vali Loss: 0.0548974 Test Loss: 0.0618186\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009944847784936428, rmse:0.09972386062145233, mae:0.061164192855358124, rse:0.29347527027130127\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:51.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1327750\n",
      "\tspeed: 0.0392s/iter; left time: 171.5321s\n",
      "\titers: 200, epoch: 1 | loss: 0.1151738\n",
      "\tspeed: 0.0222s/iter; left time: 94.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.1380184 Vali Loss: 0.1075002 Test Loss: 0.1211424\n",
      "Validation loss decreased (inf --> 0.107500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0898748\n",
      "\tspeed: 0.0455s/iter; left time: 189.0479s\n",
      "\titers: 200, epoch: 2 | loss: 0.0794849\n",
      "\tspeed: 0.0221s/iter; left time: 89.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0905244 Vali Loss: 0.0823172 Test Loss: 0.0928391\n",
      "Validation loss decreased (0.107500 --> 0.082317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804560\n",
      "\tspeed: 0.0464s/iter; left time: 182.6691s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776050\n",
      "\tspeed: 0.0222s/iter; left time: 85.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0808929 Vali Loss: 0.0794616 Test Loss: 0.0906161\n",
      "Validation loss decreased (0.082317 --> 0.079462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755306\n",
      "\tspeed: 0.0460s/iter; left time: 170.4463s\n",
      "\titers: 200, epoch: 4 | loss: 0.0755394\n",
      "\tspeed: 0.0222s/iter; left time: 80.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0769380 Vali Loss: 0.0798931 Test Loss: 0.0919429\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0722298\n",
      "\tspeed: 0.0439s/iter; left time: 153.0381s\n",
      "\titers: 200, epoch: 5 | loss: 0.0743159\n",
      "\tspeed: 0.0222s/iter; left time: 75.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0732500 Vali Loss: 0.0803050 Test Loss: 0.0922237\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0681314\n",
      "\tspeed: 0.0445s/iter; left time: 145.0482s\n",
      "\titers: 200, epoch: 6 | loss: 0.0714724\n",
      "\tspeed: 0.0222s/iter; left time: 70.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0696609 Vali Loss: 0.0804545 Test Loss: 0.0929369\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0662445\n",
      "\tspeed: 0.0446s/iter; left time: 135.3941s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645176\n",
      "\tspeed: 0.0222s/iter; left time: 65.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0819036 Test Loss: 0.0936721\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0646453\n",
      "\tspeed: 0.0446s/iter; left time: 125.4376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0620963\n",
      "\tspeed: 0.0222s/iter; left time: 60.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0630618 Vali Loss: 0.0830514 Test Loss: 0.0945923\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019271597266197205, rmse:0.13882218301296234, mae:0.09061609208583832, rse:0.4078177809715271\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1359011\n",
      "\tspeed: 0.0239s/iter; left time: 104.8345s\n",
      "\titers: 200, epoch: 1 | loss: 0.1179544\n",
      "\tspeed: 0.0222s/iter; left time: 95.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.1384543 Vali Loss: 0.1076759 Test Loss: 0.1211382\n",
      "Validation loss decreased (inf --> 0.107676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0889097\n",
      "\tspeed: 0.0449s/iter; left time: 186.7324s\n",
      "\titers: 200, epoch: 2 | loss: 0.0868934\n",
      "\tspeed: 0.0222s/iter; left time: 90.2563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0903999 Vali Loss: 0.0819206 Test Loss: 0.0922778\n",
      "Validation loss decreased (0.107676 --> 0.081921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819837\n",
      "\tspeed: 0.0461s/iter; left time: 181.4797s\n",
      "\titers: 200, epoch: 3 | loss: 0.0790465\n",
      "\tspeed: 0.0222s/iter; left time: 85.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0806006 Vali Loss: 0.0789759 Test Loss: 0.0910454\n",
      "Validation loss decreased (0.081921 --> 0.078976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0802818\n",
      "\tspeed: 0.0450s/iter; left time: 167.0762s\n",
      "\titers: 200, epoch: 4 | loss: 0.0744955\n",
      "\tspeed: 0.0223s/iter; left time: 80.4399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0764292 Vali Loss: 0.0790067 Test Loss: 0.0904807\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0730120\n",
      "\tspeed: 0.0473s/iter; left time: 164.8390s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737626\n",
      "\tspeed: 0.0223s/iter; left time: 75.4142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0720678 Vali Loss: 0.0799713 Test Loss: 0.0924472\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0680700\n",
      "\tspeed: 0.0442s/iter; left time: 144.1804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0682947\n",
      "\tspeed: 0.0223s/iter; left time: 70.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0677571 Vali Loss: 0.0811187 Test Loss: 0.0937446\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0656267\n",
      "\tspeed: 0.0441s/iter; left time: 134.0765s\n",
      "\titers: 200, epoch: 7 | loss: 0.0630400\n",
      "\tspeed: 0.0223s/iter; left time: 65.5494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0640458 Vali Loss: 0.0827304 Test Loss: 0.0952476\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0612878\n",
      "\tspeed: 0.0439s/iter; left time: 123.4383s\n",
      "\titers: 200, epoch: 8 | loss: 0.0583994\n",
      "\tspeed: 0.0223s/iter; left time: 60.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0610601 Vali Loss: 0.0839228 Test Loss: 0.0960289\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019083218649029732, rmse:0.13814201951026917, mae:0.09104538708925247, rse:0.40581971406936646\n",
      "Intermediate time for ES and pred_len 96: 00h:01m:56.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1385189\n",
      "\tspeed: 0.0407s/iter; left time: 177.6641s\n",
      "\titers: 200, epoch: 1 | loss: 0.1222085\n",
      "\tspeed: 0.0226s/iter; left time: 96.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.1415203 Vali Loss: 0.1107488 Test Loss: 0.1235423\n",
      "Validation loss decreased (inf --> 0.110749).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0943981\n",
      "\tspeed: 0.0462s/iter; left time: 191.3232s\n",
      "\titers: 200, epoch: 2 | loss: 0.0923413\n",
      "\tspeed: 0.0226s/iter; left time: 91.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0948072 Vali Loss: 0.0882457 Test Loss: 0.0986240\n",
      "Validation loss decreased (0.110749 --> 0.088246).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0849652\n",
      "\tspeed: 0.0468s/iter; left time: 183.2532s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840910\n",
      "\tspeed: 0.0226s/iter; left time: 86.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0844714 Vali Loss: 0.0858070 Test Loss: 0.0971049\n",
      "Validation loss decreased (0.088246 --> 0.085807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0787158\n",
      "\tspeed: 0.0466s/iter; left time: 171.8860s\n",
      "\titers: 200, epoch: 4 | loss: 0.0773474\n",
      "\tspeed: 0.0226s/iter; left time: 81.0493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0792804 Vali Loss: 0.0866306 Test Loss: 0.0979837\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0746874\n",
      "\tspeed: 0.0449s/iter; left time: 155.7042s\n",
      "\titers: 200, epoch: 5 | loss: 0.0745576\n",
      "\tspeed: 0.0224s/iter; left time: 75.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0749708 Vali Loss: 0.0876147 Test Loss: 0.0982907\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734099\n",
      "\tspeed: 0.0442s/iter; left time: 143.3839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0726197\n",
      "\tspeed: 0.0224s/iter; left time: 70.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0713834 Vali Loss: 0.0886993 Test Loss: 0.0983842\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0680743\n",
      "\tspeed: 0.0443s/iter; left time: 133.8580s\n",
      "\titers: 200, epoch: 7 | loss: 0.0658535\n",
      "\tspeed: 0.0223s/iter; left time: 65.2824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0679162 Vali Loss: 0.0891556 Test Loss: 0.0995721\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0637082\n",
      "\tspeed: 0.0452s/iter; left time: 126.6094s\n",
      "\titers: 200, epoch: 8 | loss: 0.0638428\n",
      "\tspeed: 0.0223s/iter; left time: 60.1778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0645114 Vali Loss: 0.0891259 Test Loss: 0.1003027\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02172878384590149, rmse:0.14740686118602753, mae:0.09710493683815002, rse:0.4330681264400482\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1338054\n",
      "\tspeed: 0.0246s/iter; left time: 107.0937s\n",
      "\titers: 200, epoch: 1 | loss: 0.1172974\n",
      "\tspeed: 0.0226s/iter; left time: 96.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.1397129 Vali Loss: 0.1100905 Test Loss: 0.1230639\n",
      "Validation loss decreased (inf --> 0.110091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0909255\n",
      "\tspeed: 0.0458s/iter; left time: 189.6162s\n",
      "\titers: 200, epoch: 2 | loss: 0.0843903\n",
      "\tspeed: 0.0224s/iter; left time: 90.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0946380 Vali Loss: 0.0877320 Test Loss: 0.0977113\n",
      "Validation loss decreased (0.110091 --> 0.087732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0839579\n",
      "\tspeed: 0.0458s/iter; left time: 179.1708s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794685\n",
      "\tspeed: 0.0223s/iter; left time: 85.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0840396 Vali Loss: 0.0863901 Test Loss: 0.0984656\n",
      "Validation loss decreased (0.087732 --> 0.086390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788893\n",
      "\tspeed: 0.0458s/iter; left time: 169.1486s\n",
      "\titers: 200, epoch: 4 | loss: 0.0761613\n",
      "\tspeed: 0.0224s/iter; left time: 80.5832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0789190 Vali Loss: 0.0869178 Test Loss: 0.0986370\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0742886\n",
      "\tspeed: 0.0478s/iter; left time: 165.6836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0743236\n",
      "\tspeed: 0.0223s/iter; left time: 75.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0746482 Vali Loss: 0.0868706 Test Loss: 0.0991525\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0722558\n",
      "\tspeed: 0.0442s/iter; left time: 143.5750s\n",
      "\titers: 200, epoch: 6 | loss: 0.0707610\n",
      "\tspeed: 0.0223s/iter; left time: 70.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0706094 Vali Loss: 0.0871155 Test Loss: 0.1002640\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0670408\n",
      "\tspeed: 0.0439s/iter; left time: 132.6848s\n",
      "\titers: 200, epoch: 7 | loss: 0.0647997\n",
      "\tspeed: 0.0224s/iter; left time: 65.4284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0668925 Vali Loss: 0.0879370 Test Loss: 0.1000142\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0650123\n",
      "\tspeed: 0.0447s/iter; left time: 125.0898s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613846\n",
      "\tspeed: 0.0224s/iter; left time: 60.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0635497 Vali Loss: 0.0889210 Test Loss: 0.1020326\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021894296631217003, rmse:0.14796721935272217, mae:0.09846556931734085, rse:0.43471434712409973\n",
      "Intermediate time for ES and pred_len 168: 00h:01m:58.41s\n",
      "Intermediate time for ES: 00h:07m:47.25s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0911608\n",
      "\tspeed: 0.0395s/iter; left time: 173.2211s\n",
      "\titers: 200, epoch: 1 | loss: 0.0807561\n",
      "\tspeed: 0.0220s/iter; left time: 93.9694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0953799 Vali Loss: 0.0820948 Test Loss: 0.0894879\n",
      "Validation loss decreased (inf --> 0.082095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0561930\n",
      "\tspeed: 0.0444s/iter; left time: 184.7348s\n",
      "\titers: 200, epoch: 2 | loss: 0.0492035\n",
      "\tspeed: 0.0220s/iter; left time: 89.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0542452 Vali Loss: 0.0557568 Test Loss: 0.0594116\n",
      "Validation loss decreased (0.082095 --> 0.055757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0486324\n",
      "\tspeed: 0.0473s/iter; left time: 185.8351s\n",
      "\titers: 200, epoch: 3 | loss: 0.0475799\n",
      "\tspeed: 0.0220s/iter; left time: 84.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0461456 Vali Loss: 0.0538717 Test Loss: 0.0575684\n",
      "Validation loss decreased (0.055757 --> 0.053872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0437132\n",
      "\tspeed: 0.0439s/iter; left time: 162.6741s\n",
      "\titers: 200, epoch: 4 | loss: 0.0451161\n",
      "\tspeed: 0.0220s/iter; left time: 79.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0440538 Vali Loss: 0.0533928 Test Loss: 0.0573033\n",
      "Validation loss decreased (0.053872 --> 0.053393).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0390914\n",
      "\tspeed: 0.0439s/iter; left time: 152.9549s\n",
      "\titers: 200, epoch: 5 | loss: 0.0422770\n",
      "\tspeed: 0.0220s/iter; left time: 74.5831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0426606 Vali Loss: 0.0522712 Test Loss: 0.0566506\n",
      "Validation loss decreased (0.053393 --> 0.052271).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0419594\n",
      "\tspeed: 0.0464s/iter; left time: 151.1885s\n",
      "\titers: 200, epoch: 6 | loss: 0.0421335\n",
      "\tspeed: 0.0220s/iter; left time: 69.6026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0415427 Vali Loss: 0.0521313 Test Loss: 0.0565895\n",
      "Validation loss decreased (0.052271 --> 0.052131).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0394318\n",
      "\tspeed: 0.0437s/iter; left time: 132.7002s\n",
      "\titers: 200, epoch: 7 | loss: 0.0366648\n",
      "\tspeed: 0.0220s/iter; left time: 64.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0405039 Vali Loss: 0.0522789 Test Loss: 0.0569994\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0414733\n",
      "\tspeed: 0.0435s/iter; left time: 122.3514s\n",
      "\titers: 200, epoch: 8 | loss: 0.0397425\n",
      "\tspeed: 0.0220s/iter; left time: 59.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0396449 Vali Loss: 0.0521628 Test Loss: 0.0571179\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0387222\n",
      "\tspeed: 0.0429s/iter; left time: 111.0310s\n",
      "\titers: 200, epoch: 9 | loss: 0.0377659\n",
      "\tspeed: 0.0220s/iter; left time: 54.7764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0387779 Vali Loss: 0.0524518 Test Loss: 0.0580054\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0399559\n",
      "\tspeed: 0.0440s/iter; left time: 103.9845s\n",
      "\titers: 200, epoch: 10 | loss: 0.0383337\n",
      "\tspeed: 0.0221s/iter; left time: 50.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0379001 Vali Loss: 0.0528825 Test Loss: 0.0582209\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0369181\n",
      "\tspeed: 0.0455s/iter; left time: 97.4036s\n",
      "\titers: 200, epoch: 11 | loss: 0.0370933\n",
      "\tspeed: 0.0222s/iter; left time: 45.3939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0371930 Vali Loss: 0.0523042 Test Loss: 0.0584522\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01019241288304329, rmse:0.1009574830532074, mae:0.056589506566524506, rse:0.38949114084243774\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0983568\n",
      "\tspeed: 0.0247s/iter; left time: 108.3098s\n",
      "\titers: 200, epoch: 1 | loss: 0.0811648\n",
      "\tspeed: 0.0220s/iter; left time: 94.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0986384 Vali Loss: 0.0830617 Test Loss: 0.0900622\n",
      "Validation loss decreased (inf --> 0.083062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0534172\n",
      "\tspeed: 0.0459s/iter; left time: 190.8347s\n",
      "\titers: 200, epoch: 2 | loss: 0.0459291\n",
      "\tspeed: 0.0220s/iter; left time: 89.4148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0541714 Vali Loss: 0.0558285 Test Loss: 0.0595404\n",
      "Validation loss decreased (0.083062 --> 0.055828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0488589\n",
      "\tspeed: 0.0455s/iter; left time: 179.1443s\n",
      "\titers: 200, epoch: 3 | loss: 0.0440432\n",
      "\tspeed: 0.0220s/iter; left time: 84.2449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0462337 Vali Loss: 0.0534941 Test Loss: 0.0573518\n",
      "Validation loss decreased (0.055828 --> 0.053494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0463716\n",
      "\tspeed: 0.0472s/iter; left time: 175.1546s\n",
      "\titers: 200, epoch: 4 | loss: 0.0456805\n",
      "\tspeed: 0.0220s/iter; left time: 79.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0441008 Vali Loss: 0.0527866 Test Loss: 0.0569766\n",
      "Validation loss decreased (0.053494 --> 0.052787).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0462096\n",
      "\tspeed: 0.0456s/iter; left time: 158.7527s\n",
      "\titers: 200, epoch: 5 | loss: 0.0410608\n",
      "\tspeed: 0.0220s/iter; left time: 74.5178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0427795 Vali Loss: 0.0525542 Test Loss: 0.0569405\n",
      "Validation loss decreased (0.052787 --> 0.052554).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0407355\n",
      "\tspeed: 0.0498s/iter; left time: 162.4428s\n",
      "\titers: 200, epoch: 6 | loss: 0.0419847\n",
      "\tspeed: 0.0221s/iter; left time: 70.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0416694 Vali Loss: 0.0518883 Test Loss: 0.0565364\n",
      "Validation loss decreased (0.052554 --> 0.051888).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0414056\n",
      "\tspeed: 0.0486s/iter; left time: 147.6256s\n",
      "\titers: 200, epoch: 7 | loss: 0.0415133\n",
      "\tspeed: 0.0221s/iter; left time: 64.8389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0407206 Vali Loss: 0.0519327 Test Loss: 0.0568358\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0397163\n",
      "\tspeed: 0.0451s/iter; left time: 126.8378s\n",
      "\titers: 200, epoch: 8 | loss: 0.0388439\n",
      "\tspeed: 0.0221s/iter; left time: 60.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0398980 Vali Loss: 0.0518868 Test Loss: 0.0571416\n",
      "Validation loss decreased (0.051888 --> 0.051887).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0371764\n",
      "\tspeed: 0.0451s/iter; left time: 116.6879s\n",
      "\titers: 200, epoch: 9 | loss: 0.0366343\n",
      "\tspeed: 0.0220s/iter; left time: 54.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0390674 Vali Loss: 0.0520276 Test Loss: 0.0576413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0378093\n",
      "\tspeed: 0.0440s/iter; left time: 103.9488s\n",
      "\titers: 200, epoch: 10 | loss: 0.0378744\n",
      "\tspeed: 0.0220s/iter; left time: 49.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0382958 Vali Loss: 0.0521671 Test Loss: 0.0580638\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0378447\n",
      "\tspeed: 0.0425s/iter; left time: 90.9655s\n",
      "\titers: 200, epoch: 11 | loss: 0.0375221\n",
      "\tspeed: 0.0220s/iter; left time: 44.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0375433 Vali Loss: 0.0524383 Test Loss: 0.0580152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0369047\n",
      "\tspeed: 0.0426s/iter; left time: 81.6378s\n",
      "\titers: 200, epoch: 12 | loss: 0.0374718\n",
      "\tspeed: 0.0220s/iter; left time: 40.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0368759 Vali Loss: 0.0522108 Test Loss: 0.0584778\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0371997\n",
      "\tspeed: 0.0426s/iter; left time: 72.0876s\n",
      "\titers: 200, epoch: 13 | loss: 0.0384833\n",
      "\tspeed: 0.0220s/iter; left time: 35.0443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0362783 Vali Loss: 0.0522735 Test Loss: 0.0587735\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010431569069623947, rmse:0.1021350547671318, mae:0.057141587138175964, rse:0.394034206867218\n",
      "Intermediate time for FR and pred_len 24: 00h:02m:50.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1006848\n",
      "\tspeed: 0.0397s/iter; left time: 174.0005s\n",
      "\titers: 200, epoch: 1 | loss: 0.0841898\n",
      "\tspeed: 0.0221s/iter; left time: 94.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.1028407 Vali Loss: 0.0909074 Test Loss: 0.1000355\n",
      "Validation loss decreased (inf --> 0.090907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0667737\n",
      "\tspeed: 0.0449s/iter; left time: 186.6393s\n",
      "\titers: 200, epoch: 2 | loss: 0.0597491\n",
      "\tspeed: 0.0222s/iter; left time: 90.1540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0683883 Vali Loss: 0.0734551 Test Loss: 0.0820000\n",
      "Validation loss decreased (0.090907 --> 0.073455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0597644\n",
      "\tspeed: 0.0536s/iter; left time: 210.6612s\n",
      "\titers: 200, epoch: 3 | loss: 0.0573469\n",
      "\tspeed: 0.0222s/iter; left time: 85.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0604713 Vali Loss: 0.0728116 Test Loss: 0.0829389\n",
      "Validation loss decreased (0.073455 --> 0.072812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0543406\n",
      "\tspeed: 0.0467s/iter; left time: 173.1935s\n",
      "\titers: 200, epoch: 4 | loss: 0.0559489\n",
      "\tspeed: 0.0222s/iter; left time: 80.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0555894 Vali Loss: 0.0726943 Test Loss: 0.0856126\n",
      "Validation loss decreased (0.072812 --> 0.072694).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0521473\n",
      "\tspeed: 0.0458s/iter; left time: 159.5019s\n",
      "\titers: 200, epoch: 5 | loss: 0.0497508\n",
      "\tspeed: 0.0222s/iter; left time: 75.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0508938 Vali Loss: 0.0734280 Test Loss: 0.0868193\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0467287\n",
      "\tspeed: 0.0453s/iter; left time: 147.8227s\n",
      "\titers: 200, epoch: 6 | loss: 0.0474530\n",
      "\tspeed: 0.0222s/iter; left time: 70.2187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0473731 Vali Loss: 0.0740491 Test Loss: 0.0903171\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0445259\n",
      "\tspeed: 0.0460s/iter; left time: 139.7311s\n",
      "\titers: 200, epoch: 7 | loss: 0.0429022\n",
      "\tspeed: 0.0222s/iter; left time: 65.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0449064 Vali Loss: 0.0749877 Test Loss: 0.0900412\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0447864\n",
      "\tspeed: 0.0459s/iter; left time: 129.0161s\n",
      "\titers: 200, epoch: 8 | loss: 0.0412697\n",
      "\tspeed: 0.0223s/iter; left time: 60.5712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0427259 Vali Loss: 0.0744871 Test Loss: 0.0900806\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0412090\n",
      "\tspeed: 0.0458s/iter; left time: 118.6480s\n",
      "\titers: 200, epoch: 9 | loss: 0.0411860\n",
      "\tspeed: 0.0225s/iter; left time: 55.9844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0410810 Vali Loss: 0.0739628 Test Loss: 0.0906877\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022053049877285957, rmse:0.14850269258022308, mae:0.08561256527900696, rse:0.5744478702545166\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1005642\n",
      "\tspeed: 0.0244s/iter; left time: 106.7894s\n",
      "\titers: 200, epoch: 1 | loss: 0.0917427\n",
      "\tspeed: 0.0221s/iter; left time: 94.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.1031050 Vali Loss: 0.0911626 Test Loss: 0.1002582\n",
      "Validation loss decreased (inf --> 0.091163).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0699997\n",
      "\tspeed: 0.0464s/iter; left time: 192.8545s\n",
      "\titers: 200, epoch: 2 | loss: 0.0637312\n",
      "\tspeed: 0.0222s/iter; left time: 90.1859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0683236 Vali Loss: 0.0735162 Test Loss: 0.0822804\n",
      "Validation loss decreased (0.091163 --> 0.073516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0605401\n",
      "\tspeed: 0.0471s/iter; left time: 185.0752s\n",
      "\titers: 200, epoch: 3 | loss: 0.0607821\n",
      "\tspeed: 0.0223s/iter; left time: 85.4301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0604257 Vali Loss: 0.0721129 Test Loss: 0.0824257\n",
      "Validation loss decreased (0.073516 --> 0.072113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0555506\n",
      "\tspeed: 0.0492s/iter; left time: 182.4720s\n",
      "\titers: 200, epoch: 4 | loss: 0.0568947\n",
      "\tspeed: 0.0222s/iter; left time: 80.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0552945 Vali Loss: 0.0730396 Test Loss: 0.0871446\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0492285\n",
      "\tspeed: 0.0458s/iter; left time: 159.7724s\n",
      "\titers: 200, epoch: 5 | loss: 0.0476777\n",
      "\tspeed: 0.0223s/iter; left time: 75.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0505104 Vali Loss: 0.0731663 Test Loss: 0.0874221\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0488765\n",
      "\tspeed: 0.0447s/iter; left time: 145.7902s\n",
      "\titers: 200, epoch: 6 | loss: 0.0477134\n",
      "\tspeed: 0.0222s/iter; left time: 70.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0469335 Vali Loss: 0.0743040 Test Loss: 0.0891248\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0456722\n",
      "\tspeed: 0.0447s/iter; left time: 135.6284s\n",
      "\titers: 200, epoch: 7 | loss: 0.0439361\n",
      "\tspeed: 0.0224s/iter; left time: 65.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0442663 Vali Loss: 0.0741631 Test Loss: 0.0898651\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0420532\n",
      "\tspeed: 0.0447s/iter; left time: 125.8808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0395115\n",
      "\tspeed: 0.0224s/iter; left time: 60.7868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0422339 Vali Loss: 0.0745660 Test Loss: 0.0915339\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019726678729057312, rmse:0.14045169949531555, mae:0.08242567628622055, rse:0.543304443359375\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:06.23s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1056457\n",
      "\tspeed: 0.0398s/iter; left time: 173.6812s\n",
      "\titers: 200, epoch: 1 | loss: 0.0920094\n",
      "\tspeed: 0.0224s/iter; left time: 95.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 223 | Train Loss: 0.1057240 Vali Loss: 0.0936650 Test Loss: 0.1019153\n",
      "Validation loss decreased (inf --> 0.093665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0718475\n",
      "\tspeed: 0.0447s/iter; left time: 185.1133s\n",
      "\titers: 200, epoch: 2 | loss: 0.0731005\n",
      "\tspeed: 0.0224s/iter; left time: 90.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0723086 Vali Loss: 0.0779335 Test Loss: 0.0873305\n",
      "Validation loss decreased (0.093665 --> 0.077934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0632716\n",
      "\tspeed: 0.0459s/iter; left time: 179.8549s\n",
      "\titers: 200, epoch: 3 | loss: 0.0641079\n",
      "\tspeed: 0.0224s/iter; left time: 85.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0631816 Vali Loss: 0.0758860 Test Loss: 0.0896951\n",
      "Validation loss decreased (0.077934 --> 0.075886).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0551088\n",
      "\tspeed: 0.0459s/iter; left time: 169.5448s\n",
      "\titers: 200, epoch: 4 | loss: 0.0547754\n",
      "\tspeed: 0.0225s/iter; left time: 80.7396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0568533 Vali Loss: 0.0776557 Test Loss: 0.0928236\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0526990\n",
      "\tspeed: 0.0449s/iter; left time: 155.9181s\n",
      "\titers: 200, epoch: 5 | loss: 0.0493257\n",
      "\tspeed: 0.0224s/iter; left time: 75.5719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0520216 Vali Loss: 0.0776104 Test Loss: 0.0933026\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0494825\n",
      "\tspeed: 0.0439s/iter; left time: 142.5911s\n",
      "\titers: 200, epoch: 6 | loss: 0.0487090\n",
      "\tspeed: 0.0225s/iter; left time: 70.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0485547 Vali Loss: 0.0779353 Test Loss: 0.0935854\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0466170\n",
      "\tspeed: 0.0443s/iter; left time: 133.9005s\n",
      "\titers: 200, epoch: 7 | loss: 0.0462868\n",
      "\tspeed: 0.0224s/iter; left time: 65.4560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0459587 Vali Loss: 0.0782540 Test Loss: 0.0941730\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0445945\n",
      "\tspeed: 0.0442s/iter; left time: 123.8177s\n",
      "\titers: 200, epoch: 8 | loss: 0.0431015\n",
      "\tspeed: 0.0225s/iter; left time: 60.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0438796 Vali Loss: 0.0789876 Test Loss: 0.0948573\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021620899438858032, rmse:0.1470404714345932, mae:0.08969511091709137, rse:0.5695016980171204\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0991714\n",
      "\tspeed: 0.0242s/iter; left time: 105.4279s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885712\n",
      "\tspeed: 0.0224s/iter; left time: 95.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.1043165 Vali Loss: 0.0933984 Test Loss: 0.1014372\n",
      "Validation loss decreased (inf --> 0.093398).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0710609\n",
      "\tspeed: 0.0452s/iter; left time: 187.1805s\n",
      "\titers: 200, epoch: 2 | loss: 0.0618889\n",
      "\tspeed: 0.0225s/iter; left time: 90.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0721745 Vali Loss: 0.0774508 Test Loss: 0.0867138\n",
      "Validation loss decreased (0.093398 --> 0.077451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0610502\n",
      "\tspeed: 0.0455s/iter; left time: 178.2605s\n",
      "\titers: 200, epoch: 3 | loss: 0.0590557\n",
      "\tspeed: 0.0225s/iter; left time: 85.7997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0635017 Vali Loss: 0.0759463 Test Loss: 0.0875126\n",
      "Validation loss decreased (0.077451 --> 0.075946).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0575557\n",
      "\tspeed: 0.0448s/iter; left time: 165.3782s\n",
      "\titers: 200, epoch: 4 | loss: 0.0550404\n",
      "\tspeed: 0.0224s/iter; left time: 80.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0579271 Vali Loss: 0.0790097 Test Loss: 0.0919720\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0552282\n",
      "\tspeed: 0.0460s/iter; left time: 159.5844s\n",
      "\titers: 200, epoch: 5 | loss: 0.0517130\n",
      "\tspeed: 0.0225s/iter; left time: 75.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0529827 Vali Loss: 0.0791752 Test Loss: 0.0956786\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0491072\n",
      "\tspeed: 0.0445s/iter; left time: 144.5271s\n",
      "\titers: 200, epoch: 6 | loss: 0.0490277\n",
      "\tspeed: 0.0225s/iter; left time: 70.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0493609 Vali Loss: 0.0793608 Test Loss: 0.0970479\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0464880\n",
      "\tspeed: 0.0440s/iter; left time: 132.9713s\n",
      "\titers: 200, epoch: 7 | loss: 0.0456919\n",
      "\tspeed: 0.0224s/iter; left time: 65.5195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0465144 Vali Loss: 0.0802678 Test Loss: 0.0969906\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0447792\n",
      "\tspeed: 0.0438s/iter; left time: 122.5531s\n",
      "\titers: 200, epoch: 8 | loss: 0.0422901\n",
      "\tspeed: 0.0225s/iter; left time: 60.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0443371 Vali Loss: 0.0795111 Test Loss: 0.0977988\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02099021151661873, rmse:0.1448799967765808, mae:0.08751260489225388, rse:0.5611339211463928\n",
      "Intermediate time for FR and pred_len 168: 00h:01m:56.97s\n",
      "Intermediate time for FR: 00h:06m:53.36s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1278432\n",
      "\tspeed: 0.0403s/iter; left time: 176.4808s\n",
      "\titers: 200, epoch: 1 | loss: 0.1199756\n",
      "\tspeed: 0.0221s/iter; left time: 94.6191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.1362877 Vali Loss: 0.0958211 Test Loss: 0.0981545\n",
      "Validation loss decreased (inf --> 0.095821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0730210\n",
      "\tspeed: 0.0448s/iter; left time: 186.1073s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685680\n",
      "\tspeed: 0.0221s/iter; left time: 89.8356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0737874 Vali Loss: 0.0606424 Test Loss: 0.0634204\n",
      "Validation loss decreased (0.095821 --> 0.060642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0679964\n",
      "\tspeed: 0.0455s/iter; left time: 179.1425s\n",
      "\titers: 200, epoch: 3 | loss: 0.0627244\n",
      "\tspeed: 0.0221s/iter; left time: 84.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0626436 Vali Loss: 0.0585590 Test Loss: 0.0609500\n",
      "Validation loss decreased (0.060642 --> 0.058559).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0576157\n",
      "\tspeed: 0.0441s/iter; left time: 163.6331s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638441\n",
      "\tspeed: 0.0221s/iter; left time: 79.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0600721 Vali Loss: 0.0572869 Test Loss: 0.0595370\n",
      "Validation loss decreased (0.058559 --> 0.057287).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0601263\n",
      "\tspeed: 0.0447s/iter; left time: 155.6338s\n",
      "\titers: 200, epoch: 5 | loss: 0.0590720\n",
      "\tspeed: 0.0222s/iter; left time: 75.0241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0583885 Vali Loss: 0.0561951 Test Loss: 0.0586180\n",
      "Validation loss decreased (0.057287 --> 0.056195).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568630\n",
      "\tspeed: 0.0444s/iter; left time: 144.7807s\n",
      "\titers: 200, epoch: 6 | loss: 0.0588873\n",
      "\tspeed: 0.0221s/iter; left time: 69.9577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0571105 Vali Loss: 0.0560492 Test Loss: 0.0585387\n",
      "Validation loss decreased (0.056195 --> 0.056049).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0534128\n",
      "\tspeed: 0.0449s/iter; left time: 136.3684s\n",
      "\titers: 200, epoch: 7 | loss: 0.0566401\n",
      "\tspeed: 0.0221s/iter; left time: 65.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0559917 Vali Loss: 0.0559686 Test Loss: 0.0586595\n",
      "Validation loss decreased (0.056049 --> 0.055969).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0540253\n",
      "\tspeed: 0.0445s/iter; left time: 125.2643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0523734\n",
      "\tspeed: 0.0221s/iter; left time: 59.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0550626 Vali Loss: 0.0557020 Test Loss: 0.0581373\n",
      "Validation loss decreased (0.055969 --> 0.055702).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0549227\n",
      "\tspeed: 0.0441s/iter; left time: 114.2035s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555563\n",
      "\tspeed: 0.0220s/iter; left time: 54.8628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0541545 Vali Loss: 0.0554387 Test Loss: 0.0579014\n",
      "Validation loss decreased (0.055702 --> 0.055439).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0573516\n",
      "\tspeed: 0.0443s/iter; left time: 104.8230s\n",
      "\titers: 200, epoch: 10 | loss: 0.0533080\n",
      "\tspeed: 0.0223s/iter; left time: 50.6226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0534064 Vali Loss: 0.0554795 Test Loss: 0.0580060\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0537935\n",
      "\tspeed: 0.0433s/iter; left time: 92.7225s\n",
      "\titers: 200, epoch: 11 | loss: 0.0519395\n",
      "\tspeed: 0.0221s/iter; left time: 45.1442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0526716 Vali Loss: 0.0553332 Test Loss: 0.0582383\n",
      "Validation loss decreased (0.055439 --> 0.055333).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494004\n",
      "\tspeed: 0.0442s/iter; left time: 84.6628s\n",
      "\titers: 200, epoch: 12 | loss: 0.0503696\n",
      "\tspeed: 0.0222s/iter; left time: 40.3168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0519590 Vali Loss: 0.0552357 Test Loss: 0.0584522\n",
      "Validation loss decreased (0.055333 --> 0.055236).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0522351\n",
      "\tspeed: 0.0446s/iter; left time: 75.5378s\n",
      "\titers: 200, epoch: 13 | loss: 0.0554844\n",
      "\tspeed: 0.0221s/iter; left time: 35.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0512310 Vali Loss: 0.0556980 Test Loss: 0.0582841\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0527922\n",
      "\tspeed: 0.0441s/iter; left time: 64.7681s\n",
      "\titers: 200, epoch: 14 | loss: 0.0496648\n",
      "\tspeed: 0.0221s/iter; left time: 30.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0505910 Vali Loss: 0.0554339 Test Loss: 0.0585908\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0505742\n",
      "\tspeed: 0.0428s/iter; left time: 53.3226s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552145\n",
      "\tspeed: 0.0221s/iter; left time: 25.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0499754 Vali Loss: 0.0557357 Test Loss: 0.0589469\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0501169\n",
      "\tspeed: 0.0435s/iter; left time: 44.3919s\n",
      "\titers: 200, epoch: 16 | loss: 0.0476602\n",
      "\tspeed: 0.0223s/iter; left time: 20.5843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0494236 Vali Loss: 0.0556930 Test Loss: 0.0588406\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0540575\n",
      "\tspeed: 0.0434s/iter; left time: 34.5807s\n",
      "\titers: 200, epoch: 17 | loss: 0.0460231\n",
      "\tspeed: 0.0221s/iter; left time: 15.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0488599 Vali Loss: 0.0560844 Test Loss: 0.0593362\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010351636447012424, rmse:0.10174299031496048, mae:0.05845222249627113, rse:0.3844366669654846\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1312290\n",
      "\tspeed: 0.0239s/iter; left time: 104.5800s\n",
      "\titers: 200, epoch: 1 | loss: 0.1132838\n",
      "\tspeed: 0.0221s/iter; left time: 94.6417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.1434084 Vali Loss: 0.0982049 Test Loss: 0.1005447\n",
      "Validation loss decreased (inf --> 0.098205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0674736\n",
      "\tspeed: 0.0449s/iter; left time: 186.7286s\n",
      "\titers: 200, epoch: 2 | loss: 0.0681145\n",
      "\tspeed: 0.0221s/iter; left time: 89.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0744928 Vali Loss: 0.0611276 Test Loss: 0.0633811\n",
      "Validation loss decreased (0.098205 --> 0.061128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0622577\n",
      "\tspeed: 0.0485s/iter; left time: 190.7232s\n",
      "\titers: 200, epoch: 3 | loss: 0.0642815\n",
      "\tspeed: 0.0221s/iter; left time: 84.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0627514 Vali Loss: 0.0584585 Test Loss: 0.0605055\n",
      "Validation loss decreased (0.061128 --> 0.058458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0570491\n",
      "\tspeed: 0.0435s/iter; left time: 161.3850s\n",
      "\titers: 200, epoch: 4 | loss: 0.0608197\n",
      "\tspeed: 0.0221s/iter; left time: 79.7839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0602316 Vali Loss: 0.0581894 Test Loss: 0.0604754\n",
      "Validation loss decreased (0.058458 --> 0.058189).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0571427\n",
      "\tspeed: 0.0434s/iter; left time: 151.1813s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591655\n",
      "\tspeed: 0.0221s/iter; left time: 74.7114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0585666 Vali Loss: 0.0570316 Test Loss: 0.0593375\n",
      "Validation loss decreased (0.058189 --> 0.057032).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569229\n",
      "\tspeed: 0.0446s/iter; left time: 145.4980s\n",
      "\titers: 200, epoch: 6 | loss: 0.0601685\n",
      "\tspeed: 0.0221s/iter; left time: 69.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0572205 Vali Loss: 0.0561985 Test Loss: 0.0586197\n",
      "Validation loss decreased (0.057032 --> 0.056198).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0528390\n",
      "\tspeed: 0.0443s/iter; left time: 134.6254s\n",
      "\titers: 200, epoch: 7 | loss: 0.0560399\n",
      "\tspeed: 0.0220s/iter; left time: 64.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0561812 Vali Loss: 0.0559815 Test Loss: 0.0584007\n",
      "Validation loss decreased (0.056198 --> 0.055982).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0566561\n",
      "\tspeed: 0.0432s/iter; left time: 121.5715s\n",
      "\titers: 200, epoch: 8 | loss: 0.0531043\n",
      "\tspeed: 0.0220s/iter; left time: 59.6308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0552645 Vali Loss: 0.0561232 Test Loss: 0.0582675\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0574572\n",
      "\tspeed: 0.0422s/iter; left time: 109.1267s\n",
      "\titers: 200, epoch: 9 | loss: 0.0525047\n",
      "\tspeed: 0.0221s/iter; left time: 55.0661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0542702 Vali Loss: 0.0558798 Test Loss: 0.0580742\n",
      "Validation loss decreased (0.055982 --> 0.055880).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514821\n",
      "\tspeed: 0.0442s/iter; left time: 104.4473s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550405\n",
      "\tspeed: 0.0222s/iter; left time: 50.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0534769 Vali Loss: 0.0561165 Test Loss: 0.0583153\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0494045\n",
      "\tspeed: 0.0429s/iter; left time: 91.7487s\n",
      "\titers: 200, epoch: 11 | loss: 0.0544998\n",
      "\tspeed: 0.0222s/iter; left time: 45.3403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0527047 Vali Loss: 0.0559758 Test Loss: 0.0582508\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558888\n",
      "\tspeed: 0.0430s/iter; left time: 82.4352s\n",
      "\titers: 200, epoch: 12 | loss: 0.0501107\n",
      "\tspeed: 0.0223s/iter; left time: 40.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0519439 Vali Loss: 0.0558040 Test Loss: 0.0584697\n",
      "Validation loss decreased (0.055880 --> 0.055804).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0464681\n",
      "\tspeed: 0.0440s/iter; left time: 74.4818s\n",
      "\titers: 200, epoch: 13 | loss: 0.0487312\n",
      "\tspeed: 0.0221s/iter; left time: 35.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0512102 Vali Loss: 0.0558723 Test Loss: 0.0584111\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0515612\n",
      "\tspeed: 0.0426s/iter; left time: 62.5964s\n",
      "\titers: 200, epoch: 14 | loss: 0.0508993\n",
      "\tspeed: 0.0221s/iter; left time: 30.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0505620 Vali Loss: 0.0561245 Test Loss: 0.0586363\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0493988\n",
      "\tspeed: 0.0426s/iter; left time: 53.0185s\n",
      "\titers: 200, epoch: 15 | loss: 0.0481921\n",
      "\tspeed: 0.0222s/iter; left time: 25.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0499058 Vali Loss: 0.0561699 Test Loss: 0.0588772\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0517682\n",
      "\tspeed: 0.0428s/iter; left time: 43.7099s\n",
      "\titers: 200, epoch: 16 | loss: 0.0486397\n",
      "\tspeed: 0.0223s/iter; left time: 20.5641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0493334 Vali Loss: 0.0565590 Test Loss: 0.0592585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0502274\n",
      "\tspeed: 0.0428s/iter; left time: 34.1402s\n",
      "\titers: 200, epoch: 17 | loss: 0.0491273\n",
      "\tspeed: 0.0221s/iter; left time: 15.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0487718 Vali Loss: 0.0566396 Test Loss: 0.0595277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010335784405469894, rmse:0.10166505724191666, mae:0.05846967175602913, rse:0.3841421902179718\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:53.46s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1406602\n",
      "\tspeed: 0.0396s/iter; left time: 173.4839s\n",
      "\titers: 200, epoch: 1 | loss: 0.1232709\n",
      "\tspeed: 0.0222s/iter; left time: 95.2344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.1463149 Vali Loss: 0.1063972 Test Loss: 0.1096973\n",
      "Validation loss decreased (inf --> 0.106397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0882624\n",
      "\tspeed: 0.0446s/iter; left time: 185.3561s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824391\n",
      "\tspeed: 0.0223s/iter; left time: 90.2859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0918562 Vali Loss: 0.0795108 Test Loss: 0.0841194\n",
      "Validation loss decreased (0.106397 --> 0.079511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0812526\n",
      "\tspeed: 0.0456s/iter; left time: 179.2393s\n",
      "\titers: 200, epoch: 3 | loss: 0.0784772\n",
      "\tspeed: 0.0222s/iter; left time: 85.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0820270 Vali Loss: 0.0783789 Test Loss: 0.0819392\n",
      "Validation loss decreased (0.079511 --> 0.078379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744383\n",
      "\tspeed: 0.0454s/iter; left time: 168.5465s\n",
      "\titers: 200, epoch: 4 | loss: 0.0777021\n",
      "\tspeed: 0.0223s/iter; left time: 80.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0783910 Vali Loss: 0.0788257 Test Loss: 0.0830169\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0753594\n",
      "\tspeed: 0.0442s/iter; left time: 153.9169s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750151\n",
      "\tspeed: 0.0223s/iter; left time: 75.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0734081 Vali Loss: 0.0819957 Test Loss: 0.0856044\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0659106\n",
      "\tspeed: 0.0441s/iter; left time: 143.8063s\n",
      "\titers: 200, epoch: 6 | loss: 0.0659576\n",
      "\tspeed: 0.0222s/iter; left time: 70.1749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0686825 Vali Loss: 0.0842883 Test Loss: 0.0852429\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0648111\n",
      "\tspeed: 0.0444s/iter; left time: 134.8696s\n",
      "\titers: 200, epoch: 7 | loss: 0.0614157\n",
      "\tspeed: 0.0222s/iter; left time: 65.2844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0650621 Vali Loss: 0.0839392 Test Loss: 0.0866236\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0651447\n",
      "\tspeed: 0.0440s/iter; left time: 123.8320s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613163\n",
      "\tspeed: 0.0222s/iter; left time: 60.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0623451 Vali Loss: 0.0845894 Test Loss: 0.0871178\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018120603635907173, rmse:0.1346127986907959, mae:0.08193915337324142, rse:0.5089855194091797\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1431607\n",
      "\tspeed: 0.0244s/iter; left time: 106.7205s\n",
      "\titers: 200, epoch: 1 | loss: 0.1226398\n",
      "\tspeed: 0.0223s/iter; left time: 95.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.1465745 Vali Loss: 0.1063707 Test Loss: 0.1097031\n",
      "Validation loss decreased (inf --> 0.106371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0898145\n",
      "\tspeed: 0.0452s/iter; left time: 188.1016s\n",
      "\titers: 200, epoch: 2 | loss: 0.0898023\n",
      "\tspeed: 0.0223s/iter; left time: 90.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0918464 Vali Loss: 0.0796784 Test Loss: 0.0837768\n",
      "Validation loss decreased (0.106371 --> 0.079678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820685\n",
      "\tspeed: 0.0451s/iter; left time: 177.2884s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804370\n",
      "\tspeed: 0.0223s/iter; left time: 85.3903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0818808 Vali Loss: 0.0782289 Test Loss: 0.0822492\n",
      "Validation loss decreased (0.079678 --> 0.078229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801883\n",
      "\tspeed: 0.0466s/iter; left time: 172.7831s\n",
      "\titers: 200, epoch: 4 | loss: 0.0770322\n",
      "\tspeed: 0.0222s/iter; left time: 80.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0781260 Vali Loss: 0.0790618 Test Loss: 0.0833921\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0714568\n",
      "\tspeed: 0.0439s/iter; left time: 152.9201s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724024\n",
      "\tspeed: 0.0222s/iter; left time: 75.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0734421 Vali Loss: 0.0818351 Test Loss: 0.0865005\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0687422\n",
      "\tspeed: 0.0441s/iter; left time: 143.6745s\n",
      "\titers: 200, epoch: 6 | loss: 0.0683053\n",
      "\tspeed: 0.0223s/iter; left time: 70.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0687262 Vali Loss: 0.0829564 Test Loss: 0.0874128\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0646902\n",
      "\tspeed: 0.0443s/iter; left time: 134.5349s\n",
      "\titers: 200, epoch: 7 | loss: 0.0637687\n",
      "\tspeed: 0.0223s/iter; left time: 65.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0650412 Vali Loss: 0.0835494 Test Loss: 0.0889566\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0622228\n",
      "\tspeed: 0.0437s/iter; left time: 123.0097s\n",
      "\titers: 200, epoch: 8 | loss: 0.0603192\n",
      "\tspeed: 0.0223s/iter; left time: 60.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0619382 Vali Loss: 0.0838071 Test Loss: 0.0882461\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01840209774672985, rmse:0.13565433025360107, mae:0.08224920183420181, rse:0.5129236578941345\n",
      "Intermediate time for IT and pred_len 96: 00h:01m:55.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1423591\n",
      "\tspeed: 0.0387s/iter; left time: 168.9553s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247035\n",
      "\tspeed: 0.0224s/iter; left time: 95.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.1496753 Vali Loss: 0.1086939 Test Loss: 0.1115384\n",
      "Validation loss decreased (inf --> 0.108694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0945189\n",
      "\tspeed: 0.0450s/iter; left time: 186.0453s\n",
      "\titers: 200, epoch: 2 | loss: 0.0915999\n",
      "\tspeed: 0.0224s/iter; left time: 90.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0958328 Vali Loss: 0.0841946 Test Loss: 0.0881004\n",
      "Validation loss decreased (0.108694 --> 0.084195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0892303\n",
      "\tspeed: 0.0455s/iter; left time: 178.0036s\n",
      "\titers: 200, epoch: 3 | loss: 0.0885527\n",
      "\tspeed: 0.0224s/iter; left time: 85.4416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0856628 Vali Loss: 0.0844716 Test Loss: 0.0865444\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801477\n",
      "\tspeed: 0.0441s/iter; left time: 162.6857s\n",
      "\titers: 200, epoch: 4 | loss: 0.0779318\n",
      "\tspeed: 0.0224s/iter; left time: 80.4699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0803572 Vali Loss: 0.0860760 Test Loss: 0.0882949\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0737198\n",
      "\tspeed: 0.0444s/iter; left time: 153.9110s\n",
      "\titers: 200, epoch: 5 | loss: 0.0765113\n",
      "\tspeed: 0.0225s/iter; left time: 75.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0744970 Vali Loss: 0.0889429 Test Loss: 0.0900481\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0701593\n",
      "\tspeed: 0.0447s/iter; left time: 145.1644s\n",
      "\titers: 200, epoch: 6 | loss: 0.0692381\n",
      "\tspeed: 0.0224s/iter; left time: 70.6155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0699709 Vali Loss: 0.0898496 Test Loss: 0.0908735\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0679185\n",
      "\tspeed: 0.0456s/iter; left time: 137.7382s\n",
      "\titers: 200, epoch: 7 | loss: 0.0630262\n",
      "\tspeed: 0.0225s/iter; left time: 65.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0663681 Vali Loss: 0.0885903 Test Loss: 0.0913930\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019992955029010773, rmse:0.1413964480161667, mae:0.08810041099786758, rse:0.5351320505142212\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1404880\n",
      "\tspeed: 0.0284s/iter; left time: 123.7550s\n",
      "\titers: 200, epoch: 1 | loss: 0.1218658\n",
      "\tspeed: 0.0225s/iter; left time: 95.6780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.1495159 Vali Loss: 0.1086430 Test Loss: 0.1113816\n",
      "Validation loss decreased (inf --> 0.108643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0947164\n",
      "\tspeed: 0.0464s/iter; left time: 191.8074s\n",
      "\titers: 200, epoch: 2 | loss: 0.0872592\n",
      "\tspeed: 0.0224s/iter; left time: 90.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0958824 Vali Loss: 0.0842354 Test Loss: 0.0879539\n",
      "Validation loss decreased (0.108643 --> 0.084235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0828680\n",
      "\tspeed: 0.0454s/iter; left time: 177.6948s\n",
      "\titers: 200, epoch: 3 | loss: 0.0856310\n",
      "\tspeed: 0.0225s/iter; left time: 85.6719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0855720 Vali Loss: 0.0846827 Test Loss: 0.0879662\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820475\n",
      "\tspeed: 0.0441s/iter; left time: 162.7253s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760696\n",
      "\tspeed: 0.0224s/iter; left time: 80.5821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0801973 Vali Loss: 0.0866909 Test Loss: 0.0899356\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758944\n",
      "\tspeed: 0.0441s/iter; left time: 152.8667s\n",
      "\titers: 200, epoch: 5 | loss: 0.0725707\n",
      "\tspeed: 0.0225s/iter; left time: 75.7098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0741449 Vali Loss: 0.0878185 Test Loss: 0.0923809\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0708352\n",
      "\tspeed: 0.0441s/iter; left time: 143.0451s\n",
      "\titers: 200, epoch: 6 | loss: 0.0676354\n",
      "\tspeed: 0.0225s/iter; left time: 70.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0694595 Vali Loss: 0.0874840 Test Loss: 0.0934459\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0662269\n",
      "\tspeed: 0.0439s/iter; left time: 132.7135s\n",
      "\titers: 200, epoch: 7 | loss: 0.0632087\n",
      "\tspeed: 0.0225s/iter; left time: 65.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0656503 Vali Loss: 0.0889737 Test Loss: 0.0943873\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019958944991230965, rmse:0.14127613604068756, mae:0.08795391023159027, rse:0.5346766710281372\n",
      "Intermediate time for IT and pred_len 168: 00h:01m:43.60s\n",
      "Intermediate time for IT: 00h:07m:33.05s\n",
      "Total time: 00h:41m:40.27s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>0.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.0569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.0840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.0821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0215  0.1466  0.0920\n",
       "        96        0.0418  0.2045  0.1345\n",
       "        168       0.0461  0.2148  0.1428\n",
       "ES      24        0.0099  0.0997  0.0613\n",
       "        96        0.0192  0.1385  0.0908\n",
       "        168       0.0218  0.1477  0.0978\n",
       "FR      24        0.0103  0.1015  0.0569\n",
       "        96        0.0209  0.1445  0.0840\n",
       "        168       0.0213  0.1460  0.0886\n",
       "GB      24        0.0251  0.1586  0.1015\n",
       "        96        0.0428  0.2069  0.1411\n",
       "        168       0.0501  0.2237  0.1511\n",
       "IT      24        0.0103  0.1017  0.0585\n",
       "        96        0.0183  0.1351  0.0821\n",
       "        168       0.0200  0.1413  0.0880"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1185825\n",
      "\tspeed: 0.6688s/iter; left time: 2929.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1090781\n",
      "\tspeed: 0.6481s/iter; left time: 2774.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:25.38s\n",
      "Steps: 224 | Train Loss: 0.1187725 Vali Loss: 0.1100739 Test Loss: 0.1098653\n",
      "Validation loss decreased (inf --> 0.110074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894905\n",
      "\tspeed: 1.0742s/iter; left time: 4465.5195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864838\n",
      "\tspeed: 0.6444s/iter; left time: 2614.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:26.19s\n",
      "Steps: 224 | Train Loss: 0.0909381 Vali Loss: 0.1002815 Test Loss: 0.1011409\n",
      "Validation loss decreased (0.110074 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831252\n",
      "\tspeed: 1.0301s/iter; left time: 4051.2992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806472\n",
      "\tspeed: 0.6468s/iter; left time: 2479.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:25.18s\n",
      "Steps: 224 | Train Loss: 0.0837995 Vali Loss: 0.0962656 Test Loss: 0.0981424\n",
      "Validation loss decreased (0.100282 --> 0.096266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774977\n",
      "\tspeed: 1.0416s/iter; left time: 3863.3389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760295\n",
      "\tspeed: 0.6417s/iter; left time: 2315.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.62s\n",
      "Steps: 224 | Train Loss: 0.0802265 Vali Loss: 0.0948865 Test Loss: 0.0951428\n",
      "Validation loss decreased (0.096266 --> 0.094887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776035\n",
      "\tspeed: 1.0485s/iter; left time: 3653.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754470\n",
      "\tspeed: 0.6488s/iter; left time: 2196.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0781352 Vali Loss: 0.0920579 Test Loss: 0.0930737\n",
      "Validation loss decreased (0.094887 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768398\n",
      "\tspeed: 1.0371s/iter; left time: 3381.9026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745844\n",
      "\tspeed: 0.6492s/iter; left time: 2052.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0772739 Vali Loss: 0.0921749 Test Loss: 0.0929615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779816\n",
      "\tspeed: 1.0322s/iter; left time: 3134.9141s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759176\n",
      "\tspeed: 0.6528s/iter; left time: 1917.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:26.20s\n",
      "Steps: 224 | Train Loss: 0.0761425 Vali Loss: 0.0916203 Test Loss: 0.0923960\n",
      "Validation loss decreased (0.092058 --> 0.091620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725002\n",
      "\tspeed: 1.0339s/iter; left time: 2908.4458s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762453\n",
      "\tspeed: 0.6654s/iter; left time: 1805.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:26.01s\n",
      "Steps: 224 | Train Loss: 0.0752119 Vali Loss: 0.0908312 Test Loss: 0.0916540\n",
      "Validation loss decreased (0.091620 --> 0.090831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725041\n",
      "\tspeed: 1.0305s/iter; left time: 2667.9906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683068\n",
      "\tspeed: 0.6454s/iter; left time: 1606.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0745990 Vali Loss: 0.0904099 Test Loss: 0.0917372\n",
      "Validation loss decreased (0.090831 --> 0.090410).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700386\n",
      "\tspeed: 1.0345s/iter; left time: 2446.5496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721033\n",
      "\tspeed: 0.6512s/iter; left time: 1474.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:25.67s\n",
      "Steps: 224 | Train Loss: 0.0740525 Vali Loss: 0.0897951 Test Loss: 0.0912578\n",
      "Validation loss decreased (0.090410 --> 0.089795).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0666174\n",
      "\tspeed: 1.0623s/iter; left time: 2274.3769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760651\n",
      "\tspeed: 0.6506s/iter; left time: 1327.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:27.15s\n",
      "Steps: 224 | Train Loss: 0.0736123 Vali Loss: 0.0899318 Test Loss: 0.0916627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0749207\n",
      "\tspeed: 1.0237s/iter; left time: 1962.4604s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740589\n",
      "\tspeed: 0.7478s/iter; left time: 1358.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:02m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0732611 Vali Loss: 0.0894925 Test Loss: 0.0912984\n",
      "Validation loss decreased (0.089795 --> 0.089493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0752842\n",
      "\tspeed: 1.2674s/iter; left time: 2145.6531s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713753\n",
      "\tspeed: 0.8199s/iter; left time: 1306.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:02m:58.25s\n",
      "Steps: 224 | Train Loss: 0.0728936 Vali Loss: 0.0895770 Test Loss: 0.0911928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732628\n",
      "\tspeed: 1.4032s/iter; left time: 2061.2683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0704660\n",
      "\tspeed: 0.7742s/iter; left time: 1059.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:02m:53.68s\n",
      "Steps: 224 | Train Loss: 0.0725533 Vali Loss: 0.0897301 Test Loss: 0.0914722\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720317\n",
      "\tspeed: 1.3729s/iter; left time: 1709.2980s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720388\n",
      "\tspeed: 0.7695s/iter; left time: 881.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:00.35s\n",
      "Steps: 224 | Train Loss: 0.0724398 Vali Loss: 0.0893662 Test Loss: 0.0911104\n",
      "Validation loss decreased (0.089493 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741066\n",
      "\tspeed: 1.4951s/iter; left time: 1526.4775s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676593\n",
      "\tspeed: 0.8263s/iter; left time: 761.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0721958 Vali Loss: 0.0895748 Test Loss: 0.0918992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727639\n",
      "\tspeed: 1.3470s/iter; left time: 1073.5445s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744767\n",
      "\tspeed: 0.8282s/iter; left time: 577.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0720195 Vali Loss: 0.0894382 Test Loss: 0.0920587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706366\n",
      "\tspeed: 1.3400s/iter; left time: 767.7954s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681392\n",
      "\tspeed: 0.7862s/iter; left time: 371.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:00.68s\n",
      "Steps: 224 | Train Loss: 0.0717208 Vali Loss: 0.0891432 Test Loss: 0.0911035\n",
      "Validation loss decreased (0.089366 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0646649\n",
      "\tspeed: 1.3424s/iter; left time: 468.4852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705285\n",
      "\tspeed: 0.8197s/iter; left time: 204.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:02.57s\n",
      "Steps: 224 | Train Loss: 0.0716752 Vali Loss: 0.0893801 Test Loss: 0.0916932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748916\n",
      "\tspeed: 1.3266s/iter; left time: 165.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762143\n",
      "\tspeed: 0.9504s/iter; left time: 23.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:03m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0715203 Vali Loss: 0.0894523 Test Loss: 0.0925765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1201662\n",
      "\tspeed: 0.6902s/iter; left time: 3023.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083984\n",
      "\tspeed: 0.8199s/iter; left time: 3510.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:51.51s\n",
      "Steps: 224 | Train Loss: 0.1197711 Vali Loss: 0.1104640 Test Loss: 0.1099900\n",
      "Validation loss decreased (inf --> 0.110464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871584\n",
      "\tspeed: 1.5188s/iter; left time: 6313.7035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852323\n",
      "\tspeed: 0.8325s/iter; left time: 3377.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0910880 Vali Loss: 0.0981202 Test Loss: 0.1009802\n",
      "Validation loss decreased (0.110464 --> 0.098120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853115\n",
      "\tspeed: 1.4874s/iter; left time: 5850.0365s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795056\n",
      "\tspeed: 0.8492s/iter; left time: 3254.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0834218 Vali Loss: 0.0952579 Test Loss: 0.0964131\n",
      "Validation loss decreased (0.098120 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764321\n",
      "\tspeed: 1.4849s/iter; left time: 5507.3214s\n",
      "\titers: 200, epoch: 4 | loss: 0.0704273\n",
      "\tspeed: 0.8500s/iter; left time: 3067.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.02s\n",
      "Steps: 224 | Train Loss: 0.0803541 Vali Loss: 0.0942130 Test Loss: 0.0944882\n",
      "Validation loss decreased (0.095258 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812252\n",
      "\tspeed: 1.4917s/iter; left time: 5198.6443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723357\n",
      "\tspeed: 0.8511s/iter; left time: 2880.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0780411 Vali Loss: 0.0926510 Test Loss: 0.0935687\n",
      "Validation loss decreased (0.094213 --> 0.092651).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0705587\n",
      "\tspeed: 1.4860s/iter; left time: 4845.7223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729282\n",
      "\tspeed: 0.8480s/iter; left time: 2680.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0770898 Vali Loss: 0.0913223 Test Loss: 0.0926111\n",
      "Validation loss decreased (0.092651 --> 0.091322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752742\n",
      "\tspeed: 1.4621s/iter; left time: 4440.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756757\n",
      "\tspeed: 0.8388s/iter; left time: 2463.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0762828 Vali Loss: 0.0902402 Test Loss: 0.0915751\n",
      "Validation loss decreased (0.091322 --> 0.090240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777563\n",
      "\tspeed: 1.4495s/iter; left time: 4077.5128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748446\n",
      "\tspeed: 0.8418s/iter; left time: 2283.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0754152 Vali Loss: 0.0899461 Test Loss: 0.0914084\n",
      "Validation loss decreased (0.090240 --> 0.089946).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721380\n",
      "\tspeed: 1.4680s/iter; left time: 3800.5822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728657\n",
      "\tspeed: 0.8333s/iter; left time: 2074.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0746742 Vali Loss: 0.0903633 Test Loss: 0.0908017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710530\n",
      "\tspeed: 1.4918s/iter; left time: 3528.1873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705148\n",
      "\tspeed: 0.8472s/iter; left time: 1919.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0740754 Vali Loss: 0.0897875 Test Loss: 0.0912357\n",
      "Validation loss decreased (0.089946 --> 0.089788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720897\n",
      "\tspeed: 1.4902s/iter; left time: 3190.4692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687625\n",
      "\tspeed: 0.8463s/iter; left time: 1727.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0735199 Vali Loss: 0.0899521 Test Loss: 0.0915615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725851\n",
      "\tspeed: 1.4774s/iter; left time: 2832.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756204\n",
      "\tspeed: 0.8193s/iter; left time: 1488.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0731441 Vali Loss: 0.0894233 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.089788 --> 0.089423).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718960\n",
      "\tspeed: 1.4565s/iter; left time: 2465.8815s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757970\n",
      "\tspeed: 0.8378s/iter; left time: 1334.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0727348 Vali Loss: 0.0896581 Test Loss: 0.0914745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0716447\n",
      "\tspeed: 1.5150s/iter; left time: 2225.6009s\n",
      "\titers: 200, epoch: 14 | loss: 0.0759265\n",
      "\tspeed: 0.8626s/iter; left time: 1180.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.92s\n",
      "Steps: 224 | Train Loss: 0.0725364 Vali Loss: 0.0889910 Test Loss: 0.0906905\n",
      "Validation loss decreased (0.089423 --> 0.088991).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730583\n",
      "\tspeed: 1.5198s/iter; left time: 1892.1442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691186\n",
      "\tspeed: 0.8478s/iter; left time: 970.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0723537 Vali Loss: 0.0896075 Test Loss: 0.0918515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0712389\n",
      "\tspeed: 1.4952s/iter; left time: 1526.6150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0701750\n",
      "\tspeed: 0.8390s/iter; left time: 772.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0719971 Vali Loss: 0.0890231 Test Loss: 0.0908993\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748366\n",
      "\tspeed: 1.4536s/iter; left time: 1158.4845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762918\n",
      "\tspeed: 0.8353s/iter; left time: 582.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0718654 Vali Loss: 0.0890983 Test Loss: 0.0911705\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735894\n",
      "\tspeed: 1.4531s/iter; left time: 832.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0716164\n",
      "\tspeed: 0.8461s/iter; left time: 400.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0716082 Vali Loss: 0.0896960 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675492\n",
      "\tspeed: 1.4522s/iter; left time: 506.8123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709308\n",
      "\tspeed: 0.8435s/iter; left time: 210.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0714599 Vali Loss: 0.0893303 Test Loss: 0.0912627\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
      "Intermediate time for DE and pred_len 24: 02h:17m:12.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1286584\n",
      "\tspeed: 0.9340s/iter; left time: 4091.8390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283274\n",
      "\tspeed: 0.8474s/iter; left time: 3627.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1345625 Vali Loss: 0.1315352 Test Loss: 0.1368086\n",
      "Validation loss decreased (inf --> 0.131535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160355\n",
      "\tspeed: 1.5376s/iter; left time: 6391.8059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159737\n",
      "\tspeed: 0.7543s/iter; left time: 3060.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:51.93s\n",
      "Steps: 224 | Train Loss: 0.1175694 Vali Loss: 0.1254385 Test Loss: 0.1331406\n",
      "Validation loss decreased (0.131535 --> 0.125439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108091\n",
      "\tspeed: 1.5735s/iter; left time: 6188.4592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1001122\n",
      "\tspeed: 0.8370s/iter; left time: 3208.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1085928 Vali Loss: 0.1210968 Test Loss: 0.1298962\n",
      "Validation loss decreased (0.125439 --> 0.121097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040234\n",
      "\tspeed: 1.5905s/iter; left time: 5899.3342s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003075\n",
      "\tspeed: 0.8453s/iter; left time: 3050.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1052479 Vali Loss: 0.1204925 Test Loss: 0.1286892\n",
      "Validation loss decreased (0.121097 --> 0.120492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077605\n",
      "\tspeed: 1.5720s/iter; left time: 5478.3663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053044\n",
      "\tspeed: 0.8029s/iter; left time: 2717.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:03.00s\n",
      "Steps: 224 | Train Loss: 0.1037430 Vali Loss: 0.1204495 Test Loss: 0.1279174\n",
      "Validation loss decreased (0.120492 --> 0.120449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021977\n",
      "\tspeed: 1.5619s/iter; left time: 5093.3130s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977674\n",
      "\tspeed: 0.7894s/iter; left time: 2495.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:59.61s\n",
      "Steps: 224 | Train Loss: 0.1024423 Vali Loss: 0.1194088 Test Loss: 0.1291354\n",
      "Validation loss decreased (0.120449 --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003975\n",
      "\tspeed: 1.5046s/iter; left time: 4569.3553s\n",
      "\titers: 200, epoch: 7 | loss: 0.1074992\n",
      "\tspeed: 0.8332s/iter; left time: 2447.0527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1017708 Vali Loss: 0.1194237 Test Loss: 0.1292074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023403\n",
      "\tspeed: 1.6401s/iter; left time: 4613.7078s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019197\n",
      "\tspeed: 0.8487s/iter; left time: 2302.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1011935 Vali Loss: 0.1189429 Test Loss: 0.1283226\n",
      "Validation loss decreased (0.119409 --> 0.118943).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991009\n",
      "\tspeed: 1.6411s/iter; left time: 4248.7852s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018876\n",
      "\tspeed: 0.8182s/iter; left time: 2036.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1006589 Vali Loss: 0.1188852 Test Loss: 0.1294801\n",
      "Validation loss decreased (0.118943 --> 0.118885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1020254\n",
      "\tspeed: 1.5694s/iter; left time: 3711.5246s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003808\n",
      "\tspeed: 0.8315s/iter; left time: 1883.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1001412 Vali Loss: 0.1185911 Test Loss: 0.1275851\n",
      "Validation loss decreased (0.118885 --> 0.118591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003736\n",
      "\tspeed: 1.5670s/iter; left time: 3355.0398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0996785\n",
      "\tspeed: 0.7831s/iter; left time: 1598.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0998360 Vali Loss: 0.1192170 Test Loss: 0.1295892\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1009651\n",
      "\tspeed: 1.6085s/iter; left time: 3083.4932s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002403\n",
      "\tspeed: 0.8107s/iter; left time: 1472.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0993493 Vali Loss: 0.1186539 Test Loss: 0.1287528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009898\n",
      "\tspeed: 1.5807s/iter; left time: 2676.0931s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007161\n",
      "\tspeed: 0.8221s/iter; left time: 1309.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0989542 Vali Loss: 0.1189050 Test Loss: 0.1297899\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981157\n",
      "\tspeed: 1.5740s/iter; left time: 2312.2567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043117\n",
      "\tspeed: 0.8439s/iter; left time: 1155.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0986829 Vali Loss: 0.1192963 Test Loss: 0.1300762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1003836\n",
      "\tspeed: 1.5546s/iter; left time: 1935.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967155\n",
      "\tspeed: 0.8249s/iter; left time: 944.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0983634 Vali Loss: 0.1188927 Test Loss: 0.1290997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364218\n",
      "\tspeed: 0.8214s/iter; left time: 3598.3893s\n",
      "\titers: 200, epoch: 1 | loss: 0.1313399\n",
      "\tspeed: 0.7984s/iter; left time: 3418.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.06s\n",
      "Steps: 224 | Train Loss: 0.1353756 Vali Loss: 0.1317179 Test Loss: 0.1366934\n",
      "Validation loss decreased (inf --> 0.131718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200846\n",
      "\tspeed: 1.6313s/iter; left time: 6781.3599s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105273\n",
      "\tspeed: 0.8539s/iter; left time: 3464.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:10.31s\n",
      "Steps: 224 | Train Loss: 0.1165046 Vali Loss: 0.1257103 Test Loss: 0.1339367\n",
      "Validation loss decreased (0.131718 --> 0.125710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135974\n",
      "\tspeed: 1.6437s/iter; left time: 6464.8500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066958\n",
      "\tspeed: 0.8525s/iter; left time: 3267.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:13.84s\n",
      "Steps: 224 | Train Loss: 0.1087123 Vali Loss: 0.1218007 Test Loss: 0.1306605\n",
      "Validation loss decreased (0.125710 --> 0.121801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062235\n",
      "\tspeed: 1.6802s/iter; left time: 6231.7454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1012442\n",
      "\tspeed: 0.8510s/iter; left time: 3071.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:12.08s\n",
      "Steps: 224 | Train Loss: 0.1057830 Vali Loss: 0.1204576 Test Loss: 0.1288750\n",
      "Validation loss decreased (0.121801 --> 0.120458).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029572\n",
      "\tspeed: 1.7320s/iter; left time: 6036.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097937\n",
      "\tspeed: 0.8764s/iter; left time: 2966.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.04s\n",
      "Steps: 224 | Train Loss: 0.1041747 Vali Loss: 0.1198968 Test Loss: 0.1290881\n",
      "Validation loss decreased (0.120458 --> 0.119897).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044354\n",
      "\tspeed: 1.7541s/iter; left time: 5720.0084s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042368\n",
      "\tspeed: 0.8483s/iter; left time: 2681.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.34s\n",
      "Steps: 224 | Train Loss: 0.1030439 Vali Loss: 0.1198872 Test Loss: 0.1294045\n",
      "Validation loss decreased (0.119897 --> 0.119887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028243\n",
      "\tspeed: 1.7801s/iter; left time: 5406.1527s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059746\n",
      "\tspeed: 0.8741s/iter; left time: 2567.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1019859 Vali Loss: 0.1196817 Test Loss: 0.1293018\n",
      "Validation loss decreased (0.119887 --> 0.119682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1014663\n",
      "\tspeed: 2.3313s/iter; left time: 6557.8122s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035754\n",
      "\tspeed: 0.7724s/iter; left time: 2095.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:38.54s\n",
      "Steps: 224 | Train Loss: 0.1013703 Vali Loss: 0.1194906 Test Loss: 0.1304186\n",
      "Validation loss decreased (0.119682 --> 0.119491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996586\n",
      "\tspeed: 1.5930s/iter; left time: 4124.2748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0992961\n",
      "\tspeed: 0.8279s/iter; left time: 2060.5846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1008033 Vali Loss: 0.1198257 Test Loss: 0.1310487\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048882\n",
      "\tspeed: 1.6737s/iter; left time: 3958.2572s\n",
      "\titers: 200, epoch: 10 | loss: 0.1055110\n",
      "\tspeed: 0.8171s/iter; left time: 1850.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1001401 Vali Loss: 0.1198027 Test Loss: 0.1308678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0972710\n",
      "\tspeed: 1.6763s/iter; left time: 3588.9164s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006895\n",
      "\tspeed: 0.8502s/iter; left time: 1735.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0996930 Vali Loss: 0.1197501 Test Loss: 0.1311171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987459\n",
      "\tspeed: 1.6857s/iter; left time: 3231.5802s\n",
      "\titers: 200, epoch: 12 | loss: 0.1033765\n",
      "\tspeed: 0.8450s/iter; left time: 1535.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0991635 Vali Loss: 0.1197549 Test Loss: 0.1314769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1000874\n",
      "\tspeed: 1.7511s/iter; left time: 2964.6524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997200\n",
      "\tspeed: 0.8513s/iter; left time: 1356.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0988495 Vali Loss: 0.1200454 Test Loss: 0.1321729\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038512662053108215, rmse:0.1962464302778244, mae:0.13041862845420837, rse:0.6949483156204224\n",
      "Intermediate time for DE and pred_len 96: 01h:57m:14.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1400413\n",
      "\tspeed: 0.8899s/iter; left time: 3880.7776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308107\n",
      "\tspeed: 0.8546s/iter; left time: 3641.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1382469 Vali Loss: 0.1349166 Test Loss: 0.1416962\n",
      "Validation loss decreased (inf --> 0.134917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1242591\n",
      "\tspeed: 1.8069s/iter; left time: 7476.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.1166725\n",
      "\tspeed: 0.8570s/iter; left time: 3460.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:14.33s\n",
      "Steps: 223 | Train Loss: 0.1226699 Vali Loss: 0.1295651 Test Loss: 0.1393560\n",
      "Validation loss decreased (0.134917 --> 0.129565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1153209\n",
      "\tspeed: 1.7485s/iter; left time: 6845.2142s\n",
      "\titers: 200, epoch: 3 | loss: 0.1126005\n",
      "\tspeed: 0.8771s/iter; left time: 3345.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:15.27s\n",
      "Steps: 223 | Train Loss: 0.1139000 Vali Loss: 0.1261486 Test Loss: 0.1358930\n",
      "Validation loss decreased (0.129565 --> 0.126149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062162\n",
      "\tspeed: 1.7090s/iter; left time: 6309.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107251\n",
      "\tspeed: 0.8831s/iter; left time: 3172.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:15.11s\n",
      "Steps: 223 | Train Loss: 0.1110505 Vali Loss: 0.1244184 Test Loss: 0.1335864\n",
      "Validation loss decreased (0.126149 --> 0.124418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1084757\n",
      "\tspeed: 1.7248s/iter; left time: 5983.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.1087421\n",
      "\tspeed: 0.8599s/iter; left time: 2897.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.65s\n",
      "Steps: 223 | Train Loss: 0.1094183 Vali Loss: 0.1241783 Test Loss: 0.1338822\n",
      "Validation loss decreased (0.124418 --> 0.124178).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141112\n",
      "\tspeed: 1.8323s/iter; left time: 5947.5092s\n",
      "\titers: 200, epoch: 6 | loss: 0.1091668\n",
      "\tspeed: 0.8817s/iter; left time: 2773.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:16.80s\n",
      "Steps: 223 | Train Loss: 0.1086366 Vali Loss: 0.1237398 Test Loss: 0.1352959\n",
      "Validation loss decreased (0.124178 --> 0.123740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1066006\n",
      "\tspeed: 1.8825s/iter; left time: 5690.6879s\n",
      "\titers: 200, epoch: 7 | loss: 0.1082050\n",
      "\tspeed: 0.8714s/iter; left time: 2547.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:18.07s\n",
      "Steps: 223 | Train Loss: 0.1077990 Vali Loss: 0.1234855 Test Loss: 0.1357112\n",
      "Validation loss decreased (0.123740 --> 0.123486).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045769\n",
      "\tspeed: 1.7335s/iter; left time: 4853.6769s\n",
      "\titers: 200, epoch: 8 | loss: 0.1086057\n",
      "\tspeed: 0.8623s/iter; left time: 2328.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.69s\n",
      "Steps: 223 | Train Loss: 0.1074179 Vali Loss: 0.1231780 Test Loss: 0.1348252\n",
      "Validation loss decreased (0.123486 --> 0.123178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 1.7192s/iter; left time: 4430.4052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060561\n",
      "\tspeed: 0.8545s/iter; left time: 2116.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:09.60s\n",
      "Steps: 223 | Train Loss: 0.1069891 Vali Loss: 0.1235725 Test Loss: 0.1355295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018216\n",
      "\tspeed: 1.7313s/iter; left time: 4075.4651s\n",
      "\titers: 200, epoch: 10 | loss: 0.1136913\n",
      "\tspeed: 0.8794s/iter; left time: 1982.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:14.36s\n",
      "Steps: 223 | Train Loss: 0.1066360 Vali Loss: 0.1234050 Test Loss: 0.1363396\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071401\n",
      "\tspeed: 1.7654s/iter; left time: 3762.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049976\n",
      "\tspeed: 0.8746s/iter; left time: 1776.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:14.34s\n",
      "Steps: 223 | Train Loss: 0.1062648 Vali Loss: 0.1234758 Test Loss: 0.1363748\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1055855\n",
      "\tspeed: 1.7604s/iter; left time: 3358.8136s\n",
      "\titers: 200, epoch: 12 | loss: 0.1099972\n",
      "\tspeed: 0.8517s/iter; left time: 1539.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:11.70s\n",
      "Steps: 223 | Train Loss: 0.1059586 Vali Loss: 0.1235797 Test Loss: 0.1368409\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016340\n",
      "\tspeed: 1.7306s/iter; left time: 2915.9802s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034260\n",
      "\tspeed: 0.8518s/iter; left time: 1350.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.89s\n",
      "Steps: 223 | Train Loss: 0.1056342 Vali Loss: 0.1233136 Test Loss: 0.1364277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.040120694786310196, rmse:0.20030151307582855, mae:0.13482515513896942, rse:0.7094841003417969\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343999\n",
      "\tspeed: 0.8474s/iter; left time: 3695.5296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272989\n",
      "\tspeed: 0.8469s/iter; left time: 3608.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1386628 Vali Loss: 0.1349369 Test Loss: 0.1415361\n",
      "Validation loss decreased (inf --> 0.134937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219488\n",
      "\tspeed: 1.7101s/iter; left time: 7076.1974s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157697\n",
      "\tspeed: 0.7994s/iter; left time: 3227.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1217117 Vali Loss: 0.1286630 Test Loss: 0.1371584\n",
      "Validation loss decreased (0.134937 --> 0.128663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1134495\n",
      "\tspeed: 1.6744s/iter; left time: 6555.3014s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091854\n",
      "\tspeed: 0.8857s/iter; left time: 3379.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:12.57s\n",
      "Steps: 223 | Train Loss: 0.1140187 Vali Loss: 0.1251376 Test Loss: 0.1358937\n",
      "Validation loss decreased (0.128663 --> 0.125138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115679\n",
      "\tspeed: 1.6663s/iter; left time: 6152.1628s\n",
      "\titers: 200, epoch: 4 | loss: 0.1115438\n",
      "\tspeed: 0.8562s/iter; left time: 3075.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:10.74s\n",
      "Steps: 223 | Train Loss: 0.1116452 Vali Loss: 0.1244681 Test Loss: 0.1350853\n",
      "Validation loss decreased (0.125138 --> 0.124468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106175\n",
      "\tspeed: 1.7480s/iter; left time: 6063.7318s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095825\n",
      "\tspeed: 0.8591s/iter; left time: 2894.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.89s\n",
      "Steps: 223 | Train Loss: 0.1102210 Vali Loss: 0.1239026 Test Loss: 0.1343044\n",
      "Validation loss decreased (0.124468 --> 0.123903).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118471\n",
      "\tspeed: 1.7579s/iter; left time: 5706.1713s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098318\n",
      "\tspeed: 0.8545s/iter; left time: 2688.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.79s\n",
      "Steps: 223 | Train Loss: 0.1090337 Vali Loss: 0.1244645 Test Loss: 0.1359817\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072461\n",
      "\tspeed: 1.8050s/iter; left time: 5456.6141s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047308\n",
      "\tspeed: 0.8728s/iter; left time: 2551.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.02s\n",
      "Steps: 223 | Train Loss: 0.1081847 Vali Loss: 0.1242444 Test Loss: 0.1349455\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977734\n",
      "\tspeed: 1.7448s/iter; left time: 4885.3021s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037813\n",
      "\tspeed: 0.8489s/iter; left time: 2292.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.29s\n",
      "Steps: 223 | Train Loss: 0.1075828 Vali Loss: 0.1239628 Test Loss: 0.1348020\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006511\n",
      "\tspeed: 1.7049s/iter; left time: 4393.5337s\n",
      "\titers: 200, epoch: 9 | loss: 0.1090960\n",
      "\tspeed: 0.8624s/iter; left time: 2136.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.65s\n",
      "Steps: 223 | Train Loss: 0.1071309 Vali Loss: 0.1239745 Test Loss: 0.1353526\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043709\n",
      "\tspeed: 1.6966s/iter; left time: 3993.7451s\n",
      "\titers: 200, epoch: 10 | loss: 0.1067678\n",
      "\tspeed: 0.8641s/iter; left time: 1947.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:13.35s\n",
      "Steps: 223 | Train Loss: 0.1066391 Vali Loss: 0.1235742 Test Loss: 0.1350486\n",
      "Validation loss decreased (0.123903 --> 0.123574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088294\n",
      "\tspeed: 1.7244s/iter; left time: 3674.6979s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030726\n",
      "\tspeed: 0.8540s/iter; left time: 1734.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:11.19s\n",
      "Steps: 223 | Train Loss: 0.1062802 Vali Loss: 0.1233648 Test Loss: 0.1349831\n",
      "Validation loss decreased (0.123574 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034573\n",
      "\tspeed: 1.8148s/iter; left time: 3462.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029600\n",
      "\tspeed: 0.8572s/iter; left time: 1549.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1059580 Vali Loss: 0.1236015 Test Loss: 0.1355882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1070623\n",
      "\tspeed: 1.7590s/iter; left time: 2963.9161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071535\n",
      "\tspeed: 0.8557s/iter; left time: 1356.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.45s\n",
      "Steps: 223 | Train Loss: 0.1056516 Vali Loss: 0.1236461 Test Loss: 0.1358070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007426\n",
      "\tspeed: 1.7315s/iter; left time: 2531.5073s\n",
      "\titers: 200, epoch: 14 | loss: 0.1061819\n",
      "\tspeed: 0.8401s/iter; left time: 1144.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.12s\n",
      "Steps: 223 | Train Loss: 0.1053684 Vali Loss: 0.1238686 Test Loss: 0.1371689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1087525\n",
      "\tspeed: 1.7272s/iter; left time: 2139.9453s\n",
      "\titers: 200, epoch: 15 | loss: 0.1041255\n",
      "\tspeed: 0.8668s/iter; left time: 987.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.73s\n",
      "Steps: 223 | Train Loss: 0.1050500 Vali Loss: 0.1236121 Test Loss: 0.1367470\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058608\n",
      "\tspeed: 1.7639s/iter; left time: 1792.1227s\n",
      "\titers: 200, epoch: 16 | loss: 0.1124790\n",
      "\tspeed: 0.8965s/iter; left time: 821.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:16.09s\n",
      "Steps: 223 | Train Loss: 0.1047191 Vali Loss: 0.1237539 Test Loss: 0.1365166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04019937664270401, rmse:0.2004978209733963, mae:0.1349831074476242, rse:0.7101793885231018\n",
      "Intermediate time for DE and pred_len 168: 02h:07m:10.52s\n",
      "Intermediate time for DE: 06h:21m:37.55s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116893\n",
      "\tspeed: 0.8959s/iter; left time: 3925.1028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038978\n",
      "\tspeed: 0.8831s/iter; left time: 3780.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:14.71s\n",
      "Steps: 224 | Train Loss: 0.1110849 Vali Loss: 0.1032261 Test Loss: 0.1155894\n",
      "Validation loss decreased (inf --> 0.103226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0890798\n",
      "\tspeed: 1.5255s/iter; left time: 6341.4464s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849172\n",
      "\tspeed: 0.8737s/iter; left time: 3544.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0889122 Vali Loss: 0.0968059 Test Loss: 0.1091108\n",
      "Validation loss decreased (0.103226 --> 0.096806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819009\n",
      "\tspeed: 1.5297s/iter; left time: 6016.2809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776293\n",
      "\tspeed: 0.8688s/iter; left time: 3330.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0812004 Vali Loss: 0.0940494 Test Loss: 0.1048684\n",
      "Validation loss decreased (0.096806 --> 0.094049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770025\n",
      "\tspeed: 1.5063s/iter; left time: 5586.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848865\n",
      "\tspeed: 0.8648s/iter; left time: 3121.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0796152 Vali Loss: 0.0937369 Test Loss: 0.1047043\n",
      "Validation loss decreased (0.094049 --> 0.093737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734676\n",
      "\tspeed: 1.5334s/iter; left time: 5343.9518s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762912\n",
      "\tspeed: 0.8661s/iter; left time: 2931.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0783571 Vali Loss: 0.0932249 Test Loss: 0.1037360\n",
      "Validation loss decreased (0.093737 --> 0.093225).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782692\n",
      "\tspeed: 1.4208s/iter; left time: 4633.1158s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721411\n",
      "\tspeed: 0.8070s/iter; left time: 2550.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:02.02s\n",
      "Steps: 224 | Train Loss: 0.0774817 Vali Loss: 0.0925879 Test Loss: 0.1041476\n",
      "Validation loss decreased (0.093225 --> 0.092588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812348\n",
      "\tspeed: 1.5342s/iter; left time: 4659.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759008\n",
      "\tspeed: 0.8840s/iter; left time: 2596.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0769514 Vali Loss: 0.0922961 Test Loss: 0.1031611\n",
      "Validation loss decreased (0.092588 --> 0.092296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749917\n",
      "\tspeed: 1.5055s/iter; left time: 4234.8770s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806865\n",
      "\tspeed: 0.8563s/iter; left time: 2323.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0766532 Vali Loss: 0.0923761 Test Loss: 0.1039077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769141\n",
      "\tspeed: 1.5225s/iter; left time: 3941.8340s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745924\n",
      "\tspeed: 0.8558s/iter; left time: 2130.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0921174 Test Loss: 0.1033806\n",
      "Validation loss decreased (0.092296 --> 0.092117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747170\n",
      "\tspeed: 1.4998s/iter; left time: 3546.9952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790516\n",
      "\tspeed: 0.8371s/iter; left time: 1895.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758396 Vali Loss: 0.0917899 Test Loss: 0.1031209\n",
      "Validation loss decreased (0.092117 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702004\n",
      "\tspeed: 1.4857s/iter; left time: 3180.9334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749110\n",
      "\tspeed: 0.8391s/iter; left time: 1712.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.92s\n",
      "Steps: 224 | Train Loss: 0.0755050 Vali Loss: 0.0919418 Test Loss: 0.1042525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728829\n",
      "\tspeed: 1.4704s/iter; left time: 2818.7016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757767\n",
      "\tspeed: 0.8425s/iter; left time: 1530.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0751960 Vali Loss: 0.0917938 Test Loss: 0.1037975\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698661\n",
      "\tspeed: 1.4651s/iter; left time: 2480.3355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741580\n",
      "\tspeed: 0.8403s/iter; left time: 1338.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0749474 Vali Loss: 0.0923169 Test Loss: 0.1042981\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734728\n",
      "\tspeed: 1.4869s/iter; left time: 2184.3007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667883\n",
      "\tspeed: 0.8433s/iter; left time: 1154.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0747666 Vali Loss: 0.0917064 Test Loss: 0.1039197\n",
      "Validation loss decreased (0.091790 --> 0.091706).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662220\n",
      "\tspeed: 1.4713s/iter; left time: 1831.7687s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799081\n",
      "\tspeed: 0.8449s/iter; left time: 967.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0746049 Vali Loss: 0.0917562 Test Loss: 0.1039334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779508\n",
      "\tspeed: 1.5109s/iter; left time: 1542.6142s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741158\n",
      "\tspeed: 0.8687s/iter; left time: 800.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0744549 Vali Loss: 0.0919189 Test Loss: 0.1040348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0742268\n",
      "\tspeed: 1.5145s/iter; left time: 1207.0217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780587\n",
      "\tspeed: 0.8582s/iter; left time: 598.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:11.58s\n",
      "Steps: 224 | Train Loss: 0.0742948 Vali Loss: 0.0919655 Test Loss: 0.1043945\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706386\n",
      "\tspeed: 1.5120s/iter; left time: 866.3568s\n",
      "\titers: 200, epoch: 18 | loss: 0.0753198\n",
      "\tspeed: 0.8484s/iter; left time: 401.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0741458 Vali Loss: 0.0919789 Test Loss: 0.1042754\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694558\n",
      "\tspeed: 1.3137s/iter; left time: 458.4893s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766510\n",
      "\tspeed: 0.6998s/iter; left time: 174.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:02m:44.93s\n",
      "Steps: 224 | Train Loss: 0.0740221 Vali Loss: 0.0918603 Test Loss: 0.1038902\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026621254161000252, rmse:0.16316020488739014, mae:0.10391969978809357, rse:0.5628564953804016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1084992\n",
      "\tspeed: 0.6800s/iter; left time: 2979.1896s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999074\n",
      "\tspeed: 0.6846s/iter; left time: 2930.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:33.04s\n",
      "Steps: 224 | Train Loss: 0.1116735 Vali Loss: 0.1036351 Test Loss: 0.1160170\n",
      "Validation loss decreased (inf --> 0.103635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0966203\n",
      "\tspeed: 1.2673s/iter; left time: 5268.3150s\n",
      "\titers: 200, epoch: 2 | loss: 0.0817607\n",
      "\tspeed: 0.8231s/iter; left time: 3339.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0888987 Vali Loss: 0.0972792 Test Loss: 0.1101744\n",
      "Validation loss decreased (0.103635 --> 0.097279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799150\n",
      "\tspeed: 1.4437s/iter; left time: 5677.8835s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805758\n",
      "\tspeed: 0.8110s/iter; left time: 3108.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0818355 Vali Loss: 0.0941807 Test Loss: 0.1062411\n",
      "Validation loss decreased (0.097279 --> 0.094181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784878\n",
      "\tspeed: 1.4282s/iter; left time: 5297.1938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763587\n",
      "\tspeed: 0.8138s/iter; left time: 2936.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:01.52s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0929848 Test Loss: 0.1047919\n",
      "Validation loss decreased (0.094181 --> 0.092985).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749025\n",
      "\tspeed: 1.3683s/iter; left time: 4768.4074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754450\n",
      "\tspeed: 0.8028s/iter; left time: 2717.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:58.70s\n",
      "Steps: 224 | Train Loss: 0.0782957 Vali Loss: 0.0929606 Test Loss: 0.1038269\n",
      "Validation loss decreased (0.092985 --> 0.092961).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793271\n",
      "\tspeed: 1.5037s/iter; left time: 4903.4140s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813081\n",
      "\tspeed: 0.8539s/iter; left time: 2699.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:12.12s\n",
      "Steps: 224 | Train Loss: 0.0773415 Vali Loss: 0.0923607 Test Loss: 0.1038644\n",
      "Validation loss decreased (0.092961 --> 0.092361).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782389\n",
      "\tspeed: 1.5050s/iter; left time: 4570.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773057\n",
      "\tspeed: 0.8308s/iter; left time: 2440.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769673 Vali Loss: 0.0921593 Test Loss: 0.1032822\n",
      "Validation loss decreased (0.092361 --> 0.092159).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770141\n",
      "\tspeed: 1.4834s/iter; left time: 4172.8993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750573\n",
      "\tspeed: 0.8219s/iter; left time: 2229.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0764386 Vali Loss: 0.0918024 Test Loss: 0.1035269\n",
      "Validation loss decreased (0.092159 --> 0.091802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0684199\n",
      "\tspeed: 1.4720s/iter; left time: 3811.0929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699812\n",
      "\tspeed: 0.8387s/iter; left time: 2087.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0761223 Vali Loss: 0.0920349 Test Loss: 0.1038026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787783\n",
      "\tspeed: 1.4548s/iter; left time: 3440.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783952\n",
      "\tspeed: 0.7669s/iter; left time: 1736.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:58.88s\n",
      "Steps: 224 | Train Loss: 0.0757484 Vali Loss: 0.0919563 Test Loss: 0.1029629\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753692\n",
      "\tspeed: 1.4349s/iter; left time: 3072.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728229\n",
      "\tspeed: 0.8486s/iter; left time: 1731.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0755147 Vali Loss: 0.0919968 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715075\n",
      "\tspeed: 1.5133s/iter; left time: 2900.9155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739322\n",
      "\tspeed: 0.8266s/iter; left time: 1501.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0752598 Vali Loss: 0.0923253 Test Loss: 0.1040638\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775367\n",
      "\tspeed: 1.4810s/iter; left time: 2507.3889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0789441\n",
      "\tspeed: 0.8396s/iter; left time: 1337.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0750797 Vali Loss: 0.0919649 Test Loss: 0.1041826\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02626371942460537, rmse:0.16206085681915283, mae:0.10352689772844315, rse:0.5590639710426331\n",
      "Intermediate time for GB and pred_len 24: 02h:03m:14.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252335\n",
      "\tspeed: 0.8947s/iter; left time: 3919.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201171\n",
      "\tspeed: 0.8332s/iter; left time: 3567.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1246595 Vali Loss: 0.1228046 Test Loss: 0.1431150\n",
      "Validation loss decreased (inf --> 0.122805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1149061\n",
      "\tspeed: 1.6577s/iter; left time: 6891.1368s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042059\n",
      "\tspeed: 0.8480s/iter; left time: 3440.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1117659 Vali Loss: 0.1201113 Test Loss: 0.1403482\n",
      "Validation loss decreased (0.122805 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069597\n",
      "\tspeed: 1.7151s/iter; left time: 6745.3664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021630\n",
      "\tspeed: 0.8387s/iter; left time: 3214.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.73s\n",
      "Steps: 224 | Train Loss: 0.1052783 Vali Loss: 0.1193737 Test Loss: 0.1403535\n",
      "Validation loss decreased (0.120111 --> 0.119374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045493\n",
      "\tspeed: 1.7337s/iter; left time: 6430.3361s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997706\n",
      "\tspeed: 0.8424s/iter; left time: 3040.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.74s\n",
      "Steps: 224 | Train Loss: 0.1036617 Vali Loss: 0.1194295 Test Loss: 0.1381266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030175\n",
      "\tspeed: 1.7161s/iter; left time: 5980.4878s\n",
      "\titers: 200, epoch: 5 | loss: 0.1078746\n",
      "\tspeed: 0.8664s/iter; left time: 2932.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.60s\n",
      "Steps: 224 | Train Loss: 0.1025570 Vali Loss: 0.1188874 Test Loss: 0.1394207\n",
      "Validation loss decreased (0.119374 --> 0.118887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021968\n",
      "\tspeed: 1.7392s/iter; left time: 5671.6279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011541\n",
      "\tspeed: 0.8588s/iter; left time: 2714.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:15.16s\n",
      "Steps: 224 | Train Loss: 0.1016647 Vali Loss: 0.1199620 Test Loss: 0.1390563\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985276\n",
      "\tspeed: 1.7798s/iter; left time: 5405.3696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043604\n",
      "\tspeed: 0.8527s/iter; left time: 2504.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:12.22s\n",
      "Steps: 224 | Train Loss: 0.1007115 Vali Loss: 0.1197896 Test Loss: 0.1403841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001039\n",
      "\tspeed: 1.7219s/iter; left time: 4843.8043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033350\n",
      "\tspeed: 0.8533s/iter; left time: 2315.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.03s\n",
      "Steps: 224 | Train Loss: 0.1001557 Vali Loss: 0.1202944 Test Loss: 0.1393946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982785\n",
      "\tspeed: 1.6656s/iter; left time: 4312.2334s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042185\n",
      "\tspeed: 0.8577s/iter; left time: 2134.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:10.93s\n",
      "Steps: 224 | Train Loss: 0.0997188 Vali Loss: 0.1200153 Test Loss: 0.1401132\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954204\n",
      "\tspeed: 1.7502s/iter; left time: 4139.2094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010626\n",
      "\tspeed: 0.8743s/iter; left time: 1980.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0993233 Vali Loss: 0.1199207 Test Loss: 0.1392622\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04243852570652962, rmse:0.20600612461566925, mae:0.13942068815231323, rse:0.7123979330062866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213994\n",
      "\tspeed: 0.8481s/iter; left time: 3715.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157816\n",
      "\tspeed: 0.8547s/iter; left time: 3659.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.57s\n",
      "Steps: 224 | Train Loss: 0.1246331 Vali Loss: 0.1226478 Test Loss: 0.1431716\n",
      "Validation loss decreased (inf --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097208\n",
      "\tspeed: 1.6775s/iter; left time: 6973.5719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1022605\n",
      "\tspeed: 0.8425s/iter; left time: 3417.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:09.36s\n",
      "Steps: 224 | Train Loss: 0.1115726 Vali Loss: 0.1201536 Test Loss: 0.1400796\n",
      "Validation loss decreased (0.122648 --> 0.120154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1016258\n",
      "\tspeed: 1.7072s/iter; left time: 6714.4824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017843\n",
      "\tspeed: 0.8483s/iter; left time: 3251.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:09.16s\n",
      "Steps: 224 | Train Loss: 0.1053649 Vali Loss: 0.1187505 Test Loss: 0.1394587\n",
      "Validation loss decreased (0.120154 --> 0.118751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072599\n",
      "\tspeed: 1.7390s/iter; left time: 6450.0632s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007376\n",
      "\tspeed: 0.8765s/iter; left time: 3163.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:16.15s\n",
      "Steps: 224 | Train Loss: 0.1034409 Vali Loss: 0.1196524 Test Loss: 0.1391735\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053430\n",
      "\tspeed: 1.7610s/iter; left time: 6137.0463s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057364\n",
      "\tspeed: 0.8451s/iter; left time: 2860.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.68s\n",
      "Steps: 224 | Train Loss: 0.1023294 Vali Loss: 0.1185409 Test Loss: 0.1385030\n",
      "Validation loss decreased (0.118751 --> 0.118541).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058340\n",
      "\tspeed: 1.6907s/iter; left time: 5513.3094s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048339\n",
      "\tspeed: 1.0748s/iter; left time: 3397.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:46.13s\n",
      "Steps: 224 | Train Loss: 0.1016991 Vali Loss: 0.1183163 Test Loss: 0.1388204\n",
      "Validation loss decreased (0.118541 --> 0.118316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021866\n",
      "\tspeed: 1.6960s/iter; left time: 5150.9019s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028333\n",
      "\tspeed: 0.7745s/iter; left time: 2274.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:54.27s\n",
      "Steps: 224 | Train Loss: 0.1008699 Vali Loss: 0.1182164 Test Loss: 0.1383967\n",
      "Validation loss decreased (0.118316 --> 0.118216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997323\n",
      "\tspeed: 1.7355s/iter; left time: 4881.9588s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055382\n",
      "\tspeed: 0.8556s/iter; left time: 2321.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:10.32s\n",
      "Steps: 224 | Train Loss: 0.1004637 Vali Loss: 0.1179797 Test Loss: 0.1388233\n",
      "Validation loss decreased (0.118216 --> 0.117980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006353\n",
      "\tspeed: 1.7252s/iter; left time: 4466.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000371\n",
      "\tspeed: 0.8375s/iter; left time: 2084.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.54s\n",
      "Steps: 224 | Train Loss: 0.1000307 Vali Loss: 0.1185631 Test Loss: 0.1388896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983968\n",
      "\tspeed: 1.7024s/iter; left time: 4026.1124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0981454\n",
      "\tspeed: 0.8492s/iter; left time: 1923.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0995587 Vali Loss: 0.1187217 Test Loss: 0.1394587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945402\n",
      "\tspeed: 1.6826s/iter; left time: 3602.5143s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004767\n",
      "\tspeed: 0.8392s/iter; left time: 1712.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0991112 Vali Loss: 0.1180590 Test Loss: 0.1385924\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008899\n",
      "\tspeed: 1.7303s/iter; left time: 3316.9489s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023057\n",
      "\tspeed: 0.8639s/iter; left time: 1569.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0988884 Vali Loss: 0.1189626 Test Loss: 0.1391280\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995492\n",
      "\tspeed: 1.7523s/iter; left time: 2966.6760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980858\n",
      "\tspeed: 0.8459s/iter; left time: 1347.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0985649 Vali Loss: 0.1183671 Test Loss: 0.1400267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04178399592638016, rmse:0.2044113427400589, mae:0.13882331550121307, rse:0.706882894039154\n",
      "Intermediate time for GB and pred_len 96: 01h:39m:54.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262437\n",
      "\tspeed: 0.8650s/iter; left time: 3772.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1255427\n",
      "\tspeed: 0.8030s/iter; left time: 3421.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.82s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize empty list\n",
    "patchtst_results = []\n",
    "\n",
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0380  0.1949  0.1290\n",
       "        168       0.0402  0.2004  0.1349\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1040  0.0585\n",
       "        96        0.0205  0.1432  0.0837\n",
       "        168       0.0216  0.1471  0.0878\n",
       "GB      24        0.0264  0.1626  0.1037\n",
       "        96        0.0421  0.2052  0.1391\n",
       "        168       0.0444  0.2106  0.1445\n",
       "IT      24        0.0109  0.1044  0.0594\n",
       "        96        0.0192  0.1387  0.0825\n",
       "        168       0.0202  0.1422  0.0865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1467022\n",
      "\tspeed: 0.0804s/iter; left time: 1792.8357s\n",
      "\titers: 200, epoch: 1 | loss: 0.1380337\n",
      "\tspeed: 0.0582s/iter; left time: 1291.8553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.14s\n",
      "Steps: 224 | Train Loss: 0.1492598 Vali Loss: 0.1491447 Test Loss: 0.1573455\n",
      "Validation loss decreased (inf --> 0.149145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0933916\n",
      "\tspeed: 0.0984s/iter; left time: 2172.1917s\n",
      "\titers: 200, epoch: 2 | loss: 0.0793409\n",
      "\tspeed: 0.0621s/iter; left time: 1364.6159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.18s\n",
      "Steps: 224 | Train Loss: 0.0958381 Vali Loss: 0.0959918 Test Loss: 0.0965967\n",
      "Validation loss decreased (0.149145 --> 0.095992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804107\n",
      "\tspeed: 0.1105s/iter; left time: 2413.7236s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822360\n",
      "\tspeed: 0.0546s/iter; left time: 1187.4525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.92s\n",
      "Steps: 224 | Train Loss: 0.0800409 Vali Loss: 0.0911792 Test Loss: 0.0924903\n",
      "Validation loss decreased (0.095992 --> 0.091179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0721088\n",
      "\tspeed: 0.1055s/iter; left time: 2281.2488s\n",
      "\titers: 200, epoch: 4 | loss: 0.0784065\n",
      "\tspeed: 0.0549s/iter; left time: 1181.8430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.87s\n",
      "Steps: 224 | Train Loss: 0.0768202 Vali Loss: 0.0894785 Test Loss: 0.0912090\n",
      "Validation loss decreased (0.091179 --> 0.089479).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0701359\n",
      "\tspeed: 0.1084s/iter; left time: 2321.0699s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721674\n",
      "\tspeed: 0.0541s/iter; left time: 1151.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 224 | Train Loss: 0.0751275 Vali Loss: 0.0886305 Test Loss: 0.0903440\n",
      "Validation loss decreased (0.089479 --> 0.088631).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0747568\n",
      "\tspeed: 0.1091s/iter; left time: 2310.7828s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739783\n",
      "\tspeed: 0.0552s/iter; left time: 1162.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0740978 Vali Loss: 0.0879776 Test Loss: 0.0896847\n",
      "Validation loss decreased (0.088631 --> 0.087978).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0773371\n",
      "\tspeed: 0.1145s/iter; left time: 2400.2737s\n",
      "\titers: 200, epoch: 7 | loss: 0.0693570\n",
      "\tspeed: 0.0553s/iter; left time: 1153.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.09s\n",
      "Steps: 224 | Train Loss: 0.0731795 Vali Loss: 0.0878054 Test Loss: 0.0894686\n",
      "Validation loss decreased (0.087978 --> 0.087805).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742184\n",
      "\tspeed: 0.1014s/iter; left time: 2102.9407s\n",
      "\titers: 200, epoch: 8 | loss: 0.0694305\n",
      "\tspeed: 0.0558s/iter; left time: 1151.7346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.18s\n",
      "Steps: 224 | Train Loss: 0.0726620 Vali Loss: 0.0872411 Test Loss: 0.0890743\n",
      "Validation loss decreased (0.087805 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0730793\n",
      "\tspeed: 0.1106s/iter; left time: 2267.7352s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740317\n",
      "\tspeed: 0.0623s/iter; left time: 1271.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0721427 Vali Loss: 0.0873636 Test Loss: 0.0895516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0651195\n",
      "\tspeed: 0.1086s/iter; left time: 2202.1219s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683019\n",
      "\tspeed: 0.0546s/iter; left time: 1101.7158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.90s\n",
      "Steps: 224 | Train Loss: 0.0717890 Vali Loss: 0.0870031 Test Loss: 0.0891616\n",
      "Validation loss decreased (0.087241 --> 0.087003).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0714403\n",
      "\tspeed: 0.1073s/iter; left time: 2152.4294s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766668\n",
      "\tspeed: 0.0624s/iter; left time: 1244.6134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.79s\n",
      "Steps: 224 | Train Loss: 0.0714359 Vali Loss: 0.0870827 Test Loss: 0.0894357\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0713613\n",
      "\tspeed: 0.1043s/iter; left time: 2068.9714s\n",
      "\titers: 200, epoch: 12 | loss: 0.0730791\n",
      "\tspeed: 0.0558s/iter; left time: 1100.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.64s\n",
      "Steps: 224 | Train Loss: 0.0711605 Vali Loss: 0.0868916 Test Loss: 0.0890513\n",
      "Validation loss decreased (0.087003 --> 0.086892).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0658389\n",
      "\tspeed: 0.1142s/iter; left time: 2239.2991s\n",
      "\titers: 200, epoch: 13 | loss: 0.0685006\n",
      "\tspeed: 0.0560s/iter; left time: 1092.6389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0708652 Vali Loss: 0.0865712 Test Loss: 0.0891132\n",
      "Validation loss decreased (0.086892 --> 0.086571).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0742952\n",
      "\tspeed: 0.1126s/iter; left time: 2182.2989s\n",
      "\titers: 200, epoch: 14 | loss: 0.0701290\n",
      "\tspeed: 0.0551s/iter; left time: 1061.8919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.80s\n",
      "Steps: 224 | Train Loss: 0.0706609 Vali Loss: 0.0864862 Test Loss: 0.0889904\n",
      "Validation loss decreased (0.086571 --> 0.086486).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0725446\n",
      "\tspeed: 0.1035s/iter; left time: 1984.5202s\n",
      "\titers: 200, epoch: 15 | loss: 0.0695209\n",
      "\tspeed: 0.0597s/iter; left time: 1137.5607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.47s\n",
      "Steps: 224 | Train Loss: 0.0704827 Vali Loss: 0.0864452 Test Loss: 0.0889387\n",
      "Validation loss decreased (0.086486 --> 0.086445).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0676632\n",
      "\tspeed: 0.1077s/iter; left time: 2040.1226s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735662\n",
      "\tspeed: 0.0561s/iter; left time: 1057.4622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.15s\n",
      "Steps: 224 | Train Loss: 0.0703078 Vali Loss: 0.0865087 Test Loss: 0.0890939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0669014\n",
      "\tspeed: 0.1090s/iter; left time: 2040.5869s\n",
      "\titers: 200, epoch: 17 | loss: 0.0692772\n",
      "\tspeed: 0.0592s/iter; left time: 1102.1735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:13.67s\n",
      "Steps: 224 | Train Loss: 0.0701388 Vali Loss: 0.0867771 Test Loss: 0.0890331\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0704841\n",
      "\tspeed: 0.1057s/iter; left time: 1954.3020s\n",
      "\titers: 200, epoch: 18 | loss: 0.0685036\n",
      "\tspeed: 0.0587s/iter; left time: 1079.3178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:13.85s\n",
      "Steps: 224 | Train Loss: 0.0699684 Vali Loss: 0.0864049 Test Loss: 0.0891183\n",
      "Validation loss decreased (0.086445 --> 0.086405).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0693344\n",
      "\tspeed: 0.1055s/iter; left time: 1927.7743s\n",
      "\titers: 200, epoch: 19 | loss: 0.0699148\n",
      "\tspeed: 0.0550s/iter; left time: 999.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 224 | Train Loss: 0.0698359 Vali Loss: 0.0864480 Test Loss: 0.0891146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0743156\n",
      "\tspeed: 0.1059s/iter; left time: 1911.6289s\n",
      "\titers: 200, epoch: 20 | loss: 0.0695782\n",
      "\tspeed: 0.0594s/iter; left time: 1066.5926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.56s\n",
      "Steps: 224 | Train Loss: 0.0698212 Vali Loss: 0.0862729 Test Loss: 0.0889007\n",
      "Validation loss decreased (0.086405 --> 0.086273).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0642834\n",
      "\tspeed: 0.1121s/iter; left time: 1997.9337s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729156\n",
      "\tspeed: 0.0612s/iter; left time: 1085.2169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:13.99s\n",
      "Steps: 224 | Train Loss: 0.0696815 Vali Loss: 0.0863191 Test Loss: 0.0889219\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0668081\n",
      "\tspeed: 0.1009s/iter; left time: 1775.3507s\n",
      "\titers: 200, epoch: 22 | loss: 0.0675850\n",
      "\tspeed: 0.0618s/iter; left time: 1081.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:13.31s\n",
      "Steps: 224 | Train Loss: 0.0696013 Vali Loss: 0.0863717 Test Loss: 0.0890059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0662554\n",
      "\tspeed: 0.1074s/iter; left time: 1866.0530s\n",
      "\titers: 200, epoch: 23 | loss: 0.0715963\n",
      "\tspeed: 0.0552s/iter; left time: 953.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 224 | Train Loss: 0.0694505 Vali Loss: 0.0862607 Test Loss: 0.0890646\n",
      "Validation loss decreased (0.086273 --> 0.086261).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0695211\n",
      "\tspeed: 0.1088s/iter; left time: 1865.6883s\n",
      "\titers: 200, epoch: 24 | loss: 0.0653179\n",
      "\tspeed: 0.0605s/iter; left time: 1030.7645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0693793 Vali Loss: 0.0863263 Test Loss: 0.0889909\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0677006\n",
      "\tspeed: 0.1094s/iter; left time: 1852.2941s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705059\n",
      "\tspeed: 0.0630s/iter; left time: 1059.6397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:13.56s\n",
      "Steps: 224 | Train Loss: 0.0693588 Vali Loss: 0.0863821 Test Loss: 0.0890807\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0654885\n",
      "\tspeed: 0.1090s/iter; left time: 1820.0963s\n",
      "\titers: 200, epoch: 26 | loss: 0.0649945\n",
      "\tspeed: 0.0556s/iter; left time: 922.1987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 224 | Train Loss: 0.0692742 Vali Loss: 0.0864751 Test Loss: 0.0893381\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0677808\n",
      "\tspeed: 0.1062s/iter; left time: 1750.5089s\n",
      "\titers: 200, epoch: 27 | loss: 0.0714075\n",
      "\tspeed: 0.0584s/iter; left time: 956.2470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:13.48s\n",
      "Steps: 224 | Train Loss: 0.0692092 Vali Loss: 0.0862476 Test Loss: 0.0890449\n",
      "Validation loss decreased (0.086261 --> 0.086248).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0650818\n",
      "\tspeed: 0.1048s/iter; left time: 1703.4446s\n",
      "\titers: 200, epoch: 28 | loss: 0.0720823\n",
      "\tspeed: 0.0545s/iter; left time: 879.8395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 224 | Train Loss: 0.0691955 Vali Loss: 0.0863042 Test Loss: 0.0889602\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0675507\n",
      "\tspeed: 0.1084s/iter; left time: 1737.1795s\n",
      "\titers: 200, epoch: 29 | loss: 0.0689953\n",
      "\tspeed: 0.0561s/iter; left time: 893.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 224 | Train Loss: 0.0691315 Vali Loss: 0.0862055 Test Loss: 0.0891577\n",
      "Validation loss decreased (0.086248 --> 0.086206).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0723119\n",
      "\tspeed: 0.1085s/iter; left time: 1714.8481s\n",
      "\titers: 200, epoch: 30 | loss: 0.0689444\n",
      "\tspeed: 0.0577s/iter; left time: 906.0195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:13.10s\n",
      "Steps: 224 | Train Loss: 0.0690726 Vali Loss: 0.0864122 Test Loss: 0.0891799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0699471\n",
      "\tspeed: 0.1054s/iter; left time: 1642.1746s\n",
      "\titers: 200, epoch: 31 | loss: 0.0650906\n",
      "\tspeed: 0.0618s/iter; left time: 957.4996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:13.60s\n",
      "Steps: 224 | Train Loss: 0.0690898 Vali Loss: 0.0861617 Test Loss: 0.0890982\n",
      "Validation loss decreased (0.086206 --> 0.086162).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0697123\n",
      "\tspeed: 0.1097s/iter; left time: 1685.1736s\n",
      "\titers: 200, epoch: 32 | loss: 0.0689837\n",
      "\tspeed: 0.0554s/iter; left time: 845.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:12.91s\n",
      "Steps: 224 | Train Loss: 0.0690290 Vali Loss: 0.0862783 Test Loss: 0.0891600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0689367\n",
      "\tspeed: 0.1053s/iter; left time: 1593.4990s\n",
      "\titers: 200, epoch: 33 | loss: 0.0651389\n",
      "\tspeed: 0.0590s/iter; left time: 887.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:13.42s\n",
      "Steps: 224 | Train Loss: 0.0689599 Vali Loss: 0.0864315 Test Loss: 0.0891968\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0703542\n",
      "\tspeed: 0.1158s/iter; left time: 1726.6573s\n",
      "\titers: 200, epoch: 34 | loss: 0.0736774\n",
      "\tspeed: 0.0578s/iter; left time: 856.6035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:13.45s\n",
      "Steps: 224 | Train Loss: 0.0689449 Vali Loss: 0.0863892 Test Loss: 0.0892073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0694088\n",
      "\tspeed: 0.1057s/iter; left time: 1552.5538s\n",
      "\titers: 200, epoch: 35 | loss: 0.0643488\n",
      "\tspeed: 0.0601s/iter; left time: 877.1630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:13.32s\n",
      "Steps: 224 | Train Loss: 0.0689930 Vali Loss: 0.0862459 Test Loss: 0.0891558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0662179\n",
      "\tspeed: 0.1103s/iter; left time: 1595.0316s\n",
      "\titers: 200, epoch: 36 | loss: 0.0716586\n",
      "\tspeed: 0.0592s/iter; left time: 850.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:13.50s\n",
      "Steps: 224 | Train Loss: 0.0689090 Vali Loss: 0.0862916 Test Loss: 0.0891562\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0689815\n",
      "\tspeed: 0.1066s/iter; left time: 1518.0397s\n",
      "\titers: 200, epoch: 37 | loss: 0.0692148\n",
      "\tspeed: 0.0601s/iter; left time: 849.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:13.08s\n",
      "Steps: 224 | Train Loss: 0.0688933 Vali Loss: 0.0864036 Test Loss: 0.0891469\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0756959\n",
      "\tspeed: 0.1132s/iter; left time: 1586.1138s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706713\n",
      "\tspeed: 0.0590s/iter; left time: 821.2138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:13.79s\n",
      "Steps: 224 | Train Loss: 0.0689504 Vali Loss: 0.0863323 Test Loss: 0.0891482\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0717678\n",
      "\tspeed: 0.1060s/iter; left time: 1461.6020s\n",
      "\titers: 200, epoch: 39 | loss: 0.0696688\n",
      "\tspeed: 0.0551s/iter; left time: 753.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:12.96s\n",
      "Steps: 224 | Train Loss: 0.0688292 Vali Loss: 0.0862189 Test Loss: 0.0891291\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0669256\n",
      "\tspeed: 0.1134s/iter; left time: 1538.2286s\n",
      "\titers: 200, epoch: 40 | loss: 0.0677449\n",
      "\tspeed: 0.0599s/iter; left time: 806.5116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:13.63s\n",
      "Steps: 224 | Train Loss: 0.0688930 Vali Loss: 0.0861876 Test Loss: 0.0891016\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0648098\n",
      "\tspeed: 0.1024s/iter; left time: 1365.9288s\n",
      "\titers: 200, epoch: 41 | loss: 0.0646161\n",
      "\tspeed: 0.0549s/iter; left time: 727.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 224 | Train Loss: 0.0688258 Vali Loss: 0.0862216 Test Loss: 0.0891206\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021291740238666534, rmse:0.1459168940782547, mae:0.08909820020198822, rse:0.5149609446525574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1485177\n",
      "\tspeed: 0.0642s/iter; left time: 1431.6516s\n",
      "\titers: 200, epoch: 1 | loss: 0.1372107\n",
      "\tspeed: 0.0598s/iter; left time: 1326.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.91s\n",
      "Steps: 224 | Train Loss: 0.1479508 Vali Loss: 0.1469130 Test Loss: 0.1552787\n",
      "Validation loss decreased (inf --> 0.146913).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0860679\n",
      "\tspeed: 0.1167s/iter; left time: 2575.3244s\n",
      "\titers: 200, epoch: 2 | loss: 0.0842555\n",
      "\tspeed: 0.0577s/iter; left time: 1267.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.36s\n",
      "Steps: 224 | Train Loss: 0.0963806 Vali Loss: 0.0965345 Test Loss: 0.0970062\n",
      "Validation loss decreased (0.146913 --> 0.096534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0792745\n",
      "\tspeed: 0.1132s/iter; left time: 2473.5513s\n",
      "\titers: 200, epoch: 3 | loss: 0.0799089\n",
      "\tspeed: 0.0573s/iter; left time: 1245.4329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.42s\n",
      "Steps: 224 | Train Loss: 0.0806034 Vali Loss: 0.0915469 Test Loss: 0.0932558\n",
      "Validation loss decreased (0.096534 --> 0.091547).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0692745\n",
      "\tspeed: 0.1043s/iter; left time: 2255.4926s\n",
      "\titers: 200, epoch: 4 | loss: 0.0753272\n",
      "\tspeed: 0.0545s/iter; left time: 1173.7106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 224 | Train Loss: 0.0771334 Vali Loss: 0.0894109 Test Loss: 0.0913275\n",
      "Validation loss decreased (0.091547 --> 0.089411).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0780892\n",
      "\tspeed: 0.1123s/iter; left time: 2403.0300s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733127\n",
      "\tspeed: 0.0612s/iter; left time: 1304.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:14.16s\n",
      "Steps: 224 | Train Loss: 0.0752457 Vali Loss: 0.0887977 Test Loss: 0.0907949\n",
      "Validation loss decreased (0.089411 --> 0.088798).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0735669\n",
      "\tspeed: 0.1116s/iter; left time: 2364.5836s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754406\n",
      "\tspeed: 0.0583s/iter; left time: 1228.0276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.49s\n",
      "Steps: 224 | Train Loss: 0.0741429 Vali Loss: 0.0879942 Test Loss: 0.0900813\n",
      "Validation loss decreased (0.088798 --> 0.087994).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0708586\n",
      "\tspeed: 0.1091s/iter; left time: 2286.0543s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723750\n",
      "\tspeed: 0.0594s/iter; left time: 1238.7991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 224 | Train Loss: 0.0733710 Vali Loss: 0.0877222 Test Loss: 0.0897023\n",
      "Validation loss decreased (0.087994 --> 0.087722).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0735653\n",
      "\tspeed: 0.1129s/iter; left time: 2341.2692s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752200\n",
      "\tspeed: 0.0541s/iter; left time: 1116.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.91s\n",
      "Steps: 224 | Train Loss: 0.0726825 Vali Loss: 0.0871324 Test Loss: 0.0893786\n",
      "Validation loss decreased (0.087722 --> 0.087132).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738944\n",
      "\tspeed: 0.1040s/iter; left time: 2132.0176s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740931\n",
      "\tspeed: 0.0640s/iter; left time: 1305.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.78s\n",
      "Steps: 224 | Train Loss: 0.0721897 Vali Loss: 0.0869960 Test Loss: 0.0890788\n",
      "Validation loss decreased (0.087132 --> 0.086996).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751932\n",
      "\tspeed: 0.1101s/iter; left time: 2233.2273s\n",
      "\titers: 200, epoch: 10 | loss: 0.0673028\n",
      "\tspeed: 0.0570s/iter; left time: 1150.5692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.90s\n",
      "Steps: 224 | Train Loss: 0.0717408 Vali Loss: 0.0867880 Test Loss: 0.0891405\n",
      "Validation loss decreased (0.086996 --> 0.086788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0667565\n",
      "\tspeed: 0.1083s/iter; left time: 2172.1899s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711614\n",
      "\tspeed: 0.0539s/iter; left time: 1076.0933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.12s\n",
      "Steps: 224 | Train Loss: 0.0714507 Vali Loss: 0.0870664 Test Loss: 0.0891779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710983\n",
      "\tspeed: 0.1155s/iter; left time: 2291.6253s\n",
      "\titers: 200, epoch: 12 | loss: 0.0680309\n",
      "\tspeed: 0.0604s/iter; left time: 1191.7242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.79s\n",
      "Steps: 224 | Train Loss: 0.0711380 Vali Loss: 0.0867219 Test Loss: 0.0890017\n",
      "Validation loss decreased (0.086788 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719549\n",
      "\tspeed: 0.1036s/iter; left time: 2032.7055s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728736\n",
      "\tspeed: 0.0565s/iter; left time: 1102.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.93s\n",
      "Steps: 224 | Train Loss: 0.0709379 Vali Loss: 0.0864662 Test Loss: 0.0890279\n",
      "Validation loss decreased (0.086722 --> 0.086466).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0695809\n",
      "\tspeed: 0.1169s/iter; left time: 2266.0128s\n",
      "\titers: 200, epoch: 14 | loss: 0.0691624\n",
      "\tspeed: 0.0567s/iter; left time: 1094.3885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.46s\n",
      "Steps: 224 | Train Loss: 0.0707244 Vali Loss: 0.0867192 Test Loss: 0.0890669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662107\n",
      "\tspeed: 0.1080s/iter; left time: 2068.9820s\n",
      "\titers: 200, epoch: 15 | loss: 0.0770034\n",
      "\tspeed: 0.0590s/iter; left time: 1123.9896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.23s\n",
      "Steps: 224 | Train Loss: 0.0704650 Vali Loss: 0.0864952 Test Loss: 0.0890869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746670\n",
      "\tspeed: 0.1099s/iter; left time: 2081.2405s\n",
      "\titers: 200, epoch: 16 | loss: 0.0751349\n",
      "\tspeed: 0.0592s/iter; left time: 1114.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.66s\n",
      "Steps: 224 | Train Loss: 0.0703478 Vali Loss: 0.0866213 Test Loss: 0.0890552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0691212\n",
      "\tspeed: 0.1024s/iter; left time: 1916.3587s\n",
      "\titers: 200, epoch: 17 | loss: 0.0701027\n",
      "\tspeed: 0.0543s/iter; left time: 1011.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.46s\n",
      "Steps: 224 | Train Loss: 0.0701723 Vali Loss: 0.0864791 Test Loss: 0.0890113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0723499\n",
      "\tspeed: 0.1138s/iter; left time: 2105.1329s\n",
      "\titers: 200, epoch: 18 | loss: 0.0661663\n",
      "\tspeed: 0.0561s/iter; left time: 1032.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:13.59s\n",
      "Steps: 224 | Train Loss: 0.0700250 Vali Loss: 0.0864334 Test Loss: 0.0889767\n",
      "Validation loss decreased (0.086466 --> 0.086433).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0676247\n",
      "\tspeed: 0.1071s/iter; left time: 1956.6899s\n",
      "\titers: 200, epoch: 19 | loss: 0.0656377\n",
      "\tspeed: 0.0583s/iter; left time: 1059.9005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:13.45s\n",
      "Steps: 224 | Train Loss: 0.0698972 Vali Loss: 0.0863700 Test Loss: 0.0890557\n",
      "Validation loss decreased (0.086433 --> 0.086370).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0731429\n",
      "\tspeed: 0.1128s/iter; left time: 2035.8120s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692441\n",
      "\tspeed: 0.0577s/iter; left time: 1034.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.28s\n",
      "Steps: 224 | Train Loss: 0.0697965 Vali Loss: 0.0862033 Test Loss: 0.0890447\n",
      "Validation loss decreased (0.086370 --> 0.086203).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0687015\n",
      "\tspeed: 0.1153s/iter; left time: 2054.9168s\n",
      "\titers: 200, epoch: 21 | loss: 0.0658207\n",
      "\tspeed: 0.0561s/iter; left time: 994.2180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:13.01s\n",
      "Steps: 224 | Train Loss: 0.0696816 Vali Loss: 0.0863567 Test Loss: 0.0893161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0706210\n",
      "\tspeed: 0.1059s/iter; left time: 1864.3488s\n",
      "\titers: 200, epoch: 22 | loss: 0.0746962\n",
      "\tspeed: 0.0614s/iter; left time: 1074.4262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:13.81s\n",
      "Steps: 224 | Train Loss: 0.0696258 Vali Loss: 0.0863918 Test Loss: 0.0891025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0717456\n",
      "\tspeed: 0.1123s/iter; left time: 1950.4919s\n",
      "\titers: 200, epoch: 23 | loss: 0.0713271\n",
      "\tspeed: 0.0559s/iter; left time: 964.8673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 224 | Train Loss: 0.0695054 Vali Loss: 0.0861524 Test Loss: 0.0890253\n",
      "Validation loss decreased (0.086203 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0754816\n",
      "\tspeed: 0.1071s/iter; left time: 1836.7928s\n",
      "\titers: 200, epoch: 24 | loss: 0.0685918\n",
      "\tspeed: 0.0620s/iter; left time: 1057.7560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:13.69s\n",
      "Steps: 224 | Train Loss: 0.0694104 Vali Loss: 0.0862667 Test Loss: 0.0890559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0633278\n",
      "\tspeed: 0.1122s/iter; left time: 1898.7872s\n",
      "\titers: 200, epoch: 25 | loss: 0.0648984\n",
      "\tspeed: 0.0580s/iter; left time: 976.0780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:13.26s\n",
      "Steps: 224 | Train Loss: 0.0693590 Vali Loss: 0.0861933 Test Loss: 0.0891097\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0697152\n",
      "\tspeed: 0.1026s/iter; left time: 1713.9152s\n",
      "\titers: 200, epoch: 26 | loss: 0.0684530\n",
      "\tspeed: 0.0620s/iter; left time: 1028.7486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:13.39s\n",
      "Steps: 224 | Train Loss: 0.0692901 Vali Loss: 0.0861402 Test Loss: 0.0891699\n",
      "Validation loss decreased (0.086152 --> 0.086140).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0680913\n",
      "\tspeed: 0.1144s/iter; left time: 1885.3376s\n",
      "\titers: 200, epoch: 27 | loss: 0.0710975\n",
      "\tspeed: 0.0599s/iter; left time: 980.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:13.73s\n",
      "Steps: 224 | Train Loss: 0.0692415 Vali Loss: 0.0861493 Test Loss: 0.0890312\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662386\n",
      "\tspeed: 0.1126s/iter; left time: 1830.1786s\n",
      "\titers: 200, epoch: 28 | loss: 0.0694833\n",
      "\tspeed: 0.0568s/iter; left time: 917.1492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:13.50s\n",
      "Steps: 224 | Train Loss: 0.0691602 Vali Loss: 0.0861183 Test Loss: 0.0892049\n",
      "Validation loss decreased (0.086140 --> 0.086118).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0725555\n",
      "\tspeed: 0.1098s/iter; left time: 1760.6731s\n",
      "\titers: 200, epoch: 29 | loss: 0.0715661\n",
      "\tspeed: 0.0589s/iter; left time: 938.3964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:13.34s\n",
      "Steps: 224 | Train Loss: 0.0691908 Vali Loss: 0.0860879 Test Loss: 0.0891321\n",
      "Validation loss decreased (0.086118 --> 0.086088).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0675764\n",
      "\tspeed: 0.1087s/iter; left time: 1718.6968s\n",
      "\titers: 200, epoch: 30 | loss: 0.0685819\n",
      "\tspeed: 0.0553s/iter; left time: 867.9731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 224 | Train Loss: 0.0691524 Vali Loss: 0.0860893 Test Loss: 0.0891131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0705770\n",
      "\tspeed: 0.1216s/iter; left time: 1894.8321s\n",
      "\titers: 200, epoch: 31 | loss: 0.0713090\n",
      "\tspeed: 0.0625s/iter; left time: 968.3353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:14.10s\n",
      "Steps: 224 | Train Loss: 0.0691323 Vali Loss: 0.0861251 Test Loss: 0.0891209\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725021\n",
      "\tspeed: 0.1154s/iter; left time: 1772.5103s\n",
      "\titers: 200, epoch: 32 | loss: 0.0674104\n",
      "\tspeed: 0.0619s/iter; left time: 944.8322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:13.85s\n",
      "Steps: 224 | Train Loss: 0.0690699 Vali Loss: 0.0860819 Test Loss: 0.0890955\n",
      "Validation loss decreased (0.086088 --> 0.086082).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0671740\n",
      "\tspeed: 0.1092s/iter; left time: 1652.7979s\n",
      "\titers: 200, epoch: 33 | loss: 0.0640508\n",
      "\tspeed: 0.0584s/iter; left time: 878.2166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:13.32s\n",
      "Steps: 224 | Train Loss: 0.0690287 Vali Loss: 0.0861212 Test Loss: 0.0891954\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0705414\n",
      "\tspeed: 0.1085s/iter; left time: 1618.0143s\n",
      "\titers: 200, epoch: 34 | loss: 0.0681740\n",
      "\tspeed: 0.0565s/iter; left time: 836.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:13.13s\n",
      "Steps: 224 | Train Loss: 0.0689596 Vali Loss: 0.0862194 Test Loss: 0.0890935\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0701695\n",
      "\tspeed: 0.1131s/iter; left time: 1660.2730s\n",
      "\titers: 200, epoch: 35 | loss: 0.0673041\n",
      "\tspeed: 0.0611s/iter; left time: 890.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:14.33s\n",
      "Steps: 224 | Train Loss: 0.0689486 Vali Loss: 0.0861580 Test Loss: 0.0891037\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0642554\n",
      "\tspeed: 0.1128s/iter; left time: 1631.1077s\n",
      "\titers: 200, epoch: 36 | loss: 0.0672532\n",
      "\tspeed: 0.0584s/iter; left time: 838.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:13.69s\n",
      "Steps: 224 | Train Loss: 0.0689205 Vali Loss: 0.0860491 Test Loss: 0.0890471\n",
      "Validation loss decreased (0.086082 --> 0.086049).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0744950\n",
      "\tspeed: 0.1191s/iter; left time: 1695.3830s\n",
      "\titers: 200, epoch: 37 | loss: 0.0638594\n",
      "\tspeed: 0.0625s/iter; left time: 883.3956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:14.20s\n",
      "Steps: 224 | Train Loss: 0.0689579 Vali Loss: 0.0861269 Test Loss: 0.0891083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0700178\n",
      "\tspeed: 0.1095s/iter; left time: 1533.7685s\n",
      "\titers: 200, epoch: 38 | loss: 0.0661885\n",
      "\tspeed: 0.0608s/iter; left time: 845.2275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:13.97s\n",
      "Steps: 224 | Train Loss: 0.0688744 Vali Loss: 0.0861560 Test Loss: 0.0891225\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0645115\n",
      "\tspeed: 0.1089s/iter; left time: 1501.7712s\n",
      "\titers: 200, epoch: 39 | loss: 0.0643578\n",
      "\tspeed: 0.0609s/iter; left time: 833.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:13.74s\n",
      "Steps: 224 | Train Loss: 0.0689252 Vali Loss: 0.0861439 Test Loss: 0.0890523\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712911\n",
      "\tspeed: 0.1159s/iter; left time: 1571.9836s\n",
      "\titers: 200, epoch: 40 | loss: 0.0740808\n",
      "\tspeed: 0.0627s/iter; left time: 844.8544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:14.39s\n",
      "Steps: 224 | Train Loss: 0.0688536 Vali Loss: 0.0859760 Test Loss: 0.0890604\n",
      "Validation loss decreased (0.086049 --> 0.085976).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0645042\n",
      "\tspeed: 0.1055s/iter; left time: 1407.9849s\n",
      "\titers: 200, epoch: 41 | loss: 0.0700506\n",
      "\tspeed: 0.0566s/iter; left time: 749.9002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:12.89s\n",
      "Steps: 224 | Train Loss: 0.0688851 Vali Loss: 0.0861665 Test Loss: 0.0890974\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0722492\n",
      "\tspeed: 0.1125s/iter; left time: 1476.2207s\n",
      "\titers: 200, epoch: 42 | loss: 0.0705930\n",
      "\tspeed: 0.0586s/iter; left time: 762.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:14.39s\n",
      "Steps: 224 | Train Loss: 0.0688321 Vali Loss: 0.0860264 Test Loss: 0.0891213\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0742681\n",
      "\tspeed: 0.1142s/iter; left time: 1472.9474s\n",
      "\titers: 200, epoch: 43 | loss: 0.0690211\n",
      "\tspeed: 0.0563s/iter; left time: 719.6545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:13.31s\n",
      "Steps: 224 | Train Loss: 0.0688786 Vali Loss: 0.0860898 Test Loss: 0.0890831\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0646683\n",
      "\tspeed: 0.1049s/iter; left time: 1329.5554s\n",
      "\titers: 200, epoch: 44 | loss: 0.0692453\n",
      "\tspeed: 0.0570s/iter; left time: 715.9026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:13.08s\n",
      "Steps: 224 | Train Loss: 0.0688329 Vali Loss: 0.0861044 Test Loss: 0.0890925\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0659040\n",
      "\tspeed: 0.1146s/iter; left time: 1426.1428s\n",
      "\titers: 200, epoch: 45 | loss: 0.0643121\n",
      "\tspeed: 0.0587s/iter; left time: 724.9735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0688306 Vali Loss: 0.0860788 Test Loss: 0.0891090\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0707033\n",
      "\tspeed: 0.1103s/iter; left time: 1347.6758s\n",
      "\titers: 200, epoch: 46 | loss: 0.0666583\n",
      "\tspeed: 0.0568s/iter; left time: 688.8852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:13.22s\n",
      "Steps: 224 | Train Loss: 0.0687669 Vali Loss: 0.0861802 Test Loss: 0.0891388\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0668203\n",
      "\tspeed: 0.1211s/iter; left time: 1452.4676s\n",
      "\titers: 200, epoch: 47 | loss: 0.0678259\n",
      "\tspeed: 0.0637s/iter; left time: 757.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:13.79s\n",
      "Steps: 224 | Train Loss: 0.0687843 Vali Loss: 0.0860328 Test Loss: 0.0891000\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0671443\n",
      "\tspeed: 0.1093s/iter; left time: 1286.5093s\n",
      "\titers: 200, epoch: 48 | loss: 0.0705720\n",
      "\tspeed: 0.0573s/iter; left time: 668.4024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:13.46s\n",
      "Steps: 224 | Train Loss: 0.0687883 Vali Loss: 0.0860063 Test Loss: 0.0891141\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0660993\n",
      "\tspeed: 0.1040s/iter; left time: 1200.5301s\n",
      "\titers: 200, epoch: 49 | loss: 0.0729448\n",
      "\tspeed: 0.0600s/iter; left time: 687.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:13.42s\n",
      "Steps: 224 | Train Loss: 0.0687500 Vali Loss: 0.0861000 Test Loss: 0.0891243\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0677664\n",
      "\tspeed: 0.1224s/iter; left time: 1386.2367s\n",
      "\titers: 200, epoch: 50 | loss: 0.0669769\n",
      "\tspeed: 0.0562s/iter; left time: 630.5606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:13.47s\n",
      "Steps: 224 | Train Loss: 0.0687967 Vali Loss: 0.0861120 Test Loss: 0.0891771\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02123580500483513, rmse:0.1457251012325287, mae:0.08906044065952301, rse:0.514284074306488\n",
      "Intermediate time for DE and pred_len 24: 00h:25m:41.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1550613\n",
      "\tspeed: 0.0879s/iter; left time: 1960.5890s\n",
      "\titers: 200, epoch: 1 | loss: 0.1477888\n",
      "\tspeed: 0.0597s/iter; left time: 1325.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.15s\n",
      "Steps: 224 | Train Loss: 0.1587900 Vali Loss: 0.1620391 Test Loss: 0.1741875\n",
      "Validation loss decreased (inf --> 0.162039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160155\n",
      "\tspeed: 0.1151s/iter; left time: 2541.1799s\n",
      "\titers: 200, epoch: 2 | loss: 0.1055968\n",
      "\tspeed: 0.0557s/iter; left time: 1224.1456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.09s\n",
      "Steps: 224 | Train Loss: 0.1189358 Vali Loss: 0.1230573 Test Loss: 0.1298083\n",
      "Validation loss decreased (0.162039 --> 0.123057).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1057696\n",
      "\tspeed: 0.1157s/iter; left time: 2528.3741s\n",
      "\titers: 200, epoch: 3 | loss: 0.1068358\n",
      "\tspeed: 0.0590s/iter; left time: 1282.9606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.54s\n",
      "Steps: 224 | Train Loss: 0.1064453 Vali Loss: 0.1199574 Test Loss: 0.1270489\n",
      "Validation loss decreased (0.123057 --> 0.119957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1014582\n",
      "\tspeed: 0.1120s/iter; left time: 2423.3132s\n",
      "\titers: 200, epoch: 4 | loss: 0.0987709\n",
      "\tspeed: 0.0618s/iter; left time: 1330.2460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.30s\n",
      "Steps: 224 | Train Loss: 0.1033780 Vali Loss: 0.1184104 Test Loss: 0.1268103\n",
      "Validation loss decreased (0.119957 --> 0.118410).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1038326\n",
      "\tspeed: 0.1089s/iter; left time: 2331.2458s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999108\n",
      "\tspeed: 0.0531s/iter; left time: 1131.0513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 224 | Train Loss: 0.1016363 Vali Loss: 0.1186604 Test Loss: 0.1271338\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0998692\n",
      "\tspeed: 0.1094s/iter; left time: 2318.1156s\n",
      "\titers: 200, epoch: 6 | loss: 0.1016956\n",
      "\tspeed: 0.0655s/iter; left time: 1380.5812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.97s\n",
      "Steps: 224 | Train Loss: 0.1003976 Vali Loss: 0.1183543 Test Loss: 0.1267805\n",
      "Validation loss decreased (0.118410 --> 0.118354).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0950561\n",
      "\tspeed: 0.1209s/iter; left time: 2534.3403s\n",
      "\titers: 200, epoch: 7 | loss: 0.1018301\n",
      "\tspeed: 0.0589s/iter; left time: 1229.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.96s\n",
      "Steps: 224 | Train Loss: 0.0993858 Vali Loss: 0.1191201 Test Loss: 0.1267930\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0975684\n",
      "\tspeed: 0.1074s/iter; left time: 2227.5680s\n",
      "\titers: 200, epoch: 8 | loss: 0.0958021\n",
      "\tspeed: 0.0661s/iter; left time: 1364.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.20s\n",
      "Steps: 224 | Train Loss: 0.0985251 Vali Loss: 0.1189736 Test Loss: 0.1276529\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0942768\n",
      "\tspeed: 0.1232s/iter; left time: 2527.6758s\n",
      "\titers: 200, epoch: 9 | loss: 0.0987583\n",
      "\tspeed: 0.0578s/iter; left time: 1178.7021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.44s\n",
      "Steps: 224 | Train Loss: 0.0976029 Vali Loss: 0.1196053 Test Loss: 0.1274840\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0960662\n",
      "\tspeed: 0.1121s/iter; left time: 2274.5692s\n",
      "\titers: 200, epoch: 10 | loss: 0.0947696\n",
      "\tspeed: 0.0574s/iter; left time: 1159.3982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 224 | Train Loss: 0.0968994 Vali Loss: 0.1194730 Test Loss: 0.1282073\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0937361\n",
      "\tspeed: 0.1072s/iter; left time: 2151.2537s\n",
      "\titers: 200, epoch: 11 | loss: 0.0961174\n",
      "\tspeed: 0.0536s/iter; left time: 1069.2231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 224 | Train Loss: 0.0961025 Vali Loss: 0.1201492 Test Loss: 0.1287695\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0976077\n",
      "\tspeed: 0.1233s/iter; left time: 2445.9063s\n",
      "\titers: 200, epoch: 12 | loss: 0.0968714\n",
      "\tspeed: 0.0577s/iter; left time: 1139.5975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.14s\n",
      "Steps: 224 | Train Loss: 0.0954843 Vali Loss: 0.1202374 Test Loss: 0.1301523\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0951096\n",
      "\tspeed: 0.1277s/iter; left time: 2504.9425s\n",
      "\titers: 200, epoch: 13 | loss: 0.0931655\n",
      "\tspeed: 0.0634s/iter; left time: 1237.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.51s\n",
      "Steps: 224 | Train Loss: 0.0946925 Vali Loss: 0.1202413 Test Loss: 0.1300704\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0932792\n",
      "\tspeed: 0.1143s/iter; left time: 2216.5050s\n",
      "\titers: 200, epoch: 14 | loss: 0.0952017\n",
      "\tspeed: 0.0635s/iter; left time: 1224.1402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.59s\n",
      "Steps: 224 | Train Loss: 0.0941036 Vali Loss: 0.1202730 Test Loss: 0.1306375\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0893586\n",
      "\tspeed: 0.1131s/iter; left time: 2168.2961s\n",
      "\titers: 200, epoch: 15 | loss: 0.0917358\n",
      "\tspeed: 0.0572s/iter; left time: 1090.6986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.84s\n",
      "Steps: 224 | Train Loss: 0.0935348 Vali Loss: 0.1209930 Test Loss: 0.1316901\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0920206\n",
      "\tspeed: 0.1243s/iter; left time: 2354.7470s\n",
      "\titers: 200, epoch: 16 | loss: 0.0893951\n",
      "\tspeed: 0.0540s/iter; left time: 1017.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.23s\n",
      "Steps: 224 | Train Loss: 0.0930603 Vali Loss: 0.1205535 Test Loss: 0.1314782\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03634786978363991, rmse:0.19065117835998535, mae:0.12678050994873047, rse:0.6751343607902527\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1646978\n",
      "\tspeed: 0.0619s/iter; left time: 1380.7575s\n",
      "\titers: 200, epoch: 1 | loss: 0.1596227\n",
      "\tspeed: 0.0595s/iter; left time: 1321.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.51s\n",
      "Steps: 224 | Train Loss: 0.1592930 Vali Loss: 0.1618121 Test Loss: 0.1739579\n",
      "Validation loss decreased (inf --> 0.161812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1183173\n",
      "\tspeed: 0.1286s/iter; left time: 2840.0484s\n",
      "\titers: 200, epoch: 2 | loss: 0.1138795\n",
      "\tspeed: 0.0585s/iter; left time: 1285.5709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.32s\n",
      "Steps: 224 | Train Loss: 0.1198862 Vali Loss: 0.1227517 Test Loss: 0.1297694\n",
      "Validation loss decreased (0.161812 --> 0.122752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1076060\n",
      "\tspeed: 0.1165s/iter; left time: 2545.1227s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004281\n",
      "\tspeed: 0.0611s/iter; left time: 1329.1101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:14.05s\n",
      "Steps: 224 | Train Loss: 0.1062988 Vali Loss: 0.1194519 Test Loss: 0.1273959\n",
      "Validation loss decreased (0.122752 --> 0.119452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068373\n",
      "\tspeed: 0.1113s/iter; left time: 2407.1785s\n",
      "\titers: 200, epoch: 4 | loss: 0.1038922\n",
      "\tspeed: 0.0573s/iter; left time: 1233.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 224 | Train Loss: 0.1036002 Vali Loss: 0.1188033 Test Loss: 0.1266809\n",
      "Validation loss decreased (0.119452 --> 0.118803).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0981667\n",
      "\tspeed: 0.1115s/iter; left time: 2387.1532s\n",
      "\titers: 200, epoch: 5 | loss: 0.1001305\n",
      "\tspeed: 0.0692s/iter; left time: 1475.1878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:14.55s\n",
      "Steps: 224 | Train Loss: 0.1017561 Vali Loss: 0.1185325 Test Loss: 0.1270410\n",
      "Validation loss decreased (0.118803 --> 0.118533).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1016373\n",
      "\tspeed: 0.1220s/iter; left time: 2583.8403s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977255\n",
      "\tspeed: 0.0619s/iter; left time: 1305.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.89s\n",
      "Steps: 224 | Train Loss: 0.1004691 Vali Loss: 0.1189096 Test Loss: 0.1266581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1057052\n",
      "\tspeed: 0.1135s/iter; left time: 2378.6283s\n",
      "\titers: 200, epoch: 7 | loss: 0.0980047\n",
      "\tspeed: 0.0574s/iter; left time: 1198.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.27s\n",
      "Steps: 224 | Train Loss: 0.0994334 Vali Loss: 0.1192198 Test Loss: 0.1271698\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0998428\n",
      "\tspeed: 0.1250s/iter; left time: 2591.9250s\n",
      "\titers: 200, epoch: 8 | loss: 0.0941586\n",
      "\tspeed: 0.0585s/iter; left time: 1206.5648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.18s\n",
      "Steps: 224 | Train Loss: 0.0984135 Vali Loss: 0.1194942 Test Loss: 0.1277537\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0962894\n",
      "\tspeed: 0.1085s/iter; left time: 2224.4726s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965957\n",
      "\tspeed: 0.0558s/iter; left time: 1139.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 224 | Train Loss: 0.0975901 Vali Loss: 0.1195832 Test Loss: 0.1275134\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0941738\n",
      "\tspeed: 0.1105s/iter; left time: 2242.4810s\n",
      "\titers: 200, epoch: 10 | loss: 0.0928220\n",
      "\tspeed: 0.0530s/iter; left time: 1070.4250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 224 | Train Loss: 0.0966882 Vali Loss: 0.1200024 Test Loss: 0.1288202\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0951017\n",
      "\tspeed: 0.1083s/iter; left time: 2173.0984s\n",
      "\titers: 200, epoch: 11 | loss: 0.0957812\n",
      "\tspeed: 0.0587s/iter; left time: 1171.1527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.47s\n",
      "Steps: 224 | Train Loss: 0.0959330 Vali Loss: 0.1206276 Test Loss: 0.1287879\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0955243\n",
      "\tspeed: 0.1103s/iter; left time: 2187.6588s\n",
      "\titers: 200, epoch: 12 | loss: 0.0936859\n",
      "\tspeed: 0.0562s/iter; left time: 1110.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 224 | Train Loss: 0.0952509 Vali Loss: 0.1204279 Test Loss: 0.1292543\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0911372\n",
      "\tspeed: 0.1038s/iter; left time: 2035.8776s\n",
      "\titers: 200, epoch: 13 | loss: 0.0944463\n",
      "\tspeed: 0.0590s/iter; left time: 1152.2088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0944741 Vali Loss: 0.1204605 Test Loss: 0.1296869\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0935038\n",
      "\tspeed: 0.1094s/iter; left time: 2120.8952s\n",
      "\titers: 200, epoch: 14 | loss: 0.0967305\n",
      "\tspeed: 0.0583s/iter; left time: 1124.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.13s\n",
      "Steps: 224 | Train Loss: 0.0937822 Vali Loss: 0.1207107 Test Loss: 0.1295574\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0885421\n",
      "\tspeed: 0.1101s/iter; left time: 2109.9148s\n",
      "\titers: 200, epoch: 15 | loss: 0.0946899\n",
      "\tspeed: 0.0593s/iter; left time: 1130.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.66s\n",
      "Steps: 224 | Train Loss: 0.0932084 Vali Loss: 0.1205535 Test Loss: 0.1298851\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03631800040602684, rmse:0.1905728280544281, mae:0.12704099714756012, rse:0.6748569011688232\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:14.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1548019\n",
      "\tspeed: 0.0890s/iter; left time: 1975.3877s\n",
      "\titers: 200, epoch: 1 | loss: 0.1487349\n",
      "\tspeed: 0.0559s/iter; left time: 1236.5304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.94s\n",
      "Steps: 223 | Train Loss: 0.1608134 Vali Loss: 0.1642606 Test Loss: 0.1773646\n",
      "Validation loss decreased (inf --> 0.164261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1214235\n",
      "\tspeed: 0.1221s/iter; left time: 2684.6071s\n",
      "\titers: 200, epoch: 2 | loss: 0.1186251\n",
      "\tspeed: 0.0648s/iter; left time: 1416.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:14.13s\n",
      "Steps: 223 | Train Loss: 0.1239817 Vali Loss: 0.1269845 Test Loss: 0.1359027\n",
      "Validation loss decreased (0.164261 --> 0.126984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1170573\n",
      "\tspeed: 0.1070s/iter; left time: 2328.2112s\n",
      "\titers: 200, epoch: 3 | loss: 0.1074152\n",
      "\tspeed: 0.0586s/iter; left time: 1269.1106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.66s\n",
      "Steps: 223 | Train Loss: 0.1123392 Vali Loss: 0.1241037 Test Loss: 0.1344680\n",
      "Validation loss decreased (0.126984 --> 0.124104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1116649\n",
      "\tspeed: 0.1233s/iter; left time: 2655.6638s\n",
      "\titers: 200, epoch: 4 | loss: 0.1098954\n",
      "\tspeed: 0.0619s/iter; left time: 1326.0755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.16s\n",
      "Steps: 223 | Train Loss: 0.1095220 Vali Loss: 0.1238564 Test Loss: 0.1336398\n",
      "Validation loss decreased (0.124104 --> 0.123856).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1103088\n",
      "\tspeed: 0.1119s/iter; left time: 2384.5344s\n",
      "\titers: 200, epoch: 5 | loss: 0.1059337\n",
      "\tspeed: 0.0585s/iter; left time: 1241.3015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:13.14s\n",
      "Steps: 223 | Train Loss: 0.1077120 Vali Loss: 0.1238542 Test Loss: 0.1340634\n",
      "Validation loss decreased (0.123856 --> 0.123854).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1093670\n",
      "\tspeed: 0.1168s/iter; left time: 2463.7163s\n",
      "\titers: 200, epoch: 6 | loss: 0.1044136\n",
      "\tspeed: 0.0605s/iter; left time: 1269.0786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.98s\n",
      "Steps: 223 | Train Loss: 0.1062742 Vali Loss: 0.1234706 Test Loss: 0.1347027\n",
      "Validation loss decreased (0.123854 --> 0.123471).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1005224\n",
      "\tspeed: 0.1134s/iter; left time: 2365.1766s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047263\n",
      "\tspeed: 0.0582s/iter; left time: 1209.2546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.00s\n",
      "Steps: 223 | Train Loss: 0.1051898 Vali Loss: 0.1239938 Test Loss: 0.1345310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1043732\n",
      "\tspeed: 0.1113s/iter; left time: 2298.0534s\n",
      "\titers: 200, epoch: 8 | loss: 0.1046246\n",
      "\tspeed: 0.0625s/iter; left time: 1283.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.65s\n",
      "Steps: 223 | Train Loss: 0.1041525 Vali Loss: 0.1243894 Test Loss: 0.1351599\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1036047\n",
      "\tspeed: 0.1054s/iter; left time: 2151.1381s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000770\n",
      "\tspeed: 0.0598s/iter; left time: 1215.1547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.44s\n",
      "Steps: 223 | Train Loss: 0.1031845 Vali Loss: 0.1245980 Test Loss: 0.1351988\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0945465\n",
      "\tspeed: 0.1079s/iter; left time: 2178.1953s\n",
      "\titers: 200, epoch: 10 | loss: 0.1016872\n",
      "\tspeed: 0.0593s/iter; left time: 1190.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.76s\n",
      "Steps: 223 | Train Loss: 0.1024096 Vali Loss: 0.1248682 Test Loss: 0.1363112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1013406\n",
      "\tspeed: 0.1149s/iter; left time: 2295.0001s\n",
      "\titers: 200, epoch: 11 | loss: 0.1035435\n",
      "\tspeed: 0.0576s/iter; left time: 1145.5459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.34s\n",
      "Steps: 223 | Train Loss: 0.1016130 Vali Loss: 0.1255188 Test Loss: 0.1362312\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0993369\n",
      "\tspeed: 0.1109s/iter; left time: 2189.5631s\n",
      "\titers: 200, epoch: 12 | loss: 0.1056814\n",
      "\tspeed: 0.0599s/iter; left time: 1177.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.82s\n",
      "Steps: 223 | Train Loss: 0.1009609 Vali Loss: 0.1256741 Test Loss: 0.1363840\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1032659\n",
      "\tspeed: 0.1068s/iter; left time: 2084.4331s\n",
      "\titers: 200, epoch: 13 | loss: 0.0941548\n",
      "\tspeed: 0.0608s/iter; left time: 1180.5427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.89s\n",
      "Steps: 223 | Train Loss: 0.1002403 Vali Loss: 0.1265315 Test Loss: 0.1380129\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0971907\n",
      "\tspeed: 0.1087s/iter; left time: 2097.4841s\n",
      "\titers: 200, epoch: 14 | loss: 0.1011847\n",
      "\tspeed: 0.0616s/iter; left time: 1183.5517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.49s\n",
      "Steps: 223 | Train Loss: 0.0995397 Vali Loss: 0.1270013 Test Loss: 0.1374407\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0925344\n",
      "\tspeed: 0.1054s/iter; left time: 2011.5656s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943704\n",
      "\tspeed: 0.0618s/iter; left time: 1172.1422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.55s\n",
      "Steps: 223 | Train Loss: 0.0989645 Vali Loss: 0.1275917 Test Loss: 0.1384556\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0975892\n",
      "\tspeed: 0.1067s/iter; left time: 2011.7776s\n",
      "\titers: 200, epoch: 16 | loss: 0.0999596\n",
      "\tspeed: 0.0603s/iter; left time: 1131.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 223 | Train Loss: 0.0984323 Vali Loss: 0.1276390 Test Loss: 0.1387271\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03956723213195801, rmse:0.19891513884067535, mae:0.13470256328582764, rse:0.7045734524726868\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1586475\n",
      "\tspeed: 0.0598s/iter; left time: 1327.1177s\n",
      "\titers: 200, epoch: 1 | loss: 0.1522224\n",
      "\tspeed: 0.0582s/iter; left time: 1286.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.30s\n",
      "Steps: 223 | Train Loss: 0.1616155 Vali Loss: 0.1641567 Test Loss: 0.1773076\n",
      "Validation loss decreased (inf --> 0.164157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1187496\n",
      "\tspeed: 0.1156s/iter; left time: 2540.8450s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157281\n",
      "\tspeed: 0.0610s/iter; left time: 1334.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.63s\n",
      "Steps: 223 | Train Loss: 0.1241101 Vali Loss: 0.1277330 Test Loss: 0.1362454\n",
      "Validation loss decreased (0.164157 --> 0.127733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1088427\n",
      "\tspeed: 0.1094s/iter; left time: 2380.2644s\n",
      "\titers: 200, epoch: 3 | loss: 0.1101429\n",
      "\tspeed: 0.0588s/iter; left time: 1272.4811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 223 | Train Loss: 0.1123035 Vali Loss: 0.1245199 Test Loss: 0.1350362\n",
      "Validation loss decreased (0.127733 --> 0.124520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1039694\n",
      "\tspeed: 0.1092s/iter; left time: 2350.9355s\n",
      "\titers: 200, epoch: 4 | loss: 0.1144476\n",
      "\tspeed: 0.0593s/iter; left time: 1271.7028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.46s\n",
      "Steps: 223 | Train Loss: 0.1094969 Vali Loss: 0.1235680 Test Loss: 0.1340981\n",
      "Validation loss decreased (0.124520 --> 0.123568).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1059165\n",
      "\tspeed: 0.1106s/iter; left time: 2356.7088s\n",
      "\titers: 200, epoch: 5 | loss: 0.1059672\n",
      "\tspeed: 0.0543s/iter; left time: 1152.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 223 | Train Loss: 0.1077130 Vali Loss: 0.1228737 Test Loss: 0.1347752\n",
      "Validation loss decreased (0.123568 --> 0.122874).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1075763\n",
      "\tspeed: 0.1144s/iter; left time: 2412.3900s\n",
      "\titers: 200, epoch: 6 | loss: 0.1046234\n",
      "\tspeed: 0.0576s/iter; left time: 1208.5745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.32s\n",
      "Steps: 223 | Train Loss: 0.1062918 Vali Loss: 0.1232371 Test Loss: 0.1351631\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1086531\n",
      "\tspeed: 0.1074s/iter; left time: 2240.0109s\n",
      "\titers: 200, epoch: 7 | loss: 0.1062272\n",
      "\tspeed: 0.0579s/iter; left time: 1202.8967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.10s\n",
      "Steps: 223 | Train Loss: 0.1050808 Vali Loss: 0.1232536 Test Loss: 0.1345480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1097154\n",
      "\tspeed: 0.1151s/iter; left time: 2375.3473s\n",
      "\titers: 200, epoch: 8 | loss: 0.1039724\n",
      "\tspeed: 0.0646s/iter; left time: 1326.8510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.23s\n",
      "Steps: 223 | Train Loss: 0.1040496 Vali Loss: 0.1236265 Test Loss: 0.1358001\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1069149\n",
      "\tspeed: 0.1194s/iter; left time: 2438.3070s\n",
      "\titers: 200, epoch: 9 | loss: 0.1070597\n",
      "\tspeed: 0.0607s/iter; left time: 1232.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.50s\n",
      "Steps: 223 | Train Loss: 0.1030779 Vali Loss: 0.1237163 Test Loss: 0.1358926\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1037227\n",
      "\tspeed: 0.1069s/iter; left time: 2158.2845s\n",
      "\titers: 200, epoch: 10 | loss: 0.1070804\n",
      "\tspeed: 0.0613s/iter; left time: 1231.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.83s\n",
      "Steps: 223 | Train Loss: 0.1020539 Vali Loss: 0.1243779 Test Loss: 0.1360747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994673\n",
      "\tspeed: 0.1149s/iter; left time: 2294.1305s\n",
      "\titers: 200, epoch: 11 | loss: 0.0967816\n",
      "\tspeed: 0.0574s/iter; left time: 1141.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.58s\n",
      "Steps: 223 | Train Loss: 0.1011504 Vali Loss: 0.1246540 Test Loss: 0.1372310\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1035772\n",
      "\tspeed: 0.1098s/iter; left time: 2168.5031s\n",
      "\titers: 200, epoch: 12 | loss: 0.1003781\n",
      "\tspeed: 0.0591s/iter; left time: 1161.2851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1002424 Vali Loss: 0.1252042 Test Loss: 0.1371934\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1011443\n",
      "\tspeed: 0.1148s/iter; left time: 2241.5754s\n",
      "\titers: 200, epoch: 13 | loss: 0.0993868\n",
      "\tspeed: 0.0614s/iter; left time: 1193.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.11s\n",
      "Steps: 223 | Train Loss: 0.0994014 Vali Loss: 0.1259811 Test Loss: 0.1378808\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0967515\n",
      "\tspeed: 0.1114s/iter; left time: 2151.1808s\n",
      "\titers: 200, epoch: 14 | loss: 0.0992444\n",
      "\tspeed: 0.0624s/iter; left time: 1197.4436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.67s\n",
      "Steps: 223 | Train Loss: 0.0987232 Vali Loss: 0.1261198 Test Loss: 0.1377028\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0974795\n",
      "\tspeed: 0.1152s/iter; left time: 2197.3100s\n",
      "\titers: 200, epoch: 15 | loss: 0.0960967\n",
      "\tspeed: 0.0633s/iter; left time: 1200.4941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.78s\n",
      "Steps: 223 | Train Loss: 0.0980965 Vali Loss: 0.1264970 Test Loss: 0.1387069\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039511777460575104, rmse:0.19877569377422333, mae:0.13477523624897003, rse:0.7040795087814331\n",
      "Intermediate time for DE and pred_len 168: 00h:09m:07.79s\n",
      "Intermediate time for DE: 00h:44m:04.37s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1337681\n",
      "\tspeed: 0.0854s/iter; left time: 1905.3122s\n",
      "\titers: 200, epoch: 1 | loss: 0.1301103\n",
      "\tspeed: 0.0555s/iter; left time: 1232.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.48s\n",
      "Steps: 224 | Train Loss: 0.1369913 Vali Loss: 0.1359314 Test Loss: 0.1558871\n",
      "Validation loss decreased (inf --> 0.135931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0913649\n",
      "\tspeed: 0.1102s/iter; left time: 2433.9808s\n",
      "\titers: 200, epoch: 2 | loss: 0.0844155\n",
      "\tspeed: 0.0572s/iter; left time: 1256.8576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.34s\n",
      "Steps: 224 | Train Loss: 0.0923259 Vali Loss: 0.0929204 Test Loss: 0.1050857\n",
      "Validation loss decreased (0.135931 --> 0.092920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0808693\n",
      "\tspeed: 0.1076s/iter; left time: 2352.1250s\n",
      "\titers: 200, epoch: 3 | loss: 0.0861732\n",
      "\tspeed: 0.0626s/iter; left time: 1362.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.76s\n",
      "Steps: 224 | Train Loss: 0.0791791 Vali Loss: 0.0913382 Test Loss: 0.1042468\n",
      "Validation loss decreased (0.092920 --> 0.091338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733298\n",
      "\tspeed: 0.1147s/iter; left time: 2480.0764s\n",
      "\titers: 200, epoch: 4 | loss: 0.0772558\n",
      "\tspeed: 0.0555s/iter; left time: 1193.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 224 | Train Loss: 0.0773386 Vali Loss: 0.0909781 Test Loss: 0.1037574\n",
      "Validation loss decreased (0.091338 --> 0.090978).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0725079\n",
      "\tspeed: 0.1073s/iter; left time: 2295.9793s\n",
      "\titers: 200, epoch: 5 | loss: 0.0707540\n",
      "\tspeed: 0.0614s/iter; left time: 1308.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:13.64s\n",
      "Steps: 224 | Train Loss: 0.0761784 Vali Loss: 0.0895637 Test Loss: 0.1028150\n",
      "Validation loss decreased (0.090978 --> 0.089564).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770092\n",
      "\tspeed: 0.1150s/iter; left time: 2435.2931s\n",
      "\titers: 200, epoch: 6 | loss: 0.0714131\n",
      "\tspeed: 0.0573s/iter; left time: 1207.6351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.39s\n",
      "Steps: 224 | Train Loss: 0.0753703 Vali Loss: 0.0893661 Test Loss: 0.1025691\n",
      "Validation loss decreased (0.089564 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0798632\n",
      "\tspeed: 0.1027s/iter; left time: 2151.3732s\n",
      "\titers: 200, epoch: 7 | loss: 0.0708998\n",
      "\tspeed: 0.0566s/iter; left time: 1181.0620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.14s\n",
      "Steps: 224 | Train Loss: 0.0748158 Vali Loss: 0.0894289 Test Loss: 0.1025083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749726\n",
      "\tspeed: 0.1126s/iter; left time: 2334.4300s\n",
      "\titers: 200, epoch: 8 | loss: 0.0733200\n",
      "\tspeed: 0.0557s/iter; left time: 1149.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.18s\n",
      "Steps: 224 | Train Loss: 0.0743430 Vali Loss: 0.0890287 Test Loss: 0.1023971\n",
      "Validation loss decreased (0.089366 --> 0.089029).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0791299\n",
      "\tspeed: 0.1007s/iter; left time: 2064.4053s\n",
      "\titers: 200, epoch: 9 | loss: 0.0748995\n",
      "\tspeed: 0.0550s/iter; left time: 1122.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.50s\n",
      "Steps: 224 | Train Loss: 0.0738968 Vali Loss: 0.0888048 Test Loss: 0.1026755\n",
      "Validation loss decreased (0.089029 --> 0.088805).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0725861\n",
      "\tspeed: 0.1109s/iter; left time: 2249.2693s\n",
      "\titers: 200, epoch: 10 | loss: 0.0756589\n",
      "\tspeed: 0.0610s/iter; left time: 1230.7109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.03s\n",
      "Steps: 224 | Train Loss: 0.0735116 Vali Loss: 0.0885439 Test Loss: 0.1022316\n",
      "Validation loss decreased (0.088805 --> 0.088544).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702687\n",
      "\tspeed: 0.1063s/iter; left time: 2133.4166s\n",
      "\titers: 200, epoch: 11 | loss: 0.0753673\n",
      "\tspeed: 0.0585s/iter; left time: 1166.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.14s\n",
      "Steps: 224 | Train Loss: 0.0731713 Vali Loss: 0.0884424 Test Loss: 0.1024115\n",
      "Validation loss decreased (0.088544 --> 0.088442).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0696664\n",
      "\tspeed: 0.1069s/iter; left time: 2121.0731s\n",
      "\titers: 200, epoch: 12 | loss: 0.0712836\n",
      "\tspeed: 0.0558s/iter; left time: 1101.6775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.14s\n",
      "Steps: 224 | Train Loss: 0.0729458 Vali Loss: 0.0885137 Test Loss: 0.1023535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0772517\n",
      "\tspeed: 0.1119s/iter; left time: 2193.9264s\n",
      "\titers: 200, epoch: 13 | loss: 0.0727321\n",
      "\tspeed: 0.0570s/iter; left time: 1112.6634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.19s\n",
      "Steps: 224 | Train Loss: 0.0727253 Vali Loss: 0.0882543 Test Loss: 0.1018357\n",
      "Validation loss decreased (0.088442 --> 0.088254).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0730511\n",
      "\tspeed: 0.1041s/iter; left time: 2018.9151s\n",
      "\titers: 200, epoch: 14 | loss: 0.0743207\n",
      "\tspeed: 0.0604s/iter; left time: 1164.4208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.14s\n",
      "Steps: 224 | Train Loss: 0.0724939 Vali Loss: 0.0883527 Test Loss: 0.1019900\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0745256\n",
      "\tspeed: 0.1156s/iter; left time: 2215.4567s\n",
      "\titers: 200, epoch: 15 | loss: 0.0704399\n",
      "\tspeed: 0.0566s/iter; left time: 1078.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.28s\n",
      "Steps: 224 | Train Loss: 0.0722996 Vali Loss: 0.0880289 Test Loss: 0.1020303\n",
      "Validation loss decreased (0.088254 --> 0.088029).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0770125\n",
      "\tspeed: 0.1114s/iter; left time: 2109.8620s\n",
      "\titers: 200, epoch: 16 | loss: 0.0694815\n",
      "\tspeed: 0.0546s/iter; left time: 1028.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 224 | Train Loss: 0.0721522 Vali Loss: 0.0880209 Test Loss: 0.1023730\n",
      "Validation loss decreased (0.088029 --> 0.088021).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0658797\n",
      "\tspeed: 0.1087s/iter; left time: 2034.2315s\n",
      "\titers: 200, epoch: 17 | loss: 0.0695038\n",
      "\tspeed: 0.0580s/iter; left time: 1079.5765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:13.41s\n",
      "Steps: 224 | Train Loss: 0.0719564 Vali Loss: 0.0880820 Test Loss: 0.1024347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0731994\n",
      "\tspeed: 0.1030s/iter; left time: 1904.4652s\n",
      "\titers: 200, epoch: 18 | loss: 0.0695477\n",
      "\tspeed: 0.0544s/iter; left time: 1000.5036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 224 | Train Loss: 0.0718094 Vali Loss: 0.0881291 Test Loss: 0.1022878\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0677946\n",
      "\tspeed: 0.1061s/iter; left time: 1937.5829s\n",
      "\titers: 200, epoch: 19 | loss: 0.0691350\n",
      "\tspeed: 0.0639s/iter; left time: 1161.3835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:13.97s\n",
      "Steps: 224 | Train Loss: 0.0717229 Vali Loss: 0.0878378 Test Loss: 0.1025048\n",
      "Validation loss decreased (0.088021 --> 0.087838).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0751754\n",
      "\tspeed: 0.1053s/iter; left time: 1899.6490s\n",
      "\titers: 200, epoch: 20 | loss: 0.0717342\n",
      "\tspeed: 0.0550s/iter; left time: 987.7469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.83s\n",
      "Steps: 224 | Train Loss: 0.0715432 Vali Loss: 0.0879541 Test Loss: 0.1023896\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683073\n",
      "\tspeed: 0.1036s/iter; left time: 1846.2816s\n",
      "\titers: 200, epoch: 21 | loss: 0.0753092\n",
      "\tspeed: 0.0574s/iter; left time: 1016.5865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 224 | Train Loss: 0.0714210 Vali Loss: 0.0878884 Test Loss: 0.1025704\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0739669\n",
      "\tspeed: 0.1142s/iter; left time: 2009.2080s\n",
      "\titers: 200, epoch: 22 | loss: 0.0735120\n",
      "\tspeed: 0.0573s/iter; left time: 1002.8254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:13.25s\n",
      "Steps: 224 | Train Loss: 0.0713990 Vali Loss: 0.0879366 Test Loss: 0.1023931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0725404\n",
      "\tspeed: 0.1036s/iter; left time: 1799.6665s\n",
      "\titers: 200, epoch: 23 | loss: 0.0742865\n",
      "\tspeed: 0.0583s/iter; left time: 1006.5757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:13.08s\n",
      "Steps: 224 | Train Loss: 0.0712040 Vali Loss: 0.0877694 Test Loss: 0.1021546\n",
      "Validation loss decreased (0.087838 --> 0.087769).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0733356\n",
      "\tspeed: 0.1134s/iter; left time: 1944.2360s\n",
      "\titers: 200, epoch: 24 | loss: 0.0658376\n",
      "\tspeed: 0.0574s/iter; left time: 977.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:13.23s\n",
      "Steps: 224 | Train Loss: 0.0712310 Vali Loss: 0.0878737 Test Loss: 0.1022747\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0756377\n",
      "\tspeed: 0.1052s/iter; left time: 1780.0728s\n",
      "\titers: 200, epoch: 25 | loss: 0.0714636\n",
      "\tspeed: 0.0586s/iter; left time: 986.5720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:13.21s\n",
      "Steps: 224 | Train Loss: 0.0711283 Vali Loss: 0.0876985 Test Loss: 0.1023861\n",
      "Validation loss decreased (0.087769 --> 0.087698).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0730481\n",
      "\tspeed: 0.1082s/iter; left time: 1806.6157s\n",
      "\titers: 200, epoch: 26 | loss: 0.0673774\n",
      "\tspeed: 0.0577s/iter; left time: 958.4876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:13.60s\n",
      "Steps: 224 | Train Loss: 0.0710204 Vali Loss: 0.0878645 Test Loss: 0.1025371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0692971\n",
      "\tspeed: 0.1038s/iter; left time: 1710.1172s\n",
      "\titers: 200, epoch: 27 | loss: 0.0748941\n",
      "\tspeed: 0.0589s/iter; left time: 965.3010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 224 | Train Loss: 0.0709922 Vali Loss: 0.0878092 Test Loss: 0.1024434\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0731720\n",
      "\tspeed: 0.1071s/iter; left time: 1740.6497s\n",
      "\titers: 200, epoch: 28 | loss: 0.0709607\n",
      "\tspeed: 0.0593s/iter; left time: 957.5803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:13.64s\n",
      "Steps: 224 | Train Loss: 0.0709522 Vali Loss: 0.0876303 Test Loss: 0.1024348\n",
      "Validation loss decreased (0.087698 --> 0.087630).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0729126\n",
      "\tspeed: 0.1125s/iter; left time: 1803.1640s\n",
      "\titers: 200, epoch: 29 | loss: 0.0757939\n",
      "\tspeed: 0.0632s/iter; left time: 1006.9332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:13.93s\n",
      "Steps: 224 | Train Loss: 0.0709114 Vali Loss: 0.0877213 Test Loss: 0.1024486\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0686514\n",
      "\tspeed: 0.1134s/iter; left time: 1792.4079s\n",
      "\titers: 200, epoch: 30 | loss: 0.0682729\n",
      "\tspeed: 0.0626s/iter; left time: 982.9538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:14.05s\n",
      "Steps: 224 | Train Loss: 0.0708208 Vali Loss: 0.0877651 Test Loss: 0.1023511\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0680746\n",
      "\tspeed: 0.1109s/iter; left time: 1727.4195s\n",
      "\titers: 200, epoch: 31 | loss: 0.0703695\n",
      "\tspeed: 0.0627s/iter; left time: 970.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:13.72s\n",
      "Steps: 224 | Train Loss: 0.0707644 Vali Loss: 0.0875608 Test Loss: 0.1024484\n",
      "Validation loss decreased (0.087630 --> 0.087561).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0712823\n",
      "\tspeed: 0.1117s/iter; left time: 1715.2678s\n",
      "\titers: 200, epoch: 32 | loss: 0.0645696\n",
      "\tspeed: 0.0604s/iter; left time: 921.8483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:13.66s\n",
      "Steps: 224 | Train Loss: 0.0707321 Vali Loss: 0.0877208 Test Loss: 0.1026194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0686052\n",
      "\tspeed: 0.1140s/iter; left time: 1725.1426s\n",
      "\titers: 200, epoch: 33 | loss: 0.0751981\n",
      "\tspeed: 0.0590s/iter; left time: 887.6427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:13.61s\n",
      "Steps: 224 | Train Loss: 0.0707160 Vali Loss: 0.0876859 Test Loss: 0.1025198\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0700265\n",
      "\tspeed: 0.1109s/iter; left time: 1653.7540s\n",
      "\titers: 200, epoch: 34 | loss: 0.0709091\n",
      "\tspeed: 0.0545s/iter; left time: 806.5487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 224 | Train Loss: 0.0706691 Vali Loss: 0.0876336 Test Loss: 0.1025292\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0714695\n",
      "\tspeed: 0.0942s/iter; left time: 1383.3705s\n",
      "\titers: 200, epoch: 35 | loss: 0.0675804\n",
      "\tspeed: 0.0523s/iter; left time: 763.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0706608 Vali Loss: 0.0876634 Test Loss: 0.1025143\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0716697\n",
      "\tspeed: 0.1165s/iter; left time: 1684.4521s\n",
      "\titers: 200, epoch: 36 | loss: 0.0745230\n",
      "\tspeed: 0.0590s/iter; left time: 847.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:13.55s\n",
      "Steps: 224 | Train Loss: 0.0706338 Vali Loss: 0.0876844 Test Loss: 0.1025104\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0692014\n",
      "\tspeed: 0.1064s/iter; left time: 1514.2644s\n",
      "\titers: 200, epoch: 37 | loss: 0.0667195\n",
      "\tspeed: 0.0634s/iter; left time: 896.2345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:13.66s\n",
      "Steps: 224 | Train Loss: 0.0706335 Vali Loss: 0.0875388 Test Loss: 0.1025336\n",
      "Validation loss decreased (0.087561 --> 0.087539).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0696882\n",
      "\tspeed: 0.1200s/iter; left time: 1681.5818s\n",
      "\titers: 200, epoch: 38 | loss: 0.0767173\n",
      "\tspeed: 0.0596s/iter; left time: 828.7526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0705597 Vali Loss: 0.0876549 Test Loss: 0.1025695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0688473\n",
      "\tspeed: 0.1116s/iter; left time: 1539.5206s\n",
      "\titers: 200, epoch: 39 | loss: 0.0736877\n",
      "\tspeed: 0.0593s/iter; left time: 812.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:13.73s\n",
      "Steps: 224 | Train Loss: 0.0705348 Vali Loss: 0.0877679 Test Loss: 0.1025379\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0706787\n",
      "\tspeed: 0.1069s/iter; left time: 1450.5590s\n",
      "\titers: 200, epoch: 40 | loss: 0.0669279\n",
      "\tspeed: 0.0586s/iter; left time: 788.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:13.49s\n",
      "Steps: 224 | Train Loss: 0.0705901 Vali Loss: 0.0876181 Test Loss: 0.1025662\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0689001\n",
      "\tspeed: 0.1101s/iter; left time: 1469.3997s\n",
      "\titers: 200, epoch: 41 | loss: 0.0677012\n",
      "\tspeed: 0.0609s/iter; left time: 806.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:13.79s\n",
      "Steps: 224 | Train Loss: 0.0705525 Vali Loss: 0.0876695 Test Loss: 0.1025416\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0700784\n",
      "\tspeed: 0.1161s/iter; left time: 1522.4237s\n",
      "\titers: 200, epoch: 42 | loss: 0.0700355\n",
      "\tspeed: 0.0596s/iter; left time: 775.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:14.05s\n",
      "Steps: 224 | Train Loss: 0.0705240 Vali Loss: 0.0876143 Test Loss: 0.1026173\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0726577\n",
      "\tspeed: 0.1055s/iter; left time: 1360.2418s\n",
      "\titers: 200, epoch: 43 | loss: 0.0706721\n",
      "\tspeed: 0.0578s/iter; left time: 739.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:13.00s\n",
      "Steps: 224 | Train Loss: 0.0705564 Vali Loss: 0.0876295 Test Loss: 0.1025662\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0696796\n",
      "\tspeed: 0.0967s/iter; left time: 1225.0796s\n",
      "\titers: 200, epoch: 44 | loss: 0.0707281\n",
      "\tspeed: 0.0538s/iter; left time: 676.4829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:12.26s\n",
      "Steps: 224 | Train Loss: 0.0704933 Vali Loss: 0.0876881 Test Loss: 0.1025814\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0757044\n",
      "\tspeed: 0.1119s/iter; left time: 1392.9842s\n",
      "\titers: 200, epoch: 45 | loss: 0.0726157\n",
      "\tspeed: 0.0604s/iter; left time: 745.2113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:13.92s\n",
      "Steps: 224 | Train Loss: 0.0705575 Vali Loss: 0.0874810 Test Loss: 0.1025429\n",
      "Validation loss decreased (0.087539 --> 0.087481).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0742189\n",
      "\tspeed: 0.1120s/iter; left time: 1369.1068s\n",
      "\titers: 200, epoch: 46 | loss: 0.0736142\n",
      "\tspeed: 0.0615s/iter; left time: 745.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:14.02s\n",
      "Steps: 224 | Train Loss: 0.0705232 Vali Loss: 0.0875848 Test Loss: 0.1025821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0672498\n",
      "\tspeed: 0.1181s/iter; left time: 1416.8976s\n",
      "\titers: 200, epoch: 47 | loss: 0.0682913\n",
      "\tspeed: 0.0626s/iter; left time: 744.8943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:14.39s\n",
      "Steps: 224 | Train Loss: 0.0704723 Vali Loss: 0.0876123 Test Loss: 0.1025846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0696902\n",
      "\tspeed: 0.1104s/iter; left time: 1299.7708s\n",
      "\titers: 200, epoch: 48 | loss: 0.0676515\n",
      "\tspeed: 0.0573s/iter; left time: 668.7522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:13.19s\n",
      "Steps: 224 | Train Loss: 0.0705277 Vali Loss: 0.0876810 Test Loss: 0.1025829\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0700386\n",
      "\tspeed: 0.1137s/iter; left time: 1313.5879s\n",
      "\titers: 200, epoch: 49 | loss: 0.0666300\n",
      "\tspeed: 0.0651s/iter; left time: 745.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0704845 Vali Loss: 0.0876203 Test Loss: 0.1025853\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0734844\n",
      "\tspeed: 0.1149s/iter; left time: 1301.2348s\n",
      "\titers: 200, epoch: 50 | loss: 0.0679541\n",
      "\tspeed: 0.0622s/iter; left time: 698.6113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:14.05s\n",
      "Steps: 224 | Train Loss: 0.0704916 Vali Loss: 0.0877179 Test Loss: 0.1025884\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0736447\n",
      "\tspeed: 0.1163s/iter; left time: 1291.3338s\n",
      "\titers: 200, epoch: 51 | loss: 0.0654428\n",
      "\tspeed: 0.0591s/iter; left time: 650.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:13.99s\n",
      "Steps: 224 | Train Loss: 0.0705029 Vali Loss: 0.0875974 Test Loss: 0.1025916\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0700766\n",
      "\tspeed: 0.1224s/iter; left time: 1330.8904s\n",
      "\titers: 200, epoch: 52 | loss: 0.0760974\n",
      "\tspeed: 0.0641s/iter; left time: 690.4694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:14.84s\n",
      "Steps: 224 | Train Loss: 0.0704561 Vali Loss: 0.0875556 Test Loss: 0.1025784\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0712552\n",
      "\tspeed: 0.1171s/iter; left time: 1247.8245s\n",
      "\titers: 200, epoch: 53 | loss: 0.0681484\n",
      "\tspeed: 0.0565s/iter; left time: 596.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:13.59s\n",
      "Steps: 224 | Train Loss: 0.0704864 Vali Loss: 0.0875903 Test Loss: 0.1026226\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0698976\n",
      "\tspeed: 0.1215s/iter; left time: 1267.2061s\n",
      "\titers: 200, epoch: 54 | loss: 0.0694280\n",
      "\tspeed: 0.0601s/iter; left time: 620.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:14.65s\n",
      "Steps: 224 | Train Loss: 0.0705067 Vali Loss: 0.0876638 Test Loss: 0.1025732\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0714906\n",
      "\tspeed: 0.1269s/iter; left time: 1295.1419s\n",
      "\titers: 200, epoch: 55 | loss: 0.0664937\n",
      "\tspeed: 0.0601s/iter; left time: 606.9585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:14.18s\n",
      "Steps: 224 | Train Loss: 0.0704601 Vali Loss: 0.0876570 Test Loss: 0.1026139\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026038529351353645, rmse:0.1613645851612091, mae:0.10254285484552383, rse:0.5566620826721191\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1340888\n",
      "\tspeed: 0.0612s/iter; left time: 1365.2559s\n",
      "\titers: 200, epoch: 1 | loss: 0.1284338\n",
      "\tspeed: 0.0605s/iter; left time: 1343.7015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.69s\n",
      "Steps: 224 | Train Loss: 0.1371192 Vali Loss: 0.1359184 Test Loss: 0.1564447\n",
      "Validation loss decreased (inf --> 0.135918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986784\n",
      "\tspeed: 0.1200s/iter; left time: 2648.4066s\n",
      "\titers: 200, epoch: 2 | loss: 0.0827210\n",
      "\tspeed: 0.0634s/iter; left time: 1392.3207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.14s\n",
      "Steps: 224 | Train Loss: 0.0929912 Vali Loss: 0.0933088 Test Loss: 0.1047612\n",
      "Validation loss decreased (0.135918 --> 0.093309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803287\n",
      "\tspeed: 0.1190s/iter; left time: 2600.4959s\n",
      "\titers: 200, epoch: 3 | loss: 0.0777847\n",
      "\tspeed: 0.0671s/iter; left time: 1458.9663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0793267 Vali Loss: 0.0914609 Test Loss: 0.1030556\n",
      "Validation loss decreased (0.093309 --> 0.091461).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0806357\n",
      "\tspeed: 0.1241s/iter; left time: 2683.4467s\n",
      "\titers: 200, epoch: 4 | loss: 0.0757164\n",
      "\tspeed: 0.0595s/iter; left time: 1281.9616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.95s\n",
      "Steps: 224 | Train Loss: 0.0774351 Vali Loss: 0.0906578 Test Loss: 0.1030808\n",
      "Validation loss decreased (0.091461 --> 0.090658).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0742374\n",
      "\tspeed: 0.1249s/iter; left time: 2674.0526s\n",
      "\titers: 200, epoch: 5 | loss: 0.0708531\n",
      "\tspeed: 0.0620s/iter; left time: 1321.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:14.73s\n",
      "Steps: 224 | Train Loss: 0.0764426 Vali Loss: 0.0899601 Test Loss: 0.1026692\n",
      "Validation loss decreased (0.090658 --> 0.089960).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0776469\n",
      "\tspeed: 0.1325s/iter; left time: 2806.3584s\n",
      "\titers: 200, epoch: 6 | loss: 0.0802776\n",
      "\tspeed: 0.0644s/iter; left time: 1357.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.97s\n",
      "Steps: 224 | Train Loss: 0.0755150 Vali Loss: 0.0892671 Test Loss: 0.1024971\n",
      "Validation loss decreased (0.089960 --> 0.089267).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0744159\n",
      "\tspeed: 0.1214s/iter; left time: 2543.6762s\n",
      "\titers: 200, epoch: 7 | loss: 0.0703802\n",
      "\tspeed: 0.0640s/iter; left time: 1334.3602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.71s\n",
      "Steps: 224 | Train Loss: 0.0749787 Vali Loss: 0.0892036 Test Loss: 0.1022584\n",
      "Validation loss decreased (0.089267 --> 0.089204).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0728884\n",
      "\tspeed: 0.1175s/iter; left time: 2436.5760s\n",
      "\titers: 200, epoch: 8 | loss: 0.0763242\n",
      "\tspeed: 0.0686s/iter; left time: 1414.7120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.58s\n",
      "Steps: 224 | Train Loss: 0.0744411 Vali Loss: 0.0888207 Test Loss: 0.1025281\n",
      "Validation loss decreased (0.089204 --> 0.088821).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749100\n",
      "\tspeed: 0.1238s/iter; left time: 2539.4949s\n",
      "\titers: 200, epoch: 9 | loss: 0.0729593\n",
      "\tspeed: 0.0648s/iter; left time: 1322.7087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:14.95s\n",
      "Steps: 224 | Train Loss: 0.0740723 Vali Loss: 0.0889069 Test Loss: 0.1022433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0736462\n",
      "\tspeed: 0.1164s/iter; left time: 2360.1877s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683928\n",
      "\tspeed: 0.0620s/iter; left time: 1250.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.48s\n",
      "Steps: 224 | Train Loss: 0.0736698 Vali Loss: 0.0882708 Test Loss: 0.1022037\n",
      "Validation loss decreased (0.088821 --> 0.088271).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685093\n",
      "\tspeed: 0.1231s/iter; left time: 2470.4764s\n",
      "\titers: 200, epoch: 11 | loss: 0.0748501\n",
      "\tspeed: 0.0624s/iter; left time: 1246.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.06s\n",
      "Steps: 224 | Train Loss: 0.0733367 Vali Loss: 0.0885927 Test Loss: 0.1025729\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0694412\n",
      "\tspeed: 0.1133s/iter; left time: 2247.7628s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729200\n",
      "\tspeed: 0.0596s/iter; left time: 1176.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0730160 Vali Loss: 0.0883027 Test Loss: 0.1023279\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722981\n",
      "\tspeed: 0.1213s/iter; left time: 2379.6536s\n",
      "\titers: 200, epoch: 13 | loss: 0.0708375\n",
      "\tspeed: 0.0608s/iter; left time: 1185.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.69s\n",
      "Steps: 224 | Train Loss: 0.0727724 Vali Loss: 0.0881370 Test Loss: 0.1023577\n",
      "Validation loss decreased (0.088271 --> 0.088137).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0679360\n",
      "\tspeed: 0.1183s/iter; left time: 2292.8159s\n",
      "\titers: 200, epoch: 14 | loss: 0.0720937\n",
      "\tspeed: 0.0635s/iter; left time: 1224.1228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0726295 Vali Loss: 0.0878316 Test Loss: 0.1023786\n",
      "Validation loss decreased (0.088137 --> 0.087832).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0757486\n",
      "\tspeed: 0.1130s/iter; left time: 2165.8483s\n",
      "\titers: 200, epoch: 15 | loss: 0.0714281\n",
      "\tspeed: 0.0619s/iter; left time: 1179.9262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.11s\n",
      "Steps: 224 | Train Loss: 0.0723702 Vali Loss: 0.0882032 Test Loss: 0.1025239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0744029\n",
      "\tspeed: 0.1128s/iter; left time: 2137.2816s\n",
      "\titers: 200, epoch: 16 | loss: 0.0732896\n",
      "\tspeed: 0.0619s/iter; left time: 1166.8103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.78s\n",
      "Steps: 224 | Train Loss: 0.0722303 Vali Loss: 0.0879967 Test Loss: 0.1022053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0708814\n",
      "\tspeed: 0.1323s/iter; left time: 2476.2811s\n",
      "\titers: 200, epoch: 17 | loss: 0.0643175\n",
      "\tspeed: 0.0633s/iter; left time: 1178.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.75s\n",
      "Steps: 224 | Train Loss: 0.0720519 Vali Loss: 0.0878360 Test Loss: 0.1024031\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0691474\n",
      "\tspeed: 0.1143s/iter; left time: 2113.5666s\n",
      "\titers: 200, epoch: 18 | loss: 0.0731347\n",
      "\tspeed: 0.0657s/iter; left time: 1207.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0717889 Vali Loss: 0.0880502 Test Loss: 0.1021411\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0713383\n",
      "\tspeed: 0.1887s/iter; left time: 3447.9243s\n",
      "\titers: 200, epoch: 19 | loss: 0.0802521\n",
      "\tspeed: 0.1288s/iter; left time: 2340.4147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.86s\n",
      "Steps: 224 | Train Loss: 0.0717140 Vali Loss: 0.0880324 Test Loss: 0.1025808\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0718002\n",
      "\tspeed: 0.2204s/iter; left time: 3977.0530s\n",
      "\titers: 200, epoch: 20 | loss: 0.0694699\n",
      "\tspeed: 0.1292s/iter; left time: 2318.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.92s\n",
      "Steps: 224 | Train Loss: 0.0716252 Vali Loss: 0.0878140 Test Loss: 0.1023368\n",
      "Validation loss decreased (0.087832 --> 0.087814).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0732282\n",
      "\tspeed: 0.2167s/iter; left time: 3861.0093s\n",
      "\titers: 200, epoch: 21 | loss: 0.0687660\n",
      "\tspeed: 0.1318s/iter; left time: 2335.8306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:29.03s\n",
      "Steps: 224 | Train Loss: 0.0715591 Vali Loss: 0.0878166 Test Loss: 0.1024134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0704203\n",
      "\tspeed: 0.2249s/iter; left time: 3957.7484s\n",
      "\titers: 200, epoch: 22 | loss: 0.0698574\n",
      "\tspeed: 0.1303s/iter; left time: 2280.2202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:29.25s\n",
      "Steps: 224 | Train Loss: 0.0714010 Vali Loss: 0.0878006 Test Loss: 0.1022703\n",
      "Validation loss decreased (0.087814 --> 0.087801).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0693955\n",
      "\tspeed: 0.2330s/iter; left time: 4047.5268s\n",
      "\titers: 200, epoch: 23 | loss: 0.0668513\n",
      "\tspeed: 0.1283s/iter; left time: 2216.4038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:29.23s\n",
      "Steps: 224 | Train Loss: 0.0713579 Vali Loss: 0.0878292 Test Loss: 0.1025530\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0714743\n",
      "\tspeed: 0.2243s/iter; left time: 3846.3294s\n",
      "\titers: 200, epoch: 24 | loss: 0.0696637\n",
      "\tspeed: 0.1295s/iter; left time: 2207.9629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:30.07s\n",
      "Steps: 224 | Train Loss: 0.0712420 Vali Loss: 0.0878795 Test Loss: 0.1024655\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0674481\n",
      "\tspeed: 0.2380s/iter; left time: 4027.8251s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701551\n",
      "\tspeed: 0.1608s/iter; left time: 2705.7032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:34.00s\n",
      "Steps: 224 | Train Loss: 0.0711827 Vali Loss: 0.0878567 Test Loss: 0.1025342\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0699493\n",
      "\tspeed: 0.3211s/iter; left time: 5363.4917s\n",
      "\titers: 200, epoch: 26 | loss: 0.0704517\n",
      "\tspeed: 0.1922s/iter; left time: 3190.9436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:42.73s\n",
      "Steps: 224 | Train Loss: 0.0711286 Vali Loss: 0.0878145 Test Loss: 0.1025468\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0690658\n",
      "\tspeed: 0.2999s/iter; left time: 4941.1748s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724766\n",
      "\tspeed: 0.1891s/iter; left time: 3096.3989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:40.11s\n",
      "Steps: 224 | Train Loss: 0.0710852 Vali Loss: 0.0877976 Test Loss: 0.1023908\n",
      "Validation loss decreased (0.087801 --> 0.087798).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0726968\n",
      "\tspeed: 0.3127s/iter; left time: 5081.9032s\n",
      "\titers: 200, epoch: 28 | loss: 0.0673573\n",
      "\tspeed: 0.1760s/iter; left time: 2842.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:40.54s\n",
      "Steps: 224 | Train Loss: 0.0710127 Vali Loss: 0.0877014 Test Loss: 0.1025226\n",
      "Validation loss decreased (0.087798 --> 0.087701).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0690880\n",
      "\tspeed: 0.2871s/iter; left time: 4601.4088s\n",
      "\titers: 200, epoch: 29 | loss: 0.0689618\n",
      "\tspeed: 0.1891s/iter; left time: 3012.0546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:39.76s\n",
      "Steps: 224 | Train Loss: 0.0709411 Vali Loss: 0.0878401 Test Loss: 0.1026098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0678539\n",
      "\tspeed: 0.3169s/iter; left time: 5007.9808s\n",
      "\titers: 200, epoch: 30 | loss: 0.0694931\n",
      "\tspeed: 0.1858s/iter; left time: 2917.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:42.08s\n",
      "Steps: 224 | Train Loss: 0.0709095 Vali Loss: 0.0877920 Test Loss: 0.1025607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0682457\n",
      "\tspeed: 0.2901s/iter; left time: 4519.6958s\n",
      "\titers: 200, epoch: 31 | loss: 0.0681491\n",
      "\tspeed: 0.1929s/iter; left time: 2986.9586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:41.90s\n",
      "Steps: 224 | Train Loss: 0.0708165 Vali Loss: 0.0876857 Test Loss: 0.1025284\n",
      "Validation loss decreased (0.087701 --> 0.087686).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0699011\n",
      "\tspeed: 0.3187s/iter; left time: 4894.5480s\n",
      "\titers: 200, epoch: 32 | loss: 0.0707282\n",
      "\tspeed: 0.1808s/iter; left time: 2758.1361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:40.92s\n",
      "Steps: 224 | Train Loss: 0.0708926 Vali Loss: 0.0877611 Test Loss: 0.1025761\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0750260\n",
      "\tspeed: 0.3012s/iter; left time: 4557.9328s\n",
      "\titers: 200, epoch: 33 | loss: 0.0712225\n",
      "\tspeed: 0.1854s/iter; left time: 2787.0886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:42.34s\n",
      "Steps: 224 | Train Loss: 0.0708430 Vali Loss: 0.0878547 Test Loss: 0.1025163\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0709231\n",
      "\tspeed: 0.3205s/iter; left time: 4778.7270s\n",
      "\titers: 200, epoch: 34 | loss: 0.0734632\n",
      "\tspeed: 0.1671s/iter; left time: 2474.8121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:39.44s\n",
      "Steps: 224 | Train Loss: 0.0707557 Vali Loss: 0.0878187 Test Loss: 0.1025741\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0741756\n",
      "\tspeed: 0.2844s/iter; left time: 4176.0166s\n",
      "\titers: 200, epoch: 35 | loss: 0.0756165\n",
      "\tspeed: 0.1499s/iter; left time: 2186.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:36.23s\n",
      "Steps: 224 | Train Loss: 0.0707925 Vali Loss: 0.0877389 Test Loss: 0.1025545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0762861\n",
      "\tspeed: 0.2345s/iter; left time: 3391.0716s\n",
      "\titers: 200, epoch: 36 | loss: 0.0745686\n",
      "\tspeed: 0.1573s/iter; left time: 2258.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:33.85s\n",
      "Steps: 224 | Train Loss: 0.0706969 Vali Loss: 0.0878429 Test Loss: 0.1024922\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752780\n",
      "\tspeed: 0.3182s/iter; left time: 4530.3374s\n",
      "\titers: 200, epoch: 37 | loss: 0.0681149\n",
      "\tspeed: 0.1888s/iter; left time: 2669.2181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:42.33s\n",
      "Steps: 224 | Train Loss: 0.0706726 Vali Loss: 0.0878174 Test Loss: 0.1026253\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0696197\n",
      "\tspeed: 0.2970s/iter; left time: 4161.2129s\n",
      "\titers: 200, epoch: 38 | loss: 0.0708822\n",
      "\tspeed: 0.1769s/iter; left time: 2460.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:39.20s\n",
      "Steps: 224 | Train Loss: 0.0706715 Vali Loss: 0.0877813 Test Loss: 0.1026189\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0691303\n",
      "\tspeed: 0.3025s/iter; left time: 4170.9151s\n",
      "\titers: 200, epoch: 39 | loss: 0.0709607\n",
      "\tspeed: 0.1884s/iter; left time: 2578.8933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:41.47s\n",
      "Steps: 224 | Train Loss: 0.0706529 Vali Loss: 0.0878448 Test Loss: 0.1025701\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0710506\n",
      "\tspeed: 0.3059s/iter; left time: 4150.1244s\n",
      "\titers: 200, epoch: 40 | loss: 0.0685172\n",
      "\tspeed: 0.1925s/iter; left time: 2592.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:40.84s\n",
      "Steps: 224 | Train Loss: 0.0706797 Vali Loss: 0.0877237 Test Loss: 0.1025156\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0680695\n",
      "\tspeed: 0.3347s/iter; left time: 4465.5871s\n",
      "\titers: 200, epoch: 41 | loss: 0.0707226\n",
      "\tspeed: 0.1900s/iter; left time: 2516.0303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 224 | Train Loss: 0.0706761 Vali Loss: 0.0877903 Test Loss: 0.1025302\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02596805803477764, rmse:0.16114607453346252, mae:0.1025284007191658, rse:0.5559083223342896\n",
      "Intermediate time for GB and pred_len 24: 00h:38m:27.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1406689\n",
      "\tspeed: 0.2193s/iter; left time: 4890.2437s\n",
      "\titers: 200, epoch: 1 | loss: 0.1337222\n",
      "\tspeed: 0.1928s/iter; left time: 4280.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.74s\n",
      "Steps: 224 | Train Loss: 0.1448316 Vali Loss: 0.1478217 Test Loss: 0.1731035\n",
      "Validation loss decreased (inf --> 0.147822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138583\n",
      "\tspeed: 0.3205s/iter; left time: 7076.4687s\n",
      "\titers: 200, epoch: 2 | loss: 0.1043878\n",
      "\tspeed: 0.1919s/iter; left time: 4217.2627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.46s\n",
      "Steps: 224 | Train Loss: 0.1130484 Vali Loss: 0.1190484 Test Loss: 0.1404722\n",
      "Validation loss decreased (0.147822 --> 0.119048).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1049010\n",
      "\tspeed: 0.3475s/iter; left time: 7593.9053s\n",
      "\titers: 200, epoch: 3 | loss: 0.0996536\n",
      "\tspeed: 0.1913s/iter; left time: 4162.1801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.66s\n",
      "Steps: 224 | Train Loss: 0.1032481 Vali Loss: 0.1175735 Test Loss: 0.1405436\n",
      "Validation loss decreased (0.119048 --> 0.117573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0995604\n",
      "\tspeed: 0.3061s/iter; left time: 6619.7832s\n",
      "\titers: 200, epoch: 4 | loss: 0.1006075\n",
      "\tspeed: 0.1810s/iter; left time: 3897.4781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.76s\n",
      "Steps: 224 | Train Loss: 0.1012283 Vali Loss: 0.1169945 Test Loss: 0.1409361\n",
      "Validation loss decreased (0.117573 --> 0.116995).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1010126\n",
      "\tspeed: 0.2632s/iter; left time: 5634.2028s\n",
      "\titers: 200, epoch: 5 | loss: 0.1020785\n",
      "\tspeed: 0.1435s/iter; left time: 3057.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.44s\n",
      "Steps: 224 | Train Loss: 0.0999265 Vali Loss: 0.1165816 Test Loss: 0.1420393\n",
      "Validation loss decreased (0.116995 --> 0.116582).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0985006\n",
      "\tspeed: 0.3545s/iter; left time: 7509.5934s\n",
      "\titers: 200, epoch: 6 | loss: 0.1023615\n",
      "\tspeed: 0.1877s/iter; left time: 3956.9149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.84s\n",
      "Steps: 224 | Train Loss: 0.0988150 Vali Loss: 0.1164725 Test Loss: 0.1419193\n",
      "Validation loss decreased (0.116582 --> 0.116472).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0936005\n",
      "\tspeed: 0.3285s/iter; left time: 6885.3108s\n",
      "\titers: 200, epoch: 7 | loss: 0.1041656\n",
      "\tspeed: 0.1785s/iter; left time: 3722.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.65s\n",
      "Steps: 224 | Train Loss: 0.0977622 Vali Loss: 0.1164984 Test Loss: 0.1426636\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0965147\n",
      "\tspeed: 0.3387s/iter; left time: 7021.4189s\n",
      "\titers: 200, epoch: 8 | loss: 0.0945425\n",
      "\tspeed: 0.2009s/iter; left time: 4145.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.53s\n",
      "Steps: 224 | Train Loss: 0.0968455 Vali Loss: 0.1165157 Test Loss: 0.1424598\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0966142\n",
      "\tspeed: 0.3162s/iter; left time: 6485.9655s\n",
      "\titers: 200, epoch: 9 | loss: 0.0961041\n",
      "\tspeed: 0.1872s/iter; left time: 3820.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.15s\n",
      "Steps: 224 | Train Loss: 0.0958037 Vali Loss: 0.1168818 Test Loss: 0.1435367\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0900782\n",
      "\tspeed: 0.3316s/iter; left time: 6726.7030s\n",
      "\titers: 200, epoch: 10 | loss: 0.0928683\n",
      "\tspeed: 0.1870s/iter; left time: 3774.1411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.18s\n",
      "Steps: 224 | Train Loss: 0.0950237 Vali Loss: 0.1168693 Test Loss: 0.1427697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0930412\n",
      "\tspeed: 0.3258s/iter; left time: 6535.2614s\n",
      "\titers: 200, epoch: 11 | loss: 0.0950651\n",
      "\tspeed: 0.1884s/iter; left time: 3760.4850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 224 | Train Loss: 0.0941731 Vali Loss: 0.1173024 Test Loss: 0.1442032\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0968957\n",
      "\tspeed: 0.3413s/iter; left time: 6770.1882s\n",
      "\titers: 200, epoch: 12 | loss: 0.0931910\n",
      "\tspeed: 0.1741s/iter; left time: 3436.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.23s\n",
      "Steps: 224 | Train Loss: 0.0934533 Vali Loss: 0.1175537 Test Loss: 0.1439120\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0920408\n",
      "\tspeed: 0.3344s/iter; left time: 6559.0429s\n",
      "\titers: 200, epoch: 13 | loss: 0.0944622\n",
      "\tspeed: 0.1917s/iter; left time: 3740.2166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 224 | Train Loss: 0.0928211 Vali Loss: 0.1180769 Test Loss: 0.1442586\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0956941\n",
      "\tspeed: 0.3002s/iter; left time: 5821.4911s\n",
      "\titers: 200, epoch: 14 | loss: 0.0928700\n",
      "\tspeed: 0.1713s/iter; left time: 3304.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 224 | Train Loss: 0.0922051 Vali Loss: 0.1175812 Test Loss: 0.1443594\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0883551\n",
      "\tspeed: 0.2738s/iter; left time: 5247.3129s\n",
      "\titers: 200, epoch: 15 | loss: 0.0926333\n",
      "\tspeed: 0.1303s/iter; left time: 2483.3893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:29.77s\n",
      "Steps: 224 | Train Loss: 0.0916389 Vali Loss: 0.1180225 Test Loss: 0.1446331\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0901917\n",
      "\tspeed: 0.3135s/iter; left time: 5938.7104s\n",
      "\titers: 200, epoch: 16 | loss: 0.0919948\n",
      "\tspeed: 0.1900s/iter; left time: 3579.1860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:42.82s\n",
      "Steps: 224 | Train Loss: 0.0911649 Vali Loss: 0.1185595 Test Loss: 0.1457173\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04354952275753021, rmse:0.20868521928787231, mae:0.14191927015781403, rse:0.7216625809669495\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1456753\n",
      "\tspeed: 0.1714s/iter; left time: 3821.5331s\n",
      "\titers: 200, epoch: 1 | loss: 0.1401336\n",
      "\tspeed: 0.1760s/iter; left time: 3906.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.71s\n",
      "Steps: 224 | Train Loss: 0.1450534 Vali Loss: 0.1476693 Test Loss: 0.1731948\n",
      "Validation loss decreased (inf --> 0.147669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1121303\n",
      "\tspeed: 0.3509s/iter; left time: 7747.2775s\n",
      "\titers: 200, epoch: 2 | loss: 0.1097031\n",
      "\tspeed: 0.1966s/iter; left time: 4320.5681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.54s\n",
      "Steps: 224 | Train Loss: 0.1142875 Vali Loss: 0.1189107 Test Loss: 0.1412798\n",
      "Validation loss decreased (0.147669 --> 0.118911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1073427\n",
      "\tspeed: 0.3165s/iter; left time: 6916.8371s\n",
      "\titers: 200, epoch: 3 | loss: 0.1005311\n",
      "\tspeed: 0.1890s/iter; left time: 4111.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.01s\n",
      "Steps: 224 | Train Loss: 0.1034565 Vali Loss: 0.1175246 Test Loss: 0.1412851\n",
      "Validation loss decreased (0.118911 --> 0.117525).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1021812\n",
      "\tspeed: 0.3423s/iter; left time: 7404.4127s\n",
      "\titers: 200, epoch: 4 | loss: 0.0990468\n",
      "\tspeed: 0.1901s/iter; left time: 4092.6470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.87s\n",
      "Steps: 224 | Train Loss: 0.1013426 Vali Loss: 0.1167549 Test Loss: 0.1418313\n",
      "Validation loss decreased (0.117525 --> 0.116755).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0974963\n",
      "\tspeed: 0.3340s/iter; left time: 7149.1094s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008517\n",
      "\tspeed: 0.1953s/iter; left time: 4161.6451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.74s\n",
      "Steps: 224 | Train Loss: 0.0997085 Vali Loss: 0.1166128 Test Loss: 0.1418357\n",
      "Validation loss decreased (0.116755 --> 0.116613).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1000176\n",
      "\tspeed: 0.3454s/iter; left time: 7316.7203s\n",
      "\titers: 200, epoch: 6 | loss: 0.0948140\n",
      "\tspeed: 0.1645s/iter; left time: 3467.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0984699 Vali Loss: 0.1163163 Test Loss: 0.1417426\n",
      "Validation loss decreased (0.116613 --> 0.116316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0972994\n",
      "\tspeed: 0.2390s/iter; left time: 5007.8331s\n",
      "\titers: 200, epoch: 7 | loss: 0.0936878\n",
      "\tspeed: 0.0988s/iter; left time: 2061.2745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.97s\n",
      "Steps: 224 | Train Loss: 0.0972406 Vali Loss: 0.1165814 Test Loss: 0.1420426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0935553\n",
      "\tspeed: 0.1237s/iter; left time: 2564.5201s\n",
      "\titers: 200, epoch: 8 | loss: 0.0962930\n",
      "\tspeed: 0.0616s/iter; left time: 1271.7131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.33s\n",
      "Steps: 224 | Train Loss: 0.0962139 Vali Loss: 0.1169551 Test Loss: 0.1428138\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0923287\n",
      "\tspeed: 0.1261s/iter; left time: 2586.0657s\n",
      "\titers: 200, epoch: 9 | loss: 0.0975701\n",
      "\tspeed: 0.0623s/iter; left time: 1271.5327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:14.26s\n",
      "Steps: 224 | Train Loss: 0.0952119 Vali Loss: 0.1167024 Test Loss: 0.1424034\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0950940\n",
      "\tspeed: 0.1201s/iter; left time: 2437.0827s\n",
      "\titers: 200, epoch: 10 | loss: 0.0920952\n",
      "\tspeed: 0.0650s/iter; left time: 1311.6705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.62s\n",
      "Steps: 224 | Train Loss: 0.0942552 Vali Loss: 0.1169274 Test Loss: 0.1425461\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0946459\n",
      "\tspeed: 0.1334s/iter; left time: 2676.2856s\n",
      "\titers: 200, epoch: 11 | loss: 0.0923537\n",
      "\tspeed: 0.0648s/iter; left time: 1293.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:14.72s\n",
      "Steps: 224 | Train Loss: 0.0934874 Vali Loss: 0.1180461 Test Loss: 0.1432987\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0927330\n",
      "\tspeed: 0.1207s/iter; left time: 2394.3228s\n",
      "\titers: 200, epoch: 12 | loss: 0.0926669\n",
      "\tspeed: 0.0627s/iter; left time: 1237.0574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.03s\n",
      "Steps: 224 | Train Loss: 0.0927273 Vali Loss: 0.1177090 Test Loss: 0.1433754\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0888391\n",
      "\tspeed: 0.1335s/iter; left time: 2618.8542s\n",
      "\titers: 200, epoch: 13 | loss: 0.0915669\n",
      "\tspeed: 0.0645s/iter; left time: 1259.0008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.68s\n",
      "Steps: 224 | Train Loss: 0.0920820 Vali Loss: 0.1174937 Test Loss: 0.1429974\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0890915\n",
      "\tspeed: 0.1240s/iter; left time: 2404.5117s\n",
      "\titers: 200, epoch: 14 | loss: 0.0909410\n",
      "\tspeed: 0.0639s/iter; left time: 1232.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.72s\n",
      "Steps: 224 | Train Loss: 0.0915154 Vali Loss: 0.1185164 Test Loss: 0.1435190\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0897911\n",
      "\tspeed: 0.1302s/iter; left time: 2495.7685s\n",
      "\titers: 200, epoch: 15 | loss: 0.0919447\n",
      "\tspeed: 0.0598s/iter; left time: 1140.9189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.42s\n",
      "Steps: 224 | Train Loss: 0.0909746 Vali Loss: 0.1183434 Test Loss: 0.1438548\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0908882\n",
      "\tspeed: 0.1171s/iter; left time: 2218.3356s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     67\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 68\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here so long because someone started running his 2 processes on my GPU while I was running my code >:( without it, it runs 3-4 hours.\n",
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1467022\n",
      "\tspeed: 0.0950s/iter; left time: 2118.9031s\n",
      "\titers: 200, epoch: 1 | loss: 0.1380337\n",
      "\tspeed: 0.0659s/iter; left time: 1463.5829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.1492598 Vali Loss: 0.1491447 Test Loss: 0.1573455\n",
      "Validation loss decreased (inf --> 0.149145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0933916\n",
      "\tspeed: 0.1230s/iter; left time: 2716.2641s\n",
      "\titers: 200, epoch: 2 | loss: 0.0793409\n",
      "\tspeed: 0.0694s/iter; left time: 1525.5481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0958381 Vali Loss: 0.0959918 Test Loss: 0.0965967\n",
      "Validation loss decreased (0.149145 --> 0.095992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804107\n",
      "\tspeed: 0.1329s/iter; left time: 2904.6195s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822360\n",
      "\tspeed: 0.0601s/iter; left time: 1306.8907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:14.72s\n",
      "Steps: 224 | Train Loss: 0.0800409 Vali Loss: 0.0911792 Test Loss: 0.0924903\n",
      "Validation loss decreased (0.095992 --> 0.091179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0721088\n",
      "\tspeed: 0.1141s/iter; left time: 2468.9429s\n",
      "\titers: 200, epoch: 4 | loss: 0.0784065\n",
      "\tspeed: 0.0637s/iter; left time: 1372.0856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.60s\n",
      "Steps: 224 | Train Loss: 0.0768202 Vali Loss: 0.0894785 Test Loss: 0.0912090\n",
      "Validation loss decreased (0.091179 --> 0.089479).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0701359\n",
      "\tspeed: 0.1280s/iter; left time: 2740.0871s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721674\n",
      "\tspeed: 0.0634s/iter; left time: 1350.0053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:14.95s\n",
      "Steps: 224 | Train Loss: 0.0751275 Vali Loss: 0.0886305 Test Loss: 0.0903440\n",
      "Validation loss decreased (0.089479 --> 0.088631).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0747568\n",
      "\tspeed: 0.1270s/iter; left time: 2689.6027s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739783\n",
      "\tspeed: 0.0656s/iter; left time: 1382.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.98s\n",
      "Steps: 224 | Train Loss: 0.0740978 Vali Loss: 0.0879776 Test Loss: 0.0896847\n",
      "Validation loss decreased (0.088631 --> 0.087978).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0773371\n",
      "\tspeed: 0.1189s/iter; left time: 2491.1703s\n",
      "\titers: 200, epoch: 7 | loss: 0.0693570\n",
      "\tspeed: 0.0658s/iter; left time: 1373.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.93s\n",
      "Steps: 224 | Train Loss: 0.0731795 Vali Loss: 0.0878054 Test Loss: 0.0894686\n",
      "Validation loss decreased (0.087978 --> 0.087805).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742184\n",
      "\tspeed: 0.1238s/iter; left time: 2565.7303s\n",
      "\titers: 200, epoch: 8 | loss: 0.0694305\n",
      "\tspeed: 0.0701s/iter; left time: 1447.0983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0726620 Vali Loss: 0.0872411 Test Loss: 0.0890743\n",
      "Validation loss decreased (0.087805 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0730793\n",
      "\tspeed: 0.1373s/iter; left time: 2816.8462s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740317\n",
      "\tspeed: 0.0627s/iter; left time: 1280.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.16s\n",
      "Steps: 224 | Train Loss: 0.0721427 Vali Loss: 0.0873636 Test Loss: 0.0895516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0651195\n",
      "\tspeed: 0.1195s/iter; left time: 2424.1713s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683019\n",
      "\tspeed: 0.0632s/iter; left time: 1276.0370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.78s\n",
      "Steps: 224 | Train Loss: 0.0717890 Vali Loss: 0.0870031 Test Loss: 0.0891616\n",
      "Validation loss decreased (0.087241 --> 0.087003).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0714403\n",
      "\tspeed: 0.1300s/iter; left time: 2607.9335s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766668\n",
      "\tspeed: 0.0645s/iter; left time: 1286.4963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0714359 Vali Loss: 0.0870827 Test Loss: 0.0894357\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0713613\n",
      "\tspeed: 0.1163s/iter; left time: 2306.6772s\n",
      "\titers: 200, epoch: 12 | loss: 0.0730791\n",
      "\tspeed: 0.0674s/iter; left time: 1330.8254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.63s\n",
      "Steps: 224 | Train Loss: 0.0711605 Vali Loss: 0.0868916 Test Loss: 0.0890513\n",
      "Validation loss decreased (0.087003 --> 0.086892).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0658389\n",
      "\tspeed: 0.1201s/iter; left time: 2356.2263s\n",
      "\titers: 200, epoch: 13 | loss: 0.0685006\n",
      "\tspeed: 0.0734s/iter; left time: 1431.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.72s\n",
      "Steps: 224 | Train Loss: 0.0708652 Vali Loss: 0.0865712 Test Loss: 0.0891132\n",
      "Validation loss decreased (0.086892 --> 0.086571).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0742952\n",
      "\tspeed: 0.1337s/iter; left time: 2591.8576s\n",
      "\titers: 200, epoch: 14 | loss: 0.0701290\n",
      "\tspeed: 0.0607s/iter; left time: 1170.5141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.60s\n",
      "Steps: 224 | Train Loss: 0.0706609 Vali Loss: 0.0864862 Test Loss: 0.0889904\n",
      "Validation loss decreased (0.086571 --> 0.086486).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0725446\n",
      "\tspeed: 0.1249s/iter; left time: 2393.5944s\n",
      "\titers: 200, epoch: 15 | loss: 0.0695209\n",
      "\tspeed: 0.0637s/iter; left time: 1214.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.81s\n",
      "Steps: 224 | Train Loss: 0.0704827 Vali Loss: 0.0864452 Test Loss: 0.0889387\n",
      "Validation loss decreased (0.086486 --> 0.086445).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0676632\n",
      "\tspeed: 0.1199s/iter; left time: 2270.5361s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735662\n",
      "\tspeed: 0.0667s/iter; left time: 1256.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.05s\n",
      "Steps: 224 | Train Loss: 0.0703078 Vali Loss: 0.0865087 Test Loss: 0.0890939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0669014\n",
      "\tspeed: 0.1205s/iter; left time: 2256.0113s\n",
      "\titers: 200, epoch: 17 | loss: 0.0692772\n",
      "\tspeed: 0.0647s/iter; left time: 1204.2729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.60s\n",
      "Steps: 224 | Train Loss: 0.0701388 Vali Loss: 0.0867771 Test Loss: 0.0890331\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0704841\n",
      "\tspeed: 0.1230s/iter; left time: 2275.2929s\n",
      "\titers: 200, epoch: 18 | loss: 0.0685036\n",
      "\tspeed: 0.0720s/iter; left time: 1324.1445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0699684 Vali Loss: 0.0864049 Test Loss: 0.0891183\n",
      "Validation loss decreased (0.086445 --> 0.086405).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0693344\n",
      "\tspeed: 0.1250s/iter; left time: 2284.3230s\n",
      "\titers: 200, epoch: 19 | loss: 0.0699148\n",
      "\tspeed: 0.0629s/iter; left time: 1143.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0698359 Vali Loss: 0.0864480 Test Loss: 0.0891146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0743156\n",
      "\tspeed: 0.1131s/iter; left time: 2040.7547s\n",
      "\titers: 200, epoch: 20 | loss: 0.0695782\n",
      "\tspeed: 0.0632s/iter; left time: 1133.6380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:14.62s\n",
      "Steps: 224 | Train Loss: 0.0698212 Vali Loss: 0.0862729 Test Loss: 0.0889007\n",
      "Validation loss decreased (0.086405 --> 0.086273).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0642834\n",
      "\tspeed: 0.1247s/iter; left time: 2223.1491s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729156\n",
      "\tspeed: 0.0623s/iter; left time: 1104.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:14.12s\n",
      "Steps: 224 | Train Loss: 0.0696815 Vali Loss: 0.0863191 Test Loss: 0.0889219\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0668081\n",
      "\tspeed: 0.1139s/iter; left time: 2003.4293s\n",
      "\titers: 200, epoch: 22 | loss: 0.0675850\n",
      "\tspeed: 0.0641s/iter; left time: 1120.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:14.34s\n",
      "Steps: 224 | Train Loss: 0.0696013 Vali Loss: 0.0863717 Test Loss: 0.0890059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0662554\n",
      "\tspeed: 0.1180s/iter; left time: 2049.7502s\n",
      "\titers: 200, epoch: 23 | loss: 0.0715963\n",
      "\tspeed: 0.0639s/iter; left time: 1103.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:14.63s\n",
      "Steps: 224 | Train Loss: 0.0694505 Vali Loss: 0.0862607 Test Loss: 0.0890646\n",
      "Validation loss decreased (0.086273 --> 0.086261).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0695211\n",
      "\tspeed: 0.1102s/iter; left time: 1889.0027s\n",
      "\titers: 200, epoch: 24 | loss: 0.0653179\n",
      "\tspeed: 0.0629s/iter; left time: 1072.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:13.89s\n",
      "Steps: 224 | Train Loss: 0.0693793 Vali Loss: 0.0863263 Test Loss: 0.0889909\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0677006\n",
      "\tspeed: 0.1239s/iter; left time: 2097.2938s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705059\n",
      "\tspeed: 0.0661s/iter; left time: 1112.4056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:14.75s\n",
      "Steps: 224 | Train Loss: 0.0693588 Vali Loss: 0.0863821 Test Loss: 0.0890807\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0654885\n",
      "\tspeed: 0.1172s/iter; left time: 1957.9176s\n",
      "\titers: 200, epoch: 26 | loss: 0.0649945\n",
      "\tspeed: 0.0655s/iter; left time: 1086.6304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:14.47s\n",
      "Steps: 224 | Train Loss: 0.0692742 Vali Loss: 0.0864751 Test Loss: 0.0893381\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0677808\n",
      "\tspeed: 0.1194s/iter; left time: 1966.8512s\n",
      "\titers: 200, epoch: 27 | loss: 0.0714075\n",
      "\tspeed: 0.0619s/iter; left time: 1014.0380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:14.69s\n",
      "Steps: 224 | Train Loss: 0.0692092 Vali Loss: 0.0862476 Test Loss: 0.0890449\n",
      "Validation loss decreased (0.086261 --> 0.086248).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0650818\n",
      "\tspeed: 0.1338s/iter; left time: 2175.3443s\n",
      "\titers: 200, epoch: 28 | loss: 0.0720823\n",
      "\tspeed: 0.0628s/iter; left time: 1013.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:14.69s\n",
      "Steps: 224 | Train Loss: 0.0691955 Vali Loss: 0.0863042 Test Loss: 0.0889602\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0675507\n",
      "\tspeed: 0.1180s/iter; left time: 1891.4063s\n",
      "\titers: 200, epoch: 29 | loss: 0.0689953\n",
      "\tspeed: 0.0637s/iter; left time: 1013.9908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:14.39s\n",
      "Steps: 224 | Train Loss: 0.0691315 Vali Loss: 0.0862055 Test Loss: 0.0891577\n",
      "Validation loss decreased (0.086248 --> 0.086206).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0723119\n",
      "\tspeed: 0.1205s/iter; left time: 1904.0685s\n",
      "\titers: 200, epoch: 30 | loss: 0.0689444\n",
      "\tspeed: 0.0712s/iter; left time: 1118.9621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0690726 Vali Loss: 0.0864122 Test Loss: 0.0891799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0699471\n",
      "\tspeed: 0.1202s/iter; left time: 1872.5759s\n",
      "\titers: 200, epoch: 31 | loss: 0.0650906\n",
      "\tspeed: 0.0614s/iter; left time: 950.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:14.07s\n",
      "Steps: 224 | Train Loss: 0.0690898 Vali Loss: 0.0861617 Test Loss: 0.0890982\n",
      "Validation loss decreased (0.086206 --> 0.086162).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0697123\n",
      "\tspeed: 0.1258s/iter; left time: 1932.4683s\n",
      "\titers: 200, epoch: 32 | loss: 0.0689837\n",
      "\tspeed: 0.0672s/iter; left time: 1025.0592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:14.74s\n",
      "Steps: 224 | Train Loss: 0.0690290 Vali Loss: 0.0862783 Test Loss: 0.0891600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0689367\n",
      "\tspeed: 0.1181s/iter; left time: 1786.6067s\n",
      "\titers: 200, epoch: 33 | loss: 0.0651389\n",
      "\tspeed: 0.0605s/iter; left time: 909.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:13.98s\n",
      "Steps: 224 | Train Loss: 0.0689599 Vali Loss: 0.0864315 Test Loss: 0.0891968\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0703542\n",
      "\tspeed: 0.1150s/iter; left time: 1714.7491s\n",
      "\titers: 200, epoch: 34 | loss: 0.0736774\n",
      "\tspeed: 0.0611s/iter; left time: 905.5012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:13.71s\n",
      "Steps: 224 | Train Loss: 0.0689449 Vali Loss: 0.0863892 Test Loss: 0.0892073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0694088\n",
      "\tspeed: 0.1209s/iter; left time: 1776.0411s\n",
      "\titers: 200, epoch: 35 | loss: 0.0643488\n",
      "\tspeed: 0.0608s/iter; left time: 886.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:14.04s\n",
      "Steps: 224 | Train Loss: 0.0689930 Vali Loss: 0.0862459 Test Loss: 0.0891558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0662179\n",
      "\tspeed: 0.1141s/iter; left time: 1649.5385s\n",
      "\titers: 200, epoch: 36 | loss: 0.0716586\n",
      "\tspeed: 0.0613s/iter; left time: 879.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:14.30s\n",
      "Steps: 224 | Train Loss: 0.0689090 Vali Loss: 0.0862916 Test Loss: 0.0891562\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0689815\n",
      "\tspeed: 0.1206s/iter; left time: 1716.8763s\n",
      "\titers: 200, epoch: 37 | loss: 0.0692148\n",
      "\tspeed: 0.0590s/iter; left time: 834.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:13.57s\n",
      "Steps: 224 | Train Loss: 0.0688933 Vali Loss: 0.0864036 Test Loss: 0.0891469\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0756959\n",
      "\tspeed: 0.1219s/iter; left time: 1707.6168s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706713\n",
      "\tspeed: 0.0631s/iter; left time: 877.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:14.53s\n",
      "Steps: 224 | Train Loss: 0.0689504 Vali Loss: 0.0863323 Test Loss: 0.0891482\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0717678\n",
      "\tspeed: 0.1210s/iter; left time: 1667.7915s\n",
      "\titers: 200, epoch: 39 | loss: 0.0696688\n",
      "\tspeed: 0.0636s/iter; left time: 871.2852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:14.90s\n",
      "Steps: 224 | Train Loss: 0.0688292 Vali Loss: 0.0862189 Test Loss: 0.0891291\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0669256\n",
      "\tspeed: 0.1225s/iter; left time: 1662.1895s\n",
      "\titers: 200, epoch: 40 | loss: 0.0677449\n",
      "\tspeed: 0.0633s/iter; left time: 851.7725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0688930 Vali Loss: 0.0861876 Test Loss: 0.0891016\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0648098\n",
      "\tspeed: 0.1213s/iter; left time: 1618.3571s\n",
      "\titers: 200, epoch: 41 | loss: 0.0646161\n",
      "\tspeed: 0.0676s/iter; left time: 894.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0688258 Vali Loss: 0.0862216 Test Loss: 0.0891206\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021291740238666534, rmse:0.1459168940782547, mae:0.08909820020198822, rse:0.5149609446525574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1485177\n",
      "\tspeed: 0.0621s/iter; left time: 1384.0774s\n",
      "\titers: 200, epoch: 1 | loss: 0.1372107\n",
      "\tspeed: 0.0651s/iter; left time: 1446.2785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.28s\n",
      "Steps: 224 | Train Loss: 0.1479508 Vali Loss: 0.1469130 Test Loss: 0.1552787\n",
      "Validation loss decreased (inf --> 0.146913).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0860679\n",
      "\tspeed: 0.1240s/iter; left time: 2736.6685s\n",
      "\titers: 200, epoch: 2 | loss: 0.0842555\n",
      "\tspeed: 0.0617s/iter; left time: 1355.3881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:14.32s\n",
      "Steps: 224 | Train Loss: 0.0963806 Vali Loss: 0.0965345 Test Loss: 0.0970062\n",
      "Validation loss decreased (0.146913 --> 0.096534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0792745\n",
      "\tspeed: 0.1228s/iter; left time: 2683.1567s\n",
      "\titers: 200, epoch: 3 | loss: 0.0799089\n",
      "\tspeed: 0.0657s/iter; left time: 1429.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.05s\n",
      "Steps: 224 | Train Loss: 0.0806034 Vali Loss: 0.0915469 Test Loss: 0.0932558\n",
      "Validation loss decreased (0.096534 --> 0.091547).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0692745\n",
      "\tspeed: 0.1149s/iter; left time: 2486.1917s\n",
      "\titers: 200, epoch: 4 | loss: 0.0753272\n",
      "\tspeed: 0.0625s/iter; left time: 1346.4517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.10s\n",
      "Steps: 224 | Train Loss: 0.0771334 Vali Loss: 0.0894109 Test Loss: 0.0913275\n",
      "Validation loss decreased (0.091547 --> 0.089411).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0780892\n",
      "\tspeed: 0.1276s/iter; left time: 2731.8281s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733127\n",
      "\tspeed: 0.0621s/iter; left time: 1322.0636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.09s\n",
      "Steps: 224 | Train Loss: 0.0752457 Vali Loss: 0.0887977 Test Loss: 0.0907949\n",
      "Validation loss decreased (0.089411 --> 0.088798).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0735669\n",
      "\tspeed: 0.1179s/iter; left time: 2496.6906s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754406\n",
      "\tspeed: 0.0604s/iter; left time: 1272.8398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.01s\n",
      "Steps: 224 | Train Loss: 0.0741429 Vali Loss: 0.0879942 Test Loss: 0.0900813\n",
      "Validation loss decreased (0.088798 --> 0.087994).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0708586\n",
      "\tspeed: 0.1147s/iter; left time: 2403.2162s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723750\n",
      "\tspeed: 0.0675s/iter; left time: 1407.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.90s\n",
      "Steps: 224 | Train Loss: 0.0733710 Vali Loss: 0.0877222 Test Loss: 0.0897023\n",
      "Validation loss decreased (0.087994 --> 0.087722).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0735653\n",
      "\tspeed: 0.1221s/iter; left time: 2530.4863s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752200\n",
      "\tspeed: 0.0629s/iter; left time: 1297.5821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.53s\n",
      "Steps: 224 | Train Loss: 0.0726825 Vali Loss: 0.0871324 Test Loss: 0.0893786\n",
      "Validation loss decreased (0.087722 --> 0.087132).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738944\n",
      "\tspeed: 0.1156s/iter; left time: 2370.1262s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740931\n",
      "\tspeed: 0.0647s/iter; left time: 1319.9574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:14.63s\n",
      "Steps: 224 | Train Loss: 0.0721897 Vali Loss: 0.0869960 Test Loss: 0.0890788\n",
      "Validation loss decreased (0.087132 --> 0.086996).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751932\n",
      "\tspeed: 0.1254s/iter; left time: 2542.9586s\n",
      "\titers: 200, epoch: 10 | loss: 0.0673028\n",
      "\tspeed: 0.0662s/iter; left time: 1336.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.72s\n",
      "Steps: 224 | Train Loss: 0.0717408 Vali Loss: 0.0867880 Test Loss: 0.0891405\n",
      "Validation loss decreased (0.086996 --> 0.086788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0667565\n",
      "\tspeed: 0.1210s/iter; left time: 2427.9128s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711614\n",
      "\tspeed: 0.0618s/iter; left time: 1232.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:14.38s\n",
      "Steps: 224 | Train Loss: 0.0714507 Vali Loss: 0.0870664 Test Loss: 0.0891779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710983\n",
      "\tspeed: 0.1320s/iter; left time: 2619.0962s\n",
      "\titers: 200, epoch: 12 | loss: 0.0680309\n",
      "\tspeed: 0.0659s/iter; left time: 1299.9922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 224 | Train Loss: 0.0711380 Vali Loss: 0.0867219 Test Loss: 0.0890017\n",
      "Validation loss decreased (0.086788 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719549\n",
      "\tspeed: 0.1264s/iter; left time: 2478.2972s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728736\n",
      "\tspeed: 0.0667s/iter; left time: 1302.1044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.77s\n",
      "Steps: 224 | Train Loss: 0.0709379 Vali Loss: 0.0864662 Test Loss: 0.0890279\n",
      "Validation loss decreased (0.086722 --> 0.086466).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0695809\n",
      "\tspeed: 0.1251s/iter; left time: 2424.6956s\n",
      "\titers: 200, epoch: 14 | loss: 0.0691624\n",
      "\tspeed: 0.0709s/iter; left time: 1367.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0707244 Vali Loss: 0.0867192 Test Loss: 0.0890669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662107\n",
      "\tspeed: 0.1254s/iter; left time: 2402.8683s\n",
      "\titers: 200, epoch: 15 | loss: 0.0770034\n",
      "\tspeed: 0.0634s/iter; left time: 1207.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.89s\n",
      "Steps: 224 | Train Loss: 0.0704650 Vali Loss: 0.0864952 Test Loss: 0.0890869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746670\n",
      "\tspeed: 0.1261s/iter; left time: 2387.6390s\n",
      "\titers: 200, epoch: 16 | loss: 0.0751349\n",
      "\tspeed: 0.0661s/iter; left time: 1246.2305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:14.93s\n",
      "Steps: 224 | Train Loss: 0.0703478 Vali Loss: 0.0866213 Test Loss: 0.0890552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0691212\n",
      "\tspeed: 0.1290s/iter; left time: 2413.9802s\n",
      "\titers: 200, epoch: 17 | loss: 0.0701027\n",
      "\tspeed: 0.0672s/iter; left time: 1250.4591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.08s\n",
      "Steps: 224 | Train Loss: 0.0701723 Vali Loss: 0.0864791 Test Loss: 0.0890113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0723499\n",
      "\tspeed: 0.1182s/iter; left time: 2185.8872s\n",
      "\titers: 200, epoch: 18 | loss: 0.0661663\n",
      "\tspeed: 0.0649s/iter; left time: 1194.5697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:14.77s\n",
      "Steps: 224 | Train Loss: 0.0700250 Vali Loss: 0.0864334 Test Loss: 0.0889767\n",
      "Validation loss decreased (0.086466 --> 0.086433).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0676247\n",
      "\tspeed: 0.1403s/iter; left time: 2563.1624s\n",
      "\titers: 200, epoch: 19 | loss: 0.0656377\n",
      "\tspeed: 0.0662s/iter; left time: 1203.3913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:16.01s\n",
      "Steps: 224 | Train Loss: 0.0698972 Vali Loss: 0.0863700 Test Loss: 0.0890557\n",
      "Validation loss decreased (0.086433 --> 0.086370).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0731429\n",
      "\tspeed: 0.1251s/iter; left time: 2257.0634s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692441\n",
      "\tspeed: 0.0640s/iter; left time: 1148.2912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.11s\n",
      "Steps: 224 | Train Loss: 0.0697965 Vali Loss: 0.0862033 Test Loss: 0.0890447\n",
      "Validation loss decreased (0.086370 --> 0.086203).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0687015\n",
      "\tspeed: 0.1302s/iter; left time: 2320.8509s\n",
      "\titers: 200, epoch: 21 | loss: 0.0658207\n",
      "\tspeed: 0.0727s/iter; left time: 1288.2780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0696816 Vali Loss: 0.0863567 Test Loss: 0.0893161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0706210\n",
      "\tspeed: 0.1223s/iter; left time: 2152.9136s\n",
      "\titers: 200, epoch: 22 | loss: 0.0746962\n",
      "\tspeed: 0.0656s/iter; left time: 1147.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:14.58s\n",
      "Steps: 224 | Train Loss: 0.0696258 Vali Loss: 0.0863918 Test Loss: 0.0891025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0717456\n",
      "\tspeed: 0.1242s/iter; left time: 2157.3633s\n",
      "\titers: 200, epoch: 23 | loss: 0.0713271\n",
      "\tspeed: 0.0631s/iter; left time: 1089.6731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:14.99s\n",
      "Steps: 224 | Train Loss: 0.0695054 Vali Loss: 0.0861524 Test Loss: 0.0890253\n",
      "Validation loss decreased (0.086203 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0754816\n",
      "\tspeed: 0.1252s/iter; left time: 2146.2373s\n",
      "\titers: 200, epoch: 24 | loss: 0.0685918\n",
      "\tspeed: 0.0637s/iter; left time: 1085.9859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:14.48s\n",
      "Steps: 224 | Train Loss: 0.0694104 Vali Loss: 0.0862667 Test Loss: 0.0890559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0633278\n",
      "\tspeed: 0.1208s/iter; left time: 2045.3087s\n",
      "\titers: 200, epoch: 25 | loss: 0.0648984\n",
      "\tspeed: 0.0652s/iter; left time: 1097.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:14.99s\n",
      "Steps: 224 | Train Loss: 0.0693590 Vali Loss: 0.0861933 Test Loss: 0.0891097\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0697152\n",
      "\tspeed: 0.1304s/iter; left time: 2177.3724s\n",
      "\titers: 200, epoch: 26 | loss: 0.0684530\n",
      "\tspeed: 0.0669s/iter; left time: 1110.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.0692901 Vali Loss: 0.0861402 Test Loss: 0.0891699\n",
      "Validation loss decreased (0.086152 --> 0.086140).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0680913\n",
      "\tspeed: 0.1202s/iter; left time: 1980.6748s\n",
      "\titers: 200, epoch: 27 | loss: 0.0710975\n",
      "\tspeed: 0.0665s/iter; left time: 1088.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:14.77s\n",
      "Steps: 224 | Train Loss: 0.0692415 Vali Loss: 0.0861493 Test Loss: 0.0890312\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662386\n",
      "\tspeed: 0.1191s/iter; left time: 1935.2237s\n",
      "\titers: 200, epoch: 28 | loss: 0.0694833\n",
      "\tspeed: 0.0707s/iter; left time: 1141.6237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0691602 Vali Loss: 0.0861183 Test Loss: 0.0892049\n",
      "Validation loss decreased (0.086140 --> 0.086118).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0725555\n",
      "\tspeed: 0.1381s/iter; left time: 2212.8754s\n",
      "\titers: 200, epoch: 29 | loss: 0.0715661\n",
      "\tspeed: 0.0615s/iter; left time: 979.6940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:14.43s\n",
      "Steps: 224 | Train Loss: 0.0691908 Vali Loss: 0.0860879 Test Loss: 0.0891321\n",
      "Validation loss decreased (0.086118 --> 0.086088).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0675764\n",
      "\tspeed: 0.1190s/iter; left time: 1880.9579s\n",
      "\titers: 200, epoch: 30 | loss: 0.0685819\n",
      "\tspeed: 0.0651s/iter; left time: 1021.9364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:14.45s\n",
      "Steps: 224 | Train Loss: 0.0691524 Vali Loss: 0.0860893 Test Loss: 0.0891131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0705770\n",
      "\tspeed: 0.1307s/iter; left time: 2036.3264s\n",
      "\titers: 200, epoch: 31 | loss: 0.0713090\n",
      "\tspeed: 0.0700s/iter; left time: 1083.7904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 224 | Train Loss: 0.0691323 Vali Loss: 0.0861251 Test Loss: 0.0891209\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725021\n",
      "\tspeed: 0.1215s/iter; left time: 1866.2094s\n",
      "\titers: 200, epoch: 32 | loss: 0.0674104\n",
      "\tspeed: 0.0628s/iter; left time: 958.6838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:14.67s\n",
      "Steps: 224 | Train Loss: 0.0690699 Vali Loss: 0.0860819 Test Loss: 0.0890955\n",
      "Validation loss decreased (0.086088 --> 0.086082).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0671740\n",
      "\tspeed: 0.1250s/iter; left time: 1891.9180s\n",
      "\titers: 200, epoch: 33 | loss: 0.0640508\n",
      "\tspeed: 0.0776s/iter; left time: 1165.9629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:16.15s\n",
      "Steps: 224 | Train Loss: 0.0690287 Vali Loss: 0.0861212 Test Loss: 0.0891954\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0705414\n",
      "\tspeed: 0.1315s/iter; left time: 1961.1411s\n",
      "\titers: 200, epoch: 34 | loss: 0.0681740\n",
      "\tspeed: 0.0631s/iter; left time: 934.4324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.14s\n",
      "Steps: 224 | Train Loss: 0.0689596 Vali Loss: 0.0862194 Test Loss: 0.0890935\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0701695\n",
      "\tspeed: 0.1257s/iter; left time: 1846.2539s\n",
      "\titers: 200, epoch: 35 | loss: 0.0673041\n",
      "\tspeed: 0.0613s/iter; left time: 893.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:14.62s\n",
      "Steps: 224 | Train Loss: 0.0689486 Vali Loss: 0.0861580 Test Loss: 0.0891037\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0642554\n",
      "\tspeed: 0.1356s/iter; left time: 1960.5575s\n",
      "\titers: 200, epoch: 36 | loss: 0.0672532\n",
      "\tspeed: 0.0671s/iter; left time: 964.1959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 224 | Train Loss: 0.0689205 Vali Loss: 0.0860491 Test Loss: 0.0890471\n",
      "Validation loss decreased (0.086082 --> 0.086049).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0744950\n",
      "\tspeed: 0.1247s/iter; left time: 1775.0127s\n",
      "\titers: 200, epoch: 37 | loss: 0.0638594\n",
      "\tspeed: 0.0624s/iter; left time: 881.9234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:14.61s\n",
      "Steps: 224 | Train Loss: 0.0689579 Vali Loss: 0.0861269 Test Loss: 0.0891083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0700178\n",
      "\tspeed: 0.1234s/iter; left time: 1728.6455s\n",
      "\titers: 200, epoch: 38 | loss: 0.0661885\n",
      "\tspeed: 0.0670s/iter; left time: 931.7994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 224 | Train Loss: 0.0688744 Vali Loss: 0.0861560 Test Loss: 0.0891225\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0645115\n",
      "\tspeed: 0.1244s/iter; left time: 1714.9794s\n",
      "\titers: 200, epoch: 39 | loss: 0.0643578\n",
      "\tspeed: 0.0657s/iter; left time: 899.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:14.99s\n",
      "Steps: 224 | Train Loss: 0.0689252 Vali Loss: 0.0861439 Test Loss: 0.0890523\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712911\n",
      "\tspeed: 0.1209s/iter; left time: 1639.7164s\n",
      "\titers: 200, epoch: 40 | loss: 0.0740808\n",
      "\tspeed: 0.0560s/iter; left time: 753.9828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:14.36s\n",
      "Steps: 224 | Train Loss: 0.0688536 Vali Loss: 0.0859760 Test Loss: 0.0890604\n",
      "Validation loss decreased (0.086049 --> 0.085976).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0645042\n",
      "\tspeed: 0.1357s/iter; left time: 1810.8289s\n",
      "\titers: 200, epoch: 41 | loss: 0.0700506\n",
      "\tspeed: 0.0656s/iter; left time: 868.9498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.02s\n",
      "Steps: 224 | Train Loss: 0.0688851 Vali Loss: 0.0861665 Test Loss: 0.0890974\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0722492\n",
      "\tspeed: 0.1259s/iter; left time: 1651.6405s\n",
      "\titers: 200, epoch: 42 | loss: 0.0705930\n",
      "\tspeed: 0.0633s/iter; left time: 824.6233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.00s\n",
      "Steps: 224 | Train Loss: 0.0688321 Vali Loss: 0.0860264 Test Loss: 0.0891213\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0742681\n",
      "\tspeed: 0.1254s/iter; left time: 1617.3489s\n",
      "\titers: 200, epoch: 43 | loss: 0.0690211\n",
      "\tspeed: 0.0662s/iter; left time: 846.3824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0688786 Vali Loss: 0.0860898 Test Loss: 0.0890831\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0646683\n",
      "\tspeed: 0.1210s/iter; left time: 1532.4200s\n",
      "\titers: 200, epoch: 44 | loss: 0.0692453\n",
      "\tspeed: 0.0637s/iter; left time: 800.6207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:14.53s\n",
      "Steps: 224 | Train Loss: 0.0688329 Vali Loss: 0.0861044 Test Loss: 0.0890925\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0659040\n",
      "\tspeed: 0.1264s/iter; left time: 1573.0609s\n",
      "\titers: 200, epoch: 45 | loss: 0.0643121\n",
      "\tspeed: 0.0621s/iter; left time: 766.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:14.93s\n",
      "Steps: 224 | Train Loss: 0.0688306 Vali Loss: 0.0860788 Test Loss: 0.0891090\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0707033\n",
      "\tspeed: 0.1271s/iter; left time: 1553.8735s\n",
      "\titers: 200, epoch: 46 | loss: 0.0666583\n",
      "\tspeed: 0.0634s/iter; left time: 768.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:14.72s\n",
      "Steps: 224 | Train Loss: 0.0687669 Vali Loss: 0.0861802 Test Loss: 0.0891388\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0668203\n",
      "\tspeed: 0.1238s/iter; left time: 1485.6883s\n",
      "\titers: 200, epoch: 47 | loss: 0.0678259\n",
      "\tspeed: 0.0630s/iter; left time: 749.3701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:14.54s\n",
      "Steps: 224 | Train Loss: 0.0687843 Vali Loss: 0.0860328 Test Loss: 0.0891000\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0671443\n",
      "\tspeed: 0.1311s/iter; left time: 1543.8882s\n",
      "\titers: 200, epoch: 48 | loss: 0.0705720\n",
      "\tspeed: 0.0642s/iter; left time: 748.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 224 | Train Loss: 0.0687883 Vali Loss: 0.0860063 Test Loss: 0.0891141\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0660993\n",
      "\tspeed: 0.1266s/iter; left time: 1461.9893s\n",
      "\titers: 200, epoch: 49 | loss: 0.0729448\n",
      "\tspeed: 0.0665s/iter; left time: 761.5672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.02s\n",
      "Steps: 224 | Train Loss: 0.0687500 Vali Loss: 0.0861000 Test Loss: 0.0891243\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0677664\n",
      "\tspeed: 0.1275s/iter; left time: 1444.1350s\n",
      "\titers: 200, epoch: 50 | loss: 0.0669769\n",
      "\tspeed: 0.0697s/iter; left time: 781.9626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.32s\n",
      "Steps: 224 | Train Loss: 0.0687967 Vali Loss: 0.0861120 Test Loss: 0.0891771\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02123580500483513, rmse:0.1457251012325287, mae:0.08906044065952301, rse:0.514284074306488\n",
      "Intermediate time for DE and pred_len 24: 00h:28m:49.86s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1550613\n",
      "\tspeed: 0.0927s/iter; left time: 2067.0848s\n",
      "\titers: 200, epoch: 1 | loss: 0.1477888\n",
      "\tspeed: 0.0637s/iter; left time: 1414.5580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.00s\n",
      "Steps: 224 | Train Loss: 0.1587900 Vali Loss: 0.1620391 Test Loss: 0.1741875\n",
      "Validation loss decreased (inf --> 0.162039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160155\n",
      "\tspeed: 0.1242s/iter; left time: 2741.3462s\n",
      "\titers: 200, epoch: 2 | loss: 0.1055968\n",
      "\tspeed: 0.0738s/iter; left time: 1621.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.90s\n",
      "Steps: 224 | Train Loss: 0.1189358 Vali Loss: 0.1230573 Test Loss: 0.1298083\n",
      "Validation loss decreased (0.162039 --> 0.123057).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1057696\n",
      "\tspeed: 0.1272s/iter; left time: 2779.8019s\n",
      "\titers: 200, epoch: 3 | loss: 0.1068358\n",
      "\tspeed: 0.0645s/iter; left time: 1402.9554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:14.85s\n",
      "Steps: 224 | Train Loss: 0.1064453 Vali Loss: 0.1199574 Test Loss: 0.1270489\n",
      "Validation loss decreased (0.123057 --> 0.119957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1014582\n",
      "\tspeed: 0.1272s/iter; left time: 2750.1429s\n",
      "\titers: 200, epoch: 4 | loss: 0.0987709\n",
      "\tspeed: 0.0642s/iter; left time: 1382.8085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.20s\n",
      "Steps: 224 | Train Loss: 0.1033780 Vali Loss: 0.1184104 Test Loss: 0.1268103\n",
      "Validation loss decreased (0.119957 --> 0.118410).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1038326\n",
      "\tspeed: 0.1427s/iter; left time: 3053.5747s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999108\n",
      "\tspeed: 0.0631s/iter; left time: 1344.9435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:14.87s\n",
      "Steps: 224 | Train Loss: 0.1016363 Vali Loss: 0.1186604 Test Loss: 0.1271338\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0998692\n",
      "\tspeed: 0.1217s/iter; left time: 2578.5565s\n",
      "\titers: 200, epoch: 6 | loss: 0.1016956\n",
      "\tspeed: 0.0626s/iter; left time: 1318.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.30s\n",
      "Steps: 224 | Train Loss: 0.1003976 Vali Loss: 0.1183543 Test Loss: 0.1267805\n",
      "Validation loss decreased (0.118410 --> 0.118354).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0950561\n",
      "\tspeed: 0.1268s/iter; left time: 2658.0194s\n",
      "\titers: 200, epoch: 7 | loss: 0.1018301\n",
      "\tspeed: 0.0682s/iter; left time: 1421.6701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 224 | Train Loss: 0.0993858 Vali Loss: 0.1191201 Test Loss: 0.1267930\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0975684\n",
      "\tspeed: 0.1226s/iter; left time: 2541.6046s\n",
      "\titers: 200, epoch: 8 | loss: 0.0958021\n",
      "\tspeed: 0.0648s/iter; left time: 1336.9003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.67s\n",
      "Steps: 224 | Train Loss: 0.0985251 Vali Loss: 0.1189736 Test Loss: 0.1276529\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0942768\n",
      "\tspeed: 0.1228s/iter; left time: 2518.5226s\n",
      "\titers: 200, epoch: 9 | loss: 0.0987583\n",
      "\tspeed: 0.0570s/iter; left time: 1164.1372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:14.51s\n",
      "Steps: 224 | Train Loss: 0.0976029 Vali Loss: 0.1196053 Test Loss: 0.1274840\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0960662\n",
      "\tspeed: 0.1316s/iter; left time: 2670.2964s\n",
      "\titers: 200, epoch: 10 | loss: 0.0947696\n",
      "\tspeed: 0.0641s/iter; left time: 1293.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.74s\n",
      "Steps: 224 | Train Loss: 0.0968994 Vali Loss: 0.1194730 Test Loss: 0.1282073\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0937361\n",
      "\tspeed: 0.1235s/iter; left time: 2477.4133s\n",
      "\titers: 200, epoch: 11 | loss: 0.0961174\n",
      "\tspeed: 0.0660s/iter; left time: 1317.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:14.87s\n",
      "Steps: 224 | Train Loss: 0.0961025 Vali Loss: 0.1201492 Test Loss: 0.1287695\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0976077\n",
      "\tspeed: 0.1246s/iter; left time: 2472.3915s\n",
      "\titers: 200, epoch: 12 | loss: 0.0968714\n",
      "\tspeed: 0.0650s/iter; left time: 1283.8619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0954843 Vali Loss: 0.1202374 Test Loss: 0.1301523\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0951096\n",
      "\tspeed: 0.1202s/iter; left time: 2357.2966s\n",
      "\titers: 200, epoch: 13 | loss: 0.0931655\n",
      "\tspeed: 0.0644s/iter; left time: 1257.0579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.64s\n",
      "Steps: 224 | Train Loss: 0.0946925 Vali Loss: 0.1202413 Test Loss: 0.1300704\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0932792\n",
      "\tspeed: 0.1225s/iter; left time: 2375.9017s\n",
      "\titers: 200, epoch: 14 | loss: 0.0952017\n",
      "\tspeed: 0.0679s/iter; left time: 1310.3449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.96s\n",
      "Steps: 224 | Train Loss: 0.0941036 Vali Loss: 0.1202730 Test Loss: 0.1306375\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0893586\n",
      "\tspeed: 0.1207s/iter; left time: 2312.8706s\n",
      "\titers: 200, epoch: 15 | loss: 0.0917358\n",
      "\tspeed: 0.0660s/iter; left time: 1259.0155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.64s\n",
      "Steps: 224 | Train Loss: 0.0935348 Vali Loss: 0.1209930 Test Loss: 0.1316901\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0920206\n",
      "\tspeed: 0.1269s/iter; left time: 2403.9661s\n",
      "\titers: 200, epoch: 16 | loss: 0.0893951\n",
      "\tspeed: 0.0637s/iter; left time: 1199.6952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:14.68s\n",
      "Steps: 224 | Train Loss: 0.0930603 Vali Loss: 0.1205535 Test Loss: 0.1314782\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03634786978363991, rmse:0.19065117835998535, mae:0.12678050994873047, rse:0.6751343607902527\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1646978\n",
      "\tspeed: 0.0641s/iter; left time: 1429.7703s\n",
      "\titers: 200, epoch: 1 | loss: 0.1596227\n",
      "\tspeed: 0.0669s/iter; left time: 1484.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.67s\n",
      "Steps: 224 | Train Loss: 0.1592930 Vali Loss: 0.1618121 Test Loss: 0.1739579\n",
      "Validation loss decreased (inf --> 0.161812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1183173\n",
      "\tspeed: 0.1220s/iter; left time: 2694.2424s\n",
      "\titers: 200, epoch: 2 | loss: 0.1138795\n",
      "\tspeed: 0.0630s/iter; left time: 1384.2941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:14.28s\n",
      "Steps: 224 | Train Loss: 0.1198862 Vali Loss: 0.1227517 Test Loss: 0.1297694\n",
      "Validation loss decreased (0.161812 --> 0.122752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1076060\n",
      "\tspeed: 0.1350s/iter; left time: 2950.2241s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004281\n",
      "\tspeed: 0.0644s/iter; left time: 1400.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.09s\n",
      "Steps: 224 | Train Loss: 0.1062988 Vali Loss: 0.1194519 Test Loss: 0.1273959\n",
      "Validation loss decreased (0.122752 --> 0.119452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068373\n",
      "\tspeed: 0.1353s/iter; left time: 2926.9106s\n",
      "\titers: 200, epoch: 4 | loss: 0.1038922\n",
      "\tspeed: 0.0623s/iter; left time: 1340.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.42s\n",
      "Steps: 224 | Train Loss: 0.1036002 Vali Loss: 0.1188033 Test Loss: 0.1266809\n",
      "Validation loss decreased (0.119452 --> 0.118803).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0981667\n",
      "\tspeed: 0.1393s/iter; left time: 2981.3798s\n",
      "\titers: 200, epoch: 5 | loss: 0.1001305\n",
      "\tspeed: 0.0680s/iter; left time: 1449.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.1017561 Vali Loss: 0.1185325 Test Loss: 0.1270410\n",
      "Validation loss decreased (0.118803 --> 0.118533).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1016373\n",
      "\tspeed: 0.1241s/iter; left time: 2629.1349s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977255\n",
      "\tspeed: 0.0680s/iter; left time: 1433.9526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.03s\n",
      "Steps: 224 | Train Loss: 0.1004691 Vali Loss: 0.1189096 Test Loss: 0.1266581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1057052\n",
      "\tspeed: 0.1249s/iter; left time: 2618.3944s\n",
      "\titers: 200, epoch: 7 | loss: 0.0980047\n",
      "\tspeed: 0.0654s/iter; left time: 1363.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.97s\n",
      "Steps: 224 | Train Loss: 0.0994334 Vali Loss: 0.1192198 Test Loss: 0.1271698\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0998428\n",
      "\tspeed: 0.1361s/iter; left time: 2821.4241s\n",
      "\titers: 200, epoch: 8 | loss: 0.0941586\n",
      "\tspeed: 0.0649s/iter; left time: 1340.0215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.81s\n",
      "Steps: 224 | Train Loss: 0.0984135 Vali Loss: 0.1194942 Test Loss: 0.1277537\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0962894\n",
      "\tspeed: 0.1307s/iter; left time: 2681.0142s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965957\n",
      "\tspeed: 0.0647s/iter; left time: 1320.1520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:14.86s\n",
      "Steps: 224 | Train Loss: 0.0975901 Vali Loss: 0.1195832 Test Loss: 0.1275134\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0941738\n",
      "\tspeed: 0.1230s/iter; left time: 2494.2907s\n",
      "\titers: 200, epoch: 10 | loss: 0.0928220\n",
      "\tspeed: 0.0694s/iter; left time: 1400.8307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.76s\n",
      "Steps: 224 | Train Loss: 0.0966882 Vali Loss: 0.1200024 Test Loss: 0.1288202\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0951017\n",
      "\tspeed: 0.1243s/iter; left time: 2494.4116s\n",
      "\titers: 200, epoch: 11 | loss: 0.0957812\n",
      "\tspeed: 0.0683s/iter; left time: 1363.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.00s\n",
      "Steps: 224 | Train Loss: 0.0959330 Vali Loss: 0.1206276 Test Loss: 0.1287879\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0955243\n",
      "\tspeed: 0.1281s/iter; left time: 2541.7955s\n",
      "\titers: 200, epoch: 12 | loss: 0.0936859\n",
      "\tspeed: 0.0704s/iter; left time: 1388.9048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 224 | Train Loss: 0.0952509 Vali Loss: 0.1204279 Test Loss: 0.1292543\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0911372\n",
      "\tspeed: 0.1371s/iter; left time: 2689.2185s\n",
      "\titers: 200, epoch: 13 | loss: 0.0944463\n",
      "\tspeed: 0.0635s/iter; left time: 1239.7751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.16s\n",
      "Steps: 224 | Train Loss: 0.0944741 Vali Loss: 0.1204605 Test Loss: 0.1296869\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0935038\n",
      "\tspeed: 0.1386s/iter; left time: 2686.6480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0967305\n",
      "\tspeed: 0.0632s/iter; left time: 1219.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.48s\n",
      "Steps: 224 | Train Loss: 0.0937822 Vali Loss: 0.1207107 Test Loss: 0.1295574\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0885421\n",
      "\tspeed: 0.1439s/iter; left time: 2757.4592s\n",
      "\titers: 200, epoch: 15 | loss: 0.0946899\n",
      "\tspeed: 0.0682s/iter; left time: 1299.5462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0932084 Vali Loss: 0.1205535 Test Loss: 0.1298851\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03631800040602684, rmse:0.1905728280544281, mae:0.12704099714756012, rse:0.6748569011688232\n",
      "Intermediate time for DE and pred_len 96: 00h:10m:19.48s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1548019\n",
      "\tspeed: 0.0885s/iter; left time: 1963.7239s\n",
      "\titers: 200, epoch: 1 | loss: 0.1487349\n",
      "\tspeed: 0.0546s/iter; left time: 1207.4693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.37s\n",
      "Steps: 223 | Train Loss: 0.1608134 Vali Loss: 0.1642606 Test Loss: 0.1773646\n",
      "Validation loss decreased (inf --> 0.164261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1214235\n",
      "\tspeed: 0.1039s/iter; left time: 2282.5374s\n",
      "\titers: 200, epoch: 2 | loss: 0.1186251\n",
      "\tspeed: 0.0604s/iter; left time: 1322.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.63s\n",
      "Steps: 223 | Train Loss: 0.1239817 Vali Loss: 0.1269845 Test Loss: 0.1359027\n",
      "Validation loss decreased (0.164261 --> 0.126984).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1170573\n",
      "\tspeed: 0.1096s/iter; left time: 2385.0655s\n",
      "\titers: 200, epoch: 3 | loss: 0.1074152\n",
      "\tspeed: 0.0581s/iter; left time: 1258.5519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.30s\n",
      "Steps: 223 | Train Loss: 0.1123392 Vali Loss: 0.1241037 Test Loss: 0.1344680\n",
      "Validation loss decreased (0.126984 --> 0.124104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1116649\n",
      "\tspeed: 0.1077s/iter; left time: 2319.0279s\n",
      "\titers: 200, epoch: 4 | loss: 0.1098954\n",
      "\tspeed: 0.0614s/iter; left time: 1315.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.55s\n",
      "Steps: 223 | Train Loss: 0.1095220 Vali Loss: 0.1238564 Test Loss: 0.1336398\n",
      "Validation loss decreased (0.124104 --> 0.123856).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1103088\n",
      "\tspeed: 0.1084s/iter; left time: 2309.2080s\n",
      "\titers: 200, epoch: 5 | loss: 0.1059337\n",
      "\tspeed: 0.0601s/iter; left time: 1275.6416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:13.62s\n",
      "Steps: 223 | Train Loss: 0.1077120 Vali Loss: 0.1238542 Test Loss: 0.1340634\n",
      "Validation loss decreased (0.123856 --> 0.123854).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1093670\n",
      "\tspeed: 0.1155s/iter; left time: 2434.6916s\n",
      "\titers: 200, epoch: 6 | loss: 0.1044136\n",
      "\tspeed: 0.0619s/iter; left time: 1299.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.85s\n",
      "Steps: 223 | Train Loss: 0.1062742 Vali Loss: 0.1234706 Test Loss: 0.1347027\n",
      "Validation loss decreased (0.123854 --> 0.123471).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1005224\n",
      "\tspeed: 0.1090s/iter; left time: 2273.5851s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047263\n",
      "\tspeed: 0.0571s/iter; left time: 1185.8803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.92s\n",
      "Steps: 223 | Train Loss: 0.1051898 Vali Loss: 0.1239938 Test Loss: 0.1345310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1043732\n",
      "\tspeed: 0.1013s/iter; left time: 2091.7110s\n",
      "\titers: 200, epoch: 8 | loss: 0.1046246\n",
      "\tspeed: 0.0549s/iter; left time: 1128.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 223 | Train Loss: 0.1041525 Vali Loss: 0.1243894 Test Loss: 0.1351599\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1036047\n",
      "\tspeed: 0.0972s/iter; left time: 1984.3051s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000770\n",
      "\tspeed: 0.0535s/iter; left time: 1086.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.21s\n",
      "Steps: 223 | Train Loss: 0.1031845 Vali Loss: 0.1245980 Test Loss: 0.1351988\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0945465\n",
      "\tspeed: 0.0962s/iter; left time: 1942.2344s\n",
      "\titers: 200, epoch: 10 | loss: 0.1016872\n",
      "\tspeed: 0.0555s/iter; left time: 1115.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.38s\n",
      "Steps: 223 | Train Loss: 0.1024096 Vali Loss: 0.1248682 Test Loss: 0.1363112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1013406\n",
      "\tspeed: 0.0979s/iter; left time: 1955.9067s\n",
      "\titers: 200, epoch: 11 | loss: 0.1035435\n",
      "\tspeed: 0.0537s/iter; left time: 1067.5552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.20s\n",
      "Steps: 223 | Train Loss: 0.1016130 Vali Loss: 0.1255188 Test Loss: 0.1362312\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0993369\n",
      "\tspeed: 0.0959s/iter; left time: 1894.2588s\n",
      "\titers: 200, epoch: 12 | loss: 0.1056814\n",
      "\tspeed: 0.0535s/iter; left time: 1051.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.14s\n",
      "Steps: 223 | Train Loss: 0.1009609 Vali Loss: 0.1256741 Test Loss: 0.1363840\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1032659\n",
      "\tspeed: 0.0964s/iter; left time: 1881.4402s\n",
      "\titers: 200, epoch: 13 | loss: 0.0941548\n",
      "\tspeed: 0.0533s/iter; left time: 1035.6132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 223 | Train Loss: 0.1002403 Vali Loss: 0.1265315 Test Loss: 0.1380129\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0971907\n",
      "\tspeed: 0.0953s/iter; left time: 1840.0929s\n",
      "\titers: 200, epoch: 14 | loss: 0.1011847\n",
      "\tspeed: 0.0533s/iter; left time: 1023.1713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 223 | Train Loss: 0.0995397 Vali Loss: 0.1270013 Test Loss: 0.1374407\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0925344\n",
      "\tspeed: 0.0943s/iter; left time: 1798.3851s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943704\n",
      "\tspeed: 0.0532s/iter; left time: 1009.4163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 223 | Train Loss: 0.0989645 Vali Loss: 0.1275917 Test Loss: 0.1384556\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0975892\n",
      "\tspeed: 0.0950s/iter; left time: 1792.1456s\n",
      "\titers: 200, epoch: 16 | loss: 0.0999596\n",
      "\tspeed: 0.0532s/iter; left time: 997.6198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.11s\n",
      "Steps: 223 | Train Loss: 0.0984323 Vali Loss: 0.1276390 Test Loss: 0.1387271\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03956723213195801, rmse:0.19891513884067535, mae:0.13470256328582764, rse:0.7045734524726868\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1586475\n",
      "\tspeed: 0.0549s/iter; left time: 1218.9030s\n",
      "\titers: 200, epoch: 1 | loss: 0.1522224\n",
      "\tspeed: 0.0532s/iter; left time: 1176.7078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.1616155 Vali Loss: 0.1641567 Test Loss: 0.1773076\n",
      "Validation loss decreased (inf --> 0.164157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1187496\n",
      "\tspeed: 0.1064s/iter; left time: 2338.9623s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157281\n",
      "\tspeed: 0.0533s/iter; left time: 1166.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 223 | Train Loss: 0.1241101 Vali Loss: 0.1277330 Test Loss: 0.1362454\n",
      "Validation loss decreased (0.164157 --> 0.127733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1088427\n",
      "\tspeed: 0.0992s/iter; left time: 2158.0220s\n",
      "\titers: 200, epoch: 3 | loss: 0.1101429\n",
      "\tspeed: 0.0533s/iter; left time: 1154.7108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 223 | Train Loss: 0.1123035 Vali Loss: 0.1245199 Test Loss: 0.1350362\n",
      "Validation loss decreased (0.127733 --> 0.124520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1039694\n",
      "\tspeed: 0.0974s/iter; left time: 2097.0559s\n",
      "\titers: 200, epoch: 4 | loss: 0.1144476\n",
      "\tspeed: 0.0532s/iter; left time: 1140.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 223 | Train Loss: 0.1094969 Vali Loss: 0.1235680 Test Loss: 0.1340981\n",
      "Validation loss decreased (0.124520 --> 0.123568).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1059165\n",
      "\tspeed: 0.0975s/iter; left time: 2077.6615s\n",
      "\titers: 200, epoch: 5 | loss: 0.1059672\n",
      "\tspeed: 0.0532s/iter; left time: 1129.3562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.12s\n",
      "Steps: 223 | Train Loss: 0.1077130 Vali Loss: 0.1228737 Test Loss: 0.1347752\n",
      "Validation loss decreased (0.123568 --> 0.122874).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1075763\n",
      "\tspeed: 0.0986s/iter; left time: 2078.2449s\n",
      "\titers: 200, epoch: 6 | loss: 0.1046234\n",
      "\tspeed: 0.0533s/iter; left time: 1118.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.1062918 Vali Loss: 0.1232371 Test Loss: 0.1351631\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1086531\n",
      "\tspeed: 0.0960s/iter; left time: 2003.7094s\n",
      "\titers: 200, epoch: 7 | loss: 0.1062272\n",
      "\tspeed: 0.0532s/iter; left time: 1104.1128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 223 | Train Loss: 0.1050808 Vali Loss: 0.1232536 Test Loss: 0.1345480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1097154\n",
      "\tspeed: 0.0969s/iter; left time: 2000.8928s\n",
      "\titers: 200, epoch: 8 | loss: 0.1039724\n",
      "\tspeed: 0.0532s/iter; left time: 1091.9763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 223 | Train Loss: 0.1040496 Vali Loss: 0.1236265 Test Loss: 0.1358001\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1069149\n",
      "\tspeed: 0.0966s/iter; left time: 1971.3761s\n",
      "\titers: 200, epoch: 9 | loss: 0.1070597\n",
      "\tspeed: 0.0533s/iter; left time: 1083.0819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.12s\n",
      "Steps: 223 | Train Loss: 0.1030779 Vali Loss: 0.1237163 Test Loss: 0.1358926\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1037227\n",
      "\tspeed: 0.0962s/iter; left time: 1942.7337s\n",
      "\titers: 200, epoch: 10 | loss: 0.1070804\n",
      "\tspeed: 0.0532s/iter; left time: 1068.8481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.1020539 Vali Loss: 0.1243779 Test Loss: 0.1360747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994673\n",
      "\tspeed: 0.0966s/iter; left time: 1929.8477s\n",
      "\titers: 200, epoch: 11 | loss: 0.0967816\n",
      "\tspeed: 0.0531s/iter; left time: 1055.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.10s\n",
      "Steps: 223 | Train Loss: 0.1011504 Vali Loss: 0.1246540 Test Loss: 0.1372310\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1035772\n",
      "\tspeed: 0.0970s/iter; left time: 1916.4164s\n",
      "\titers: 200, epoch: 12 | loss: 0.1003781\n",
      "\tspeed: 0.0530s/iter; left time: 1041.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.1002424 Vali Loss: 0.1252042 Test Loss: 0.1371934\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1011443\n",
      "\tspeed: 0.0960s/iter; left time: 1874.5248s\n",
      "\titers: 200, epoch: 13 | loss: 0.0993868\n",
      "\tspeed: 0.0531s/iter; left time: 1032.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.11s\n",
      "Steps: 223 | Train Loss: 0.0994014 Vali Loss: 0.1259811 Test Loss: 0.1378808\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0967515\n",
      "\tspeed: 0.0956s/iter; left time: 1845.2392s\n",
      "\titers: 200, epoch: 14 | loss: 0.0992444\n",
      "\tspeed: 0.0530s/iter; left time: 1018.3774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 223 | Train Loss: 0.0987232 Vali Loss: 0.1261198 Test Loss: 0.1377028\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0974795\n",
      "\tspeed: 0.0957s/iter; left time: 1824.9962s\n",
      "\titers: 200, epoch: 15 | loss: 0.0960967\n",
      "\tspeed: 0.0532s/iter; left time: 1009.6834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 223 | Train Loss: 0.0980965 Vali Loss: 0.1264970 Test Loss: 0.1387069\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039511777460575104, rmse:0.19877569377422333, mae:0.13477523624897003, rse:0.7040795087814331\n",
      "Intermediate time for DE and pred_len 168: 00h:08m:14.84s\n",
      "Intermediate time for DE: 00h:47m:24.17s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1337681\n",
      "\tspeed: 0.0772s/iter; left time: 1721.4568s\n",
      "\titers: 200, epoch: 1 | loss: 0.1301103\n",
      "\tspeed: 0.0521s/iter; left time: 1155.9863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.21s\n",
      "Steps: 224 | Train Loss: 0.1369913 Vali Loss: 0.1359314 Test Loss: 0.1558871\n",
      "Validation loss decreased (inf --> 0.135931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0913649\n",
      "\tspeed: 0.0945s/iter; left time: 2087.3596s\n",
      "\titers: 200, epoch: 2 | loss: 0.0844155\n",
      "\tspeed: 0.0524s/iter; left time: 1150.6662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0923259 Vali Loss: 0.0929204 Test Loss: 0.1050857\n",
      "Validation loss decreased (0.135931 --> 0.092920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0808693\n",
      "\tspeed: 0.0952s/iter; left time: 2080.9624s\n",
      "\titers: 200, epoch: 3 | loss: 0.0861732\n",
      "\tspeed: 0.0523s/iter; left time: 1136.8411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0791791 Vali Loss: 0.0913382 Test Loss: 0.1042468\n",
      "Validation loss decreased (0.092920 --> 0.091338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0733298\n",
      "\tspeed: 0.0966s/iter; left time: 2089.7803s\n",
      "\titers: 200, epoch: 4 | loss: 0.0772558\n",
      "\tspeed: 0.0524s/iter; left time: 1128.5724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0773386 Vali Loss: 0.0909781 Test Loss: 0.1037574\n",
      "Validation loss decreased (0.091338 --> 0.090978).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0725079\n",
      "\tspeed: 0.0944s/iter; left time: 2021.6394s\n",
      "\titers: 200, epoch: 5 | loss: 0.0707540\n",
      "\tspeed: 0.0523s/iter; left time: 1113.9711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0761784 Vali Loss: 0.0895637 Test Loss: 0.1028150\n",
      "Validation loss decreased (0.090978 --> 0.089564).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770092\n",
      "\tspeed: 0.0953s/iter; left time: 2018.1352s\n",
      "\titers: 200, epoch: 6 | loss: 0.0714131\n",
      "\tspeed: 0.0524s/iter; left time: 1105.5169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0753703 Vali Loss: 0.0893661 Test Loss: 0.1025691\n",
      "Validation loss decreased (0.089564 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0798632\n",
      "\tspeed: 0.0984s/iter; left time: 2061.6240s\n",
      "\titers: 200, epoch: 7 | loss: 0.0708998\n",
      "\tspeed: 0.0522s/iter; left time: 1089.3604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0748158 Vali Loss: 0.0894289 Test Loss: 0.1025083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749726\n",
      "\tspeed: 0.0936s/iter; left time: 1940.1901s\n",
      "\titers: 200, epoch: 8 | loss: 0.0733200\n",
      "\tspeed: 0.0523s/iter; left time: 1078.8051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0743430 Vali Loss: 0.0890287 Test Loss: 0.1023971\n",
      "Validation loss decreased (0.089366 --> 0.089029).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0791299\n",
      "\tspeed: 0.0941s/iter; left time: 1930.5205s\n",
      "\titers: 200, epoch: 9 | loss: 0.0748995\n",
      "\tspeed: 0.0523s/iter; left time: 1067.4508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0738968 Vali Loss: 0.0888048 Test Loss: 0.1026755\n",
      "Validation loss decreased (0.089029 --> 0.088805).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0725861\n",
      "\tspeed: 0.0945s/iter; left time: 1916.4283s\n",
      "\titers: 200, epoch: 10 | loss: 0.0756589\n",
      "\tspeed: 0.0524s/iter; left time: 1056.8750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0735116 Vali Loss: 0.0885439 Test Loss: 0.1022316\n",
      "Validation loss decreased (0.088805 --> 0.088544).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702687\n",
      "\tspeed: 0.0943s/iter; left time: 1890.8247s\n",
      "\titers: 200, epoch: 11 | loss: 0.0753673\n",
      "\tspeed: 0.0525s/iter; left time: 1048.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.95s\n",
      "Steps: 224 | Train Loss: 0.0731713 Vali Loss: 0.0884424 Test Loss: 0.1024115\n",
      "Validation loss decreased (0.088544 --> 0.088442).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0696664\n",
      "\tspeed: 0.0934s/iter; left time: 1853.0548s\n",
      "\titers: 200, epoch: 12 | loss: 0.0712836\n",
      "\tspeed: 0.0525s/iter; left time: 1035.3221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0729458 Vali Loss: 0.0885137 Test Loss: 0.1023535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0772517\n",
      "\tspeed: 0.0933s/iter; left time: 1830.2605s\n",
      "\titers: 200, epoch: 13 | loss: 0.0727321\n",
      "\tspeed: 0.0523s/iter; left time: 1020.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0727253 Vali Loss: 0.0882543 Test Loss: 0.1018357\n",
      "Validation loss decreased (0.088442 --> 0.088254).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0730511\n",
      "\tspeed: 0.0940s/iter; left time: 1822.8780s\n",
      "\titers: 200, epoch: 14 | loss: 0.0743207\n",
      "\tspeed: 0.0521s/iter; left time: 1005.4792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0724939 Vali Loss: 0.0883527 Test Loss: 0.1019900\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0745256\n",
      "\tspeed: 0.0933s/iter; left time: 1787.9579s\n",
      "\titers: 200, epoch: 15 | loss: 0.0704399\n",
      "\tspeed: 0.0523s/iter; left time: 997.3905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0722996 Vali Loss: 0.0880289 Test Loss: 0.1020303\n",
      "Validation loss decreased (0.088254 --> 0.088029).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0770125\n",
      "\tspeed: 0.0940s/iter; left time: 1780.8996s\n",
      "\titers: 200, epoch: 16 | loss: 0.0694815\n",
      "\tspeed: 0.0521s/iter; left time: 982.0702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0721522 Vali Loss: 0.0880209 Test Loss: 0.1023730\n",
      "Validation loss decreased (0.088029 --> 0.088021).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0658797\n",
      "\tspeed: 0.0931s/iter; left time: 1742.2440s\n",
      "\titers: 200, epoch: 17 | loss: 0.0695038\n",
      "\tspeed: 0.0523s/iter; left time: 973.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0719564 Vali Loss: 0.0880820 Test Loss: 0.1024347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0731994\n",
      "\tspeed: 0.0932s/iter; left time: 1723.4834s\n",
      "\titers: 200, epoch: 18 | loss: 0.0695477\n",
      "\tspeed: 0.0524s/iter; left time: 963.7179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0718094 Vali Loss: 0.0881291 Test Loss: 0.1022878\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0677946\n",
      "\tspeed: 0.0927s/iter; left time: 1693.1766s\n",
      "\titers: 200, epoch: 19 | loss: 0.0691350\n",
      "\tspeed: 0.0523s/iter; left time: 950.6167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0717229 Vali Loss: 0.0878378 Test Loss: 0.1025048\n",
      "Validation loss decreased (0.088021 --> 0.087838).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0751754\n",
      "\tspeed: 0.0938s/iter; left time: 1692.2204s\n",
      "\titers: 200, epoch: 20 | loss: 0.0717342\n",
      "\tspeed: 0.0525s/iter; left time: 942.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0715432 Vali Loss: 0.0879541 Test Loss: 0.1023896\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683073\n",
      "\tspeed: 0.0922s/iter; left time: 1643.4609s\n",
      "\titers: 200, epoch: 21 | loss: 0.0753092\n",
      "\tspeed: 0.0525s/iter; left time: 929.9080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0714210 Vali Loss: 0.0878884 Test Loss: 0.1025704\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0739669\n",
      "\tspeed: 0.0934s/iter; left time: 1642.8751s\n",
      "\titers: 200, epoch: 22 | loss: 0.0735120\n",
      "\tspeed: 0.0524s/iter; left time: 917.1106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0713990 Vali Loss: 0.0879366 Test Loss: 0.1023931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0725404\n",
      "\tspeed: 0.0928s/iter; left time: 1611.5688s\n",
      "\titers: 200, epoch: 23 | loss: 0.0742865\n",
      "\tspeed: 0.0523s/iter; left time: 903.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0712040 Vali Loss: 0.0877694 Test Loss: 0.1021546\n",
      "Validation loss decreased (0.087838 --> 0.087769).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0733356\n",
      "\tspeed: 0.0931s/iter; left time: 1596.4130s\n",
      "\titers: 200, epoch: 24 | loss: 0.0658376\n",
      "\tspeed: 0.0522s/iter; left time: 890.6319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0712310 Vali Loss: 0.0878737 Test Loss: 0.1022747\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0756377\n",
      "\tspeed: 0.0932s/iter; left time: 1578.1782s\n",
      "\titers: 200, epoch: 25 | loss: 0.0714636\n",
      "\tspeed: 0.0524s/iter; left time: 880.9829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0711283 Vali Loss: 0.0876985 Test Loss: 0.1023861\n",
      "Validation loss decreased (0.087769 --> 0.087698).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0730481\n",
      "\tspeed: 0.0943s/iter; left time: 1575.0464s\n",
      "\titers: 200, epoch: 26 | loss: 0.0673774\n",
      "\tspeed: 0.0525s/iter; left time: 870.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0710204 Vali Loss: 0.0878645 Test Loss: 0.1025371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0692971\n",
      "\tspeed: 0.0931s/iter; left time: 1533.2364s\n",
      "\titers: 200, epoch: 27 | loss: 0.0748941\n",
      "\tspeed: 0.0523s/iter; left time: 855.8746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0709922 Vali Loss: 0.0878092 Test Loss: 0.1024434\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0731720\n",
      "\tspeed: 0.0933s/iter; left time: 1515.9991s\n",
      "\titers: 200, epoch: 28 | loss: 0.0709607\n",
      "\tspeed: 0.0523s/iter; left time: 845.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0709522 Vali Loss: 0.0876303 Test Loss: 0.1024348\n",
      "Validation loss decreased (0.087698 --> 0.087630).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0729126\n",
      "\tspeed: 0.0942s/iter; left time: 1509.2603s\n",
      "\titers: 200, epoch: 29 | loss: 0.0757939\n",
      "\tspeed: 0.0523s/iter; left time: 832.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0709114 Vali Loss: 0.0877213 Test Loss: 0.1024486\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0686514\n",
      "\tspeed: 0.0939s/iter; left time: 1484.8003s\n",
      "\titers: 200, epoch: 30 | loss: 0.0682729\n",
      "\tspeed: 0.0525s/iter; left time: 823.7680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:11.95s\n",
      "Steps: 224 | Train Loss: 0.0708208 Vali Loss: 0.0877651 Test Loss: 0.1023511\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0680746\n",
      "\tspeed: 0.0933s/iter; left time: 1454.2431s\n",
      "\titers: 200, epoch: 31 | loss: 0.0703695\n",
      "\tspeed: 0.0524s/iter; left time: 810.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0707644 Vali Loss: 0.0875608 Test Loss: 0.1024484\n",
      "Validation loss decreased (0.087630 --> 0.087561).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0712823\n",
      "\tspeed: 0.0939s/iter; left time: 1441.3324s\n",
      "\titers: 200, epoch: 32 | loss: 0.0645696\n",
      "\tspeed: 0.0523s/iter; left time: 797.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0707321 Vali Loss: 0.0877208 Test Loss: 0.1026194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0686052\n",
      "\tspeed: 0.0934s/iter; left time: 1413.3648s\n",
      "\titers: 200, epoch: 33 | loss: 0.0751981\n",
      "\tspeed: 0.0524s/iter; left time: 788.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0707160 Vali Loss: 0.0876859 Test Loss: 0.1025198\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0700265\n",
      "\tspeed: 0.0931s/iter; left time: 1388.3844s\n",
      "\titers: 200, epoch: 34 | loss: 0.0709091\n",
      "\tspeed: 0.0522s/iter; left time: 773.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0706691 Vali Loss: 0.0876336 Test Loss: 0.1025292\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0714695\n",
      "\tspeed: 0.0929s/iter; left time: 1364.3497s\n",
      "\titers: 200, epoch: 35 | loss: 0.0675804\n",
      "\tspeed: 0.0523s/iter; left time: 762.1868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0706608 Vali Loss: 0.0876634 Test Loss: 0.1025143\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0716697\n",
      "\tspeed: 0.0931s/iter; left time: 1346.7562s\n",
      "\titers: 200, epoch: 36 | loss: 0.0745230\n",
      "\tspeed: 0.0524s/iter; left time: 752.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0706338 Vali Loss: 0.0876844 Test Loss: 0.1025104\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0692014\n",
      "\tspeed: 0.0938s/iter; left time: 1335.3094s\n",
      "\titers: 200, epoch: 37 | loss: 0.0667195\n",
      "\tspeed: 0.0523s/iter; left time: 739.4948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0706335 Vali Loss: 0.0875388 Test Loss: 0.1025336\n",
      "Validation loss decreased (0.087561 --> 0.087539).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0696882\n",
      "\tspeed: 0.0945s/iter; left time: 1324.8033s\n",
      "\titers: 200, epoch: 38 | loss: 0.0767173\n",
      "\tspeed: 0.0520s/iter; left time: 722.7913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0705597 Vali Loss: 0.0876549 Test Loss: 0.1025695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0688473\n",
      "\tspeed: 0.0937s/iter; left time: 1292.6102s\n",
      "\titers: 200, epoch: 39 | loss: 0.0736877\n",
      "\tspeed: 0.0525s/iter; left time: 718.7778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:11.98s\n",
      "Steps: 224 | Train Loss: 0.0705348 Vali Loss: 0.0877679 Test Loss: 0.1025379\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0706787\n",
      "\tspeed: 0.0929s/iter; left time: 1260.7052s\n",
      "\titers: 200, epoch: 40 | loss: 0.0669279\n",
      "\tspeed: 0.0523s/iter; left time: 703.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0705901 Vali Loss: 0.0876181 Test Loss: 0.1025662\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0689001\n",
      "\tspeed: 0.0939s/iter; left time: 1252.2301s\n",
      "\titers: 200, epoch: 41 | loss: 0.0677012\n",
      "\tspeed: 0.0523s/iter; left time: 692.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.95s\n",
      "Steps: 224 | Train Loss: 0.0705525 Vali Loss: 0.0876695 Test Loss: 0.1025416\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0700784\n",
      "\tspeed: 0.0929s/iter; left time: 1218.8393s\n",
      "\titers: 200, epoch: 42 | loss: 0.0700355\n",
      "\tspeed: 0.0520s/iter; left time: 677.4660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0705240 Vali Loss: 0.0876143 Test Loss: 0.1026173\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0726577\n",
      "\tspeed: 0.0930s/iter; left time: 1198.8184s\n",
      "\titers: 200, epoch: 43 | loss: 0.0706721\n",
      "\tspeed: 0.0522s/iter; left time: 668.3542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0705564 Vali Loss: 0.0876295 Test Loss: 0.1025662\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0696796\n",
      "\tspeed: 0.0926s/iter; left time: 1173.7211s\n",
      "\titers: 200, epoch: 44 | loss: 0.0707281\n",
      "\tspeed: 0.0522s/iter; left time: 656.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0704933 Vali Loss: 0.0876881 Test Loss: 0.1025814\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0757044\n",
      "\tspeed: 0.0932s/iter; left time: 1160.3548s\n",
      "\titers: 200, epoch: 45 | loss: 0.0726157\n",
      "\tspeed: 0.0523s/iter; left time: 645.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:11.95s\n",
      "Steps: 224 | Train Loss: 0.0705575 Vali Loss: 0.0874810 Test Loss: 0.1025429\n",
      "Validation loss decreased (0.087539 --> 0.087481).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0742189\n",
      "\tspeed: 0.0941s/iter; left time: 1149.8477s\n",
      "\titers: 200, epoch: 46 | loss: 0.0736142\n",
      "\tspeed: 0.0523s/iter; left time: 633.9717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0705232 Vali Loss: 0.0875848 Test Loss: 0.1025821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0672498\n",
      "\tspeed: 0.0926s/iter; left time: 1110.7055s\n",
      "\titers: 200, epoch: 47 | loss: 0.0682913\n",
      "\tspeed: 0.0522s/iter; left time: 621.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0704723 Vali Loss: 0.0876123 Test Loss: 0.1025846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0696902\n",
      "\tspeed: 0.0927s/iter; left time: 1091.8042s\n",
      "\titers: 200, epoch: 48 | loss: 0.0676515\n",
      "\tspeed: 0.0522s/iter; left time: 608.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0705277 Vali Loss: 0.0876810 Test Loss: 0.1025829\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0700386\n",
      "\tspeed: 0.0924s/iter; left time: 1067.2475s\n",
      "\titers: 200, epoch: 49 | loss: 0.0666300\n",
      "\tspeed: 0.0523s/iter; left time: 598.6801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0704845 Vali Loss: 0.0876203 Test Loss: 0.1025853\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0734844\n",
      "\tspeed: 0.0924s/iter; left time: 1046.8790s\n",
      "\titers: 200, epoch: 50 | loss: 0.0679541\n",
      "\tspeed: 0.0522s/iter; left time: 585.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0704916 Vali Loss: 0.0877179 Test Loss: 0.1025884\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0736447\n",
      "\tspeed: 0.0937s/iter; left time: 1039.9746s\n",
      "\titers: 200, epoch: 51 | loss: 0.0654428\n",
      "\tspeed: 0.0522s/iter; left time: 574.6351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:11.95s\n",
      "Steps: 224 | Train Loss: 0.0705029 Vali Loss: 0.0875974 Test Loss: 0.1025916\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0700766\n",
      "\tspeed: 0.0926s/iter; left time: 1007.6814s\n",
      "\titers: 200, epoch: 52 | loss: 0.0760974\n",
      "\tspeed: 0.0522s/iter; left time: 562.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0704561 Vali Loss: 0.0875556 Test Loss: 0.1025784\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0712552\n",
      "\tspeed: 0.0926s/iter; left time: 985.9431s\n",
      "\titers: 200, epoch: 53 | loss: 0.0681484\n",
      "\tspeed: 0.0523s/iter; left time: 551.6700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0704864 Vali Loss: 0.0875903 Test Loss: 0.1026226\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0698976\n",
      "\tspeed: 0.0922s/iter; left time: 961.8901s\n",
      "\titers: 200, epoch: 54 | loss: 0.0694280\n",
      "\tspeed: 0.0522s/iter; left time: 539.0669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0705067 Vali Loss: 0.0876638 Test Loss: 0.1025732\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0714906\n",
      "\tspeed: 0.0925s/iter; left time: 944.1057s\n",
      "\titers: 200, epoch: 55 | loss: 0.0664937\n",
      "\tspeed: 0.0523s/iter; left time: 528.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0704601 Vali Loss: 0.0876570 Test Loss: 0.1026139\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026038529351353645, rmse:0.1613645851612091, mae:0.10254285484552383, rse:0.5566620826721191\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1340888\n",
      "\tspeed: 0.0543s/iter; left time: 1209.8383s\n",
      "\titers: 200, epoch: 1 | loss: 0.1284338\n",
      "\tspeed: 0.0525s/iter; left time: 1165.6667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.99s\n",
      "Steps: 224 | Train Loss: 0.1371192 Vali Loss: 0.1359184 Test Loss: 0.1564447\n",
      "Validation loss decreased (inf --> 0.135918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986784\n",
      "\tspeed: 0.0945s/iter; left time: 2086.9999s\n",
      "\titers: 200, epoch: 2 | loss: 0.0827210\n",
      "\tspeed: 0.0526s/iter; left time: 1156.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0929912 Vali Loss: 0.0933088 Test Loss: 0.1047612\n",
      "Validation loss decreased (0.135918 --> 0.093309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803287\n",
      "\tspeed: 0.0945s/iter; left time: 2064.1116s\n",
      "\titers: 200, epoch: 3 | loss: 0.0777847\n",
      "\tspeed: 0.0524s/iter; left time: 1139.5728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.98s\n",
      "Steps: 224 | Train Loss: 0.0793267 Vali Loss: 0.0914609 Test Loss: 0.1030556\n",
      "Validation loss decreased (0.093309 --> 0.091461).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0806357\n",
      "\tspeed: 0.0942s/iter; left time: 2037.6861s\n",
      "\titers: 200, epoch: 4 | loss: 0.0757164\n",
      "\tspeed: 0.0523s/iter; left time: 1126.1738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0774351 Vali Loss: 0.0906578 Test Loss: 0.1030808\n",
      "Validation loss decreased (0.091461 --> 0.090658).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0742374\n",
      "\tspeed: 0.0943s/iter; left time: 2018.3902s\n",
      "\titers: 200, epoch: 5 | loss: 0.0708531\n",
      "\tspeed: 0.0523s/iter; left time: 1115.0898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.95s\n",
      "Steps: 224 | Train Loss: 0.0764426 Vali Loss: 0.0899601 Test Loss: 0.1026692\n",
      "Validation loss decreased (0.090658 --> 0.089960).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0776469\n",
      "\tspeed: 0.0947s/iter; left time: 2006.8819s\n",
      "\titers: 200, epoch: 6 | loss: 0.0802776\n",
      "\tspeed: 0.0526s/iter; left time: 1109.2554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0755150 Vali Loss: 0.0892671 Test Loss: 0.1024971\n",
      "Validation loss decreased (0.089960 --> 0.089267).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0744159\n",
      "\tspeed: 0.0942s/iter; left time: 1973.8478s\n",
      "\titers: 200, epoch: 7 | loss: 0.0703802\n",
      "\tspeed: 0.0525s/iter; left time: 1094.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0749787 Vali Loss: 0.0892036 Test Loss: 0.1022584\n",
      "Validation loss decreased (0.089267 --> 0.089204).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0728884\n",
      "\tspeed: 0.0941s/iter; left time: 1951.0242s\n",
      "\titers: 200, epoch: 8 | loss: 0.0763242\n",
      "\tspeed: 0.0524s/iter; left time: 1080.9020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0744411 Vali Loss: 0.0888207 Test Loss: 0.1025281\n",
      "Validation loss decreased (0.089204 --> 0.088821).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749100\n",
      "\tspeed: 0.0940s/iter; left time: 1928.1962s\n",
      "\titers: 200, epoch: 9 | loss: 0.0729593\n",
      "\tspeed: 0.0524s/iter; left time: 1069.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0740723 Vali Loss: 0.0889069 Test Loss: 0.1022433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0736462\n",
      "\tspeed: 0.0939s/iter; left time: 1904.0869s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683928\n",
      "\tspeed: 0.0525s/iter; left time: 1060.2319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.00s\n",
      "Steps: 224 | Train Loss: 0.0736698 Vali Loss: 0.0882708 Test Loss: 0.1022037\n",
      "Validation loss decreased (0.088821 --> 0.088271).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685093\n",
      "\tspeed: 0.0941s/iter; left time: 1887.1174s\n",
      "\titers: 200, epoch: 11 | loss: 0.0748501\n",
      "\tspeed: 0.0521s/iter; left time: 1039.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0733367 Vali Loss: 0.0885927 Test Loss: 0.1025729\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0694412\n",
      "\tspeed: 0.0941s/iter; left time: 1866.7245s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729200\n",
      "\tspeed: 0.0525s/iter; left time: 1035.2776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0730160 Vali Loss: 0.0883027 Test Loss: 0.1023279\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722981\n",
      "\tspeed: 0.0943s/iter; left time: 1849.0667s\n",
      "\titers: 200, epoch: 13 | loss: 0.0708375\n",
      "\tspeed: 0.0525s/iter; left time: 1023.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0727724 Vali Loss: 0.0881370 Test Loss: 0.1023577\n",
      "Validation loss decreased (0.088271 --> 0.088137).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0679360\n",
      "\tspeed: 0.0949s/iter; left time: 1839.3175s\n",
      "\titers: 200, epoch: 14 | loss: 0.0720937\n",
      "\tspeed: 0.0524s/iter; left time: 1010.5496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.99s\n",
      "Steps: 224 | Train Loss: 0.0726295 Vali Loss: 0.0878316 Test Loss: 0.1023786\n",
      "Validation loss decreased (0.088137 --> 0.087832).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0757486\n",
      "\tspeed: 0.0949s/iter; left time: 1819.5625s\n",
      "\titers: 200, epoch: 15 | loss: 0.0714281\n",
      "\tspeed: 0.0524s/iter; left time: 998.1405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0723702 Vali Loss: 0.0882032 Test Loss: 0.1025239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0744029\n",
      "\tspeed: 0.0937s/iter; left time: 1775.1121s\n",
      "\titers: 200, epoch: 16 | loss: 0.0732896\n",
      "\tspeed: 0.0524s/iter; left time: 987.9542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0722303 Vali Loss: 0.0879967 Test Loss: 0.1022053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0708814\n",
      "\tspeed: 0.0935s/iter; left time: 1749.8102s\n",
      "\titers: 200, epoch: 17 | loss: 0.0643175\n",
      "\tspeed: 0.0525s/iter; left time: 978.0579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.98s\n",
      "Steps: 224 | Train Loss: 0.0720519 Vali Loss: 0.0878360 Test Loss: 0.1024031\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0691474\n",
      "\tspeed: 0.0938s/iter; left time: 1735.2624s\n",
      "\titers: 200, epoch: 18 | loss: 0.0731347\n",
      "\tspeed: 0.0523s/iter; left time: 962.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.95s\n",
      "Steps: 224 | Train Loss: 0.0717889 Vali Loss: 0.0880502 Test Loss: 0.1021411\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0713383\n",
      "\tspeed: 0.0936s/iter; left time: 1709.7715s\n",
      "\titers: 200, epoch: 19 | loss: 0.0802521\n",
      "\tspeed: 0.0524s/iter; left time: 951.1599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0717140 Vali Loss: 0.0880324 Test Loss: 0.1025808\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0718002\n",
      "\tspeed: 0.0938s/iter; left time: 1693.0729s\n",
      "\titers: 200, epoch: 20 | loss: 0.0694699\n",
      "\tspeed: 0.0524s/iter; left time: 941.2006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.00s\n",
      "Steps: 224 | Train Loss: 0.0716252 Vali Loss: 0.0878140 Test Loss: 0.1023368\n",
      "Validation loss decreased (0.087832 --> 0.087814).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0732282\n",
      "\tspeed: 0.0950s/iter; left time: 1693.3363s\n",
      "\titers: 200, epoch: 21 | loss: 0.0687660\n",
      "\tspeed: 0.0521s/iter; left time: 924.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0715591 Vali Loss: 0.0878166 Test Loss: 0.1024134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0704203\n",
      "\tspeed: 0.0938s/iter; left time: 1649.8494s\n",
      "\titers: 200, epoch: 22 | loss: 0.0698574\n",
      "\tspeed: 0.0524s/iter; left time: 917.4953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.98s\n",
      "Steps: 224 | Train Loss: 0.0714010 Vali Loss: 0.0878006 Test Loss: 0.1022703\n",
      "Validation loss decreased (0.087814 --> 0.087801).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0693955\n",
      "\tspeed: 0.0957s/iter; left time: 1662.1524s\n",
      "\titers: 200, epoch: 23 | loss: 0.0668513\n",
      "\tspeed: 0.0523s/iter; left time: 904.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.98s\n",
      "Steps: 224 | Train Loss: 0.0713579 Vali Loss: 0.0878292 Test Loss: 0.1025530\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0714743\n",
      "\tspeed: 0.0943s/iter; left time: 1617.4032s\n",
      "\titers: 200, epoch: 24 | loss: 0.0696637\n",
      "\tspeed: 0.0525s/iter; left time: 894.6946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:12.02s\n",
      "Steps: 224 | Train Loss: 0.0712420 Vali Loss: 0.0878795 Test Loss: 0.1024655\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0674481\n",
      "\tspeed: 0.0945s/iter; left time: 1598.9433s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701551\n",
      "\tspeed: 0.0523s/iter; left time: 880.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.02s\n",
      "Steps: 224 | Train Loss: 0.0711827 Vali Loss: 0.0878567 Test Loss: 0.1025342\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0699493\n",
      "\tspeed: 0.0951s/iter; left time: 1587.6389s\n",
      "\titers: 200, epoch: 26 | loss: 0.0704517\n",
      "\tspeed: 0.0523s/iter; left time: 868.8810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 224 | Train Loss: 0.0711286 Vali Loss: 0.0878145 Test Loss: 0.1025468\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0690658\n",
      "\tspeed: 0.0947s/iter; left time: 1560.5824s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724766\n",
      "\tspeed: 0.0524s/iter; left time: 858.8684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.03s\n",
      "Steps: 224 | Train Loss: 0.0710852 Vali Loss: 0.0877976 Test Loss: 0.1023908\n",
      "Validation loss decreased (0.087801 --> 0.087798).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0726968\n",
      "\tspeed: 0.0951s/iter; left time: 1545.3238s\n",
      "\titers: 200, epoch: 28 | loss: 0.0673573\n",
      "\tspeed: 0.0525s/iter; left time: 847.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0710127 Vali Loss: 0.0877014 Test Loss: 0.1025226\n",
      "Validation loss decreased (0.087798 --> 0.087701).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0690880\n",
      "\tspeed: 0.0958s/iter; left time: 1535.1482s\n",
      "\titers: 200, epoch: 29 | loss: 0.0689618\n",
      "\tspeed: 0.0524s/iter; left time: 834.5876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:12.00s\n",
      "Steps: 224 | Train Loss: 0.0709411 Vali Loss: 0.0878401 Test Loss: 0.1026098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0678539\n",
      "\tspeed: 0.0947s/iter; left time: 1497.1219s\n",
      "\titers: 200, epoch: 30 | loss: 0.0694931\n",
      "\tspeed: 0.0524s/iter; left time: 822.8117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0709095 Vali Loss: 0.0877920 Test Loss: 0.1025607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0682457\n",
      "\tspeed: 0.0935s/iter; left time: 1457.1596s\n",
      "\titers: 200, epoch: 31 | loss: 0.0681491\n",
      "\tspeed: 0.0521s/iter; left time: 807.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0708165 Vali Loss: 0.0876857 Test Loss: 0.1025284\n",
      "Validation loss decreased (0.087701 --> 0.087686).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0699011\n",
      "\tspeed: 0.0948s/iter; left time: 1455.1746s\n",
      "\titers: 200, epoch: 32 | loss: 0.0707282\n",
      "\tspeed: 0.0522s/iter; left time: 797.0003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0708926 Vali Loss: 0.0877611 Test Loss: 0.1025761\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0750260\n",
      "\tspeed: 0.0937s/iter; left time: 1417.7752s\n",
      "\titers: 200, epoch: 33 | loss: 0.0712225\n",
      "\tspeed: 0.0524s/iter; left time: 787.6366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0708430 Vali Loss: 0.0878547 Test Loss: 0.1025163\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0709231\n",
      "\tspeed: 0.0935s/iter; left time: 1393.7420s\n",
      "\titers: 200, epoch: 34 | loss: 0.0734632\n",
      "\tspeed: 0.0526s/iter; left time: 778.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:11.99s\n",
      "Steps: 224 | Train Loss: 0.0707557 Vali Loss: 0.0878187 Test Loss: 0.1025741\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0741756\n",
      "\tspeed: 0.0938s/iter; left time: 1377.9772s\n",
      "\titers: 200, epoch: 35 | loss: 0.0756165\n",
      "\tspeed: 0.0524s/iter; left time: 764.4085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.98s\n",
      "Steps: 224 | Train Loss: 0.0707925 Vali Loss: 0.0877389 Test Loss: 0.1025545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0762861\n",
      "\tspeed: 0.0935s/iter; left time: 1352.1350s\n",
      "\titers: 200, epoch: 36 | loss: 0.0745686\n",
      "\tspeed: 0.0525s/iter; left time: 753.7614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0706969 Vali Loss: 0.0878429 Test Loss: 0.1024922\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752780\n",
      "\tspeed: 0.0940s/iter; left time: 1338.2770s\n",
      "\titers: 200, epoch: 37 | loss: 0.0681149\n",
      "\tspeed: 0.0525s/iter; left time: 741.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0706726 Vali Loss: 0.0878174 Test Loss: 0.1026253\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0696197\n",
      "\tspeed: 0.0947s/iter; left time: 1326.9728s\n",
      "\titers: 200, epoch: 38 | loss: 0.0708822\n",
      "\tspeed: 0.0525s/iter; left time: 730.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:12.04s\n",
      "Steps: 224 | Train Loss: 0.0706715 Vali Loss: 0.0877813 Test Loss: 0.1026189\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0691303\n",
      "\tspeed: 0.0944s/iter; left time: 1301.7707s\n",
      "\titers: 200, epoch: 39 | loss: 0.0709607\n",
      "\tspeed: 0.0524s/iter; left time: 716.8210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:12.00s\n",
      "Steps: 224 | Train Loss: 0.0706529 Vali Loss: 0.0878448 Test Loss: 0.1025701\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0710506\n",
      "\tspeed: 0.0938s/iter; left time: 1272.4545s\n",
      "\titers: 200, epoch: 40 | loss: 0.0685172\n",
      "\tspeed: 0.0524s/iter; left time: 705.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.98s\n",
      "Steps: 224 | Train Loss: 0.0706797 Vali Loss: 0.0877237 Test Loss: 0.1025156\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0680695\n",
      "\tspeed: 0.0939s/iter; left time: 1252.7076s\n",
      "\titers: 200, epoch: 41 | loss: 0.0707226\n",
      "\tspeed: 0.0525s/iter; left time: 694.8040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.98s\n",
      "Steps: 224 | Train Loss: 0.0706761 Vali Loss: 0.0877903 Test Loss: 0.1025302\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02596805803477764, rmse:0.16114607453346252, mae:0.1025284007191658, rse:0.5559083223342896\n",
      "Intermediate time for GB and pred_len 24: 00h:23m:37.48s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1406689\n",
      "\tspeed: 0.0778s/iter; left time: 1735.0379s\n",
      "\titers: 200, epoch: 1 | loss: 0.1337222\n",
      "\tspeed: 0.0531s/iter; left time: 1179.5028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.41s\n",
      "Steps: 224 | Train Loss: 0.1448316 Vali Loss: 0.1478217 Test Loss: 0.1731035\n",
      "Validation loss decreased (inf --> 0.147822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138583\n",
      "\tspeed: 0.0962s/iter; left time: 2124.7654s\n",
      "\titers: 200, epoch: 2 | loss: 0.1043878\n",
      "\tspeed: 0.0528s/iter; left time: 1160.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 224 | Train Loss: 0.1130484 Vali Loss: 0.1190484 Test Loss: 0.1404722\n",
      "Validation loss decreased (0.147822 --> 0.119048).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1049010\n",
      "\tspeed: 0.0957s/iter; left time: 2090.6869s\n",
      "\titers: 200, epoch: 3 | loss: 0.0996536\n",
      "\tspeed: 0.0528s/iter; left time: 1147.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.04s\n",
      "Steps: 224 | Train Loss: 0.1032481 Vali Loss: 0.1175735 Test Loss: 0.1405436\n",
      "Validation loss decreased (0.119048 --> 0.117573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0995604\n",
      "\tspeed: 0.0952s/iter; left time: 2059.6948s\n",
      "\titers: 200, epoch: 4 | loss: 0.1006075\n",
      "\tspeed: 0.0525s/iter; left time: 1130.2437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.95s\n",
      "Steps: 224 | Train Loss: 0.1012283 Vali Loss: 0.1169945 Test Loss: 0.1409361\n",
      "Validation loss decreased (0.117573 --> 0.116995).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1010126\n",
      "\tspeed: 0.0959s/iter; left time: 2051.9458s\n",
      "\titers: 200, epoch: 5 | loss: 0.1020785\n",
      "\tspeed: 0.0528s/iter; left time: 1123.9785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0999265 Vali Loss: 0.1165816 Test Loss: 0.1420393\n",
      "Validation loss decreased (0.116995 --> 0.116582).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0985006\n",
      "\tspeed: 0.0969s/iter; left time: 2051.6560s\n",
      "\titers: 200, epoch: 6 | loss: 0.1023615\n",
      "\tspeed: 0.0529s/iter; left time: 1115.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.11s\n",
      "Steps: 224 | Train Loss: 0.0988150 Vali Loss: 0.1164725 Test Loss: 0.1419193\n",
      "Validation loss decreased (0.116582 --> 0.116472).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0936005\n",
      "\tspeed: 0.0974s/iter; left time: 2041.5122s\n",
      "\titers: 200, epoch: 7 | loss: 0.1041656\n",
      "\tspeed: 0.0528s/iter; left time: 1100.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 224 | Train Loss: 0.0977622 Vali Loss: 0.1164984 Test Loss: 0.1426636\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0965147\n",
      "\tspeed: 0.0958s/iter; left time: 1987.1782s\n",
      "\titers: 200, epoch: 8 | loss: 0.0945425\n",
      "\tspeed: 0.0529s/iter; left time: 1090.7124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 224 | Train Loss: 0.0968455 Vali Loss: 0.1165157 Test Loss: 0.1424598\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0966142\n",
      "\tspeed: 0.0949s/iter; left time: 1947.1544s\n",
      "\titers: 200, epoch: 9 | loss: 0.0961041\n",
      "\tspeed: 0.0524s/iter; left time: 1070.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.04s\n",
      "Steps: 224 | Train Loss: 0.0958037 Vali Loss: 0.1168818 Test Loss: 0.1435367\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0900782\n",
      "\tspeed: 0.0957s/iter; left time: 1941.4901s\n",
      "\titers: 200, epoch: 10 | loss: 0.0928683\n",
      "\tspeed: 0.0525s/iter; left time: 1060.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.05s\n",
      "Steps: 224 | Train Loss: 0.0950237 Vali Loss: 0.1168693 Test Loss: 0.1427697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0930412\n",
      "\tspeed: 0.0949s/iter; left time: 1904.4256s\n",
      "\titers: 200, epoch: 11 | loss: 0.0950651\n",
      "\tspeed: 0.0529s/iter; left time: 1056.0567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 224 | Train Loss: 0.0941731 Vali Loss: 0.1173024 Test Loss: 0.1442032\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0968957\n",
      "\tspeed: 0.0955s/iter; left time: 1893.4818s\n",
      "\titers: 200, epoch: 12 | loss: 0.0931910\n",
      "\tspeed: 0.0528s/iter; left time: 1043.0468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 224 | Train Loss: 0.0934533 Vali Loss: 0.1175537 Test Loss: 0.1439120\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0920408\n",
      "\tspeed: 0.0952s/iter; left time: 1866.3103s\n",
      "\titers: 200, epoch: 13 | loss: 0.0944622\n",
      "\tspeed: 0.0527s/iter; left time: 1027.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.05s\n",
      "Steps: 224 | Train Loss: 0.0928211 Vali Loss: 0.1180769 Test Loss: 0.1442586\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0956941\n",
      "\tspeed: 0.0952s/iter; left time: 1846.1370s\n",
      "\titers: 200, epoch: 14 | loss: 0.0928700\n",
      "\tspeed: 0.0528s/iter; left time: 1017.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.03s\n",
      "Steps: 224 | Train Loss: 0.0922051 Vali Loss: 0.1175812 Test Loss: 0.1443594\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0883551\n",
      "\tspeed: 0.0954s/iter; left time: 1827.9641s\n",
      "\titers: 200, epoch: 15 | loss: 0.0926333\n",
      "\tspeed: 0.0526s/iter; left time: 1002.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.05s\n",
      "Steps: 224 | Train Loss: 0.0916389 Vali Loss: 0.1180225 Test Loss: 0.1446331\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0901917\n",
      "\tspeed: 0.0953s/iter; left time: 1804.3375s\n",
      "\titers: 200, epoch: 16 | loss: 0.0919948\n",
      "\tspeed: 0.0525s/iter; left time: 989.9656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0911649 Vali Loss: 0.1185595 Test Loss: 0.1457173\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04354952275753021, rmse:0.20868521928787231, mae:0.14191927015781403, rse:0.7216625809669495\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1456753\n",
      "\tspeed: 0.0545s/iter; left time: 1216.4646s\n",
      "\titers: 200, epoch: 1 | loss: 0.1401336\n",
      "\tspeed: 0.0528s/iter; left time: 1172.0063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 224 | Train Loss: 0.1450534 Vali Loss: 0.1476693 Test Loss: 0.1731948\n",
      "Validation loss decreased (inf --> 0.147669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1121303\n",
      "\tspeed: 0.0971s/iter; left time: 2144.6319s\n",
      "\titers: 200, epoch: 2 | loss: 0.1097031\n",
      "\tspeed: 0.0523s/iter; left time: 1150.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.03s\n",
      "Steps: 224 | Train Loss: 0.1142875 Vali Loss: 0.1189107 Test Loss: 0.1412798\n",
      "Validation loss decreased (0.147669 --> 0.118911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1073427\n",
      "\tspeed: 0.0961s/iter; left time: 2099.4687s\n",
      "\titers: 200, epoch: 3 | loss: 0.1005311\n",
      "\tspeed: 0.0526s/iter; left time: 1143.6469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.1034565 Vali Loss: 0.1175246 Test Loss: 0.1412851\n",
      "Validation loss decreased (0.118911 --> 0.117525).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1021812\n",
      "\tspeed: 0.0962s/iter; left time: 2079.8129s\n",
      "\titers: 200, epoch: 4 | loss: 0.0990468\n",
      "\tspeed: 0.0524s/iter; left time: 1128.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.99s\n",
      "Steps: 224 | Train Loss: 0.1013426 Vali Loss: 0.1167549 Test Loss: 0.1418313\n",
      "Validation loss decreased (0.117525 --> 0.116755).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0974963\n",
      "\tspeed: 0.0975s/iter; left time: 2086.9744s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008517\n",
      "\tspeed: 0.0525s/iter; left time: 1118.9854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.03s\n",
      "Steps: 224 | Train Loss: 0.0997085 Vali Loss: 0.1166128 Test Loss: 0.1418357\n",
      "Validation loss decreased (0.116755 --> 0.116613).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1000176\n",
      "\tspeed: 0.0971s/iter; left time: 2057.1909s\n",
      "\titers: 200, epoch: 6 | loss: 0.0948140\n",
      "\tspeed: 0.0528s/iter; left time: 1113.1116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.10s\n",
      "Steps: 224 | Train Loss: 0.0984699 Vali Loss: 0.1163163 Test Loss: 0.1417426\n",
      "Validation loss decreased (0.116613 --> 0.116316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0972994\n",
      "\tspeed: 0.0985s/iter; left time: 2063.5184s\n",
      "\titers: 200, epoch: 7 | loss: 0.0936878\n",
      "\tspeed: 0.0529s/iter; left time: 1102.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.11s\n",
      "Steps: 224 | Train Loss: 0.0972406 Vali Loss: 0.1165814 Test Loss: 0.1420426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0935553\n",
      "\tspeed: 0.0957s/iter; left time: 1984.6068s\n",
      "\titers: 200, epoch: 8 | loss: 0.0962930\n",
      "\tspeed: 0.0524s/iter; left time: 1081.9871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.00s\n",
      "Steps: 224 | Train Loss: 0.0962139 Vali Loss: 0.1169551 Test Loss: 0.1428138\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0923287\n",
      "\tspeed: 0.0947s/iter; left time: 1941.2373s\n",
      "\titers: 200, epoch: 9 | loss: 0.0975701\n",
      "\tspeed: 0.0526s/iter; left time: 1073.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.00s\n",
      "Steps: 224 | Train Loss: 0.0952119 Vali Loss: 0.1167024 Test Loss: 0.1424034\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0950940\n",
      "\tspeed: 0.0950s/iter; left time: 1927.0254s\n",
      "\titers: 200, epoch: 10 | loss: 0.0920952\n",
      "\tspeed: 0.0523s/iter; left time: 1056.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.99s\n",
      "Steps: 224 | Train Loss: 0.0942552 Vali Loss: 0.1169274 Test Loss: 0.1425461\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0946459\n",
      "\tspeed: 0.0958s/iter; left time: 1921.9933s\n",
      "\titers: 200, epoch: 11 | loss: 0.0923537\n",
      "\tspeed: 0.0526s/iter; left time: 1049.9876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0934874 Vali Loss: 0.1180461 Test Loss: 0.1432987\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0927330\n",
      "\tspeed: 0.0948s/iter; left time: 1879.7731s\n",
      "\titers: 200, epoch: 12 | loss: 0.0926669\n",
      "\tspeed: 0.0524s/iter; left time: 1034.8491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0927273 Vali Loss: 0.1177090 Test Loss: 0.1433754\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0888391\n",
      "\tspeed: 0.0959s/iter; left time: 1880.3587s\n",
      "\titers: 200, epoch: 13 | loss: 0.0915669\n",
      "\tspeed: 0.0525s/iter; left time: 1024.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0920820 Vali Loss: 0.1174937 Test Loss: 0.1429974\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0890915\n",
      "\tspeed: 0.0951s/iter; left time: 1844.2392s\n",
      "\titers: 200, epoch: 14 | loss: 0.0909410\n",
      "\tspeed: 0.0525s/iter; left time: 1011.8706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0915154 Vali Loss: 0.1185164 Test Loss: 0.1435190\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0897911\n",
      "\tspeed: 0.0955s/iter; left time: 1829.3221s\n",
      "\titers: 200, epoch: 15 | loss: 0.0919447\n",
      "\tspeed: 0.0526s/iter; left time: 1002.4357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.03s\n",
      "Steps: 224 | Train Loss: 0.0909746 Vali Loss: 0.1183434 Test Loss: 0.1438548\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0908882\n",
      "\tspeed: 0.0958s/iter; left time: 1815.0659s\n",
      "\titers: 200, epoch: 16 | loss: 0.0895689\n",
      "\tspeed: 0.0526s/iter; left time: 990.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0904027 Vali Loss: 0.1184962 Test Loss: 0.1438918\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04310917481780052, rmse:0.20762749016284943, mae:0.14174264669418335, rse:0.7180048227310181\n",
      "Intermediate time for GB and pred_len 96: 00h:08m:09.21s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1386354\n",
      "\tspeed: 0.0799s/iter; left time: 1774.0109s\n",
      "\titers: 200, epoch: 1 | loss: 0.1395205\n",
      "\tspeed: 0.0533s/iter; left time: 1178.3183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.50s\n",
      "Steps: 223 | Train Loss: 0.1463431 Vali Loss: 0.1503382 Test Loss: 0.1766342\n",
      "Validation loss decreased (inf --> 0.150338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1167225\n",
      "\tspeed: 0.0971s/iter; left time: 2133.9906s\n",
      "\titers: 200, epoch: 2 | loss: 0.1144232\n",
      "\tspeed: 0.0532s/iter; left time: 1163.7614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 223 | Train Loss: 0.1172889 Vali Loss: 0.1233330 Test Loss: 0.1472234\n",
      "Validation loss decreased (0.150338 --> 0.123333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1107266\n",
      "\tspeed: 0.0966s/iter; left time: 2100.9772s\n",
      "\titers: 200, epoch: 3 | loss: 0.1062191\n",
      "\tspeed: 0.0532s/iter; left time: 1151.7519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.14s\n",
      "Steps: 223 | Train Loss: 0.1077707 Vali Loss: 0.1215602 Test Loss: 0.1480374\n",
      "Validation loss decreased (0.123333 --> 0.121560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1096353\n",
      "\tspeed: 0.0962s/iter; left time: 2071.6968s\n",
      "\titers: 200, epoch: 4 | loss: 0.1031461\n",
      "\tspeed: 0.0530s/iter; left time: 1135.9295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 223 | Train Loss: 0.1054061 Vali Loss: 0.1210068 Test Loss: 0.1477708\n",
      "Validation loss decreased (0.121560 --> 0.121007).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1060579\n",
      "\tspeed: 0.1009s/iter; left time: 2150.0264s\n",
      "\titers: 200, epoch: 5 | loss: 0.1032196\n",
      "\tspeed: 0.0531s/iter; left time: 1126.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.14s\n",
      "Steps: 223 | Train Loss: 0.1034220 Vali Loss: 0.1211447 Test Loss: 0.1495119\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1040526\n",
      "\tspeed: 0.0952s/iter; left time: 2007.9565s\n",
      "\titers: 200, epoch: 6 | loss: 0.0999122\n",
      "\tspeed: 0.0532s/iter; left time: 1116.9635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.1017199 Vali Loss: 0.1208167 Test Loss: 0.1491451\n",
      "Validation loss decreased (0.121007 --> 0.120817).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0974309\n",
      "\tspeed: 0.0971s/iter; left time: 2026.3603s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973077\n",
      "\tspeed: 0.0532s/iter; left time: 1104.9180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 223 | Train Loss: 0.1002500 Vali Loss: 0.1214452 Test Loss: 0.1506692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0991654\n",
      "\tspeed: 0.0961s/iter; left time: 1983.5420s\n",
      "\titers: 200, epoch: 8 | loss: 0.0999737\n",
      "\tspeed: 0.0534s/iter; left time: 1096.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 223 | Train Loss: 0.0989331 Vali Loss: 0.1217749 Test Loss: 0.1506914\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0970173\n",
      "\tspeed: 0.0953s/iter; left time: 1945.7000s\n",
      "\titers: 200, epoch: 9 | loss: 0.0956019\n",
      "\tspeed: 0.0529s/iter; left time: 1074.7306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 223 | Train Loss: 0.0976805 Vali Loss: 0.1223509 Test Loss: 0.1528988\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0916557\n",
      "\tspeed: 0.0952s/iter; left time: 1922.6336s\n",
      "\titers: 200, epoch: 10 | loss: 0.0955586\n",
      "\tspeed: 0.0533s/iter; left time: 1070.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.10s\n",
      "Steps: 223 | Train Loss: 0.0966453 Vali Loss: 0.1220048 Test Loss: 0.1516780\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0931706\n",
      "\tspeed: 0.0954s/iter; left time: 1905.0389s\n",
      "\titers: 200, epoch: 11 | loss: 0.0948939\n",
      "\tspeed: 0.0530s/iter; left time: 1053.6415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 223 | Train Loss: 0.0956451 Vali Loss: 0.1224576 Test Loss: 0.1529393\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0946385\n",
      "\tspeed: 0.0951s/iter; left time: 1878.5123s\n",
      "\titers: 200, epoch: 12 | loss: 0.0961585\n",
      "\tspeed: 0.0531s/iter; left time: 1043.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.0948170 Vali Loss: 0.1230200 Test Loss: 0.1536463\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0947491\n",
      "\tspeed: 0.0963s/iter; left time: 1880.2425s\n",
      "\titers: 200, epoch: 13 | loss: 0.0919266\n",
      "\tspeed: 0.0532s/iter; left time: 1032.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.15s\n",
      "Steps: 223 | Train Loss: 0.0940334 Vali Loss: 0.1228369 Test Loss: 0.1537511\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0905955\n",
      "\tspeed: 0.0954s/iter; left time: 1842.2054s\n",
      "\titers: 200, epoch: 14 | loss: 0.0925452\n",
      "\tspeed: 0.0531s/iter; left time: 1019.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.0933891 Vali Loss: 0.1232879 Test Loss: 0.1543309\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0899824\n",
      "\tspeed: 0.0961s/iter; left time: 1833.3011s\n",
      "\titers: 200, epoch: 15 | loss: 0.0903571\n",
      "\tspeed: 0.0531s/iter; left time: 1008.5286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.11s\n",
      "Steps: 223 | Train Loss: 0.0927193 Vali Loss: 0.1231269 Test Loss: 0.1540274\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0921509\n",
      "\tspeed: 0.0953s/iter; left time: 1797.8988s\n",
      "\titers: 200, epoch: 16 | loss: 0.0940645\n",
      "\tspeed: 0.0528s/iter; left time: 991.0784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 223 | Train Loss: 0.0921280 Vali Loss: 0.1235844 Test Loss: 0.1547213\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04644313454627991, rmse:0.2155066877603531, mae:0.14914505183696747, rse:0.7471926212310791\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1437372\n",
      "\tspeed: 0.0554s/iter; left time: 1230.5675s\n",
      "\titers: 200, epoch: 1 | loss: 0.1413468\n",
      "\tspeed: 0.0531s/iter; left time: 1173.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.15s\n",
      "Steps: 223 | Train Loss: 0.1469574 Vali Loss: 0.1503597 Test Loss: 0.1767833\n",
      "Validation loss decreased (inf --> 0.150360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1121952\n",
      "\tspeed: 0.0985s/iter; left time: 2165.5026s\n",
      "\titers: 200, epoch: 2 | loss: 0.1107133\n",
      "\tspeed: 0.0531s/iter; left time: 1160.6755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.11s\n",
      "Steps: 223 | Train Loss: 0.1172488 Vali Loss: 0.1230871 Test Loss: 0.1470359\n",
      "Validation loss decreased (0.150360 --> 0.123087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1074790\n",
      "\tspeed: 0.0977s/iter; left time: 2125.6744s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082936\n",
      "\tspeed: 0.0531s/iter; left time: 1150.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.12s\n",
      "Steps: 223 | Train Loss: 0.1079106 Vali Loss: 0.1219156 Test Loss: 0.1472393\n",
      "Validation loss decreased (0.123087 --> 0.121916).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1024566\n",
      "\tspeed: 0.0985s/iter; left time: 2121.1252s\n",
      "\titers: 200, epoch: 4 | loss: 0.1093854\n",
      "\tspeed: 0.0530s/iter; left time: 1135.9856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.11s\n",
      "Steps: 223 | Train Loss: 0.1056144 Vali Loss: 0.1214643 Test Loss: 0.1478963\n",
      "Validation loss decreased (0.121916 --> 0.121464).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043837\n",
      "\tspeed: 0.0995s/iter; left time: 2120.1471s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008662\n",
      "\tspeed: 0.0532s/iter; left time: 1128.3737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.15s\n",
      "Steps: 223 | Train Loss: 0.1037652 Vali Loss: 0.1209340 Test Loss: 0.1483610\n",
      "Validation loss decreased (0.121464 --> 0.120934).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1018177\n",
      "\tspeed: 0.0988s/iter; left time: 2082.5883s\n",
      "\titers: 200, epoch: 6 | loss: 0.1021051\n",
      "\tspeed: 0.0528s/iter; left time: 1108.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.11s\n",
      "Steps: 223 | Train Loss: 0.1021854 Vali Loss: 0.1211857 Test Loss: 0.1487773\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1033683\n",
      "\tspeed: 0.0959s/iter; left time: 2001.1717s\n",
      "\titers: 200, epoch: 7 | loss: 0.1002985\n",
      "\tspeed: 0.0526s/iter; left time: 1092.4706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.00s\n",
      "Steps: 223 | Train Loss: 0.1008956 Vali Loss: 0.1210550 Test Loss: 0.1488046\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1034819\n",
      "\tspeed: 0.0961s/iter; left time: 1982.6148s\n",
      "\titers: 200, epoch: 8 | loss: 0.0974347\n",
      "\tspeed: 0.0529s/iter; left time: 1086.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 223 | Train Loss: 0.0997048 Vali Loss: 0.1213903 Test Loss: 0.1492843\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996106\n",
      "\tspeed: 0.0971s/iter; left time: 1983.2062s\n",
      "\titers: 200, epoch: 9 | loss: 0.1009926\n",
      "\tspeed: 0.0529s/iter; left time: 1074.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 223 | Train Loss: 0.0987894 Vali Loss: 0.1212850 Test Loss: 0.1499267\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0979183\n",
      "\tspeed: 0.0963s/iter; left time: 1943.9106s\n",
      "\titers: 200, epoch: 10 | loss: 0.0985871\n",
      "\tspeed: 0.0530s/iter; left time: 1065.6986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 223 | Train Loss: 0.0978428 Vali Loss: 0.1210372 Test Loss: 0.1496313\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0980109\n",
      "\tspeed: 0.0968s/iter; left time: 1933.7956s\n",
      "\titers: 200, epoch: 11 | loss: 0.0930352\n",
      "\tspeed: 0.0531s/iter; left time: 1054.9296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.0970727 Vali Loss: 0.1218514 Test Loss: 0.1515267\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0990410\n",
      "\tspeed: 0.0972s/iter; left time: 1919.2860s\n",
      "\titers: 200, epoch: 12 | loss: 0.0954193\n",
      "\tspeed: 0.0533s/iter; left time: 1046.5248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.17s\n",
      "Steps: 223 | Train Loss: 0.0962643 Vali Loss: 0.1218991 Test Loss: 0.1503961\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0943987\n",
      "\tspeed: 0.0971s/iter; left time: 1895.7932s\n",
      "\titers: 200, epoch: 13 | loss: 0.0911834\n",
      "\tspeed: 0.0531s/iter; left time: 1031.6715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.12s\n",
      "Steps: 223 | Train Loss: 0.0956385 Vali Loss: 0.1226010 Test Loss: 0.1523950\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0947586\n",
      "\tspeed: 0.0979s/iter; left time: 1889.2056s\n",
      "\titers: 200, epoch: 14 | loss: 0.0958324\n",
      "\tspeed: 0.0532s/iter; left time: 1020.6452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.15s\n",
      "Steps: 223 | Train Loss: 0.0950461 Vali Loss: 0.1226071 Test Loss: 0.1518613\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0910238\n",
      "\tspeed: 0.0971s/iter; left time: 1851.7204s\n",
      "\titers: 200, epoch: 15 | loss: 0.0908302\n",
      "\tspeed: 0.0533s/iter; left time: 1012.1962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.15s\n",
      "Steps: 223 | Train Loss: 0.0944825 Vali Loss: 0.1224583 Test Loss: 0.1519933\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04599538445472717, rmse:0.21446534991264343, mae:0.14836086332798004, rse:0.7435821890830994\n",
      "Intermediate time for GB and pred_len 168: 00h:07m:59.59s\n",
      "Intermediate time for GB: 00h:39m:46.28s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1526842\n",
      "\tspeed: 0.0604s/iter; left time: 1346.6424s\n",
      "\titers: 200, epoch: 1 | loss: 0.1366305\n",
      "\tspeed: 0.0345s/iter; left time: 766.6100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.1550454 Vali Loss: 0.1393994 Test Loss: 0.1681718\n",
      "Validation loss decreased (inf --> 0.139399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0732484\n",
      "\tspeed: 0.0661s/iter; left time: 1460.0271s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723599\n",
      "\tspeed: 0.0360s/iter; left time: 790.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.0805116 Vali Loss: 0.0647224 Test Loss: 0.0717992\n",
      "Validation loss decreased (0.139399 --> 0.064722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670712\n",
      "\tspeed: 0.0676s/iter; left time: 1477.0346s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631713\n",
      "\tspeed: 0.0340s/iter; left time: 739.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0640164 Vali Loss: 0.0604511 Test Loss: 0.0675387\n",
      "Validation loss decreased (0.064722 --> 0.060451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615953\n",
      "\tspeed: 0.0650s/iter; left time: 1405.4457s\n",
      "\titers: 200, epoch: 4 | loss: 0.0594863\n",
      "\tspeed: 0.0354s/iter; left time: 762.2104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.0607313 Vali Loss: 0.0585351 Test Loss: 0.0652289\n",
      "Validation loss decreased (0.060451 --> 0.058535).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582284\n",
      "\tspeed: 0.0646s/iter; left time: 1383.3173s\n",
      "\titers: 200, epoch: 5 | loss: 0.0548869\n",
      "\tspeed: 0.0340s/iter; left time: 723.9232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0586365 Vali Loss: 0.0571023 Test Loss: 0.0640453\n",
      "Validation loss decreased (0.058535 --> 0.057102).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568549\n",
      "\tspeed: 0.0667s/iter; left time: 1413.1525s\n",
      "\titers: 200, epoch: 6 | loss: 0.0545233\n",
      "\tspeed: 0.0343s/iter; left time: 722.9715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0572533 Vali Loss: 0.0562853 Test Loss: 0.0630265\n",
      "Validation loss decreased (0.057102 --> 0.056285).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588305\n",
      "\tspeed: 0.0663s/iter; left time: 1388.5654s\n",
      "\titers: 200, epoch: 7 | loss: 0.0523065\n",
      "\tspeed: 0.0356s/iter; left time: 742.9014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 224 | Train Loss: 0.0561701 Vali Loss: 0.0557691 Test Loss: 0.0625740\n",
      "Validation loss decreased (0.056285 --> 0.055769).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0549896\n",
      "\tspeed: 0.0635s/iter; left time: 1316.3383s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590127\n",
      "\tspeed: 0.0342s/iter; left time: 706.0416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0555243 Vali Loss: 0.0552860 Test Loss: 0.0622382\n",
      "Validation loss decreased (0.055769 --> 0.055286).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0538663\n",
      "\tspeed: 0.0643s/iter; left time: 1318.4272s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581174\n",
      "\tspeed: 0.0339s/iter; left time: 692.2422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0549856 Vali Loss: 0.0547778 Test Loss: 0.0615789\n",
      "Validation loss decreased (0.055286 --> 0.054778).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0544842\n",
      "\tspeed: 0.0641s/iter; left time: 1299.8318s\n",
      "\titers: 200, epoch: 10 | loss: 0.0509822\n",
      "\tspeed: 0.0339s/iter; left time: 684.6274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0545583 Vali Loss: 0.0547986 Test Loss: 0.0614929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541769\n",
      "\tspeed: 0.0632s/iter; left time: 1267.4606s\n",
      "\titers: 200, epoch: 11 | loss: 0.0549371\n",
      "\tspeed: 0.0338s/iter; left time: 675.3753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0541390 Vali Loss: 0.0542580 Test Loss: 0.0609762\n",
      "Validation loss decreased (0.054778 --> 0.054258).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0538365\n",
      "\tspeed: 0.0632s/iter; left time: 1253.3795s\n",
      "\titers: 200, epoch: 12 | loss: 0.0529875\n",
      "\tspeed: 0.0341s/iter; left time: 672.4888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0538779 Vali Loss: 0.0541497 Test Loss: 0.0608541\n",
      "Validation loss decreased (0.054258 --> 0.054150).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0556539\n",
      "\tspeed: 0.0644s/iter; left time: 1262.7040s\n",
      "\titers: 200, epoch: 13 | loss: 0.0526646\n",
      "\tspeed: 0.0343s/iter; left time: 670.0860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0536023 Vali Loss: 0.0540321 Test Loss: 0.0606161\n",
      "Validation loss decreased (0.054150 --> 0.054032).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0543625\n",
      "\tspeed: 0.0634s/iter; left time: 1228.6336s\n",
      "\titers: 200, epoch: 14 | loss: 0.0530023\n",
      "\tspeed: 0.0339s/iter; left time: 653.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0533630 Vali Loss: 0.0541184 Test Loss: 0.0608187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0521512\n",
      "\tspeed: 0.0620s/iter; left time: 1188.6895s\n",
      "\titers: 200, epoch: 15 | loss: 0.0521281\n",
      "\tspeed: 0.0339s/iter; left time: 645.8167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0531000 Vali Loss: 0.0539720 Test Loss: 0.0605283\n",
      "Validation loss decreased (0.054032 --> 0.053972).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509178\n",
      "\tspeed: 0.0634s/iter; left time: 1200.9643s\n",
      "\titers: 200, epoch: 16 | loss: 0.0512274\n",
      "\tspeed: 0.0338s/iter; left time: 636.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0529989 Vali Loss: 0.0536041 Test Loss: 0.0602776\n",
      "Validation loss decreased (0.053972 --> 0.053604).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0513468\n",
      "\tspeed: 0.0637s/iter; left time: 1192.9851s\n",
      "\titers: 200, epoch: 17 | loss: 0.0483066\n",
      "\tspeed: 0.0341s/iter; left time: 635.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0528339 Vali Loss: 0.0536399 Test Loss: 0.0601474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0508105\n",
      "\tspeed: 0.0630s/iter; left time: 1164.2827s\n",
      "\titers: 200, epoch: 18 | loss: 0.0472548\n",
      "\tspeed: 0.0337s/iter; left time: 619.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0526830 Vali Loss: 0.0535131 Test Loss: 0.0600573\n",
      "Validation loss decreased (0.053604 --> 0.053513).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0543427\n",
      "\tspeed: 0.0631s/iter; left time: 1153.5161s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539975\n",
      "\tspeed: 0.0338s/iter; left time: 614.1322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0526239 Vali Loss: 0.0534467 Test Loss: 0.0600467\n",
      "Validation loss decreased (0.053513 --> 0.053447).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0512956\n",
      "\tspeed: 0.0653s/iter; left time: 1178.5996s\n",
      "\titers: 200, epoch: 20 | loss: 0.0518979\n",
      "\tspeed: 0.0338s/iter; left time: 606.8786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0524580 Vali Loss: 0.0534504 Test Loss: 0.0601290\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0516894\n",
      "\tspeed: 0.0621s/iter; left time: 1106.9958s\n",
      "\titers: 200, epoch: 21 | loss: 0.0514001\n",
      "\tspeed: 0.0338s/iter; left time: 599.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0523597 Vali Loss: 0.0533231 Test Loss: 0.0599976\n",
      "Validation loss decreased (0.053447 --> 0.053323).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0483420\n",
      "\tspeed: 0.0634s/iter; left time: 1114.9022s\n",
      "\titers: 200, epoch: 22 | loss: 0.0524221\n",
      "\tspeed: 0.0341s/iter; left time: 597.3589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0522725 Vali Loss: 0.0532108 Test Loss: 0.0598633\n",
      "Validation loss decreased (0.053323 --> 0.053211).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0503389\n",
      "\tspeed: 0.0634s/iter; left time: 1101.4061s\n",
      "\titers: 200, epoch: 23 | loss: 0.0539414\n",
      "\tspeed: 0.0340s/iter; left time: 587.2548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0522263 Vali Loss: 0.0532671 Test Loss: 0.0599022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0542046\n",
      "\tspeed: 0.0623s/iter; left time: 1067.7372s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510984\n",
      "\tspeed: 0.0337s/iter; left time: 574.7898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0521891 Vali Loss: 0.0531939 Test Loss: 0.0597542\n",
      "Validation loss decreased (0.053211 --> 0.053194).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0514270\n",
      "\tspeed: 0.0630s/iter; left time: 1066.0431s\n",
      "\titers: 200, epoch: 25 | loss: 0.0550747\n",
      "\tspeed: 0.0353s/iter; left time: 593.5440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0520553 Vali Loss: 0.0530766 Test Loss: 0.0597279\n",
      "Validation loss decreased (0.053194 --> 0.053077).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0486141\n",
      "\tspeed: 0.0624s/iter; left time: 1042.4930s\n",
      "\titers: 200, epoch: 26 | loss: 0.0538085\n",
      "\tspeed: 0.0337s/iter; left time: 559.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0519923 Vali Loss: 0.0531875 Test Loss: 0.0597662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0524277\n",
      "\tspeed: 0.0620s/iter; left time: 1021.5561s\n",
      "\titers: 200, epoch: 27 | loss: 0.0521245\n",
      "\tspeed: 0.0340s/iter; left time: 556.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0520323 Vali Loss: 0.0530715 Test Loss: 0.0596598\n",
      "Validation loss decreased (0.053077 --> 0.053071).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0528489\n",
      "\tspeed: 0.0635s/iter; left time: 1032.3777s\n",
      "\titers: 200, epoch: 28 | loss: 0.0528272\n",
      "\tspeed: 0.0338s/iter; left time: 545.7895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0519045 Vali Loss: 0.0530310 Test Loss: 0.0596944\n",
      "Validation loss decreased (0.053071 --> 0.053031).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0494530\n",
      "\tspeed: 0.0640s/iter; left time: 1026.1535s\n",
      "\titers: 200, epoch: 29 | loss: 0.0549773\n",
      "\tspeed: 0.0339s/iter; left time: 539.8393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0518919 Vali Loss: 0.0531214 Test Loss: 0.0597658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0509516\n",
      "\tspeed: 0.0634s/iter; left time: 1002.2817s\n",
      "\titers: 200, epoch: 30 | loss: 0.0541899\n",
      "\tspeed: 0.0340s/iter; left time: 534.1842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0518665 Vali Loss: 0.0530275 Test Loss: 0.0596586\n",
      "Validation loss decreased (0.053031 --> 0.053028).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0517120\n",
      "\tspeed: 0.0643s/iter; left time: 1001.5331s\n",
      "\titers: 200, epoch: 31 | loss: 0.0504429\n",
      "\tspeed: 0.0339s/iter; left time: 525.2424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0518409 Vali Loss: 0.0530472 Test Loss: 0.0595775\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0496667\n",
      "\tspeed: 0.0627s/iter; left time: 962.6306s\n",
      "\titers: 200, epoch: 32 | loss: 0.0514431\n",
      "\tspeed: 0.0338s/iter; left time: 516.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0518175 Vali Loss: 0.0530794 Test Loss: 0.0596468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0489944\n",
      "\tspeed: 0.0629s/iter; left time: 951.3312s\n",
      "\titers: 200, epoch: 33 | loss: 0.0532939\n",
      "\tspeed: 0.0340s/iter; left time: 511.1134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0517973 Vali Loss: 0.0530503 Test Loss: 0.0596521\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0528417\n",
      "\tspeed: 0.0622s/iter; left time: 927.0861s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519611\n",
      "\tspeed: 0.0343s/iter; left time: 508.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0517021 Vali Loss: 0.0530652 Test Loss: 0.0594816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0530752\n",
      "\tspeed: 0.0621s/iter; left time: 911.7153s\n",
      "\titers: 200, epoch: 35 | loss: 0.0518166\n",
      "\tspeed: 0.0339s/iter; left time: 493.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0517347 Vali Loss: 0.0528620 Test Loss: 0.0595123\n",
      "Validation loss decreased (0.053028 --> 0.052862).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0506464\n",
      "\tspeed: 0.0628s/iter; left time: 908.1825s\n",
      "\titers: 200, epoch: 36 | loss: 0.0517927\n",
      "\tspeed: 0.0337s/iter; left time: 483.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0516731 Vali Loss: 0.0529967 Test Loss: 0.0596204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0519233\n",
      "\tspeed: 0.0620s/iter; left time: 882.0725s\n",
      "\titers: 200, epoch: 37 | loss: 0.0506047\n",
      "\tspeed: 0.0337s/iter; left time: 477.0007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0516810 Vali Loss: 0.0530068 Test Loss: 0.0595802\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0507490\n",
      "\tspeed: 0.0626s/iter; left time: 876.5285s\n",
      "\titers: 200, epoch: 38 | loss: 0.0562936\n",
      "\tspeed: 0.0340s/iter; left time: 473.5797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0516737 Vali Loss: 0.0529319 Test Loss: 0.0594970\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0492359\n",
      "\tspeed: 0.0624s/iter; left time: 859.9221s\n",
      "\titers: 200, epoch: 39 | loss: 0.0538159\n",
      "\tspeed: 0.0340s/iter; left time: 466.0065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0516829 Vali Loss: 0.0529696 Test Loss: 0.0594831\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0513327\n",
      "\tspeed: 0.0621s/iter; left time: 842.2274s\n",
      "\titers: 200, epoch: 40 | loss: 0.0514433\n",
      "\tspeed: 0.0339s/iter; left time: 456.3563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0516562 Vali Loss: 0.0530150 Test Loss: 0.0596243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0518598\n",
      "\tspeed: 0.0626s/iter; left time: 835.4721s\n",
      "\titers: 200, epoch: 41 | loss: 0.0497989\n",
      "\tspeed: 0.0337s/iter; left time: 446.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0516688 Vali Loss: 0.0528681 Test Loss: 0.0594650\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0497980\n",
      "\tspeed: 0.0621s/iter; left time: 815.0426s\n",
      "\titers: 200, epoch: 42 | loss: 0.0535568\n",
      "\tspeed: 0.0338s/iter; left time: 439.9037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0516297 Vali Loss: 0.0529409 Test Loss: 0.0594555\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0522472\n",
      "\tspeed: 0.0624s/iter; left time: 804.6057s\n",
      "\titers: 200, epoch: 43 | loss: 0.0489027\n",
      "\tspeed: 0.0341s/iter; left time: 436.8538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0516606 Vali Loss: 0.0529695 Test Loss: 0.0595177\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0520200\n",
      "\tspeed: 0.0624s/iter; left time: 790.9626s\n",
      "\titers: 200, epoch: 44 | loss: 0.0508248\n",
      "\tspeed: 0.0339s/iter; left time: 426.7010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0515849 Vali Loss: 0.0529528 Test Loss: 0.0595244\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0524924\n",
      "\tspeed: 0.0624s/iter; left time: 776.7002s\n",
      "\titers: 200, epoch: 45 | loss: 0.0509926\n",
      "\tspeed: 0.0337s/iter; left time: 416.1641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0515887 Vali Loss: 0.0530027 Test Loss: 0.0595490\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009823016822338104, rmse:0.09911113232374191, mae:0.05951228737831116, rse:0.2916720509529114\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1579360\n",
      "\tspeed: 0.0361s/iter; left time: 804.0798s\n",
      "\titers: 200, epoch: 1 | loss: 0.1345574\n",
      "\tspeed: 0.0339s/iter; left time: 751.8680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.1544287 Vali Loss: 0.1378902 Test Loss: 0.1664125\n",
      "Validation loss decreased (inf --> 0.137890).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0723953\n",
      "\tspeed: 0.0656s/iter; left time: 1447.5926s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673680\n",
      "\tspeed: 0.0343s/iter; left time: 752.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0807752 Vali Loss: 0.0640944 Test Loss: 0.0714371\n",
      "Validation loss decreased (0.137890 --> 0.064094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0664814\n",
      "\tspeed: 0.0640s/iter; left time: 1399.1998s\n",
      "\titers: 200, epoch: 3 | loss: 0.0602823\n",
      "\tspeed: 0.0338s/iter; left time: 735.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0644568 Vali Loss: 0.0613151 Test Loss: 0.0682127\n",
      "Validation loss decreased (0.064094 --> 0.061315).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0619137\n",
      "\tspeed: 0.0638s/iter; left time: 1379.6420s\n",
      "\titers: 200, epoch: 4 | loss: 0.0629501\n",
      "\tspeed: 0.0340s/iter; left time: 731.6259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0613793 Vali Loss: 0.0588372 Test Loss: 0.0659621\n",
      "Validation loss decreased (0.061315 --> 0.058837).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0599205\n",
      "\tspeed: 0.0636s/iter; left time: 1361.2482s\n",
      "\titers: 200, epoch: 5 | loss: 0.0566143\n",
      "\tspeed: 0.0343s/iter; left time: 729.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0592500 Vali Loss: 0.0577281 Test Loss: 0.0648115\n",
      "Validation loss decreased (0.058837 --> 0.057728).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0587412\n",
      "\tspeed: 0.0646s/iter; left time: 1368.8715s\n",
      "\titers: 200, epoch: 6 | loss: 0.0555555\n",
      "\tspeed: 0.0337s/iter; left time: 710.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0577187 Vali Loss: 0.0565377 Test Loss: 0.0634899\n",
      "Validation loss decreased (0.057728 --> 0.056538).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0582398\n",
      "\tspeed: 0.0647s/iter; left time: 1355.8622s\n",
      "\titers: 200, epoch: 7 | loss: 0.0569732\n",
      "\tspeed: 0.0342s/iter; left time: 713.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0565804 Vali Loss: 0.0560253 Test Loss: 0.0630894\n",
      "Validation loss decreased (0.056538 --> 0.056025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0576674\n",
      "\tspeed: 0.0638s/iter; left time: 1323.4970s\n",
      "\titers: 200, epoch: 8 | loss: 0.0565004\n",
      "\tspeed: 0.0338s/iter; left time: 697.2153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0557787 Vali Loss: 0.0554661 Test Loss: 0.0624663\n",
      "Validation loss decreased (0.056025 --> 0.055466).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0545671\n",
      "\tspeed: 0.0644s/iter; left time: 1320.2648s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577309\n",
      "\tspeed: 0.0339s/iter; left time: 692.3419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0551741 Vali Loss: 0.0550627 Test Loss: 0.0620055\n",
      "Validation loss decreased (0.055466 --> 0.055063).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536375\n",
      "\tspeed: 0.0638s/iter; left time: 1294.8314s\n",
      "\titers: 200, epoch: 10 | loss: 0.0555455\n",
      "\tspeed: 0.0338s/iter; left time: 682.6029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0547537 Vali Loss: 0.0550868 Test Loss: 0.0618774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0518436\n",
      "\tspeed: 0.0642s/iter; left time: 1288.8872s\n",
      "\titers: 200, epoch: 11 | loss: 0.0547084\n",
      "\tspeed: 0.0338s/iter; left time: 675.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0543565 Vali Loss: 0.0546177 Test Loss: 0.0611843\n",
      "Validation loss decreased (0.055063 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567422\n",
      "\tspeed: 0.0646s/iter; left time: 1282.2327s\n",
      "\titers: 200, epoch: 12 | loss: 0.0523581\n",
      "\tspeed: 0.0345s/iter; left time: 681.3067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0540275 Vali Loss: 0.0544829 Test Loss: 0.0609822\n",
      "Validation loss decreased (0.054618 --> 0.054483).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0552673\n",
      "\tspeed: 0.0641s/iter; left time: 1257.6833s\n",
      "\titers: 200, epoch: 13 | loss: 0.0510562\n",
      "\tspeed: 0.0350s/iter; left time: 682.6441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0537494 Vali Loss: 0.0542448 Test Loss: 0.0610533\n",
      "Validation loss decreased (0.054483 --> 0.054245).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0562548\n",
      "\tspeed: 0.0641s/iter; left time: 1243.7317s\n",
      "\titers: 200, epoch: 14 | loss: 0.0558280\n",
      "\tspeed: 0.0339s/iter; left time: 654.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0534659 Vali Loss: 0.0541800 Test Loss: 0.0609532\n",
      "Validation loss decreased (0.054245 --> 0.054180).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0524575\n",
      "\tspeed: 0.0645s/iter; left time: 1236.6597s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552186\n",
      "\tspeed: 0.0342s/iter; left time: 652.7631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0533038 Vali Loss: 0.0540752 Test Loss: 0.0606174\n",
      "Validation loss decreased (0.054180 --> 0.054075).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0530639\n",
      "\tspeed: 0.0638s/iter; left time: 1208.7191s\n",
      "\titers: 200, epoch: 16 | loss: 0.0518307\n",
      "\tspeed: 0.0340s/iter; left time: 640.5706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0531068 Vali Loss: 0.0539237 Test Loss: 0.0606197\n",
      "Validation loss decreased (0.054075 --> 0.053924).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0549129\n",
      "\tspeed: 0.0634s/iter; left time: 1186.5953s\n",
      "\titers: 200, epoch: 17 | loss: 0.0486911\n",
      "\tspeed: 0.0341s/iter; left time: 634.3103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0529943 Vali Loss: 0.0538352 Test Loss: 0.0604584\n",
      "Validation loss decreased (0.053924 --> 0.053835).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0533815\n",
      "\tspeed: 0.0634s/iter; left time: 1172.0304s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563068\n",
      "\tspeed: 0.0337s/iter; left time: 620.0059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0528632 Vali Loss: 0.0536740 Test Loss: 0.0603638\n",
      "Validation loss decreased (0.053835 --> 0.053674).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0529857\n",
      "\tspeed: 0.0644s/iter; left time: 1176.9571s\n",
      "\titers: 200, epoch: 19 | loss: 0.0518051\n",
      "\tspeed: 0.0345s/iter; left time: 627.5872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0526865 Vali Loss: 0.0534223 Test Loss: 0.0601238\n",
      "Validation loss decreased (0.053674 --> 0.053422).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0509609\n",
      "\tspeed: 0.0664s/iter; left time: 1197.7934s\n",
      "\titers: 200, epoch: 20 | loss: 0.0505578\n",
      "\tspeed: 0.0340s/iter; left time: 610.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0526346 Vali Loss: 0.0535342 Test Loss: 0.0601085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0515755\n",
      "\tspeed: 0.0633s/iter; left time: 1128.2819s\n",
      "\titers: 200, epoch: 21 | loss: 0.0507104\n",
      "\tspeed: 0.0338s/iter; left time: 599.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0525259 Vali Loss: 0.0534651 Test Loss: 0.0600710\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0511437\n",
      "\tspeed: 0.0634s/iter; left time: 1115.0485s\n",
      "\titers: 200, epoch: 22 | loss: 0.0498561\n",
      "\tspeed: 0.0341s/iter; left time: 596.6270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0524205 Vali Loss: 0.0534762 Test Loss: 0.0601843\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0535026\n",
      "\tspeed: 0.0638s/iter; left time: 1108.3810s\n",
      "\titers: 200, epoch: 23 | loss: 0.0500406\n",
      "\tspeed: 0.0339s/iter; left time: 585.4355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0523597 Vali Loss: 0.0534131 Test Loss: 0.0600998\n",
      "Validation loss decreased (0.053422 --> 0.053413).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0492497\n",
      "\tspeed: 0.0636s/iter; left time: 1091.3796s\n",
      "\titers: 200, epoch: 24 | loss: 0.0506229\n",
      "\tspeed: 0.0342s/iter; left time: 582.3522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0522823 Vali Loss: 0.0532963 Test Loss: 0.0599198\n",
      "Validation loss decreased (0.053413 --> 0.053296).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0521318\n",
      "\tspeed: 0.0641s/iter; left time: 1084.4582s\n",
      "\titers: 200, epoch: 25 | loss: 0.0511510\n",
      "\tspeed: 0.0338s/iter; left time: 569.1534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0522033 Vali Loss: 0.0533299 Test Loss: 0.0599659\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0504086\n",
      "\tspeed: 0.0655s/iter; left time: 1094.5408s\n",
      "\titers: 200, epoch: 26 | loss: 0.0505698\n",
      "\tspeed: 0.0338s/iter; left time: 561.8624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0521587 Vali Loss: 0.0533623 Test Loss: 0.0599633\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0529970\n",
      "\tspeed: 0.0630s/iter; left time: 1037.4595s\n",
      "\titers: 200, epoch: 27 | loss: 0.0493081\n",
      "\tspeed: 0.0338s/iter; left time: 553.8609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0521429 Vali Loss: 0.0534271 Test Loss: 0.0600620\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0561010\n",
      "\tspeed: 0.0630s/iter; left time: 1023.9073s\n",
      "\titers: 200, epoch: 28 | loss: 0.0526673\n",
      "\tspeed: 0.0343s/iter; left time: 554.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0520879 Vali Loss: 0.0532309 Test Loss: 0.0596975\n",
      "Validation loss decreased (0.053296 --> 0.053231).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0538653\n",
      "\tspeed: 0.0646s/iter; left time: 1035.0157s\n",
      "\titers: 200, epoch: 29 | loss: 0.0507462\n",
      "\tspeed: 0.0338s/iter; left time: 538.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0520182 Vali Loss: 0.0532914 Test Loss: 0.0598624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0564779\n",
      "\tspeed: 0.0630s/iter; left time: 996.0205s\n",
      "\titers: 200, epoch: 30 | loss: 0.0513206\n",
      "\tspeed: 0.0340s/iter; left time: 534.3814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0519411 Vali Loss: 0.0531523 Test Loss: 0.0597022\n",
      "Validation loss decreased (0.053231 --> 0.053152).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0504823\n",
      "\tspeed: 0.0650s/iter; left time: 1013.0064s\n",
      "\titers: 200, epoch: 31 | loss: 0.0540285\n",
      "\tspeed: 0.0347s/iter; left time: 536.8186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0519207 Vali Loss: 0.0531699 Test Loss: 0.0596743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0498894\n",
      "\tspeed: 0.0643s/iter; left time: 988.1779s\n",
      "\titers: 200, epoch: 32 | loss: 0.0540251\n",
      "\tspeed: 0.0341s/iter; left time: 520.0592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0519015 Vali Loss: 0.0531963 Test Loss: 0.0597262\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0543305\n",
      "\tspeed: 0.0635s/iter; left time: 960.2463s\n",
      "\titers: 200, epoch: 33 | loss: 0.0495824\n",
      "\tspeed: 0.0338s/iter; left time: 508.1895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0518915 Vali Loss: 0.0531901 Test Loss: 0.0596950\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0508410\n",
      "\tspeed: 0.0629s/iter; left time: 937.3653s\n",
      "\titers: 200, epoch: 34 | loss: 0.0491989\n",
      "\tspeed: 0.0338s/iter; left time: 500.3855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0518669 Vali Loss: 0.0531966 Test Loss: 0.0597255\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0490082\n",
      "\tspeed: 0.0637s/iter; left time: 935.0894s\n",
      "\titers: 200, epoch: 35 | loss: 0.0526008\n",
      "\tspeed: 0.0340s/iter; left time: 495.3771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0518020 Vali Loss: 0.0531861 Test Loss: 0.0596925\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0554945\n",
      "\tspeed: 0.0636s/iter; left time: 920.2849s\n",
      "\titers: 200, epoch: 36 | loss: 0.0519463\n",
      "\tspeed: 0.0342s/iter; left time: 490.6210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0518643 Vali Loss: 0.0531078 Test Loss: 0.0596932\n",
      "Validation loss decreased (0.053152 --> 0.053108).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0496504\n",
      "\tspeed: 0.0642s/iter; left time: 914.6147s\n",
      "\titers: 200, epoch: 37 | loss: 0.0498719\n",
      "\tspeed: 0.0339s/iter; left time: 478.8486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0518462 Vali Loss: 0.0531845 Test Loss: 0.0596469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0510170\n",
      "\tspeed: 0.0632s/iter; left time: 885.8509s\n",
      "\titers: 200, epoch: 38 | loss: 0.0542504\n",
      "\tspeed: 0.0340s/iter; left time: 472.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0518217 Vali Loss: 0.0531203 Test Loss: 0.0596973\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0488454\n",
      "\tspeed: 0.0647s/iter; left time: 892.1316s\n",
      "\titers: 200, epoch: 39 | loss: 0.0506440\n",
      "\tspeed: 0.0345s/iter; left time: 471.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0517673 Vali Loss: 0.0530957 Test Loss: 0.0596440\n",
      "Validation loss decreased (0.053108 --> 0.053096).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0500557\n",
      "\tspeed: 0.0677s/iter; left time: 918.0741s\n",
      "\titers: 200, epoch: 40 | loss: 0.0513093\n",
      "\tspeed: 0.0343s/iter; left time: 462.1892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0517291 Vali Loss: 0.0530914 Test Loss: 0.0595172\n",
      "Validation loss decreased (0.053096 --> 0.053091).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0547261\n",
      "\tspeed: 0.0639s/iter; left time: 852.7917s\n",
      "\titers: 200, epoch: 41 | loss: 0.0481549\n",
      "\tspeed: 0.0339s/iter; left time: 449.3066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0517457 Vali Loss: 0.0530916 Test Loss: 0.0596419\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0524280\n",
      "\tspeed: 0.0630s/iter; left time: 825.7892s\n",
      "\titers: 200, epoch: 42 | loss: 0.0527511\n",
      "\tspeed: 0.0341s/iter; left time: 444.1422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0517541 Vali Loss: 0.0532012 Test Loss: 0.0597727\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0527208\n",
      "\tspeed: 0.0644s/iter; left time: 830.0778s\n",
      "\titers: 200, epoch: 43 | loss: 0.0518980\n",
      "\tspeed: 0.0346s/iter; left time: 442.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0517267 Vali Loss: 0.0529711 Test Loss: 0.0595133\n",
      "Validation loss decreased (0.053091 --> 0.052971).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0536714\n",
      "\tspeed: 0.0677s/iter; left time: 858.0545s\n",
      "\titers: 200, epoch: 44 | loss: 0.0551635\n",
      "\tspeed: 0.0341s/iter; left time: 428.2017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 224 | Train Loss: 0.0517666 Vali Loss: 0.0530981 Test Loss: 0.0596632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0518254\n",
      "\tspeed: 0.0636s/iter; left time: 791.2838s\n",
      "\titers: 200, epoch: 45 | loss: 0.0512678\n",
      "\tspeed: 0.0345s/iter; left time: 426.1934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0516751 Vali Loss: 0.0531732 Test Loss: 0.0596597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0521856\n",
      "\tspeed: 0.0635s/iter; left time: 776.6086s\n",
      "\titers: 200, epoch: 46 | loss: 0.0487361\n",
      "\tspeed: 0.0339s/iter; left time: 410.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0516208 Vali Loss: 0.0530561 Test Loss: 0.0595802\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0530450\n",
      "\tspeed: 0.0639s/iter; left time: 766.6442s\n",
      "\titers: 200, epoch: 47 | loss: 0.0445639\n",
      "\tspeed: 0.0342s/iter; left time: 407.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0516959 Vali Loss: 0.0531059 Test Loss: 0.0596224\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0539990\n",
      "\tspeed: 0.0642s/iter; left time: 756.1971s\n",
      "\titers: 200, epoch: 48 | loss: 0.0513229\n",
      "\tspeed: 0.0340s/iter; left time: 396.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0516967 Vali Loss: 0.0530909 Test Loss: 0.0596255\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0525027\n",
      "\tspeed: 0.0636s/iter; left time: 734.5643s\n",
      "\titers: 200, epoch: 49 | loss: 0.0530085\n",
      "\tspeed: 0.0339s/iter; left time: 388.6068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0516743 Vali Loss: 0.0531389 Test Loss: 0.0596946\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0477419\n",
      "\tspeed: 0.0644s/iter; left time: 729.6514s\n",
      "\titers: 200, epoch: 50 | loss: 0.0513889\n",
      "\tspeed: 0.0341s/iter; left time: 382.6163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0516918 Vali Loss: 0.0530067 Test Loss: 0.0595521\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0530295\n",
      "\tspeed: 0.0628s/iter; left time: 696.8344s\n",
      "\titers: 200, epoch: 51 | loss: 0.0510417\n",
      "\tspeed: 0.0338s/iter; left time: 371.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0516617 Vali Loss: 0.0531040 Test Loss: 0.0595510\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0517732\n",
      "\tspeed: 0.0640s/iter; left time: 696.2413s\n",
      "\titers: 200, epoch: 52 | loss: 0.0523332\n",
      "\tspeed: 0.0337s/iter; left time: 363.2735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0517148 Vali Loss: 0.0530957 Test Loss: 0.0596316\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0531154\n",
      "\tspeed: 0.0630s/iter; left time: 671.4200s\n",
      "\titers: 200, epoch: 53 | loss: 0.0505686\n",
      "\tspeed: 0.0339s/iter; left time: 357.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0516867 Vali Loss: 0.0530429 Test Loss: 0.0595754\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00980827771127224, rmse:0.09903674572706223, mae:0.059513285756111145, rse:0.29145318269729614\n",
      "Intermediate time for ES and pred_len 24: 00h:16m:11.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1583152\n",
      "\tspeed: 0.0590s/iter; left time: 1315.7724s\n",
      "\titers: 200, epoch: 1 | loss: 0.1448403\n",
      "\tspeed: 0.0342s/iter; left time: 760.0676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.1628648 Vali Loss: 0.1497765 Test Loss: 0.1801975\n",
      "Validation loss decreased (inf --> 0.149776).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0921436\n",
      "\tspeed: 0.0649s/iter; left time: 1432.1076s\n",
      "\titers: 200, epoch: 2 | loss: 0.0816166\n",
      "\tspeed: 0.0347s/iter; left time: 761.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0972727 Vali Loss: 0.0838135 Test Loss: 0.0948474\n",
      "Validation loss decreased (0.149776 --> 0.083813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829061\n",
      "\tspeed: 0.0668s/iter; left time: 1460.3469s\n",
      "\titers: 200, epoch: 3 | loss: 0.0841351\n",
      "\tspeed: 0.0345s/iter; left time: 749.5907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0835706 Vali Loss: 0.0805995 Test Loss: 0.0918064\n",
      "Validation loss decreased (0.083813 --> 0.080599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807449\n",
      "\tspeed: 0.0663s/iter; left time: 1434.2795s\n",
      "\titers: 200, epoch: 4 | loss: 0.0770914\n",
      "\tspeed: 0.0342s/iter; left time: 736.5181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0804804 Vali Loss: 0.0785825 Test Loss: 0.0897993\n",
      "Validation loss decreased (0.080599 --> 0.078583).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813333\n",
      "\tspeed: 0.0651s/iter; left time: 1394.2855s\n",
      "\titers: 200, epoch: 5 | loss: 0.0801107\n",
      "\tspeed: 0.0341s/iter; left time: 726.4598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0785711 Vali Loss: 0.0776296 Test Loss: 0.0890472\n",
      "Validation loss decreased (0.078583 --> 0.077630).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0758659\n",
      "\tspeed: 0.0660s/iter; left time: 1397.9019s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811755\n",
      "\tspeed: 0.0345s/iter; left time: 727.8188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0773020 Vali Loss: 0.0770908 Test Loss: 0.0882573\n",
      "Validation loss decreased (0.077630 --> 0.077091).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0749255\n",
      "\tspeed: 0.0656s/iter; left time: 1374.3857s\n",
      "\titers: 200, epoch: 7 | loss: 0.0767308\n",
      "\tspeed: 0.0346s/iter; left time: 720.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0764460 Vali Loss: 0.0769096 Test Loss: 0.0878721\n",
      "Validation loss decreased (0.077091 --> 0.076910).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0756682\n",
      "\tspeed: 0.0648s/iter; left time: 1342.9008s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762002\n",
      "\tspeed: 0.0345s/iter; left time: 711.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758666 Vali Loss: 0.0765788 Test Loss: 0.0876366\n",
      "Validation loss decreased (0.076910 --> 0.076579).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0734542\n",
      "\tspeed: 0.0653s/iter; left time: 1339.5656s\n",
      "\titers: 200, epoch: 9 | loss: 0.0735278\n",
      "\tspeed: 0.0346s/iter; left time: 705.7365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0753596 Vali Loss: 0.0765925 Test Loss: 0.0876100\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0753230\n",
      "\tspeed: 0.0652s/iter; left time: 1321.6367s\n",
      "\titers: 200, epoch: 10 | loss: 0.0781913\n",
      "\tspeed: 0.0345s/iter; left time: 696.4015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0748802 Vali Loss: 0.0762593 Test Loss: 0.0871955\n",
      "Validation loss decreased (0.076579 --> 0.076259).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0749062\n",
      "\tspeed: 0.0653s/iter; left time: 1310.9624s\n",
      "\titers: 200, epoch: 11 | loss: 0.0777845\n",
      "\tspeed: 0.0342s/iter; left time: 683.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0745766 Vali Loss: 0.0759519 Test Loss: 0.0867373\n",
      "Validation loss decreased (0.076259 --> 0.075952).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0746499\n",
      "\tspeed: 0.0650s/iter; left time: 1288.9790s\n",
      "\titers: 200, epoch: 12 | loss: 0.0707181\n",
      "\tspeed: 0.0342s/iter; left time: 674.8921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0741716 Vali Loss: 0.0759469 Test Loss: 0.0867018\n",
      "Validation loss decreased (0.075952 --> 0.075947).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0738060\n",
      "\tspeed: 0.0646s/iter; left time: 1267.8282s\n",
      "\titers: 200, epoch: 13 | loss: 0.0733494\n",
      "\tspeed: 0.0344s/iter; left time: 672.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0739369 Vali Loss: 0.0760515 Test Loss: 0.0871067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0706884\n",
      "\tspeed: 0.0642s/iter; left time: 1245.0887s\n",
      "\titers: 200, epoch: 14 | loss: 0.0737723\n",
      "\tspeed: 0.0349s/iter; left time: 672.7586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0736894 Vali Loss: 0.0760189 Test Loss: 0.0869981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755268\n",
      "\tspeed: 0.0648s/iter; left time: 1242.6854s\n",
      "\titers: 200, epoch: 15 | loss: 0.0732484\n",
      "\tspeed: 0.0343s/iter; left time: 653.0179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0733935 Vali Loss: 0.0757354 Test Loss: 0.0867739\n",
      "Validation loss decreased (0.075947 --> 0.075735).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715213\n",
      "\tspeed: 0.0667s/iter; left time: 1263.4738s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740862\n",
      "\tspeed: 0.0342s/iter; left time: 643.8856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0732062 Vali Loss: 0.0755924 Test Loss: 0.0867386\n",
      "Validation loss decreased (0.075735 --> 0.075592).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0706640\n",
      "\tspeed: 0.0652s/iter; left time: 1219.5419s\n",
      "\titers: 200, epoch: 17 | loss: 0.0721274\n",
      "\tspeed: 0.0343s/iter; left time: 639.0968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0730183 Vali Loss: 0.0758885 Test Loss: 0.0868945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0740165\n",
      "\tspeed: 0.0639s/iter; left time: 1181.8771s\n",
      "\titers: 200, epoch: 18 | loss: 0.0715243\n",
      "\tspeed: 0.0343s/iter; left time: 630.1533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0728788 Vali Loss: 0.0759454 Test Loss: 0.0867216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0722490\n",
      "\tspeed: 0.0646s/iter; left time: 1180.8540s\n",
      "\titers: 200, epoch: 19 | loss: 0.0700200\n",
      "\tspeed: 0.0353s/iter; left time: 642.0328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0728002 Vali Loss: 0.0754850 Test Loss: 0.0865807\n",
      "Validation loss decreased (0.075592 --> 0.075485).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0729250\n",
      "\tspeed: 0.0703s/iter; left time: 1268.5333s\n",
      "\titers: 200, epoch: 20 | loss: 0.0730267\n",
      "\tspeed: 0.0347s/iter; left time: 622.5789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 224 | Train Loss: 0.0726108 Vali Loss: 0.0756786 Test Loss: 0.0865085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0720294\n",
      "\tspeed: 0.0646s/iter; left time: 1151.0404s\n",
      "\titers: 200, epoch: 21 | loss: 0.0724624\n",
      "\tspeed: 0.0342s/iter; left time: 606.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0724719 Vali Loss: 0.0756035 Test Loss: 0.0865330\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0717145\n",
      "\tspeed: 0.0643s/iter; left time: 1131.2873s\n",
      "\titers: 200, epoch: 22 | loss: 0.0705282\n",
      "\tspeed: 0.0343s/iter; left time: 600.2867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0723564 Vali Loss: 0.0755396 Test Loss: 0.0866191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0681314\n",
      "\tspeed: 0.0647s/iter; left time: 1123.2192s\n",
      "\titers: 200, epoch: 23 | loss: 0.0691133\n",
      "\tspeed: 0.0346s/iter; left time: 598.0977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0722308 Vali Loss: 0.0756375 Test Loss: 0.0867327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0723156\n",
      "\tspeed: 0.0672s/iter; left time: 1152.0120s\n",
      "\titers: 200, epoch: 24 | loss: 0.0737724\n",
      "\tspeed: 0.0393s/iter; left time: 669.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.84s\n",
      "Steps: 224 | Train Loss: 0.0722322 Vali Loss: 0.0753499 Test Loss: 0.0864964\n",
      "Validation loss decreased (0.075485 --> 0.075350).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0734103\n",
      "\tspeed: 0.0675s/iter; left time: 1143.0537s\n",
      "\titers: 200, epoch: 25 | loss: 0.0698764\n",
      "\tspeed: 0.0355s/iter; left time: 596.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0721284 Vali Loss: 0.0755213 Test Loss: 0.0866127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0749125\n",
      "\tspeed: 0.0656s/iter; left time: 1095.3208s\n",
      "\titers: 200, epoch: 26 | loss: 0.0681941\n",
      "\tspeed: 0.0367s/iter; left time: 609.6762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 224 | Train Loss: 0.0720451 Vali Loss: 0.0755095 Test Loss: 0.0866491\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0748759\n",
      "\tspeed: 0.0644s/iter; left time: 1060.3908s\n",
      "\titers: 200, epoch: 27 | loss: 0.0692100\n",
      "\tspeed: 0.0344s/iter; left time: 563.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0719510 Vali Loss: 0.0755535 Test Loss: 0.0866617\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0701714\n",
      "\tspeed: 0.0641s/iter; left time: 1042.6154s\n",
      "\titers: 200, epoch: 28 | loss: 0.0740284\n",
      "\tspeed: 0.0348s/iter; left time: 562.0250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0718891 Vali Loss: 0.0755887 Test Loss: 0.0867537\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0725884\n",
      "\tspeed: 0.0644s/iter; left time: 1032.7483s\n",
      "\titers: 200, epoch: 29 | loss: 0.0677367\n",
      "\tspeed: 0.0345s/iter; left time: 549.8622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0718561 Vali Loss: 0.0753443 Test Loss: 0.0863624\n",
      "Validation loss decreased (0.075350 --> 0.075344).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0719654\n",
      "\tspeed: 0.0651s/iter; left time: 1028.8544s\n",
      "\titers: 200, epoch: 30 | loss: 0.0742018\n",
      "\tspeed: 0.0347s/iter; left time: 544.6679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0718349 Vali Loss: 0.0753530 Test Loss: 0.0864401\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0718995\n",
      "\tspeed: 0.0645s/iter; left time: 1004.7464s\n",
      "\titers: 200, epoch: 31 | loss: 0.0726714\n",
      "\tspeed: 0.0344s/iter; left time: 531.9041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0716989 Vali Loss: 0.0755160 Test Loss: 0.0866547\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725034\n",
      "\tspeed: 0.0642s/iter; left time: 985.9795s\n",
      "\titers: 200, epoch: 32 | loss: 0.0703748\n",
      "\tspeed: 0.0345s/iter; left time: 525.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0716934 Vali Loss: 0.0754083 Test Loss: 0.0864467\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0715083\n",
      "\tspeed: 0.0644s/iter; left time: 974.0109s\n",
      "\titers: 200, epoch: 33 | loss: 0.0704834\n",
      "\tspeed: 0.0345s/iter; left time: 518.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0716789 Vali Loss: 0.0755103 Test Loss: 0.0866822\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697350\n",
      "\tspeed: 0.0645s/iter; left time: 961.4561s\n",
      "\titers: 200, epoch: 34 | loss: 0.0721267\n",
      "\tspeed: 0.0343s/iter; left time: 508.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0716551 Vali Loss: 0.0756040 Test Loss: 0.0869137\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0750437\n",
      "\tspeed: 0.0651s/iter; left time: 955.7285s\n",
      "\titers: 200, epoch: 35 | loss: 0.0722882\n",
      "\tspeed: 0.0345s/iter; left time: 502.5394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0716405 Vali Loss: 0.0754976 Test Loss: 0.0866905\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0708376\n",
      "\tspeed: 0.0635s/iter; left time: 918.7989s\n",
      "\titers: 200, epoch: 36 | loss: 0.0717003\n",
      "\tspeed: 0.0342s/iter; left time: 491.7724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0715762 Vali Loss: 0.0754502 Test Loss: 0.0866363\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0710196\n",
      "\tspeed: 0.0658s/iter; left time: 937.1543s\n",
      "\titers: 200, epoch: 37 | loss: 0.0715786\n",
      "\tspeed: 0.0345s/iter; left time: 488.3489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0715935 Vali Loss: 0.0754666 Test Loss: 0.0865808\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0731768\n",
      "\tspeed: 0.0644s/iter; left time: 902.1619s\n",
      "\titers: 200, epoch: 38 | loss: 0.0697412\n",
      "\tspeed: 0.0349s/iter; left time: 485.1953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0715302 Vali Loss: 0.0754760 Test Loss: 0.0866731\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0720512\n",
      "\tspeed: 0.0649s/iter; left time: 894.4278s\n",
      "\titers: 200, epoch: 39 | loss: 0.0706587\n",
      "\tspeed: 0.0342s/iter; left time: 468.5931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0715180 Vali Loss: 0.0755162 Test Loss: 0.0867972\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0185981597751379, rmse:0.1363750696182251, mae:0.08636235445737839, rse:0.4006288945674896\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1582830\n",
      "\tspeed: 0.0364s/iter; left time: 811.4456s\n",
      "\titers: 200, epoch: 1 | loss: 0.1536793\n",
      "\tspeed: 0.0348s/iter; left time: 773.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1618317 Vali Loss: 0.1495777 Test Loss: 0.1801662\n",
      "Validation loss decreased (inf --> 0.149578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0939178\n",
      "\tspeed: 0.0676s/iter; left time: 1492.5444s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864733\n",
      "\tspeed: 0.0343s/iter; left time: 754.0109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0985453 Vali Loss: 0.0839609 Test Loss: 0.0956050\n",
      "Validation loss decreased (0.149578 --> 0.083961).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878430\n",
      "\tspeed: 0.0650s/iter; left time: 1421.2057s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782254\n",
      "\tspeed: 0.0343s/iter; left time: 746.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0840291 Vali Loss: 0.0807863 Test Loss: 0.0920472\n",
      "Validation loss decreased (0.083961 --> 0.080786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836028\n",
      "\tspeed: 0.0667s/iter; left time: 1443.3118s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806706\n",
      "\tspeed: 0.0344s/iter; left time: 740.8030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0807939 Vali Loss: 0.0788258 Test Loss: 0.0900378\n",
      "Validation loss decreased (0.080786 --> 0.078826).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788435\n",
      "\tspeed: 0.0668s/iter; left time: 1429.3499s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807367\n",
      "\tspeed: 0.0344s/iter; left time: 732.5102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0788217 Vali Loss: 0.0780139 Test Loss: 0.0892532\n",
      "Validation loss decreased (0.078826 --> 0.078014).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0773067\n",
      "\tspeed: 0.0666s/iter; left time: 1410.2190s\n",
      "\titers: 200, epoch: 6 | loss: 0.0772312\n",
      "\tspeed: 0.0343s/iter; left time: 723.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0775746 Vali Loss: 0.0777914 Test Loss: 0.0886277\n",
      "Validation loss decreased (0.078014 --> 0.077791).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0767768\n",
      "\tspeed: 0.0656s/iter; left time: 1375.0271s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746151\n",
      "\tspeed: 0.0344s/iter; left time: 718.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0767128 Vali Loss: 0.0770210 Test Loss: 0.0880919\n",
      "Validation loss decreased (0.077791 --> 0.077021).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772053\n",
      "\tspeed: 0.0660s/iter; left time: 1368.8719s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728543\n",
      "\tspeed: 0.0344s/iter; left time: 708.8748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0759991 Vali Loss: 0.0769128 Test Loss: 0.0879381\n",
      "Validation loss decreased (0.077021 --> 0.076913).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0746797\n",
      "\tspeed: 0.0672s/iter; left time: 1378.6858s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793813\n",
      "\tspeed: 0.0348s/iter; left time: 711.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0754255 Vali Loss: 0.0765287 Test Loss: 0.0876836\n",
      "Validation loss decreased (0.076913 --> 0.076529).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0778281\n",
      "\tspeed: 0.0663s/iter; left time: 1345.0732s\n",
      "\titers: 200, epoch: 10 | loss: 0.0760081\n",
      "\tspeed: 0.0344s/iter; left time: 695.0386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0749424 Vali Loss: 0.0765791 Test Loss: 0.0876946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761849\n",
      "\tspeed: 0.0648s/iter; left time: 1300.8232s\n",
      "\titers: 200, epoch: 11 | loss: 0.0759281\n",
      "\tspeed: 0.0346s/iter; left time: 691.4679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0745479 Vali Loss: 0.0765141 Test Loss: 0.0871809\n",
      "Validation loss decreased (0.076529 --> 0.076514).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0740213\n",
      "\tspeed: 0.0666s/iter; left time: 1321.0962s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729842\n",
      "\tspeed: 0.0344s/iter; left time: 678.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0742243 Vali Loss: 0.0766330 Test Loss: 0.0873586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0739172\n",
      "\tspeed: 0.0649s/iter; left time: 1273.3946s\n",
      "\titers: 200, epoch: 13 | loss: 0.0755008\n",
      "\tspeed: 0.0345s/iter; left time: 672.4258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0739385 Vali Loss: 0.0763564 Test Loss: 0.0872647\n",
      "Validation loss decreased (0.076514 --> 0.076356).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0703849\n",
      "\tspeed: 0.0656s/iter; left time: 1272.8350s\n",
      "\titers: 200, epoch: 14 | loss: 0.0713772\n",
      "\tspeed: 0.0343s/iter; left time: 662.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0736357 Vali Loss: 0.0765072 Test Loss: 0.0869802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0685526\n",
      "\tspeed: 0.0653s/iter; left time: 1252.1004s\n",
      "\titers: 200, epoch: 15 | loss: 0.0744490\n",
      "\tspeed: 0.0346s/iter; left time: 660.5611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0733645 Vali Loss: 0.0765096 Test Loss: 0.0869906\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0745860\n",
      "\tspeed: 0.0646s/iter; left time: 1223.7277s\n",
      "\titers: 200, epoch: 16 | loss: 0.0714565\n",
      "\tspeed: 0.0341s/iter; left time: 642.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0731870 Vali Loss: 0.0763907 Test Loss: 0.0867740\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0767808\n",
      "\tspeed: 0.0648s/iter; left time: 1212.7443s\n",
      "\titers: 200, epoch: 17 | loss: 0.0734670\n",
      "\tspeed: 0.0343s/iter; left time: 638.6161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0729853 Vali Loss: 0.0765046 Test Loss: 0.0869768\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0747071\n",
      "\tspeed: 0.0653s/iter; left time: 1207.1564s\n",
      "\titers: 200, epoch: 18 | loss: 0.0728723\n",
      "\tspeed: 0.0345s/iter; left time: 635.3889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0727439 Vali Loss: 0.0765303 Test Loss: 0.0870398\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0708978\n",
      "\tspeed: 0.0651s/iter; left time: 1190.1975s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723809\n",
      "\tspeed: 0.0350s/iter; left time: 635.0696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0725793 Vali Loss: 0.0764471 Test Loss: 0.0870042\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0734421\n",
      "\tspeed: 0.0665s/iter; left time: 1200.1180s\n",
      "\titers: 200, epoch: 20 | loss: 0.0769663\n",
      "\tspeed: 0.0344s/iter; left time: 617.9313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0725307 Vali Loss: 0.0765048 Test Loss: 0.0870345\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0716774\n",
      "\tspeed: 0.0657s/iter; left time: 1170.1201s\n",
      "\titers: 200, epoch: 21 | loss: 0.0718850\n",
      "\tspeed: 0.0343s/iter; left time: 607.0500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0723870 Vali Loss: 0.0766452 Test Loss: 0.0869602\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0720396\n",
      "\tspeed: 0.0660s/iter; left time: 1161.1070s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696126\n",
      "\tspeed: 0.0343s/iter; left time: 600.0298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0722414 Vali Loss: 0.0765089 Test Loss: 0.0867656\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0730018\n",
      "\tspeed: 0.0653s/iter; left time: 1134.6921s\n",
      "\titers: 200, epoch: 23 | loss: 0.0753521\n",
      "\tspeed: 0.0345s/iter; left time: 595.4149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0721670 Vali Loss: 0.0766542 Test Loss: 0.0870228\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018632538616657257, rmse:0.13650105893611908, mae:0.08726463466882706, rse:0.4009990394115448\n",
      "Intermediate time for ES and pred_len 96: 00h:10m:32.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1581242\n",
      "\tspeed: 0.0630s/iter; left time: 1398.1511s\n",
      "\titers: 200, epoch: 1 | loss: 0.1507171\n",
      "\tspeed: 0.0350s/iter; left time: 773.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 223 | Train Loss: 0.1638708 Vali Loss: 0.1523550 Test Loss: 0.1819388\n",
      "Validation loss decreased (inf --> 0.152355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986643\n",
      "\tspeed: 0.0665s/iter; left time: 1460.6345s\n",
      "\titers: 200, epoch: 2 | loss: 0.0934433\n",
      "\tspeed: 0.0348s/iter; left time: 761.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1013446 Vali Loss: 0.0890421 Test Loss: 0.1011388\n",
      "Validation loss decreased (0.152355 --> 0.089042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0940395\n",
      "\tspeed: 0.0650s/iter; left time: 1414.3198s\n",
      "\titers: 200, epoch: 3 | loss: 0.0868575\n",
      "\tspeed: 0.0350s/iter; left time: 757.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0888059 Vali Loss: 0.0860402 Test Loss: 0.0980579\n",
      "Validation loss decreased (0.089042 --> 0.086040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0851304\n",
      "\tspeed: 0.0664s/iter; left time: 1429.6060s\n",
      "\titers: 200, epoch: 4 | loss: 0.0841597\n",
      "\tspeed: 0.0352s/iter; left time: 755.3775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0857711 Vali Loss: 0.0841981 Test Loss: 0.0959112\n",
      "Validation loss decreased (0.086040 --> 0.084198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0825492\n",
      "\tspeed: 0.0656s/iter; left time: 1396.8516s\n",
      "\titers: 200, epoch: 5 | loss: 0.0825241\n",
      "\tspeed: 0.0349s/iter; left time: 740.3545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0838901 Vali Loss: 0.0835975 Test Loss: 0.0951364\n",
      "Validation loss decreased (0.084198 --> 0.083597).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831312\n",
      "\tspeed: 0.0659s/iter; left time: 1390.0068s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821218\n",
      "\tspeed: 0.0347s/iter; left time: 727.3247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0827609 Vali Loss: 0.0835203 Test Loss: 0.0949269\n",
      "Validation loss decreased (0.083597 --> 0.083520).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0847962\n",
      "\tspeed: 0.0659s/iter; left time: 1374.9758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0801695\n",
      "\tspeed: 0.0348s/iter; left time: 722.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0820128 Vali Loss: 0.0828906 Test Loss: 0.0942042\n",
      "Validation loss decreased (0.083520 --> 0.082891).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826582\n",
      "\tspeed: 0.0663s/iter; left time: 1368.6312s\n",
      "\titers: 200, epoch: 8 | loss: 0.0829372\n",
      "\tspeed: 0.0352s/iter; left time: 722.6593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0813807 Vali Loss: 0.0829064 Test Loss: 0.0940305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0785602\n",
      "\tspeed: 0.0652s/iter; left time: 1331.3931s\n",
      "\titers: 200, epoch: 9 | loss: 0.0813846\n",
      "\tspeed: 0.0354s/iter; left time: 719.0891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0808702 Vali Loss: 0.0826419 Test Loss: 0.0939117\n",
      "Validation loss decreased (0.082891 --> 0.082642).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0784310\n",
      "\tspeed: 0.0663s/iter; left time: 1338.8498s\n",
      "\titers: 200, epoch: 10 | loss: 0.0772360\n",
      "\tspeed: 0.0350s/iter; left time: 703.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0803654 Vali Loss: 0.0824731 Test Loss: 0.0937046\n",
      "Validation loss decreased (0.082642 --> 0.082473).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0798821\n",
      "\tspeed: 0.0665s/iter; left time: 1328.1396s\n",
      "\titers: 200, epoch: 11 | loss: 0.0784780\n",
      "\tspeed: 0.0348s/iter; left time: 691.3370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0799386 Vali Loss: 0.0822538 Test Loss: 0.0935915\n",
      "Validation loss decreased (0.082473 --> 0.082254).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0809544\n",
      "\tspeed: 0.0666s/iter; left time: 1315.2420s\n",
      "\titers: 200, epoch: 12 | loss: 0.0804690\n",
      "\tspeed: 0.0348s/iter; left time: 684.4643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0795472 Vali Loss: 0.0822670 Test Loss: 0.0936214\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0796984\n",
      "\tspeed: 0.0646s/iter; left time: 1260.7374s\n",
      "\titers: 200, epoch: 13 | loss: 0.0766402\n",
      "\tspeed: 0.0346s/iter; left time: 672.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0792191 Vali Loss: 0.0818180 Test Loss: 0.0939182\n",
      "Validation loss decreased (0.082254 --> 0.081818).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0797491\n",
      "\tspeed: 0.0659s/iter; left time: 1272.3367s\n",
      "\titers: 200, epoch: 14 | loss: 0.0768970\n",
      "\tspeed: 0.0353s/iter; left time: 677.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0789267 Vali Loss: 0.0818768 Test Loss: 0.0939726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793521\n",
      "\tspeed: 0.0649s/iter; left time: 1238.7376s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760051\n",
      "\tspeed: 0.0348s/iter; left time: 660.7859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0786685 Vali Loss: 0.0820166 Test Loss: 0.0940066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786998\n",
      "\tspeed: 0.0647s/iter; left time: 1220.3448s\n",
      "\titers: 200, epoch: 16 | loss: 0.0790844\n",
      "\tspeed: 0.0347s/iter; left time: 650.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0784924 Vali Loss: 0.0818277 Test Loss: 0.0944564\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0776468\n",
      "\tspeed: 0.0649s/iter; left time: 1209.4681s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762781\n",
      "\tspeed: 0.0349s/iter; left time: 646.4701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0782404 Vali Loss: 0.0818648 Test Loss: 0.0947103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0797928\n",
      "\tspeed: 0.0645s/iter; left time: 1187.7365s\n",
      "\titers: 200, epoch: 18 | loss: 0.0767054\n",
      "\tspeed: 0.0347s/iter; left time: 636.0733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0780503 Vali Loss: 0.0820865 Test Loss: 0.0952556\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800530\n",
      "\tspeed: 0.0650s/iter; left time: 1183.0390s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773672\n",
      "\tspeed: 0.0347s/iter; left time: 627.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0779013 Vali Loss: 0.0819001 Test Loss: 0.0952660\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764023\n",
      "\tspeed: 0.0641s/iter; left time: 1151.3233s\n",
      "\titers: 200, epoch: 20 | loss: 0.0789287\n",
      "\tspeed: 0.0352s/iter; left time: 628.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0777259 Vali Loss: 0.0817606 Test Loss: 0.0951863\n",
      "Validation loss decreased (0.081818 --> 0.081761).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766384\n",
      "\tspeed: 0.0668s/iter; left time: 1184.6482s\n",
      "\titers: 200, epoch: 21 | loss: 0.0782197\n",
      "\tspeed: 0.0350s/iter; left time: 618.2103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0775856 Vali Loss: 0.0819180 Test Loss: 0.0953271\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756970\n",
      "\tspeed: 0.0649s/iter; left time: 1136.2370s\n",
      "\titers: 200, epoch: 22 | loss: 0.0782074\n",
      "\tspeed: 0.0351s/iter; left time: 612.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0774701 Vali Loss: 0.0816166 Test Loss: 0.0955943\n",
      "Validation loss decreased (0.081761 --> 0.081617).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767044\n",
      "\tspeed: 0.0674s/iter; left time: 1166.2206s\n",
      "\titers: 200, epoch: 23 | loss: 0.0780989\n",
      "\tspeed: 0.0359s/iter; left time: 616.7085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 223 | Train Loss: 0.0773348 Vali Loss: 0.0818224 Test Loss: 0.0957033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0800862\n",
      "\tspeed: 0.0653s/iter; left time: 1113.9552s\n",
      "\titers: 200, epoch: 24 | loss: 0.0712628\n",
      "\tspeed: 0.0350s/iter; left time: 593.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0772094 Vali Loss: 0.0816642 Test Loss: 0.0957151\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0788048\n",
      "\tspeed: 0.0663s/iter; left time: 1117.1215s\n",
      "\titers: 200, epoch: 25 | loss: 0.0728152\n",
      "\tspeed: 0.0351s/iter; left time: 587.2085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0771515 Vali Loss: 0.0817642 Test Loss: 0.0957897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0781624\n",
      "\tspeed: 0.0663s/iter; left time: 1102.8555s\n",
      "\titers: 200, epoch: 26 | loss: 0.0739947\n",
      "\tspeed: 0.0347s/iter; left time: 574.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0770992 Vali Loss: 0.0816698 Test Loss: 0.0958092\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0785158\n",
      "\tspeed: 0.0649s/iter; left time: 1064.3347s\n",
      "\titers: 200, epoch: 27 | loss: 0.0776058\n",
      "\tspeed: 0.0347s/iter; left time: 565.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0770031 Vali Loss: 0.0817289 Test Loss: 0.0957823\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762650\n",
      "\tspeed: 0.0653s/iter; left time: 1057.1673s\n",
      "\titers: 200, epoch: 28 | loss: 0.0730262\n",
      "\tspeed: 0.0354s/iter; left time: 568.6214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0769375 Vali Loss: 0.0817190 Test Loss: 0.0960716\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0779013\n",
      "\tspeed: 0.0659s/iter; left time: 1050.9776s\n",
      "\titers: 200, epoch: 29 | loss: 0.0780241\n",
      "\tspeed: 0.0350s/iter; left time: 555.0852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0768650 Vali Loss: 0.0818699 Test Loss: 0.0961976\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0775625\n",
      "\tspeed: 0.0642s/iter; left time: 1010.3148s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751118\n",
      "\tspeed: 0.0346s/iter; left time: 540.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0768085 Vali Loss: 0.0818688 Test Loss: 0.0963391\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0737045\n",
      "\tspeed: 0.0643s/iter; left time: 997.6590s\n",
      "\titers: 200, epoch: 31 | loss: 0.0770995\n",
      "\tspeed: 0.0354s/iter; left time: 545.2687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0767635 Vali Loss: 0.0816762 Test Loss: 0.0960850\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0781929\n",
      "\tspeed: 0.0646s/iter; left time: 986.8986s\n",
      "\titers: 200, epoch: 32 | loss: 0.0797998\n",
      "\tspeed: 0.0348s/iter; left time: 528.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0767546 Vali Loss: 0.0817475 Test Loss: 0.0963959\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02126566879451275, rmse:0.1458275318145752, mae:0.0955943912267685, rse:0.42842817306518555\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1622073\n",
      "\tspeed: 0.0371s/iter; left time: 822.8089s\n",
      "\titers: 200, epoch: 1 | loss: 0.1511776\n",
      "\tspeed: 0.0350s/iter; left time: 773.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1635544 Vali Loss: 0.1513875 Test Loss: 0.1804619\n",
      "Validation loss decreased (inf --> 0.151388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0963681\n",
      "\tspeed: 0.0682s/iter; left time: 1497.8571s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897276\n",
      "\tspeed: 0.0349s/iter; left time: 762.4773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.1009506 Vali Loss: 0.0887425 Test Loss: 0.1008672\n",
      "Validation loss decreased (0.151388 --> 0.088743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0909871\n",
      "\tspeed: 0.0676s/iter; left time: 1470.1090s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840339\n",
      "\tspeed: 0.0362s/iter; left time: 784.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 223 | Train Loss: 0.0886917 Vali Loss: 0.0861339 Test Loss: 0.0982522\n",
      "Validation loss decreased (0.088743 --> 0.086134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863238\n",
      "\tspeed: 0.0671s/iter; left time: 1444.2573s\n",
      "\titers: 200, epoch: 4 | loss: 0.0863077\n",
      "\tspeed: 0.0350s/iter; left time: 749.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0857665 Vali Loss: 0.0844378 Test Loss: 0.0962862\n",
      "Validation loss decreased (0.086134 --> 0.084438).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0852887\n",
      "\tspeed: 0.0672s/iter; left time: 1432.6733s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826804\n",
      "\tspeed: 0.0346s/iter; left time: 733.8268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0839180 Vali Loss: 0.0839240 Test Loss: 0.0957661\n",
      "Validation loss decreased (0.084438 --> 0.083924).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0836342\n",
      "\tspeed: 0.0671s/iter; left time: 1414.6025s\n",
      "\titers: 200, epoch: 6 | loss: 0.0806390\n",
      "\tspeed: 0.0348s/iter; left time: 730.6954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0828160 Vali Loss: 0.0837571 Test Loss: 0.0950037\n",
      "Validation loss decreased (0.083924 --> 0.083757).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0857420\n",
      "\tspeed: 0.0674s/iter; left time: 1405.2264s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848666\n",
      "\tspeed: 0.0347s/iter; left time: 720.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0820557 Vali Loss: 0.0831144 Test Loss: 0.0942615\n",
      "Validation loss decreased (0.083757 --> 0.083114).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834368\n",
      "\tspeed: 0.0689s/iter; left time: 1422.0157s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797058\n",
      "\tspeed: 0.0348s/iter; left time: 714.0920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0814393 Vali Loss: 0.0832333 Test Loss: 0.0942153\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792525\n",
      "\tspeed: 0.0663s/iter; left time: 1352.6476s\n",
      "\titers: 200, epoch: 9 | loss: 0.0831456\n",
      "\tspeed: 0.0348s/iter; left time: 707.7840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0809265 Vali Loss: 0.0834103 Test Loss: 0.0940458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0839281\n",
      "\tspeed: 0.0674s/iter; left time: 1361.9193s\n",
      "\titers: 200, epoch: 10 | loss: 0.0820906\n",
      "\tspeed: 0.0355s/iter; left time: 713.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 223 | Train Loss: 0.0804400 Vali Loss: 0.0831343 Test Loss: 0.0936590\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0800651\n",
      "\tspeed: 0.0664s/iter; left time: 1327.0249s\n",
      "\titers: 200, epoch: 11 | loss: 0.0795596\n",
      "\tspeed: 0.0359s/iter; left time: 713.8801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0799918 Vali Loss: 0.0829600 Test Loss: 0.0931671\n",
      "Validation loss decreased (0.083114 --> 0.082960).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0811823\n",
      "\tspeed: 0.0672s/iter; left time: 1327.9084s\n",
      "\titers: 200, epoch: 12 | loss: 0.0830218\n",
      "\tspeed: 0.0348s/iter; left time: 683.5517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0796409 Vali Loss: 0.0829638 Test Loss: 0.0932920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763461\n",
      "\tspeed: 0.0670s/iter; left time: 1309.0778s\n",
      "\titers: 200, epoch: 13 | loss: 0.0818228\n",
      "\tspeed: 0.0361s/iter; left time: 700.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 223 | Train Loss: 0.0793178 Vali Loss: 0.0828459 Test Loss: 0.0931148\n",
      "Validation loss decreased (0.082960 --> 0.082846).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0800062\n",
      "\tspeed: 0.0693s/iter; left time: 1337.6314s\n",
      "\titers: 200, epoch: 14 | loss: 0.0819832\n",
      "\tspeed: 0.0354s/iter; left time: 679.0999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.31s\n",
      "Steps: 223 | Train Loss: 0.0789994 Vali Loss: 0.0825182 Test Loss: 0.0933117\n",
      "Validation loss decreased (0.082846 --> 0.082518).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0812188\n",
      "\tspeed: 0.0686s/iter; left time: 1309.6940s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769876\n",
      "\tspeed: 0.0349s/iter; left time: 663.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0787149 Vali Loss: 0.0826182 Test Loss: 0.0934537\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786891\n",
      "\tspeed: 0.0663s/iter; left time: 1249.6553s\n",
      "\titers: 200, epoch: 16 | loss: 0.0829321\n",
      "\tspeed: 0.0345s/iter; left time: 647.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0785222 Vali Loss: 0.0824578 Test Loss: 0.0933246\n",
      "Validation loss decreased (0.082518 --> 0.082458).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0766105\n",
      "\tspeed: 0.0677s/iter; left time: 1260.6527s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775430\n",
      "\tspeed: 0.0347s/iter; left time: 643.4154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0782164 Vali Loss: 0.0823364 Test Loss: 0.0936304\n",
      "Validation loss decreased (0.082458 --> 0.082336).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0737783\n",
      "\tspeed: 0.0674s/iter; left time: 1240.6921s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795119\n",
      "\tspeed: 0.0345s/iter; left time: 632.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0780388 Vali Loss: 0.0823434 Test Loss: 0.0939227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0779562\n",
      "\tspeed: 0.0665s/iter; left time: 1209.5024s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744572\n",
      "\tspeed: 0.0346s/iter; left time: 625.9008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0778180 Vali Loss: 0.0823256 Test Loss: 0.0938507\n",
      "Validation loss decreased (0.082336 --> 0.082326).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811709\n",
      "\tspeed: 0.0667s/iter; left time: 1198.8429s\n",
      "\titers: 200, epoch: 20 | loss: 0.0786681\n",
      "\tspeed: 0.0347s/iter; left time: 619.0352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0775951 Vali Loss: 0.0823114 Test Loss: 0.0941019\n",
      "Validation loss decreased (0.082326 --> 0.082311).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0748576\n",
      "\tspeed: 0.0672s/iter; left time: 1192.0376s\n",
      "\titers: 200, epoch: 21 | loss: 0.0787515\n",
      "\tspeed: 0.0346s/iter; left time: 609.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0774586 Vali Loss: 0.0820314 Test Loss: 0.0940175\n",
      "Validation loss decreased (0.082311 --> 0.082031).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0802003\n",
      "\tspeed: 0.0675s/iter; left time: 1183.2490s\n",
      "\titers: 200, epoch: 22 | loss: 0.0754237\n",
      "\tspeed: 0.0349s/iter; left time: 607.2937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0773000 Vali Loss: 0.0820159 Test Loss: 0.0942531\n",
      "Validation loss decreased (0.082031 --> 0.082016).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0779743\n",
      "\tspeed: 0.0677s/iter; left time: 1171.6439s\n",
      "\titers: 200, epoch: 23 | loss: 0.0747215\n",
      "\tspeed: 0.0346s/iter; left time: 594.9294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0772234 Vali Loss: 0.0822244 Test Loss: 0.0947550\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0775924\n",
      "\tspeed: 0.0677s/iter; left time: 1154.9276s\n",
      "\titers: 200, epoch: 24 | loss: 0.0774336\n",
      "\tspeed: 0.0345s/iter; left time: 585.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0770066 Vali Loss: 0.0819901 Test Loss: 0.0946638\n",
      "Validation loss decreased (0.082016 --> 0.081990).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0765772\n",
      "\tspeed: 0.0681s/iter; left time: 1147.0967s\n",
      "\titers: 200, epoch: 25 | loss: 0.0774296\n",
      "\tspeed: 0.0351s/iter; left time: 587.2769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0769184 Vali Loss: 0.0818508 Test Loss: 0.0945564\n",
      "Validation loss decreased (0.081990 --> 0.081851).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0752274\n",
      "\tspeed: 0.0680s/iter; left time: 1131.3903s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780611\n",
      "\tspeed: 0.0353s/iter; left time: 583.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0768677 Vali Loss: 0.0820124 Test Loss: 0.0949415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0767367\n",
      "\tspeed: 0.0657s/iter; left time: 1077.5556s\n",
      "\titers: 200, epoch: 27 | loss: 0.0761459\n",
      "\tspeed: 0.0345s/iter; left time: 562.0168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0767765 Vali Loss: 0.0820813 Test Loss: 0.0948841\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0743221\n",
      "\tspeed: 0.0661s/iter; left time: 1069.9981s\n",
      "\titers: 200, epoch: 28 | loss: 0.0752958\n",
      "\tspeed: 0.0345s/iter; left time: 554.8820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0767860 Vali Loss: 0.0819307 Test Loss: 0.0946716\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0782983\n",
      "\tspeed: 0.0670s/iter; left time: 1069.5213s\n",
      "\titers: 200, epoch: 29 | loss: 0.0778854\n",
      "\tspeed: 0.0349s/iter; left time: 553.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0766185 Vali Loss: 0.0818122 Test Loss: 0.0950429\n",
      "Validation loss decreased (0.081851 --> 0.081812).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0740042\n",
      "\tspeed: 0.0677s/iter; left time: 1065.8825s\n",
      "\titers: 200, epoch: 30 | loss: 0.0801981\n",
      "\tspeed: 0.0350s/iter; left time: 547.0448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0765305 Vali Loss: 0.0820920 Test Loss: 0.0952042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0767182\n",
      "\tspeed: 0.0665s/iter; left time: 1031.8913s\n",
      "\titers: 200, epoch: 31 | loss: 0.0758625\n",
      "\tspeed: 0.0351s/iter; left time: 540.7807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0765871 Vali Loss: 0.0818485 Test Loss: 0.0951992\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0781168\n",
      "\tspeed: 0.0664s/iter; left time: 1015.8220s\n",
      "\titers: 200, epoch: 32 | loss: 0.0793877\n",
      "\tspeed: 0.0346s/iter; left time: 526.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0764493 Vali Loss: 0.0820237 Test Loss: 0.0955673\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0740315\n",
      "\tspeed: 0.0673s/iter; left time: 1013.5381s\n",
      "\titers: 200, epoch: 33 | loss: 0.0757111\n",
      "\tspeed: 0.0351s/iter; left time: 524.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0763936 Vali Loss: 0.0819379 Test Loss: 0.0954416\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0753173\n",
      "\tspeed: 0.0661s/iter; left time: 980.3859s\n",
      "\titers: 200, epoch: 34 | loss: 0.0706699\n",
      "\tspeed: 0.0349s/iter; left time: 514.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0763890 Vali Loss: 0.0819006 Test Loss: 0.0955024\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0773871\n",
      "\tspeed: 0.0662s/iter; left time: 967.3064s\n",
      "\titers: 200, epoch: 35 | loss: 0.0741799\n",
      "\tspeed: 0.0345s/iter; left time: 500.8015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0763201 Vali Loss: 0.0818680 Test Loss: 0.0954335\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0785499\n",
      "\tspeed: 0.0665s/iter; left time: 957.3399s\n",
      "\titers: 200, epoch: 36 | loss: 0.0738299\n",
      "\tspeed: 0.0347s/iter; left time: 496.5049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0762440 Vali Loss: 0.0819575 Test Loss: 0.0954877\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755313\n",
      "\tspeed: 0.0661s/iter; left time: 936.3916s\n",
      "\titers: 200, epoch: 37 | loss: 0.0735468\n",
      "\tspeed: 0.0349s/iter; left time: 490.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0762236 Vali Loss: 0.0820155 Test Loss: 0.0955825\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0732269\n",
      "\tspeed: 0.0662s/iter; left time: 923.8246s\n",
      "\titers: 200, epoch: 38 | loss: 0.0770698\n",
      "\tspeed: 0.0347s/iter; left time: 480.0003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0762167 Vali Loss: 0.0818996 Test Loss: 0.0954762\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765640\n",
      "\tspeed: 0.0650s/iter; left time: 892.6714s\n",
      "\titers: 200, epoch: 39 | loss: 0.0754804\n",
      "\tspeed: 0.0345s/iter; left time: 469.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0761922 Vali Loss: 0.0818792 Test Loss: 0.0953627\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02110309898853302, rmse:0.14526905119419098, mae:0.09504284709692001, rse:0.42678743600845337\n",
      "Intermediate time for ES and pred_len 168: 00h:12m:12.76s\n",
      "Intermediate time for ES: 00h:38m:56.89s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116106\n",
      "\tspeed: 0.0593s/iter; left time: 1322.9017s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999537\n",
      "\tspeed: 0.0341s/iter; left time: 758.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.1124358 Vali Loss: 0.1140086 Test Loss: 0.1257845\n",
      "Validation loss decreased (inf --> 0.114009).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0549609\n",
      "\tspeed: 0.0642s/iter; left time: 1417.1195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0493058\n",
      "\tspeed: 0.0343s/iter; left time: 752.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0611678 Vali Loss: 0.0598257 Test Loss: 0.0630514\n",
      "Validation loss decreased (0.114009 --> 0.059826).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0481192\n",
      "\tspeed: 0.0647s/iter; left time: 1413.7064s\n",
      "\titers: 200, epoch: 3 | loss: 0.0486705\n",
      "\tspeed: 0.0340s/iter; left time: 738.6109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0486903 Vali Loss: 0.0571938 Test Loss: 0.0604145\n",
      "Validation loss decreased (0.059826 --> 0.057194).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0446055\n",
      "\tspeed: 0.0648s/iter; left time: 1401.1282s\n",
      "\titers: 200, epoch: 4 | loss: 0.0433150\n",
      "\tspeed: 0.0340s/iter; left time: 732.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0464468 Vali Loss: 0.0553259 Test Loss: 0.0587835\n",
      "Validation loss decreased (0.057194 --> 0.055326).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0416506\n",
      "\tspeed: 0.0644s/iter; left time: 1378.7821s\n",
      "\titers: 200, epoch: 5 | loss: 0.0478258\n",
      "\tspeed: 0.0339s/iter; left time: 722.4945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0450221 Vali Loss: 0.0544317 Test Loss: 0.0578488\n",
      "Validation loss decreased (0.055326 --> 0.054432).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0430584\n",
      "\tspeed: 0.0646s/iter; left time: 1368.2821s\n",
      "\titers: 200, epoch: 6 | loss: 0.0435158\n",
      "\tspeed: 0.0340s/iter; left time: 717.5696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0438523 Vali Loss: 0.0536000 Test Loss: 0.0572354\n",
      "Validation loss decreased (0.054432 --> 0.053600).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0451543\n",
      "\tspeed: 0.0637s/iter; left time: 1335.1167s\n",
      "\titers: 200, epoch: 7 | loss: 0.0420685\n",
      "\tspeed: 0.0340s/iter; left time: 709.9499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0432100 Vali Loss: 0.0533147 Test Loss: 0.0569039\n",
      "Validation loss decreased (0.053600 --> 0.053315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0422426\n",
      "\tspeed: 0.0653s/iter; left time: 1354.6848s\n",
      "\titers: 200, epoch: 8 | loss: 0.0431216\n",
      "\tspeed: 0.0342s/iter; left time: 705.7998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0426419 Vali Loss: 0.0527611 Test Loss: 0.0564472\n",
      "Validation loss decreased (0.053315 --> 0.052761).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0423509\n",
      "\tspeed: 0.0648s/iter; left time: 1329.3455s\n",
      "\titers: 200, epoch: 9 | loss: 0.0432939\n",
      "\tspeed: 0.0340s/iter; left time: 694.4398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0422622 Vali Loss: 0.0525936 Test Loss: 0.0564336\n",
      "Validation loss decreased (0.052761 --> 0.052594).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0399028\n",
      "\tspeed: 0.0643s/iter; left time: 1303.3671s\n",
      "\titers: 200, epoch: 10 | loss: 0.0399608\n",
      "\tspeed: 0.0341s/iter; left time: 687.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0419118 Vali Loss: 0.0523241 Test Loss: 0.0560268\n",
      "Validation loss decreased (0.052594 --> 0.052324).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0448097\n",
      "\tspeed: 0.0646s/iter; left time: 1295.6634s\n",
      "\titers: 200, epoch: 11 | loss: 0.0413758\n",
      "\tspeed: 0.0340s/iter; left time: 678.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0416651 Vali Loss: 0.0522914 Test Loss: 0.0561402\n",
      "Validation loss decreased (0.052324 --> 0.052291).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0400997\n",
      "\tspeed: 0.0651s/iter; left time: 1291.9483s\n",
      "\titers: 200, epoch: 12 | loss: 0.0403079\n",
      "\tspeed: 0.0341s/iter; left time: 672.0480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0414033 Vali Loss: 0.0523278 Test Loss: 0.0561529\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0406680\n",
      "\tspeed: 0.0641s/iter; left time: 1256.9465s\n",
      "\titers: 200, epoch: 13 | loss: 0.0439693\n",
      "\tspeed: 0.0344s/iter; left time: 671.3764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0411912 Vali Loss: 0.0521584 Test Loss: 0.0558714\n",
      "Validation loss decreased (0.052291 --> 0.052158).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0443909\n",
      "\tspeed: 0.0641s/iter; left time: 1242.0645s\n",
      "\titers: 200, epoch: 14 | loss: 0.0410335\n",
      "\tspeed: 0.0345s/iter; left time: 665.8426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0410604 Vali Loss: 0.0520966 Test Loss: 0.0557349\n",
      "Validation loss decreased (0.052158 --> 0.052097).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0426491\n",
      "\tspeed: 0.0653s/iter; left time: 1251.7173s\n",
      "\titers: 200, epoch: 15 | loss: 0.0410878\n",
      "\tspeed: 0.0343s/iter; left time: 653.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0408608 Vali Loss: 0.0522173 Test Loss: 0.0559802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0420199\n",
      "\tspeed: 0.0638s/iter; left time: 1209.2118s\n",
      "\titers: 200, epoch: 16 | loss: 0.0383129\n",
      "\tspeed: 0.0340s/iter; left time: 640.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0408030 Vali Loss: 0.0520518 Test Loss: 0.0557027\n",
      "Validation loss decreased (0.052097 --> 0.052052).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0373026\n",
      "\tspeed: 0.0645s/iter; left time: 1206.6407s\n",
      "\titers: 200, epoch: 17 | loss: 0.0383360\n",
      "\tspeed: 0.0340s/iter; left time: 632.6412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0406606 Vali Loss: 0.0520363 Test Loss: 0.0557682\n",
      "Validation loss decreased (0.052052 --> 0.052036).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0412390\n",
      "\tspeed: 0.0646s/iter; left time: 1194.6779s\n",
      "\titers: 200, epoch: 18 | loss: 0.0358473\n",
      "\tspeed: 0.0341s/iter; left time: 627.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0405495 Vali Loss: 0.0519978 Test Loss: 0.0555904\n",
      "Validation loss decreased (0.052036 --> 0.051998).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0373392\n",
      "\tspeed: 0.0651s/iter; left time: 1189.3143s\n",
      "\titers: 200, epoch: 19 | loss: 0.0407665\n",
      "\tspeed: 0.0345s/iter; left time: 627.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0404592 Vali Loss: 0.0519362 Test Loss: 0.0555198\n",
      "Validation loss decreased (0.051998 --> 0.051936).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0412234\n",
      "\tspeed: 0.0646s/iter; left time: 1166.0737s\n",
      "\titers: 200, epoch: 20 | loss: 0.0396656\n",
      "\tspeed: 0.0341s/iter; left time: 611.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0403646 Vali Loss: 0.0520998 Test Loss: 0.0556649\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0373310\n",
      "\tspeed: 0.0643s/iter; left time: 1146.4092s\n",
      "\titers: 200, epoch: 21 | loss: 0.0401153\n",
      "\tspeed: 0.0340s/iter; left time: 601.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0402911 Vali Loss: 0.0519288 Test Loss: 0.0554669\n",
      "Validation loss decreased (0.051936 --> 0.051929).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0404831\n",
      "\tspeed: 0.0657s/iter; left time: 1156.6298s\n",
      "\titers: 200, epoch: 22 | loss: 0.0438901\n",
      "\tspeed: 0.0339s/iter; left time: 593.6115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0402111 Vali Loss: 0.0519242 Test Loss: 0.0554432\n",
      "Validation loss decreased (0.051929 --> 0.051924).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0380333\n",
      "\tspeed: 0.0642s/iter; left time: 1115.1035s\n",
      "\titers: 200, epoch: 23 | loss: 0.0435249\n",
      "\tspeed: 0.0340s/iter; left time: 587.2865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0401183 Vali Loss: 0.0519605 Test Loss: 0.0554244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0405794\n",
      "\tspeed: 0.0631s/iter; left time: 1081.9224s\n",
      "\titers: 200, epoch: 24 | loss: 0.0401202\n",
      "\tspeed: 0.0341s/iter; left time: 580.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0400855 Vali Loss: 0.0518724 Test Loss: 0.0554681\n",
      "Validation loss decreased (0.051924 --> 0.051872).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0394155\n",
      "\tspeed: 0.0644s/iter; left time: 1089.5760s\n",
      "\titers: 200, epoch: 25 | loss: 0.0379388\n",
      "\tspeed: 0.0339s/iter; left time: 570.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0400947 Vali Loss: 0.0518481 Test Loss: 0.0554663\n",
      "Validation loss decreased (0.051872 --> 0.051848).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0417797\n",
      "\tspeed: 0.0650s/iter; left time: 1085.9534s\n",
      "\titers: 200, epoch: 26 | loss: 0.0404329\n",
      "\tspeed: 0.0341s/iter; left time: 566.4458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0400209 Vali Loss: 0.0519860 Test Loss: 0.0555432\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0387534\n",
      "\tspeed: 0.0652s/iter; left time: 1073.6171s\n",
      "\titers: 200, epoch: 27 | loss: 0.0388816\n",
      "\tspeed: 0.0338s/iter; left time: 554.0888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0399715 Vali Loss: 0.0518692 Test Loss: 0.0553300\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0414896\n",
      "\tspeed: 0.0637s/iter; left time: 1035.8004s\n",
      "\titers: 200, epoch: 28 | loss: 0.0427325\n",
      "\tspeed: 0.0340s/iter; left time: 548.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0399775 Vali Loss: 0.0519125 Test Loss: 0.0554073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0402069\n",
      "\tspeed: 0.0631s/iter; left time: 1011.9898s\n",
      "\titers: 200, epoch: 29 | loss: 0.0397794\n",
      "\tspeed: 0.0346s/iter; left time: 551.6192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0399143 Vali Loss: 0.0517919 Test Loss: 0.0553706\n",
      "Validation loss decreased (0.051848 --> 0.051792).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0404619\n",
      "\tspeed: 0.0659s/iter; left time: 1041.6696s\n",
      "\titers: 200, epoch: 30 | loss: 0.0417322\n",
      "\tspeed: 0.0339s/iter; left time: 533.1483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0398649 Vali Loss: 0.0519664 Test Loss: 0.0553933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0404604\n",
      "\tspeed: 0.0635s/iter; left time: 988.6864s\n",
      "\titers: 200, epoch: 31 | loss: 0.0367844\n",
      "\tspeed: 0.0339s/iter; left time: 524.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0398406 Vali Loss: 0.0518829 Test Loss: 0.0554485\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0417230\n",
      "\tspeed: 0.0627s/iter; left time: 962.9298s\n",
      "\titers: 200, epoch: 32 | loss: 0.0367436\n",
      "\tspeed: 0.0340s/iter; left time: 519.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0398467 Vali Loss: 0.0518404 Test Loss: 0.0554078\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0369080\n",
      "\tspeed: 0.0632s/iter; left time: 957.1100s\n",
      "\titers: 200, epoch: 33 | loss: 0.0412066\n",
      "\tspeed: 0.0340s/iter; left time: 511.6876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0397875 Vali Loss: 0.0518950 Test Loss: 0.0554227\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0421704\n",
      "\tspeed: 0.0634s/iter; left time: 945.8384s\n",
      "\titers: 200, epoch: 34 | loss: 0.0425691\n",
      "\tspeed: 0.0340s/iter; left time: 503.1850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0397469 Vali Loss: 0.0518491 Test Loss: 0.0554131\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0411076\n",
      "\tspeed: 0.0635s/iter; left time: 933.2036s\n",
      "\titers: 200, epoch: 35 | loss: 0.0394340\n",
      "\tspeed: 0.0339s/iter; left time: 494.4870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0397841 Vali Loss: 0.0518472 Test Loss: 0.0553956\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0379899\n",
      "\tspeed: 0.0632s/iter; left time: 914.5856s\n",
      "\titers: 200, epoch: 36 | loss: 0.0464343\n",
      "\tspeed: 0.0338s/iter; left time: 486.0098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0397807 Vali Loss: 0.0518250 Test Loss: 0.0554601\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0436030\n",
      "\tspeed: 0.0631s/iter; left time: 898.1131s\n",
      "\titers: 200, epoch: 37 | loss: 0.0395444\n",
      "\tspeed: 0.0339s/iter; left time: 479.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0398131 Vali Loss: 0.0518522 Test Loss: 0.0554317\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0391678\n",
      "\tspeed: 0.0633s/iter; left time: 887.1587s\n",
      "\titers: 200, epoch: 38 | loss: 0.0418203\n",
      "\tspeed: 0.0339s/iter; left time: 471.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0397366 Vali Loss: 0.0518405 Test Loss: 0.0553314\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0387209\n",
      "\tspeed: 0.0634s/iter; left time: 874.4528s\n",
      "\titers: 200, epoch: 39 | loss: 0.0396145\n",
      "\tspeed: 0.0339s/iter; left time: 463.4650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0397391 Vali Loss: 0.0518850 Test Loss: 0.0553082\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010155079886317253, rmse:0.1007724180817604, mae:0.055370621383190155, rse:0.3887771964073181\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1094401\n",
      "\tspeed: 0.0362s/iter; left time: 807.6698s\n",
      "\titers: 200, epoch: 1 | loss: 0.1005816\n",
      "\tspeed: 0.0338s/iter; left time: 751.3744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.1106520 Vali Loss: 0.1126437 Test Loss: 0.1250588\n",
      "Validation loss decreased (inf --> 0.112644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0544627\n",
      "\tspeed: 0.0649s/iter; left time: 1432.8599s\n",
      "\titers: 200, epoch: 2 | loss: 0.0556115\n",
      "\tspeed: 0.0340s/iter; left time: 746.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0617397 Vali Loss: 0.0603577 Test Loss: 0.0636075\n",
      "Validation loss decreased (0.112644 --> 0.060358).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0505745\n",
      "\tspeed: 0.0646s/iter; left time: 1411.1494s\n",
      "\titers: 200, epoch: 3 | loss: 0.0481833\n",
      "\tspeed: 0.0340s/iter; left time: 739.9706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0490784 Vali Loss: 0.0574146 Test Loss: 0.0607994\n",
      "Validation loss decreased (0.060358 --> 0.057415).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0464242\n",
      "\tspeed: 0.0653s/iter; left time: 1413.3350s\n",
      "\titers: 200, epoch: 4 | loss: 0.0459194\n",
      "\tspeed: 0.0340s/iter; left time: 732.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0467708 Vali Loss: 0.0557457 Test Loss: 0.0591055\n",
      "Validation loss decreased (0.057415 --> 0.055746).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0451788\n",
      "\tspeed: 0.0655s/iter; left time: 1402.5287s\n",
      "\titers: 200, epoch: 5 | loss: 0.0424137\n",
      "\tspeed: 0.0339s/iter; left time: 722.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0452176 Vali Loss: 0.0545432 Test Loss: 0.0581420\n",
      "Validation loss decreased (0.055746 --> 0.054543).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0388246\n",
      "\tspeed: 0.0650s/iter; left time: 1376.0239s\n",
      "\titers: 200, epoch: 6 | loss: 0.0420071\n",
      "\tspeed: 0.0340s/iter; left time: 716.7809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0442202 Vali Loss: 0.0532858 Test Loss: 0.0572766\n",
      "Validation loss decreased (0.054543 --> 0.053286).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0463440\n",
      "\tspeed: 0.0654s/iter; left time: 1370.6924s\n",
      "\titers: 200, epoch: 7 | loss: 0.0442682\n",
      "\tspeed: 0.0339s/iter; left time: 707.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0434301 Vali Loss: 0.0530425 Test Loss: 0.0569921\n",
      "Validation loss decreased (0.053286 --> 0.053043).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0456950\n",
      "\tspeed: 0.0665s/iter; left time: 1378.4367s\n",
      "\titers: 200, epoch: 8 | loss: 0.0421521\n",
      "\tspeed: 0.0347s/iter; left time: 716.7931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0428847 Vali Loss: 0.0531325 Test Loss: 0.0566786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0417287\n",
      "\tspeed: 0.0647s/iter; left time: 1325.9924s\n",
      "\titers: 200, epoch: 9 | loss: 0.0442855\n",
      "\tspeed: 0.0342s/iter; left time: 698.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0424366 Vali Loss: 0.0526041 Test Loss: 0.0563456\n",
      "Validation loss decreased (0.053043 --> 0.052604).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0429612\n",
      "\tspeed: 0.0660s/iter; left time: 1338.2909s\n",
      "\titers: 200, epoch: 10 | loss: 0.0458863\n",
      "\tspeed: 0.0339s/iter; left time: 684.6313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0420584 Vali Loss: 0.0526172 Test Loss: 0.0566575\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0429619\n",
      "\tspeed: 0.0638s/iter; left time: 1279.1407s\n",
      "\titers: 200, epoch: 11 | loss: 0.0428643\n",
      "\tspeed: 0.0340s/iter; left time: 678.3812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0417614 Vali Loss: 0.0522490 Test Loss: 0.0558945\n",
      "Validation loss decreased (0.052604 --> 0.052249).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0444045\n",
      "\tspeed: 0.0663s/iter; left time: 1314.7652s\n",
      "\titers: 200, epoch: 12 | loss: 0.0396510\n",
      "\tspeed: 0.0341s/iter; left time: 672.4310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0415418 Vali Loss: 0.0523290 Test Loss: 0.0560020\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0381419\n",
      "\tspeed: 0.0639s/iter; left time: 1253.6912s\n",
      "\titers: 200, epoch: 13 | loss: 0.0405829\n",
      "\tspeed: 0.0339s/iter; left time: 661.3600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0413200 Vali Loss: 0.0521626 Test Loss: 0.0557546\n",
      "Validation loss decreased (0.052249 --> 0.052163).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0425900\n",
      "\tspeed: 0.0655s/iter; left time: 1269.4160s\n",
      "\titers: 200, epoch: 14 | loss: 0.0441515\n",
      "\tspeed: 0.0339s/iter; left time: 654.2193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0411346 Vali Loss: 0.0519422 Test Loss: 0.0557106\n",
      "Validation loss decreased (0.052163 --> 0.051942).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0393237\n",
      "\tspeed: 0.0646s/iter; left time: 1237.9296s\n",
      "\titers: 200, epoch: 15 | loss: 0.0445696\n",
      "\tspeed: 0.0344s/iter; left time: 655.8553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0410265 Vali Loss: 0.0520698 Test Loss: 0.0555845\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0392608\n",
      "\tspeed: 0.0642s/iter; left time: 1215.9841s\n",
      "\titers: 200, epoch: 16 | loss: 0.0390381\n",
      "\tspeed: 0.0339s/iter; left time: 638.7679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0408100 Vali Loss: 0.0520630 Test Loss: 0.0554447\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0408467\n",
      "\tspeed: 0.0639s/iter; left time: 1196.7954s\n",
      "\titers: 200, epoch: 17 | loss: 0.0394916\n",
      "\tspeed: 0.0345s/iter; left time: 642.8564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0407442 Vali Loss: 0.0520150 Test Loss: 0.0554374\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0407220\n",
      "\tspeed: 0.0645s/iter; left time: 1192.2501s\n",
      "\titers: 200, epoch: 18 | loss: 0.0391960\n",
      "\tspeed: 0.0340s/iter; left time: 625.0734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0405791 Vali Loss: 0.0518669 Test Loss: 0.0553506\n",
      "Validation loss decreased (0.051942 --> 0.051867).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0418227\n",
      "\tspeed: 0.0647s/iter; left time: 1182.3281s\n",
      "\titers: 200, epoch: 19 | loss: 0.0407169\n",
      "\tspeed: 0.0340s/iter; left time: 616.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0405353 Vali Loss: 0.0519316 Test Loss: 0.0553939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0447454\n",
      "\tspeed: 0.0663s/iter; left time: 1196.9953s\n",
      "\titers: 200, epoch: 20 | loss: 0.0399602\n",
      "\tspeed: 0.0347s/iter; left time: 622.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 224 | Train Loss: 0.0404139 Vali Loss: 0.0518210 Test Loss: 0.0553704\n",
      "Validation loss decreased (0.051867 --> 0.051821).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0401816\n",
      "\tspeed: 0.0668s/iter; left time: 1190.2473s\n",
      "\titers: 200, epoch: 21 | loss: 0.0379708\n",
      "\tspeed: 0.0346s/iter; left time: 613.8889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0403843 Vali Loss: 0.0518794 Test Loss: 0.0552368\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0394045\n",
      "\tspeed: 0.0647s/iter; left time: 1139.0224s\n",
      "\titers: 200, epoch: 22 | loss: 0.0403346\n",
      "\tspeed: 0.0339s/iter; left time: 594.0014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0402803 Vali Loss: 0.0517825 Test Loss: 0.0554102\n",
      "Validation loss decreased (0.051821 --> 0.051782).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0382460\n",
      "\tspeed: 0.0679s/iter; left time: 1179.3249s\n",
      "\titers: 200, epoch: 23 | loss: 0.0375762\n",
      "\tspeed: 0.0342s/iter; left time: 590.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0402176 Vali Loss: 0.0517951 Test Loss: 0.0553523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0401320\n",
      "\tspeed: 0.0652s/iter; left time: 1118.0325s\n",
      "\titers: 200, epoch: 24 | loss: 0.0385567\n",
      "\tspeed: 0.0340s/iter; left time: 579.2939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0401603 Vali Loss: 0.0517928 Test Loss: 0.0553305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0406993\n",
      "\tspeed: 0.0659s/iter; left time: 1115.3775s\n",
      "\titers: 200, epoch: 25 | loss: 0.0390302\n",
      "\tspeed: 0.0342s/iter; left time: 575.0774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0401084 Vali Loss: 0.0515937 Test Loss: 0.0551319\n",
      "Validation loss decreased (0.051782 --> 0.051594).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0428648\n",
      "\tspeed: 0.0648s/iter; left time: 1081.4468s\n",
      "\titers: 200, epoch: 26 | loss: 0.0403279\n",
      "\tspeed: 0.0340s/iter; left time: 565.1855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0400728 Vali Loss: 0.0516763 Test Loss: 0.0551821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0387913\n",
      "\tspeed: 0.0647s/iter; left time: 1065.2723s\n",
      "\titers: 200, epoch: 27 | loss: 0.0396870\n",
      "\tspeed: 0.0339s/iter; left time: 554.8977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0400329 Vali Loss: 0.0517391 Test Loss: 0.0552157\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0412506\n",
      "\tspeed: 0.0644s/iter; left time: 1045.9661s\n",
      "\titers: 200, epoch: 28 | loss: 0.0388730\n",
      "\tspeed: 0.0342s/iter; left time: 552.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0399488 Vali Loss: 0.0516464 Test Loss: 0.0551403\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0434460\n",
      "\tspeed: 0.0650s/iter; left time: 1042.2943s\n",
      "\titers: 200, epoch: 29 | loss: 0.0378317\n",
      "\tspeed: 0.0339s/iter; left time: 540.3149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0399308 Vali Loss: 0.0517076 Test Loss: 0.0551429\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0363359\n",
      "\tspeed: 0.0661s/iter; left time: 1045.4556s\n",
      "\titers: 200, epoch: 30 | loss: 0.0391354\n",
      "\tspeed: 0.0340s/iter; left time: 533.5865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0399297 Vali Loss: 0.0516798 Test Loss: 0.0550891\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0417295\n",
      "\tspeed: 0.0686s/iter; left time: 1069.6033s\n",
      "\titers: 200, epoch: 31 | loss: 0.0409997\n",
      "\tspeed: 0.0339s/iter; left time: 525.1216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 224 | Train Loss: 0.0398885 Vali Loss: 0.0515366 Test Loss: 0.0550938\n",
      "Validation loss decreased (0.051594 --> 0.051537).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0421586\n",
      "\tspeed: 0.0656s/iter; left time: 1007.4437s\n",
      "\titers: 200, epoch: 32 | loss: 0.0414021\n",
      "\tspeed: 0.0339s/iter; left time: 517.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0399434 Vali Loss: 0.0517420 Test Loss: 0.0551615\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0417471\n",
      "\tspeed: 0.0645s/iter; left time: 976.1938s\n",
      "\titers: 200, epoch: 33 | loss: 0.0378959\n",
      "\tspeed: 0.0341s/iter; left time: 512.4632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0398366 Vali Loss: 0.0516584 Test Loss: 0.0550776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0419260\n",
      "\tspeed: 0.0649s/iter; left time: 967.9931s\n",
      "\titers: 200, epoch: 34 | loss: 0.0400693\n",
      "\tspeed: 0.0340s/iter; left time: 502.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0398225 Vali Loss: 0.0516691 Test Loss: 0.0550839\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0443570\n",
      "\tspeed: 0.0651s/iter; left time: 956.1675s\n",
      "\titers: 200, epoch: 35 | loss: 0.0384875\n",
      "\tspeed: 0.0343s/iter; left time: 500.5030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0398284 Vali Loss: 0.0516524 Test Loss: 0.0551450\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0444361\n",
      "\tspeed: 0.0642s/iter; left time: 928.4809s\n",
      "\titers: 200, epoch: 36 | loss: 0.0367514\n",
      "\tspeed: 0.0340s/iter; left time: 487.9621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0398057 Vali Loss: 0.0515834 Test Loss: 0.0550931\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0442064\n",
      "\tspeed: 0.0634s/iter; left time: 902.3862s\n",
      "\titers: 200, epoch: 37 | loss: 0.0412975\n",
      "\tspeed: 0.0340s/iter; left time: 480.7403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0398019 Vali Loss: 0.0516367 Test Loss: 0.0551290\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0357967\n",
      "\tspeed: 0.0655s/iter; left time: 918.0591s\n",
      "\titers: 200, epoch: 38 | loss: 0.0372386\n",
      "\tspeed: 0.0339s/iter; left time: 471.5232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0397723 Vali Loss: 0.0515989 Test Loss: 0.0550932\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0391088\n",
      "\tspeed: 0.0653s/iter; left time: 900.1992s\n",
      "\titers: 200, epoch: 39 | loss: 0.0371802\n",
      "\tspeed: 0.0344s/iter; left time: 470.6175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0397517 Vali Loss: 0.0516996 Test Loss: 0.0550966\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0400200\n",
      "\tspeed: 0.0651s/iter; left time: 883.3657s\n",
      "\titers: 200, epoch: 40 | loss: 0.0437033\n",
      "\tspeed: 0.0339s/iter; left time: 456.5061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0397919 Vali Loss: 0.0516300 Test Loss: 0.0551088\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0427056\n",
      "\tspeed: 0.0655s/iter; left time: 873.8880s\n",
      "\titers: 200, epoch: 41 | loss: 0.0400225\n",
      "\tspeed: 0.0343s/iter; left time: 454.3322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0397633 Vali Loss: 0.0517601 Test Loss: 0.0551124\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010057547129690647, rmse:0.10028732568025589, mae:0.055093761533498764, rse:0.386905699968338\n",
      "Intermediate time for FR and pred_len 24: 00h:13m:22.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1156252\n",
      "\tspeed: 0.0604s/iter; left time: 1345.9853s\n",
      "\titers: 200, epoch: 1 | loss: 0.1060459\n",
      "\tspeed: 0.0343s/iter; left time: 761.8394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 224 | Train Loss: 0.1190825 Vali Loss: 0.1222190 Test Loss: 0.1367768\n",
      "Validation loss decreased (inf --> 0.122219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0704846\n",
      "\tspeed: 0.0676s/iter; left time: 1493.0354s\n",
      "\titers: 200, epoch: 2 | loss: 0.0632950\n",
      "\tspeed: 0.0344s/iter; left time: 756.0345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0741069 Vali Loss: 0.0766063 Test Loss: 0.0843476\n",
      "Validation loss decreased (0.122219 --> 0.076606).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0635311\n",
      "\tspeed: 0.0748s/iter; left time: 1634.8924s\n",
      "\titers: 200, epoch: 3 | loss: 0.0638851\n",
      "\tspeed: 0.0346s/iter; left time: 753.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0637177 Vali Loss: 0.0739754 Test Loss: 0.0829573\n",
      "Validation loss decreased (0.076606 --> 0.073975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0602097\n",
      "\tspeed: 0.0689s/iter; left time: 1490.0047s\n",
      "\titers: 200, epoch: 4 | loss: 0.0603170\n",
      "\tspeed: 0.0345s/iter; left time: 742.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0613591 Vali Loss: 0.0727099 Test Loss: 0.0827149\n",
      "Validation loss decreased (0.073975 --> 0.072710).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0608542\n",
      "\tspeed: 0.0668s/iter; left time: 1430.9076s\n",
      "\titers: 200, epoch: 5 | loss: 0.0596984\n",
      "\tspeed: 0.0351s/iter; left time: 748.4870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0599456 Vali Loss: 0.0722712 Test Loss: 0.0833736\n",
      "Validation loss decreased (0.072710 --> 0.072271).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0593878\n",
      "\tspeed: 0.0673s/iter; left time: 1426.2353s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608334\n",
      "\tspeed: 0.0342s/iter; left time: 721.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0589583 Vali Loss: 0.0716899 Test Loss: 0.0825764\n",
      "Validation loss decreased (0.072271 --> 0.071690).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0560035\n",
      "\tspeed: 0.0691s/iter; left time: 1448.2979s\n",
      "\titers: 200, epoch: 7 | loss: 0.0553835\n",
      "\tspeed: 0.0349s/iter; left time: 728.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0582878 Vali Loss: 0.0717173 Test Loss: 0.0819899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0581815\n",
      "\tspeed: 0.0659s/iter; left time: 1366.7073s\n",
      "\titers: 200, epoch: 8 | loss: 0.0568370\n",
      "\tspeed: 0.0347s/iter; left time: 715.0457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0577010 Vali Loss: 0.0716664 Test Loss: 0.0823132\n",
      "Validation loss decreased (0.071690 --> 0.071666).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0548898\n",
      "\tspeed: 0.0687s/iter; left time: 1409.4139s\n",
      "\titers: 200, epoch: 9 | loss: 0.0588697\n",
      "\tspeed: 0.0344s/iter; left time: 701.7075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0572062 Vali Loss: 0.0716870 Test Loss: 0.0822819\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0548872\n",
      "\tspeed: 0.0645s/iter; left time: 1307.4689s\n",
      "\titers: 200, epoch: 10 | loss: 0.0590986\n",
      "\tspeed: 0.0343s/iter; left time: 692.5745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0567653 Vali Loss: 0.0713302 Test Loss: 0.0821311\n",
      "Validation loss decreased (0.071666 --> 0.071330).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579021\n",
      "\tspeed: 0.0679s/iter; left time: 1362.5119s\n",
      "\titers: 200, epoch: 11 | loss: 0.0552177\n",
      "\tspeed: 0.0341s/iter; left time: 680.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0563869 Vali Loss: 0.0716126 Test Loss: 0.0826249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0555543\n",
      "\tspeed: 0.0667s/iter; left time: 1323.7540s\n",
      "\titers: 200, epoch: 12 | loss: 0.0536382\n",
      "\tspeed: 0.0350s/iter; left time: 690.3991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.0560712 Vali Loss: 0.0713404 Test Loss: 0.0824922\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0569652\n",
      "\tspeed: 0.0660s/iter; left time: 1294.0780s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547314\n",
      "\tspeed: 0.0347s/iter; left time: 678.0448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0557423 Vali Loss: 0.0713660 Test Loss: 0.0824726\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0589291\n",
      "\tspeed: 0.0657s/iter; left time: 1273.0113s\n",
      "\titers: 200, epoch: 14 | loss: 0.0563333\n",
      "\tspeed: 0.0345s/iter; left time: 665.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0554690 Vali Loss: 0.0713429 Test Loss: 0.0827610\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0554153\n",
      "\tspeed: 0.0651s/iter; left time: 1248.5381s\n",
      "\titers: 200, epoch: 15 | loss: 0.0534402\n",
      "\tspeed: 0.0351s/iter; left time: 669.9150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0552738 Vali Loss: 0.0714421 Test Loss: 0.0823074\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0558507\n",
      "\tspeed: 0.0651s/iter; left time: 1233.1843s\n",
      "\titers: 200, epoch: 16 | loss: 0.0544727\n",
      "\tspeed: 0.0349s/iter; left time: 657.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0550275 Vali Loss: 0.0715380 Test Loss: 0.0824943\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0563965\n",
      "\tspeed: 0.0660s/iter; left time: 1234.7593s\n",
      "\titers: 200, epoch: 17 | loss: 0.0557426\n",
      "\tspeed: 0.0348s/iter; left time: 647.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0548346 Vali Loss: 0.0713193 Test Loss: 0.0822374\n",
      "Validation loss decreased (0.071330 --> 0.071319).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0557317\n",
      "\tspeed: 0.0666s/iter; left time: 1231.6848s\n",
      "\titers: 200, epoch: 18 | loss: 0.0546155\n",
      "\tspeed: 0.0342s/iter; left time: 629.2543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0546819 Vali Loss: 0.0714567 Test Loss: 0.0823589\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0554896\n",
      "\tspeed: 0.0652s/iter; left time: 1190.8170s\n",
      "\titers: 200, epoch: 19 | loss: 0.0566898\n",
      "\tspeed: 0.0343s/iter; left time: 622.2937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0545064 Vali Loss: 0.0715879 Test Loss: 0.0822342\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0555959\n",
      "\tspeed: 0.0665s/iter; left time: 1199.1972s\n",
      "\titers: 200, epoch: 20 | loss: 0.0549557\n",
      "\tspeed: 0.0348s/iter; left time: 625.1631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0543912 Vali Loss: 0.0714636 Test Loss: 0.0820047\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0523533\n",
      "\tspeed: 0.0661s/iter; left time: 1177.5761s\n",
      "\titers: 200, epoch: 21 | loss: 0.0542324\n",
      "\tspeed: 0.0343s/iter; left time: 607.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0542423 Vali Loss: 0.0715133 Test Loss: 0.0822591\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0547638\n",
      "\tspeed: 0.0656s/iter; left time: 1154.3612s\n",
      "\titers: 200, epoch: 22 | loss: 0.0534443\n",
      "\tspeed: 0.0344s/iter; left time: 601.7239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0541305 Vali Loss: 0.0715368 Test Loss: 0.0822879\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0543886\n",
      "\tspeed: 0.0649s/iter; left time: 1127.2654s\n",
      "\titers: 200, epoch: 23 | loss: 0.0536552\n",
      "\tspeed: 0.0344s/iter; left time: 593.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0540624 Vali Loss: 0.0716271 Test Loss: 0.0821227\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0565382\n",
      "\tspeed: 0.0656s/iter; left time: 1124.6657s\n",
      "\titers: 200, epoch: 24 | loss: 0.0541424\n",
      "\tspeed: 0.0343s/iter; left time: 584.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0539107 Vali Loss: 0.0714931 Test Loss: 0.0822808\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0554970\n",
      "\tspeed: 0.0655s/iter; left time: 1107.9420s\n",
      "\titers: 200, epoch: 25 | loss: 0.0549087\n",
      "\tspeed: 0.0342s/iter; left time: 575.5909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0538984 Vali Loss: 0.0715967 Test Loss: 0.0822921\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0516994\n",
      "\tspeed: 0.0650s/iter; left time: 1085.5945s\n",
      "\titers: 200, epoch: 26 | loss: 0.0525186\n",
      "\tspeed: 0.0341s/iter; left time: 566.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0537778 Vali Loss: 0.0716958 Test Loss: 0.0822449\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0538938\n",
      "\tspeed: 0.0649s/iter; left time: 1069.1663s\n",
      "\titers: 200, epoch: 27 | loss: 0.0564168\n",
      "\tspeed: 0.0344s/iter; left time: 563.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0537319 Vali Loss: 0.0715339 Test Loss: 0.0823089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01963534578680992, rmse:0.14012618362903595, mae:0.0822373777627945, rse:0.5420452952384949\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1154160\n",
      "\tspeed: 0.0369s/iter; left time: 822.2644s\n",
      "\titers: 200, epoch: 1 | loss: 0.1075368\n",
      "\tspeed: 0.0342s/iter; left time: 758.8033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1184687 Vali Loss: 0.1218070 Test Loss: 0.1364096\n",
      "Validation loss decreased (inf --> 0.121807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0671379\n",
      "\tspeed: 0.0674s/iter; left time: 1488.5667s\n",
      "\titers: 200, epoch: 2 | loss: 0.0653378\n",
      "\tspeed: 0.0345s/iter; left time: 759.2689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0744347 Vali Loss: 0.0762421 Test Loss: 0.0846303\n",
      "Validation loss decreased (0.121807 --> 0.076242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0609564\n",
      "\tspeed: 0.0672s/iter; left time: 1468.8353s\n",
      "\titers: 200, epoch: 3 | loss: 0.0597287\n",
      "\tspeed: 0.0349s/iter; left time: 759.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0638290 Vali Loss: 0.0739613 Test Loss: 0.0829957\n",
      "Validation loss decreased (0.076242 --> 0.073961).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0612373\n",
      "\tspeed: 0.0676s/iter; left time: 1462.1886s\n",
      "\titers: 200, epoch: 4 | loss: 0.0595653\n",
      "\tspeed: 0.0346s/iter; left time: 743.9171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0615989 Vali Loss: 0.0728422 Test Loss: 0.0828065\n",
      "Validation loss decreased (0.073961 --> 0.072842).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597562\n",
      "\tspeed: 0.0678s/iter; left time: 1452.0248s\n",
      "\titers: 200, epoch: 5 | loss: 0.0553987\n",
      "\tspeed: 0.0346s/iter; left time: 736.4323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0600575 Vali Loss: 0.0720670 Test Loss: 0.0821896\n",
      "Validation loss decreased (0.072842 --> 0.072067).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0634054\n",
      "\tspeed: 0.0698s/iter; left time: 1478.7075s\n",
      "\titers: 200, epoch: 6 | loss: 0.0571606\n",
      "\tspeed: 0.0347s/iter; left time: 732.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0590135 Vali Loss: 0.0718440 Test Loss: 0.0823829\n",
      "Validation loss decreased (0.072067 --> 0.071844).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590718\n",
      "\tspeed: 0.0685s/iter; left time: 1435.3223s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594180\n",
      "\tspeed: 0.0342s/iter; left time: 713.2879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0582545 Vali Loss: 0.0717599 Test Loss: 0.0820033\n",
      "Validation loss decreased (0.071844 --> 0.071760).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0619572\n",
      "\tspeed: 0.0680s/iter; left time: 1410.2946s\n",
      "\titers: 200, epoch: 8 | loss: 0.0600717\n",
      "\tspeed: 0.0345s/iter; left time: 712.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0577964 Vali Loss: 0.0718982 Test Loss: 0.0819674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0560200\n",
      "\tspeed: 0.0658s/iter; left time: 1349.9095s\n",
      "\titers: 200, epoch: 9 | loss: 0.0540999\n",
      "\tspeed: 0.0343s/iter; left time: 699.8930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0572643 Vali Loss: 0.0718750 Test Loss: 0.0820005\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0550202\n",
      "\tspeed: 0.0656s/iter; left time: 1330.6960s\n",
      "\titers: 200, epoch: 10 | loss: 0.0548419\n",
      "\tspeed: 0.0343s/iter; left time: 691.4751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0568043 Vali Loss: 0.0720056 Test Loss: 0.0818854\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0563849\n",
      "\tspeed: 0.0675s/iter; left time: 1354.5707s\n",
      "\titers: 200, epoch: 11 | loss: 0.0559479\n",
      "\tspeed: 0.0341s/iter; left time: 679.7345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0565039 Vali Loss: 0.0718800 Test Loss: 0.0816959\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0566436\n",
      "\tspeed: 0.0665s/iter; left time: 1319.8537s\n",
      "\titers: 200, epoch: 12 | loss: 0.0577709\n",
      "\tspeed: 0.0343s/iter; left time: 677.2418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0561187 Vali Loss: 0.0717747 Test Loss: 0.0819871\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0572069\n",
      "\tspeed: 0.0657s/iter; left time: 1287.8029s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562036\n",
      "\tspeed: 0.0343s/iter; left time: 669.8438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0558834 Vali Loss: 0.0718664 Test Loss: 0.0820116\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0550445\n",
      "\tspeed: 0.0664s/iter; left time: 1288.2498s\n",
      "\titers: 200, epoch: 14 | loss: 0.0556109\n",
      "\tspeed: 0.0346s/iter; left time: 666.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0556139 Vali Loss: 0.0718217 Test Loss: 0.0819398\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0537335\n",
      "\tspeed: 0.0649s/iter; left time: 1243.9253s\n",
      "\titers: 200, epoch: 15 | loss: 0.0527605\n",
      "\tspeed: 0.0340s/iter; left time: 649.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0554120 Vali Loss: 0.0716225 Test Loss: 0.0815059\n",
      "Validation loss decreased (0.071760 --> 0.071622).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0604739\n",
      "\tspeed: 0.0668s/iter; left time: 1264.5059s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552410\n",
      "\tspeed: 0.0342s/iter; left time: 645.2052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0552135 Vali Loss: 0.0717006 Test Loss: 0.0817680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0567907\n",
      "\tspeed: 0.0662s/iter; left time: 1238.6092s\n",
      "\titers: 200, epoch: 17 | loss: 0.0579164\n",
      "\tspeed: 0.0343s/iter; left time: 638.6202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0550305 Vali Loss: 0.0715534 Test Loss: 0.0811857\n",
      "Validation loss decreased (0.071622 --> 0.071553).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0576145\n",
      "\tspeed: 0.0674s/iter; left time: 1246.4929s\n",
      "\titers: 200, epoch: 18 | loss: 0.0511277\n",
      "\tspeed: 0.0348s/iter; left time: 639.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0548723 Vali Loss: 0.0716544 Test Loss: 0.0812668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0563549\n",
      "\tspeed: 0.0660s/iter; left time: 1205.7830s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547888\n",
      "\tspeed: 0.0342s/iter; left time: 621.9084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0546784 Vali Loss: 0.0715687 Test Loss: 0.0814313\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0552318\n",
      "\tspeed: 0.0652s/iter; left time: 1176.8254s\n",
      "\titers: 200, epoch: 20 | loss: 0.0549999\n",
      "\tspeed: 0.0346s/iter; left time: 620.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0545594 Vali Loss: 0.0717095 Test Loss: 0.0815305\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0532561\n",
      "\tspeed: 0.0660s/iter; left time: 1175.4948s\n",
      "\titers: 200, epoch: 21 | loss: 0.0591274\n",
      "\tspeed: 0.0342s/iter; left time: 605.6960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0544117 Vali Loss: 0.0716369 Test Loss: 0.0813597\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0557993\n",
      "\tspeed: 0.0661s/iter; left time: 1163.9386s\n",
      "\titers: 200, epoch: 22 | loss: 0.0508411\n",
      "\tspeed: 0.0342s/iter; left time: 598.7943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0543858 Vali Loss: 0.0716580 Test Loss: 0.0815713\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0556825\n",
      "\tspeed: 0.0673s/iter; left time: 1169.2730s\n",
      "\titers: 200, epoch: 23 | loss: 0.0515426\n",
      "\tspeed: 0.0356s/iter; left time: 614.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 224 | Train Loss: 0.0542970 Vali Loss: 0.0717369 Test Loss: 0.0813571\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0522207\n",
      "\tspeed: 0.0659s/iter; left time: 1129.9488s\n",
      "\titers: 200, epoch: 24 | loss: 0.0535139\n",
      "\tspeed: 0.0342s/iter; left time: 583.3232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0541846 Vali Loss: 0.0715603 Test Loss: 0.0812604\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0517692\n",
      "\tspeed: 0.0677s/iter; left time: 1145.7009s\n",
      "\titers: 200, epoch: 25 | loss: 0.0537290\n",
      "\tspeed: 0.0342s/iter; left time: 574.6679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0540874 Vali Loss: 0.0717348 Test Loss: 0.0813865\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0540747\n",
      "\tspeed: 0.0656s/iter; left time: 1094.9858s\n",
      "\titers: 200, epoch: 26 | loss: 0.0552746\n",
      "\tspeed: 0.0343s/iter; left time: 568.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0540465 Vali Loss: 0.0716443 Test Loss: 0.0814750\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0510588\n",
      "\tspeed: 0.0672s/iter; left time: 1107.5105s\n",
      "\titers: 200, epoch: 27 | loss: 0.0515561\n",
      "\tspeed: 0.0350s/iter; left time: 573.5724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 224 | Train Loss: 0.0539529 Vali Loss: 0.0717339 Test Loss: 0.0817004\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019514502957463264, rmse:0.13969431817531586, mae:0.08118564635515213, rse:0.540374755859375\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:19.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1153208\n",
      "\tspeed: 0.0603s/iter; left time: 1337.6876s\n",
      "\titers: 200, epoch: 1 | loss: 0.1100991\n",
      "\tspeed: 0.0347s/iter; left time: 767.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 223 | Train Loss: 0.1203847 Vali Loss: 0.1246423 Test Loss: 0.1390748\n",
      "Validation loss decreased (inf --> 0.124642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0745880\n",
      "\tspeed: 0.0673s/iter; left time: 1479.0777s\n",
      "\titers: 200, epoch: 2 | loss: 0.0722736\n",
      "\tspeed: 0.0349s/iter; left time: 762.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0777389 Vali Loss: 0.0799943 Test Loss: 0.0888394\n",
      "Validation loss decreased (0.124642 --> 0.079994).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0674564\n",
      "\tspeed: 0.0664s/iter; left time: 1445.5302s\n",
      "\titers: 200, epoch: 3 | loss: 0.0637951\n",
      "\tspeed: 0.0347s/iter; left time: 751.1428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0680533 Vali Loss: 0.0776140 Test Loss: 0.0879805\n",
      "Validation loss decreased (0.079994 --> 0.077614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0654204\n",
      "\tspeed: 0.0672s/iter; left time: 1447.0490s\n",
      "\titers: 200, epoch: 4 | loss: 0.0639187\n",
      "\tspeed: 0.0350s/iter; left time: 749.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0657068 Vali Loss: 0.0768534 Test Loss: 0.0878971\n",
      "Validation loss decreased (0.077614 --> 0.076853).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0666997\n",
      "\tspeed: 0.0666s/iter; left time: 1419.5269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0655546\n",
      "\tspeed: 0.0347s/iter; left time: 735.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0641879 Vali Loss: 0.0760667 Test Loss: 0.0877345\n",
      "Validation loss decreased (0.076853 --> 0.076067).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0664016\n",
      "\tspeed: 0.0668s/iter; left time: 1409.2923s\n",
      "\titers: 200, epoch: 6 | loss: 0.0615867\n",
      "\tspeed: 0.0348s/iter; left time: 730.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0632301 Vali Loss: 0.0757157 Test Loss: 0.0874930\n",
      "Validation loss decreased (0.076067 --> 0.075716).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0584839\n",
      "\tspeed: 0.0656s/iter; left time: 1368.6534s\n",
      "\titers: 200, epoch: 7 | loss: 0.0630124\n",
      "\tspeed: 0.0348s/iter; left time: 722.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0625077 Vali Loss: 0.0755675 Test Loss: 0.0875279\n",
      "Validation loss decreased (0.075716 --> 0.075568).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0630511\n",
      "\tspeed: 0.0660s/iter; left time: 1361.3566s\n",
      "\titers: 200, epoch: 8 | loss: 0.0623851\n",
      "\tspeed: 0.0351s/iter; left time: 719.9735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0618813 Vali Loss: 0.0757895 Test Loss: 0.0882833\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0657311\n",
      "\tspeed: 0.0646s/iter; left time: 1319.1850s\n",
      "\titers: 200, epoch: 9 | loss: 0.0610993\n",
      "\tspeed: 0.0350s/iter; left time: 711.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0613065 Vali Loss: 0.0753160 Test Loss: 0.0877921\n",
      "Validation loss decreased (0.075568 --> 0.075316).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0575956\n",
      "\tspeed: 0.0666s/iter; left time: 1344.8136s\n",
      "\titers: 200, epoch: 10 | loss: 0.0608523\n",
      "\tspeed: 0.0347s/iter; left time: 696.4536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0608570 Vali Loss: 0.0752572 Test Loss: 0.0885264\n",
      "Validation loss decreased (0.075316 --> 0.075257).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0602005\n",
      "\tspeed: 0.0659s/iter; left time: 1315.2547s\n",
      "\titers: 200, epoch: 11 | loss: 0.0629922\n",
      "\tspeed: 0.0346s/iter; left time: 688.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0604874 Vali Loss: 0.0755354 Test Loss: 0.0883545\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0592349\n",
      "\tspeed: 0.0654s/iter; left time: 1292.3911s\n",
      "\titers: 200, epoch: 12 | loss: 0.0635952\n",
      "\tspeed: 0.0348s/iter; left time: 684.6834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0600681 Vali Loss: 0.0754909 Test Loss: 0.0881430\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0601584\n",
      "\tspeed: 0.0644s/iter; left time: 1256.7896s\n",
      "\titers: 200, epoch: 13 | loss: 0.0585968\n",
      "\tspeed: 0.0348s/iter; left time: 676.0389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0596364 Vali Loss: 0.0754418 Test Loss: 0.0889707\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0573724\n",
      "\tspeed: 0.0644s/iter; left time: 1243.6262s\n",
      "\titers: 200, epoch: 14 | loss: 0.0607545\n",
      "\tspeed: 0.0347s/iter; left time: 665.3496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0593828 Vali Loss: 0.0757721 Test Loss: 0.0886866\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0580708\n",
      "\tspeed: 0.0644s/iter; left time: 1229.6352s\n",
      "\titers: 200, epoch: 15 | loss: 0.0588880\n",
      "\tspeed: 0.0347s/iter; left time: 658.5333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0590973 Vali Loss: 0.0754703 Test Loss: 0.0889454\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0575878\n",
      "\tspeed: 0.0648s/iter; left time: 1221.7293s\n",
      "\titers: 200, epoch: 16 | loss: 0.0604072\n",
      "\tspeed: 0.0346s/iter; left time: 649.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0588240 Vali Loss: 0.0754639 Test Loss: 0.0887070\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0572679\n",
      "\tspeed: 0.0647s/iter; left time: 1206.1892s\n",
      "\titers: 200, epoch: 17 | loss: 0.0556697\n",
      "\tspeed: 0.0349s/iter; left time: 646.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0585886 Vali Loss: 0.0757347 Test Loss: 0.0891244\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0596313\n",
      "\tspeed: 0.0653s/iter; left time: 1202.1653s\n",
      "\titers: 200, epoch: 18 | loss: 0.0587842\n",
      "\tspeed: 0.0346s/iter; left time: 633.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0583622 Vali Loss: 0.0758549 Test Loss: 0.0893418\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0568345\n",
      "\tspeed: 0.0656s/iter; left time: 1192.7889s\n",
      "\titers: 200, epoch: 19 | loss: 0.0550314\n",
      "\tspeed: 0.0348s/iter; left time: 629.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0582125 Vali Loss: 0.0756776 Test Loss: 0.0891228\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0581905\n",
      "\tspeed: 0.0657s/iter; left time: 1180.0864s\n",
      "\titers: 200, epoch: 20 | loss: 0.0588121\n",
      "\tspeed: 0.0349s/iter; left time: 624.0670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0580326 Vali Loss: 0.0758502 Test Loss: 0.0892652\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021153263747692108, rmse:0.14544162154197693, mae:0.0885264202952385, rse:0.5633091330528259\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1190915\n",
      "\tspeed: 0.0365s/iter; left time: 810.2243s\n",
      "\titers: 200, epoch: 1 | loss: 0.1097881\n",
      "\tspeed: 0.0347s/iter; left time: 767.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.1205956 Vali Loss: 0.1248965 Test Loss: 0.1393289\n",
      "Validation loss decreased (inf --> 0.124897).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0711008\n",
      "\tspeed: 0.0673s/iter; left time: 1479.4554s\n",
      "\titers: 200, epoch: 2 | loss: 0.0703841\n",
      "\tspeed: 0.0350s/iter; left time: 765.3464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0782206 Vali Loss: 0.0799629 Test Loss: 0.0888531\n",
      "Validation loss decreased (0.124897 --> 0.079963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0687007\n",
      "\tspeed: 0.0662s/iter; left time: 1440.9972s\n",
      "\titers: 200, epoch: 3 | loss: 0.0673348\n",
      "\tspeed: 0.0347s/iter; left time: 751.0225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0680140 Vali Loss: 0.0777647 Test Loss: 0.0882832\n",
      "Validation loss decreased (0.079963 --> 0.077765).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0688667\n",
      "\tspeed: 0.0665s/iter; left time: 1430.8825s\n",
      "\titers: 200, epoch: 4 | loss: 0.0627218\n",
      "\tspeed: 0.0347s/iter; left time: 743.1052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0656168 Vali Loss: 0.0766561 Test Loss: 0.0883783\n",
      "Validation loss decreased (0.077765 --> 0.076656).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0656176\n",
      "\tspeed: 0.0666s/iter; left time: 1419.0821s\n",
      "\titers: 200, epoch: 5 | loss: 0.0660023\n",
      "\tspeed: 0.0351s/iter; left time: 744.9462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0642845 Vali Loss: 0.0762945 Test Loss: 0.0880121\n",
      "Validation loss decreased (0.076656 --> 0.076295).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0643106\n",
      "\tspeed: 0.0665s/iter; left time: 1402.0931s\n",
      "\titers: 200, epoch: 6 | loss: 0.0636514\n",
      "\tspeed: 0.0347s/iter; left time: 727.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0633810 Vali Loss: 0.0759921 Test Loss: 0.0878032\n",
      "Validation loss decreased (0.076295 --> 0.075992).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605581\n",
      "\tspeed: 0.0662s/iter; left time: 1380.2859s\n",
      "\titers: 200, epoch: 7 | loss: 0.0603610\n",
      "\tspeed: 0.0348s/iter; left time: 722.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0625573 Vali Loss: 0.0758101 Test Loss: 0.0877436\n",
      "Validation loss decreased (0.075992 --> 0.075810).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640318\n",
      "\tspeed: 0.0697s/iter; left time: 1439.4564s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560514\n",
      "\tspeed: 0.0347s/iter; left time: 712.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0619226 Vali Loss: 0.0752848 Test Loss: 0.0878139\n",
      "Validation loss decreased (0.075810 --> 0.075285).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0624686\n",
      "\tspeed: 0.0691s/iter; left time: 1411.6781s\n",
      "\titers: 200, epoch: 9 | loss: 0.0615818\n",
      "\tspeed: 0.0347s/iter; left time: 705.8846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 223 | Train Loss: 0.0613472 Vali Loss: 0.0754208 Test Loss: 0.0882448\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0598454\n",
      "\tspeed: 0.0658s/iter; left time: 1328.9268s\n",
      "\titers: 200, epoch: 10 | loss: 0.0620275\n",
      "\tspeed: 0.0347s/iter; left time: 698.2017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0608847 Vali Loss: 0.0753788 Test Loss: 0.0879055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0595490\n",
      "\tspeed: 0.0655s/iter; left time: 1308.5181s\n",
      "\titers: 200, epoch: 11 | loss: 0.0564547\n",
      "\tspeed: 0.0348s/iter; left time: 690.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0604800 Vali Loss: 0.0753783 Test Loss: 0.0885742\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0663159\n",
      "\tspeed: 0.0666s/iter; left time: 1315.7838s\n",
      "\titers: 200, epoch: 12 | loss: 0.0586635\n",
      "\tspeed: 0.0347s/iter; left time: 682.3563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0601038 Vali Loss: 0.0752748 Test Loss: 0.0883173\n",
      "Validation loss decreased (0.075285 --> 0.075275).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0591716\n",
      "\tspeed: 0.0669s/iter; left time: 1306.7900s\n",
      "\titers: 200, epoch: 13 | loss: 0.0619611\n",
      "\tspeed: 0.0348s/iter; left time: 676.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0597688 Vali Loss: 0.0754530 Test Loss: 0.0886947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0628451\n",
      "\tspeed: 0.0660s/iter; left time: 1274.2231s\n",
      "\titers: 200, epoch: 14 | loss: 0.0571450\n",
      "\tspeed: 0.0347s/iter; left time: 667.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0594889 Vali Loss: 0.0754246 Test Loss: 0.0889243\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597695\n",
      "\tspeed: 0.0653s/iter; left time: 1246.0228s\n",
      "\titers: 200, epoch: 15 | loss: 0.0608148\n",
      "\tspeed: 0.0352s/iter; left time: 668.3314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0592113 Vali Loss: 0.0752915 Test Loss: 0.0887281\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0587053\n",
      "\tspeed: 0.0655s/iter; left time: 1234.8179s\n",
      "\titers: 200, epoch: 16 | loss: 0.0613898\n",
      "\tspeed: 0.0347s/iter; left time: 650.2221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0590177 Vali Loss: 0.0752665 Test Loss: 0.0886148\n",
      "Validation loss decreased (0.075275 --> 0.075266).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0556257\n",
      "\tspeed: 0.0681s/iter; left time: 1268.6138s\n",
      "\titers: 200, epoch: 17 | loss: 0.0600753\n",
      "\tspeed: 0.0346s/iter; left time: 641.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0587513 Vali Loss: 0.0754278 Test Loss: 0.0891135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0595197\n",
      "\tspeed: 0.0666s/iter; left time: 1225.2562s\n",
      "\titers: 200, epoch: 18 | loss: 0.0541842\n",
      "\tspeed: 0.0347s/iter; left time: 634.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0586244 Vali Loss: 0.0753491 Test Loss: 0.0892311\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0618455\n",
      "\tspeed: 0.0663s/iter; left time: 1206.5824s\n",
      "\titers: 200, epoch: 19 | loss: 0.0609220\n",
      "\tspeed: 0.0352s/iter; left time: 636.3206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0584854 Vali Loss: 0.0752955 Test Loss: 0.0892121\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0582511\n",
      "\tspeed: 0.0664s/iter; left time: 1192.4749s\n",
      "\titers: 200, epoch: 20 | loss: 0.0580657\n",
      "\tspeed: 0.0349s/iter; left time: 623.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0583330 Vali Loss: 0.0755161 Test Loss: 0.0891338\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0597132\n",
      "\tspeed: 0.0659s/iter; left time: 1169.1982s\n",
      "\titers: 200, epoch: 21 | loss: 0.0572131\n",
      "\tspeed: 0.0348s/iter; left time: 613.1017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0581857 Vali Loss: 0.0752635 Test Loss: 0.0893303\n",
      "Validation loss decreased (0.075266 --> 0.075264).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0599081\n",
      "\tspeed: 0.0675s/iter; left time: 1182.4693s\n",
      "\titers: 200, epoch: 22 | loss: 0.0631349\n",
      "\tspeed: 0.0353s/iter; left time: 614.5435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0580309 Vali Loss: 0.0754908 Test Loss: 0.0894723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0593954\n",
      "\tspeed: 0.0665s/iter; left time: 1149.2976s\n",
      "\titers: 200, epoch: 23 | loss: 0.0571021\n",
      "\tspeed: 0.0349s/iter; left time: 600.8016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0579649 Vali Loss: 0.0752245 Test Loss: 0.0894107\n",
      "Validation loss decreased (0.075264 --> 0.075224).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0609411\n",
      "\tspeed: 0.0666s/iter; left time: 1136.2541s\n",
      "\titers: 200, epoch: 24 | loss: 0.0616606\n",
      "\tspeed: 0.0347s/iter; left time: 588.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0578781 Vali Loss: 0.0755082 Test Loss: 0.0896305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0574753\n",
      "\tspeed: 0.0661s/iter; left time: 1113.4850s\n",
      "\titers: 200, epoch: 25 | loss: 0.0571148\n",
      "\tspeed: 0.0348s/iter; left time: 583.6325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0577253 Vali Loss: 0.0754464 Test Loss: 0.0895677\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0566095\n",
      "\tspeed: 0.0656s/iter; left time: 1091.2293s\n",
      "\titers: 200, epoch: 26 | loss: 0.0602154\n",
      "\tspeed: 0.0347s/iter; left time: 573.0307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0576776 Vali Loss: 0.0753909 Test Loss: 0.0896359\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0608131\n",
      "\tspeed: 0.0653s/iter; left time: 1071.2662s\n",
      "\titers: 200, epoch: 27 | loss: 0.0541946\n",
      "\tspeed: 0.0347s/iter; left time: 566.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0576239 Vali Loss: 0.0753789 Test Loss: 0.0897510\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0563107\n",
      "\tspeed: 0.0649s/iter; left time: 1049.3249s\n",
      "\titers: 200, epoch: 28 | loss: 0.0646379\n",
      "\tspeed: 0.0351s/iter; left time: 564.8705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0576085 Vali Loss: 0.0753111 Test Loss: 0.0897061\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0537694\n",
      "\tspeed: 0.0650s/iter; left time: 1037.8461s\n",
      "\titers: 200, epoch: 29 | loss: 0.0549931\n",
      "\tspeed: 0.0348s/iter; left time: 551.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0575102 Vali Loss: 0.0755265 Test Loss: 0.0897974\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0543042\n",
      "\tspeed: 0.0654s/iter; left time: 1028.7636s\n",
      "\titers: 200, epoch: 30 | loss: 0.0600720\n",
      "\tspeed: 0.0346s/iter; left time: 540.6175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0574181 Vali Loss: 0.0753452 Test Loss: 0.0897552\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0569441\n",
      "\tspeed: 0.0648s/iter; left time: 1005.1043s\n",
      "\titers: 200, epoch: 31 | loss: 0.0567248\n",
      "\tspeed: 0.0350s/iter; left time: 540.1078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0573839 Vali Loss: 0.0754152 Test Loss: 0.0897348\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0576866\n",
      "\tspeed: 0.0667s/iter; left time: 1019.0075s\n",
      "\titers: 200, epoch: 32 | loss: 0.0556905\n",
      "\tspeed: 0.0348s/iter; left time: 527.8390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.0573533 Vali Loss: 0.0753913 Test Loss: 0.0897891\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0569799\n",
      "\tspeed: 0.0653s/iter; left time: 984.4409s\n",
      "\titers: 200, epoch: 33 | loss: 0.0603436\n",
      "\tspeed: 0.0349s/iter; left time: 521.8852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0573787 Vali Loss: 0.0753961 Test Loss: 0.0897591\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021873392164707184, rmse:0.14789655804634094, mae:0.08941067010164261, rse:0.5728173851966858\n",
      "Intermediate time for FR and pred_len 168: 00h:09m:07.49s\n",
      "Intermediate time for FR: 00h:31m:49.39s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1670014\n",
      "\tspeed: 0.0610s/iter; left time: 1359.2600s\n",
      "\titers: 200, epoch: 1 | loss: 0.1489597\n",
      "\tspeed: 0.0340s/iter; left time: 754.9766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 224 | Train Loss: 0.1647013 Vali Loss: 0.1381420 Test Loss: 0.1453397\n",
      "Validation loss decreased (inf --> 0.138142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0750999\n",
      "\tspeed: 0.0637s/iter; left time: 1406.4205s\n",
      "\titers: 200, epoch: 2 | loss: 0.0690238\n",
      "\tspeed: 0.0340s/iter; left time: 746.5705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0844961 Vali Loss: 0.0635143 Test Loss: 0.0670098\n",
      "Validation loss decreased (0.138142 --> 0.063514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0655265\n",
      "\tspeed: 0.0631s/iter; left time: 1379.5755s\n",
      "\titers: 200, epoch: 3 | loss: 0.0632529\n",
      "\tspeed: 0.0341s/iter; left time: 742.7435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0647828 Vali Loss: 0.0602731 Test Loss: 0.0637938\n",
      "Validation loss decreased (0.063514 --> 0.060273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0584319\n",
      "\tspeed: 0.0630s/iter; left time: 1363.3126s\n",
      "\titers: 200, epoch: 4 | loss: 0.0584496\n",
      "\tspeed: 0.0341s/iter; left time: 734.0579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0615912 Vali Loss: 0.0586225 Test Loss: 0.0620069\n",
      "Validation loss decreased (0.060273 --> 0.058623).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0533112\n",
      "\tspeed: 0.0635s/iter; left time: 1359.4961s\n",
      "\titers: 200, epoch: 5 | loss: 0.0589854\n",
      "\tspeed: 0.0339s/iter; left time: 722.5336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0597137 Vali Loss: 0.0576908 Test Loss: 0.0609164\n",
      "Validation loss decreased (0.058623 --> 0.057691).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0561888\n",
      "\tspeed: 0.0628s/iter; left time: 1329.4210s\n",
      "\titers: 200, epoch: 6 | loss: 0.0549157\n",
      "\tspeed: 0.0340s/iter; left time: 716.1461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0582900 Vali Loss: 0.0568975 Test Loss: 0.0601823\n",
      "Validation loss decreased (0.057691 --> 0.056897).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0597739\n",
      "\tspeed: 0.0634s/iter; left time: 1329.4983s\n",
      "\titers: 200, epoch: 7 | loss: 0.0557049\n",
      "\tspeed: 0.0338s/iter; left time: 704.6721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0573733 Vali Loss: 0.0562706 Test Loss: 0.0595303\n",
      "Validation loss decreased (0.056897 --> 0.056271).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0595894\n",
      "\tspeed: 0.0636s/iter; left time: 1319.4512s\n",
      "\titers: 200, epoch: 8 | loss: 0.0569145\n",
      "\tspeed: 0.0339s/iter; left time: 699.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0567145 Vali Loss: 0.0558174 Test Loss: 0.0591373\n",
      "Validation loss decreased (0.056271 --> 0.055817).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0568185\n",
      "\tspeed: 0.0630s/iter; left time: 1291.9065s\n",
      "\titers: 200, epoch: 9 | loss: 0.0579889\n",
      "\tspeed: 0.0339s/iter; left time: 690.9568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0561700 Vali Loss: 0.0554012 Test Loss: 0.0587200\n",
      "Validation loss decreased (0.055817 --> 0.055401).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0552366\n",
      "\tspeed: 0.0643s/iter; left time: 1304.0597s\n",
      "\titers: 200, epoch: 10 | loss: 0.0576353\n",
      "\tspeed: 0.0339s/iter; left time: 685.2184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0557297 Vali Loss: 0.0552699 Test Loss: 0.0583700\n",
      "Validation loss decreased (0.055401 --> 0.055270).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569591\n",
      "\tspeed: 0.0637s/iter; left time: 1278.0031s\n",
      "\titers: 200, epoch: 11 | loss: 0.0549891\n",
      "\tspeed: 0.0339s/iter; left time: 676.7483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0553976 Vali Loss: 0.0552579 Test Loss: 0.0583410\n",
      "Validation loss decreased (0.055270 --> 0.055258).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558492\n",
      "\tspeed: 0.0640s/iter; left time: 1269.3833s\n",
      "\titers: 200, epoch: 12 | loss: 0.0542611\n",
      "\tspeed: 0.0341s/iter; left time: 672.1110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0551059 Vali Loss: 0.0549728 Test Loss: 0.0580589\n",
      "Validation loss decreased (0.055258 --> 0.054973).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0535999\n",
      "\tspeed: 0.0647s/iter; left time: 1268.4732s\n",
      "\titers: 200, epoch: 13 | loss: 0.0559298\n",
      "\tspeed: 0.0342s/iter; left time: 667.6684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0547429 Vali Loss: 0.0549172 Test Loss: 0.0579679\n",
      "Validation loss decreased (0.054973 --> 0.054917).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0529017\n",
      "\tspeed: 0.0634s/iter; left time: 1228.7968s\n",
      "\titers: 200, epoch: 14 | loss: 0.0515292\n",
      "\tspeed: 0.0341s/iter; left time: 657.5581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0545808 Vali Loss: 0.0548573 Test Loss: 0.0578365\n",
      "Validation loss decreased (0.054917 --> 0.054857).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0529730\n",
      "\tspeed: 0.0632s/iter; left time: 1210.7666s\n",
      "\titers: 200, epoch: 15 | loss: 0.0543535\n",
      "\tspeed: 0.0339s/iter; left time: 646.9571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0543980 Vali Loss: 0.0548917 Test Loss: 0.0579333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0531671\n",
      "\tspeed: 0.0628s/iter; left time: 1189.8872s\n",
      "\titers: 200, epoch: 16 | loss: 0.0551569\n",
      "\tspeed: 0.0338s/iter; left time: 636.6986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0542372 Vali Loss: 0.0547073 Test Loss: 0.0578216\n",
      "Validation loss decreased (0.054857 --> 0.054707).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0498223\n",
      "\tspeed: 0.0640s/iter; left time: 1197.1398s\n",
      "\titers: 200, epoch: 17 | loss: 0.0495734\n",
      "\tspeed: 0.0342s/iter; left time: 636.5193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0540312 Vali Loss: 0.0546522 Test Loss: 0.0577874\n",
      "Validation loss decreased (0.054707 --> 0.054652).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0524506\n",
      "\tspeed: 0.0665s/iter; left time: 1229.7721s\n",
      "\titers: 200, epoch: 18 | loss: 0.0500953\n",
      "\tspeed: 0.0339s/iter; left time: 623.8325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0539062 Vali Loss: 0.0546065 Test Loss: 0.0576987\n",
      "Validation loss decreased (0.054652 --> 0.054607).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0556998\n",
      "\tspeed: 0.0630s/iter; left time: 1150.0473s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539675\n",
      "\tspeed: 0.0341s/iter; left time: 619.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0538145 Vali Loss: 0.0546639 Test Loss: 0.0576787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0527673\n",
      "\tspeed: 0.0616s/iter; left time: 1111.4715s\n",
      "\titers: 200, epoch: 20 | loss: 0.0554663\n",
      "\tspeed: 0.0340s/iter; left time: 609.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0537279 Vali Loss: 0.0545529 Test Loss: 0.0575282\n",
      "Validation loss decreased (0.054607 --> 0.054553).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0509504\n",
      "\tspeed: 0.0630s/iter; left time: 1122.2505s\n",
      "\titers: 200, epoch: 21 | loss: 0.0495274\n",
      "\tspeed: 0.0339s/iter; left time: 599.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0535640 Vali Loss: 0.0544416 Test Loss: 0.0574515\n",
      "Validation loss decreased (0.054553 --> 0.054442).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0533115\n",
      "\tspeed: 0.0629s/iter; left time: 1107.1221s\n",
      "\titers: 200, epoch: 22 | loss: 0.0542290\n",
      "\tspeed: 0.0338s/iter; left time: 591.3214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0534959 Vali Loss: 0.0542820 Test Loss: 0.0574463\n",
      "Validation loss decreased (0.054442 --> 0.054282).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0526288\n",
      "\tspeed: 0.0633s/iter; left time: 1100.3808s\n",
      "\titers: 200, epoch: 23 | loss: 0.0600811\n",
      "\tspeed: 0.0342s/iter; left time: 589.9398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0534766 Vali Loss: 0.0543668 Test Loss: 0.0574086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0539013\n",
      "\tspeed: 0.0628s/iter; left time: 1077.5361s\n",
      "\titers: 200, epoch: 24 | loss: 0.0493163\n",
      "\tspeed: 0.0342s/iter; left time: 582.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0533377 Vali Loss: 0.0544038 Test Loss: 0.0574341\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0503086\n",
      "\tspeed: 0.0626s/iter; left time: 1060.0305s\n",
      "\titers: 200, epoch: 25 | loss: 0.0536984\n",
      "\tspeed: 0.0338s/iter; left time: 569.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0533721 Vali Loss: 0.0542806 Test Loss: 0.0573443\n",
      "Validation loss decreased (0.054282 --> 0.054281).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0499277\n",
      "\tspeed: 0.0641s/iter; left time: 1069.8160s\n",
      "\titers: 200, epoch: 26 | loss: 0.0532250\n",
      "\tspeed: 0.0347s/iter; left time: 576.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0533321 Vali Loss: 0.0543798 Test Loss: 0.0574476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0477513\n",
      "\tspeed: 0.0621s/iter; left time: 1023.4171s\n",
      "\titers: 200, epoch: 27 | loss: 0.0493515\n",
      "\tspeed: 0.0339s/iter; left time: 555.7160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0532538 Vali Loss: 0.0543540 Test Loss: 0.0573775\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0525711\n",
      "\tspeed: 0.0630s/iter; left time: 1023.9152s\n",
      "\titers: 200, epoch: 28 | loss: 0.0506829\n",
      "\tspeed: 0.0339s/iter; left time: 547.2639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0532494 Vali Loss: 0.0543063 Test Loss: 0.0573612\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0528766\n",
      "\tspeed: 0.0626s/iter; left time: 1002.6497s\n",
      "\titers: 200, epoch: 29 | loss: 0.0544927\n",
      "\tspeed: 0.0348s/iter; left time: 553.7796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0531865 Vali Loss: 0.0542757 Test Loss: 0.0572928\n",
      "Validation loss decreased (0.054281 --> 0.054276).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0529646\n",
      "\tspeed: 0.0637s/iter; left time: 1007.3349s\n",
      "\titers: 200, epoch: 30 | loss: 0.0546274\n",
      "\tspeed: 0.0339s/iter; left time: 532.4153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0531795 Vali Loss: 0.0543578 Test Loss: 0.0573470\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0503102\n",
      "\tspeed: 0.0623s/iter; left time: 971.2654s\n",
      "\titers: 200, epoch: 31 | loss: 0.0527957\n",
      "\tspeed: 0.0339s/iter; left time: 524.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0531406 Vali Loss: 0.0542675 Test Loss: 0.0572747\n",
      "Validation loss decreased (0.054276 --> 0.054267).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0553217\n",
      "\tspeed: 0.0630s/iter; left time: 967.9845s\n",
      "\titers: 200, epoch: 32 | loss: 0.0545876\n",
      "\tspeed: 0.0341s/iter; left time: 520.2935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0530841 Vali Loss: 0.0542606 Test Loss: 0.0572245\n",
      "Validation loss decreased (0.054267 --> 0.054261).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0551260\n",
      "\tspeed: 0.0644s/iter; left time: 974.4908s\n",
      "\titers: 200, epoch: 33 | loss: 0.0535069\n",
      "\tspeed: 0.0337s/iter; left time: 506.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0530346 Vali Loss: 0.0544190 Test Loss: 0.0573000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0557198\n",
      "\tspeed: 0.0624s/iter; left time: 930.4660s\n",
      "\titers: 200, epoch: 34 | loss: 0.0516284\n",
      "\tspeed: 0.0342s/iter; left time: 506.7373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0530344 Vali Loss: 0.0543570 Test Loss: 0.0573233\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517058\n",
      "\tspeed: 0.0624s/iter; left time: 916.4048s\n",
      "\titers: 200, epoch: 35 | loss: 0.0504066\n",
      "\tspeed: 0.0344s/iter; left time: 502.1405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0530052 Vali Loss: 0.0542769 Test Loss: 0.0572484\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0498497\n",
      "\tspeed: 0.0625s/iter; left time: 904.5077s\n",
      "\titers: 200, epoch: 36 | loss: 0.0520643\n",
      "\tspeed: 0.0341s/iter; left time: 490.0631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0529799 Vali Loss: 0.0543435 Test Loss: 0.0572919\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0537570\n",
      "\tspeed: 0.0623s/iter; left time: 887.2193s\n",
      "\titers: 200, epoch: 37 | loss: 0.0553898\n",
      "\tspeed: 0.0338s/iter; left time: 477.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0529558 Vali Loss: 0.0542968 Test Loss: 0.0572239\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0527173\n",
      "\tspeed: 0.0625s/iter; left time: 875.5509s\n",
      "\titers: 200, epoch: 38 | loss: 0.0577624\n",
      "\tspeed: 0.0342s/iter; left time: 476.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0529243 Vali Loss: 0.0542218 Test Loss: 0.0572267\n",
      "Validation loss decreased (0.054261 --> 0.054222).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0527045\n",
      "\tspeed: 0.0640s/iter; left time: 882.6612s\n",
      "\titers: 200, epoch: 39 | loss: 0.0528507\n",
      "\tspeed: 0.0339s/iter; left time: 464.4768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0529220 Vali Loss: 0.0541531 Test Loss: 0.0572099\n",
      "Validation loss decreased (0.054222 --> 0.054153).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0555587\n",
      "\tspeed: 0.0640s/iter; left time: 867.7170s\n",
      "\titers: 200, epoch: 40 | loss: 0.0516601\n",
      "\tspeed: 0.0341s/iter; left time: 459.2415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0529083 Vali Loss: 0.0542817 Test Loss: 0.0572354\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0571790\n",
      "\tspeed: 0.0624s/iter; left time: 831.8615s\n",
      "\titers: 200, epoch: 41 | loss: 0.0551317\n",
      "\tspeed: 0.0341s/iter; left time: 451.7523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0529310 Vali Loss: 0.0542987 Test Loss: 0.0572387\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0539040\n",
      "\tspeed: 0.0630s/iter; left time: 825.8557s\n",
      "\titers: 200, epoch: 42 | loss: 0.0542281\n",
      "\tspeed: 0.0337s/iter; left time: 438.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0529366 Vali Loss: 0.0542584 Test Loss: 0.0572168\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0535784\n",
      "\tspeed: 0.0626s/iter; left time: 807.4526s\n",
      "\titers: 200, epoch: 43 | loss: 0.0499920\n",
      "\tspeed: 0.0342s/iter; left time: 437.9764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0529107 Vali Loss: 0.0541936 Test Loss: 0.0572207\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0497392\n",
      "\tspeed: 0.0628s/iter; left time: 795.9702s\n",
      "\titers: 200, epoch: 44 | loss: 0.0531565\n",
      "\tspeed: 0.0340s/iter; left time: 426.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0529647 Vali Loss: 0.0542098 Test Loss: 0.0572039\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0524694\n",
      "\tspeed: 0.0625s/iter; left time: 778.1356s\n",
      "\titers: 200, epoch: 45 | loss: 0.0541316\n",
      "\tspeed: 0.0339s/iter; left time: 418.6191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0529106 Vali Loss: 0.0542475 Test Loss: 0.0571963\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0542567\n",
      "\tspeed: 0.0686s/iter; left time: 837.9284s\n",
      "\titers: 200, epoch: 46 | loss: 0.0523972\n",
      "\tspeed: 0.0366s/iter; left time: 444.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0529340 Vali Loss: 0.0542955 Test Loss: 0.0572426\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0530457\n",
      "\tspeed: 0.0623s/iter; left time: 747.2901s\n",
      "\titers: 200, epoch: 47 | loss: 0.0522194\n",
      "\tspeed: 0.0339s/iter; left time: 403.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0528431 Vali Loss: 0.0543051 Test Loss: 0.0572482\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0551153\n",
      "\tspeed: 0.0625s/iter; left time: 735.7430s\n",
      "\titers: 200, epoch: 48 | loss: 0.0525597\n",
      "\tspeed: 0.0339s/iter; left time: 395.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0528467 Vali Loss: 0.0542701 Test Loss: 0.0572070\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0565221\n",
      "\tspeed: 0.0624s/iter; left time: 720.8405s\n",
      "\titers: 200, epoch: 49 | loss: 0.0526045\n",
      "\tspeed: 0.0338s/iter; left time: 386.8022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0529101 Vali Loss: 0.0542374 Test Loss: 0.0571746\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010236818343400955, rmse:0.1011771634221077, mae:0.05720987543463707, rse:0.38229870796203613\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1621688\n",
      "\tspeed: 0.0355s/iter; left time: 791.1282s\n",
      "\titers: 200, epoch: 1 | loss: 0.1480829\n",
      "\tspeed: 0.0337s/iter; left time: 748.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.1636317 Vali Loss: 0.1371520 Test Loss: 0.1445785\n",
      "Validation loss decreased (inf --> 0.137152).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0798413\n",
      "\tspeed: 0.0641s/iter; left time: 1414.4975s\n",
      "\titers: 200, epoch: 2 | loss: 0.0680234\n",
      "\tspeed: 0.0364s/iter; left time: 799.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 224 | Train Loss: 0.0861070 Vali Loss: 0.0640334 Test Loss: 0.0674341\n",
      "Validation loss decreased (0.137152 --> 0.064033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0621117\n",
      "\tspeed: 0.0641s/iter; left time: 1400.5036s\n",
      "\titers: 200, epoch: 3 | loss: 0.0625479\n",
      "\tspeed: 0.0344s/iter; left time: 748.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0656358 Vali Loss: 0.0609181 Test Loss: 0.0640399\n",
      "Validation loss decreased (0.064033 --> 0.060918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0576662\n",
      "\tspeed: 0.0654s/iter; left time: 1414.0814s\n",
      "\titers: 200, epoch: 4 | loss: 0.0587245\n",
      "\tspeed: 0.0339s/iter; left time: 729.6234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0623379 Vali Loss: 0.0589963 Test Loss: 0.0623144\n",
      "Validation loss decreased (0.060918 --> 0.058996).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582271\n",
      "\tspeed: 0.0632s/iter; left time: 1353.7053s\n",
      "\titers: 200, epoch: 5 | loss: 0.0601743\n",
      "\tspeed: 0.0340s/iter; left time: 723.5229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0601944 Vali Loss: 0.0576187 Test Loss: 0.0609705\n",
      "Validation loss decreased (0.058996 --> 0.057619).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0583400\n",
      "\tspeed: 0.0627s/iter; left time: 1327.2818s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598197\n",
      "\tspeed: 0.0339s/iter; left time: 714.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0586558 Vali Loss: 0.0567894 Test Loss: 0.0597033\n",
      "Validation loss decreased (0.057619 --> 0.056789).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0587187\n",
      "\tspeed: 0.0642s/iter; left time: 1345.4747s\n",
      "\titers: 200, epoch: 7 | loss: 0.0549502\n",
      "\tspeed: 0.0338s/iter; left time: 705.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0575522 Vali Loss: 0.0564804 Test Loss: 0.0593413\n",
      "Validation loss decreased (0.056789 --> 0.056480).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0576376\n",
      "\tspeed: 0.0635s/iter; left time: 1317.1115s\n",
      "\titers: 200, epoch: 8 | loss: 0.0604712\n",
      "\tspeed: 0.0338s/iter; left time: 697.7233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0568006 Vali Loss: 0.0560504 Test Loss: 0.0590656\n",
      "Validation loss decreased (0.056480 --> 0.056050).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0524535\n",
      "\tspeed: 0.0645s/iter; left time: 1322.3546s\n",
      "\titers: 200, epoch: 9 | loss: 0.0537298\n",
      "\tspeed: 0.0338s/iter; left time: 689.8205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0561865 Vali Loss: 0.0557121 Test Loss: 0.0586558\n",
      "Validation loss decreased (0.056050 --> 0.055712).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570483\n",
      "\tspeed: 0.0631s/iter; left time: 1279.1294s\n",
      "\titers: 200, epoch: 10 | loss: 0.0529609\n",
      "\tspeed: 0.0338s/iter; left time: 682.1217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0557597 Vali Loss: 0.0554276 Test Loss: 0.0585423\n",
      "Validation loss decreased (0.055712 --> 0.055428).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0543032\n",
      "\tspeed: 0.0659s/iter; left time: 1321.7488s\n",
      "\titers: 200, epoch: 11 | loss: 0.0550120\n",
      "\tspeed: 0.0337s/iter; left time: 673.5995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0553544 Vali Loss: 0.0552403 Test Loss: 0.0582124\n",
      "Validation loss decreased (0.055428 --> 0.055240).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0529443\n",
      "\tspeed: 0.0664s/iter; left time: 1316.7593s\n",
      "\titers: 200, epoch: 12 | loss: 0.0546039\n",
      "\tspeed: 0.0340s/iter; left time: 670.6249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0550798 Vali Loss: 0.0553219 Test Loss: 0.0583543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0552135\n",
      "\tspeed: 0.0620s/iter; left time: 1216.8340s\n",
      "\titers: 200, epoch: 13 | loss: 0.0542144\n",
      "\tspeed: 0.0339s/iter; left time: 661.2807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0548424 Vali Loss: 0.0552345 Test Loss: 0.0580900\n",
      "Validation loss decreased (0.055240 --> 0.055235).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0516681\n",
      "\tspeed: 0.0628s/iter; left time: 1216.7089s\n",
      "\titers: 200, epoch: 14 | loss: 0.0560737\n",
      "\tspeed: 0.0338s/iter; left time: 652.4142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0546319 Vali Loss: 0.0550627 Test Loss: 0.0579910\n",
      "Validation loss decreased (0.055235 --> 0.055063).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0576609\n",
      "\tspeed: 0.0627s/iter; left time: 1201.5765s\n",
      "\titers: 200, epoch: 15 | loss: 0.0566705\n",
      "\tspeed: 0.0340s/iter; left time: 648.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0543967 Vali Loss: 0.0550173 Test Loss: 0.0579663\n",
      "Validation loss decreased (0.055063 --> 0.055017).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0581773\n",
      "\tspeed: 0.0634s/iter; left time: 1201.0449s\n",
      "\titers: 200, epoch: 16 | loss: 0.0566819\n",
      "\tspeed: 0.0340s/iter; left time: 640.9139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0542331 Vali Loss: 0.0548165 Test Loss: 0.0577646\n",
      "Validation loss decreased (0.055017 --> 0.054816).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0518837\n",
      "\tspeed: 0.0632s/iter; left time: 1183.1684s\n",
      "\titers: 200, epoch: 17 | loss: 0.0521889\n",
      "\tspeed: 0.0340s/iter; left time: 633.3272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0540859 Vali Loss: 0.0547377 Test Loss: 0.0577218\n",
      "Validation loss decreased (0.054816 --> 0.054738).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0507305\n",
      "\tspeed: 0.0633s/iter; left time: 1170.5826s\n",
      "\titers: 200, epoch: 18 | loss: 0.0521321\n",
      "\tspeed: 0.0338s/iter; left time: 622.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0539531 Vali Loss: 0.0547232 Test Loss: 0.0576991\n",
      "Validation loss decreased (0.054738 --> 0.054723).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0515661\n",
      "\tspeed: 0.0640s/iter; left time: 1169.6368s\n",
      "\titers: 200, epoch: 19 | loss: 0.0490565\n",
      "\tspeed: 0.0339s/iter; left time: 615.0773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0538102 Vali Loss: 0.0545976 Test Loss: 0.0575722\n",
      "Validation loss decreased (0.054723 --> 0.054598).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0540523\n",
      "\tspeed: 0.0627s/iter; left time: 1131.3324s\n",
      "\titers: 200, epoch: 20 | loss: 0.0558243\n",
      "\tspeed: 0.0340s/iter; left time: 610.6172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0537262 Vali Loss: 0.0545503 Test Loss: 0.0574780\n",
      "Validation loss decreased (0.054598 --> 0.054550).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0531959\n",
      "\tspeed: 0.0634s/iter; left time: 1130.4634s\n",
      "\titers: 200, epoch: 21 | loss: 0.0531068\n",
      "\tspeed: 0.0346s/iter; left time: 612.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0536436 Vali Loss: 0.0545609 Test Loss: 0.0576187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0549796\n",
      "\tspeed: 0.0621s/iter; left time: 1092.5973s\n",
      "\titers: 200, epoch: 22 | loss: 0.0504838\n",
      "\tspeed: 0.0339s/iter; left time: 592.9505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0535751 Vali Loss: 0.0543996 Test Loss: 0.0574319\n",
      "Validation loss decreased (0.054550 --> 0.054400).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0524602\n",
      "\tspeed: 0.0641s/iter; left time: 1114.2832s\n",
      "\titers: 200, epoch: 23 | loss: 0.0520602\n",
      "\tspeed: 0.0341s/iter; left time: 588.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0534214 Vali Loss: 0.0544026 Test Loss: 0.0573988\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0566802\n",
      "\tspeed: 0.0631s/iter; left time: 1081.8506s\n",
      "\titers: 200, epoch: 24 | loss: 0.0517550\n",
      "\tspeed: 0.0344s/iter; left time: 586.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0533806 Vali Loss: 0.0544291 Test Loss: 0.0574103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0517298\n",
      "\tspeed: 0.0632s/iter; left time: 1069.6751s\n",
      "\titers: 200, epoch: 25 | loss: 0.0507057\n",
      "\tspeed: 0.0340s/iter; left time: 572.3292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0533945 Vali Loss: 0.0544829 Test Loss: 0.0574231\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0491315\n",
      "\tspeed: 0.0624s/iter; left time: 1042.1019s\n",
      "\titers: 200, epoch: 26 | loss: 0.0530935\n",
      "\tspeed: 0.0337s/iter; left time: 559.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0533575 Vali Loss: 0.0542973 Test Loss: 0.0573110\n",
      "Validation loss decreased (0.054400 --> 0.054297).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0490967\n",
      "\tspeed: 0.0631s/iter; left time: 1040.0874s\n",
      "\titers: 200, epoch: 27 | loss: 0.0517953\n",
      "\tspeed: 0.0343s/iter; left time: 562.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0532923 Vali Loss: 0.0543248 Test Loss: 0.0573602\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0512018\n",
      "\tspeed: 0.0635s/iter; left time: 1031.3157s\n",
      "\titers: 200, epoch: 28 | loss: 0.0506737\n",
      "\tspeed: 0.0338s/iter; left time: 546.2470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0532094 Vali Loss: 0.0543913 Test Loss: 0.0573815\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0583045\n",
      "\tspeed: 0.0630s/iter; left time: 1009.2881s\n",
      "\titers: 200, epoch: 29 | loss: 0.0556699\n",
      "\tspeed: 0.0339s/iter; left time: 540.1052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0531794 Vali Loss: 0.0543335 Test Loss: 0.0573315\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0514338\n",
      "\tspeed: 0.0629s/iter; left time: 994.8156s\n",
      "\titers: 200, epoch: 30 | loss: 0.0496146\n",
      "\tspeed: 0.0340s/iter; left time: 533.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0532194 Vali Loss: 0.0542887 Test Loss: 0.0572902\n",
      "Validation loss decreased (0.054297 --> 0.054289).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0534682\n",
      "\tspeed: 0.0640s/iter; left time: 997.0319s\n",
      "\titers: 200, epoch: 31 | loss: 0.0533699\n",
      "\tspeed: 0.0341s/iter; left time: 527.6837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0530668 Vali Loss: 0.0543162 Test Loss: 0.0572438\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0534906\n",
      "\tspeed: 0.0635s/iter; left time: 975.1197s\n",
      "\titers: 200, epoch: 32 | loss: 0.0558061\n",
      "\tspeed: 0.0343s/iter; left time: 523.9937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0530975 Vali Loss: 0.0542848 Test Loss: 0.0572557\n",
      "Validation loss decreased (0.054289 --> 0.054285).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0511128\n",
      "\tspeed: 0.0639s/iter; left time: 967.5762s\n",
      "\titers: 200, epoch: 33 | loss: 0.0516018\n",
      "\tspeed: 0.0339s/iter; left time: 509.5225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0530165 Vali Loss: 0.0542628 Test Loss: 0.0572513\n",
      "Validation loss decreased (0.054285 --> 0.054263).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0518864\n",
      "\tspeed: 0.0642s/iter; left time: 957.8793s\n",
      "\titers: 200, epoch: 34 | loss: 0.0545096\n",
      "\tspeed: 0.0339s/iter; left time: 501.6444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0529784 Vali Loss: 0.0542210 Test Loss: 0.0572153\n",
      "Validation loss decreased (0.054263 --> 0.054221).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0510553\n",
      "\tspeed: 0.0643s/iter; left time: 943.7723s\n",
      "\titers: 200, epoch: 35 | loss: 0.0511590\n",
      "\tspeed: 0.0344s/iter; left time: 501.6780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0529844 Vali Loss: 0.0542394 Test Loss: 0.0572186\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0522200\n",
      "\tspeed: 0.0624s/iter; left time: 901.9441s\n",
      "\titers: 200, epoch: 36 | loss: 0.0524517\n",
      "\tspeed: 0.0342s/iter; left time: 491.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0530213 Vali Loss: 0.0542710 Test Loss: 0.0572017\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0506751\n",
      "\tspeed: 0.0628s/iter; left time: 893.4562s\n",
      "\titers: 200, epoch: 37 | loss: 0.0464932\n",
      "\tspeed: 0.0340s/iter; left time: 481.2202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0530234 Vali Loss: 0.0541738 Test Loss: 0.0571844\n",
      "Validation loss decreased (0.054221 --> 0.054174).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0501622\n",
      "\tspeed: 0.0630s/iter; left time: 882.1578s\n",
      "\titers: 200, epoch: 38 | loss: 0.0518436\n",
      "\tspeed: 0.0339s/iter; left time: 471.0068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0529541 Vali Loss: 0.0543143 Test Loss: 0.0572248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0525550\n",
      "\tspeed: 0.0627s/iter; left time: 864.7172s\n",
      "\titers: 200, epoch: 39 | loss: 0.0533633\n",
      "\tspeed: 0.0341s/iter; left time: 467.3947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0529305 Vali Loss: 0.0541389 Test Loss: 0.0571800\n",
      "Validation loss decreased (0.054174 --> 0.054139).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0552160\n",
      "\tspeed: 0.0643s/iter; left time: 872.1290s\n",
      "\titers: 200, epoch: 40 | loss: 0.0551916\n",
      "\tspeed: 0.0340s/iter; left time: 458.3141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0528851 Vali Loss: 0.0541413 Test Loss: 0.0571632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530558\n",
      "\tspeed: 0.0634s/iter; left time: 845.3774s\n",
      "\titers: 200, epoch: 41 | loss: 0.0574618\n",
      "\tspeed: 0.0340s/iter; left time: 450.5248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0529675 Vali Loss: 0.0541982 Test Loss: 0.0571757\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0524376\n",
      "\tspeed: 0.0624s/iter; left time: 817.9675s\n",
      "\titers: 200, epoch: 42 | loss: 0.0524560\n",
      "\tspeed: 0.0337s/iter; left time: 439.2131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0529099 Vali Loss: 0.0541665 Test Loss: 0.0571621\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0551292\n",
      "\tspeed: 0.0624s/iter; left time: 805.1638s\n",
      "\titers: 200, epoch: 43 | loss: 0.0514255\n",
      "\tspeed: 0.0339s/iter; left time: 434.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0529093 Vali Loss: 0.0542868 Test Loss: 0.0571981\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0526689\n",
      "\tspeed: 0.0622s/iter; left time: 787.9536s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535498\n",
      "\tspeed: 0.0340s/iter; left time: 427.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0529326 Vali Loss: 0.0542185 Test Loss: 0.0571942\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0596547\n",
      "\tspeed: 0.0627s/iter; left time: 779.7806s\n",
      "\titers: 200, epoch: 45 | loss: 0.0498769\n",
      "\tspeed: 0.0338s/iter; left time: 417.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0528972 Vali Loss: 0.0542430 Test Loss: 0.0572216\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0516230\n",
      "\tspeed: 0.0624s/iter; left time: 762.5652s\n",
      "\titers: 200, epoch: 46 | loss: 0.0527195\n",
      "\tspeed: 0.0339s/iter; left time: 410.8358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0528695 Vali Loss: 0.0541202 Test Loss: 0.0571376\n",
      "Validation loss decreased (0.054139 --> 0.054120).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0525249\n",
      "\tspeed: 0.0630s/iter; left time: 756.0183s\n",
      "\titers: 200, epoch: 47 | loss: 0.0511307\n",
      "\tspeed: 0.0339s/iter; left time: 403.1342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0529027 Vali Loss: 0.0541644 Test Loss: 0.0571724\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0508050\n",
      "\tspeed: 0.0629s/iter; left time: 740.6182s\n",
      "\titers: 200, epoch: 48 | loss: 0.0541915\n",
      "\tspeed: 0.0342s/iter; left time: 399.0152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0528709 Vali Loss: 0.0541885 Test Loss: 0.0571710\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0553696\n",
      "\tspeed: 0.0624s/iter; left time: 720.8960s\n",
      "\titers: 200, epoch: 49 | loss: 0.0518353\n",
      "\tspeed: 0.0338s/iter; left time: 387.3759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0529159 Vali Loss: 0.0541697 Test Loss: 0.0571644\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0539344\n",
      "\tspeed: 0.0623s/iter; left time: 706.1050s\n",
      "\titers: 200, epoch: 50 | loss: 0.0496123\n",
      "\tspeed: 0.0341s/iter; left time: 383.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0528739 Vali Loss: 0.0541643 Test Loss: 0.0571312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0521338\n",
      "\tspeed: 0.0628s/iter; left time: 697.1460s\n",
      "\titers: 200, epoch: 51 | loss: 0.0517713\n",
      "\tspeed: 0.0340s/iter; left time: 374.4859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0529285 Vali Loss: 0.0541869 Test Loss: 0.0571487\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0502872\n",
      "\tspeed: 0.0632s/iter; left time: 687.5517s\n",
      "\titers: 200, epoch: 52 | loss: 0.0518404\n",
      "\tspeed: 0.0340s/iter; left time: 366.8974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0528991 Vali Loss: 0.0541382 Test Loss: 0.0571131\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0528773\n",
      "\tspeed: 0.0640s/iter; left time: 682.1553s\n",
      "\titers: 200, epoch: 53 | loss: 0.0550838\n",
      "\tspeed: 0.0340s/iter; left time: 359.0225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0528394 Vali Loss: 0.0540858 Test Loss: 0.0571252\n",
      "Validation loss decreased (0.054120 --> 0.054086).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0533713\n",
      "\tspeed: 0.0640s/iter; left time: 667.0699s\n",
      "\titers: 200, epoch: 54 | loss: 0.0546677\n",
      "\tspeed: 0.0341s/iter; left time: 351.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0529049 Vali Loss: 0.0541218 Test Loss: 0.0571443\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0513141\n",
      "\tspeed: 0.0628s/iter; left time: 641.3197s\n",
      "\titers: 200, epoch: 55 | loss: 0.0553885\n",
      "\tspeed: 0.0339s/iter; left time: 342.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0528430 Vali Loss: 0.0541577 Test Loss: 0.0571592\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0541152\n",
      "\tspeed: 0.0631s/iter; left time: 629.7683s\n",
      "\titers: 200, epoch: 56 | loss: 0.0500019\n",
      "\tspeed: 0.0343s/iter; left time: 338.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0528580 Vali Loss: 0.0541782 Test Loss: 0.0571533\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0504828\n",
      "\tspeed: 0.0635s/iter; left time: 620.0526s\n",
      "\titers: 200, epoch: 57 | loss: 0.0521803\n",
      "\tspeed: 0.0341s/iter; left time: 328.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0528007 Vali Loss: 0.0541686 Test Loss: 0.0571215\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0518517\n",
      "\tspeed: 0.0623s/iter; left time: 594.2006s\n",
      "\titers: 200, epoch: 58 | loss: 0.0560168\n",
      "\tspeed: 0.0338s/iter; left time: 319.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0528598 Vali Loss: 0.0542424 Test Loss: 0.0571867\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0541537\n",
      "\tspeed: 0.0626s/iter; left time: 582.9825s\n",
      "\titers: 200, epoch: 59 | loss: 0.0537782\n",
      "\tspeed: 0.0340s/iter; left time: 313.2510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0528410 Vali Loss: 0.0541864 Test Loss: 0.0571392\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0491767\n",
      "\tspeed: 0.0624s/iter; left time: 566.7145s\n",
      "\titers: 200, epoch: 60 | loss: 0.0531485\n",
      "\tspeed: 0.0339s/iter; left time: 304.3246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0528693 Vali Loss: 0.0541679 Test Loss: 0.0571413\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0544172\n",
      "\tspeed: 0.0625s/iter; left time: 553.4237s\n",
      "\titers: 200, epoch: 61 | loss: 0.0510035\n",
      "\tspeed: 0.0338s/iter; left time: 296.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0528560 Vali Loss: 0.0542183 Test Loss: 0.0571623\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0512042\n",
      "\tspeed: 0.0628s/iter; left time: 542.5279s\n",
      "\titers: 200, epoch: 62 | loss: 0.0531393\n",
      "\tspeed: 0.0346s/iter; left time: 295.4480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0528431 Vali Loss: 0.0541732 Test Loss: 0.0571681\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0540698\n",
      "\tspeed: 0.0628s/iter; left time: 528.2091s\n",
      "\titers: 200, epoch: 63 | loss: 0.0589358\n",
      "\tspeed: 0.0339s/iter; left time: 281.6424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0528726 Vali Loss: 0.0541508 Test Loss: 0.0571197\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01018845196813345, rmse:0.1009378582239151, mae:0.057125240564346313, rse:0.38139447569847107\n",
      "Intermediate time for IT and pred_len 24: 00h:18m:22.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1708428\n",
      "\tspeed: 0.0604s/iter; left time: 1345.8820s\n",
      "\titers: 200, epoch: 1 | loss: 0.1594457\n",
      "\tspeed: 0.0345s/iter; left time: 764.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.1731542 Vali Loss: 0.1467581 Test Loss: 0.1548955\n",
      "Validation loss decreased (inf --> 0.146758).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0911917\n",
      "\tspeed: 0.0676s/iter; left time: 1492.1971s\n",
      "\titers: 200, epoch: 2 | loss: 0.0814402\n",
      "\tspeed: 0.0346s/iter; left time: 760.2033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1010911 Vali Loss: 0.0820083 Test Loss: 0.0875059\n",
      "Validation loss decreased (0.146758 --> 0.082008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0830979\n",
      "\tspeed: 0.0655s/iter; left time: 1430.7089s\n",
      "\titers: 200, epoch: 3 | loss: 0.0889395\n",
      "\tspeed: 0.0343s/iter; left time: 745.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0844789 Vali Loss: 0.0791793 Test Loss: 0.0851529\n",
      "Validation loss decreased (0.082008 --> 0.079179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0824321\n",
      "\tspeed: 0.0652s/iter; left time: 1409.2475s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785757\n",
      "\tspeed: 0.0344s/iter; left time: 740.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0813190 Vali Loss: 0.0774232 Test Loss: 0.0832199\n",
      "Validation loss decreased (0.079179 --> 0.077423).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0809543\n",
      "\tspeed: 0.0650s/iter; left time: 1392.1430s\n",
      "\titers: 200, epoch: 5 | loss: 0.0777268\n",
      "\tspeed: 0.0347s/iter; left time: 739.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0791435 Vali Loss: 0.0766719 Test Loss: 0.0825766\n",
      "Validation loss decreased (0.077423 --> 0.076672).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0763184\n",
      "\tspeed: 0.0653s/iter; left time: 1382.2476s\n",
      "\titers: 200, epoch: 6 | loss: 0.0782094\n",
      "\tspeed: 0.0360s/iter; left time: 758.0795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 224 | Train Loss: 0.0778040 Vali Loss: 0.0764557 Test Loss: 0.0820813\n",
      "Validation loss decreased (0.076672 --> 0.076456).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754540\n",
      "\tspeed: 0.0665s/iter; left time: 1394.0757s\n",
      "\titers: 200, epoch: 7 | loss: 0.0774429\n",
      "\tspeed: 0.0342s/iter; left time: 713.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0768773 Vali Loss: 0.0759133 Test Loss: 0.0815514\n",
      "Validation loss decreased (0.076456 --> 0.075913).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0827561\n",
      "\tspeed: 0.0653s/iter; left time: 1353.7802s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756439\n",
      "\tspeed: 0.0347s/iter; left time: 715.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0761391 Vali Loss: 0.0757392 Test Loss: 0.0811567\n",
      "Validation loss decreased (0.075913 --> 0.075739).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0711883\n",
      "\tspeed: 0.0655s/iter; left time: 1343.3206s\n",
      "\titers: 200, epoch: 9 | loss: 0.0744836\n",
      "\tspeed: 0.0342s/iter; left time: 698.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0754943 Vali Loss: 0.0753163 Test Loss: 0.0810659\n",
      "Validation loss decreased (0.075739 --> 0.075316).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0763812\n",
      "\tspeed: 0.0641s/iter; left time: 1300.1501s\n",
      "\titers: 200, epoch: 10 | loss: 0.0725944\n",
      "\tspeed: 0.0343s/iter; left time: 693.3268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0750145 Vali Loss: 0.0755616 Test Loss: 0.0812671\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0727805\n",
      "\tspeed: 0.0647s/iter; left time: 1297.2183s\n",
      "\titers: 200, epoch: 11 | loss: 0.0757687\n",
      "\tspeed: 0.0345s/iter; left time: 689.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0746283 Vali Loss: 0.0752170 Test Loss: 0.0808455\n",
      "Validation loss decreased (0.075316 --> 0.075217).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0721116\n",
      "\tspeed: 0.0648s/iter; left time: 1286.3889s\n",
      "\titers: 200, epoch: 12 | loss: 0.0727255\n",
      "\tspeed: 0.0342s/iter; left time: 675.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0742536 Vali Loss: 0.0751851 Test Loss: 0.0806396\n",
      "Validation loss decreased (0.075217 --> 0.075185).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0705675\n",
      "\tspeed: 0.0662s/iter; left time: 1297.5205s\n",
      "\titers: 200, epoch: 13 | loss: 0.0709595\n",
      "\tspeed: 0.0345s/iter; left time: 672.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0738950 Vali Loss: 0.0749574 Test Loss: 0.0804897\n",
      "Validation loss decreased (0.075185 --> 0.074957).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0724083\n",
      "\tspeed: 0.0652s/iter; left time: 1264.6320s\n",
      "\titers: 200, epoch: 14 | loss: 0.0710550\n",
      "\tspeed: 0.0348s/iter; left time: 671.2010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0735501 Vali Loss: 0.0751684 Test Loss: 0.0806189\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0723576\n",
      "\tspeed: 0.0642s/iter; left time: 1230.2187s\n",
      "\titers: 200, epoch: 15 | loss: 0.0725039\n",
      "\tspeed: 0.0342s/iter; left time: 651.1582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0732920 Vali Loss: 0.0750311 Test Loss: 0.0806733\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0713176\n",
      "\tspeed: 0.0638s/iter; left time: 1208.0324s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744308\n",
      "\tspeed: 0.0340s/iter; left time: 639.7744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0730593 Vali Loss: 0.0752731 Test Loss: 0.0807205\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0710878\n",
      "\tspeed: 0.0636s/iter; left time: 1189.7422s\n",
      "\titers: 200, epoch: 17 | loss: 0.0697964\n",
      "\tspeed: 0.0340s/iter; left time: 633.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0727951 Vali Loss: 0.0751548 Test Loss: 0.0807240\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0758380\n",
      "\tspeed: 0.0636s/iter; left time: 1175.4070s\n",
      "\titers: 200, epoch: 18 | loss: 0.0758936\n",
      "\tspeed: 0.0345s/iter; left time: 634.5195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0725756 Vali Loss: 0.0750683 Test Loss: 0.0805463\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716046\n",
      "\tspeed: 0.0644s/iter; left time: 1176.1559s\n",
      "\titers: 200, epoch: 19 | loss: 0.0751578\n",
      "\tspeed: 0.0344s/iter; left time: 625.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0723964 Vali Loss: 0.0750442 Test Loss: 0.0805577\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0689812\n",
      "\tspeed: 0.0640s/iter; left time: 1155.7426s\n",
      "\titers: 200, epoch: 20 | loss: 0.0691623\n",
      "\tspeed: 0.0344s/iter; left time: 617.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0722792 Vali Loss: 0.0751461 Test Loss: 0.0805010\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0688393\n",
      "\tspeed: 0.0641s/iter; left time: 1141.9272s\n",
      "\titers: 200, epoch: 21 | loss: 0.0750959\n",
      "\tspeed: 0.0344s/iter; left time: 610.2391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0720699 Vali Loss: 0.0750215 Test Loss: 0.0805558\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0725956\n",
      "\tspeed: 0.0642s/iter; left time: 1130.1982s\n",
      "\titers: 200, epoch: 22 | loss: 0.0757748\n",
      "\tspeed: 0.0344s/iter; left time: 601.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0718513 Vali Loss: 0.0750700 Test Loss: 0.0805067\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0682724\n",
      "\tspeed: 0.0649s/iter; left time: 1128.2544s\n",
      "\titers: 200, epoch: 23 | loss: 0.0704672\n",
      "\tspeed: 0.0346s/iter; left time: 597.2213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0718010 Vali Loss: 0.0751507 Test Loss: 0.0804503\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018429992720484734, rmse:0.13575710356235504, mae:0.08048970252275467, rse:0.5133122801780701\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1717162\n",
      "\tspeed: 0.0361s/iter; left time: 804.8448s\n",
      "\titers: 200, epoch: 1 | loss: 0.1547311\n",
      "\tspeed: 0.0342s/iter; left time: 759.0579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.1720086 Vali Loss: 0.1459155 Test Loss: 0.1540600\n",
      "Validation loss decreased (inf --> 0.145916).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0902586\n",
      "\tspeed: 0.0670s/iter; left time: 1479.2132s\n",
      "\titers: 200, epoch: 2 | loss: 0.0884021\n",
      "\tspeed: 0.0347s/iter; left time: 761.5463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1020034 Vali Loss: 0.0817397 Test Loss: 0.0876089\n",
      "Validation loss decreased (0.145916 --> 0.081740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0806921\n",
      "\tspeed: 0.0664s/iter; left time: 1450.4385s\n",
      "\titers: 200, epoch: 3 | loss: 0.0818520\n",
      "\tspeed: 0.0353s/iter; left time: 767.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0844065 Vali Loss: 0.0787544 Test Loss: 0.0849668\n",
      "Validation loss decreased (0.081740 --> 0.078754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0823183\n",
      "\tspeed: 0.0661s/iter; left time: 1430.1323s\n",
      "\titers: 200, epoch: 4 | loss: 0.0748083\n",
      "\tspeed: 0.0347s/iter; left time: 746.8314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0812384 Vali Loss: 0.0773447 Test Loss: 0.0834567\n",
      "Validation loss decreased (0.078754 --> 0.077345).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773717\n",
      "\tspeed: 0.0659s/iter; left time: 1411.4664s\n",
      "\titers: 200, epoch: 5 | loss: 0.0803391\n",
      "\tspeed: 0.0364s/iter; left time: 774.9536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.0791357 Vali Loss: 0.0765479 Test Loss: 0.0827161\n",
      "Validation loss decreased (0.077345 --> 0.076548).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0742378\n",
      "\tspeed: 0.0655s/iter; left time: 1387.0200s\n",
      "\titers: 200, epoch: 6 | loss: 0.0735158\n",
      "\tspeed: 0.0342s/iter; left time: 721.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0778847 Vali Loss: 0.0759478 Test Loss: 0.0819176\n",
      "Validation loss decreased (0.076548 --> 0.075948).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0798959\n",
      "\tspeed: 0.0656s/iter; left time: 1375.0080s\n",
      "\titers: 200, epoch: 7 | loss: 0.0762781\n",
      "\tspeed: 0.0346s/iter; left time: 721.0470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0770121 Vali Loss: 0.0754765 Test Loss: 0.0812748\n",
      "Validation loss decreased (0.075948 --> 0.075477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0762613\n",
      "\tspeed: 0.0663s/iter; left time: 1375.4889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738247\n",
      "\tspeed: 0.0348s/iter; left time: 717.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0763575 Vali Loss: 0.0754799 Test Loss: 0.0810893\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0707921\n",
      "\tspeed: 0.0644s/iter; left time: 1320.0440s\n",
      "\titers: 200, epoch: 9 | loss: 0.0730707\n",
      "\tspeed: 0.0343s/iter; left time: 700.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0758007 Vali Loss: 0.0752670 Test Loss: 0.0810076\n",
      "Validation loss decreased (0.075477 --> 0.075267).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0768500\n",
      "\tspeed: 0.0658s/iter; left time: 1333.8397s\n",
      "\titers: 200, epoch: 10 | loss: 0.0770572\n",
      "\tspeed: 0.0342s/iter; left time: 690.6711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0752275 Vali Loss: 0.0755037 Test Loss: 0.0809618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702061\n",
      "\tspeed: 0.0643s/iter; left time: 1290.4299s\n",
      "\titers: 200, epoch: 11 | loss: 0.0721966\n",
      "\tspeed: 0.0345s/iter; left time: 687.7470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0747662 Vali Loss: 0.0752120 Test Loss: 0.0806102\n",
      "Validation loss decreased (0.075267 --> 0.075212).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0721364\n",
      "\tspeed: 0.0654s/iter; left time: 1297.7648s\n",
      "\titers: 200, epoch: 12 | loss: 0.0765346\n",
      "\tspeed: 0.0342s/iter; left time: 674.3479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0744425 Vali Loss: 0.0750042 Test Loss: 0.0803983\n",
      "Validation loss decreased (0.075212 --> 0.075004).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0755303\n",
      "\tspeed: 0.0658s/iter; left time: 1291.2967s\n",
      "\titers: 200, epoch: 13 | loss: 0.0725444\n",
      "\tspeed: 0.0342s/iter; left time: 666.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0740546 Vali Loss: 0.0751376 Test Loss: 0.0805491\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0720178\n",
      "\tspeed: 0.0655s/iter; left time: 1269.5515s\n",
      "\titers: 200, epoch: 14 | loss: 0.0738684\n",
      "\tspeed: 0.0346s/iter; left time: 667.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0737559 Vali Loss: 0.0750192 Test Loss: 0.0804674\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0704391\n",
      "\tspeed: 0.0648s/iter; left time: 1241.0324s\n",
      "\titers: 200, epoch: 15 | loss: 0.0770458\n",
      "\tspeed: 0.0345s/iter; left time: 658.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0734251 Vali Loss: 0.0749590 Test Loss: 0.0803911\n",
      "Validation loss decreased (0.075004 --> 0.074959).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0704973\n",
      "\tspeed: 0.0664s/iter; left time: 1257.7991s\n",
      "\titers: 200, epoch: 16 | loss: 0.0751103\n",
      "\tspeed: 0.0342s/iter; left time: 644.3762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0731332 Vali Loss: 0.0751347 Test Loss: 0.0805202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0713474\n",
      "\tspeed: 0.0655s/iter; left time: 1226.1795s\n",
      "\titers: 200, epoch: 17 | loss: 0.0723478\n",
      "\tspeed: 0.0345s/iter; left time: 641.4608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0729386 Vali Loss: 0.0752624 Test Loss: 0.0806591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0748544\n",
      "\tspeed: 0.0651s/iter; left time: 1204.7753s\n",
      "\titers: 200, epoch: 18 | loss: 0.0719111\n",
      "\tspeed: 0.0345s/iter; left time: 635.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0726287 Vali Loss: 0.0750974 Test Loss: 0.0806480\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0740988\n",
      "\tspeed: 0.0652s/iter; left time: 1191.3455s\n",
      "\titers: 200, epoch: 19 | loss: 0.0716079\n",
      "\tspeed: 0.0345s/iter; left time: 626.2177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0723735 Vali Loss: 0.0751401 Test Loss: 0.0804492\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0795438\n",
      "\tspeed: 0.0645s/iter; left time: 1163.3321s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723670\n",
      "\tspeed: 0.0342s/iter; left time: 614.0082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0722089 Vali Loss: 0.0750112 Test Loss: 0.0805029\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0775375\n",
      "\tspeed: 0.0646s/iter; left time: 1151.3928s\n",
      "\titers: 200, epoch: 21 | loss: 0.0697027\n",
      "\tspeed: 0.0341s/iter; left time: 604.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0720628 Vali Loss: 0.0752527 Test Loss: 0.0808125\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0729531\n",
      "\tspeed: 0.0646s/iter; left time: 1137.3580s\n",
      "\titers: 200, epoch: 22 | loss: 0.0735260\n",
      "\tspeed: 0.0342s/iter; left time: 598.2798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0718946 Vali Loss: 0.0754438 Test Loss: 0.0807066\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729971\n",
      "\tspeed: 0.0653s/iter; left time: 1134.9392s\n",
      "\titers: 200, epoch: 23 | loss: 0.0684208\n",
      "\tspeed: 0.0341s/iter; left time: 589.6345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0717447 Vali Loss: 0.0752911 Test Loss: 0.0807496\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0746076\n",
      "\tspeed: 0.0650s/iter; left time: 1114.7638s\n",
      "\titers: 200, epoch: 24 | loss: 0.0737846\n",
      "\tspeed: 0.0341s/iter; left time: 581.7698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0715528 Vali Loss: 0.0754601 Test Loss: 0.0807979\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0713751\n",
      "\tspeed: 0.0662s/iter; left time: 1119.8767s\n",
      "\titers: 200, epoch: 25 | loss: 0.0718056\n",
      "\tspeed: 0.0341s/iter; left time: 574.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0714146 Vali Loss: 0.0752501 Test Loss: 0.0808415\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018284546211361885, rmse:0.13522036373615265, mae:0.08039116114377975, rse:0.5112828016281128\n",
      "Intermediate time for IT and pred_len 96: 00h:08m:11.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1685615\n",
      "\tspeed: 0.0630s/iter; left time: 1398.8682s\n",
      "\titers: 200, epoch: 1 | loss: 0.1568272\n",
      "\tspeed: 0.0348s/iter; left time: 768.3004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 223 | Train Loss: 0.1736213 Vali Loss: 0.1484853 Test Loss: 0.1557566\n",
      "Validation loss decreased (inf --> 0.148485).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0974978\n",
      "\tspeed: 0.0661s/iter; left time: 1452.6432s\n",
      "\titers: 200, epoch: 2 | loss: 0.0910320\n",
      "\tspeed: 0.0348s/iter; left time: 760.5426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1043769 Vali Loss: 0.0866889 Test Loss: 0.0919048\n",
      "Validation loss decreased (0.148485 --> 0.086689).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0912040\n",
      "\tspeed: 0.0657s/iter; left time: 1429.5490s\n",
      "\titers: 200, epoch: 3 | loss: 0.0904868\n",
      "\tspeed: 0.0348s/iter; left time: 752.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0892210 Vali Loss: 0.0842649 Test Loss: 0.0895253\n",
      "Validation loss decreased (0.086689 --> 0.084265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0852099\n",
      "\tspeed: 0.0657s/iter; left time: 1414.6351s\n",
      "\titers: 200, epoch: 4 | loss: 0.0859520\n",
      "\tspeed: 0.0346s/iter; left time: 740.7383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0859204 Vali Loss: 0.0823648 Test Loss: 0.0877696\n",
      "Validation loss decreased (0.084265 --> 0.082365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0825829\n",
      "\tspeed: 0.0660s/iter; left time: 1407.1327s\n",
      "\titers: 200, epoch: 5 | loss: 0.0865354\n",
      "\tspeed: 0.0349s/iter; left time: 739.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0837493 Vali Loss: 0.0820099 Test Loss: 0.0869467\n",
      "Validation loss decreased (0.082365 --> 0.082010).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0812117\n",
      "\tspeed: 0.0660s/iter; left time: 1391.9976s\n",
      "\titers: 200, epoch: 6 | loss: 0.0805016\n",
      "\tspeed: 0.0349s/iter; left time: 731.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0823856 Vali Loss: 0.0815980 Test Loss: 0.0865260\n",
      "Validation loss decreased (0.082010 --> 0.081598).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0781863\n",
      "\tspeed: 0.0655s/iter; left time: 1365.7983s\n",
      "\titers: 200, epoch: 7 | loss: 0.0789772\n",
      "\tspeed: 0.0346s/iter; left time: 718.5576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0814742 Vali Loss: 0.0814899 Test Loss: 0.0861910\n",
      "Validation loss decreased (0.081598 --> 0.081490).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0846676\n",
      "\tspeed: 0.0650s/iter; left time: 1341.8151s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805376\n",
      "\tspeed: 0.0346s/iter; left time: 710.1787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0806293 Vali Loss: 0.0812760 Test Loss: 0.0857881\n",
      "Validation loss decreased (0.081490 --> 0.081276).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0786573\n",
      "\tspeed: 0.0661s/iter; left time: 1349.5099s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793395\n",
      "\tspeed: 0.0353s/iter; left time: 718.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0799030 Vali Loss: 0.0811255 Test Loss: 0.0857040\n",
      "Validation loss decreased (0.081276 --> 0.081126).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0748710\n",
      "\tspeed: 0.0658s/iter; left time: 1329.4709s\n",
      "\titers: 200, epoch: 10 | loss: 0.0782158\n",
      "\tspeed: 0.0349s/iter; left time: 700.3029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0792681 Vali Loss: 0.0811365 Test Loss: 0.0855135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0783835\n",
      "\tspeed: 0.0644s/iter; left time: 1286.3416s\n",
      "\titers: 200, epoch: 11 | loss: 0.0823445\n",
      "\tspeed: 0.0347s/iter; left time: 689.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0788008 Vali Loss: 0.0812760 Test Loss: 0.0855287\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0793765\n",
      "\tspeed: 0.0652s/iter; left time: 1287.6063s\n",
      "\titers: 200, epoch: 12 | loss: 0.0761238\n",
      "\tspeed: 0.0350s/iter; left time: 688.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0782779 Vali Loss: 0.0819592 Test Loss: 0.0858866\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0769632\n",
      "\tspeed: 0.0649s/iter; left time: 1267.7708s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757491\n",
      "\tspeed: 0.0346s/iter; left time: 671.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0778690 Vali Loss: 0.0812044 Test Loss: 0.0857033\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0760562\n",
      "\tspeed: 0.0645s/iter; left time: 1244.6670s\n",
      "\titers: 200, epoch: 14 | loss: 0.0776277\n",
      "\tspeed: 0.0354s/iter; left time: 679.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0774190 Vali Loss: 0.0813871 Test Loss: 0.0856038\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0768229\n",
      "\tspeed: 0.0648s/iter; left time: 1237.2421s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817131\n",
      "\tspeed: 0.0347s/iter; left time: 657.8893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0771079 Vali Loss: 0.0816075 Test Loss: 0.0856013\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0770470\n",
      "\tspeed: 0.0649s/iter; left time: 1222.9102s\n",
      "\titers: 200, epoch: 16 | loss: 0.0779783\n",
      "\tspeed: 0.0348s/iter; left time: 651.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0767886 Vali Loss: 0.0815303 Test Loss: 0.0856111\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0730242\n",
      "\tspeed: 0.0644s/iter; left time: 1199.9369s\n",
      "\titers: 200, epoch: 17 | loss: 0.0730916\n",
      "\tspeed: 0.0345s/iter; left time: 639.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 223 | Train Loss: 0.0765942 Vali Loss: 0.0811437 Test Loss: 0.0854295\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0739851\n",
      "\tspeed: 0.0644s/iter; left time: 1184.9958s\n",
      "\titers: 200, epoch: 18 | loss: 0.0721104\n",
      "\tspeed: 0.0348s/iter; left time: 636.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0762804 Vali Loss: 0.0812141 Test Loss: 0.0856437\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0764789\n",
      "\tspeed: 0.0657s/iter; left time: 1194.2780s\n",
      "\titers: 200, epoch: 19 | loss: 0.0732362\n",
      "\tspeed: 0.0345s/iter; left time: 624.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0760899 Vali Loss: 0.0813462 Test Loss: 0.0856425\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01992725394666195, rmse:0.1411639302968979, mae:0.08570398390293121, rse:0.5342520475387573\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1683050\n",
      "\tspeed: 0.0371s/iter; left time: 823.3448s\n",
      "\titers: 200, epoch: 1 | loss: 0.1609643\n",
      "\tspeed: 0.0349s/iter; left time: 771.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1735891 Vali Loss: 0.1484374 Test Loss: 0.1558327\n",
      "Validation loss decreased (inf --> 0.148437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1005189\n",
      "\tspeed: 0.0668s/iter; left time: 1467.9994s\n",
      "\titers: 200, epoch: 2 | loss: 0.0957257\n",
      "\tspeed: 0.0357s/iter; left time: 781.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.1053175 Vali Loss: 0.0867120 Test Loss: 0.0919353\n",
      "Validation loss decreased (0.148437 --> 0.086712).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0910446\n",
      "\tspeed: 0.0665s/iter; left time: 1446.1851s\n",
      "\titers: 200, epoch: 3 | loss: 0.0867514\n",
      "\tspeed: 0.0345s/iter; left time: 747.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0895826 Vali Loss: 0.0842891 Test Loss: 0.0896376\n",
      "Validation loss decreased (0.086712 --> 0.084289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0842633\n",
      "\tspeed: 0.0662s/iter; left time: 1424.8121s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837887\n",
      "\tspeed: 0.0353s/iter; left time: 756.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0864344 Vali Loss: 0.0827821 Test Loss: 0.0879717\n",
      "Validation loss decreased (0.084289 --> 0.082782).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0866451\n",
      "\tspeed: 0.0667s/iter; left time: 1420.6010s\n",
      "\titers: 200, epoch: 5 | loss: 0.0811731\n",
      "\tspeed: 0.0347s/iter; left time: 735.8709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0838926 Vali Loss: 0.0819751 Test Loss: 0.0869465\n",
      "Validation loss decreased (0.082782 --> 0.081975).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0824393\n",
      "\tspeed: 0.0666s/iter; left time: 1404.8578s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826765\n",
      "\tspeed: 0.0349s/iter; left time: 733.3537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0824055 Vali Loss: 0.0814825 Test Loss: 0.0861749\n",
      "Validation loss decreased (0.081975 --> 0.081483).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0800761\n",
      "\tspeed: 0.0654s/iter; left time: 1363.9162s\n",
      "\titers: 200, epoch: 7 | loss: 0.0836602\n",
      "\tspeed: 0.0346s/iter; left time: 717.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0812305 Vali Loss: 0.0814719 Test Loss: 0.0861034\n",
      "Validation loss decreased (0.081483 --> 0.081472).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0795792\n",
      "\tspeed: 0.0659s/iter; left time: 1360.5517s\n",
      "\titers: 200, epoch: 8 | loss: 0.0773741\n",
      "\tspeed: 0.0345s/iter; left time: 709.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 223 | Train Loss: 0.0803744 Vali Loss: 0.0819383 Test Loss: 0.0864487\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0826027\n",
      "\tspeed: 0.0655s/iter; left time: 1336.8366s\n",
      "\titers: 200, epoch: 9 | loss: 0.0796509\n",
      "\tspeed: 0.0347s/iter; left time: 705.8878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0796907 Vali Loss: 0.0814607 Test Loss: 0.0857157\n",
      "Validation loss decreased (0.081472 --> 0.081461).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0774815\n",
      "\tspeed: 0.0662s/iter; left time: 1336.8656s\n",
      "\titers: 200, epoch: 10 | loss: 0.0809388\n",
      "\tspeed: 0.0348s/iter; left time: 699.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0790804 Vali Loss: 0.0810461 Test Loss: 0.0858849\n",
      "Validation loss decreased (0.081461 --> 0.081046).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0768481\n",
      "\tspeed: 0.0660s/iter; left time: 1317.3015s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760282\n",
      "\tspeed: 0.0344s/iter; left time: 683.2307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 223 | Train Loss: 0.0785108 Vali Loss: 0.0815009 Test Loss: 0.0857234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0766115\n",
      "\tspeed: 0.0646s/iter; left time: 1274.9758s\n",
      "\titers: 200, epoch: 12 | loss: 0.0779266\n",
      "\tspeed: 0.0347s/iter; left time: 682.4678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0780359 Vali Loss: 0.0812513 Test Loss: 0.0858585\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0796628\n",
      "\tspeed: 0.0656s/iter; left time: 1281.0470s\n",
      "\titers: 200, epoch: 13 | loss: 0.0790740\n",
      "\tspeed: 0.0356s/iter; left time: 690.8332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 223 | Train Loss: 0.0776244 Vali Loss: 0.0812385 Test Loss: 0.0857170\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0790037\n",
      "\tspeed: 0.0683s/iter; left time: 1317.8873s\n",
      "\titers: 200, epoch: 14 | loss: 0.0766306\n",
      "\tspeed: 0.0350s/iter; left time: 671.2272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 223 | Train Loss: 0.0771826 Vali Loss: 0.0817818 Test Loss: 0.0858997\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0781479\n",
      "\tspeed: 0.0654s/iter; left time: 1246.9404s\n",
      "\titers: 200, epoch: 15 | loss: 0.0743111\n",
      "\tspeed: 0.0345s/iter; left time: 654.7870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0769004 Vali Loss: 0.0816473 Test Loss: 0.0860531\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0774469\n",
      "\tspeed: 0.0654s/iter; left time: 1232.9693s\n",
      "\titers: 200, epoch: 16 | loss: 0.0763741\n",
      "\tspeed: 0.0354s/iter; left time: 664.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.0765900 Vali Loss: 0.0816954 Test Loss: 0.0859498\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0787390\n",
      "\tspeed: 0.0663s/iter; left time: 1236.1100s\n",
      "\titers: 200, epoch: 17 | loss: 0.0796342\n",
      "\tspeed: 0.0346s/iter; left time: 641.6290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0762675 Vali Loss: 0.0815481 Test Loss: 0.0859443\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0713304\n",
      "\tspeed: 0.0652s/iter; left time: 1201.2073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0787289\n",
      "\tspeed: 0.0347s/iter; left time: 636.1353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0761126 Vali Loss: 0.0816839 Test Loss: 0.0860736\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0760462\n",
      "\tspeed: 0.0652s/iter; left time: 1185.8225s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744022\n",
      "\tspeed: 0.0347s/iter; left time: 627.8678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0758258 Vali Loss: 0.0815189 Test Loss: 0.0859328\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0774111\n",
      "\tspeed: 0.0661s/iter; left time: 1186.6793s\n",
      "\titers: 200, epoch: 20 | loss: 0.0786737\n",
      "\tspeed: 0.0344s/iter; left time: 615.2253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0756284 Vali Loss: 0.0817036 Test Loss: 0.0859395\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02019226923584938, rmse:0.1420994997024536, mae:0.08588487654924393, rse:0.5377928018569946\n",
      "Intermediate time for IT and pred_len 168: 00h:06m:44.86s\n",
      "Intermediate time for IT: 00h:33m:18.11s\n",
      "Total time: 03h:11m:14.85s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.1347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0213  0.1458  0.0891\n",
       "        96              0.0363  0.1906  0.1269\n",
       "        168             0.0395  0.1988  0.1347\n",
       "ES      24              0.0098  0.0991  0.0595\n",
       "        96              0.0186  0.1364  0.0868\n",
       "        168             0.0212  0.1455  0.0953\n",
       "FR      24              0.0101  0.1005  0.0552\n",
       "        96              0.0196  0.1399  0.0817\n",
       "        168             0.0215  0.1467  0.0890\n",
       "GB      24              0.0260  0.1613  0.1025\n",
       "        96              0.0433  0.2082  0.1418\n",
       "        168             0.0462  0.2150  0.1488\n",
       "IT      24              0.0102  0.1011  0.0572\n",
       "        96              0.0184  0.1355  0.0804\n",
       "        168             0.0201  0.1416  0.0858"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0213  0.1459  0.0891\n",
       "        96              0.0361  0.1899  0.1267\n",
       "        168             0.0395  0.1987  0.1348\n",
       "ES      24              0.0098  0.0990  0.0595\n",
       "        96              0.0185  0.1361  0.0864\n",
       "        168             0.0212  0.1456  0.0953\n",
       "FR      24              0.0101  0.1005  0.0552\n",
       "        96              0.0195  0.1397  0.0819\n",
       "        168             0.0216  0.1468  0.0891\n",
       "GB      24              0.0260  0.1614  0.1025\n",
       "        96              0.0431  0.2075  0.1421\n",
       "        168             0.0463  0.2151  0.1488\n",
       "IT      24              0.0102  0.1011  0.0572\n",
       "        96              0.0182  0.1350  0.0800\n",
       "        168             0.0198  0.1406  0.0857"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
