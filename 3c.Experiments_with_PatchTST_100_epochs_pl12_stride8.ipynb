{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No channel-independence (Channel-Mixing) & No RevIN](#3-no-channel-independence-channel-mixing-and-no-revin)\n",
    "- [3. No Patching](#4-no-patching)\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2550365\n",
      "\tspeed: 0.1512s/iter; left time: 3370.9083s\n",
      "\titers: 200, epoch: 1 | loss: 0.2457977\n",
      "\tspeed: 0.1083s/iter; left time: 2403.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.95s\n",
      "Steps: 224 | Train Loss: 0.2636525 Vali Loss: 0.2223240 Test Loss: 0.2203597\n",
      "Validation loss decreased (inf --> 0.222324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520796\n",
      "\tspeed: 0.2477s/iter; left time: 5468.0461s\n",
      "\titers: 200, epoch: 2 | loss: 0.1205256\n",
      "\tspeed: 0.1078s/iter; left time: 2370.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 224 | Train Loss: 0.1539750 Vali Loss: 0.1156458 Test Loss: 0.1176853\n",
      "Validation loss decreased (0.222324 --> 0.115646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1005996\n",
      "\tspeed: 0.2421s/iter; left time: 5291.0575s\n",
      "\titers: 200, epoch: 3 | loss: 0.0970483\n",
      "\tspeed: 0.1083s/iter; left time: 2355.3988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 224 | Train Loss: 0.1041881 Vali Loss: 0.1089347 Test Loss: 0.1104642\n",
      "Validation loss decreased (0.115646 --> 0.108935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0982103\n",
      "\tspeed: 0.2528s/iter; left time: 5466.9704s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984537\n",
      "\tspeed: 0.1091s/iter; left time: 2349.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.34s\n",
      "Steps: 224 | Train Loss: 0.0939128 Vali Loss: 0.0990459 Test Loss: 0.1011217\n",
      "Validation loss decreased (0.108935 --> 0.099046).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0911076\n",
      "\tspeed: 0.2471s/iter; left time: 5288.4864s\n",
      "\titers: 200, epoch: 5 | loss: 0.0862528\n",
      "\tspeed: 0.1062s/iter; left time: 2263.2516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 224 | Train Loss: 0.0887181 Vali Loss: 0.0971453 Test Loss: 0.0990388\n",
      "Validation loss decreased (0.099046 --> 0.097145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0950661\n",
      "\tspeed: 0.2500s/iter; left time: 5295.2987s\n",
      "\titers: 200, epoch: 6 | loss: 0.0842719\n",
      "\tspeed: 0.1085s/iter; left time: 2288.1397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 224 | Train Loss: 0.0861451 Vali Loss: 0.0956699 Test Loss: 0.0969987\n",
      "Validation loss decreased (0.097145 --> 0.095670).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839096\n",
      "\tspeed: 0.2425s/iter; left time: 5081.4807s\n",
      "\titers: 200, epoch: 7 | loss: 0.0866961\n",
      "\tspeed: 0.1074s/iter; left time: 2239.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.52s\n",
      "Steps: 224 | Train Loss: 0.0841479 Vali Loss: 0.0947514 Test Loss: 0.0958692\n",
      "Validation loss decreased (0.095670 --> 0.094751).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0829691\n",
      "\tspeed: 0.2404s/iter; left time: 4984.6904s\n",
      "\titers: 200, epoch: 8 | loss: 0.0823774\n",
      "\tspeed: 0.1078s/iter; left time: 2225.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 224 | Train Loss: 0.0832175 Vali Loss: 0.0942965 Test Loss: 0.0952594\n",
      "Validation loss decreased (0.094751 --> 0.094296).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0858870\n",
      "\tspeed: 0.2479s/iter; left time: 5083.8341s\n",
      "\titers: 200, epoch: 9 | loss: 0.0867997\n",
      "\tspeed: 0.1092s/iter; left time: 2229.4529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.12s\n",
      "Steps: 224 | Train Loss: 0.0821404 Vali Loss: 0.0937571 Test Loss: 0.0946131\n",
      "Validation loss decreased (0.094296 --> 0.093757).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825628\n",
      "\tspeed: 0.2441s/iter; left time: 4951.4857s\n",
      "\titers: 200, epoch: 10 | loss: 0.0792029\n",
      "\tspeed: 0.1090s/iter; left time: 2200.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.52s\n",
      "Steps: 224 | Train Loss: 0.0810580 Vali Loss: 0.0932953 Test Loss: 0.0947511\n",
      "Validation loss decreased (0.093757 --> 0.093295).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754763\n",
      "\tspeed: 0.2424s/iter; left time: 4862.7232s\n",
      "\titers: 200, epoch: 11 | loss: 0.0797897\n",
      "\tspeed: 0.1084s/iter; left time: 2164.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0806771 Vali Loss: 0.0926870 Test Loss: 0.0941004\n",
      "Validation loss decreased (0.093295 --> 0.092687).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0781097\n",
      "\tspeed: 0.2466s/iter; left time: 4891.8704s\n",
      "\titers: 200, epoch: 12 | loss: 0.0794911\n",
      "\tspeed: 0.1063s/iter; left time: 2098.7969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:24.80s\n",
      "Steps: 224 | Train Loss: 0.0802304 Vali Loss: 0.0920582 Test Loss: 0.0929922\n",
      "Validation loss decreased (0.092687 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0742479\n",
      "\tspeed: 0.2419s/iter; left time: 4744.7085s\n",
      "\titers: 200, epoch: 13 | loss: 0.0781071\n",
      "\tspeed: 0.1063s/iter; left time: 2074.6250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:24.36s\n",
      "Steps: 224 | Train Loss: 0.0792328 Vali Loss: 0.0923637 Test Loss: 0.0930975\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0793341\n",
      "\tspeed: 0.2429s/iter; left time: 4709.5209s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800474\n",
      "\tspeed: 0.1058s/iter; left time: 2040.0484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:24.50s\n",
      "Steps: 224 | Train Loss: 0.0789391 Vali Loss: 0.0918005 Test Loss: 0.0931362\n",
      "Validation loss decreased (0.092058 --> 0.091800).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0771248\n",
      "\tspeed: 0.2442s/iter; left time: 4679.4770s\n",
      "\titers: 200, epoch: 15 | loss: 0.0753231\n",
      "\tspeed: 0.1063s/iter; left time: 2027.3215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:24.42s\n",
      "Steps: 224 | Train Loss: 0.0787969 Vali Loss: 0.0915194 Test Loss: 0.0925866\n",
      "Validation loss decreased (0.091800 --> 0.091519).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782704\n",
      "\tspeed: 0.2412s/iter; left time: 4567.9239s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772400\n",
      "\tspeed: 0.1070s/iter; left time: 2015.4578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 224 | Train Loss: 0.0784861 Vali Loss: 0.0913881 Test Loss: 0.0923093\n",
      "Validation loss decreased (0.091519 --> 0.091388).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0805517\n",
      "\tspeed: 0.2436s/iter; left time: 4559.5672s\n",
      "\titers: 200, epoch: 17 | loss: 0.0789460\n",
      "\tspeed: 0.1071s/iter; left time: 1994.0841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:24.34s\n",
      "Steps: 224 | Train Loss: 0.0782088 Vali Loss: 0.0910957 Test Loss: 0.0928803\n",
      "Validation loss decreased (0.091388 --> 0.091096).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0786623\n",
      "\tspeed: 0.2428s/iter; left time: 4489.9514s\n",
      "\titers: 200, epoch: 18 | loss: 0.0864841\n",
      "\tspeed: 0.1090s/iter; left time: 2004.0165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 224 | Train Loss: 0.0781278 Vali Loss: 0.0906170 Test Loss: 0.0922537\n",
      "Validation loss decreased (0.091096 --> 0.090617).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0733132\n",
      "\tspeed: 0.2402s/iter; left time: 4389.0120s\n",
      "\titers: 200, epoch: 19 | loss: 0.0748601\n",
      "\tspeed: 0.1097s/iter; left time: 1992.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 224 | Train Loss: 0.0776100 Vali Loss: 0.0925481 Test Loss: 0.0934079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0750869\n",
      "\tspeed: 0.2411s/iter; left time: 4351.1089s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796996\n",
      "\tspeed: 0.1067s/iter; left time: 1914.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:24.34s\n",
      "Steps: 224 | Train Loss: 0.0776347 Vali Loss: 0.0912388 Test Loss: 0.0920733\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0717305\n",
      "\tspeed: 0.2418s/iter; left time: 4308.3256s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779008\n",
      "\tspeed: 0.1078s/iter; left time: 1910.2627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:24.81s\n",
      "Steps: 224 | Train Loss: 0.0773463 Vali Loss: 0.0907112 Test Loss: 0.0929124\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0695258\n",
      "\tspeed: 0.2452s/iter; left time: 4314.8076s\n",
      "\titers: 200, epoch: 22 | loss: 0.0743904\n",
      "\tspeed: 0.1070s/iter; left time: 1872.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 224 | Train Loss: 0.0772748 Vali Loss: 0.0906642 Test Loss: 0.0918941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0765106\n",
      "\tspeed: 0.2444s/iter; left time: 4245.4752s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724670\n",
      "\tspeed: 0.1086s/iter; left time: 1875.7367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 224 | Train Loss: 0.0771813 Vali Loss: 0.0903736 Test Loss: 0.0917934\n",
      "Validation loss decreased (0.090617 --> 0.090374).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761368\n",
      "\tspeed: 0.2464s/iter; left time: 4225.4397s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754004\n",
      "\tspeed: 0.1091s/iter; left time: 1860.3314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:24.83s\n",
      "Steps: 224 | Train Loss: 0.0769390 Vali Loss: 0.0905244 Test Loss: 0.0917674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0757375\n",
      "\tspeed: 0.2413s/iter; left time: 4083.5700s\n",
      "\titers: 200, epoch: 25 | loss: 0.0855225\n",
      "\tspeed: 0.1074s/iter; left time: 1807.0032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 224 | Train Loss: 0.0769140 Vali Loss: 0.0903169 Test Loss: 0.0915357\n",
      "Validation loss decreased (0.090374 --> 0.090317).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0757507\n",
      "\tspeed: 0.2473s/iter; left time: 4130.6728s\n",
      "\titers: 200, epoch: 26 | loss: 0.0741878\n",
      "\tspeed: 0.1082s/iter; left time: 1796.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:24.95s\n",
      "Steps: 224 | Train Loss: 0.0768205 Vali Loss: 0.0904948 Test Loss: 0.0916539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0808719\n",
      "\tspeed: 0.2414s/iter; left time: 3977.5828s\n",
      "\titers: 200, epoch: 27 | loss: 0.0802896\n",
      "\tspeed: 0.1118s/iter; left time: 1831.3889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:24.93s\n",
      "Steps: 224 | Train Loss: 0.0766795 Vali Loss: 0.0902025 Test Loss: 0.0917831\n",
      "Validation loss decreased (0.090317 --> 0.090203).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0725205\n",
      "\tspeed: 0.2472s/iter; left time: 4018.3637s\n",
      "\titers: 200, epoch: 28 | loss: 0.0790190\n",
      "\tspeed: 0.1066s/iter; left time: 1721.4457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 224 | Train Loss: 0.0766123 Vali Loss: 0.0903282 Test Loss: 0.0917660\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0783704\n",
      "\tspeed: 0.2431s/iter; left time: 3896.7499s\n",
      "\titers: 200, epoch: 29 | loss: 0.0704855\n",
      "\tspeed: 0.1078s/iter; left time: 1717.6263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:24.65s\n",
      "Steps: 224 | Train Loss: 0.0764633 Vali Loss: 0.0900399 Test Loss: 0.0916202\n",
      "Validation loss decreased (0.090203 --> 0.090040).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0822489\n",
      "\tspeed: 0.2431s/iter; left time: 3842.3130s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782273\n",
      "\tspeed: 0.1093s/iter; left time: 1715.8864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 224 | Train Loss: 0.0764063 Vali Loss: 0.0900986 Test Loss: 0.0918674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0760647\n",
      "\tspeed: 0.2432s/iter; left time: 3788.6184s\n",
      "\titers: 200, epoch: 31 | loss: 0.0729531\n",
      "\tspeed: 0.1067s/iter; left time: 1651.1142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 224 | Train Loss: 0.0764971 Vali Loss: 0.0904406 Test Loss: 0.0918275\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0721018\n",
      "\tspeed: 0.2427s/iter; left time: 3726.4338s\n",
      "\titers: 200, epoch: 32 | loss: 0.0794974\n",
      "\tspeed: 0.1075s/iter; left time: 1640.8668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 224 | Train Loss: 0.0763520 Vali Loss: 0.0900065 Test Loss: 0.0917493\n",
      "Validation loss decreased (0.090040 --> 0.090006).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0815010\n",
      "\tspeed: 0.2475s/iter; left time: 3745.5301s\n",
      "\titers: 200, epoch: 33 | loss: 0.0701651\n",
      "\tspeed: 0.1083s/iter; left time: 1627.6945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:25.26s\n",
      "Steps: 224 | Train Loss: 0.0763374 Vali Loss: 0.0906072 Test Loss: 0.0921051\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0747005\n",
      "\tspeed: 0.2423s/iter; left time: 3612.9615s\n",
      "\titers: 200, epoch: 34 | loss: 0.0780534\n",
      "\tspeed: 0.1082s/iter; left time: 1601.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 224 | Train Loss: 0.0763812 Vali Loss: 0.0904683 Test Loss: 0.0916902\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0778864\n",
      "\tspeed: 0.2419s/iter; left time: 3552.5083s\n",
      "\titers: 200, epoch: 35 | loss: 0.0721459\n",
      "\tspeed: 0.1079s/iter; left time: 1574.0042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 224 | Train Loss: 0.0762177 Vali Loss: 0.0901533 Test Loss: 0.0917088\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0776389\n",
      "\tspeed: 0.2456s/iter; left time: 3552.2586s\n",
      "\titers: 200, epoch: 36 | loss: 0.0809103\n",
      "\tspeed: 0.1054s/iter; left time: 1513.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:24.31s\n",
      "Steps: 224 | Train Loss: 0.0762244 Vali Loss: 0.0907832 Test Loss: 0.0919312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0838915\n",
      "\tspeed: 0.2372s/iter; left time: 3377.7146s\n",
      "\titers: 200, epoch: 37 | loss: 0.0783533\n",
      "\tspeed: 0.1056s/iter; left time: 1493.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:24.20s\n",
      "Steps: 224 | Train Loss: 0.0762900 Vali Loss: 0.0904310 Test Loss: 0.0916811\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0742543\n",
      "\tspeed: 0.2368s/iter; left time: 3317.6627s\n",
      "\titers: 200, epoch: 38 | loss: 0.0717227\n",
      "\tspeed: 0.1048s/iter; left time: 1458.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:24.07s\n",
      "Steps: 224 | Train Loss: 0.0762770 Vali Loss: 0.0905645 Test Loss: 0.0919782\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0804269\n",
      "\tspeed: 0.2405s/iter; left time: 3315.9571s\n",
      "\titers: 200, epoch: 39 | loss: 0.0715565\n",
      "\tspeed: 0.1070s/iter; left time: 1464.9644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:24.39s\n",
      "Steps: 224 | Train Loss: 0.0762279 Vali Loss: 0.0899833 Test Loss: 0.0918329\n",
      "Validation loss decreased (0.090006 --> 0.089983).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0722721\n",
      "\tspeed: 0.2376s/iter; left time: 3222.5864s\n",
      "\titers: 200, epoch: 40 | loss: 0.0838491\n",
      "\tspeed: 0.1045s/iter; left time: 1407.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:24.00s\n",
      "Steps: 224 | Train Loss: 0.0761840 Vali Loss: 0.0900733 Test Loss: 0.0916720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0712462\n",
      "\tspeed: 0.2442s/iter; left time: 3258.0080s\n",
      "\titers: 200, epoch: 41 | loss: 0.0757762\n",
      "\tspeed: 0.1229s/iter; left time: 1627.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:26.98s\n",
      "Steps: 224 | Train Loss: 0.0762211 Vali Loss: 0.0899296 Test Loss: 0.0918514\n",
      "Validation loss decreased (0.089983 --> 0.089930).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0745897\n",
      "\tspeed: 0.2666s/iter; left time: 3497.3550s\n",
      "\titers: 200, epoch: 42 | loss: 0.0823171\n",
      "\tspeed: 0.1081s/iter; left time: 1406.4978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:26.81s\n",
      "Steps: 224 | Train Loss: 0.0762181 Vali Loss: 0.0901200 Test Loss: 0.0916466\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0824856\n",
      "\tspeed: 0.2714s/iter; left time: 3499.1962s\n",
      "\titers: 200, epoch: 43 | loss: 0.0770590\n",
      "\tspeed: 0.1168s/iter; left time: 1494.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:26.72s\n",
      "Steps: 224 | Train Loss: 0.0762000 Vali Loss: 0.0902058 Test Loss: 0.0917577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0722135\n",
      "\tspeed: 0.2666s/iter; left time: 3377.2280s\n",
      "\titers: 200, epoch: 44 | loss: 0.0762586\n",
      "\tspeed: 0.1282s/iter; left time: 1611.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 224 | Train Loss: 0.0761000 Vali Loss: 0.0901161 Test Loss: 0.0916589\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0769771\n",
      "\tspeed: 0.2604s/iter; left time: 3240.8001s\n",
      "\titers: 200, epoch: 45 | loss: 0.0785704\n",
      "\tspeed: 0.1159s/iter; left time: 1431.2403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:26.30s\n",
      "Steps: 224 | Train Loss: 0.0760175 Vali Loss: 0.0901326 Test Loss: 0.0917347\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0757564\n",
      "\tspeed: 0.2594s/iter; left time: 3169.8647s\n",
      "\titers: 200, epoch: 46 | loss: 0.0814028\n",
      "\tspeed: 0.1117s/iter; left time: 1353.9986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 224 | Train Loss: 0.0761109 Vali Loss: 0.0901451 Test Loss: 0.0917158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0753020\n",
      "\tspeed: 0.2731s/iter; left time: 3276.1763s\n",
      "\titers: 200, epoch: 47 | loss: 0.0748562\n",
      "\tspeed: 0.1206s/iter; left time: 1435.3448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:27.20s\n",
      "Steps: 224 | Train Loss: 0.0760741 Vali Loss: 0.0902223 Test Loss: 0.0918635\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0774492\n",
      "\tspeed: 0.2706s/iter; left time: 3185.7770s\n",
      "\titers: 200, epoch: 48 | loss: 0.0754168\n",
      "\tspeed: 0.1162s/iter; left time: 1356.0648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:27.81s\n",
      "Steps: 224 | Train Loss: 0.0760505 Vali Loss: 0.0900400 Test Loss: 0.0917029\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0775502\n",
      "\tspeed: 0.2735s/iter; left time: 3158.6544s\n",
      "\titers: 200, epoch: 49 | loss: 0.0808157\n",
      "\tspeed: 0.1320s/iter; left time: 1510.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:29.05s\n",
      "Steps: 224 | Train Loss: 0.0760683 Vali Loss: 0.0899930 Test Loss: 0.0916899\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0717994\n",
      "\tspeed: 0.2609s/iter; left time: 2954.9706s\n",
      "\titers: 200, epoch: 50 | loss: 0.0748966\n",
      "\tspeed: 0.1201s/iter; left time: 1348.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:27.26s\n",
      "Steps: 224 | Train Loss: 0.0760453 Vali Loss: 0.0907101 Test Loss: 0.0920141\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0711623\n",
      "\tspeed: 0.2688s/iter; left time: 2984.2581s\n",
      "\titers: 200, epoch: 51 | loss: 0.0779105\n",
      "\tspeed: 0.1140s/iter; left time: 1253.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:27.54s\n",
      "Steps: 224 | Train Loss: 0.0760741 Vali Loss: 0.0902494 Test Loss: 0.0916917\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0219077430665493, rmse:0.14801263809204102, mae:0.0918513685464859, rse:0.5223571062088013\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2613133\n",
      "\tspeed: 0.1230s/iter; left time: 2744.1311s\n",
      "\titers: 200, epoch: 1 | loss: 0.2378061\n",
      "\tspeed: 0.1454s/iter; left time: 3228.4253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.59s\n",
      "Steps: 224 | Train Loss: 0.2633763 Vali Loss: 0.2141813 Test Loss: 0.2135043\n",
      "Validation loss decreased (inf --> 0.214181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1348917\n",
      "\tspeed: 0.2645s/iter; left time: 5839.5659s\n",
      "\titers: 200, epoch: 2 | loss: 0.1091313\n",
      "\tspeed: 0.1158s/iter; left time: 2545.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 224 | Train Loss: 0.1502631 Vali Loss: 0.1215096 Test Loss: 0.1213722\n",
      "Validation loss decreased (0.214181 --> 0.121510).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0991456\n",
      "\tspeed: 0.2823s/iter; left time: 6168.2100s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028467\n",
      "\tspeed: 0.1247s/iter; left time: 2712.1968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.60s\n",
      "Steps: 224 | Train Loss: 0.1039570 Vali Loss: 0.1042667 Test Loss: 0.1060531\n",
      "Validation loss decreased (0.121510 --> 0.104267).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944739\n",
      "\tspeed: 0.2747s/iter; left time: 5941.8837s\n",
      "\titers: 200, epoch: 4 | loss: 0.0906489\n",
      "\tspeed: 0.1103s/iter; left time: 2375.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0935735 Vali Loss: 0.0997090 Test Loss: 0.1010089\n",
      "Validation loss decreased (0.104267 --> 0.099709).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0875830\n",
      "\tspeed: 0.2443s/iter; left time: 5229.4803s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934917\n",
      "\tspeed: 0.1053s/iter; left time: 2244.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 224 | Train Loss: 0.0890781 Vali Loss: 0.0966424 Test Loss: 0.0981480\n",
      "Validation loss decreased (0.099709 --> 0.096642).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861180\n",
      "\tspeed: 0.2424s/iter; left time: 5134.4485s\n",
      "\titers: 200, epoch: 6 | loss: 0.0829359\n",
      "\tspeed: 0.1062s/iter; left time: 2238.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.22s\n",
      "Steps: 224 | Train Loss: 0.0859295 Vali Loss: 0.0960166 Test Loss: 0.0969701\n",
      "Validation loss decreased (0.096642 --> 0.096017).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899564\n",
      "\tspeed: 0.2406s/iter; left time: 5042.7237s\n",
      "\titers: 200, epoch: 7 | loss: 0.0825942\n",
      "\tspeed: 0.1095s/iter; left time: 2283.4213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 224 | Train Loss: 0.0842214 Vali Loss: 0.0949593 Test Loss: 0.0966665\n",
      "Validation loss decreased (0.096017 --> 0.094959).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0767608\n",
      "\tspeed: 0.2423s/iter; left time: 5024.0582s\n",
      "\titers: 200, epoch: 8 | loss: 0.0868971\n",
      "\tspeed: 0.1050s/iter; left time: 2167.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.21s\n",
      "Steps: 224 | Train Loss: 0.0831380 Vali Loss: 0.0947526 Test Loss: 0.0960211\n",
      "Validation loss decreased (0.094959 --> 0.094753).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0841403\n",
      "\tspeed: 0.2419s/iter; left time: 4962.0523s\n",
      "\titers: 200, epoch: 9 | loss: 0.0848030\n",
      "\tspeed: 0.1065s/iter; left time: 2174.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:24.31s\n",
      "Steps: 224 | Train Loss: 0.0828001 Vali Loss: 0.0948078 Test Loss: 0.0960022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0816145\n",
      "\tspeed: 0.2396s/iter; left time: 4859.8447s\n",
      "\titers: 200, epoch: 10 | loss: 0.0803980\n",
      "\tspeed: 0.1076s/iter; left time: 2172.3881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.80s\n",
      "Steps: 224 | Train Loss: 0.0809367 Vali Loss: 0.0950351 Test Loss: 0.0961022\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0774165\n",
      "\tspeed: 0.2649s/iter; left time: 5314.5085s\n",
      "\titers: 200, epoch: 11 | loss: 0.0758484\n",
      "\tspeed: 0.1300s/iter; left time: 2594.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.17s\n",
      "Steps: 224 | Train Loss: 0.0802822 Vali Loss: 0.0916017 Test Loss: 0.0935093\n",
      "Validation loss decreased (0.094753 --> 0.091602).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0839585\n",
      "\tspeed: 0.5408s/iter; left time: 10728.4096s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788689\n",
      "\tspeed: 0.2028s/iter; left time: 4001.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.69s\n",
      "Steps: 224 | Train Loss: 0.0804069 Vali Loss: 0.0939275 Test Loss: 0.0949371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782914\n",
      "\tspeed: 0.2683s/iter; left time: 5262.5800s\n",
      "\titers: 200, epoch: 13 | loss: 0.0784861\n",
      "\tspeed: 0.1135s/iter; left time: 2214.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:26.47s\n",
      "Steps: 224 | Train Loss: 0.0793854 Vali Loss: 0.0912577 Test Loss: 0.0931827\n",
      "Validation loss decreased (0.091602 --> 0.091258).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0735934\n",
      "\tspeed: 0.5369s/iter; left time: 10410.8767s\n",
      "\titers: 200, epoch: 14 | loss: 0.0790708\n",
      "\tspeed: 0.2510s/iter; left time: 4841.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:58.23s\n",
      "Steps: 224 | Train Loss: 0.0786873 Vali Loss: 0.0919591 Test Loss: 0.0934465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0759815\n",
      "\tspeed: 0.5854s/iter; left time: 11218.6524s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776908\n",
      "\tspeed: 0.2552s/iter; left time: 4865.4070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:57.35s\n",
      "Steps: 224 | Train Loss: 0.0783673 Vali Loss: 0.0911349 Test Loss: 0.0928662\n",
      "Validation loss decreased (0.091258 --> 0.091135).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789143\n",
      "\tspeed: 0.5877s/iter; left time: 11130.9549s\n",
      "\titers: 200, epoch: 16 | loss: 0.0804386\n",
      "\tspeed: 0.2430s/iter; left time: 4578.9894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:55.62s\n",
      "Steps: 224 | Train Loss: 0.0783604 Vali Loss: 0.0913257 Test Loss: 0.0931277\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0740282\n",
      "\tspeed: 0.7075s/iter; left time: 13241.7670s\n",
      "\titers: 200, epoch: 17 | loss: 0.0791384\n",
      "\tspeed: 0.2536s/iter; left time: 4721.1037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:01m:12.32s\n",
      "Steps: 224 | Train Loss: 0.0780464 Vali Loss: 0.0904279 Test Loss: 0.0924158\n",
      "Validation loss decreased (0.091135 --> 0.090428).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0804243\n",
      "\tspeed: 0.6128s/iter; left time: 11333.1378s\n",
      "\titers: 200, epoch: 18 | loss: 0.0783238\n",
      "\tspeed: 0.4248s/iter; left time: 7813.5611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:01m:17.38s\n",
      "Steps: 224 | Train Loss: 0.0776671 Vali Loss: 0.0924424 Test Loss: 0.0937582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0769621\n",
      "\tspeed: 0.6785s/iter; left time: 12394.9323s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769336\n",
      "\tspeed: 0.3051s/iter; left time: 5543.6788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:01m:10.64s\n",
      "Steps: 224 | Train Loss: 0.0776793 Vali Loss: 0.0904061 Test Loss: 0.0922572\n",
      "Validation loss decreased (0.090428 --> 0.090406).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0763526\n",
      "\tspeed: 0.5938s/iter; left time: 10715.1350s\n",
      "\titers: 200, epoch: 20 | loss: 0.0778286\n",
      "\tspeed: 0.2581s/iter; left time: 4632.1380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:01m:00.37s\n",
      "Steps: 224 | Train Loss: 0.0774899 Vali Loss: 0.0901770 Test Loss: 0.0921280\n",
      "Validation loss decreased (0.090406 --> 0.090177).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0757957\n",
      "\tspeed: 0.7333s/iter; left time: 13068.4842s\n",
      "\titers: 200, epoch: 21 | loss: 0.0736768\n",
      "\tspeed: 0.2811s/iter; left time: 4981.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:01m:05.74s\n",
      "Steps: 224 | Train Loss: 0.0771877 Vali Loss: 0.0917508 Test Loss: 0.0932515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0798429\n",
      "\tspeed: 0.6155s/iter; left time: 10831.2909s\n",
      "\titers: 200, epoch: 22 | loss: 0.0763701\n",
      "\tspeed: 0.2889s/iter; left time: 5054.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:58.84s\n",
      "Steps: 224 | Train Loss: 0.0769310 Vali Loss: 0.0910191 Test Loss: 0.0925784\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767220\n",
      "\tspeed: 0.3263s/iter; left time: 5669.2843s\n",
      "\titers: 200, epoch: 23 | loss: 0.0793968\n",
      "\tspeed: 0.1144s/iter; left time: 1976.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 224 | Train Loss: 0.0769935 Vali Loss: 0.0900505 Test Loss: 0.0921190\n",
      "Validation loss decreased (0.090177 --> 0.090050).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0806249\n",
      "\tspeed: 0.2590s/iter; left time: 4442.0003s\n",
      "\titers: 200, epoch: 24 | loss: 0.0744155\n",
      "\tspeed: 0.1172s/iter; left time: 1997.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:26.70s\n",
      "Steps: 224 | Train Loss: 0.0769818 Vali Loss: 0.0898234 Test Loss: 0.0918337\n",
      "Validation loss decreased (0.090050 --> 0.089823).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0764382\n",
      "\tspeed: 0.2632s/iter; left time: 4454.1771s\n",
      "\titers: 200, epoch: 25 | loss: 0.0735312\n",
      "\tspeed: 0.1165s/iter; left time: 1960.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0768267 Vali Loss: 0.0901439 Test Loss: 0.0919796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763813\n",
      "\tspeed: 0.2570s/iter; left time: 4292.0756s\n",
      "\titers: 200, epoch: 26 | loss: 0.0757832\n",
      "\tspeed: 0.1614s/iter; left time: 2678.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:32.01s\n",
      "Steps: 224 | Train Loss: 0.0766008 Vali Loss: 0.0901050 Test Loss: 0.0919692\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0752778\n",
      "\tspeed: 0.3078s/iter; left time: 5071.3881s\n",
      "\titers: 200, epoch: 27 | loss: 0.0755920\n",
      "\tspeed: 0.1260s/iter; left time: 2062.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:29.14s\n",
      "Steps: 224 | Train Loss: 0.0764962 Vali Loss: 0.0905604 Test Loss: 0.0923967\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0744643\n",
      "\tspeed: 0.2722s/iter; left time: 4424.0175s\n",
      "\titers: 200, epoch: 28 | loss: 0.0749847\n",
      "\tspeed: 0.1208s/iter; left time: 1950.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:27.65s\n",
      "Steps: 224 | Train Loss: 0.0765897 Vali Loss: 0.0897865 Test Loss: 0.0917170\n",
      "Validation loss decreased (0.089823 --> 0.089786).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0751541\n",
      "\tspeed: 0.2787s/iter; left time: 4467.0822s\n",
      "\titers: 200, epoch: 29 | loss: 0.0740950\n",
      "\tspeed: 0.1208s/iter; left time: 1923.9034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:27.78s\n",
      "Steps: 224 | Train Loss: 0.0764319 Vali Loss: 0.0901526 Test Loss: 0.0920242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0806817\n",
      "\tspeed: 0.2698s/iter; left time: 4263.5552s\n",
      "\titers: 200, epoch: 30 | loss: 0.0741300\n",
      "\tspeed: 0.1191s/iter; left time: 1869.7943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:27.11s\n",
      "Steps: 224 | Train Loss: 0.0764454 Vali Loss: 0.0910322 Test Loss: 0.0927493\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0785073\n",
      "\tspeed: 0.2675s/iter; left time: 4168.4875s\n",
      "\titers: 200, epoch: 31 | loss: 0.0822864\n",
      "\tspeed: 0.1178s/iter; left time: 1823.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:27.24s\n",
      "Steps: 224 | Train Loss: 0.0763724 Vali Loss: 0.0905380 Test Loss: 0.0923370\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0720525\n",
      "\tspeed: 0.2670s/iter; left time: 4099.7668s\n",
      "\titers: 200, epoch: 32 | loss: 0.0754558\n",
      "\tspeed: 0.1182s/iter; left time: 1803.1603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:26.78s\n",
      "Steps: 224 | Train Loss: 0.0762633 Vali Loss: 0.0902661 Test Loss: 0.0921785\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0764711\n",
      "\tspeed: 0.2623s/iter; left time: 3969.2843s\n",
      "\titers: 200, epoch: 33 | loss: 0.0753409\n",
      "\tspeed: 0.1168s/iter; left time: 1755.5251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:26.48s\n",
      "Steps: 224 | Train Loss: 0.0762685 Vali Loss: 0.0898499 Test Loss: 0.0918554\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0713696\n",
      "\tspeed: 0.2613s/iter; left time: 3896.4166s\n",
      "\titers: 200, epoch: 34 | loss: 0.0775798\n",
      "\tspeed: 0.1145s/iter; left time: 1695.9915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:26.64s\n",
      "Steps: 224 | Train Loss: 0.0761226 Vali Loss: 0.0897780 Test Loss: 0.0916997\n",
      "Validation loss decreased (0.089786 --> 0.089778).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0767672\n",
      "\tspeed: 0.2645s/iter; left time: 3883.9269s\n",
      "\titers: 200, epoch: 35 | loss: 0.0773636\n",
      "\tspeed: 0.1963s/iter; left time: 2862.8023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 224 | Train Loss: 0.0762109 Vali Loss: 0.0896653 Test Loss: 0.0916823\n",
      "Validation loss decreased (0.089778 --> 0.089665).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0710060\n",
      "\tspeed: 0.5680s/iter; left time: 8213.1948s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774741\n",
      "\tspeed: 0.1260s/iter; left time: 1809.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:40.64s\n",
      "Steps: 224 | Train Loss: 0.0761405 Vali Loss: 0.0903530 Test Loss: 0.0922118\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0769212\n",
      "\tspeed: 0.2676s/iter; left time: 3810.4897s\n",
      "\titers: 200, epoch: 37 | loss: 0.0737745\n",
      "\tspeed: 0.1143s/iter; left time: 1615.2601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:26.52s\n",
      "Steps: 224 | Train Loss: 0.0761545 Vali Loss: 0.0899915 Test Loss: 0.0918158\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0786948\n",
      "\tspeed: 0.4057s/iter; left time: 5685.5417s\n",
      "\titers: 200, epoch: 38 | loss: 0.0819519\n",
      "\tspeed: 0.1902s/iter; left time: 2645.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 224 | Train Loss: 0.0760353 Vali Loss: 0.0901752 Test Loss: 0.0920487\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0791225\n",
      "\tspeed: 0.5206s/iter; left time: 7178.7747s\n",
      "\titers: 200, epoch: 39 | loss: 0.0748556\n",
      "\tspeed: 0.2586s/iter; left time: 3540.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:59.18s\n",
      "Steps: 224 | Train Loss: 0.0761031 Vali Loss: 0.0903731 Test Loss: 0.0921540\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0743467\n",
      "\tspeed: 0.5385s/iter; left time: 7305.1768s\n",
      "\titers: 200, epoch: 40 | loss: 0.0701768\n",
      "\tspeed: 0.2463s/iter; left time: 3315.8515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:54.46s\n",
      "Steps: 224 | Train Loss: 0.0761037 Vali Loss: 0.0899823 Test Loss: 0.0919424\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0750129\n",
      "\tspeed: 0.5121s/iter; left time: 6831.3053s\n",
      "\titers: 200, epoch: 41 | loss: 0.0762946\n",
      "\tspeed: 0.2206s/iter; left time: 2920.8003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:51.89s\n",
      "Steps: 224 | Train Loss: 0.0761046 Vali Loss: 0.0899809 Test Loss: 0.0918796\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0789293\n",
      "\tspeed: 0.5522s/iter; left time: 7243.3106s\n",
      "\titers: 200, epoch: 42 | loss: 0.0742998\n",
      "\tspeed: 0.2486s/iter; left time: 3236.6313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:56.43s\n",
      "Steps: 224 | Train Loss: 0.0760946 Vali Loss: 0.0904575 Test Loss: 0.0922634\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0779338\n",
      "\tspeed: 0.5295s/iter; left time: 6827.0705s\n",
      "\titers: 200, epoch: 43 | loss: 0.0743775\n",
      "\tspeed: 0.2320s/iter; left time: 2967.4002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:52.42s\n",
      "Steps: 224 | Train Loss: 0.0760662 Vali Loss: 0.0898107 Test Loss: 0.0917817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0754502\n",
      "\tspeed: 0.5345s/iter; left time: 6771.5185s\n",
      "\titers: 200, epoch: 44 | loss: 0.0784478\n",
      "\tspeed: 0.2398s/iter; left time: 3014.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:55.24s\n",
      "Steps: 224 | Train Loss: 0.0759680 Vali Loss: 0.0896233 Test Loss: 0.0916874\n",
      "Validation loss decreased (0.089665 --> 0.089623).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0741628\n",
      "\tspeed: 0.5100s/iter; left time: 6346.5414s\n",
      "\titers: 200, epoch: 45 | loss: 0.0764964\n",
      "\tspeed: 0.2598s/iter; left time: 3207.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:53.21s\n",
      "Steps: 224 | Train Loss: 0.0759114 Vali Loss: 0.0901750 Test Loss: 0.0919436\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0750005\n",
      "\tspeed: 0.5559s/iter; left time: 6793.8731s\n",
      "\titers: 200, epoch: 46 | loss: 0.0753702\n",
      "\tspeed: 0.2679s/iter; left time: 3246.6753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:58.52s\n",
      "Steps: 224 | Train Loss: 0.0759626 Vali Loss: 0.0899723 Test Loss: 0.0918334\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0721205\n",
      "\tspeed: 0.5151s/iter; left time: 6179.4881s\n",
      "\titers: 200, epoch: 47 | loss: 0.0742215\n",
      "\tspeed: 0.2474s/iter; left time: 2943.5418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:53.06s\n",
      "Steps: 224 | Train Loss: 0.0758324 Vali Loss: 0.0900548 Test Loss: 0.0918610\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0769353\n",
      "\tspeed: 0.3917s/iter; left time: 4611.3534s\n",
      "\titers: 200, epoch: 48 | loss: 0.0775490\n",
      "\tspeed: 0.1220s/iter; left time: 1424.6142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:30.27s\n",
      "Steps: 224 | Train Loss: 0.0759903 Vali Loss: 0.0901668 Test Loss: 0.0921282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0747070\n",
      "\tspeed: 0.3124s/iter; left time: 3608.3544s\n",
      "\titers: 200, epoch: 49 | loss: 0.0788589\n",
      "\tspeed: 0.1532s/iter; left time: 1753.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:36.39s\n",
      "Steps: 224 | Train Loss: 0.0759863 Vali Loss: 0.0901804 Test Loss: 0.0920464\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0756816\n",
      "\tspeed: 0.2918s/iter; left time: 3305.0317s\n",
      "\titers: 200, epoch: 50 | loss: 0.0746113\n",
      "\tspeed: 0.1218s/iter; left time: 1366.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:28.43s\n",
      "Steps: 224 | Train Loss: 0.0758465 Vali Loss: 0.0899366 Test Loss: 0.0917983\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0800348\n",
      "\tspeed: 0.2776s/iter; left time: 3081.9676s\n",
      "\titers: 200, epoch: 51 | loss: 0.0769174\n",
      "\tspeed: 0.1237s/iter; left time: 1360.4398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 224 | Train Loss: 0.0757991 Vali Loss: 0.0899113 Test Loss: 0.0919283\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0765539\n",
      "\tspeed: 0.2784s/iter; left time: 3027.8402s\n",
      "\titers: 200, epoch: 52 | loss: 0.0767253\n",
      "\tspeed: 0.1225s/iter; left time: 1320.5936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:28.33s\n",
      "Steps: 224 | Train Loss: 0.0759097 Vali Loss: 0.0906954 Test Loss: 0.0924402\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0756539\n",
      "\tspeed: 0.2734s/iter; left time: 2912.8104s\n",
      "\titers: 200, epoch: 53 | loss: 0.0754662\n",
      "\tspeed: 0.1232s/iter; left time: 1300.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 224 | Train Loss: 0.0758398 Vali Loss: 0.0899791 Test Loss: 0.0918872\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0751490\n",
      "\tspeed: 0.2708s/iter; left time: 2824.2580s\n",
      "\titers: 200, epoch: 54 | loss: 0.0724882\n",
      "\tspeed: 0.1193s/iter; left time: 1231.8705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:27.37s\n",
      "Steps: 224 | Train Loss: 0.0758643 Vali Loss: 0.0899040 Test Loss: 0.0917923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02174472063779831, rmse:0.1474609076976776, mae:0.09168744832277298, rse:0.5204100012779236\n",
      "Intermediate time for DE and pred_len 24: 01h:21m:23.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2624439\n",
      "\tspeed: 0.1655s/iter; left time: 3689.8555s\n",
      "\titers: 200, epoch: 1 | loss: 0.2533581\n",
      "\tspeed: 0.1182s/iter; left time: 2624.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.72s\n",
      "Steps: 224 | Train Loss: 0.2657103 Vali Loss: 0.2249349 Test Loss: 0.2257290\n",
      "Validation loss decreased (inf --> 0.224935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1578444\n",
      "\tspeed: 0.3866s/iter; left time: 8536.0222s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355329\n",
      "\tspeed: 0.1187s/iter; left time: 2609.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.78s\n",
      "Steps: 224 | Train Loss: 0.1630478 Vali Loss: 0.1429868 Test Loss: 0.1473229\n",
      "Validation loss decreased (0.224935 --> 0.142987).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1218379\n",
      "\tspeed: 0.6945s/iter; left time: 15175.8487s\n",
      "\titers: 200, epoch: 3 | loss: 0.1212928\n",
      "\tspeed: 0.2342s/iter; left time: 5094.9403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:53.59s\n",
      "Steps: 224 | Train Loss: 0.1243166 Vali Loss: 0.1323241 Test Loss: 0.1419654\n",
      "Validation loss decreased (0.142987 --> 0.132324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1167402\n",
      "\tspeed: 0.3986s/iter; left time: 8621.6634s\n",
      "\titers: 200, epoch: 4 | loss: 0.1118756\n",
      "\tspeed: 0.1804s/iter; left time: 3884.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.43s\n",
      "Steps: 224 | Train Loss: 0.1161288 Vali Loss: 0.1285778 Test Loss: 0.1394080\n",
      "Validation loss decreased (0.132324 --> 0.128578).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1120939\n",
      "\tspeed: 0.8583s/iter; left time: 18372.1020s\n",
      "\titers: 200, epoch: 5 | loss: 0.1029756\n",
      "\tspeed: 0.2391s/iter; left time: 5093.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:55.93s\n",
      "Steps: 224 | Train Loss: 0.1115568 Vali Loss: 0.1238497 Test Loss: 0.1320646\n",
      "Validation loss decreased (0.128578 --> 0.123850).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1175425\n",
      "\tspeed: 0.8939s/iter; left time: 18934.2528s\n",
      "\titers: 200, epoch: 6 | loss: 0.1142166\n",
      "\tspeed: 0.2601s/iter; left time: 5483.4692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.00s\n",
      "Steps: 224 | Train Loss: 0.1093992 Vali Loss: 0.1259839 Test Loss: 0.1353314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1083458\n",
      "\tspeed: 0.8282s/iter; left time: 17355.9170s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027447\n",
      "\tspeed: 0.2378s/iter; left time: 4959.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.79s\n",
      "Steps: 224 | Train Loss: 0.1081467 Vali Loss: 0.1243413 Test Loss: 0.1341996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1075349\n",
      "\tspeed: 0.8572s/iter; left time: 17772.2859s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041051\n",
      "\tspeed: 0.2401s/iter; left time: 4954.9808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:55.41s\n",
      "Steps: 224 | Train Loss: 0.1069057 Vali Loss: 0.1231056 Test Loss: 0.1338573\n",
      "Validation loss decreased (0.123850 --> 0.123106).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1053689\n",
      "\tspeed: 0.9020s/iter; left time: 18500.0082s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085160\n",
      "\tspeed: 0.2355s/iter; left time: 4805.9895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:54.13s\n",
      "Steps: 224 | Train Loss: 0.1065368 Vali Loss: 0.1244978 Test Loss: 0.1342114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047870\n",
      "\tspeed: 0.8497s/iter; left time: 17235.6077s\n",
      "\titers: 200, epoch: 10 | loss: 0.1017206\n",
      "\tspeed: 0.2331s/iter; left time: 4705.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:54.90s\n",
      "Steps: 224 | Train Loss: 0.1056799 Vali Loss: 0.1234504 Test Loss: 0.1373607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1044058\n",
      "\tspeed: 0.9052s/iter; left time: 18158.8690s\n",
      "\titers: 200, epoch: 11 | loss: 0.1065060\n",
      "\tspeed: 0.2377s/iter; left time: 4745.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:52.44s\n",
      "Steps: 224 | Train Loss: 0.1052327 Vali Loss: 0.1222100 Test Loss: 0.1352888\n",
      "Validation loss decreased (0.123106 --> 0.122210).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066850\n",
      "\tspeed: 0.4477s/iter; left time: 8881.0437s\n",
      "\titers: 200, epoch: 12 | loss: 0.1037025\n",
      "\tspeed: 0.1140s/iter; left time: 2249.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.69s\n",
      "Steps: 224 | Train Loss: 0.1049357 Vali Loss: 0.1230136 Test Loss: 0.1366802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1043193\n",
      "\tspeed: 0.5201s/iter; left time: 10201.2865s\n",
      "\titers: 200, epoch: 13 | loss: 0.1049683\n",
      "\tspeed: 0.1246s/iter; left time: 2430.8146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 224 | Train Loss: 0.1044607 Vali Loss: 0.1213381 Test Loss: 0.1331712\n",
      "Validation loss decreased (0.122210 --> 0.121338).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1062233\n",
      "\tspeed: 0.4136s/iter; left time: 8019.4579s\n",
      "\titers: 200, epoch: 14 | loss: 0.0998157\n",
      "\tspeed: 0.1216s/iter; left time: 2344.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.37s\n",
      "Steps: 224 | Train Loss: 0.1040727 Vali Loss: 0.1226940 Test Loss: 0.1351359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0996267\n",
      "\tspeed: 0.3954s/iter; left time: 7577.6684s\n",
      "\titers: 200, epoch: 15 | loss: 0.1062605\n",
      "\tspeed: 0.1236s/iter; left time: 2356.4094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.92s\n",
      "Steps: 224 | Train Loss: 0.1039674 Vali Loss: 0.1219179 Test Loss: 0.1358486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1072159\n",
      "\tspeed: 0.3835s/iter; left time: 7264.2275s\n",
      "\titers: 200, epoch: 16 | loss: 0.1091402\n",
      "\tspeed: 0.1175s/iter; left time: 2213.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 224 | Train Loss: 0.1037040 Vali Loss: 0.1214257 Test Loss: 0.1346061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1043148\n",
      "\tspeed: 0.3856s/iter; left time: 7218.1348s\n",
      "\titers: 200, epoch: 17 | loss: 0.1040580\n",
      "\tspeed: 0.1153s/iter; left time: 2145.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:26.90s\n",
      "Steps: 224 | Train Loss: 0.1034399 Vali Loss: 0.1213346 Test Loss: 0.1334521\n",
      "Validation loss decreased (0.121338 --> 0.121335).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1028586\n",
      "\tspeed: 0.3855s/iter; left time: 7128.6473s\n",
      "\titers: 200, epoch: 18 | loss: 0.0969299\n",
      "\tspeed: 0.1162s/iter; left time: 2137.9971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:30.01s\n",
      "Steps: 224 | Train Loss: 0.1032042 Vali Loss: 0.1209691 Test Loss: 0.1328134\n",
      "Validation loss decreased (0.121335 --> 0.120969).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1028012\n",
      "\tspeed: 0.7956s/iter; left time: 14535.6314s\n",
      "\titers: 200, epoch: 19 | loss: 0.1008040\n",
      "\tspeed: 0.1293s/iter; left time: 2349.1383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 224 | Train Loss: 0.1032438 Vali Loss: 0.1215783 Test Loss: 0.1350771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1028210\n",
      "\tspeed: 0.3801s/iter; left time: 6858.9683s\n",
      "\titers: 200, epoch: 20 | loss: 0.1061794\n",
      "\tspeed: 0.1166s/iter; left time: 2091.6124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:26.98s\n",
      "Steps: 224 | Train Loss: 0.1028983 Vali Loss: 0.1210929 Test Loss: 0.1349423\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033960\n",
      "\tspeed: 0.5610s/iter; left time: 9996.8977s\n",
      "\titers: 200, epoch: 21 | loss: 0.1023306\n",
      "\tspeed: 0.3139s/iter; left time: 5563.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:59.30s\n",
      "Steps: 224 | Train Loss: 0.1026721 Vali Loss: 0.1210574 Test Loss: 0.1348963\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1006399\n",
      "\tspeed: 0.8281s/iter; left time: 14572.4296s\n",
      "\titers: 200, epoch: 22 | loss: 0.1029968\n",
      "\tspeed: 0.2601s/iter; left time: 4551.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:57.99s\n",
      "Steps: 224 | Train Loss: 0.1025208 Vali Loss: 0.1210968 Test Loss: 0.1336726\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1028404\n",
      "\tspeed: 0.8819s/iter; left time: 15321.0237s\n",
      "\titers: 200, epoch: 23 | loss: 0.1074014\n",
      "\tspeed: 0.2498s/iter; left time: 4313.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:01m:01.41s\n",
      "Steps: 224 | Train Loss: 0.1024946 Vali Loss: 0.1203637 Test Loss: 0.1331069\n",
      "Validation loss decreased (0.120969 --> 0.120364).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1077754\n",
      "\tspeed: 0.8649s/iter; left time: 14832.3594s\n",
      "\titers: 200, epoch: 24 | loss: 0.1004269\n",
      "\tspeed: 0.2687s/iter; left time: 4581.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:58.66s\n",
      "Steps: 224 | Train Loss: 0.1023391 Vali Loss: 0.1204766 Test Loss: 0.1342240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1016895\n",
      "\tspeed: 0.8483s/iter; left time: 14356.9109s\n",
      "\titers: 200, epoch: 25 | loss: 0.0960510\n",
      "\tspeed: 0.2323s/iter; left time: 3907.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:55.92s\n",
      "Steps: 224 | Train Loss: 0.1022619 Vali Loss: 0.1215099 Test Loss: 0.1329345\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1032051\n",
      "\tspeed: 0.8813s/iter; left time: 14718.0882s\n",
      "\titers: 200, epoch: 26 | loss: 0.1087515\n",
      "\tspeed: 0.2591s/iter; left time: 4301.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:59.69s\n",
      "Steps: 224 | Train Loss: 0.1022497 Vali Loss: 0.1206701 Test Loss: 0.1335198\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1040444\n",
      "\tspeed: 0.8396s/iter; left time: 13834.4424s\n",
      "\titers: 200, epoch: 27 | loss: 0.0977249\n",
      "\tspeed: 0.1568s/iter; left time: 2568.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:44.75s\n",
      "Steps: 224 | Train Loss: 0.1021985 Vali Loss: 0.1205080 Test Loss: 0.1342546\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1052764\n",
      "\tspeed: 0.4244s/iter; left time: 6897.5054s\n",
      "\titers: 200, epoch: 28 | loss: 0.0975134\n",
      "\tspeed: 0.1886s/iter; left time: 3046.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:35.15s\n",
      "Steps: 224 | Train Loss: 0.1019502 Vali Loss: 0.1210460 Test Loss: 0.1345772\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0996965\n",
      "\tspeed: 0.4606s/iter; left time: 7383.1543s\n",
      "\titers: 200, epoch: 29 | loss: 0.1094052\n",
      "\tspeed: 0.1286s/iter; left time: 2049.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:30.30s\n",
      "Steps: 224 | Train Loss: 0.1019759 Vali Loss: 0.1204747 Test Loss: 0.1332983\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0972120\n",
      "\tspeed: 0.4294s/iter; left time: 6786.5756s\n",
      "\titers: 200, epoch: 30 | loss: 0.1037831\n",
      "\tspeed: 0.1281s/iter; left time: 2012.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:29.77s\n",
      "Steps: 224 | Train Loss: 0.1018909 Vali Loss: 0.1201878 Test Loss: 0.1332775\n",
      "Validation loss decreased (0.120364 --> 0.120188).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0998103\n",
      "\tspeed: 0.4215s/iter; left time: 6566.6763s\n",
      "\titers: 200, epoch: 31 | loss: 0.0966518\n",
      "\tspeed: 0.1279s/iter; left time: 1980.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 224 | Train Loss: 0.1019227 Vali Loss: 0.1212375 Test Loss: 0.1331787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1017513\n",
      "\tspeed: 0.4254s/iter; left time: 6532.6847s\n",
      "\titers: 200, epoch: 32 | loss: 0.1009322\n",
      "\tspeed: 0.1268s/iter; left time: 1933.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:29.33s\n",
      "Steps: 224 | Train Loss: 0.1018305 Vali Loss: 0.1203657 Test Loss: 0.1338133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1026395\n",
      "\tspeed: 0.4018s/iter; left time: 6079.8228s\n",
      "\titers: 200, epoch: 33 | loss: 0.1020070\n",
      "\tspeed: 0.1209s/iter; left time: 1817.2060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:27.75s\n",
      "Steps: 224 | Train Loss: 0.1018055 Vali Loss: 0.1201956 Test Loss: 0.1328612\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1067616\n",
      "\tspeed: 0.3999s/iter; left time: 5962.5837s\n",
      "\titers: 200, epoch: 34 | loss: 0.1023788\n",
      "\tspeed: 0.1818s/iter; left time: 2692.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 224 | Train Loss: 0.1017142 Vali Loss: 0.1204072 Test Loss: 0.1334088\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0938389\n",
      "\tspeed: 0.7497s/iter; left time: 11009.5429s\n",
      "\titers: 200, epoch: 35 | loss: 0.1035917\n",
      "\tspeed: 0.1279s/iter; left time: 1865.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:30.59s\n",
      "Steps: 224 | Train Loss: 0.1016174 Vali Loss: 0.1205804 Test Loss: 0.1323296\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0989040\n",
      "\tspeed: 0.6981s/iter; left time: 10094.5079s\n",
      "\titers: 200, epoch: 36 | loss: 0.0989800\n",
      "\tspeed: 0.2587s/iter; left time: 3714.6485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:58.23s\n",
      "Steps: 224 | Train Loss: 0.1016506 Vali Loss: 0.1203181 Test Loss: 0.1335595\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1087715\n",
      "\tspeed: 0.8550s/iter; left time: 12172.6308s\n",
      "\titers: 200, epoch: 37 | loss: 0.1035411\n",
      "\tspeed: 0.1438s/iter; left time: 2033.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:41.01s\n",
      "Steps: 224 | Train Loss: 0.1016309 Vali Loss: 0.1202777 Test Loss: 0.1338640\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1005551\n",
      "\tspeed: 0.7876s/iter; left time: 11036.0117s\n",
      "\titers: 200, epoch: 38 | loss: 0.1086734\n",
      "\tspeed: 0.2342s/iter; left time: 3258.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:54.61s\n",
      "Steps: 224 | Train Loss: 0.1015396 Vali Loss: 0.1201334 Test Loss: 0.1330781\n",
      "Validation loss decreased (0.120188 --> 0.120133).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1019120\n",
      "\tspeed: 0.8587s/iter; left time: 11841.2038s\n",
      "\titers: 200, epoch: 39 | loss: 0.1053489\n",
      "\tspeed: 0.2526s/iter; left time: 3458.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:56.50s\n",
      "Steps: 224 | Train Loss: 0.1016398 Vali Loss: 0.1205702 Test Loss: 0.1335148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1039687\n",
      "\tspeed: 0.8186s/iter; left time: 11103.6663s\n",
      "\titers: 200, epoch: 40 | loss: 0.1052855\n",
      "\tspeed: 0.2537s/iter; left time: 3416.2635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:57.53s\n",
      "Steps: 224 | Train Loss: 0.1016112 Vali Loss: 0.1201181 Test Loss: 0.1329917\n",
      "Validation loss decreased (0.120133 --> 0.120118).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1032790\n",
      "\tspeed: 0.8241s/iter; left time: 10993.7257s\n",
      "\titers: 200, epoch: 41 | loss: 0.0986189\n",
      "\tspeed: 0.2480s/iter; left time: 3283.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:57.15s\n",
      "Steps: 224 | Train Loss: 0.1015481 Vali Loss: 0.1201114 Test Loss: 0.1333343\n",
      "Validation loss decreased (0.120118 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1040610\n",
      "\tspeed: 0.8156s/iter; left time: 10697.7058s\n",
      "\titers: 200, epoch: 42 | loss: 0.1028562\n",
      "\tspeed: 0.2702s/iter; left time: 3517.3116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:58.70s\n",
      "Steps: 224 | Train Loss: 0.1015372 Vali Loss: 0.1203343 Test Loss: 0.1330506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1020140\n",
      "\tspeed: 0.8194s/iter; left time: 10563.8796s\n",
      "\titers: 200, epoch: 43 | loss: 0.0965043\n",
      "\tspeed: 0.2248s/iter; left time: 2875.4296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:53.58s\n",
      "Steps: 224 | Train Loss: 0.1015124 Vali Loss: 0.1205626 Test Loss: 0.1332887\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1006550\n",
      "\tspeed: 0.5500s/iter; left time: 6968.2391s\n",
      "\titers: 200, epoch: 44 | loss: 0.0985992\n",
      "\tspeed: 0.1104s/iter; left time: 1387.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:27.15s\n",
      "Steps: 224 | Train Loss: 0.1015197 Vali Loss: 0.1200902 Test Loss: 0.1333098\n",
      "Validation loss decreased (0.120111 --> 0.120090).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1013960\n",
      "\tspeed: 0.4970s/iter; left time: 6185.2816s\n",
      "\titers: 200, epoch: 45 | loss: 0.1004077\n",
      "\tspeed: 0.1324s/iter; left time: 1634.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:30.90s\n",
      "Steps: 224 | Train Loss: 0.1014997 Vali Loss: 0.1205729 Test Loss: 0.1332386\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0944509\n",
      "\tspeed: 0.4059s/iter; left time: 4960.8590s\n",
      "\titers: 200, epoch: 46 | loss: 0.1032707\n",
      "\tspeed: 0.1219s/iter; left time: 1477.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:27.79s\n",
      "Steps: 224 | Train Loss: 0.1014372 Vali Loss: 0.1199568 Test Loss: 0.1329821\n",
      "Validation loss decreased (0.120090 --> 0.119957).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1047865\n",
      "\tspeed: 0.4058s/iter; left time: 4867.9475s\n",
      "\titers: 200, epoch: 47 | loss: 0.1014198\n",
      "\tspeed: 0.1235s/iter; left time: 1469.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:28.43s\n",
      "Steps: 224 | Train Loss: 0.1014733 Vali Loss: 0.1202763 Test Loss: 0.1330418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1058092\n",
      "\tspeed: 0.3916s/iter; left time: 4609.7357s\n",
      "\titers: 200, epoch: 48 | loss: 0.0998233\n",
      "\tspeed: 0.1173s/iter; left time: 1369.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:27.70s\n",
      "Steps: 224 | Train Loss: 0.1014681 Vali Loss: 0.1202359 Test Loss: 0.1334759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1017546\n",
      "\tspeed: 0.3942s/iter; left time: 4552.5407s\n",
      "\titers: 200, epoch: 49 | loss: 0.0944112\n",
      "\tspeed: 0.1159s/iter; left time: 1327.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:27.04s\n",
      "Steps: 224 | Train Loss: 0.1014350 Vali Loss: 0.1203048 Test Loss: 0.1332014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1012539\n",
      "\tspeed: 0.3794s/iter; left time: 4296.7012s\n",
      "\titers: 200, epoch: 50 | loss: 0.0989887\n",
      "\tspeed: 0.1199s/iter; left time: 1346.2740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:27.45s\n",
      "Steps: 224 | Train Loss: 0.1014373 Vali Loss: 0.1202343 Test Loss: 0.1333372\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.1002797\n",
      "\tspeed: 0.5822s/iter; left time: 6462.5589s\n",
      "\titers: 200, epoch: 51 | loss: 0.1037587\n",
      "\tspeed: 0.2489s/iter; left time: 2738.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:57.61s\n",
      "Steps: 224 | Train Loss: 0.1013838 Vali Loss: 0.1202643 Test Loss: 0.1329726\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1003040\n",
      "\tspeed: 0.4638s/iter; left time: 5044.5349s\n",
      "\titers: 200, epoch: 52 | loss: 0.1027404\n",
      "\tspeed: 0.1160s/iter; left time: 1250.4068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:26.95s\n",
      "Steps: 224 | Train Loss: 0.1014626 Vali Loss: 0.1202116 Test Loss: 0.1333047\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1025127\n",
      "\tspeed: 0.4570s/iter; left time: 4867.9767s\n",
      "\titers: 200, epoch: 53 | loss: 0.1010907\n",
      "\tspeed: 0.2695s/iter; left time: 2844.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:54.45s\n",
      "Steps: 224 | Train Loss: 0.1015266 Vali Loss: 0.1201307 Test Loss: 0.1329808\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0957577\n",
      "\tspeed: 0.8121s/iter; left time: 8469.1168s\n",
      "\titers: 200, epoch: 54 | loss: 0.1033463\n",
      "\tspeed: 0.2401s/iter; left time: 2479.9924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:56.06s\n",
      "Steps: 224 | Train Loss: 0.1014345 Vali Loss: 0.1200416 Test Loss: 0.1329347\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.1019332\n",
      "\tspeed: 0.8461s/iter; left time: 8634.7176s\n",
      "\titers: 200, epoch: 55 | loss: 0.0997111\n",
      "\tspeed: 0.2452s/iter; left time: 2477.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:56.52s\n",
      "Steps: 224 | Train Loss: 0.1014097 Vali Loss: 0.1199121 Test Loss: 0.1326514\n",
      "Validation loss decreased (0.119957 --> 0.119912).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1037415\n",
      "\tspeed: 0.8525s/iter; left time: 8509.0414s\n",
      "\titers: 200, epoch: 56 | loss: 0.1031300\n",
      "\tspeed: 0.2377s/iter; left time: 2348.4586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:56.19s\n",
      "Steps: 224 | Train Loss: 0.1014731 Vali Loss: 0.1202566 Test Loss: 0.1329472\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1008514\n",
      "\tspeed: 0.8013s/iter; left time: 7818.4867s\n",
      "\titers: 200, epoch: 57 | loss: 0.1031975\n",
      "\tspeed: 0.2705s/iter; left time: 2612.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:58.50s\n",
      "Steps: 224 | Train Loss: 0.1013736 Vali Loss: 0.1200582 Test Loss: 0.1330758\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.1050920\n",
      "\tspeed: 0.8331s/iter; left time: 7941.6055s\n",
      "\titers: 200, epoch: 58 | loss: 0.1070896\n",
      "\tspeed: 0.2151s/iter; left time: 2028.8474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:52.59s\n",
      "Steps: 224 | Train Loss: 0.1014259 Vali Loss: 0.1205388 Test Loss: 0.1337711\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.1043649\n",
      "\tspeed: 0.8516s/iter; left time: 7927.2217s\n",
      "\titers: 200, epoch: 59 | loss: 0.1081941\n",
      "\tspeed: 0.2484s/iter; left time: 2287.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:55.67s\n",
      "Steps: 224 | Train Loss: 0.1013385 Vali Loss: 0.1205128 Test Loss: 0.1335953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0988084\n",
      "\tspeed: 0.7956s/iter; left time: 7228.2403s\n",
      "\titers: 200, epoch: 60 | loss: 0.1033372\n",
      "\tspeed: 0.2171s/iter; left time: 1950.3318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:51.53s\n",
      "Steps: 224 | Train Loss: 0.1013759 Vali Loss: 0.1203726 Test Loss: 0.1334884\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0946015\n",
      "\tspeed: 0.4507s/iter; left time: 3993.2869s\n",
      "\titers: 200, epoch: 61 | loss: 0.0986594\n",
      "\tspeed: 0.1157s/iter; left time: 1013.3095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:27.18s\n",
      "Steps: 224 | Train Loss: 0.1013898 Vali Loss: 0.1200167 Test Loss: 0.1329747\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.1028007\n",
      "\tspeed: 0.5268s/iter; left time: 4549.7012s\n",
      "\titers: 200, epoch: 62 | loss: 0.0947230\n",
      "\tspeed: 0.1303s/iter; left time: 1112.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:29.76s\n",
      "Steps: 224 | Train Loss: 0.1014403 Vali Loss: 0.1200507 Test Loss: 0.1330406\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.1043935\n",
      "\tspeed: 0.4010s/iter; left time: 3373.5372s\n",
      "\titers: 200, epoch: 63 | loss: 0.1031553\n",
      "\tspeed: 0.1229s/iter; left time: 1021.9637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:28.35s\n",
      "Steps: 224 | Train Loss: 0.1013708 Vali Loss: 0.1202125 Test Loss: 0.1334334\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0993519\n",
      "\tspeed: 0.4078s/iter; left time: 3339.5816s\n",
      "\titers: 200, epoch: 64 | loss: 0.0975773\n",
      "\tspeed: 0.1208s/iter; left time: 977.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:27.84s\n",
      "Steps: 224 | Train Loss: 0.1014076 Vali Loss: 0.1202848 Test Loss: 0.1335480\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.1044489\n",
      "\tspeed: 0.4025s/iter; left time: 3205.8998s\n",
      "\titers: 200, epoch: 65 | loss: 0.0990196\n",
      "\tspeed: 0.1207s/iter; left time: 949.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:27.98s\n",
      "Steps: 224 | Train Loss: 0.1013829 Vali Loss: 0.1203224 Test Loss: 0.1333933\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041031237691640854, rmse:0.20256169140338898, mae:0.13265147805213928, rse:0.7173118591308594\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2637779\n",
      "\tspeed: 0.1372s/iter; left time: 3059.5645s\n",
      "\titers: 200, epoch: 1 | loss: 0.2539923\n",
      "\tspeed: 0.1345s/iter; left time: 2986.4745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.36s\n",
      "Steps: 224 | Train Loss: 0.2697836 Vali Loss: 0.2269523 Test Loss: 0.2268142\n",
      "Validation loss decreased (inf --> 0.226952).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1553876\n",
      "\tspeed: 0.4171s/iter; left time: 9207.8952s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364550\n",
      "\tspeed: 0.1824s/iter; left time: 4008.5037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.73s\n",
      "Steps: 224 | Train Loss: 0.1634123 Vali Loss: 0.1403220 Test Loss: 0.1478905\n",
      "Validation loss decreased (0.226952 --> 0.140322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1286377\n",
      "\tspeed: 0.7281s/iter; left time: 15910.8845s\n",
      "\titers: 200, epoch: 3 | loss: 0.1138140\n",
      "\tspeed: 0.1274s/iter; left time: 2772.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:35.64s\n",
      "Steps: 224 | Train Loss: 0.1238197 Vali Loss: 0.1302920 Test Loss: 0.1432873\n",
      "Validation loss decreased (0.140322 --> 0.130292).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1141549\n",
      "\tspeed: 0.5290s/iter; left time: 11441.0569s\n",
      "\titers: 200, epoch: 4 | loss: 0.1127083\n",
      "\tspeed: 0.2532s/iter; left time: 5451.1752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:56.28s\n",
      "Steps: 224 | Train Loss: 0.1154949 Vali Loss: 0.1249511 Test Loss: 0.1344829\n",
      "Validation loss decreased (0.130292 --> 0.124951).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1176004\n",
      "\tspeed: 0.8327s/iter; left time: 17824.2131s\n",
      "\titers: 200, epoch: 5 | loss: 0.1118314\n",
      "\tspeed: 0.2622s/iter; left time: 5586.9675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:59.04s\n",
      "Steps: 224 | Train Loss: 0.1117181 Vali Loss: 0.1234926 Test Loss: 0.1330716\n",
      "Validation loss decreased (0.124951 --> 0.123493).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1080893\n",
      "\tspeed: 0.8528s/iter; left time: 18063.2646s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098259\n",
      "\tspeed: 0.2863s/iter; left time: 6034.8184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:02.03s\n",
      "Steps: 224 | Train Loss: 0.1098882 Vali Loss: 0.1231055 Test Loss: 0.1313563\n",
      "Validation loss decreased (0.123493 --> 0.123106).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1121295\n",
      "\tspeed: 0.8423s/iter; left time: 17651.8771s\n",
      "\titers: 200, epoch: 7 | loss: 0.1001399\n",
      "\tspeed: 0.2452s/iter; left time: 5113.5324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.69s\n",
      "Steps: 224 | Train Loss: 0.1085345 Vali Loss: 0.1220433 Test Loss: 0.1314394\n",
      "Validation loss decreased (0.123106 --> 0.122043).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1054836\n",
      "\tspeed: 0.8403s/iter; left time: 17421.4164s\n",
      "\titers: 200, epoch: 8 | loss: 0.1088158\n",
      "\tspeed: 0.2380s/iter; left time: 4910.4341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:56.40s\n",
      "Steps: 224 | Train Loss: 0.1074146 Vali Loss: 0.1220296 Test Loss: 0.1324325\n",
      "Validation loss decreased (0.122043 --> 0.122030).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063514\n",
      "\tspeed: 0.8752s/iter; left time: 17950.3079s\n",
      "\titers: 200, epoch: 9 | loss: 0.1069098\n",
      "\tspeed: 0.2653s/iter; left time: 5414.6269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:00.40s\n",
      "Steps: 224 | Train Loss: 0.1070694 Vali Loss: 0.1217695 Test Loss: 0.1323135\n",
      "Validation loss decreased (0.122030 --> 0.121769).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1109394\n",
      "\tspeed: 0.8571s/iter; left time: 17385.3396s\n",
      "\titers: 200, epoch: 10 | loss: 0.1069677\n",
      "\tspeed: 0.2456s/iter; left time: 4957.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:57.45s\n",
      "Steps: 224 | Train Loss: 0.1063840 Vali Loss: 0.1224054 Test Loss: 0.1326594\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1090138\n",
      "\tspeed: 0.7265s/iter; left time: 14574.8101s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049139\n",
      "\tspeed: 0.1345s/iter; left time: 2684.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:36.06s\n",
      "Steps: 224 | Train Loss: 0.1058753 Vali Loss: 0.1216009 Test Loss: 0.1337217\n",
      "Validation loss decreased (0.121769 --> 0.121601).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1080899\n",
      "\tspeed: 0.4648s/iter; left time: 9220.9210s\n",
      "\titers: 200, epoch: 12 | loss: 0.1054267\n",
      "\tspeed: 0.1415s/iter; left time: 2792.9273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:36.18s\n",
      "Steps: 224 | Train Loss: 0.1053662 Vali Loss: 0.1221200 Test Loss: 0.1341606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1055244\n",
      "\tspeed: 0.4462s/iter; left time: 8752.1789s\n",
      "\titers: 200, epoch: 13 | loss: 0.1087706\n",
      "\tspeed: 0.1303s/iter; left time: 2543.2865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.99s\n",
      "Steps: 224 | Train Loss: 0.1050417 Vali Loss: 0.1212838 Test Loss: 0.1324103\n",
      "Validation loss decreased (0.121601 --> 0.121284).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1043101\n",
      "\tspeed: 0.4238s/iter; left time: 8216.5703s\n",
      "\titers: 200, epoch: 14 | loss: 0.1007886\n",
      "\tspeed: 0.1276s/iter; left time: 2461.2887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.55s\n",
      "Steps: 224 | Train Loss: 0.1045775 Vali Loss: 0.1208834 Test Loss: 0.1339697\n",
      "Validation loss decreased (0.121284 --> 0.120883).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1068064\n",
      "\tspeed: 0.4174s/iter; left time: 8000.1406s\n",
      "\titers: 200, epoch: 15 | loss: 0.0979744\n",
      "\tspeed: 0.1218s/iter; left time: 2321.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.32s\n",
      "Steps: 224 | Train Loss: 0.1041305 Vali Loss: 0.1214591 Test Loss: 0.1339417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1082182\n",
      "\tspeed: 0.4103s/iter; left time: 7771.6859s\n",
      "\titers: 200, epoch: 16 | loss: 0.1022706\n",
      "\tspeed: 0.1186s/iter; left time: 2234.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.62s\n",
      "Steps: 224 | Train Loss: 0.1039353 Vali Loss: 0.1231866 Test Loss: 0.1344898\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1073123\n",
      "\tspeed: 0.3983s/iter; left time: 7455.6463s\n",
      "\titers: 200, epoch: 17 | loss: 0.1039126\n",
      "\tspeed: 0.1233s/iter; left time: 2294.8785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.86s\n",
      "Steps: 224 | Train Loss: 0.1037457 Vali Loss: 0.1206146 Test Loss: 0.1327467\n",
      "Validation loss decreased (0.120883 --> 0.120615).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1039048\n",
      "\tspeed: 0.4899s/iter; left time: 9060.5731s\n",
      "\titers: 200, epoch: 18 | loss: 0.1027165\n",
      "\tspeed: 0.2188s/iter; left time: 4025.2858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:49.55s\n",
      "Steps: 224 | Train Loss: 0.1034835 Vali Loss: 0.1214214 Test Loss: 0.1346130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1010692\n",
      "\tspeed: 0.5714s/iter; left time: 10439.4127s\n",
      "\titers: 200, epoch: 19 | loss: 0.1035050\n",
      "\tspeed: 0.1217s/iter; left time: 2211.2607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 224 | Train Loss: 0.1030755 Vali Loss: 0.1214949 Test Loss: 0.1360879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1027409\n",
      "\tspeed: 0.3985s/iter; left time: 7191.2009s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025753\n",
      "\tspeed: 0.1598s/iter; left time: 2868.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:34.36s\n",
      "Steps: 224 | Train Loss: 0.1029724 Vali Loss: 0.1217011 Test Loss: 0.1374518\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1017875\n",
      "\tspeed: 0.8156s/iter; left time: 14534.9035s\n",
      "\titers: 200, epoch: 21 | loss: 0.1028564\n",
      "\tspeed: 0.2403s/iter; left time: 4258.9846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:54.89s\n",
      "Steps: 224 | Train Loss: 0.1027034 Vali Loss: 0.1215911 Test Loss: 0.1348408\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1058805\n",
      "\tspeed: 0.7412s/iter; left time: 13042.1944s\n",
      "\titers: 200, epoch: 22 | loss: 0.1023147\n",
      "\tspeed: 0.2253s/iter; left time: 3941.7214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:54.09s\n",
      "Steps: 224 | Train Loss: 0.1026770 Vali Loss: 0.1212407 Test Loss: 0.1360069\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0985907\n",
      "\tspeed: 0.8257s/iter; left time: 14345.3529s\n",
      "\titers: 200, epoch: 23 | loss: 0.0965465\n",
      "\tspeed: 0.2411s/iter; left time: 4164.6608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:57.13s\n",
      "Steps: 224 | Train Loss: 0.1025187 Vali Loss: 0.1206689 Test Loss: 0.1343070\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1008442\n",
      "\tspeed: 0.8186s/iter; left time: 14038.4567s\n",
      "\titers: 200, epoch: 24 | loss: 0.1059913\n",
      "\tspeed: 0.2668s/iter; left time: 4549.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:01m:00.21s\n",
      "Steps: 224 | Train Loss: 0.1023237 Vali Loss: 0.1219813 Test Loss: 0.1354348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1031865\n",
      "\tspeed: 0.8608s/iter; left time: 14569.8028s\n",
      "\titers: 200, epoch: 25 | loss: 0.1060965\n",
      "\tspeed: 0.2352s/iter; left time: 3957.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:54.46s\n",
      "Steps: 224 | Train Loss: 0.1021904 Vali Loss: 0.1211420 Test Loss: 0.1354917\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1074181\n",
      "\tspeed: 0.8642s/iter; left time: 14433.5571s\n",
      "\titers: 200, epoch: 26 | loss: 0.1013318\n",
      "\tspeed: 0.2313s/iter; left time: 3839.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:56.46s\n",
      "Steps: 224 | Train Loss: 0.1020890 Vali Loss: 0.1218510 Test Loss: 0.1367242\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1010258\n",
      "\tspeed: 0.8195s/iter; left time: 13502.3842s\n",
      "\titers: 200, epoch: 27 | loss: 0.1017653\n",
      "\tspeed: 0.2660s/iter; left time: 4356.9209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:59.23s\n",
      "Steps: 224 | Train Loss: 0.1020027 Vali Loss: 0.1219892 Test Loss: 0.1365549\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04001430422067642, rmse:0.20003575086593628, mae:0.13274672627449036, rse:0.7083670496940613\n",
      "Intermediate time for DE and pred_len 96: 02h:06m:51.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2677401\n",
      "\tspeed: 0.1820s/iter; left time: 4040.1145s\n",
      "\titers: 200, epoch: 1 | loss: 0.2500999\n",
      "\tspeed: 0.1208s/iter; left time: 2670.7722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 223 | Train Loss: 0.2677914 Vali Loss: 0.2254755 Test Loss: 0.2269949\n",
      "Validation loss decreased (inf --> 0.225476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1593123\n",
      "\tspeed: 0.5065s/iter; left time: 11131.0234s\n",
      "\titers: 200, epoch: 2 | loss: 0.1386128\n",
      "\tspeed: 0.1369s/iter; left time: 2995.7880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.79s\n",
      "Steps: 223 | Train Loss: 0.1644203 Vali Loss: 0.1425524 Test Loss: 0.1512714\n",
      "Validation loss decreased (0.225476 --> 0.142552).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1321919\n",
      "\tspeed: 0.4190s/iter; left time: 9116.4001s\n",
      "\titers: 200, epoch: 3 | loss: 0.1247367\n",
      "\tspeed: 0.1273s/iter; left time: 2755.9920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.85s\n",
      "Steps: 223 | Train Loss: 0.1279126 Vali Loss: 0.1341396 Test Loss: 0.1474057\n",
      "Validation loss decreased (0.142552 --> 0.134140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1182213\n",
      "\tspeed: 0.4161s/iter; left time: 8959.8817s\n",
      "\titers: 200, epoch: 4 | loss: 0.1244321\n",
      "\tspeed: 0.1242s/iter; left time: 2661.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.72s\n",
      "Steps: 223 | Train Loss: 0.1203479 Vali Loss: 0.1314158 Test Loss: 0.1428362\n",
      "Validation loss decreased (0.134140 --> 0.131416).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1133140\n",
      "\tspeed: 0.4057s/iter; left time: 8644.1970s\n",
      "\titers: 200, epoch: 5 | loss: 0.1205413\n",
      "\tspeed: 0.1257s/iter; left time: 2666.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 223 | Train Loss: 0.1167874 Vali Loss: 0.1323499 Test Loss: 0.1460033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116394\n",
      "\tspeed: 0.3879s/iter; left time: 8178.9912s\n",
      "\titers: 200, epoch: 6 | loss: 0.1199970\n",
      "\tspeed: 0.1190s/iter; left time: 2496.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.91s\n",
      "Steps: 223 | Train Loss: 0.1157549 Vali Loss: 0.1268357 Test Loss: 0.1388419\n",
      "Validation loss decreased (0.131416 --> 0.126836).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1147387\n",
      "\tspeed: 0.3745s/iter; left time: 7812.5994s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117559\n",
      "\tspeed: 0.1141s/iter; left time: 2369.2890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:26.73s\n",
      "Steps: 223 | Train Loss: 0.1136810 Vali Loss: 0.1281963 Test Loss: 0.1412103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1097705\n",
      "\tspeed: 0.4119s/iter; left time: 8501.1668s\n",
      "\titers: 200, epoch: 8 | loss: 0.1177658\n",
      "\tspeed: 0.2162s/iter; left time: 4440.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.15s\n",
      "Steps: 223 | Train Loss: 0.1128562 Vali Loss: 0.1255399 Test Loss: 0.1383563\n",
      "Validation loss decreased (0.126836 --> 0.125540).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1115139\n",
      "\tspeed: 0.6424s/iter; left time: 13114.9236s\n",
      "\titers: 200, epoch: 9 | loss: 0.1040265\n",
      "\tspeed: 0.1242s/iter; left time: 2523.3825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.41s\n",
      "Steps: 223 | Train Loss: 0.1121096 Vali Loss: 0.1247006 Test Loss: 0.1388338\n",
      "Validation loss decreased (0.125540 --> 0.124701).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1090760\n",
      "\tspeed: 0.4173s/iter; left time: 8426.7990s\n",
      "\titers: 200, epoch: 10 | loss: 0.1103452\n",
      "\tspeed: 0.2344s/iter; left time: 4710.1678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.13s\n",
      "Steps: 223 | Train Loss: 0.1114390 Vali Loss: 0.1259230 Test Loss: 0.1378208\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1114614\n",
      "\tspeed: 0.7927s/iter; left time: 15831.7958s\n",
      "\titers: 200, epoch: 11 | loss: 0.1060762\n",
      "\tspeed: 0.2121s/iter; left time: 4214.2286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:51.49s\n",
      "Steps: 223 | Train Loss: 0.1108384 Vali Loss: 0.1250621 Test Loss: 0.1402404\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1065840\n",
      "\tspeed: 0.6699s/iter; left time: 13228.7014s\n",
      "\titers: 200, epoch: 12 | loss: 0.1133321\n",
      "\tspeed: 0.2306s/iter; left time: 4531.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:48.12s\n",
      "Steps: 223 | Train Loss: 0.1104513 Vali Loss: 0.1243598 Test Loss: 0.1387811\n",
      "Validation loss decreased (0.124701 --> 0.124360).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1147133\n",
      "\tspeed: 0.8004s/iter; left time: 15627.8795s\n",
      "\titers: 200, epoch: 13 | loss: 0.1110229\n",
      "\tspeed: 0.2324s/iter; left time: 4514.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:50.87s\n",
      "Steps: 223 | Train Loss: 0.1098902 Vali Loss: 0.1252507 Test Loss: 0.1385313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1030627\n",
      "\tspeed: 0.7667s/iter; left time: 14799.2301s\n",
      "\titers: 200, epoch: 14 | loss: 0.1171217\n",
      "\tspeed: 0.2492s/iter; left time: 4784.1928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:53.88s\n",
      "Steps: 223 | Train Loss: 0.1096920 Vali Loss: 0.1240418 Test Loss: 0.1379994\n",
      "Validation loss decreased (0.124360 --> 0.124042).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1099146\n",
      "\tspeed: 0.7925s/iter; left time: 15120.7059s\n",
      "\titers: 200, epoch: 15 | loss: 0.1168502\n",
      "\tspeed: 0.2386s/iter; left time: 4527.7700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:54.25s\n",
      "Steps: 223 | Train Loss: 0.1091754 Vali Loss: 0.1244492 Test Loss: 0.1391391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1109005\n",
      "\tspeed: 0.8506s/iter; left time: 16039.5180s\n",
      "\titers: 200, epoch: 16 | loss: 0.1168759\n",
      "\tspeed: 0.2385s/iter; left time: 4473.2860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:56.54s\n",
      "Steps: 223 | Train Loss: 0.1089259 Vali Loss: 0.1237585 Test Loss: 0.1388641\n",
      "Validation loss decreased (0.124042 --> 0.123758).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1079608\n",
      "\tspeed: 0.8065s/iter; left time: 15026.7810s\n",
      "\titers: 200, epoch: 17 | loss: 0.1118281\n",
      "\tspeed: 0.2684s/iter; left time: 4974.9967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:60.00s\n",
      "Steps: 223 | Train Loss: 0.1089215 Vali Loss: 0.1239117 Test Loss: 0.1385030\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1070187\n",
      "\tspeed: 0.8212s/iter; left time: 15118.3243s\n",
      "\titers: 200, epoch: 18 | loss: 0.1113766\n",
      "\tspeed: 0.2308s/iter; left time: 4226.7087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:54.10s\n",
      "Steps: 223 | Train Loss: 0.1084525 Vali Loss: 0.1245929 Test Loss: 0.1390746\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1078872\n",
      "\tspeed: 0.5102s/iter; left time: 9278.2869s\n",
      "\titers: 200, epoch: 19 | loss: 0.1082217\n",
      "\tspeed: 0.1234s/iter; left time: 2231.5405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.64s\n",
      "Steps: 223 | Train Loss: 0.1083489 Vali Loss: 0.1241439 Test Loss: 0.1387376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1106229\n",
      "\tspeed: 0.5091s/iter; left time: 9144.9814s\n",
      "\titers: 200, epoch: 20 | loss: 0.1058486\n",
      "\tspeed: 0.1367s/iter; left time: 2442.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:30.81s\n",
      "Steps: 223 | Train Loss: 0.1081340 Vali Loss: 0.1249562 Test Loss: 0.1388736\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1109785\n",
      "\tspeed: 0.4165s/iter; left time: 7388.9705s\n",
      "\titers: 200, epoch: 21 | loss: 0.1143317\n",
      "\tspeed: 0.1311s/iter; left time: 2313.4206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:29.82s\n",
      "Steps: 223 | Train Loss: 0.1078482 Vali Loss: 0.1240840 Test Loss: 0.1393505\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1025771\n",
      "\tspeed: 0.4115s/iter; left time: 7208.7390s\n",
      "\titers: 200, epoch: 22 | loss: 0.1160046\n",
      "\tspeed: 0.1290s/iter; left time: 2247.3632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:29.41s\n",
      "Steps: 223 | Train Loss: 0.1077650 Vali Loss: 0.1239440 Test Loss: 0.1394758\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1055426\n",
      "\tspeed: 0.4009s/iter; left time: 6933.0544s\n",
      "\titers: 200, epoch: 23 | loss: 0.1066774\n",
      "\tspeed: 0.1223s/iter; left time: 2103.2561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 223 | Train Loss: 0.1076436 Vali Loss: 0.1237174 Test Loss: 0.1397213\n",
      "Validation loss decreased (0.123758 --> 0.123717).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1117916\n",
      "\tspeed: 0.4060s/iter; left time: 6931.2183s\n",
      "\titers: 200, epoch: 24 | loss: 0.1053094\n",
      "\tspeed: 0.1229s/iter; left time: 2085.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 223 | Train Loss: 0.1075170 Vali Loss: 0.1242549 Test Loss: 0.1396834\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1053841\n",
      "\tspeed: 0.3909s/iter; left time: 6585.9963s\n",
      "\titers: 200, epoch: 25 | loss: 0.1098340\n",
      "\tspeed: 0.1257s/iter; left time: 2104.7875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:27.87s\n",
      "Steps: 223 | Train Loss: 0.1074955 Vali Loss: 0.1253681 Test Loss: 0.1398134\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1112672\n",
      "\tspeed: 0.4496s/iter; left time: 7474.9399s\n",
      "\titers: 200, epoch: 26 | loss: 0.1081250\n",
      "\tspeed: 0.2468s/iter; left time: 4078.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 223 | Train Loss: 0.1073715 Vali Loss: 0.1239515 Test Loss: 0.1398005\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1046215\n",
      "\tspeed: 0.6356s/iter; left time: 10426.2286s\n",
      "\titers: 200, epoch: 27 | loss: 0.1099223\n",
      "\tspeed: 0.1248s/iter; left time: 2035.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:30.29s\n",
      "Steps: 223 | Train Loss: 0.1072185 Vali Loss: 0.1245477 Test Loss: 0.1405662\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1015848\n",
      "\tspeed: 0.3879s/iter; left time: 6276.5514s\n",
      "\titers: 200, epoch: 28 | loss: 0.1063603\n",
      "\tspeed: 0.1238s/iter; left time: 1991.2611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:28.48s\n",
      "Steps: 223 | Train Loss: 0.1071196 Vali Loss: 0.1245505 Test Loss: 0.1407450\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1069006\n",
      "\tspeed: 0.5189s/iter; left time: 8280.5286s\n",
      "\titers: 200, epoch: 29 | loss: 0.1105788\n",
      "\tspeed: 0.2086s/iter; left time: 3308.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 223 | Train Loss: 0.1070262 Vali Loss: 0.1245916 Test Loss: 0.1401049\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1082705\n",
      "\tspeed: 0.8010s/iter; left time: 12603.3532s\n",
      "\titers: 200, epoch: 30 | loss: 0.1039594\n",
      "\tspeed: 0.2132s/iter; left time: 3333.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:49.66s\n",
      "Steps: 223 | Train Loss: 0.1069801 Vali Loss: 0.1240263 Test Loss: 0.1407945\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1060863\n",
      "\tspeed: 0.8509s/iter; left time: 13198.8991s\n",
      "\titers: 200, epoch: 31 | loss: 0.1059026\n",
      "\tspeed: 0.2570s/iter; left time: 3960.3181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:58.35s\n",
      "Steps: 223 | Train Loss: 0.1069937 Vali Loss: 0.1243488 Test Loss: 0.1395311\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1063939\n",
      "\tspeed: 0.8256s/iter; left time: 12621.6915s\n",
      "\titers: 200, epoch: 32 | loss: 0.1106143\n",
      "\tspeed: 0.2488s/iter; left time: 3778.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:56.81s\n",
      "Steps: 223 | Train Loss: 0.1068519 Vali Loss: 0.1243310 Test Loss: 0.1400480\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1028770\n",
      "\tspeed: 0.7825s/iter; left time: 11788.2613s\n",
      "\titers: 200, epoch: 33 | loss: 0.1085596\n",
      "\tspeed: 0.2671s/iter; left time: 3997.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:58.78s\n",
      "Steps: 223 | Train Loss: 0.1068738 Vali Loss: 0.1245206 Test Loss: 0.1404692\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04376948997378349, rmse:0.2092115879058838, mae:0.13972122967243195, rse:0.7410442233085632\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2678179\n",
      "\tspeed: 0.2540s/iter; left time: 5640.1258s\n",
      "\titers: 200, epoch: 1 | loss: 0.2601849\n",
      "\tspeed: 0.2870s/iter; left time: 6343.8273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:59.61s\n",
      "Steps: 223 | Train Loss: 0.2700721 Vali Loss: 0.2284293 Test Loss: 0.2284866\n",
      "Validation loss decreased (inf --> 0.228429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1526771\n",
      "\tspeed: 0.7921s/iter; left time: 17407.7969s\n",
      "\titers: 200, epoch: 2 | loss: 0.1368490\n",
      "\tspeed: 0.2312s/iter; left time: 5057.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:52.45s\n",
      "Steps: 223 | Train Loss: 0.1647886 Vali Loss: 0.1434907 Test Loss: 0.1514495\n",
      "Validation loss decreased (0.228429 --> 0.143491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1290625\n",
      "\tspeed: 0.5263s/iter; left time: 11448.8424s\n",
      "\titers: 200, epoch: 3 | loss: 0.1342795\n",
      "\tspeed: 0.1253s/iter; left time: 2714.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.66s\n",
      "Steps: 223 | Train Loss: 0.1285911 Vali Loss: 0.1325456 Test Loss: 0.1435570\n",
      "Validation loss decreased (0.143491 --> 0.132546).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1286276\n",
      "\tspeed: 0.5247s/iter; left time: 11297.1592s\n",
      "\titers: 200, epoch: 4 | loss: 0.1129482\n",
      "\tspeed: 0.1466s/iter; left time: 3141.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 223 | Train Loss: 0.1204149 Vali Loss: 0.1294772 Test Loss: 0.1390823\n",
      "Validation loss decreased (0.132546 --> 0.129477).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1217600\n",
      "\tspeed: 0.4444s/iter; left time: 9470.6474s\n",
      "\titers: 200, epoch: 5 | loss: 0.1188570\n",
      "\tspeed: 0.1338s/iter; left time: 2837.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.74s\n",
      "Steps: 223 | Train Loss: 0.1169646 Vali Loss: 0.1268400 Test Loss: 0.1379709\n",
      "Validation loss decreased (0.129477 --> 0.126840).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114642\n",
      "\tspeed: 0.4307s/iter; left time: 9081.9841s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119515\n",
      "\tspeed: 0.1303s/iter; left time: 2734.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.80s\n",
      "Steps: 223 | Train Loss: 0.1150505 Vali Loss: 0.1270903 Test Loss: 0.1384747\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1139235\n",
      "\tspeed: 0.4103s/iter; left time: 8559.3823s\n",
      "\titers: 200, epoch: 7 | loss: 0.1189825\n",
      "\tspeed: 0.1289s/iter; left time: 2676.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.51s\n",
      "Steps: 223 | Train Loss: 0.1139136 Vali Loss: 0.1262894 Test Loss: 0.1383724\n",
      "Validation loss decreased (0.126840 --> 0.126289).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1130129\n",
      "\tspeed: 0.4018s/iter; left time: 8293.9554s\n",
      "\titers: 200, epoch: 8 | loss: 0.1207840\n",
      "\tspeed: 0.1275s/iter; left time: 2619.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.59s\n",
      "Steps: 223 | Train Loss: 0.1127733 Vali Loss: 0.1258684 Test Loss: 0.1373622\n",
      "Validation loss decreased (0.126289 --> 0.125868).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1110505\n",
      "\tspeed: 0.4051s/iter; left time: 8271.9044s\n",
      "\titers: 200, epoch: 9 | loss: 0.1110816\n",
      "\tspeed: 0.1264s/iter; left time: 2568.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.85s\n",
      "Steps: 223 | Train Loss: 0.1121919 Vali Loss: 0.1263518 Test Loss: 0.1391543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1166428\n",
      "\tspeed: 0.7764s/iter; left time: 15678.3245s\n",
      "\titers: 200, epoch: 10 | loss: 0.1149522\n",
      "\tspeed: 0.1712s/iter; left time: 3439.2503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:47.23s\n",
      "Steps: 223 | Train Loss: 0.1114415 Vali Loss: 0.1262719 Test Loss: 0.1381124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1055341\n",
      "\tspeed: 0.3971s/iter; left time: 7930.6501s\n",
      "\titers: 200, epoch: 11 | loss: 0.1137167\n",
      "\tspeed: 0.2145s/iter; left time: 4262.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.70s\n",
      "Steps: 223 | Train Loss: 0.1108182 Vali Loss: 0.1267690 Test Loss: 0.1385165\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1069434\n",
      "\tspeed: 0.8410s/iter; left time: 16608.4448s\n",
      "\titers: 200, epoch: 12 | loss: 0.1059299\n",
      "\tspeed: 0.2371s/iter; left time: 4657.7625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:57.53s\n",
      "Steps: 223 | Train Loss: 0.1103836 Vali Loss: 0.1263347 Test Loss: 0.1401135\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1044335\n",
      "\tspeed: 0.7244s/iter; left time: 14143.1075s\n",
      "\titers: 200, epoch: 13 | loss: 0.1083170\n",
      "\tspeed: 0.2509s/iter; left time: 4874.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:54.05s\n",
      "Steps: 223 | Train Loss: 0.1099808 Vali Loss: 0.1268499 Test Loss: 0.1402075\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1096646\n",
      "\tspeed: 0.8618s/iter; left time: 16635.2676s\n",
      "\titers: 200, epoch: 14 | loss: 0.1067409\n",
      "\tspeed: 0.2504s/iter; left time: 4807.3588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:55.99s\n",
      "Steps: 223 | Train Loss: 0.1094623 Vali Loss: 0.1260219 Test Loss: 0.1396585\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064554\n",
      "\tspeed: 0.7868s/iter; left time: 15010.7394s\n",
      "\titers: 200, epoch: 15 | loss: 0.1081098\n",
      "\tspeed: 0.2402s/iter; left time: 4559.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:55.87s\n",
      "Steps: 223 | Train Loss: 0.1093660 Vali Loss: 0.1271766 Test Loss: 0.1433219\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1019990\n",
      "\tspeed: 0.8123s/iter; left time: 15316.9019s\n",
      "\titers: 200, epoch: 16 | loss: 0.1077828\n",
      "\tspeed: 0.2168s/iter; left time: 4065.5676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:53.67s\n",
      "Steps: 223 | Train Loss: 0.1088845 Vali Loss: 0.1253926 Test Loss: 0.1404834\n",
      "Validation loss decreased (0.125868 --> 0.125393).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1036045\n",
      "\tspeed: 0.8206s/iter; left time: 15289.7479s\n",
      "\titers: 200, epoch: 17 | loss: 0.1056815\n",
      "\tspeed: 0.2338s/iter; left time: 4332.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:54.17s\n",
      "Steps: 223 | Train Loss: 0.1086885 Vali Loss: 0.1257666 Test Loss: 0.1409977\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1111665\n",
      "\tspeed: 0.8052s/iter; left time: 14824.3938s\n",
      "\titers: 200, epoch: 18 | loss: 0.1033416\n",
      "\tspeed: 0.2361s/iter; left time: 4322.5970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:56.42s\n",
      "Steps: 223 | Train Loss: 0.1084472 Vali Loss: 0.1270310 Test Loss: 0.1410703\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1108564\n",
      "\tspeed: 0.8173s/iter; left time: 14863.9069s\n",
      "\titers: 200, epoch: 19 | loss: 0.1109359\n",
      "\tspeed: 0.1586s/iter; left time: 2867.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:46.60s\n",
      "Steps: 223 | Train Loss: 0.1081637 Vali Loss: 0.1256811 Test Loss: 0.1405032\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1067661\n",
      "\tspeed: 0.4018s/iter; left time: 7218.3277s\n",
      "\titers: 200, epoch: 20 | loss: 0.1044444\n",
      "\tspeed: 0.1904s/iter; left time: 3400.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:34.63s\n",
      "Steps: 223 | Train Loss: 0.1079339 Vali Loss: 0.1257926 Test Loss: 0.1412392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1056872\n",
      "\tspeed: 0.4436s/iter; left time: 7870.1020s\n",
      "\titers: 200, epoch: 21 | loss: 0.1056417\n",
      "\tspeed: 0.1299s/iter; left time: 2291.7125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:29.73s\n",
      "Steps: 223 | Train Loss: 0.1077745 Vali Loss: 0.1258196 Test Loss: 0.1431788\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1139322\n",
      "\tspeed: 0.4151s/iter; left time: 7272.0868s\n",
      "\titers: 200, epoch: 22 | loss: 0.1058415\n",
      "\tspeed: 0.1288s/iter; left time: 2243.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:30.05s\n",
      "Steps: 223 | Train Loss: 0.1075359 Vali Loss: 0.1259646 Test Loss: 0.1420330\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1095286\n",
      "\tspeed: 0.4013s/iter; left time: 6941.1695s\n",
      "\titers: 200, epoch: 23 | loss: 0.1078017\n",
      "\tspeed: 0.1243s/iter; left time: 2138.0348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:28.58s\n",
      "Steps: 223 | Train Loss: 0.1074522 Vali Loss: 0.1257875 Test Loss: 0.1423701\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1091207\n",
      "\tspeed: 0.3856s/iter; left time: 6582.4909s\n",
      "\titers: 200, epoch: 24 | loss: 0.1038631\n",
      "\tspeed: 0.1220s/iter; left time: 2071.0148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:27.86s\n",
      "Steps: 223 | Train Loss: 0.1073591 Vali Loss: 0.1257603 Test Loss: 0.1420650\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1121939\n",
      "\tspeed: 0.3751s/iter; left time: 6320.0785s\n",
      "\titers: 200, epoch: 25 | loss: 0.1112160\n",
      "\tspeed: 0.1183s/iter; left time: 1980.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:26.75s\n",
      "Steps: 223 | Train Loss: 0.1072176 Vali Loss: 0.1256680 Test Loss: 0.1424301\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1042429\n",
      "\tspeed: 0.3613s/iter; left time: 6007.2710s\n",
      "\titers: 200, epoch: 26 | loss: 0.1059490\n",
      "\tspeed: 0.1166s/iter; left time: 1926.1155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 223 | Train Loss: 0.1070919 Vali Loss: 0.1255325 Test Loss: 0.1433024\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04371935874223709, rmse:0.20909175276756287, mae:0.14048337936401367, rse:0.7406197786331177\n",
      "Intermediate time for DE and pred_len 168: 01h:15m:12.16s\n",
      "Intermediate time for DE: 04h:43m:27.27s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2732777\n",
      "\tspeed: 0.1593s/iter; left time: 3553.0049s\n",
      "\titers: 200, epoch: 1 | loss: 0.2720621\n",
      "\tspeed: 0.1189s/iter; left time: 2640.2591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.88s\n",
      "Steps: 224 | Train Loss: 0.2827680 Vali Loss: 0.2356778 Test Loss: 0.2525736\n",
      "Validation loss decreased (inf --> 0.235678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1387694\n",
      "\tspeed: 0.2660s/iter; left time: 5873.2732s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159531\n",
      "\tspeed: 0.1170s/iter; left time: 2571.3214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.58s\n",
      "Steps: 224 | Train Loss: 0.1535574 Vali Loss: 0.1098190 Test Loss: 0.1249808\n",
      "Validation loss decreased (0.235678 --> 0.109819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0959700\n",
      "\tspeed: 0.2738s/iter; left time: 5983.0666s\n",
      "\titers: 200, epoch: 3 | loss: 0.0960949\n",
      "\tspeed: 0.1120s/iter; left time: 2435.6666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:26.70s\n",
      "Steps: 224 | Train Loss: 0.1007390 Vali Loss: 0.0985863 Test Loss: 0.1108643\n",
      "Validation loss decreased (0.109819 --> 0.098586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0849966\n",
      "\tspeed: 0.2717s/iter; left time: 5876.0580s\n",
      "\titers: 200, epoch: 4 | loss: 0.0877187\n",
      "\tspeed: 0.1096s/iter; left time: 2359.4925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 224 | Train Loss: 0.0908397 Vali Loss: 0.0958362 Test Loss: 0.1094365\n",
      "Validation loss decreased (0.098586 --> 0.095836).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867388\n",
      "\tspeed: 0.2666s/iter; left time: 5707.3573s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858547\n",
      "\tspeed: 0.1153s/iter; left time: 2456.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 224 | Train Loss: 0.0873146 Vali Loss: 0.0950037 Test Loss: 0.1087565\n",
      "Validation loss decreased (0.095836 --> 0.095004).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0896161\n",
      "\tspeed: 0.2761s/iter; left time: 5847.8479s\n",
      "\titers: 200, epoch: 6 | loss: 0.0897431\n",
      "\tspeed: 0.1198s/iter; left time: 2524.4589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.48s\n",
      "Steps: 224 | Train Loss: 0.0856580 Vali Loss: 0.0942042 Test Loss: 0.1067638\n",
      "Validation loss decreased (0.095004 --> 0.094204).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0861706\n",
      "\tspeed: 0.2637s/iter; left time: 5526.9787s\n",
      "\titers: 200, epoch: 7 | loss: 0.0910879\n",
      "\tspeed: 0.1140s/iter; left time: 2378.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.05s\n",
      "Steps: 224 | Train Loss: 0.0843104 Vali Loss: 0.0939418 Test Loss: 0.1065206\n",
      "Validation loss decreased (0.094204 --> 0.093942).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0868900\n",
      "\tspeed: 0.2711s/iter; left time: 5621.1550s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891830\n",
      "\tspeed: 0.1182s/iter; left time: 2438.7115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:26.48s\n",
      "Steps: 224 | Train Loss: 0.0837029 Vali Loss: 0.0930818 Test Loss: 0.1063534\n",
      "Validation loss decreased (0.093942 --> 0.093082).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808643\n",
      "\tspeed: 0.2609s/iter; left time: 5351.4064s\n",
      "\titers: 200, epoch: 9 | loss: 0.0846620\n",
      "\tspeed: 0.1078s/iter; left time: 2199.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.56s\n",
      "Steps: 224 | Train Loss: 0.0823498 Vali Loss: 0.0925918 Test Loss: 0.1057123\n",
      "Validation loss decreased (0.093082 --> 0.092592).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0857914\n",
      "\tspeed: 0.2493s/iter; left time: 5056.6801s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791522\n",
      "\tspeed: 0.1132s/iter; left time: 2284.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:26.10s\n",
      "Steps: 224 | Train Loss: 0.0818558 Vali Loss: 0.0929591 Test Loss: 0.1057555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0838465\n",
      "\tspeed: 0.2463s/iter; left time: 4941.1746s\n",
      "\titers: 200, epoch: 11 | loss: 0.0808435\n",
      "\tspeed: 0.1102s/iter; left time: 2199.9180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.52s\n",
      "Steps: 224 | Train Loss: 0.0815923 Vali Loss: 0.0924967 Test Loss: 0.1059232\n",
      "Validation loss decreased (0.092592 --> 0.092497).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0839619\n",
      "\tspeed: 0.2494s/iter; left time: 4947.5902s\n",
      "\titers: 200, epoch: 12 | loss: 0.0779535\n",
      "\tspeed: 0.1063s/iter; left time: 2098.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:24.05s\n",
      "Steps: 224 | Train Loss: 0.0812129 Vali Loss: 0.0923236 Test Loss: 0.1048749\n",
      "Validation loss decreased (0.092497 --> 0.092324).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0790549\n",
      "\tspeed: 0.2384s/iter; left time: 4674.9738s\n",
      "\titers: 200, epoch: 13 | loss: 0.0779859\n",
      "\tspeed: 0.1020s/iter; left time: 1990.0249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:24.04s\n",
      "Steps: 224 | Train Loss: 0.0807267 Vali Loss: 0.0921772 Test Loss: 0.1047238\n",
      "Validation loss decreased (0.092324 --> 0.092177).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0853954\n",
      "\tspeed: 0.2280s/iter; left time: 4420.5453s\n",
      "\titers: 200, epoch: 14 | loss: 0.0746003\n",
      "\tspeed: 0.1086s/iter; left time: 2095.6712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:23.85s\n",
      "Steps: 224 | Train Loss: 0.0802270 Vali Loss: 0.0931399 Test Loss: 0.1056225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734837\n",
      "\tspeed: 0.2246s/iter; left time: 4304.6741s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766692\n",
      "\tspeed: 0.1018s/iter; left time: 1939.8838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 224 | Train Loss: 0.0799810 Vali Loss: 0.0919641 Test Loss: 0.1047651\n",
      "Validation loss decreased (0.092177 --> 0.091964).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0803031\n",
      "\tspeed: 0.2228s/iter; left time: 4220.1685s\n",
      "\titers: 200, epoch: 16 | loss: 0.0833222\n",
      "\tspeed: 0.1016s/iter; left time: 1914.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.97s\n",
      "Steps: 224 | Train Loss: 0.0796829 Vali Loss: 0.0916351 Test Loss: 0.1045505\n",
      "Validation loss decreased (0.091964 --> 0.091635).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0800758\n",
      "\tspeed: 0.2198s/iter; left time: 4114.2021s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850667\n",
      "\tspeed: 0.0980s/iter; left time: 1824.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0794944 Vali Loss: 0.0918174 Test Loss: 0.1047843\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0795045\n",
      "\tspeed: 0.2113s/iter; left time: 3908.4594s\n",
      "\titers: 200, epoch: 18 | loss: 0.0793329\n",
      "\tspeed: 0.0932s/iter; left time: 1713.8002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:21.80s\n",
      "Steps: 224 | Train Loss: 0.0791213 Vali Loss: 0.0920421 Test Loss: 0.1048954\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0752362\n",
      "\tspeed: 0.2013s/iter; left time: 3678.1749s\n",
      "\titers: 200, epoch: 19 | loss: 0.0795645\n",
      "\tspeed: 0.0969s/iter; left time: 1760.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:20.73s\n",
      "Steps: 224 | Train Loss: 0.0790941 Vali Loss: 0.0919640 Test Loss: 0.1051726\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0693512\n",
      "\tspeed: 0.1863s/iter; left time: 3361.8817s\n",
      "\titers: 200, epoch: 20 | loss: 0.0776814\n",
      "\tspeed: 0.0978s/iter; left time: 1755.7089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:21.71s\n",
      "Steps: 224 | Train Loss: 0.0793341 Vali Loss: 0.0919688 Test Loss: 0.1050962\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0803427\n",
      "\tspeed: 0.2087s/iter; left time: 3718.5319s\n",
      "\titers: 200, epoch: 21 | loss: 0.0761298\n",
      "\tspeed: 0.0889s/iter; left time: 1574.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:20.47s\n",
      "Steps: 224 | Train Loss: 0.0786495 Vali Loss: 0.0917224 Test Loss: 0.1051333\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0793081\n",
      "\tspeed: 0.2028s/iter; left time: 3567.8110s\n",
      "\titers: 200, epoch: 22 | loss: 0.0722682\n",
      "\tspeed: 0.0906s/iter; left time: 1584.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:20.21s\n",
      "Steps: 224 | Train Loss: 0.0786959 Vali Loss: 0.0915074 Test Loss: 0.1051770\n",
      "Validation loss decreased (0.091635 --> 0.091507).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0766330\n",
      "\tspeed: 0.1931s/iter; left time: 3354.2591s\n",
      "\titers: 200, epoch: 23 | loss: 0.0733423\n",
      "\tspeed: 0.0766s/iter; left time: 1322.8655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:19.37s\n",
      "Steps: 224 | Train Loss: 0.0784980 Vali Loss: 0.0919009 Test Loss: 0.1048966\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761709\n",
      "\tspeed: 0.2067s/iter; left time: 3545.3543s\n",
      "\titers: 200, epoch: 24 | loss: 0.0780645\n",
      "\tspeed: 0.0825s/iter; left time: 1406.2202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:20.35s\n",
      "Steps: 224 | Train Loss: 0.0783720 Vali Loss: 0.0916299 Test Loss: 0.1046226\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0810427\n",
      "\tspeed: 0.1965s/iter; left time: 3325.5859s\n",
      "\titers: 200, epoch: 25 | loss: 0.0821714\n",
      "\tspeed: 0.0758s/iter; left time: 1274.8388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:19.23s\n",
      "Steps: 224 | Train Loss: 0.0782597 Vali Loss: 0.0912908 Test Loss: 0.1047380\n",
      "Validation loss decreased (0.091507 --> 0.091291).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0789223\n",
      "\tspeed: 0.1849s/iter; left time: 3088.1771s\n",
      "\titers: 200, epoch: 26 | loss: 0.0750540\n",
      "\tspeed: 0.0821s/iter; left time: 1362.9461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 224 | Train Loss: 0.0782287 Vali Loss: 0.0915640 Test Loss: 0.1049205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0766358\n",
      "\tspeed: 0.1775s/iter; left time: 2925.1618s\n",
      "\titers: 200, epoch: 27 | loss: 0.0834665\n",
      "\tspeed: 0.0866s/iter; left time: 1417.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:19.13s\n",
      "Steps: 224 | Train Loss: 0.0782089 Vali Loss: 0.0913870 Test Loss: 0.1050899\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0840169\n",
      "\tspeed: 0.1819s/iter; left time: 2956.5559s\n",
      "\titers: 200, epoch: 28 | loss: 0.0778707\n",
      "\tspeed: 0.0694s/iter; left time: 1121.6788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:17.41s\n",
      "Steps: 224 | Train Loss: 0.0782109 Vali Loss: 0.0915899 Test Loss: 0.1048287\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0804981\n",
      "\tspeed: 0.1949s/iter; left time: 3124.6053s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728595\n",
      "\tspeed: 0.0791s/iter; left time: 1259.6302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:19.02s\n",
      "Steps: 224 | Train Loss: 0.0780370 Vali Loss: 0.0912884 Test Loss: 0.1044882\n",
      "Validation loss decreased (0.091291 --> 0.091288).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0806050\n",
      "\tspeed: 0.1758s/iter; left time: 2778.0758s\n",
      "\titers: 200, epoch: 30 | loss: 0.0777817\n",
      "\tspeed: 0.0778s/iter; left time: 1221.2068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 224 | Train Loss: 0.0780019 Vali Loss: 0.0915458 Test Loss: 0.1049417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0720626\n",
      "\tspeed: 0.1814s/iter; left time: 2826.3887s\n",
      "\titers: 200, epoch: 31 | loss: 0.0781787\n",
      "\tspeed: 0.0692s/iter; left time: 1071.6669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 224 | Train Loss: 0.0779044 Vali Loss: 0.0917564 Test Loss: 0.1048540\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0772920\n",
      "\tspeed: 0.1866s/iter; left time: 2865.1041s\n",
      "\titers: 200, epoch: 32 | loss: 0.0818259\n",
      "\tspeed: 0.0688s/iter; left time: 1050.4209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:17.17s\n",
      "Steps: 224 | Train Loss: 0.0780444 Vali Loss: 0.0914081 Test Loss: 0.1050759\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0771960\n",
      "\tspeed: 0.1838s/iter; left time: 2780.7518s\n",
      "\titers: 200, epoch: 33 | loss: 0.0779091\n",
      "\tspeed: 0.0676s/iter; left time: 1016.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:17.12s\n",
      "Steps: 224 | Train Loss: 0.0779376 Vali Loss: 0.0916778 Test Loss: 0.1050947\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0783090\n",
      "\tspeed: 0.1776s/iter; left time: 2648.0884s\n",
      "\titers: 200, epoch: 34 | loss: 0.0801738\n",
      "\tspeed: 0.0753s/iter; left time: 1114.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:17.48s\n",
      "Steps: 224 | Train Loss: 0.0778886 Vali Loss: 0.0916403 Test Loss: 0.1051711\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0825290\n",
      "\tspeed: 0.1669s/iter; left time: 2451.3214s\n",
      "\titers: 200, epoch: 35 | loss: 0.0802409\n",
      "\tspeed: 0.0659s/iter; left time: 961.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0778877 Vali Loss: 0.0913229 Test Loss: 0.1050001\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0749355\n",
      "\tspeed: 0.1694s/iter; left time: 2449.4018s\n",
      "\titers: 200, epoch: 36 | loss: 0.0816746\n",
      "\tspeed: 0.0678s/iter; left time: 973.0413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:17.83s\n",
      "Steps: 224 | Train Loss: 0.0777349 Vali Loss: 0.0917867 Test Loss: 0.1050216\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0813361\n",
      "\tspeed: 0.1550s/iter; left time: 2206.3937s\n",
      "\titers: 200, epoch: 37 | loss: 0.0754358\n",
      "\tspeed: 0.0675s/iter; left time: 953.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:16.45s\n",
      "Steps: 224 | Train Loss: 0.0777111 Vali Loss: 0.0916470 Test Loss: 0.1050093\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0793837\n",
      "\tspeed: 0.1662s/iter; left time: 2328.3784s\n",
      "\titers: 200, epoch: 38 | loss: 0.0736020\n",
      "\tspeed: 0.0722s/iter; left time: 1005.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 224 | Train Loss: 0.0778182 Vali Loss: 0.0913163 Test Loss: 0.1047526\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0812351\n",
      "\tspeed: 0.1567s/iter; left time: 2160.7461s\n",
      "\titers: 200, epoch: 39 | loss: 0.0750793\n",
      "\tspeed: 0.0675s/iter; left time: 924.2459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:16.39s\n",
      "Steps: 224 | Train Loss: 0.0778398 Vali Loss: 0.0914048 Test Loss: 0.1049108\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02613024413585663, rmse:0.16164852678775787, mae:0.10448814183473587, rse:0.5576415657997131\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2829589\n",
      "\tspeed: 0.0706s/iter; left time: 1574.6817s\n",
      "\titers: 200, epoch: 1 | loss: 0.2735544\n",
      "\tspeed: 0.0784s/iter; left time: 1741.4684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.50s\n",
      "Steps: 224 | Train Loss: 0.2834174 Vali Loss: 0.2331240 Test Loss: 0.2490584\n",
      "Validation loss decreased (inf --> 0.233124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1386662\n",
      "\tspeed: 0.1546s/iter; left time: 3412.6168s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143011\n",
      "\tspeed: 0.0729s/iter; left time: 1602.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 224 | Train Loss: 0.1521513 Vali Loss: 0.1101775 Test Loss: 0.1256462\n",
      "Validation loss decreased (0.233124 --> 0.110177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0974621\n",
      "\tspeed: 0.1689s/iter; left time: 3690.2675s\n",
      "\titers: 200, epoch: 3 | loss: 0.0961546\n",
      "\tspeed: 0.0702s/iter; left time: 1526.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.1001052 Vali Loss: 0.0974129 Test Loss: 0.1106429\n",
      "Validation loss decreased (0.110177 --> 0.097413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0973717\n",
      "\tspeed: 0.1634s/iter; left time: 3533.6434s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828793\n",
      "\tspeed: 0.0742s/iter; left time: 1596.5897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:16.70s\n",
      "Steps: 224 | Train Loss: 0.0902158 Vali Loss: 0.0951305 Test Loss: 0.1084296\n",
      "Validation loss decreased (0.097413 --> 0.095130).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0863252\n",
      "\tspeed: 0.1674s/iter; left time: 3583.7488s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836697\n",
      "\tspeed: 0.0606s/iter; left time: 1291.1068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 224 | Train Loss: 0.0872277 Vali Loss: 0.1001542 Test Loss: 0.1112641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0821471\n",
      "\tspeed: 0.1599s/iter; left time: 3387.2966s\n",
      "\titers: 200, epoch: 6 | loss: 0.0882102\n",
      "\tspeed: 0.0687s/iter; left time: 1448.5095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:16.84s\n",
      "Steps: 224 | Train Loss: 0.0855210 Vali Loss: 0.0939254 Test Loss: 0.1064992\n",
      "Validation loss decreased (0.095130 --> 0.093925).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0843503\n",
      "\tspeed: 0.1536s/iter; left time: 3219.2537s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793133\n",
      "\tspeed: 0.0652s/iter; left time: 1360.3741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:16.27s\n",
      "Steps: 224 | Train Loss: 0.0841044 Vali Loss: 0.0936347 Test Loss: 0.1060433\n",
      "Validation loss decreased (0.093925 --> 0.093635).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0857669\n",
      "\tspeed: 0.1635s/iter; left time: 3388.8228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738804\n",
      "\tspeed: 0.0657s/iter; left time: 1356.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.23s\n",
      "Steps: 224 | Train Loss: 0.0832240 Vali Loss: 0.0942479 Test Loss: 0.1066506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0770256\n",
      "\tspeed: 0.1586s/iter; left time: 3252.2215s\n",
      "\titers: 200, epoch: 9 | loss: 0.0815676\n",
      "\tspeed: 0.0693s/iter; left time: 1414.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.05s\n",
      "Steps: 224 | Train Loss: 0.0824953 Vali Loss: 0.0954476 Test Loss: 0.1074440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811249\n",
      "\tspeed: 0.1573s/iter; left time: 3190.3890s\n",
      "\titers: 200, epoch: 10 | loss: 0.0843753\n",
      "\tspeed: 0.0686s/iter; left time: 1385.5921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:16.28s\n",
      "Steps: 224 | Train Loss: 0.0820141 Vali Loss: 0.0959082 Test Loss: 0.1079797\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0834924\n",
      "\tspeed: 0.1458s/iter; left time: 2925.4068s\n",
      "\titers: 200, epoch: 11 | loss: 0.0825599\n",
      "\tspeed: 0.0648s/iter; left time: 1293.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:14.67s\n",
      "Steps: 224 | Train Loss: 0.0818041 Vali Loss: 0.0939030 Test Loss: 0.1064604\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0840865\n",
      "\tspeed: 0.1496s/iter; left time: 2967.7773s\n",
      "\titers: 200, epoch: 12 | loss: 0.0901997\n",
      "\tspeed: 0.0647s/iter; left time: 1277.2168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.24s\n",
      "Steps: 224 | Train Loss: 0.0811319 Vali Loss: 0.0924839 Test Loss: 0.1059597\n",
      "Validation loss decreased (0.093635 --> 0.092484).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0816619\n",
      "\tspeed: 0.1471s/iter; left time: 2885.1935s\n",
      "\titers: 200, epoch: 13 | loss: 0.0857115\n",
      "\tspeed: 0.0622s/iter; left time: 1212.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.57s\n",
      "Steps: 224 | Train Loss: 0.0808126 Vali Loss: 0.0922774 Test Loss: 0.1050042\n",
      "Validation loss decreased (0.092484 --> 0.092277).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0798821\n",
      "\tspeed: 0.1452s/iter; left time: 2815.4868s\n",
      "\titers: 200, epoch: 14 | loss: 0.0821096\n",
      "\tspeed: 0.0596s/iter; left time: 1148.8547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.13s\n",
      "Steps: 224 | Train Loss: 0.0803621 Vali Loss: 0.0928964 Test Loss: 0.1051456\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0801050\n",
      "\tspeed: 0.1417s/iter; left time: 2715.9222s\n",
      "\titers: 200, epoch: 15 | loss: 0.0803853\n",
      "\tspeed: 0.0608s/iter; left time: 1159.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.60s\n",
      "Steps: 224 | Train Loss: 0.0800876 Vali Loss: 0.0925348 Test Loss: 0.1050143\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779930\n",
      "\tspeed: 0.1426s/iter; left time: 2701.2965s\n",
      "\titers: 200, epoch: 16 | loss: 0.0760460\n",
      "\tspeed: 0.0613s/iter; left time: 1154.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:14.24s\n",
      "Steps: 224 | Train Loss: 0.0800769 Vali Loss: 0.0919332 Test Loss: 0.1048650\n",
      "Validation loss decreased (0.092277 --> 0.091933).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0779226\n",
      "\tspeed: 0.1445s/iter; left time: 2704.1343s\n",
      "\titers: 200, epoch: 17 | loss: 0.0824409\n",
      "\tspeed: 0.0601s/iter; left time: 1119.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.36s\n",
      "Steps: 224 | Train Loss: 0.0796293 Vali Loss: 0.0919880 Test Loss: 0.1047408\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0836078\n",
      "\tspeed: 0.1426s/iter; left time: 2637.2727s\n",
      "\titers: 200, epoch: 18 | loss: 0.0755881\n",
      "\tspeed: 0.0616s/iter; left time: 1133.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:14.34s\n",
      "Steps: 224 | Train Loss: 0.0793821 Vali Loss: 0.0935409 Test Loss: 0.1057734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0789372\n",
      "\tspeed: 0.1441s/iter; left time: 2631.7090s\n",
      "\titers: 200, epoch: 19 | loss: 0.0822771\n",
      "\tspeed: 0.0639s/iter; left time: 1161.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:14.66s\n",
      "Steps: 224 | Train Loss: 0.0792881 Vali Loss: 0.0920678 Test Loss: 0.1049124\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0803816\n",
      "\tspeed: 0.1377s/iter; left time: 2485.4572s\n",
      "\titers: 200, epoch: 20 | loss: 0.0725582\n",
      "\tspeed: 0.0629s/iter; left time: 1129.3756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:14.42s\n",
      "Steps: 224 | Train Loss: 0.0792481 Vali Loss: 0.0923251 Test Loss: 0.1047930\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0782624\n",
      "\tspeed: 0.1479s/iter; left time: 2636.5923s\n",
      "\titers: 200, epoch: 21 | loss: 0.0807235\n",
      "\tspeed: 0.0613s/iter; left time: 1086.9552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:14.35s\n",
      "Steps: 224 | Train Loss: 0.0791205 Vali Loss: 0.0915585 Test Loss: 0.1047115\n",
      "Validation loss decreased (0.091933 --> 0.091559).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0774362\n",
      "\tspeed: 0.1436s/iter; left time: 2526.3506s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750218\n",
      "\tspeed: 0.0652s/iter; left time: 1141.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.12s\n",
      "Steps: 224 | Train Loss: 0.0788140 Vali Loss: 0.0915766 Test Loss: 0.1046148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0835078\n",
      "\tspeed: 0.1657s/iter; left time: 2878.9221s\n",
      "\titers: 200, epoch: 23 | loss: 0.0831055\n",
      "\tspeed: 0.0622s/iter; left time: 1074.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 224 | Train Loss: 0.0787915 Vali Loss: 0.0916489 Test Loss: 0.1047008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0767098\n",
      "\tspeed: 0.2093s/iter; left time: 3589.0231s\n",
      "\titers: 200, epoch: 24 | loss: 0.0781655\n",
      "\tspeed: 0.1273s/iter; left time: 2170.9226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:27.76s\n",
      "Steps: 224 | Train Loss: 0.0785680 Vali Loss: 0.0916642 Test Loss: 0.1045094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0748016\n",
      "\tspeed: 0.2687s/iter; left time: 4547.6541s\n",
      "\titers: 200, epoch: 25 | loss: 0.0803296\n",
      "\tspeed: 0.0989s/iter; left time: 1664.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 224 | Train Loss: 0.0785531 Vali Loss: 0.0927032 Test Loss: 0.1051954\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0785484\n",
      "\tspeed: 0.2619s/iter; left time: 4373.8124s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780891\n",
      "\tspeed: 0.0738s/iter; left time: 1224.9797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:20.72s\n",
      "Steps: 224 | Train Loss: 0.0785391 Vali Loss: 0.0919392 Test Loss: 0.1046671\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0818643\n",
      "\tspeed: 0.1645s/iter; left time: 2710.7259s\n",
      "\titers: 200, epoch: 27 | loss: 0.0832281\n",
      "\tspeed: 0.0771s/iter; left time: 1261.9662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 224 | Train Loss: 0.0783988 Vali Loss: 0.0916684 Test Loss: 0.1046386\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0819602\n",
      "\tspeed: 0.1616s/iter; left time: 2626.0116s\n",
      "\titers: 200, epoch: 28 | loss: 0.0757173\n",
      "\tspeed: 0.0965s/iter; left time: 1558.6478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.74s\n",
      "Steps: 224 | Train Loss: 0.0783943 Vali Loss: 0.0918128 Test Loss: 0.1046350\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0791748\n",
      "\tspeed: 0.1647s/iter; left time: 2639.6766s\n",
      "\titers: 200, epoch: 29 | loss: 0.0760127\n",
      "\tspeed: 0.0707s/iter; left time: 1125.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:17.13s\n",
      "Steps: 224 | Train Loss: 0.0782546 Vali Loss: 0.0918441 Test Loss: 0.1047709\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0866583\n",
      "\tspeed: 0.2445s/iter; left time: 3863.6753s\n",
      "\titers: 200, epoch: 30 | loss: 0.0805861\n",
      "\tspeed: 0.1218s/iter; left time: 1913.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 224 | Train Loss: 0.0782145 Vali Loss: 0.0920427 Test Loss: 0.1048282\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0793006\n",
      "\tspeed: 0.2284s/iter; left time: 3559.3344s\n",
      "\titers: 200, epoch: 31 | loss: 0.0783196\n",
      "\tspeed: 0.1508s/iter; left time: 2334.8935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:27.79s\n",
      "Steps: 224 | Train Loss: 0.0782091 Vali Loss: 0.0913861 Test Loss: 0.1045544\n",
      "Validation loss decreased (0.091559 --> 0.091386).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0755953\n",
      "\tspeed: 0.2049s/iter; left time: 3146.5898s\n",
      "\titers: 200, epoch: 32 | loss: 0.0780552\n",
      "\tspeed: 0.0609s/iter; left time: 928.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0781753 Vali Loss: 0.0913696 Test Loss: 0.1045366\n",
      "Validation loss decreased (0.091386 --> 0.091370).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0786503\n",
      "\tspeed: 0.1734s/iter; left time: 2624.4935s\n",
      "\titers: 200, epoch: 33 | loss: 0.0741667\n",
      "\tspeed: 0.0691s/iter; left time: 1038.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0781753 Vali Loss: 0.0915798 Test Loss: 0.1045586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0758473\n",
      "\tspeed: 0.1742s/iter; left time: 2596.8696s\n",
      "\titers: 200, epoch: 34 | loss: 0.0814890\n",
      "\tspeed: 0.0687s/iter; left time: 1017.3928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 224 | Train Loss: 0.0779901 Vali Loss: 0.0914310 Test Loss: 0.1044736\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0816251\n",
      "\tspeed: 0.1587s/iter; left time: 2329.9572s\n",
      "\titers: 200, epoch: 35 | loss: 0.0792780\n",
      "\tspeed: 0.0690s/iter; left time: 1006.6384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.85s\n",
      "Steps: 224 | Train Loss: 0.0780430 Vali Loss: 0.0911854 Test Loss: 0.1043826\n",
      "Validation loss decreased (0.091370 --> 0.091185).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0775518\n",
      "\tspeed: 0.2167s/iter; left time: 3134.2909s\n",
      "\titers: 200, epoch: 36 | loss: 0.0818657\n",
      "\tspeed: 0.1418s/iter; left time: 2035.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:30.25s\n",
      "Steps: 224 | Train Loss: 0.0780594 Vali Loss: 0.0915816 Test Loss: 0.1045595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0740627\n",
      "\tspeed: 0.3494s/iter; left time: 4973.8520s\n",
      "\titers: 200, epoch: 37 | loss: 0.0784322\n",
      "\tspeed: 0.1255s/iter; left time: 1774.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:29.86s\n",
      "Steps: 224 | Train Loss: 0.0780414 Vali Loss: 0.0913854 Test Loss: 0.1044060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0747805\n",
      "\tspeed: 0.2479s/iter; left time: 3474.0910s\n",
      "\titers: 200, epoch: 38 | loss: 0.0861316\n",
      "\tspeed: 0.0821s/iter; left time: 1141.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:19.09s\n",
      "Steps: 224 | Train Loss: 0.0780091 Vali Loss: 0.0919002 Test Loss: 0.1047737\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0760940\n",
      "\tspeed: 0.1696s/iter; left time: 2338.9796s\n",
      "\titers: 200, epoch: 39 | loss: 0.0777859\n",
      "\tspeed: 0.0720s/iter; left time: 985.4523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:17.27s\n",
      "Steps: 224 | Train Loss: 0.0779444 Vali Loss: 0.0914011 Test Loss: 0.1044038\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0799233\n",
      "\tspeed: 0.1604s/iter; left time: 2176.3779s\n",
      "\titers: 200, epoch: 40 | loss: 0.0754051\n",
      "\tspeed: 0.0875s/iter; left time: 1177.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:17.56s\n",
      "Steps: 224 | Train Loss: 0.0778833 Vali Loss: 0.0916526 Test Loss: 0.1045305\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0744100\n",
      "\tspeed: 0.1493s/iter; left time: 1991.2059s\n",
      "\titers: 200, epoch: 41 | loss: 0.0791146\n",
      "\tspeed: 0.0655s/iter; left time: 867.8199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.28s\n",
      "Steps: 224 | Train Loss: 0.0779660 Vali Loss: 0.0917087 Test Loss: 0.1047505\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0800332\n",
      "\tspeed: 0.1913s/iter; left time: 2509.8755s\n",
      "\titers: 200, epoch: 42 | loss: 0.0824590\n",
      "\tspeed: 0.0591s/iter; left time: 769.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:16.63s\n",
      "Steps: 224 | Train Loss: 0.0779900 Vali Loss: 0.0919105 Test Loss: 0.1049223\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0784396\n",
      "\tspeed: 0.2539s/iter; left time: 3274.0653s\n",
      "\titers: 200, epoch: 43 | loss: 0.0829708\n",
      "\tspeed: 0.0926s/iter; left time: 1184.7503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 224 | Train Loss: 0.0778764 Vali Loss: 0.0915392 Test Loss: 0.1046613\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0719128\n",
      "\tspeed: 0.2764s/iter; left time: 3502.1654s\n",
      "\titers: 200, epoch: 44 | loss: 0.0779391\n",
      "\tspeed: 0.1366s/iter; left time: 1717.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:31.28s\n",
      "Steps: 224 | Train Loss: 0.0778312 Vali Loss: 0.0913401 Test Loss: 0.1044554\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0845949\n",
      "\tspeed: 0.1742s/iter; left time: 2168.5268s\n",
      "\titers: 200, epoch: 45 | loss: 0.0814397\n",
      "\tspeed: 0.0779s/iter; left time: 961.6872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:17.66s\n",
      "Steps: 224 | Train Loss: 0.0778472 Vali Loss: 0.0912811 Test Loss: 0.1044334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02611997351050377, rmse:0.1616167426109314, mae:0.10438255965709686, rse:0.5575319528579712\n",
      "Intermediate time for GB and pred_len 24: 00h:39m:38.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2811899\n",
      "\tspeed: 0.1164s/iter; left time: 2595.9715s\n",
      "\titers: 200, epoch: 1 | loss: 0.2773139\n",
      "\tspeed: 0.0718s/iter; left time: 1594.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.37s\n",
      "Steps: 224 | Train Loss: 0.2828053 Vali Loss: 0.2358261 Test Loss: 0.2561615\n",
      "Validation loss decreased (inf --> 0.235826).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1466443\n",
      "\tspeed: 0.2590s/iter; left time: 5718.1337s\n",
      "\titers: 200, epoch: 2 | loss: 0.1285976\n",
      "\tspeed: 0.0777s/iter; left time: 1707.7011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.21s\n",
      "Steps: 224 | Train Loss: 0.1596364 Vali Loss: 0.1324323 Test Loss: 0.1522585\n",
      "Validation loss decreased (0.235826 --> 0.132432).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1164060\n",
      "\tspeed: 0.3459s/iter; left time: 7559.5957s\n",
      "\titers: 200, epoch: 3 | loss: 0.1118729\n",
      "\tspeed: 0.1181s/iter; left time: 2570.0235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.08s\n",
      "Steps: 224 | Train Loss: 0.1175868 Vali Loss: 0.1226253 Test Loss: 0.1469084\n",
      "Validation loss decreased (0.132432 --> 0.122625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1088176\n",
      "\tspeed: 0.3606s/iter; left time: 7799.0243s\n",
      "\titers: 200, epoch: 4 | loss: 0.1094141\n",
      "\tspeed: 0.0826s/iter; left time: 1778.8423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.56s\n",
      "Steps: 224 | Train Loss: 0.1116613 Vali Loss: 0.1230795 Test Loss: 0.1469986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1095746\n",
      "\tspeed: 0.2305s/iter; left time: 4932.9279s\n",
      "\titers: 200, epoch: 5 | loss: 0.1039534\n",
      "\tspeed: 0.0688s/iter; left time: 1464.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.67s\n",
      "Steps: 224 | Train Loss: 0.1092688 Vali Loss: 0.1258865 Test Loss: 0.1509726\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1110413\n",
      "\tspeed: 0.2478s/iter; left time: 5248.2462s\n",
      "\titers: 200, epoch: 6 | loss: 0.1123277\n",
      "\tspeed: 0.0686s/iter; left time: 1446.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:16.02s\n",
      "Steps: 224 | Train Loss: 0.1075262 Vali Loss: 0.1218966 Test Loss: 0.1459282\n",
      "Validation loss decreased (0.122625 --> 0.121897).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1124330\n",
      "\tspeed: 0.2333s/iter; left time: 4888.2375s\n",
      "\titers: 200, epoch: 7 | loss: 0.1046457\n",
      "\tspeed: 0.1071s/iter; left time: 2233.8870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.1067450 Vali Loss: 0.1230637 Test Loss: 0.1489426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1063998\n",
      "\tspeed: 0.3851s/iter; left time: 7984.5527s\n",
      "\titers: 200, epoch: 8 | loss: 0.1066169\n",
      "\tspeed: 0.1001s/iter; left time: 2064.8213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 224 | Train Loss: 0.1057111 Vali Loss: 0.1230550 Test Loss: 0.1487140\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042437\n",
      "\tspeed: 0.3712s/iter; left time: 7612.3887s\n",
      "\titers: 200, epoch: 9 | loss: 0.1064159\n",
      "\tspeed: 0.0718s/iter; left time: 1464.5632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.22s\n",
      "Steps: 224 | Train Loss: 0.1051231 Vali Loss: 0.1218349 Test Loss: 0.1465024\n",
      "Validation loss decreased (0.121897 --> 0.121835).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1070441\n",
      "\tspeed: 0.1986s/iter; left time: 4028.5260s\n",
      "\titers: 200, epoch: 10 | loss: 0.1019509\n",
      "\tspeed: 0.0737s/iter; left time: 1488.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.1045971 Vali Loss: 0.1219275 Test Loss: 0.1472034\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1038086\n",
      "\tspeed: 0.2153s/iter; left time: 4319.1777s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048296\n",
      "\tspeed: 0.0640s/iter; left time: 1277.7282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:16.65s\n",
      "Steps: 224 | Train Loss: 0.1043262 Vali Loss: 0.1218618 Test Loss: 0.1466882\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1061131\n",
      "\tspeed: 0.1973s/iter; left time: 3913.8148s\n",
      "\titers: 200, epoch: 12 | loss: 0.1024074\n",
      "\tspeed: 0.0624s/iter; left time: 1231.0938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.89s\n",
      "Steps: 224 | Train Loss: 0.1040099 Vali Loss: 0.1222625 Test Loss: 0.1484645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1036150\n",
      "\tspeed: 0.1952s/iter; left time: 3827.6572s\n",
      "\titers: 200, epoch: 13 | loss: 0.1049463\n",
      "\tspeed: 0.0851s/iter; left time: 1661.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:17.04s\n",
      "Steps: 224 | Train Loss: 0.1034427 Vali Loss: 0.1218187 Test Loss: 0.1478378\n",
      "Validation loss decreased (0.121835 --> 0.121819).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1026465\n",
      "\tspeed: 0.2463s/iter; left time: 4775.7503s\n",
      "\titers: 200, epoch: 14 | loss: 0.1020778\n",
      "\tspeed: 0.1032s/iter; left time: 1991.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 224 | Train Loss: 0.1031087 Vali Loss: 0.1234696 Test Loss: 0.1482420\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0989395\n",
      "\tspeed: 0.3182s/iter; left time: 6098.3201s\n",
      "\titers: 200, epoch: 15 | loss: 0.1011934\n",
      "\tspeed: 0.0821s/iter; left time: 1565.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:21.93s\n",
      "Steps: 224 | Train Loss: 0.1032518 Vali Loss: 0.1219308 Test Loss: 0.1483418\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1068590\n",
      "\tspeed: 0.2983s/iter; left time: 5649.9136s\n",
      "\titers: 200, epoch: 16 | loss: 0.1081710\n",
      "\tspeed: 0.0667s/iter; left time: 1256.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:17.73s\n",
      "Steps: 224 | Train Loss: 0.1028392 Vali Loss: 0.1229158 Test Loss: 0.1500667\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1007148\n",
      "\tspeed: 0.2202s/iter; left time: 4122.3242s\n",
      "\titers: 200, epoch: 17 | loss: 0.1020223\n",
      "\tspeed: 0.0608s/iter; left time: 1132.6131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.85s\n",
      "Steps: 224 | Train Loss: 0.1024451 Vali Loss: 0.1222682 Test Loss: 0.1486770\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1035123\n",
      "\tspeed: 0.2271s/iter; left time: 4199.2190s\n",
      "\titers: 200, epoch: 18 | loss: 0.1021960\n",
      "\tspeed: 0.0655s/iter; left time: 1204.7211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:16.09s\n",
      "Steps: 224 | Train Loss: 0.1023276 Vali Loss: 0.1229518 Test Loss: 0.1491501\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1033197\n",
      "\tspeed: 0.2293s/iter; left time: 4188.6240s\n",
      "\titers: 200, epoch: 19 | loss: 0.1077417\n",
      "\tspeed: 0.0896s/iter; left time: 1627.3379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.79s\n",
      "Steps: 224 | Train Loss: 0.1022994 Vali Loss: 0.1221497 Test Loss: 0.1489767\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0977007\n",
      "\tspeed: 0.3307s/iter; left time: 5966.8420s\n",
      "\titers: 200, epoch: 20 | loss: 0.1003424\n",
      "\tspeed: 0.1091s/iter; left time: 1957.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.1019455 Vali Loss: 0.1224613 Test Loss: 0.1499345\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033141\n",
      "\tspeed: 0.3064s/iter; left time: 5460.2180s\n",
      "\titers: 200, epoch: 21 | loss: 0.0951334\n",
      "\tspeed: 0.0655s/iter; left time: 1161.4873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:16.34s\n",
      "Steps: 224 | Train Loss: 0.1018706 Vali Loss: 0.1225154 Test Loss: 0.1498047\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1002901\n",
      "\tspeed: 0.2018s/iter; left time: 3551.8717s\n",
      "\titers: 200, epoch: 22 | loss: 0.1056146\n",
      "\tspeed: 0.0621s/iter; left time: 1085.9538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:14.27s\n",
      "Steps: 224 | Train Loss: 0.1018136 Vali Loss: 0.1228043 Test Loss: 0.1500367\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1037120\n",
      "\tspeed: 0.2035s/iter; left time: 3534.6647s\n",
      "\titers: 200, epoch: 23 | loss: 0.1074599\n",
      "\tspeed: 0.0601s/iter; left time: 1037.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.1016899 Vali Loss: 0.1222177 Test Loss: 0.1494471\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.046170711517333984, rmse:0.21487371623516083, mae:0.1478378027677536, rse:0.74306321144104\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2751544\n",
      "\tspeed: 0.0942s/iter; left time: 2101.0951s\n",
      "\titers: 200, epoch: 1 | loss: 0.2690022\n",
      "\tspeed: 0.0601s/iter; left time: 1334.4382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.91s\n",
      "Steps: 224 | Train Loss: 0.2880403 Vali Loss: 0.2443856 Test Loss: 0.2635888\n",
      "Validation loss decreased (inf --> 0.244386).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471211\n",
      "\tspeed: 0.2997s/iter; left time: 6615.6465s\n",
      "\titers: 200, epoch: 2 | loss: 0.1257094\n",
      "\tspeed: 0.0893s/iter; left time: 1961.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.45s\n",
      "Steps: 224 | Train Loss: 0.1623488 Vali Loss: 0.1323770 Test Loss: 0.1548301\n",
      "Validation loss decreased (0.244386 --> 0.132377).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156411\n",
      "\tspeed: 0.3138s/iter; left time: 6856.9776s\n",
      "\titers: 200, epoch: 3 | loss: 0.1155942\n",
      "\tspeed: 0.1012s/iter; left time: 2202.0368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:21.94s\n",
      "Steps: 224 | Train Loss: 0.1178669 Vali Loss: 0.1236418 Test Loss: 0.1486955\n",
      "Validation loss decreased (0.132377 --> 0.123642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115227\n",
      "\tspeed: 0.1962s/iter; left time: 4243.3604s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097663\n",
      "\tspeed: 0.0605s/iter; left time: 1301.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.94s\n",
      "Steps: 224 | Train Loss: 0.1110766 Vali Loss: 0.1231859 Test Loss: 0.1460845\n",
      "Validation loss decreased (0.123642 --> 0.123186).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1064800\n",
      "\tspeed: 0.1808s/iter; left time: 3870.5084s\n",
      "\titers: 200, epoch: 5 | loss: 0.1035658\n",
      "\tspeed: 0.0740s/iter; left time: 1576.5757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.05s\n",
      "Steps: 224 | Train Loss: 0.1089646 Vali Loss: 0.1240072 Test Loss: 0.1480751\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1063515\n",
      "\tspeed: 0.1845s/iter; left time: 3908.7830s\n",
      "\titers: 200, epoch: 6 | loss: 0.1103406\n",
      "\tspeed: 0.0590s/iter; left time: 1243.6748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.04s\n",
      "Steps: 224 | Train Loss: 0.1076616 Vali Loss: 0.1230691 Test Loss: 0.1457833\n",
      "Validation loss decreased (0.123186 --> 0.123069).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1019193\n",
      "\tspeed: 0.2065s/iter; left time: 4326.9002s\n",
      "\titers: 200, epoch: 7 | loss: 0.1002145\n",
      "\tspeed: 0.1017s/iter; left time: 2122.1129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.10s\n",
      "Steps: 224 | Train Loss: 0.1072305 Vali Loss: 0.1227324 Test Loss: 0.1465946\n",
      "Validation loss decreased (0.123069 --> 0.122732).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1047203\n",
      "\tspeed: 0.3192s/iter; left time: 6617.9938s\n",
      "\titers: 200, epoch: 8 | loss: 0.1054557\n",
      "\tspeed: 0.1202s/iter; left time: 2479.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:26.34s\n",
      "Steps: 224 | Train Loss: 0.1056827 Vali Loss: 0.1223315 Test Loss: 0.1469460\n",
      "Validation loss decreased (0.122732 --> 0.122332).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1066574\n",
      "\tspeed: 0.4266s/iter; left time: 8749.6327s\n",
      "\titers: 200, epoch: 9 | loss: 0.1028503\n",
      "\tspeed: 0.0600s/iter; left time: 1223.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.05s\n",
      "Steps: 224 | Train Loss: 0.1047605 Vali Loss: 0.1237396 Test Loss: 0.1499159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1034151\n",
      "\tspeed: 0.2063s/iter; left time: 4183.8318s\n",
      "\titers: 200, epoch: 10 | loss: 0.1038620\n",
      "\tspeed: 0.0622s/iter; left time: 1255.4163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.80s\n",
      "Steps: 224 | Train Loss: 0.1044648 Vali Loss: 0.1228130 Test Loss: 0.1473190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1017232\n",
      "\tspeed: 0.1879s/iter; left time: 3768.4609s\n",
      "\titers: 200, epoch: 11 | loss: 0.1019154\n",
      "\tspeed: 0.0727s/iter; left time: 1451.7768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.93s\n",
      "Steps: 224 | Train Loss: 0.1040054 Vali Loss: 0.1216314 Test Loss: 0.1474853\n",
      "Validation loss decreased (0.122332 --> 0.121631).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020506\n",
      "\tspeed: 0.1901s/iter; left time: 3770.7642s\n",
      "\titers: 200, epoch: 12 | loss: 0.1037784\n",
      "\tspeed: 0.0616s/iter; left time: 1215.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.14s\n",
      "Steps: 224 | Train Loss: 0.1035084 Vali Loss: 0.1222913 Test Loss: 0.1485128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1061251\n",
      "\tspeed: 0.1796s/iter; left time: 3521.5960s\n",
      "\titers: 200, epoch: 13 | loss: 0.1065978\n",
      "\tspeed: 0.1081s/iter; left time: 2109.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:20.77s\n",
      "Steps: 224 | Train Loss: 0.1032757 Vali Loss: 0.1229722 Test Loss: 0.1485819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0994283\n",
      "\tspeed: 0.4018s/iter; left time: 7789.9260s\n",
      "\titers: 200, epoch: 14 | loss: 0.1047804\n",
      "\tspeed: 0.0800s/iter; left time: 1543.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:21.42s\n",
      "Steps: 224 | Train Loss: 0.1029077 Vali Loss: 0.1216839 Test Loss: 0.1486514\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1024000\n",
      "\tspeed: 0.2913s/iter; left time: 5583.0224s\n",
      "\titers: 200, epoch: 15 | loss: 0.1030937\n",
      "\tspeed: 0.0827s/iter; left time: 1577.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:21.54s\n",
      "Steps: 224 | Train Loss: 0.1025582 Vali Loss: 0.1223017 Test Loss: 0.1490696\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0989172\n",
      "\tspeed: 0.2044s/iter; left time: 3871.5684s\n",
      "\titers: 200, epoch: 16 | loss: 0.0993790\n",
      "\tspeed: 0.0609s/iter; left time: 1148.0605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:14.74s\n",
      "Steps: 224 | Train Loss: 0.1024495 Vali Loss: 0.1216694 Test Loss: 0.1483023\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0984783\n",
      "\tspeed: 0.1802s/iter; left time: 3372.8909s\n",
      "\titers: 200, epoch: 17 | loss: 0.1007645\n",
      "\tspeed: 0.0590s/iter; left time: 1098.4165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:13.61s\n",
      "Steps: 224 | Train Loss: 0.1021411 Vali Loss: 0.1231461 Test Loss: 0.1493856\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1034188\n",
      "\tspeed: 0.1685s/iter; left time: 3116.8703s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061611\n",
      "\tspeed: 0.0596s/iter; left time: 1096.2874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:13.64s\n",
      "Steps: 224 | Train Loss: 0.1021219 Vali Loss: 0.1220998 Test Loss: 0.1483709\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1036211\n",
      "\tspeed: 0.1679s/iter; left time: 3068.2041s\n",
      "\titers: 200, epoch: 19 | loss: 0.1033579\n",
      "\tspeed: 0.0588s/iter; left time: 1068.9463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:13.45s\n",
      "Steps: 224 | Train Loss: 0.1019313 Vali Loss: 0.1223465 Test Loss: 0.1501660\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1007602\n",
      "\tspeed: 0.1474s/iter; left time: 2659.6100s\n",
      "\titers: 200, epoch: 20 | loss: 0.0987899\n",
      "\tspeed: 0.0598s/iter; left time: 1072.6115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:14.00s\n",
      "Steps: 224 | Train Loss: 0.1019313 Vali Loss: 0.1230411 Test Loss: 0.1515038\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1043691\n",
      "\tspeed: 0.1531s/iter; left time: 2728.1489s\n",
      "\titers: 200, epoch: 21 | loss: 0.0983655\n",
      "\tspeed: 0.0591s/iter; left time: 1046.8257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:13.66s\n",
      "Steps: 224 | Train Loss: 0.1017233 Vali Loss: 0.1221559 Test Loss: 0.1496819\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04573627561330795, rmse:0.2138604074716568, mae:0.14748531579971313, rse:0.7395591139793396\n",
      "Intermediate time for GB and pred_len 96: 00h:23m:58.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2805795\n",
      "\tspeed: 0.0849s/iter; left time: 1885.6805s\n",
      "\titers: 200, epoch: 1 | loss: 0.2665880\n",
      "\tspeed: 0.0614s/iter; left time: 1356.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.00s\n",
      "Steps: 223 | Train Loss: 0.2841599 Vali Loss: 0.2366052 Test Loss: 0.2561878\n",
      "Validation loss decreased (inf --> 0.236605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1437043\n",
      "\tspeed: 0.1577s/iter; left time: 3466.4891s\n",
      "\titers: 200, epoch: 2 | loss: 0.1314376\n",
      "\tspeed: 0.0556s/iter; left time: 1216.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.36s\n",
      "Steps: 223 | Train Loss: 0.1595849 Vali Loss: 0.1343092 Test Loss: 0.1558792\n",
      "Validation loss decreased (0.236605 --> 0.134309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1214988\n",
      "\tspeed: 0.1700s/iter; left time: 3697.9901s\n",
      "\titers: 200, epoch: 3 | loss: 0.1159652\n",
      "\tspeed: 0.0588s/iter; left time: 1274.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.59s\n",
      "Steps: 223 | Train Loss: 0.1207849 Vali Loss: 0.1272497 Test Loss: 0.1550700\n",
      "Validation loss decreased (0.134309 --> 0.127250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1159328\n",
      "\tspeed: 0.1418s/iter; left time: 3053.5483s\n",
      "\titers: 200, epoch: 4 | loss: 0.1211720\n",
      "\tspeed: 0.0612s/iter; left time: 1312.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.03s\n",
      "Steps: 223 | Train Loss: 0.1156752 Vali Loss: 0.1275790 Test Loss: 0.1541177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1087668\n",
      "\tspeed: 0.1580s/iter; left time: 3366.7634s\n",
      "\titers: 200, epoch: 5 | loss: 0.1183135\n",
      "\tspeed: 0.0562s/iter; left time: 1190.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:13.18s\n",
      "Steps: 223 | Train Loss: 0.1133053 Vali Loss: 0.1288943 Test Loss: 0.1578989\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1145881\n",
      "\tspeed: 0.1673s/iter; left time: 3528.1159s\n",
      "\titers: 200, epoch: 6 | loss: 0.1126134\n",
      "\tspeed: 0.0593s/iter; left time: 1244.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.74s\n",
      "Steps: 223 | Train Loss: 0.1121655 Vali Loss: 0.1262892 Test Loss: 0.1520014\n",
      "Validation loss decreased (0.127250 --> 0.126289).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1098545\n",
      "\tspeed: 0.1616s/iter; left time: 3370.9452s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040441\n",
      "\tspeed: 0.0599s/iter; left time: 1244.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.64s\n",
      "Steps: 223 | Train Loss: 0.1106994 Vali Loss: 0.1270565 Test Loss: 0.1523455\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1078050\n",
      "\tspeed: 0.1713s/iter; left time: 3536.6142s\n",
      "\titers: 200, epoch: 8 | loss: 0.1134647\n",
      "\tspeed: 0.0600s/iter; left time: 1233.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.69s\n",
      "Steps: 223 | Train Loss: 0.1100026 Vali Loss: 0.1262635 Test Loss: 0.1524508\n",
      "Validation loss decreased (0.126289 --> 0.126264).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1121218\n",
      "\tspeed: 0.1585s/iter; left time: 3236.1811s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042695\n",
      "\tspeed: 0.0580s/iter; left time: 1178.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.38s\n",
      "Steps: 223 | Train Loss: 0.1092496 Vali Loss: 0.1265422 Test Loss: 0.1536072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061702\n",
      "\tspeed: 0.1732s/iter; left time: 3497.8461s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068518\n",
      "\tspeed: 0.0563s/iter; left time: 1131.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.31s\n",
      "Steps: 223 | Train Loss: 0.1091715 Vali Loss: 0.1272561 Test Loss: 0.1545485\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1064177\n",
      "\tspeed: 0.1674s/iter; left time: 3343.7573s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081345\n",
      "\tspeed: 0.0590s/iter; left time: 1171.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.38s\n",
      "Steps: 223 | Train Loss: 0.1083997 Vali Loss: 0.1283244 Test Loss: 0.1554234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1033464\n",
      "\tspeed: 0.1701s/iter; left time: 3359.9938s\n",
      "\titers: 200, epoch: 12 | loss: 0.1067691\n",
      "\tspeed: 0.0559s/iter; left time: 1097.5961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.11s\n",
      "Steps: 223 | Train Loss: 0.1080228 Vali Loss: 0.1280793 Test Loss: 0.1546156\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1089391\n",
      "\tspeed: 0.1657s/iter; left time: 3234.5999s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101136\n",
      "\tspeed: 0.0599s/iter; left time: 1163.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.87s\n",
      "Steps: 223 | Train Loss: 0.1076153 Vali Loss: 0.1262170 Test Loss: 0.1541574\n",
      "Validation loss decreased (0.126264 --> 0.126217).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1080553\n",
      "\tspeed: 0.1651s/iter; left time: 3186.0856s\n",
      "\titers: 200, epoch: 14 | loss: 0.1076848\n",
      "\tspeed: 0.0611s/iter; left time: 1172.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.68s\n",
      "Steps: 223 | Train Loss: 0.1074516 Vali Loss: 0.1272199 Test Loss: 0.1567310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1082365\n",
      "\tspeed: 0.1709s/iter; left time: 3261.1932s\n",
      "\titers: 200, epoch: 15 | loss: 0.1119653\n",
      "\tspeed: 0.0600s/iter; left time: 1137.9151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.84s\n",
      "Steps: 223 | Train Loss: 0.1071711 Vali Loss: 0.1278471 Test Loss: 0.1553990\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1057544\n",
      "\tspeed: 0.1682s/iter; left time: 3172.3196s\n",
      "\titers: 200, epoch: 16 | loss: 0.1113250\n",
      "\tspeed: 0.0594s/iter; left time: 1113.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.67s\n",
      "Steps: 223 | Train Loss: 0.1068134 Vali Loss: 0.1272139 Test Loss: 0.1558869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1057327\n",
      "\tspeed: 0.1719s/iter; left time: 3203.1942s\n",
      "\titers: 200, epoch: 17 | loss: 0.1119125\n",
      "\tspeed: 0.0580s/iter; left time: 1074.5981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:13.52s\n",
      "Steps: 223 | Train Loss: 0.1066584 Vali Loss: 0.1278494 Test Loss: 0.1559488\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1080534\n",
      "\tspeed: 0.1719s/iter; left time: 3165.4081s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061387\n",
      "\tspeed: 0.0597s/iter; left time: 1093.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:13.76s\n",
      "Steps: 223 | Train Loss: 0.1064652 Vali Loss: 0.1271346 Test Loss: 0.1559392\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1063600\n",
      "\tspeed: 0.1490s/iter; left time: 2709.2162s\n",
      "\titers: 200, epoch: 19 | loss: 0.1053678\n",
      "\tspeed: 0.0583s/iter; left time: 1053.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:13.65s\n",
      "Steps: 223 | Train Loss: 0.1064515 Vali Loss: 0.1278743 Test Loss: 0.1555194\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1093144\n",
      "\tspeed: 0.1677s/iter; left time: 3012.0809s\n",
      "\titers: 200, epoch: 20 | loss: 0.1053254\n",
      "\tspeed: 0.0618s/iter; left time: 1104.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.98s\n",
      "Steps: 223 | Train Loss: 0.1061429 Vali Loss: 0.1276555 Test Loss: 0.1559118\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1056989\n",
      "\tspeed: 0.1685s/iter; left time: 2988.6161s\n",
      "\titers: 200, epoch: 21 | loss: 0.1070963\n",
      "\tspeed: 0.0593s/iter; left time: 1046.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:13.62s\n",
      "Steps: 223 | Train Loss: 0.1060465 Vali Loss: 0.1272785 Test Loss: 0.1558666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1043583\n",
      "\tspeed: 0.1519s/iter; left time: 2660.4587s\n",
      "\titers: 200, epoch: 22 | loss: 0.1117992\n",
      "\tspeed: 0.0588s/iter; left time: 1024.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 223 | Train Loss: 0.1059251 Vali Loss: 0.1277202 Test Loss: 0.1564436\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1069213\n",
      "\tspeed: 0.1528s/iter; left time: 2643.4708s\n",
      "\titers: 200, epoch: 23 | loss: 0.1089702\n",
      "\tspeed: 0.0589s/iter; left time: 1013.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:13.49s\n",
      "Steps: 223 | Train Loss: 0.1058554 Vali Loss: 0.1273729 Test Loss: 0.1572211\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04950212314724922, rmse:0.22249072790145874, mae:0.1541573852300644, rse:0.7714073061943054\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2798281\n",
      "\tspeed: 0.0685s/iter; left time: 1520.2324s\n",
      "\titers: 200, epoch: 1 | loss: 0.2796101\n",
      "\tspeed: 0.0579s/iter; left time: 1279.9032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.03s\n",
      "Steps: 223 | Train Loss: 0.2874158 Vali Loss: 0.2419178 Test Loss: 0.2583910\n",
      "Validation loss decreased (inf --> 0.241918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1470139\n",
      "\tspeed: 0.1576s/iter; left time: 3464.6054s\n",
      "\titers: 200, epoch: 2 | loss: 0.1360404\n",
      "\tspeed: 0.0580s/iter; left time: 1268.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.40s\n",
      "Steps: 223 | Train Loss: 0.1620429 Vali Loss: 0.1324001 Test Loss: 0.1555783\n",
      "Validation loss decreased (0.241918 --> 0.132400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1224503\n",
      "\tspeed: 0.1718s/iter; left time: 3736.6508s\n",
      "\titers: 200, epoch: 3 | loss: 0.1194079\n",
      "\tspeed: 0.0587s/iter; left time: 1270.1073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.65s\n",
      "Steps: 223 | Train Loss: 0.1209563 Vali Loss: 0.1285254 Test Loss: 0.1587481\n",
      "Validation loss decreased (0.132400 --> 0.128525).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1190334\n",
      "\tspeed: 0.1627s/iter; left time: 3503.9184s\n",
      "\titers: 200, epoch: 4 | loss: 0.1133567\n",
      "\tspeed: 0.0560s/iter; left time: 1199.3982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.24s\n",
      "Steps: 223 | Train Loss: 0.1153008 Vali Loss: 0.1266772 Test Loss: 0.1528318\n",
      "Validation loss decreased (0.128525 --> 0.126677).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1166971\n",
      "\tspeed: 0.1708s/iter; left time: 3639.9572s\n",
      "\titers: 200, epoch: 5 | loss: 0.1135501\n",
      "\tspeed: 0.0578s/iter; left time: 1225.6723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:13.40s\n",
      "Steps: 223 | Train Loss: 0.1133565 Vali Loss: 0.1270372 Test Loss: 0.1530850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116466\n",
      "\tspeed: 0.1672s/iter; left time: 3526.5418s\n",
      "\titers: 200, epoch: 6 | loss: 0.1131961\n",
      "\tspeed: 0.0581s/iter; left time: 1219.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.44s\n",
      "Steps: 223 | Train Loss: 0.1120323 Vali Loss: 0.1262882 Test Loss: 0.1512015\n",
      "Validation loss decreased (0.126677 --> 0.126288).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1110709\n",
      "\tspeed: 0.1718s/iter; left time: 3583.3838s\n",
      "\titers: 200, epoch: 7 | loss: 0.1122461\n",
      "\tspeed: 0.0614s/iter; left time: 1275.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.80s\n",
      "Steps: 223 | Train Loss: 0.1107886 Vali Loss: 0.1260154 Test Loss: 0.1505157\n",
      "Validation loss decreased (0.126288 --> 0.126015).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1137041\n",
      "\tspeed: 0.1548s/iter; left time: 3196.0656s\n",
      "\titers: 200, epoch: 8 | loss: 0.1114934\n",
      "\tspeed: 0.0569s/iter; left time: 1168.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.18s\n",
      "Steps: 223 | Train Loss: 0.1101817 Vali Loss: 0.1283005 Test Loss: 0.1520257\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1082447\n",
      "\tspeed: 0.1606s/iter; left time: 3279.4971s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085083\n",
      "\tspeed: 0.0554s/iter; left time: 1126.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.23s\n",
      "Steps: 223 | Train Loss: 0.1093660 Vali Loss: 0.1273274 Test Loss: 0.1535498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1132136\n",
      "\tspeed: 0.1588s/iter; left time: 3207.6975s\n",
      "\titers: 200, epoch: 10 | loss: 0.1100807\n",
      "\tspeed: 0.0587s/iter; left time: 1179.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.31s\n",
      "Steps: 223 | Train Loss: 0.1087154 Vali Loss: 0.1264748 Test Loss: 0.1527026\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1092578\n",
      "\tspeed: 0.1699s/iter; left time: 3393.8324s\n",
      "\titers: 200, epoch: 11 | loss: 0.1136826\n",
      "\tspeed: 0.0583s/iter; left time: 1158.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:14.05s\n",
      "Steps: 223 | Train Loss: 0.1083815 Vali Loss: 0.1259720 Test Loss: 0.1532263\n",
      "Validation loss decreased (0.126015 --> 0.125972).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1047081\n",
      "\tspeed: 0.1624s/iter; left time: 3206.5003s\n",
      "\titers: 200, epoch: 12 | loss: 0.1076780\n",
      "\tspeed: 0.0587s/iter; left time: 1152.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.47s\n",
      "Steps: 223 | Train Loss: 0.1078201 Vali Loss: 0.1269041 Test Loss: 0.1554941\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1085408\n",
      "\tspeed: 0.1379s/iter; left time: 2692.8286s\n",
      "\titers: 200, epoch: 13 | loss: 0.1136421\n",
      "\tspeed: 0.0578s/iter; left time: 1121.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.30s\n",
      "Steps: 223 | Train Loss: 0.1075764 Vali Loss: 0.1262433 Test Loss: 0.1552299\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1109355\n",
      "\tspeed: 0.1441s/iter; left time: 2780.7429s\n",
      "\titers: 200, epoch: 14 | loss: 0.1060089\n",
      "\tspeed: 0.0551s/iter; left time: 1058.6062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.90s\n",
      "Steps: 223 | Train Loss: 0.1072533 Vali Loss: 0.1278901 Test Loss: 0.1560870\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1082978\n",
      "\tspeed: 0.1564s/iter; left time: 2983.1299s\n",
      "\titers: 200, epoch: 15 | loss: 0.1049112\n",
      "\tspeed: 0.0587s/iter; left time: 1113.8211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.76s\n",
      "Steps: 223 | Train Loss: 0.1070636 Vali Loss: 0.1279757 Test Loss: 0.1570617\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1055828\n",
      "\tspeed: 0.1409s/iter; left time: 2657.3262s\n",
      "\titers: 200, epoch: 16 | loss: 0.1024492\n",
      "\tspeed: 0.0575s/iter; left time: 1079.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.07s\n",
      "Steps: 223 | Train Loss: 0.1068914 Vali Loss: 0.1279063 Test Loss: 0.1571817\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1027009\n",
      "\tspeed: 0.1499s/iter; left time: 2792.4229s\n",
      "\titers: 200, epoch: 17 | loss: 0.1086375\n",
      "\tspeed: 0.0528s/iter; left time: 979.2464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.1065439 Vali Loss: 0.1273960 Test Loss: 0.1578892\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1072937\n",
      "\tspeed: 0.1340s/iter; left time: 2467.6887s\n",
      "\titers: 200, epoch: 18 | loss: 0.1089958\n",
      "\tspeed: 0.0556s/iter; left time: 1018.9116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.86s\n",
      "Steps: 223 | Train Loss: 0.1064188 Vali Loss: 0.1278954 Test Loss: 0.1574066\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1050638\n",
      "\tspeed: 0.1598s/iter; left time: 2906.7842s\n",
      "\titers: 200, epoch: 19 | loss: 0.1049717\n",
      "\tspeed: 0.0538s/iter; left time: 972.5369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:13.06s\n",
      "Steps: 223 | Train Loss: 0.1062466 Vali Loss: 0.1284166 Test Loss: 0.1578706\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1094487\n",
      "\tspeed: 0.1204s/iter; left time: 2163.2699s\n",
      "\titers: 200, epoch: 20 | loss: 0.1091652\n",
      "\tspeed: 0.0589s/iter; left time: 1052.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.53s\n",
      "Steps: 223 | Train Loss: 0.1061791 Vali Loss: 0.1281609 Test Loss: 0.1586148\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1061795\n",
      "\tspeed: 0.1071s/iter; left time: 1899.4123s\n",
      "\titers: 200, epoch: 21 | loss: 0.1096702\n",
      "\tspeed: 0.0575s/iter; left time: 1014.4477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 223 | Train Loss: 0.1059624 Vali Loss: 0.1275128 Test Loss: 0.1575601\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.049270931631326675, rmse:0.2219705581665039, mae:0.15322630107402802, rse:0.7696038484573364\n",
      "Intermediate time for GB and pred_len 168: 00h:16m:10.15s\n",
      "Intermediate time for GB: 01h:19m:47.03s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2716131\n",
      "\tspeed: 0.0620s/iter; left time: 1383.3947s\n",
      "\titers: 200, epoch: 1 | loss: 0.2593319\n",
      "\tspeed: 0.0391s/iter; left time: 867.3466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 224 | Train Loss: 0.2778731 Vali Loss: 0.2073302 Test Loss: 0.2330006\n",
      "Validation loss decreased (inf --> 0.207330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1464825\n",
      "\tspeed: 0.0917s/iter; left time: 2025.3139s\n",
      "\titers: 200, epoch: 2 | loss: 0.1116916\n",
      "\tspeed: 0.0403s/iter; left time: 886.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 224 | Train Loss: 0.1571436 Vali Loss: 0.0884075 Test Loss: 0.0956739\n",
      "Validation loss decreased (0.207330 --> 0.088407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0997519\n",
      "\tspeed: 0.0871s/iter; left time: 1903.5526s\n",
      "\titers: 200, epoch: 3 | loss: 0.0955165\n",
      "\tspeed: 0.0422s/iter; left time: 918.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.1000043 Vali Loss: 0.0812965 Test Loss: 0.0899712\n",
      "Validation loss decreased (0.088407 --> 0.081297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0840793\n",
      "\tspeed: 0.0827s/iter; left time: 1788.2187s\n",
      "\titers: 200, epoch: 4 | loss: 0.0856045\n",
      "\tspeed: 0.0376s/iter; left time: 809.2258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0867236 Vali Loss: 0.0711788 Test Loss: 0.0805066\n",
      "Validation loss decreased (0.081297 --> 0.071179).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740249\n",
      "\tspeed: 0.0972s/iter; left time: 2080.6764s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783605\n",
      "\tspeed: 0.0430s/iter; left time: 916.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.23s\n",
      "Steps: 224 | Train Loss: 0.0776597 Vali Loss: 0.0685233 Test Loss: 0.0805469\n",
      "Validation loss decreased (0.071179 --> 0.068523).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0707931\n",
      "\tspeed: 0.0821s/iter; left time: 1739.6779s\n",
      "\titers: 200, epoch: 6 | loss: 0.0718116\n",
      "\tspeed: 0.0350s/iter; left time: 738.3943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0726654 Vali Loss: 0.0661333 Test Loss: 0.0771873\n",
      "Validation loss decreased (0.068523 --> 0.066133).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0774625\n",
      "\tspeed: 0.0936s/iter; left time: 1962.0807s\n",
      "\titers: 200, epoch: 7 | loss: 0.0722932\n",
      "\tspeed: 0.0373s/iter; left time: 777.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.90s\n",
      "Steps: 224 | Train Loss: 0.0704756 Vali Loss: 0.0649412 Test Loss: 0.0773020\n",
      "Validation loss decreased (0.066133 --> 0.064941).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0697776\n",
      "\tspeed: 0.0982s/iter; left time: 2036.4373s\n",
      "\titers: 200, epoch: 8 | loss: 0.0655571\n",
      "\tspeed: 0.0415s/iter; left time: 856.7596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0686286 Vali Loss: 0.0638556 Test Loss: 0.0769916\n",
      "Validation loss decreased (0.064941 --> 0.063856).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0665638\n",
      "\tspeed: 0.0914s/iter; left time: 1875.5252s\n",
      "\titers: 200, epoch: 9 | loss: 0.0648902\n",
      "\tspeed: 0.0407s/iter; left time: 830.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0675502 Vali Loss: 0.0635374 Test Loss: 0.0782119\n",
      "Validation loss decreased (0.063856 --> 0.063537).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682065\n",
      "\tspeed: 0.0917s/iter; left time: 1859.4762s\n",
      "\titers: 200, epoch: 10 | loss: 0.0665417\n",
      "\tspeed: 0.0391s/iter; left time: 789.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0668213 Vali Loss: 0.0628312 Test Loss: 0.0764607\n",
      "Validation loss decreased (0.063537 --> 0.062831).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0680640\n",
      "\tspeed: 0.0975s/iter; left time: 1955.9046s\n",
      "\titers: 200, epoch: 11 | loss: 0.0630656\n",
      "\tspeed: 0.0399s/iter; left time: 797.4271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0660543 Vali Loss: 0.0619433 Test Loss: 0.0762425\n",
      "Validation loss decreased (0.062831 --> 0.061943).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0638028\n",
      "\tspeed: 0.0978s/iter; left time: 1940.1685s\n",
      "\titers: 200, epoch: 12 | loss: 0.0652062\n",
      "\tspeed: 0.0392s/iter; left time: 772.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0650445 Vali Loss: 0.0612709 Test Loss: 0.0755187\n",
      "Validation loss decreased (0.061943 --> 0.061271).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0625371\n",
      "\tspeed: 0.0945s/iter; left time: 1853.4836s\n",
      "\titers: 200, epoch: 13 | loss: 0.0627733\n",
      "\tspeed: 0.0363s/iter; left time: 708.9159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 224 | Train Loss: 0.0645904 Vali Loss: 0.0615720 Test Loss: 0.0754482\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650286\n",
      "\tspeed: 0.0848s/iter; left time: 1644.9258s\n",
      "\titers: 200, epoch: 14 | loss: 0.0635685\n",
      "\tspeed: 0.0462s/iter; left time: 890.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.17s\n",
      "Steps: 224 | Train Loss: 0.0643176 Vali Loss: 0.0610712 Test Loss: 0.0745695\n",
      "Validation loss decreased (0.061271 --> 0.061071).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0648136\n",
      "\tspeed: 0.0905s/iter; left time: 1734.2314s\n",
      "\titers: 200, epoch: 15 | loss: 0.0631165\n",
      "\tspeed: 0.0389s/iter; left time: 742.0290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 224 | Train Loss: 0.0635331 Vali Loss: 0.0606045 Test Loss: 0.0749791\n",
      "Validation loss decreased (0.061071 --> 0.060605).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0590337\n",
      "\tspeed: 0.0887s/iter; left time: 1679.6016s\n",
      "\titers: 200, epoch: 16 | loss: 0.0637494\n",
      "\tspeed: 0.0352s/iter; left time: 662.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 224 | Train Loss: 0.0633014 Vali Loss: 0.0602402 Test Loss: 0.0740316\n",
      "Validation loss decreased (0.060605 --> 0.060240).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0605904\n",
      "\tspeed: 0.0786s/iter; left time: 1471.0012s\n",
      "\titers: 200, epoch: 17 | loss: 0.0624010\n",
      "\tspeed: 0.0415s/iter; left time: 771.7794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 224 | Train Loss: 0.0635225 Vali Loss: 0.0603043 Test Loss: 0.0742424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0593180\n",
      "\tspeed: 0.0895s/iter; left time: 1655.1360s\n",
      "\titers: 200, epoch: 18 | loss: 0.0632965\n",
      "\tspeed: 0.0242s/iter; left time: 445.4323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.0626809 Vali Loss: 0.0599838 Test Loss: 0.0740956\n",
      "Validation loss decreased (0.060240 --> 0.059984).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0612943\n",
      "\tspeed: 0.0816s/iter; left time: 1491.1073s\n",
      "\titers: 200, epoch: 19 | loss: 0.0634427\n",
      "\tspeed: 0.0350s/iter; left time: 636.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 224 | Train Loss: 0.0624049 Vali Loss: 0.0601246 Test Loss: 0.0740726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0614391\n",
      "\tspeed: 0.0861s/iter; left time: 1553.4367s\n",
      "\titers: 200, epoch: 20 | loss: 0.0655361\n",
      "\tspeed: 0.0386s/iter; left time: 692.0164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 224 | Train Loss: 0.0622837 Vali Loss: 0.0598788 Test Loss: 0.0742467\n",
      "Validation loss decreased (0.059984 --> 0.059879).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0737994\n",
      "\tspeed: 0.0778s/iter; left time: 1386.7130s\n",
      "\titers: 200, epoch: 21 | loss: 0.0640391\n",
      "\tspeed: 0.0393s/iter; left time: 695.5571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 224 | Train Loss: 0.0619410 Vali Loss: 0.0596888 Test Loss: 0.0747392\n",
      "Validation loss decreased (0.059879 --> 0.059689).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0621355\n",
      "\tspeed: 0.0939s/iter; left time: 1651.9794s\n",
      "\titers: 200, epoch: 22 | loss: 0.0603194\n",
      "\tspeed: 0.0355s/iter; left time: 621.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 224 | Train Loss: 0.0623530 Vali Loss: 0.0593907 Test Loss: 0.0727883\n",
      "Validation loss decreased (0.059689 --> 0.059391).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0599057\n",
      "\tspeed: 0.0696s/iter; left time: 1208.6553s\n",
      "\titers: 200, epoch: 23 | loss: 0.0608324\n",
      "\tspeed: 0.0389s/iter; left time: 671.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0618754 Vali Loss: 0.0594392 Test Loss: 0.0731889\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0604659\n",
      "\tspeed: 0.0706s/iter; left time: 1210.1898s\n",
      "\titers: 200, epoch: 24 | loss: 0.0639650\n",
      "\tspeed: 0.0339s/iter; left time: 577.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0616088 Vali Loss: 0.0591857 Test Loss: 0.0736739\n",
      "Validation loss decreased (0.059391 --> 0.059186).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0660595\n",
      "\tspeed: 0.0760s/iter; left time: 1285.8850s\n",
      "\titers: 200, epoch: 25 | loss: 0.0597431\n",
      "\tspeed: 0.0265s/iter; left time: 446.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0615581 Vali Loss: 0.0593212 Test Loss: 0.0740524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0617152\n",
      "\tspeed: 0.0735s/iter; left time: 1228.1243s\n",
      "\titers: 200, epoch: 26 | loss: 0.0594254\n",
      "\tspeed: 0.0368s/iter; left time: 610.8378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 224 | Train Loss: 0.0615665 Vali Loss: 0.0591473 Test Loss: 0.0734034\n",
      "Validation loss decreased (0.059186 --> 0.059147).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0603081\n",
      "\tspeed: 0.0733s/iter; left time: 1208.1742s\n",
      "\titers: 200, epoch: 27 | loss: 0.0647205\n",
      "\tspeed: 0.0368s/iter; left time: 602.9465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0614026 Vali Loss: 0.0591085 Test Loss: 0.0735312\n",
      "Validation loss decreased (0.059147 --> 0.059109).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0578692\n",
      "\tspeed: 0.0729s/iter; left time: 1185.1252s\n",
      "\titers: 200, epoch: 28 | loss: 0.0589528\n",
      "\tspeed: 0.0384s/iter; left time: 620.8163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 224 | Train Loss: 0.0612589 Vali Loss: 0.0589551 Test Loss: 0.0731288\n",
      "Validation loss decreased (0.059109 --> 0.058955).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0601848\n",
      "\tspeed: 0.0752s/iter; left time: 1205.6722s\n",
      "\titers: 200, epoch: 29 | loss: 0.0609453\n",
      "\tspeed: 0.0392s/iter; left time: 624.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0614763 Vali Loss: 0.0590970 Test Loss: 0.0733710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0587087\n",
      "\tspeed: 0.0745s/iter; left time: 1177.9392s\n",
      "\titers: 200, epoch: 30 | loss: 0.0610784\n",
      "\tspeed: 0.0302s/iter; left time: 473.7506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0610941 Vali Loss: 0.0589220 Test Loss: 0.0737904\n",
      "Validation loss decreased (0.058955 --> 0.058922).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0618162\n",
      "\tspeed: 0.0837s/iter; left time: 1304.7752s\n",
      "\titers: 200, epoch: 31 | loss: 0.0635032\n",
      "\tspeed: 0.0337s/iter; left time: 521.7064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 224 | Train Loss: 0.0614045 Vali Loss: 0.0595656 Test Loss: 0.0737262\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0616083\n",
      "\tspeed: 0.0818s/iter; left time: 1256.1973s\n",
      "\titers: 200, epoch: 32 | loss: 0.0572779\n",
      "\tspeed: 0.0290s/iter; left time: 442.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0610035 Vali Loss: 0.0588141 Test Loss: 0.0732145\n",
      "Validation loss decreased (0.058922 --> 0.058814).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0620334\n",
      "\tspeed: 0.0694s/iter; left time: 1049.9153s\n",
      "\titers: 200, epoch: 33 | loss: 0.0603480\n",
      "\tspeed: 0.0357s/iter; left time: 536.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0609497 Vali Loss: 0.0586152 Test Loss: 0.0732236\n",
      "Validation loss decreased (0.058814 --> 0.058615).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0654920\n",
      "\tspeed: 0.0833s/iter; left time: 1241.2000s\n",
      "\titers: 200, epoch: 34 | loss: 0.0584530\n",
      "\tspeed: 0.0329s/iter; left time: 486.9258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.0609431 Vali Loss: 0.0586743 Test Loss: 0.0730879\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0600631\n",
      "\tspeed: 0.0670s/iter; left time: 984.3613s\n",
      "\titers: 200, epoch: 35 | loss: 0.0608742\n",
      "\tspeed: 0.0353s/iter; left time: 514.2754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0609527 Vali Loss: 0.0587862 Test Loss: 0.0733456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0629283\n",
      "\tspeed: 0.0846s/iter; left time: 1223.3680s\n",
      "\titers: 200, epoch: 36 | loss: 0.0615985\n",
      "\tspeed: 0.0253s/iter; left time: 363.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 224 | Train Loss: 0.0608360 Vali Loss: 0.0586137 Test Loss: 0.0733216\n",
      "Validation loss decreased (0.058615 --> 0.058614).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0615572\n",
      "\tspeed: 0.0742s/iter; left time: 1055.9211s\n",
      "\titers: 200, epoch: 37 | loss: 0.0602170\n",
      "\tspeed: 0.0370s/iter; left time: 523.4378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0607253 Vali Loss: 0.0586815 Test Loss: 0.0732841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0578529\n",
      "\tspeed: 0.0791s/iter; left time: 1108.4269s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618689\n",
      "\tspeed: 0.0283s/iter; left time: 393.2660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0608215 Vali Loss: 0.0586132 Test Loss: 0.0734925\n",
      "Validation loss decreased (0.058614 --> 0.058613).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0601412\n",
      "\tspeed: 0.0563s/iter; left time: 776.3001s\n",
      "\titers: 200, epoch: 39 | loss: 0.0578164\n",
      "\tspeed: 0.0357s/iter; left time: 488.4868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0605890 Vali Loss: 0.0586529 Test Loss: 0.0735201\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0572843\n",
      "\tspeed: 0.0871s/iter; left time: 1181.4842s\n",
      "\titers: 200, epoch: 40 | loss: 0.0614513\n",
      "\tspeed: 0.0296s/iter; left time: 398.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0606020 Vali Loss: 0.0585021 Test Loss: 0.0733150\n",
      "Validation loss decreased (0.058613 --> 0.058502).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0591269\n",
      "\tspeed: 0.0710s/iter; left time: 947.3505s\n",
      "\titers: 200, epoch: 41 | loss: 0.0607502\n",
      "\tspeed: 0.0395s/iter; left time: 522.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0606079 Vali Loss: 0.0586638 Test Loss: 0.0733574\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0627736\n",
      "\tspeed: 0.0682s/iter; left time: 894.4352s\n",
      "\titers: 200, epoch: 42 | loss: 0.0601050\n",
      "\tspeed: 0.0368s/iter; left time: 479.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0605499 Vali Loss: 0.0586009 Test Loss: 0.0735421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0562877\n",
      "\tspeed: 0.0699s/iter; left time: 901.3944s\n",
      "\titers: 200, epoch: 43 | loss: 0.0592064\n",
      "\tspeed: 0.0338s/iter; left time: 432.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0607410 Vali Loss: 0.0587485 Test Loss: 0.0736325\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0617348\n",
      "\tspeed: 0.0743s/iter; left time: 941.2455s\n",
      "\titers: 200, epoch: 44 | loss: 0.0614126\n",
      "\tspeed: 0.0228s/iter; left time: 287.0035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 224 | Train Loss: 0.0606123 Vali Loss: 0.0585737 Test Loss: 0.0734087\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0604446\n",
      "\tspeed: 0.0831s/iter; left time: 1034.3857s\n",
      "\titers: 200, epoch: 45 | loss: 0.0666469\n",
      "\tspeed: 0.0344s/iter; left time: 424.2265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0605810 Vali Loss: 0.0584803 Test Loss: 0.0734012\n",
      "Validation loss decreased (0.058502 --> 0.058480).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0582605\n",
      "\tspeed: 0.0660s/iter; left time: 806.1261s\n",
      "\titers: 200, epoch: 46 | loss: 0.0636819\n",
      "\tspeed: 0.0245s/iter; left time: 296.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0605376 Vali Loss: 0.0584897 Test Loss: 0.0730279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0617488\n",
      "\tspeed: 0.0779s/iter; left time: 934.4499s\n",
      "\titers: 200, epoch: 47 | loss: 0.0661087\n",
      "\tspeed: 0.0372s/iter; left time: 443.1035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 224 | Train Loss: 0.0605746 Vali Loss: 0.0586828 Test Loss: 0.0737944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0613210\n",
      "\tspeed: 0.0762s/iter; left time: 897.5516s\n",
      "\titers: 200, epoch: 48 | loss: 0.0577578\n",
      "\tspeed: 0.0254s/iter; left time: 296.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 224 | Train Loss: 0.0606481 Vali Loss: 0.0584786 Test Loss: 0.0732720\n",
      "Validation loss decreased (0.058480 --> 0.058479).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0596579\n",
      "\tspeed: 0.0717s/iter; left time: 828.3484s\n",
      "\titers: 200, epoch: 49 | loss: 0.0626817\n",
      "\tspeed: 0.0383s/iter; left time: 438.9985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 224 | Train Loss: 0.0605355 Vali Loss: 0.0583748 Test Loss: 0.0731672\n",
      "Validation loss decreased (0.058479 --> 0.058375).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0622368\n",
      "\tspeed: 0.0666s/iter; left time: 754.4371s\n",
      "\titers: 200, epoch: 50 | loss: 0.0606601\n",
      "\tspeed: 0.0258s/iter; left time: 289.6600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0604692 Vali Loss: 0.0586458 Test Loss: 0.0736936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0577491\n",
      "\tspeed: 0.0610s/iter; left time: 676.9807s\n",
      "\titers: 200, epoch: 51 | loss: 0.0616590\n",
      "\tspeed: 0.0350s/iter; left time: 385.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0607899 Vali Loss: 0.0584731 Test Loss: 0.0731942\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0627529\n",
      "\tspeed: 0.0751s/iter; left time: 816.6876s\n",
      "\titers: 200, epoch: 52 | loss: 0.0618755\n",
      "\tspeed: 0.0307s/iter; left time: 331.0471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0604956 Vali Loss: 0.0586692 Test Loss: 0.0737382\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0614029\n",
      "\tspeed: 0.0553s/iter; left time: 589.1858s\n",
      "\titers: 200, epoch: 53 | loss: 0.0634207\n",
      "\tspeed: 0.0347s/iter; left time: 366.5371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0604386 Vali Loss: 0.0585684 Test Loss: 0.0734891\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0619802\n",
      "\tspeed: 0.0707s/iter; left time: 737.7474s\n",
      "\titers: 200, epoch: 54 | loss: 0.0586568\n",
      "\tspeed: 0.0297s/iter; left time: 307.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0604947 Vali Loss: 0.0586781 Test Loss: 0.0738493\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0597096\n",
      "\tspeed: 0.0553s/iter; left time: 563.8997s\n",
      "\titers: 200, epoch: 55 | loss: 0.0618582\n",
      "\tspeed: 0.0256s/iter; left time: 258.3619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 224 | Train Loss: 0.0606621 Vali Loss: 0.0585085 Test Loss: 0.0733606\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0586016\n",
      "\tspeed: 0.0746s/iter; left time: 744.5528s\n",
      "\titers: 200, epoch: 56 | loss: 0.0651014\n",
      "\tspeed: 0.0333s/iter; left time: 329.0567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0605923 Vali Loss: 0.0586657 Test Loss: 0.0734124\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0601418\n",
      "\tspeed: 0.0625s/iter; left time: 610.0345s\n",
      "\titers: 200, epoch: 57 | loss: 0.0607323\n",
      "\tspeed: 0.0314s/iter; left time: 303.5014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0605401 Vali Loss: 0.0586670 Test Loss: 0.0736131\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0585449\n",
      "\tspeed: 0.0747s/iter; left time: 712.1006s\n",
      "\titers: 200, epoch: 58 | loss: 0.0581753\n",
      "\tspeed: 0.0363s/iter; left time: 342.1683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0603512 Vali Loss: 0.0585405 Test Loss: 0.0733575\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0599505\n",
      "\tspeed: 0.0640s/iter; left time: 595.9604s\n",
      "\titers: 200, epoch: 59 | loss: 0.0574748\n",
      "\tspeed: 0.0280s/iter; left time: 257.9884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0603631 Vali Loss: 0.0584929 Test Loss: 0.0734470\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012924049980938435, rmse:0.11368399113416672, mae:0.07316716760396957, rse:0.33455824851989746\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2877905\n",
      "\tspeed: 0.0373s/iter; left time: 831.3403s\n",
      "\titers: 200, epoch: 1 | loss: 0.2638871\n",
      "\tspeed: 0.0305s/iter; left time: 676.7040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.2862083 Vali Loss: 0.2111465 Test Loss: 0.2343626\n",
      "Validation loss decreased (inf --> 0.211147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1492624\n",
      "\tspeed: 0.0638s/iter; left time: 1407.5522s\n",
      "\titers: 200, epoch: 2 | loss: 0.1152855\n",
      "\tspeed: 0.0297s/iter; left time: 651.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.1596880 Vali Loss: 0.0918335 Test Loss: 0.0994620\n",
      "Validation loss decreased (0.211147 --> 0.091833).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1029339\n",
      "\tspeed: 0.0545s/iter; left time: 1191.4308s\n",
      "\titers: 200, epoch: 3 | loss: 0.0945148\n",
      "\tspeed: 0.0297s/iter; left time: 646.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 224 | Train Loss: 0.0993995 Vali Loss: 0.0775245 Test Loss: 0.0858982\n",
      "Validation loss decreased (0.091833 --> 0.077524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0870824\n",
      "\tspeed: 0.0561s/iter; left time: 1213.9102s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815023\n",
      "\tspeed: 0.0264s/iter; left time: 568.1189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0860380 Vali Loss: 0.0716859 Test Loss: 0.0803887\n",
      "Validation loss decreased (0.077524 --> 0.071686).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0764270\n",
      "\tspeed: 0.0563s/iter; left time: 1204.8606s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755505\n",
      "\tspeed: 0.0265s/iter; left time: 564.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0773875 Vali Loss: 0.0691720 Test Loss: 0.0884821\n",
      "Validation loss decreased (0.071686 --> 0.069172).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737963\n",
      "\tspeed: 0.0645s/iter; left time: 1367.0448s\n",
      "\titers: 200, epoch: 6 | loss: 0.0713646\n",
      "\tspeed: 0.0243s/iter; left time: 511.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0728628 Vali Loss: 0.0663896 Test Loss: 0.0809351\n",
      "Validation loss decreased (0.069172 --> 0.066390).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0698943\n",
      "\tspeed: 0.0598s/iter; left time: 1254.2241s\n",
      "\titers: 200, epoch: 7 | loss: 0.0737890\n",
      "\tspeed: 0.0333s/iter; left time: 694.4965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0706566 Vali Loss: 0.0645864 Test Loss: 0.0816118\n",
      "Validation loss decreased (0.066390 --> 0.064586).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0694184\n",
      "\tspeed: 0.0605s/iter; left time: 1254.3143s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706043\n",
      "\tspeed: 0.0228s/iter; left time: 471.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0689727 Vali Loss: 0.0638241 Test Loss: 0.0809232\n",
      "Validation loss decreased (0.064586 --> 0.063824).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0660098\n",
      "\tspeed: 0.0613s/iter; left time: 1256.9677s\n",
      "\titers: 200, epoch: 9 | loss: 0.0670574\n",
      "\tspeed: 0.0297s/iter; left time: 606.6604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0678072 Vali Loss: 0.0630422 Test Loss: 0.0805838\n",
      "Validation loss decreased (0.063824 --> 0.063042).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0685804\n",
      "\tspeed: 0.0573s/iter; left time: 1163.1480s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675971\n",
      "\tspeed: 0.0235s/iter; left time: 474.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0666880 Vali Loss: 0.0623324 Test Loss: 0.0792666\n",
      "Validation loss decreased (0.063042 --> 0.062332).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0727281\n",
      "\tspeed: 0.0553s/iter; left time: 1109.0684s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697532\n",
      "\tspeed: 0.0258s/iter; left time: 515.6125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0664021 Vali Loss: 0.0620938 Test Loss: 0.0790071\n",
      "Validation loss decreased (0.062332 --> 0.062094).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0692039\n",
      "\tspeed: 0.0541s/iter; left time: 1073.1026s\n",
      "\titers: 200, epoch: 12 | loss: 0.0633237\n",
      "\tspeed: 0.0251s/iter; left time: 495.6565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0654965 Vali Loss: 0.0614724 Test Loss: 0.0783267\n",
      "Validation loss decreased (0.062094 --> 0.061472).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0663230\n",
      "\tspeed: 0.0621s/iter; left time: 1218.6507s\n",
      "\titers: 200, epoch: 13 | loss: 0.0644192\n",
      "\tspeed: 0.0242s/iter; left time: 472.6835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0647666 Vali Loss: 0.0608936 Test Loss: 0.0760295\n",
      "Validation loss decreased (0.061472 --> 0.060894).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0687837\n",
      "\tspeed: 0.0548s/iter; left time: 1062.3141s\n",
      "\titers: 200, epoch: 14 | loss: 0.0678449\n",
      "\tspeed: 0.0238s/iter; left time: 459.9092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0643334 Vali Loss: 0.0602578 Test Loss: 0.0752936\n",
      "Validation loss decreased (0.060894 --> 0.060258).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0623422\n",
      "\tspeed: 0.0674s/iter; left time: 1291.4343s\n",
      "\titers: 200, epoch: 15 | loss: 0.0661111\n",
      "\tspeed: 0.0237s/iter; left time: 451.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0640402 Vali Loss: 0.0605470 Test Loss: 0.0750898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0681814\n",
      "\tspeed: 0.0489s/iter; left time: 926.0799s\n",
      "\titers: 200, epoch: 16 | loss: 0.0622716\n",
      "\tspeed: 0.0267s/iter; left time: 503.5467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0641407 Vali Loss: 0.0607534 Test Loss: 0.0760613\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0632059\n",
      "\tspeed: 0.0599s/iter; left time: 1121.6365s\n",
      "\titers: 200, epoch: 17 | loss: 0.0677324\n",
      "\tspeed: 0.0289s/iter; left time: 538.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0633371 Vali Loss: 0.0607128 Test Loss: 0.0756752\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0676642\n",
      "\tspeed: 0.0636s/iter; left time: 1175.3280s\n",
      "\titers: 200, epoch: 18 | loss: 0.0611327\n",
      "\tspeed: 0.0257s/iter; left time: 472.7043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0631575 Vali Loss: 0.0593235 Test Loss: 0.0744360\n",
      "Validation loss decreased (0.060258 --> 0.059323).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0636197\n",
      "\tspeed: 0.0486s/iter; left time: 888.4544s\n",
      "\titers: 200, epoch: 19 | loss: 0.0633235\n",
      "\tspeed: 0.0303s/iter; left time: 549.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0627403 Vali Loss: 0.0594330 Test Loss: 0.0742841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0635506\n",
      "\tspeed: 0.0592s/iter; left time: 1068.4226s\n",
      "\titers: 200, epoch: 20 | loss: 0.0622648\n",
      "\tspeed: 0.0221s/iter; left time: 396.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0625273 Vali Loss: 0.0590419 Test Loss: 0.0737318\n",
      "Validation loss decreased (0.059323 --> 0.059042).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0619661\n",
      "\tspeed: 0.0685s/iter; left time: 1221.0642s\n",
      "\titers: 200, epoch: 21 | loss: 0.0584053\n",
      "\tspeed: 0.0336s/iter; left time: 594.6205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0626985 Vali Loss: 0.0592678 Test Loss: 0.0749659\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0646252\n",
      "\tspeed: 0.0499s/iter; left time: 878.0924s\n",
      "\titers: 200, epoch: 22 | loss: 0.0588910\n",
      "\tspeed: 0.0304s/iter; left time: 531.2168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0619731 Vali Loss: 0.0590993 Test Loss: 0.0746543\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0636457\n",
      "\tspeed: 0.0583s/iter; left time: 1012.0700s\n",
      "\titers: 200, epoch: 23 | loss: 0.0639213\n",
      "\tspeed: 0.0262s/iter; left time: 452.7072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 224 | Train Loss: 0.0618764 Vali Loss: 0.0595535 Test Loss: 0.0753576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0565846\n",
      "\tspeed: 0.0541s/iter; left time: 927.5493s\n",
      "\titers: 200, epoch: 24 | loss: 0.0620618\n",
      "\tspeed: 0.0249s/iter; left time: 425.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0620649 Vali Loss: 0.0586336 Test Loss: 0.0746801\n",
      "Validation loss decreased (0.059042 --> 0.058634).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0639940\n",
      "\tspeed: 0.0610s/iter; left time: 1031.9849s\n",
      "\titers: 200, epoch: 25 | loss: 0.0591630\n",
      "\tspeed: 0.0275s/iter; left time: 462.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0618124 Vali Loss: 0.0591847 Test Loss: 0.0742414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0596955\n",
      "\tspeed: 0.0680s/iter; left time: 1136.2434s\n",
      "\titers: 200, epoch: 26 | loss: 0.0613243\n",
      "\tspeed: 0.0220s/iter; left time: 365.0552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 224 | Train Loss: 0.0616533 Vali Loss: 0.0583399 Test Loss: 0.0742313\n",
      "Validation loss decreased (0.058634 --> 0.058340).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0597679\n",
      "\tspeed: 0.0697s/iter; left time: 1148.5683s\n",
      "\titers: 200, epoch: 27 | loss: 0.0643352\n",
      "\tspeed: 0.0231s/iter; left time: 378.2617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0615879 Vali Loss: 0.0587037 Test Loss: 0.0734117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0602489\n",
      "\tspeed: 0.0462s/iter; left time: 750.4977s\n",
      "\titers: 200, epoch: 28 | loss: 0.0589547\n",
      "\tspeed: 0.0233s/iter; left time: 376.5196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0613679 Vali Loss: 0.0587699 Test Loss: 0.0742184\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0589752\n",
      "\tspeed: 0.0798s/iter; left time: 1278.5915s\n",
      "\titers: 200, epoch: 29 | loss: 0.0617351\n",
      "\tspeed: 0.0246s/iter; left time: 391.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0612729 Vali Loss: 0.0584835 Test Loss: 0.0732371\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0629638\n",
      "\tspeed: 0.0471s/iter; left time: 743.7526s\n",
      "\titers: 200, epoch: 30 | loss: 0.0575505\n",
      "\tspeed: 0.0227s/iter; left time: 357.1753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0615552 Vali Loss: 0.0583954 Test Loss: 0.0737525\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0595907\n",
      "\tspeed: 0.0735s/iter; left time: 1144.9477s\n",
      "\titers: 200, epoch: 31 | loss: 0.0623036\n",
      "\tspeed: 0.0254s/iter; left time: 393.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0611098 Vali Loss: 0.0583293 Test Loss: 0.0739518\n",
      "Validation loss decreased (0.058340 --> 0.058329).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0654049\n",
      "\tspeed: 0.0634s/iter; left time: 973.5009s\n",
      "\titers: 200, epoch: 32 | loss: 0.0628865\n",
      "\tspeed: 0.0239s/iter; left time: 365.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0612368 Vali Loss: 0.0582500 Test Loss: 0.0737642\n",
      "Validation loss decreased (0.058329 --> 0.058250).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0642568\n",
      "\tspeed: 0.0516s/iter; left time: 780.9929s\n",
      "\titers: 200, epoch: 33 | loss: 0.0604563\n",
      "\tspeed: 0.0368s/iter; left time: 552.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0608660 Vali Loss: 0.0581025 Test Loss: 0.0734115\n",
      "Validation loss decreased (0.058250 --> 0.058103).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0618693\n",
      "\tspeed: 0.0556s/iter; left time: 828.4284s\n",
      "\titers: 200, epoch: 34 | loss: 0.0602822\n",
      "\tspeed: 0.0223s/iter; left time: 329.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0609611 Vali Loss: 0.0583429 Test Loss: 0.0734754\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0639292\n",
      "\tspeed: 0.0628s/iter; left time: 921.9673s\n",
      "\titers: 200, epoch: 35 | loss: 0.0599125\n",
      "\tspeed: 0.0307s/iter; left time: 447.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0610319 Vali Loss: 0.0584516 Test Loss: 0.0738476\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0604735\n",
      "\tspeed: 0.0501s/iter; left time: 723.9196s\n",
      "\titers: 200, epoch: 36 | loss: 0.0553955\n",
      "\tspeed: 0.0245s/iter; left time: 351.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0609390 Vali Loss: 0.0583936 Test Loss: 0.0738283\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0568553\n",
      "\tspeed: 0.0560s/iter; left time: 797.2746s\n",
      "\titers: 200, epoch: 37 | loss: 0.0597522\n",
      "\tspeed: 0.0235s/iter; left time: 331.6437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 224 | Train Loss: 0.0606664 Vali Loss: 0.0581718 Test Loss: 0.0734708\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0581451\n",
      "\tspeed: 0.0652s/iter; left time: 913.0194s\n",
      "\titers: 200, epoch: 38 | loss: 0.0630017\n",
      "\tspeed: 0.0343s/iter; left time: 476.5427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0608828 Vali Loss: 0.0580958 Test Loss: 0.0737848\n",
      "Validation loss decreased (0.058103 --> 0.058096).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0586447\n",
      "\tspeed: 0.0483s/iter; left time: 666.1527s\n",
      "\titers: 200, epoch: 39 | loss: 0.0649154\n",
      "\tspeed: 0.0223s/iter; left time: 305.5510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0607158 Vali Loss: 0.0581686 Test Loss: 0.0743360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0599744\n",
      "\tspeed: 0.0580s/iter; left time: 786.7101s\n",
      "\titers: 200, epoch: 40 | loss: 0.0576915\n",
      "\tspeed: 0.0330s/iter; left time: 444.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 224 | Train Loss: 0.0608292 Vali Loss: 0.0581034 Test Loss: 0.0736245\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0619106\n",
      "\tspeed: 0.0517s/iter; left time: 689.9634s\n",
      "\titers: 200, epoch: 41 | loss: 0.0563842\n",
      "\tspeed: 0.0220s/iter; left time: 291.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0607239 Vali Loss: 0.0581008 Test Loss: 0.0740254\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0621693\n",
      "\tspeed: 0.0588s/iter; left time: 771.4744s\n",
      "\titers: 200, epoch: 42 | loss: 0.0602721\n",
      "\tspeed: 0.0232s/iter; left time: 301.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0607545 Vali Loss: 0.0581054 Test Loss: 0.0736836\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0579938\n",
      "\tspeed: 0.0486s/iter; left time: 626.5627s\n",
      "\titers: 200, epoch: 43 | loss: 0.0627912\n",
      "\tspeed: 0.0244s/iter; left time: 311.9865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0606253 Vali Loss: 0.0581325 Test Loss: 0.0736885\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0614558\n",
      "\tspeed: 0.0624s/iter; left time: 789.9374s\n",
      "\titers: 200, epoch: 44 | loss: 0.0582512\n",
      "\tspeed: 0.0218s/iter; left time: 274.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0605794 Vali Loss: 0.0581799 Test Loss: 0.0736219\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0598212\n",
      "\tspeed: 0.0512s/iter; left time: 637.2990s\n",
      "\titers: 200, epoch: 45 | loss: 0.0593993\n",
      "\tspeed: 0.0308s/iter; left time: 380.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0606073 Vali Loss: 0.0579255 Test Loss: 0.0731540\n",
      "Validation loss decreased (0.058096 --> 0.057925).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0618426\n",
      "\tspeed: 0.0527s/iter; left time: 643.5973s\n",
      "\titers: 200, epoch: 46 | loss: 0.0592247\n",
      "\tspeed: 0.0283s/iter; left time: 343.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0605780 Vali Loss: 0.0582018 Test Loss: 0.0738711\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0604415\n",
      "\tspeed: 0.0539s/iter; left time: 646.9506s\n",
      "\titers: 200, epoch: 47 | loss: 0.0577849\n",
      "\tspeed: 0.0238s/iter; left time: 282.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0606646 Vali Loss: 0.0580042 Test Loss: 0.0732950\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0578090\n",
      "\tspeed: 0.0521s/iter; left time: 612.9044s\n",
      "\titers: 200, epoch: 48 | loss: 0.0599391\n",
      "\tspeed: 0.0285s/iter; left time: 333.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0606206 Vali Loss: 0.0579175 Test Loss: 0.0728856\n",
      "Validation loss decreased (0.057925 --> 0.057918).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0617991\n",
      "\tspeed: 0.0659s/iter; left time: 761.1362s\n",
      "\titers: 200, epoch: 49 | loss: 0.0634511\n",
      "\tspeed: 0.0293s/iter; left time: 335.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0606752 Vali Loss: 0.0579695 Test Loss: 0.0735182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0605634\n",
      "\tspeed: 0.0667s/iter; left time: 755.3805s\n",
      "\titers: 200, epoch: 50 | loss: 0.0630069\n",
      "\tspeed: 0.0306s/iter; left time: 343.6580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0607077 Vali Loss: 0.0578800 Test Loss: 0.0732009\n",
      "Validation loss decreased (0.057918 --> 0.057880).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0638899\n",
      "\tspeed: 0.0516s/iter; left time: 573.1161s\n",
      "\titers: 200, epoch: 51 | loss: 0.0582444\n",
      "\tspeed: 0.0262s/iter; left time: 288.4492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0605479 Vali Loss: 0.0580509 Test Loss: 0.0732340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0588226\n",
      "\tspeed: 0.0478s/iter; left time: 519.9598s\n",
      "\titers: 200, epoch: 52 | loss: 0.0580830\n",
      "\tspeed: 0.0234s/iter; left time: 252.6863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0608150 Vali Loss: 0.0580036 Test Loss: 0.0732753\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0612364\n",
      "\tspeed: 0.0732s/iter; left time: 779.3471s\n",
      "\titers: 200, epoch: 53 | loss: 0.0602664\n",
      "\tspeed: 0.0228s/iter; left time: 240.6802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0605894 Vali Loss: 0.0578158 Test Loss: 0.0733499\n",
      "Validation loss decreased (0.057880 --> 0.057816).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0612249\n",
      "\tspeed: 0.0497s/iter; left time: 518.3190s\n",
      "\titers: 200, epoch: 54 | loss: 0.0626555\n",
      "\tspeed: 0.0226s/iter; left time: 233.5561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0606305 Vali Loss: 0.0579054 Test Loss: 0.0728906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0623724\n",
      "\tspeed: 0.0559s/iter; left time: 570.5075s\n",
      "\titers: 200, epoch: 55 | loss: 0.0563497\n",
      "\tspeed: 0.0306s/iter; left time: 308.9545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0605508 Vali Loss: 0.0579716 Test Loss: 0.0731202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0620142\n",
      "\tspeed: 0.0686s/iter; left time: 684.2417s\n",
      "\titers: 200, epoch: 56 | loss: 0.0586572\n",
      "\tspeed: 0.0231s/iter; left time: 228.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0606216 Vali Loss: 0.0579800 Test Loss: 0.0732933\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0613465\n",
      "\tspeed: 0.0533s/iter; left time: 519.7709s\n",
      "\titers: 200, epoch: 57 | loss: 0.0593647\n",
      "\tspeed: 0.0265s/iter; left time: 255.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0609250 Vali Loss: 0.0579943 Test Loss: 0.0732995\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0602495\n",
      "\tspeed: 0.0645s/iter; left time: 614.8183s\n",
      "\titers: 200, epoch: 58 | loss: 0.0588583\n",
      "\tspeed: 0.0243s/iter; left time: 229.4753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0604744 Vali Loss: 0.0580824 Test Loss: 0.0733517\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0596012\n",
      "\tspeed: 0.0504s/iter; left time: 469.2024s\n",
      "\titers: 200, epoch: 59 | loss: 0.0629138\n",
      "\tspeed: 0.0239s/iter; left time: 220.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0604661 Vali Loss: 0.0578026 Test Loss: 0.0728349\n",
      "Validation loss decreased (0.057816 --> 0.057803).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0583539\n",
      "\tspeed: 0.0668s/iter; left time: 607.2010s\n",
      "\titers: 200, epoch: 60 | loss: 0.0633144\n",
      "\tspeed: 0.0229s/iter; left time: 206.1757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0605610 Vali Loss: 0.0577595 Test Loss: 0.0730932\n",
      "Validation loss decreased (0.057803 --> 0.057759).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0619486\n",
      "\tspeed: 0.0636s/iter; left time: 563.2169s\n",
      "\titers: 200, epoch: 61 | loss: 0.0600652\n",
      "\tspeed: 0.0231s/iter; left time: 202.2844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 224 | Train Loss: 0.0605581 Vali Loss: 0.0580633 Test Loss: 0.0733728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0612883\n",
      "\tspeed: 0.0467s/iter; left time: 403.1129s\n",
      "\titers: 200, epoch: 62 | loss: 0.0598977\n",
      "\tspeed: 0.0291s/iter; left time: 248.8356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0605784 Vali Loss: 0.0578533 Test Loss: 0.0728168\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0592462\n",
      "\tspeed: 0.0572s/iter; left time: 481.2805s\n",
      "\titers: 200, epoch: 63 | loss: 0.0612592\n",
      "\tspeed: 0.0224s/iter; left time: 185.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0606407 Vali Loss: 0.0581431 Test Loss: 0.0736098\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0592890\n",
      "\tspeed: 0.0528s/iter; left time: 432.2228s\n",
      "\titers: 200, epoch: 64 | loss: 0.0557728\n",
      "\tspeed: 0.0312s/iter; left time: 252.0829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0605665 Vali Loss: 0.0579799 Test Loss: 0.0728870\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0594655\n",
      "\tspeed: 0.0611s/iter; left time: 486.7320s\n",
      "\titers: 200, epoch: 65 | loss: 0.0624393\n",
      "\tspeed: 0.0221s/iter; left time: 173.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 224 | Train Loss: 0.0603938 Vali Loss: 0.0579359 Test Loss: 0.0730231\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0584601\n",
      "\tspeed: 0.0477s/iter; left time: 369.5386s\n",
      "\titers: 200, epoch: 66 | loss: 0.0605349\n",
      "\tspeed: 0.0240s/iter; left time: 183.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0604561 Vali Loss: 0.0581021 Test Loss: 0.0734265\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0601984\n",
      "\tspeed: 0.0697s/iter; left time: 524.2843s\n",
      "\titers: 200, epoch: 67 | loss: 0.0605302\n",
      "\tspeed: 0.0253s/iter; left time: 187.8994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0606215 Vali Loss: 0.0581030 Test Loss: 0.0734250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0607060\n",
      "\tspeed: 0.0497s/iter; left time: 362.3583s\n",
      "\titers: 200, epoch: 68 | loss: 0.0581991\n",
      "\tspeed: 0.0232s/iter; left time: 166.8285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0608544 Vali Loss: 0.0579180 Test Loss: 0.0731836\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0632075\n",
      "\tspeed: 0.0501s/iter; left time: 354.4930s\n",
      "\titers: 200, epoch: 69 | loss: 0.0613793\n",
      "\tspeed: 0.0262s/iter; left time: 182.6931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0605738 Vali Loss: 0.0580780 Test Loss: 0.0736589\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0615018\n",
      "\tspeed: 0.0483s/iter; left time: 330.5479s\n",
      "\titers: 200, epoch: 70 | loss: 0.0607887\n",
      "\tspeed: 0.0250s/iter; left time: 168.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0606270 Vali Loss: 0.0581670 Test Loss: 0.0734960\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012619041837751865, rmse:0.11233451217412949, mae:0.0730932354927063, rse:0.33058688044548035\n",
      "Intermediate time for ES and pred_len 24: 00h:21m:09.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2704993\n",
      "\tspeed: 0.0560s/iter; left time: 1247.8731s\n",
      "\titers: 200, epoch: 1 | loss: 0.2554511\n",
      "\tspeed: 0.0363s/iter; left time: 806.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 224 | Train Loss: 0.2778322 Vali Loss: 0.2091237 Test Loss: 0.2344305\n",
      "Validation loss decreased (inf --> 0.209124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1443953\n",
      "\tspeed: 0.0514s/iter; left time: 1135.2416s\n",
      "\titers: 200, epoch: 2 | loss: 0.1187204\n",
      "\tspeed: 0.0239s/iter; left time: 524.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.1552305 Vali Loss: 0.1045255 Test Loss: 0.1173863\n",
      "Validation loss decreased (0.209124 --> 0.104526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089211\n",
      "\tspeed: 0.0534s/iter; left time: 1167.2588s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028839\n",
      "\tspeed: 0.0225s/iter; left time: 488.3935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.1089467 Vali Loss: 0.0931613 Test Loss: 0.1099090\n",
      "Validation loss decreased (0.104526 --> 0.093161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0921360\n",
      "\tspeed: 0.0588s/iter; left time: 1271.9857s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907388\n",
      "\tspeed: 0.0375s/iter; left time: 807.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0957239 Vali Loss: 0.0871257 Test Loss: 0.1042031\n",
      "Validation loss decreased (0.093161 --> 0.087126).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918303\n",
      "\tspeed: 0.0583s/iter; left time: 1248.3684s\n",
      "\titers: 200, epoch: 5 | loss: 0.0875634\n",
      "\tspeed: 0.0279s/iter; left time: 594.3987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0908779 Vali Loss: 0.0851532 Test Loss: 0.1045321\n",
      "Validation loss decreased (0.087126 --> 0.085153).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932905\n",
      "\tspeed: 0.0527s/iter; left time: 1115.9048s\n",
      "\titers: 200, epoch: 6 | loss: 0.0870134\n",
      "\tspeed: 0.0242s/iter; left time: 510.0199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0886906 Vali Loss: 0.0837882 Test Loss: 0.1056718\n",
      "Validation loss decreased (0.085153 --> 0.083788).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0887610\n",
      "\tspeed: 0.0536s/iter; left time: 1122.4169s\n",
      "\titers: 200, epoch: 7 | loss: 0.0822823\n",
      "\tspeed: 0.0296s/iter; left time: 616.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0861625 Vali Loss: 0.0821757 Test Loss: 0.1054372\n",
      "Validation loss decreased (0.083788 --> 0.082176).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0863238\n",
      "\tspeed: 0.0508s/iter; left time: 1053.2908s\n",
      "\titers: 200, epoch: 8 | loss: 0.0813287\n",
      "\tspeed: 0.0239s/iter; left time: 492.1285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0849600 Vali Loss: 0.0809413 Test Loss: 0.1054865\n",
      "Validation loss decreased (0.082176 --> 0.080941).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0837449\n",
      "\tspeed: 0.0516s/iter; left time: 1058.5137s\n",
      "\titers: 200, epoch: 9 | loss: 0.0798360\n",
      "\tspeed: 0.0233s/iter; left time: 474.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0837917 Vali Loss: 0.0810303 Test Loss: 0.1073283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0854328\n",
      "\tspeed: 0.0523s/iter; left time: 1061.9036s\n",
      "\titers: 200, epoch: 10 | loss: 0.0859400\n",
      "\tspeed: 0.0311s/iter; left time: 627.8248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 224 | Train Loss: 0.0832026 Vali Loss: 0.0806594 Test Loss: 0.1060589\n",
      "Validation loss decreased (0.080941 --> 0.080659).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0832818\n",
      "\tspeed: 0.0501s/iter; left time: 1004.9937s\n",
      "\titers: 200, epoch: 11 | loss: 0.0840366\n",
      "\tspeed: 0.0228s/iter; left time: 454.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0827407 Vali Loss: 0.0801369 Test Loss: 0.1064315\n",
      "Validation loss decreased (0.080659 --> 0.080137).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837808\n",
      "\tspeed: 0.0560s/iter; left time: 1110.2882s\n",
      "\titers: 200, epoch: 12 | loss: 0.0812744\n",
      "\tspeed: 0.0259s/iter; left time: 511.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0821527 Vali Loss: 0.0798724 Test Loss: 0.1057109\n",
      "Validation loss decreased (0.080137 --> 0.079872).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783565\n",
      "\tspeed: 0.0537s/iter; left time: 1053.0977s\n",
      "\titers: 200, epoch: 13 | loss: 0.0837794\n",
      "\tspeed: 0.0227s/iter; left time: 442.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0817536 Vali Loss: 0.0803160 Test Loss: 0.1077637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0762014\n",
      "\tspeed: 0.0508s/iter; left time: 984.4545s\n",
      "\titers: 200, epoch: 14 | loss: 0.0786795\n",
      "\tspeed: 0.0295s/iter; left time: 569.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0813115 Vali Loss: 0.0805098 Test Loss: 0.1053479\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0781552\n",
      "\tspeed: 0.0589s/iter; left time: 1129.7244s\n",
      "\titers: 200, epoch: 15 | loss: 0.0823384\n",
      "\tspeed: 0.0253s/iter; left time: 483.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0810086 Vali Loss: 0.0794107 Test Loss: 0.1068668\n",
      "Validation loss decreased (0.079872 --> 0.079411).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0775683\n",
      "\tspeed: 0.0491s/iter; left time: 930.9083s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845360\n",
      "\tspeed: 0.0250s/iter; left time: 470.4449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0810002 Vali Loss: 0.0793832 Test Loss: 0.1062732\n",
      "Validation loss decreased (0.079411 --> 0.079383).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0785738\n",
      "\tspeed: 0.0604s/iter; left time: 1129.5765s\n",
      "\titers: 200, epoch: 17 | loss: 0.0830793\n",
      "\tspeed: 0.0258s/iter; left time: 479.6877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0806805 Vali Loss: 0.0796757 Test Loss: 0.1081794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0810726\n",
      "\tspeed: 0.0534s/iter; left time: 987.6375s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812911\n",
      "\tspeed: 0.0224s/iter; left time: 412.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0801853 Vali Loss: 0.0788049 Test Loss: 0.1056824\n",
      "Validation loss decreased (0.079383 --> 0.078805).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0818440\n",
      "\tspeed: 0.0505s/iter; left time: 923.3333s\n",
      "\titers: 200, epoch: 19 | loss: 0.0842848\n",
      "\tspeed: 0.0249s/iter; left time: 452.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0800752 Vali Loss: 0.0789717 Test Loss: 0.1065343\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801755\n",
      "\tspeed: 0.0604s/iter; left time: 1089.0852s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796499\n",
      "\tspeed: 0.0252s/iter; left time: 452.8986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0799425 Vali Loss: 0.0790023 Test Loss: 0.1056895\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0788750\n",
      "\tspeed: 0.0551s/iter; left time: 982.1864s\n",
      "\titers: 200, epoch: 21 | loss: 0.0768064\n",
      "\tspeed: 0.0280s/iter; left time: 495.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0798105 Vali Loss: 0.0786801 Test Loss: 0.1066256\n",
      "Validation loss decreased (0.078805 --> 0.078680).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0817088\n",
      "\tspeed: 0.0487s/iter; left time: 857.2357s\n",
      "\titers: 200, epoch: 22 | loss: 0.0811852\n",
      "\tspeed: 0.0221s/iter; left time: 387.3115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0794791 Vali Loss: 0.0787583 Test Loss: 0.1066551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0780964\n",
      "\tspeed: 0.0648s/iter; left time: 1126.6143s\n",
      "\titers: 200, epoch: 23 | loss: 0.0819277\n",
      "\tspeed: 0.0282s/iter; left time: 487.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0794437 Vali Loss: 0.0786141 Test Loss: 0.1061799\n",
      "Validation loss decreased (0.078680 --> 0.078614).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0778028\n",
      "\tspeed: 0.0554s/iter; left time: 950.4224s\n",
      "\titers: 200, epoch: 24 | loss: 0.0758676\n",
      "\tspeed: 0.0259s/iter; left time: 441.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.0795189 Vali Loss: 0.0787810 Test Loss: 0.1073045\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0792079\n",
      "\tspeed: 0.0528s/iter; left time: 893.6485s\n",
      "\titers: 200, epoch: 25 | loss: 0.0812866\n",
      "\tspeed: 0.0245s/iter; left time: 412.7581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 224 | Train Loss: 0.0793172 Vali Loss: 0.0787688 Test Loss: 0.1074945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763770\n",
      "\tspeed: 0.0562s/iter; left time: 939.0085s\n",
      "\titers: 200, epoch: 26 | loss: 0.0783638\n",
      "\tspeed: 0.0222s/iter; left time: 368.3912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0792577 Vali Loss: 0.0787418 Test Loss: 0.1073678\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0775584\n",
      "\tspeed: 0.0504s/iter; left time: 831.1723s\n",
      "\titers: 200, epoch: 27 | loss: 0.0783684\n",
      "\tspeed: 0.0295s/iter; left time: 482.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0791592 Vali Loss: 0.0785288 Test Loss: 0.1066040\n",
      "Validation loss decreased (0.078614 --> 0.078529).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0803237\n",
      "\tspeed: 0.0662s/iter; left time: 1075.8438s\n",
      "\titers: 200, epoch: 28 | loss: 0.0806329\n",
      "\tspeed: 0.0351s/iter; left time: 567.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 224 | Train Loss: 0.0789692 Vali Loss: 0.0784907 Test Loss: 0.1069626\n",
      "Validation loss decreased (0.078529 --> 0.078491).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0771088\n",
      "\tspeed: 0.0560s/iter; left time: 897.2086s\n",
      "\titers: 200, epoch: 29 | loss: 0.0797537\n",
      "\tspeed: 0.0275s/iter; left time: 438.0735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0789747 Vali Loss: 0.0785680 Test Loss: 0.1075136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0768419\n",
      "\tspeed: 0.0605s/iter; left time: 955.5593s\n",
      "\titers: 200, epoch: 30 | loss: 0.0750424\n",
      "\tspeed: 0.0298s/iter; left time: 468.5193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.0790785 Vali Loss: 0.0785908 Test Loss: 0.1073105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0787101\n",
      "\tspeed: 0.0585s/iter; left time: 911.8833s\n",
      "\titers: 200, epoch: 31 | loss: 0.0802411\n",
      "\tspeed: 0.0247s/iter; left time: 381.6253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0789518 Vali Loss: 0.0784791 Test Loss: 0.1074833\n",
      "Validation loss decreased (0.078491 --> 0.078479).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0823305\n",
      "\tspeed: 0.0557s/iter; left time: 854.9853s\n",
      "\titers: 200, epoch: 32 | loss: 0.0796036\n",
      "\tspeed: 0.0286s/iter; left time: 436.6633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0788601 Vali Loss: 0.0782840 Test Loss: 0.1062653\n",
      "Validation loss decreased (0.078479 --> 0.078284).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0793923\n",
      "\tspeed: 0.3947s/iter; left time: 5972.4182s\n",
      "\titers: 200, epoch: 33 | loss: 0.0793243\n",
      "\tspeed: 0.2738s/iter; left time: 4116.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:57.38s\n",
      "Steps: 224 | Train Loss: 0.0788686 Vali Loss: 0.0784163 Test Loss: 0.1069686\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0756958\n",
      "\tspeed: 0.8538s/iter; left time: 12728.7993s\n",
      "\titers: 200, epoch: 34 | loss: 0.0838103\n",
      "\tspeed: 0.2451s/iter; left time: 3629.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:58.46s\n",
      "Steps: 224 | Train Loss: 0.0788095 Vali Loss: 0.0782736 Test Loss: 0.1072011\n",
      "Validation loss decreased (0.078284 --> 0.078274).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0812744\n",
      "\tspeed: 0.8012s/iter; left time: 11765.4880s\n",
      "\titers: 200, epoch: 35 | loss: 0.0821269\n",
      "\tspeed: 0.2272s/iter; left time: 3313.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:53.92s\n",
      "Steps: 224 | Train Loss: 0.0787743 Vali Loss: 0.0782643 Test Loss: 0.1069137\n",
      "Validation loss decreased (0.078274 --> 0.078264).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0798463\n",
      "\tspeed: 0.7605s/iter; left time: 10997.1287s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770300\n",
      "\tspeed: 0.2165s/iter; left time: 3108.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:51.23s\n",
      "Steps: 224 | Train Loss: 0.0787331 Vali Loss: 0.0783624 Test Loss: 0.1071056\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0807413\n",
      "\tspeed: 0.5070s/iter; left time: 7217.6860s\n",
      "\titers: 200, epoch: 37 | loss: 0.0780625\n",
      "\tspeed: 0.0645s/iter; left time: 912.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:18.51s\n",
      "Steps: 224 | Train Loss: 0.0787729 Vali Loss: 0.0782518 Test Loss: 0.1068003\n",
      "Validation loss decreased (0.078264 --> 0.078252).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0758653\n",
      "\tspeed: 0.1457s/iter; left time: 2041.5289s\n",
      "\titers: 200, epoch: 38 | loss: 0.0763736\n",
      "\tspeed: 0.0452s/iter; left time: 628.9367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:10.25s\n",
      "Steps: 224 | Train Loss: 0.0786084 Vali Loss: 0.0782499 Test Loss: 0.1072317\n",
      "Validation loss decreased (0.078252 --> 0.078250).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0760216\n",
      "\tspeed: 0.0724s/iter; left time: 998.0064s\n",
      "\titers: 200, epoch: 39 | loss: 0.0784634\n",
      "\tspeed: 0.0334s/iter; left time: 456.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 224 | Train Loss: 0.0785685 Vali Loss: 0.0782051 Test Loss: 0.1070562\n",
      "Validation loss decreased (0.078250 --> 0.078205).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0802338\n",
      "\tspeed: 0.0714s/iter; left time: 968.4450s\n",
      "\titers: 200, epoch: 40 | loss: 0.0773618\n",
      "\tspeed: 0.0298s/iter; left time: 401.1484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 224 | Train Loss: 0.0786725 Vali Loss: 0.0781130 Test Loss: 0.1067497\n",
      "Validation loss decreased (0.078205 --> 0.078113).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0785245\n",
      "\tspeed: 0.0585s/iter; left time: 780.0350s\n",
      "\titers: 200, epoch: 41 | loss: 0.0785387\n",
      "\tspeed: 0.0243s/iter; left time: 322.2650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0785518 Vali Loss: 0.0784730 Test Loss: 0.1084492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0791963\n",
      "\tspeed: 0.0645s/iter; left time: 845.8526s\n",
      "\titers: 200, epoch: 42 | loss: 0.0760376\n",
      "\tspeed: 0.0362s/iter; left time: 471.4391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 224 | Train Loss: 0.0786132 Vali Loss: 0.0782817 Test Loss: 0.1074298\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0778955\n",
      "\tspeed: 0.0511s/iter; left time: 658.8355s\n",
      "\titers: 200, epoch: 43 | loss: 0.0800252\n",
      "\tspeed: 0.0286s/iter; left time: 366.4441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0786420 Vali Loss: 0.0781189 Test Loss: 0.1067718\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0819997\n",
      "\tspeed: 0.0542s/iter; left time: 687.1672s\n",
      "\titers: 200, epoch: 44 | loss: 0.0814772\n",
      "\tspeed: 0.0268s/iter; left time: 337.4000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0786479 Vali Loss: 0.0782319 Test Loss: 0.1075585\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0748167\n",
      "\tspeed: 0.1371s/iter; left time: 1706.3845s\n",
      "\titers: 200, epoch: 45 | loss: 0.0806576\n",
      "\tspeed: 0.1234s/iter; left time: 1523.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:26.77s\n",
      "Steps: 224 | Train Loss: 0.0785665 Vali Loss: 0.0781131 Test Loss: 0.1069098\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0779535\n",
      "\tspeed: 0.4148s/iter; left time: 5069.2781s\n",
      "\titers: 200, epoch: 46 | loss: 0.0775306\n",
      "\tspeed: 0.1757s/iter; left time: 2129.2589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:38.85s\n",
      "Steps: 224 | Train Loss: 0.0789313 Vali Loss: 0.0782464 Test Loss: 0.1069450\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0779391\n",
      "\tspeed: 0.5836s/iter; left time: 7001.9260s\n",
      "\titers: 200, epoch: 47 | loss: 0.0755811\n",
      "\tspeed: 0.1768s/iter; left time: 2103.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:39.99s\n",
      "Steps: 224 | Train Loss: 0.0785349 Vali Loss: 0.0782029 Test Loss: 0.1071916\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0790833\n",
      "\tspeed: 0.6386s/iter; left time: 7518.3920s\n",
      "\titers: 200, epoch: 48 | loss: 0.0748542\n",
      "\tspeed: 0.1245s/iter; left time: 1453.4596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:38.87s\n",
      "Steps: 224 | Train Loss: 0.0785826 Vali Loss: 0.0781639 Test Loss: 0.1072817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0800797\n",
      "\tspeed: 0.6446s/iter; left time: 7444.5921s\n",
      "\titers: 200, epoch: 49 | loss: 0.0780519\n",
      "\tspeed: 0.1807s/iter; left time: 2068.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 224 | Train Loss: 0.0786275 Vali Loss: 0.0782234 Test Loss: 0.1074842\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0796954\n",
      "\tspeed: 0.6242s/iter; left time: 7068.8319s\n",
      "\titers: 200, epoch: 50 | loss: 0.0800935\n",
      "\tspeed: 0.1073s/iter; left time: 1204.9534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:28.37s\n",
      "Steps: 224 | Train Loss: 0.0785114 Vali Loss: 0.0783420 Test Loss: 0.1074089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02606804110109806, rmse:0.16145600378513336, mae:0.10674968361854553, rse:0.47430914640426636\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2792787\n",
      "\tspeed: 0.1123s/iter; left time: 2504.1473s\n",
      "\titers: 200, epoch: 1 | loss: 0.2649852\n",
      "\tspeed: 0.2170s/iter; left time: 4817.5636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.81s\n",
      "Steps: 224 | Train Loss: 0.2850079 Vali Loss: 0.2131646 Test Loss: 0.2377978\n",
      "Validation loss decreased (inf --> 0.213165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1498872\n",
      "\tspeed: 0.7532s/iter; left time: 16627.6748s\n",
      "\titers: 200, epoch: 2 | loss: 0.1174857\n",
      "\tspeed: 0.1869s/iter; left time: 4108.2810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.52s\n",
      "Steps: 224 | Train Loss: 0.1591635 Vali Loss: 0.1057102 Test Loss: 0.1189962\n",
      "Validation loss decreased (0.213165 --> 0.105710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1049837\n",
      "\tspeed: 0.1610s/iter; left time: 3518.0804s\n",
      "\titers: 200, epoch: 3 | loss: 0.1032990\n",
      "\tspeed: 0.2035s/iter; left time: 4427.1211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.82s\n",
      "Steps: 224 | Train Loss: 0.1071122 Vali Loss: 0.0968849 Test Loss: 0.1164992\n",
      "Validation loss decreased (0.105710 --> 0.096885).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0999881\n",
      "\tspeed: 0.7049s/iter; left time: 15245.2421s\n",
      "\titers: 200, epoch: 4 | loss: 0.0945148\n",
      "\tspeed: 0.2131s/iter; left time: 4587.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.43s\n",
      "Steps: 224 | Train Loss: 0.0949442 Vali Loss: 0.0855487 Test Loss: 0.1054883\n",
      "Validation loss decreased (0.096885 --> 0.085549).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918293\n",
      "\tspeed: 0.1286s/iter; left time: 2753.1486s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848560\n",
      "\tspeed: 0.1432s/iter; left time: 3051.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.35s\n",
      "Steps: 224 | Train Loss: 0.0899307 Vali Loss: 0.0839947 Test Loss: 0.1064513\n",
      "Validation loss decreased (0.085549 --> 0.083995).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0849024\n",
      "\tspeed: 0.7414s/iter; left time: 15704.4504s\n",
      "\titers: 200, epoch: 6 | loss: 0.0857075\n",
      "\tspeed: 0.2066s/iter; left time: 4354.3372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 224 | Train Loss: 0.0874642 Vali Loss: 0.0827074 Test Loss: 0.1042721\n",
      "Validation loss decreased (0.083995 --> 0.082707).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839053\n",
      "\tspeed: 0.1686s/iter; left time: 3532.5966s\n",
      "\titers: 200, epoch: 7 | loss: 0.0827757\n",
      "\tspeed: 0.0300s/iter; left time: 626.5406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0866783 Vali Loss: 0.0823522 Test Loss: 0.1039911\n",
      "Validation loss decreased (0.082707 --> 0.082352).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826827\n",
      "\tspeed: 0.0603s/iter; left time: 1250.0757s\n",
      "\titers: 200, epoch: 8 | loss: 0.0804850\n",
      "\tspeed: 0.2091s/iter; left time: 4313.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 224 | Train Loss: 0.0850287 Vali Loss: 0.0804520 Test Loss: 0.1010032\n",
      "Validation loss decreased (0.082352 --> 0.080452).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822033\n",
      "\tspeed: 0.7216s/iter; left time: 14799.2126s\n",
      "\titers: 200, epoch: 9 | loss: 0.0845221\n",
      "\tspeed: 0.2003s/iter; left time: 4087.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 224 | Train Loss: 0.0845946 Vali Loss: 0.0813719 Test Loss: 0.1031057\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825328\n",
      "\tspeed: 0.3124s/iter; left time: 6336.8346s\n",
      "\titers: 200, epoch: 10 | loss: 0.0838826\n",
      "\tspeed: 0.0233s/iter; left time: 470.2486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 224 | Train Loss: 0.0836564 Vali Loss: 0.0800238 Test Loss: 0.1021235\n",
      "Validation loss decreased (0.080452 --> 0.080024).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0814183\n",
      "\tspeed: 0.0510s/iter; left time: 1022.4978s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828138\n",
      "\tspeed: 0.0225s/iter; left time: 448.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0825868 Vali Loss: 0.0798358 Test Loss: 0.1017064\n",
      "Validation loss decreased (0.080024 --> 0.079836).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0808523\n",
      "\tspeed: 0.2032s/iter; left time: 4030.3804s\n",
      "\titers: 200, epoch: 12 | loss: 0.0792476\n",
      "\tspeed: 0.2275s/iter; left time: 4490.8502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 224 | Train Loss: 0.0824364 Vali Loss: 0.0807601 Test Loss: 0.1016696\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0799127\n",
      "\tspeed: 0.7428s/iter; left time: 14569.3599s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800191\n",
      "\tspeed: 0.0284s/iter; left time: 554.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:20.54s\n",
      "Steps: 224 | Train Loss: 0.0824644 Vali Loss: 0.0793439 Test Loss: 0.1021537\n",
      "Validation loss decreased (0.079836 --> 0.079344).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0812680\n",
      "\tspeed: 0.0505s/iter; left time: 979.5646s\n",
      "\titers: 200, epoch: 14 | loss: 0.0834910\n",
      "\tspeed: 0.0221s/iter; left time: 426.8188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0820589 Vali Loss: 0.0805328 Test Loss: 0.1022749\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0818415\n",
      "\tspeed: 0.0529s/iter; left time: 1013.8770s\n",
      "\titers: 200, epoch: 15 | loss: 0.0847595\n",
      "\tspeed: 0.0249s/iter; left time: 474.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0816347 Vali Loss: 0.0789403 Test Loss: 0.1031928\n",
      "Validation loss decreased (0.079344 --> 0.078940).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0810707\n",
      "\tspeed: 0.0515s/iter; left time: 975.7457s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827591\n",
      "\tspeed: 0.0274s/iter; left time: 515.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0810812 Vali Loss: 0.0792231 Test Loss: 0.1041535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777121\n",
      "\tspeed: 0.0507s/iter; left time: 949.5416s\n",
      "\titers: 200, epoch: 17 | loss: 0.0815162\n",
      "\tspeed: 0.0230s/iter; left time: 427.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 224 | Train Loss: 0.0807954 Vali Loss: 0.0791107 Test Loss: 0.1040923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0780679\n",
      "\tspeed: 0.0531s/iter; left time: 982.0820s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805871\n",
      "\tspeed: 0.0290s/iter; left time: 533.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0807699 Vali Loss: 0.0792412 Test Loss: 0.1038266\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0765163\n",
      "\tspeed: 0.0543s/iter; left time: 992.4047s\n",
      "\titers: 200, epoch: 19 | loss: 0.0815112\n",
      "\tspeed: 0.0235s/iter; left time: 426.7585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0804458 Vali Loss: 0.0788845 Test Loss: 0.1041001\n",
      "Validation loss decreased (0.078940 --> 0.078885).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801165\n",
      "\tspeed: 0.0520s/iter; left time: 938.9256s\n",
      "\titers: 200, epoch: 20 | loss: 0.0791187\n",
      "\tspeed: 0.0285s/iter; left time: 511.8360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0804614 Vali Loss: 0.0789123 Test Loss: 0.1037632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0806711\n",
      "\tspeed: 0.0578s/iter; left time: 1030.7559s\n",
      "\titers: 200, epoch: 21 | loss: 0.0815572\n",
      "\tspeed: 0.1401s/iter; left time: 2483.3305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:19.95s\n",
      "Steps: 224 | Train Loss: 0.0804909 Vali Loss: 0.0783832 Test Loss: 0.1024599\n",
      "Validation loss decreased (0.078885 --> 0.078383).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0809093\n",
      "\tspeed: 0.3965s/iter; left time: 6977.8942s\n",
      "\titers: 200, epoch: 22 | loss: 0.0796040\n",
      "\tspeed: 0.1332s/iter; left time: 2331.3592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:30.89s\n",
      "Steps: 224 | Train Loss: 0.0802909 Vali Loss: 0.0786344 Test Loss: 0.1040339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0830954\n",
      "\tspeed: 0.4559s/iter; left time: 7920.8444s\n",
      "\titers: 200, epoch: 23 | loss: 0.0778427\n",
      "\tspeed: 0.1095s/iter; left time: 1890.9211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:26.81s\n",
      "Steps: 224 | Train Loss: 0.0800006 Vali Loss: 0.0784222 Test Loss: 0.1044553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0773367\n",
      "\tspeed: 0.1509s/iter; left time: 2587.6522s\n",
      "\titers: 200, epoch: 24 | loss: 0.0789202\n",
      "\tspeed: 0.0252s/iter; left time: 429.5529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0798820 Vali Loss: 0.0782881 Test Loss: 0.1039032\n",
      "Validation loss decreased (0.078383 --> 0.078288).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0797844\n",
      "\tspeed: 0.0722s/iter; left time: 1222.4980s\n",
      "\titers: 200, epoch: 25 | loss: 0.0784464\n",
      "\tspeed: 0.0319s/iter; left time: 537.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.0798312 Vali Loss: 0.0784625 Test Loss: 0.1041823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0799882\n",
      "\tspeed: 0.0519s/iter; left time: 867.5433s\n",
      "\titers: 200, epoch: 26 | loss: 0.0793978\n",
      "\tspeed: 0.0231s/iter; left time: 383.4286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0798466 Vali Loss: 0.0785042 Test Loss: 0.1049148\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0813180\n",
      "\tspeed: 0.0582s/iter; left time: 958.8430s\n",
      "\titers: 200, epoch: 27 | loss: 0.0806970\n",
      "\tspeed: 0.0333s/iter; left time: 545.8540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 224 | Train Loss: 0.0796077 Vali Loss: 0.0782184 Test Loss: 0.1042569\n",
      "Validation loss decreased (0.078288 --> 0.078218).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0809176\n",
      "\tspeed: 0.0730s/iter; left time: 1186.7856s\n",
      "\titers: 200, epoch: 28 | loss: 0.0783188\n",
      "\tspeed: 0.0426s/iter; left time: 688.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0797784 Vali Loss: 0.0782920 Test Loss: 0.1042234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0803838\n",
      "\tspeed: 0.0568s/iter; left time: 910.7059s\n",
      "\titers: 200, epoch: 29 | loss: 0.0735765\n",
      "\tspeed: 0.0274s/iter; left time: 435.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0795765 Vali Loss: 0.0783056 Test Loss: 0.1045026\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0800161\n",
      "\tspeed: 0.0565s/iter; left time: 892.8838s\n",
      "\titers: 200, epoch: 30 | loss: 0.0809262\n",
      "\tspeed: 0.0240s/iter; left time: 377.5996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0793852 Vali Loss: 0.0783652 Test Loss: 0.1049954\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0801490\n",
      "\tspeed: 0.0504s/iter; left time: 785.2314s\n",
      "\titers: 200, epoch: 31 | loss: 0.0802145\n",
      "\tspeed: 0.0222s/iter; left time: 343.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0801062 Vali Loss: 0.0782773 Test Loss: 0.1041020\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0752822\n",
      "\tspeed: 0.0489s/iter; left time: 750.3437s\n",
      "\titers: 200, epoch: 32 | loss: 0.0803191\n",
      "\tspeed: 0.0233s/iter; left time: 355.9119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0793204 Vali Loss: 0.0780731 Test Loss: 0.1041139\n",
      "Validation loss decreased (0.078218 --> 0.078073).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0780417\n",
      "\tspeed: 0.7921s/iter; left time: 11987.3402s\n",
      "\titers: 200, epoch: 33 | loss: 0.0772895\n",
      "\tspeed: 0.2483s/iter; left time: 3732.7423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:56.14s\n",
      "Steps: 224 | Train Loss: 0.0793370 Vali Loss: 0.0781708 Test Loss: 0.1053759\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0790620\n",
      "\tspeed: 0.8496s/iter; left time: 12666.7549s\n",
      "\titers: 200, epoch: 34 | loss: 0.0777277\n",
      "\tspeed: 0.2543s/iter; left time: 3766.2556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:57.48s\n",
      "Steps: 224 | Train Loss: 0.0794318 Vali Loss: 0.0782324 Test Loss: 0.1049891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0817989\n",
      "\tspeed: 0.8616s/iter; left time: 12651.9174s\n",
      "\titers: 200, epoch: 35 | loss: 0.0772448\n",
      "\tspeed: 0.2481s/iter; left time: 3618.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0793121 Vali Loss: 0.0781840 Test Loss: 0.1047611\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0781003\n",
      "\tspeed: 0.8514s/iter; left time: 12312.1161s\n",
      "\titers: 200, epoch: 36 | loss: 0.0811642\n",
      "\tspeed: 0.2283s/iter; left time: 3277.9179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:54.93s\n",
      "Steps: 224 | Train Loss: 0.0791830 Vali Loss: 0.0780559 Test Loss: 0.1044061\n",
      "Validation loss decreased (0.078073 --> 0.078056).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0784464\n",
      "\tspeed: 0.8834s/iter; left time: 12576.2804s\n",
      "\titers: 200, epoch: 37 | loss: 0.0760975\n",
      "\tspeed: 0.2326s/iter; left time: 3288.3291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:57.21s\n",
      "Steps: 224 | Train Loss: 0.0791224 Vali Loss: 0.0781889 Test Loss: 0.1049399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0813418\n",
      "\tspeed: 0.8238s/iter; left time: 11543.2200s\n",
      "\titers: 200, epoch: 38 | loss: 0.0797402\n",
      "\tspeed: 0.2500s/iter; left time: 3477.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:56.48s\n",
      "Steps: 224 | Train Loss: 0.0792424 Vali Loss: 0.0779811 Test Loss: 0.1042640\n",
      "Validation loss decreased (0.078056 --> 0.077981).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0851971\n",
      "\tspeed: 0.4956s/iter; left time: 6834.1378s\n",
      "\titers: 200, epoch: 39 | loss: 0.0805692\n",
      "\tspeed: 0.0615s/iter; left time: 841.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:16.44s\n",
      "Steps: 224 | Train Loss: 0.0794647 Vali Loss: 0.0780003 Test Loss: 0.1041515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0819355\n",
      "\tspeed: 0.1664s/iter; left time: 2257.6419s\n",
      "\titers: 200, epoch: 40 | loss: 0.0819953\n",
      "\tspeed: 0.0490s/iter; left time: 659.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0791665 Vali Loss: 0.0780685 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0768735\n",
      "\tspeed: 0.1592s/iter; left time: 2124.4003s\n",
      "\titers: 200, epoch: 41 | loss: 0.0772569\n",
      "\tspeed: 0.0491s/iter; left time: 650.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.41s\n",
      "Steps: 224 | Train Loss: 0.0790473 Vali Loss: 0.0780292 Test Loss: 0.1046755\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0796933\n",
      "\tspeed: 0.1379s/iter; left time: 1808.7054s\n",
      "\titers: 200, epoch: 42 | loss: 0.0786233\n",
      "\tspeed: 0.0412s/iter; left time: 536.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0793347 Vali Loss: 0.0778732 Test Loss: 0.1041902\n",
      "Validation loss decreased (0.077981 --> 0.077873).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0764746\n",
      "\tspeed: 0.0544s/iter; left time: 701.5526s\n",
      "\titers: 200, epoch: 43 | loss: 0.0744639\n",
      "\tspeed: 0.0232s/iter; left time: 296.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0791484 Vali Loss: 0.0780769 Test Loss: 0.1050623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0755760\n",
      "\tspeed: 0.0662s/iter; left time: 838.1293s\n",
      "\titers: 200, epoch: 44 | loss: 0.0787479\n",
      "\tspeed: 0.0299s/iter; left time: 375.2761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0791972 Vali Loss: 0.0779868 Test Loss: 0.1043765\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0762714\n",
      "\tspeed: 0.0746s/iter; left time: 927.7961s\n",
      "\titers: 200, epoch: 45 | loss: 0.0759438\n",
      "\tspeed: 0.0222s/iter; left time: 273.4962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0790206 Vali Loss: 0.0781770 Test Loss: 0.1054556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0754517\n",
      "\tspeed: 0.0546s/iter; left time: 667.5340s\n",
      "\titers: 200, epoch: 46 | loss: 0.0785779\n",
      "\tspeed: 0.0239s/iter; left time: 290.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 224 | Train Loss: 0.0790998 Vali Loss: 0.0779618 Test Loss: 0.1047398\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0816835\n",
      "\tspeed: 0.0557s/iter; left time: 668.4182s\n",
      "\titers: 200, epoch: 47 | loss: 0.0801519\n",
      "\tspeed: 0.0226s/iter; left time: 268.8318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0792747 Vali Loss: 0.0779582 Test Loss: 0.1046278\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0784598\n",
      "\tspeed: 0.0545s/iter; left time: 641.7825s\n",
      "\titers: 200, epoch: 48 | loss: 0.0811592\n",
      "\tspeed: 0.0224s/iter; left time: 261.3685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0791503 Vali Loss: 0.0779428 Test Loss: 0.1043643\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0766961\n",
      "\tspeed: 0.0525s/iter; left time: 606.8447s\n",
      "\titers: 200, epoch: 49 | loss: 0.0796693\n",
      "\tspeed: 0.0223s/iter; left time: 254.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0790683 Vali Loss: 0.0779037 Test Loss: 0.1040635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0831854\n",
      "\tspeed: 0.0518s/iter; left time: 586.1710s\n",
      "\titers: 200, epoch: 50 | loss: 0.0752173\n",
      "\tspeed: 0.0230s/iter; left time: 258.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0791010 Vali Loss: 0.0779972 Test Loss: 0.1044786\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0789320\n",
      "\tspeed: 0.0512s/iter; left time: 568.7515s\n",
      "\titers: 200, epoch: 51 | loss: 0.0761701\n",
      "\tspeed: 0.0222s/iter; left time: 244.0749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0790944 Vali Loss: 0.0779185 Test Loss: 0.1042843\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0803050\n",
      "\tspeed: 0.0509s/iter; left time: 553.3961s\n",
      "\titers: 200, epoch: 52 | loss: 0.0811822\n",
      "\tspeed: 0.0291s/iter; left time: 313.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0790576 Vali Loss: 0.0779051 Test Loss: 0.1044083\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.023792318999767303, rmse:0.15424759685993195, mae:0.1041901558637619, rse:0.4531330168247223\n",
      "Intermediate time for ES and pred_len 96: 00h:50m:39.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2741542\n",
      "\tspeed: 0.0411s/iter; left time: 913.3161s\n",
      "\titers: 200, epoch: 1 | loss: 0.2625363\n",
      "\tspeed: 0.0228s/iter; left time: 503.1415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.2789657 Vali Loss: 0.2099814 Test Loss: 0.2343885\n",
      "Validation loss decreased (inf --> 0.209981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1420116\n",
      "\tspeed: 0.0517s/iter; left time: 1135.4608s\n",
      "\titers: 200, epoch: 2 | loss: 0.1204582\n",
      "\tspeed: 0.0228s/iter; left time: 498.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.1545209 Vali Loss: 0.1098287 Test Loss: 0.1241958\n",
      "Validation loss decreased (0.209981 --> 0.109829).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1149083\n",
      "\tspeed: 0.0497s/iter; left time: 1081.0783s\n",
      "\titers: 200, epoch: 3 | loss: 0.1036759\n",
      "\tspeed: 0.0230s/iter; left time: 498.5417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.1100028 Vali Loss: 0.0971829 Test Loss: 0.1128965\n",
      "Validation loss decreased (0.109829 --> 0.097183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0992307\n",
      "\tspeed: 0.0575s/iter; left time: 1238.8396s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954987\n",
      "\tspeed: 0.0239s/iter; left time: 512.6749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0981677 Vali Loss: 0.0916976 Test Loss: 0.1122032\n",
      "Validation loss decreased (0.097183 --> 0.091698).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0940899\n",
      "\tspeed: 0.0499s/iter; left time: 1064.0593s\n",
      "\titers: 200, epoch: 5 | loss: 0.0911457\n",
      "\tspeed: 0.0240s/iter; left time: 508.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 223 | Train Loss: 0.0938299 Vali Loss: 0.0894631 Test Loss: 0.1140021\n",
      "Validation loss decreased (0.091698 --> 0.089463).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889462\n",
      "\tspeed: 0.0497s/iter; left time: 1047.7245s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896733\n",
      "\tspeed: 0.0224s/iter; left time: 470.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 223 | Train Loss: 0.0908899 Vali Loss: 0.0876844 Test Loss: 0.1145647\n",
      "Validation loss decreased (0.089463 --> 0.087684).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891580\n",
      "\tspeed: 0.0533s/iter; left time: 1111.7686s\n",
      "\titers: 200, epoch: 7 | loss: 0.0899919\n",
      "\tspeed: 0.0239s/iter; left time: 496.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 223 | Train Loss: 0.0894373 Vali Loss: 0.0871091 Test Loss: 0.1139508\n",
      "Validation loss decreased (0.087684 --> 0.087109).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847955\n",
      "\tspeed: 0.0504s/iter; left time: 1041.1489s\n",
      "\titers: 200, epoch: 8 | loss: 0.0884005\n",
      "\tspeed: 0.0227s/iter; left time: 465.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0885475 Vali Loss: 0.0869177 Test Loss: 0.1149949\n",
      "Validation loss decreased (0.087109 --> 0.086918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0868295\n",
      "\tspeed: 0.0497s/iter; left time: 1013.7421s\n",
      "\titers: 200, epoch: 9 | loss: 0.0845316\n",
      "\tspeed: 0.0223s/iter; left time: 453.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0875132 Vali Loss: 0.0869876 Test Loss: 0.1171902\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0868861\n",
      "\tspeed: 0.0479s/iter; left time: 968.2232s\n",
      "\titers: 200, epoch: 10 | loss: 0.0906792\n",
      "\tspeed: 0.0224s/iter; left time: 450.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0868785 Vali Loss: 0.0860478 Test Loss: 0.1130730\n",
      "Validation loss decreased (0.086918 --> 0.086048).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0893267\n",
      "\tspeed: 0.0551s/iter; left time: 1100.3981s\n",
      "\titers: 200, epoch: 11 | loss: 0.0827111\n",
      "\tspeed: 0.0225s/iter; left time: 447.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 223 | Train Loss: 0.0865897 Vali Loss: 0.0860126 Test Loss: 0.1144221\n",
      "Validation loss decreased (0.086048 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819745\n",
      "\tspeed: 0.0489s/iter; left time: 965.6123s\n",
      "\titers: 200, epoch: 12 | loss: 0.0886843\n",
      "\tspeed: 0.0222s/iter; left time: 436.0645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0861147 Vali Loss: 0.0857337 Test Loss: 0.1126444\n",
      "Validation loss decreased (0.086013 --> 0.085734).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0843310\n",
      "\tspeed: 0.0553s/iter; left time: 1079.3323s\n",
      "\titers: 200, epoch: 13 | loss: 0.0851573\n",
      "\tspeed: 0.0231s/iter; left time: 448.3385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0857890 Vali Loss: 0.0853501 Test Loss: 0.1129777\n",
      "Validation loss decreased (0.085734 --> 0.085350).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0846311\n",
      "\tspeed: 0.0493s/iter; left time: 950.8982s\n",
      "\titers: 200, epoch: 14 | loss: 0.0863972\n",
      "\tspeed: 0.0242s/iter; left time: 464.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0853135 Vali Loss: 0.0860326 Test Loss: 0.1155821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0844489\n",
      "\tspeed: 0.0499s/iter; left time: 952.9456s\n",
      "\titers: 200, epoch: 15 | loss: 0.0898472\n",
      "\tspeed: 0.0225s/iter; left time: 427.5287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0852884 Vali Loss: 0.0856989 Test Loss: 0.1137507\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0848589\n",
      "\tspeed: 0.0483s/iter; left time: 910.1439s\n",
      "\titers: 200, epoch: 16 | loss: 0.0860770\n",
      "\tspeed: 0.0226s/iter; left time: 423.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0849384 Vali Loss: 0.0850861 Test Loss: 0.1144261\n",
      "Validation loss decreased (0.085350 --> 0.085086).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0846847\n",
      "\tspeed: 0.0565s/iter; left time: 1052.6888s\n",
      "\titers: 200, epoch: 17 | loss: 0.0837189\n",
      "\tspeed: 0.0240s/iter; left time: 445.4024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0848462 Vali Loss: 0.0850919 Test Loss: 0.1139559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0814941\n",
      "\tspeed: 0.0479s/iter; left time: 881.4486s\n",
      "\titers: 200, epoch: 18 | loss: 0.0866240\n",
      "\tspeed: 0.0223s/iter; left time: 408.2574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0844770 Vali Loss: 0.0848956 Test Loss: 0.1148819\n",
      "Validation loss decreased (0.085086 --> 0.084896).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0841063\n",
      "\tspeed: 0.0483s/iter; left time: 879.1632s\n",
      "\titers: 200, epoch: 19 | loss: 0.0829668\n",
      "\tspeed: 0.0224s/iter; left time: 405.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0844081 Vali Loss: 0.0847860 Test Loss: 0.1142331\n",
      "Validation loss decreased (0.084896 --> 0.084786).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0865711\n",
      "\tspeed: 0.0506s/iter; left time: 909.8474s\n",
      "\titers: 200, epoch: 20 | loss: 0.0815339\n",
      "\tspeed: 0.0223s/iter; left time: 399.0772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0839790 Vali Loss: 0.0844200 Test Loss: 0.1142257\n",
      "Validation loss decreased (0.084786 --> 0.084420).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0841301\n",
      "\tspeed: 0.0494s/iter; left time: 875.8635s\n",
      "\titers: 200, epoch: 21 | loss: 0.0852435\n",
      "\tspeed: 0.0231s/iter; left time: 407.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0840244 Vali Loss: 0.0848042 Test Loss: 0.1145657\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0834487\n",
      "\tspeed: 0.0482s/iter; left time: 845.0994s\n",
      "\titers: 200, epoch: 22 | loss: 0.0854497\n",
      "\tspeed: 0.0223s/iter; left time: 389.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0837983 Vali Loss: 0.0846703 Test Loss: 0.1149464\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0797565\n",
      "\tspeed: 0.0477s/iter; left time: 825.1302s\n",
      "\titers: 200, epoch: 23 | loss: 0.0886405\n",
      "\tspeed: 0.0224s/iter; left time: 385.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0837015 Vali Loss: 0.0848153 Test Loss: 0.1154751\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0827907\n",
      "\tspeed: 0.0478s/iter; left time: 816.5478s\n",
      "\titers: 200, epoch: 24 | loss: 0.0804853\n",
      "\tspeed: 0.0226s/iter; left time: 382.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0839030 Vali Loss: 0.0849845 Test Loss: 0.1162583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0866296\n",
      "\tspeed: 0.0497s/iter; left time: 836.9247s\n",
      "\titers: 200, epoch: 25 | loss: 0.0841012\n",
      "\tspeed: 0.0224s/iter; left time: 375.5985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0836358 Vali Loss: 0.0844903 Test Loss: 0.1157465\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0883430\n",
      "\tspeed: 0.0474s/iter; left time: 788.5813s\n",
      "\titers: 200, epoch: 26 | loss: 0.0811828\n",
      "\tspeed: 0.0223s/iter; left time: 368.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0834041 Vali Loss: 0.0847251 Test Loss: 0.1161266\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0818763\n",
      "\tspeed: 0.0496s/iter; left time: 814.0956s\n",
      "\titers: 200, epoch: 27 | loss: 0.0849266\n",
      "\tspeed: 0.0223s/iter; left time: 363.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0833626 Vali Loss: 0.0846412 Test Loss: 0.1157158\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0802514\n",
      "\tspeed: 0.0506s/iter; left time: 818.3934s\n",
      "\titers: 200, epoch: 28 | loss: 0.0816113\n",
      "\tspeed: 0.0223s/iter; left time: 357.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0832860 Vali Loss: 0.0843503 Test Loss: 0.1161194\n",
      "Validation loss decreased (0.084420 --> 0.084350).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0844431\n",
      "\tspeed: 0.0479s/iter; left time: 764.9561s\n",
      "\titers: 200, epoch: 29 | loss: 0.0873203\n",
      "\tspeed: 0.0225s/iter; left time: 356.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0833549 Vali Loss: 0.0845832 Test Loss: 0.1168200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0824091\n",
      "\tspeed: 0.0488s/iter; left time: 768.5213s\n",
      "\titers: 200, epoch: 30 | loss: 0.0861688\n",
      "\tspeed: 0.0222s/iter; left time: 347.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0833028 Vali Loss: 0.0843686 Test Loss: 0.1156648\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0835953\n",
      "\tspeed: 0.0486s/iter; left time: 753.5353s\n",
      "\titers: 200, epoch: 31 | loss: 0.0814292\n",
      "\tspeed: 0.0222s/iter; left time: 341.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0834859 Vali Loss: 0.0845277 Test Loss: 0.1161598\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0804389\n",
      "\tspeed: 0.0486s/iter; left time: 743.0883s\n",
      "\titers: 200, epoch: 32 | loss: 0.0855126\n",
      "\tspeed: 0.0222s/iter; left time: 337.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0831986 Vali Loss: 0.0842656 Test Loss: 0.1159719\n",
      "Validation loss decreased (0.084350 --> 0.084266).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0863953\n",
      "\tspeed: 0.0501s/iter; left time: 755.2867s\n",
      "\titers: 200, epoch: 33 | loss: 0.0838326\n",
      "\tspeed: 0.0225s/iter; left time: 337.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0831748 Vali Loss: 0.0843822 Test Loss: 0.1160463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0808025\n",
      "\tspeed: 0.0488s/iter; left time: 723.9458s\n",
      "\titers: 200, epoch: 34 | loss: 0.0868584\n",
      "\tspeed: 0.0222s/iter; left time: 327.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0830420 Vali Loss: 0.0843849 Test Loss: 0.1160896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0853546\n",
      "\tspeed: 0.0518s/iter; left time: 757.0629s\n",
      "\titers: 200, epoch: 35 | loss: 0.0830138\n",
      "\tspeed: 0.0222s/iter; left time: 322.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0830166 Vali Loss: 0.0843050 Test Loss: 0.1160584\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0823329\n",
      "\tspeed: 0.0482s/iter; left time: 694.5629s\n",
      "\titers: 200, epoch: 36 | loss: 0.0845633\n",
      "\tspeed: 0.0257s/iter; left time: 367.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0828777 Vali Loss: 0.0842713 Test Loss: 0.1163082\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0866595\n",
      "\tspeed: 0.0486s/iter; left time: 688.7751s\n",
      "\titers: 200, epoch: 37 | loss: 0.0826903\n",
      "\tspeed: 0.0221s/iter; left time: 311.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0829554 Vali Loss: 0.0842408 Test Loss: 0.1162088\n",
      "Validation loss decreased (0.084266 --> 0.084241).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0889198\n",
      "\tspeed: 0.0496s/iter; left time: 691.4277s\n",
      "\titers: 200, epoch: 38 | loss: 0.0815963\n",
      "\tspeed: 0.0222s/iter; left time: 307.7284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0829357 Vali Loss: 0.0841646 Test Loss: 0.1161689\n",
      "Validation loss decreased (0.084241 --> 0.084165).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0819173\n",
      "\tspeed: 0.0512s/iter; left time: 703.1885s\n",
      "\titers: 200, epoch: 39 | loss: 0.0850061\n",
      "\tspeed: 0.0226s/iter; left time: 307.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0829882 Vali Loss: 0.0842645 Test Loss: 0.1162499\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0827347\n",
      "\tspeed: 0.0531s/iter; left time: 716.7213s\n",
      "\titers: 200, epoch: 40 | loss: 0.0846230\n",
      "\tspeed: 0.0294s/iter; left time: 393.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0829915 Vali Loss: 0.0842339 Test Loss: 0.1159945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0837643\n",
      "\tspeed: 0.0528s/iter; left time: 701.2124s\n",
      "\titers: 200, epoch: 41 | loss: 0.0824249\n",
      "\tspeed: 0.0223s/iter; left time: 293.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0831939 Vali Loss: 0.0841574 Test Loss: 0.1158621\n",
      "Validation loss decreased (0.084165 --> 0.084157).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0813586\n",
      "\tspeed: 0.0645s/iter; left time: 841.7738s\n",
      "\titers: 200, epoch: 42 | loss: 0.0813456\n",
      "\tspeed: 0.0522s/iter; left time: 675.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0828358 Vali Loss: 0.0843383 Test Loss: 0.1163305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0834796\n",
      "\tspeed: 0.0476s/iter; left time: 611.0854s\n",
      "\titers: 200, epoch: 43 | loss: 0.0813733\n",
      "\tspeed: 0.0222s/iter; left time: 283.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0828592 Vali Loss: 0.0841866 Test Loss: 0.1161202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0799217\n",
      "\tspeed: 0.0475s/iter; left time: 599.0262s\n",
      "\titers: 200, epoch: 44 | loss: 0.0826981\n",
      "\tspeed: 0.0225s/iter; left time: 281.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0829095 Vali Loss: 0.0844392 Test Loss: 0.1166744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0829774\n",
      "\tspeed: 0.0499s/iter; left time: 617.8617s\n",
      "\titers: 200, epoch: 45 | loss: 0.0829286\n",
      "\tspeed: 0.0230s/iter; left time: 282.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0828461 Vali Loss: 0.0842382 Test Loss: 0.1163864\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0839270\n",
      "\tspeed: 0.0484s/iter; left time: 588.6365s\n",
      "\titers: 200, epoch: 46 | loss: 0.0843543\n",
      "\tspeed: 0.0222s/iter; left time: 267.8328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0828379 Vali Loss: 0.0842043 Test Loss: 0.1163348\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0796322\n",
      "\tspeed: 0.0479s/iter; left time: 571.5518s\n",
      "\titers: 200, epoch: 47 | loss: 0.0834307\n",
      "\tspeed: 0.0223s/iter; left time: 264.0966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0827978 Vali Loss: 0.0841979 Test Loss: 0.1164009\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0844782\n",
      "\tspeed: 0.0476s/iter; left time: 557.8686s\n",
      "\titers: 200, epoch: 48 | loss: 0.0807830\n",
      "\tspeed: 0.0223s/iter; left time: 259.4295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0831386 Vali Loss: 0.0842695 Test Loss: 0.1163612\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0842269\n",
      "\tspeed: 0.0498s/iter; left time: 572.5881s\n",
      "\titers: 200, epoch: 49 | loss: 0.0786305\n",
      "\tspeed: 0.0222s/iter; left time: 253.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0828130 Vali Loss: 0.0842645 Test Loss: 0.1165766\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0851781\n",
      "\tspeed: 0.0495s/iter; left time: 558.0791s\n",
      "\titers: 200, epoch: 50 | loss: 0.0817751\n",
      "\tspeed: 0.0230s/iter; left time: 256.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0828581 Vali Loss: 0.0842051 Test Loss: 0.1164734\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0830675\n",
      "\tspeed: 0.2006s/iter; left time: 2217.0376s\n",
      "\titers: 200, epoch: 51 | loss: 0.0815906\n",
      "\tspeed: 0.0762s/iter; left time: 834.6704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:16.45s\n",
      "Steps: 223 | Train Loss: 0.0828718 Vali Loss: 0.0843836 Test Loss: 0.1167695\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03044012002646923, rmse:0.17447097599506378, mae:0.11586214601993561, rse:0.5125800371170044\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2715008\n",
      "\tspeed: 0.1322s/iter; left time: 2934.7063s\n",
      "\titers: 200, epoch: 1 | loss: 0.2621438\n",
      "\tspeed: 0.0609s/iter; left time: 1344.9514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:19.87s\n",
      "Steps: 223 | Train Loss: 0.2808324 Vali Loss: 0.2086999 Test Loss: 0.2318538\n",
      "Validation loss decreased (inf --> 0.208700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1406341\n",
      "\tspeed: 0.2592s/iter; left time: 5696.8053s\n",
      "\titers: 200, epoch: 2 | loss: 0.1156944\n",
      "\tspeed: 0.0643s/iter; left time: 1405.8682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.57s\n",
      "Steps: 223 | Train Loss: 0.1531506 Vali Loss: 0.1074509 Test Loss: 0.1221174\n",
      "Validation loss decreased (0.208700 --> 0.107451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1058786\n",
      "\tspeed: 0.1348s/iter; left time: 2933.1687s\n",
      "\titers: 200, epoch: 3 | loss: 0.0988292\n",
      "\tspeed: 0.1439s/iter; left time: 3115.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 223 | Train Loss: 0.1088643 Vali Loss: 0.0949075 Test Loss: 0.1160958\n",
      "Validation loss decreased (0.107451 --> 0.094908).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1014423\n",
      "\tspeed: 0.3017s/iter; left time: 6495.2209s\n",
      "\titers: 200, epoch: 4 | loss: 0.1010499\n",
      "\tspeed: 0.0652s/iter; left time: 1396.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.09s\n",
      "Steps: 223 | Train Loss: 0.0973781 Vali Loss: 0.0909562 Test Loss: 0.1235237\n",
      "Validation loss decreased (0.094908 --> 0.090956).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0913087\n",
      "\tspeed: 0.5496s/iter; left time: 11710.6381s\n",
      "\titers: 200, epoch: 5 | loss: 0.0929417\n",
      "\tspeed: 0.1961s/iter; left time: 4158.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.12s\n",
      "Steps: 223 | Train Loss: 0.0935050 Vali Loss: 0.0888496 Test Loss: 0.1242957\n",
      "Validation loss decreased (0.090956 --> 0.088850).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0904964\n",
      "\tspeed: 0.0885s/iter; left time: 1866.7655s\n",
      "\titers: 200, epoch: 6 | loss: 0.0928248\n",
      "\tspeed: 0.0251s/iter; left time: 526.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 223 | Train Loss: 0.0909621 Vali Loss: 0.0874295 Test Loss: 0.1247244\n",
      "Validation loss decreased (0.088850 --> 0.087430).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0912138\n",
      "\tspeed: 0.0999s/iter; left time: 2083.5726s\n",
      "\titers: 200, epoch: 7 | loss: 0.0925503\n",
      "\tspeed: 0.0225s/iter; left time: 467.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0895669 Vali Loss: 0.0888368 Test Loss: 0.1265373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0887621\n",
      "\tspeed: 0.0500s/iter; left time: 1031.3246s\n",
      "\titers: 200, epoch: 8 | loss: 0.0896031\n",
      "\tspeed: 0.0227s/iter; left time: 466.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0887712 Vali Loss: 0.0872580 Test Loss: 0.1197735\n",
      "Validation loss decreased (0.087430 --> 0.087258).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0878859\n",
      "\tspeed: 0.1417s/iter; left time: 2893.6165s\n",
      "\titers: 200, epoch: 9 | loss: 0.0869749\n",
      "\tspeed: 0.1261s/iter; left time: 2562.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.34s\n",
      "Steps: 223 | Train Loss: 0.0885864 Vali Loss: 0.0871530 Test Loss: 0.1097007\n",
      "Validation loss decreased (0.087258 --> 0.087153).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920990\n",
      "\tspeed: 0.4117s/iter; left time: 8313.3375s\n",
      "\titers: 200, epoch: 10 | loss: 0.0847813\n",
      "\tspeed: 0.0643s/iter; left time: 1292.6056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:20.84s\n",
      "Steps: 223 | Train Loss: 0.0876953 Vali Loss: 0.0861443 Test Loss: 0.1178766\n",
      "Validation loss decreased (0.087153 --> 0.086144).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0869060\n",
      "\tspeed: 0.0616s/iter; left time: 1230.3363s\n",
      "\titers: 200, epoch: 11 | loss: 0.0855299\n",
      "\tspeed: 0.0226s/iter; left time: 449.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 223 | Train Loss: 0.0868600 Vali Loss: 0.0855552 Test Loss: 0.1193667\n",
      "Validation loss decreased (0.086144 --> 0.085555).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883427\n",
      "\tspeed: 0.0520s/iter; left time: 1025.9397s\n",
      "\titers: 200, epoch: 12 | loss: 0.0818175\n",
      "\tspeed: 0.0251s/iter; left time: 493.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 223 | Train Loss: 0.0862828 Vali Loss: 0.0857884 Test Loss: 0.1194353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0862641\n",
      "\tspeed: 0.0536s/iter; left time: 1046.7910s\n",
      "\titers: 200, epoch: 13 | loss: 0.0857989\n",
      "\tspeed: 0.0225s/iter; left time: 436.4858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0859228 Vali Loss: 0.0854638 Test Loss: 0.1165428\n",
      "Validation loss decreased (0.085555 --> 0.085464).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894362\n",
      "\tspeed: 0.0544s/iter; left time: 1050.1561s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860724\n",
      "\tspeed: 0.0231s/iter; left time: 443.7900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0854616 Vali Loss: 0.0857663 Test Loss: 0.1200690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0831092\n",
      "\tspeed: 0.0529s/iter; left time: 1008.9988s\n",
      "\titers: 200, epoch: 15 | loss: 0.0876814\n",
      "\tspeed: 0.0223s/iter; left time: 424.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 223 | Train Loss: 0.0851888 Vali Loss: 0.0851492 Test Loss: 0.1212800\n",
      "Validation loss decreased (0.085464 --> 0.085149).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0824745\n",
      "\tspeed: 0.0579s/iter; left time: 1092.1405s\n",
      "\titers: 200, epoch: 16 | loss: 0.0850440\n",
      "\tspeed: 0.0231s/iter; left time: 432.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 223 | Train Loss: 0.0849335 Vali Loss: 0.0852520 Test Loss: 0.1180814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0832800\n",
      "\tspeed: 0.0563s/iter; left time: 1048.4469s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843466\n",
      "\tspeed: 0.0222s/iter; left time: 411.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0846814 Vali Loss: 0.0847475 Test Loss: 0.1196820\n",
      "Validation loss decreased (0.085149 --> 0.084747).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0875870\n",
      "\tspeed: 0.0528s/iter; left time: 972.4698s\n",
      "\titers: 200, epoch: 18 | loss: 0.0847477\n",
      "\tspeed: 0.0227s/iter; left time: 415.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 223 | Train Loss: 0.0846317 Vali Loss: 0.0845270 Test Loss: 0.1162244\n",
      "Validation loss decreased (0.084747 --> 0.084527).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0821703\n",
      "\tspeed: 0.0538s/iter; left time: 977.5800s\n",
      "\titers: 200, epoch: 19 | loss: 0.0849935\n",
      "\tspeed: 0.0241s/iter; left time: 436.3318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0844657 Vali Loss: 0.0848649 Test Loss: 0.1194516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802291\n",
      "\tspeed: 0.0530s/iter; left time: 951.7404s\n",
      "\titers: 200, epoch: 20 | loss: 0.0800778\n",
      "\tspeed: 0.0249s/iter; left time: 445.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0844274 Vali Loss: 0.0844849 Test Loss: 0.1150948\n",
      "Validation loss decreased (0.084527 --> 0.084485).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0838399\n",
      "\tspeed: 0.0517s/iter; left time: 916.3918s\n",
      "\titers: 200, epoch: 21 | loss: 0.0823502\n",
      "\tspeed: 0.0226s/iter; left time: 399.2700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0842312 Vali Loss: 0.0847522 Test Loss: 0.1175591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0856613\n",
      "\tspeed: 0.0488s/iter; left time: 854.5653s\n",
      "\titers: 200, epoch: 22 | loss: 0.0827729\n",
      "\tspeed: 0.0223s/iter; left time: 388.1163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0838928 Vali Loss: 0.0850711 Test Loss: 0.1228586\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0865541\n",
      "\tspeed: 0.0483s/iter; left time: 835.5106s\n",
      "\titers: 200, epoch: 23 | loss: 0.0829072\n",
      "\tspeed: 0.0227s/iter; left time: 389.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0838293 Vali Loss: 0.0848606 Test Loss: 0.1205242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0785990\n",
      "\tspeed: 0.0519s/iter; left time: 885.1978s\n",
      "\titers: 200, epoch: 24 | loss: 0.0821744\n",
      "\tspeed: 0.0229s/iter; left time: 388.0422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0838091 Vali Loss: 0.0847127 Test Loss: 0.1159968\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0839403\n",
      "\tspeed: 0.0509s/iter; left time: 857.8227s\n",
      "\titers: 200, epoch: 25 | loss: 0.0832041\n",
      "\tspeed: 0.0250s/iter; left time: 418.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0836742 Vali Loss: 0.0844283 Test Loss: 0.1181025\n",
      "Validation loss decreased (0.084485 --> 0.084428).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0831596\n",
      "\tspeed: 0.0534s/iter; left time: 888.6234s\n",
      "\titers: 200, epoch: 26 | loss: 0.0861969\n",
      "\tspeed: 0.0224s/iter; left time: 370.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0835499 Vali Loss: 0.0844193 Test Loss: 0.1213674\n",
      "Validation loss decreased (0.084428 --> 0.084419).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0881168\n",
      "\tspeed: 0.0525s/iter; left time: 860.5811s\n",
      "\titers: 200, epoch: 27 | loss: 0.0837724\n",
      "\tspeed: 0.0236s/iter; left time: 383.9791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 223 | Train Loss: 0.0837224 Vali Loss: 0.0842958 Test Loss: 0.1159074\n",
      "Validation loss decreased (0.084419 --> 0.084296).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0820167\n",
      "\tspeed: 0.0514s/iter; left time: 831.9788s\n",
      "\titers: 200, epoch: 28 | loss: 0.0854088\n",
      "\tspeed: 0.0245s/iter; left time: 393.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0835717 Vali Loss: 0.0845032 Test Loss: 0.1200302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0830966\n",
      "\tspeed: 0.0545s/iter; left time: 868.8940s\n",
      "\titers: 200, epoch: 29 | loss: 0.0786469\n",
      "\tspeed: 0.0231s/iter; left time: 365.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 223 | Train Loss: 0.0833944 Vali Loss: 0.0842272 Test Loss: 0.1198121\n",
      "Validation loss decreased (0.084296 --> 0.084227).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0836487\n",
      "\tspeed: 0.0508s/iter; left time: 799.3045s\n",
      "\titers: 200, epoch: 30 | loss: 0.0803401\n",
      "\tspeed: 0.0227s/iter; left time: 355.5918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0832734 Vali Loss: 0.0841208 Test Loss: 0.1173771\n",
      "Validation loss decreased (0.084227 --> 0.084121).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0809827\n",
      "\tspeed: 0.0552s/iter; left time: 856.9800s\n",
      "\titers: 200, epoch: 31 | loss: 0.0842370\n",
      "\tspeed: 0.0224s/iter; left time: 345.0817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0834217 Vali Loss: 0.0842179 Test Loss: 0.1186745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0793326\n",
      "\tspeed: 0.0529s/iter; left time: 808.4634s\n",
      "\titers: 200, epoch: 32 | loss: 0.0811508\n",
      "\tspeed: 0.0222s/iter; left time: 336.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0832636 Vali Loss: 0.0842897 Test Loss: 0.1188567\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0806536\n",
      "\tspeed: 0.0509s/iter; left time: 766.1664s\n",
      "\titers: 200, epoch: 33 | loss: 0.0816683\n",
      "\tspeed: 0.0222s/iter; left time: 332.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 223 | Train Loss: 0.0832670 Vali Loss: 0.0839720 Test Loss: 0.1184661\n",
      "Validation loss decreased (0.084121 --> 0.083972).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0836224\n",
      "\tspeed: 0.0505s/iter; left time: 750.1474s\n",
      "\titers: 200, epoch: 34 | loss: 0.0844120\n",
      "\tspeed: 0.0331s/iter; left time: 487.6187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0832786 Vali Loss: 0.0840682 Test Loss: 0.1174169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0817028\n",
      "\tspeed: 0.0497s/iter; left time: 725.9847s\n",
      "\titers: 200, epoch: 35 | loss: 0.0823539\n",
      "\tspeed: 0.0226s/iter; left time: 327.6722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0832299 Vali Loss: 0.0841118 Test Loss: 0.1174949\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0829380\n",
      "\tspeed: 0.0514s/iter; left time: 740.4531s\n",
      "\titers: 200, epoch: 36 | loss: 0.0796161\n",
      "\tspeed: 0.0222s/iter; left time: 317.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0831137 Vali Loss: 0.0840316 Test Loss: 0.1187578\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0838125\n",
      "\tspeed: 0.0490s/iter; left time: 694.3179s\n",
      "\titers: 200, epoch: 37 | loss: 0.0850530\n",
      "\tspeed: 0.0221s/iter; left time: 311.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0831243 Vali Loss: 0.0842547 Test Loss: 0.1187132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0824745\n",
      "\tspeed: 0.0544s/iter; left time: 759.1829s\n",
      "\titers: 200, epoch: 38 | loss: 0.0825395\n",
      "\tspeed: 0.0223s/iter; left time: 309.4850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0831444 Vali Loss: 0.0838713 Test Loss: 0.1173147\n",
      "Validation loss decreased (0.083972 --> 0.083871).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0854075\n",
      "\tspeed: 0.0507s/iter; left time: 696.3349s\n",
      "\titers: 200, epoch: 39 | loss: 0.0816420\n",
      "\tspeed: 0.0221s/iter; left time: 301.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0832312 Vali Loss: 0.0839343 Test Loss: 0.1172149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0818202\n",
      "\tspeed: 0.0486s/iter; left time: 656.5611s\n",
      "\titers: 200, epoch: 40 | loss: 0.0884314\n",
      "\tspeed: 0.0496s/iter; left time: 664.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:10.72s\n",
      "Steps: 223 | Train Loss: 0.0831206 Vali Loss: 0.0842566 Test Loss: 0.1184728\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0827821\n",
      "\tspeed: 0.3016s/iter; left time: 4005.2421s\n",
      "\titers: 200, epoch: 41 | loss: 0.0795763\n",
      "\tspeed: 0.1308s/iter; left time: 1723.4482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:27.43s\n",
      "Steps: 223 | Train Loss: 0.0830118 Vali Loss: 0.0839769 Test Loss: 0.1194157\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0845354\n",
      "\tspeed: 0.4657s/iter; left time: 6081.2555s\n",
      "\titers: 200, epoch: 42 | loss: 0.0829298\n",
      "\tspeed: 0.1514s/iter; left time: 1962.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:34.61s\n",
      "Steps: 223 | Train Loss: 0.0831070 Vali Loss: 0.0840556 Test Loss: 0.1188590\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0832543\n",
      "\tspeed: 0.5482s/iter; left time: 7036.5363s\n",
      "\titers: 200, epoch: 43 | loss: 0.0820783\n",
      "\tspeed: 0.1736s/iter; left time: 2210.4139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:39.99s\n",
      "Steps: 223 | Train Loss: 0.0830777 Vali Loss: 0.0838464 Test Loss: 0.1184260\n",
      "Validation loss decreased (0.083871 --> 0.083846).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0821071\n",
      "\tspeed: 0.6737s/iter; left time: 8497.3165s\n",
      "\titers: 200, epoch: 44 | loss: 0.0839722\n",
      "\tspeed: 0.1827s/iter; left time: 2286.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:45.72s\n",
      "Steps: 223 | Train Loss: 0.0830476 Vali Loss: 0.0839466 Test Loss: 0.1192060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0812912\n",
      "\tspeed: 0.6738s/iter; left time: 8347.1780s\n",
      "\titers: 200, epoch: 45 | loss: 0.0849999\n",
      "\tspeed: 0.1873s/iter; left time: 2302.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:43.66s\n",
      "Steps: 223 | Train Loss: 0.0830057 Vali Loss: 0.0840486 Test Loss: 0.1191918\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0830692\n",
      "\tspeed: 0.4021s/iter; left time: 4892.0183s\n",
      "\titers: 200, epoch: 46 | loss: 0.0840345\n",
      "\tspeed: 0.0549s/iter; left time: 662.5758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:13.72s\n",
      "Steps: 223 | Train Loss: 0.0830333 Vali Loss: 0.0838347 Test Loss: 0.1183836\n",
      "Validation loss decreased (0.083846 --> 0.083835).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0855173\n",
      "\tspeed: 0.1588s/iter; left time: 1896.3097s\n",
      "\titers: 200, epoch: 47 | loss: 0.0849277\n",
      "\tspeed: 0.0275s/iter; left time: 325.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 223 | Train Loss: 0.0829685 Vali Loss: 0.0840135 Test Loss: 0.1198245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0814747\n",
      "\tspeed: 0.0665s/iter; left time: 779.0993s\n",
      "\titers: 200, epoch: 48 | loss: 0.0844937\n",
      "\tspeed: 0.0304s/iter; left time: 353.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 223 | Train Loss: 0.0829573 Vali Loss: 0.0838248 Test Loss: 0.1194821\n",
      "Validation loss decreased (0.083835 --> 0.083825).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0810249\n",
      "\tspeed: 0.0561s/iter; left time: 644.4281s\n",
      "\titers: 200, epoch: 49 | loss: 0.0801658\n",
      "\tspeed: 0.0273s/iter; left time: 310.6409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0829287 Vali Loss: 0.0837962 Test Loss: 0.1174986\n",
      "Validation loss decreased (0.083825 --> 0.083796).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0813590\n",
      "\tspeed: 0.0603s/iter; left time: 679.8552s\n",
      "\titers: 200, epoch: 50 | loss: 0.0843758\n",
      "\tspeed: 0.0296s/iter; left time: 330.7794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 223 | Train Loss: 0.0830149 Vali Loss: 0.0839692 Test Loss: 0.1182753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0855806\n",
      "\tspeed: 0.0533s/iter; left time: 588.6377s\n",
      "\titers: 200, epoch: 51 | loss: 0.0813496\n",
      "\tspeed: 0.0228s/iter; left time: 249.4155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 223 | Train Loss: 0.0829588 Vali Loss: 0.0838750 Test Loss: 0.1184985\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0826729\n",
      "\tspeed: 0.0585s/iter; left time: 633.0245s\n",
      "\titers: 200, epoch: 52 | loss: 0.0843770\n",
      "\tspeed: 0.0293s/iter; left time: 314.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 223 | Train Loss: 0.0828833 Vali Loss: 0.0838117 Test Loss: 0.1178757\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0807884\n",
      "\tspeed: 0.0636s/iter; left time: 674.0047s\n",
      "\titers: 200, epoch: 53 | loss: 0.0842347\n",
      "\tspeed: 0.0230s/iter; left time: 241.8009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0829059 Vali Loss: 0.0838893 Test Loss: 0.1188719\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0866821\n",
      "\tspeed: 0.0519s/iter; left time: 538.6363s\n",
      "\titers: 200, epoch: 54 | loss: 0.0871154\n",
      "\tspeed: 0.0256s/iter; left time: 263.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0830573 Vali Loss: 0.0839538 Test Loss: 0.1191130\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0805923\n",
      "\tspeed: 0.0513s/iter; left time: 521.5899s\n",
      "\titers: 200, epoch: 55 | loss: 0.0814596\n",
      "\tspeed: 0.0225s/iter; left time: 226.4621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0829082 Vali Loss: 0.0839973 Test Loss: 0.1191791\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0827185\n",
      "\tspeed: 0.0503s/iter; left time: 500.1209s\n",
      "\titers: 200, epoch: 56 | loss: 0.0800721\n",
      "\tspeed: 0.0239s/iter; left time: 234.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 223 | Train Loss: 0.0829025 Vali Loss: 0.0839681 Test Loss: 0.1191142\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0834955\n",
      "\tspeed: 0.0510s/iter; left time: 495.6749s\n",
      "\titers: 200, epoch: 57 | loss: 0.0855532\n",
      "\tspeed: 0.0250s/iter; left time: 239.9826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0837015 Vali Loss: 0.0841293 Test Loss: 0.1184584\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0803595\n",
      "\tspeed: 0.0519s/iter; left time: 492.5632s\n",
      "\titers: 200, epoch: 58 | loss: 0.0822290\n",
      "\tspeed: 0.0224s/iter; left time: 210.7548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0829205 Vali Loss: 0.0839069 Test Loss: 0.1189180\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0823312\n",
      "\tspeed: 0.0604s/iter; left time: 560.0524s\n",
      "\titers: 200, epoch: 59 | loss: 0.0823177\n",
      "\tspeed: 0.0334s/iter; left time: 306.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 223 | Train Loss: 0.0830652 Vali Loss: 0.0839202 Test Loss: 0.1194182\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03177133947610855, rmse:0.1782451719045639, mae:0.11749859899282455, rse:0.5236682891845703\n",
      "Intermediate time for ES and pred_len 168: 00h:24m:19.95s\n",
      "Intermediate time for ES: 01h:36m:09.35s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2181389\n",
      "\tspeed: 0.0423s/iter; left time: 942.6217s\n",
      "\titers: 200, epoch: 1 | loss: 0.2111445\n",
      "\tspeed: 0.0217s/iter; left time: 482.8121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.2282664 Vali Loss: 0.1756847 Test Loss: 0.1781302\n",
      "Validation loss decreased (inf --> 0.175685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1335730\n",
      "\tspeed: 0.0453s/iter; left time: 1001.1880s\n",
      "\titers: 200, epoch: 2 | loss: 0.1074380\n",
      "\tspeed: 0.0218s/iter; left time: 478.7046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.1404796 Vali Loss: 0.0845311 Test Loss: 0.0938503\n",
      "Validation loss decreased (0.175685 --> 0.084531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853166\n",
      "\tspeed: 0.0509s/iter; left time: 1112.2445s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792229\n",
      "\tspeed: 0.0220s/iter; left time: 479.5260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0880394 Vali Loss: 0.0806688 Test Loss: 0.0855705\n",
      "Validation loss decreased (0.084531 --> 0.080669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731423\n",
      "\tspeed: 0.0498s/iter; left time: 1077.8728s\n",
      "\titers: 200, epoch: 4 | loss: 0.0740642\n",
      "\tspeed: 0.0217s/iter; left time: 467.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0730655 Vali Loss: 0.0691024 Test Loss: 0.0712667\n",
      "Validation loss decreased (0.080669 --> 0.069102).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0754679\n",
      "\tspeed: 0.0524s/iter; left time: 1121.6967s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652138\n",
      "\tspeed: 0.0230s/iter; left time: 489.0386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0662490 Vali Loss: 0.0648778 Test Loss: 0.0669197\n",
      "Validation loss decreased (0.069102 --> 0.064878).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0644869\n",
      "\tspeed: 0.0907s/iter; left time: 1920.4291s\n",
      "\titers: 200, epoch: 6 | loss: 0.0584586\n",
      "\tspeed: 0.0377s/iter; left time: 795.6066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 224 | Train Loss: 0.0622531 Vali Loss: 0.0639652 Test Loss: 0.0666962\n",
      "Validation loss decreased (0.064878 --> 0.063965).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0674949\n",
      "\tspeed: 0.0746s/iter; left time: 1564.1282s\n",
      "\titers: 200, epoch: 7 | loss: 0.0582944\n",
      "\tspeed: 0.0343s/iter; left time: 714.4735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 224 | Train Loss: 0.0588587 Vali Loss: 0.0622077 Test Loss: 0.0646266\n",
      "Validation loss decreased (0.063965 --> 0.062208).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0585581\n",
      "\tspeed: 0.0716s/iter; left time: 1484.8755s\n",
      "\titers: 200, epoch: 8 | loss: 0.0569029\n",
      "\tspeed: 0.0284s/iter; left time: 586.9076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0567618 Vali Loss: 0.0615584 Test Loss: 0.0641556\n",
      "Validation loss decreased (0.062208 --> 0.061558).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0528698\n",
      "\tspeed: 0.0658s/iter; left time: 1349.0457s\n",
      "\titers: 200, epoch: 9 | loss: 0.0579437\n",
      "\tspeed: 0.0720s/iter; left time: 1468.5759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.05s\n",
      "Steps: 224 | Train Loss: 0.0552896 Vali Loss: 0.0615507 Test Loss: 0.0641657\n",
      "Validation loss decreased (0.061558 --> 0.061551).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546288\n",
      "\tspeed: 0.0760s/iter; left time: 1540.8223s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551801\n",
      "\tspeed: 0.0310s/iter; left time: 625.8715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0542231 Vali Loss: 0.0603106 Test Loss: 0.0630094\n",
      "Validation loss decreased (0.061551 --> 0.060311).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0561088\n",
      "\tspeed: 0.1170s/iter; left time: 2347.8200s\n",
      "\titers: 200, epoch: 11 | loss: 0.0542017\n",
      "\tspeed: 0.0373s/iter; left time: 743.6668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.84s\n",
      "Steps: 224 | Train Loss: 0.0536799 Vali Loss: 0.0598929 Test Loss: 0.0625099\n",
      "Validation loss decreased (0.060311 --> 0.059893).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0499799\n",
      "\tspeed: 0.0700s/iter; left time: 1388.2059s\n",
      "\titers: 200, epoch: 12 | loss: 0.0523489\n",
      "\tspeed: 0.0221s/iter; left time: 435.5728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0529196 Vali Loss: 0.0602319 Test Loss: 0.0624424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0491447\n",
      "\tspeed: 0.0902s/iter; left time: 1768.5301s\n",
      "\titers: 200, epoch: 13 | loss: 0.0520317\n",
      "\tspeed: 0.0384s/iter; left time: 748.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0523668 Vali Loss: 0.0609408 Test Loss: 0.0633019\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0507173\n",
      "\tspeed: 0.1209s/iter; left time: 2344.1409s\n",
      "\titers: 200, epoch: 14 | loss: 0.0496766\n",
      "\tspeed: 0.0220s/iter; left time: 423.7006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0524151 Vali Loss: 0.0590211 Test Loss: 0.0615146\n",
      "Validation loss decreased (0.059893 --> 0.059021).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0520709\n",
      "\tspeed: 0.0549s/iter; left time: 1051.5509s\n",
      "\titers: 200, epoch: 15 | loss: 0.0485042\n",
      "\tspeed: 0.0229s/iter; left time: 435.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0517539 Vali Loss: 0.0590966 Test Loss: 0.0613239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0489230\n",
      "\tspeed: 0.0550s/iter; left time: 1041.2109s\n",
      "\titers: 200, epoch: 16 | loss: 0.0493918\n",
      "\tspeed: 0.0219s/iter; left time: 412.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0515838 Vali Loss: 0.0601093 Test Loss: 0.0623992\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0536681\n",
      "\tspeed: 0.2253s/iter; left time: 4217.4673s\n",
      "\titers: 200, epoch: 17 | loss: 0.0495015\n",
      "\tspeed: 0.1086s/iter; left time: 2022.5506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 224 | Train Loss: 0.0510330 Vali Loss: 0.0588917 Test Loss: 0.0610924\n",
      "Validation loss decreased (0.059021 --> 0.058892).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0497430\n",
      "\tspeed: 0.1394s/iter; left time: 2577.6853s\n",
      "\titers: 200, epoch: 18 | loss: 0.0503742\n",
      "\tspeed: 0.0221s/iter; left time: 406.8475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0510123 Vali Loss: 0.0601279 Test Loss: 0.0624680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0476078\n",
      "\tspeed: 0.0588s/iter; left time: 1073.4730s\n",
      "\titers: 200, epoch: 19 | loss: 0.0500075\n",
      "\tspeed: 0.0221s/iter; left time: 401.1010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0507696 Vali Loss: 0.0584594 Test Loss: 0.0606458\n",
      "Validation loss decreased (0.058892 --> 0.058459).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0492038\n",
      "\tspeed: 0.0529s/iter; left time: 954.8555s\n",
      "\titers: 200, epoch: 20 | loss: 0.0507360\n",
      "\tspeed: 0.0225s/iter; left time: 403.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0507538 Vali Loss: 0.0582857 Test Loss: 0.0605878\n",
      "Validation loss decreased (0.058459 --> 0.058286).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0492622\n",
      "\tspeed: 0.0485s/iter; left time: 865.0052s\n",
      "\titers: 200, epoch: 21 | loss: 0.0504524\n",
      "\tspeed: 0.0221s/iter; left time: 391.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0503666 Vali Loss: 0.0579396 Test Loss: 0.0603647\n",
      "Validation loss decreased (0.058286 --> 0.057940).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0513644\n",
      "\tspeed: 0.0503s/iter; left time: 885.3366s\n",
      "\titers: 200, epoch: 22 | loss: 0.0459494\n",
      "\tspeed: 0.0220s/iter; left time: 385.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0505424 Vali Loss: 0.0588128 Test Loss: 0.0610600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0497645\n",
      "\tspeed: 0.0497s/iter; left time: 863.9255s\n",
      "\titers: 200, epoch: 23 | loss: 0.0514681\n",
      "\tspeed: 0.0222s/iter; left time: 383.8841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0502120 Vali Loss: 0.0581234 Test Loss: 0.0604336\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0499401\n",
      "\tspeed: 0.0471s/iter; left time: 808.3519s\n",
      "\titers: 200, epoch: 24 | loss: 0.0499325\n",
      "\tspeed: 0.0221s/iter; left time: 377.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0504926 Vali Loss: 0.0588108 Test Loss: 0.0610789\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0513012\n",
      "\tspeed: 0.0477s/iter; left time: 806.6728s\n",
      "\titers: 200, epoch: 25 | loss: 0.0503770\n",
      "\tspeed: 0.0224s/iter; left time: 377.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0501510 Vali Loss: 0.0581049 Test Loss: 0.0603452\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0496439\n",
      "\tspeed: 0.0503s/iter; left time: 839.3671s\n",
      "\titers: 200, epoch: 26 | loss: 0.0481229\n",
      "\tspeed: 0.0221s/iter; left time: 367.0816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0503726 Vali Loss: 0.0579120 Test Loss: 0.0601472\n",
      "Validation loss decreased (0.057940 --> 0.057912).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0490163\n",
      "\tspeed: 0.0485s/iter; left time: 798.3652s\n",
      "\titers: 200, epoch: 27 | loss: 0.0505212\n",
      "\tspeed: 0.0222s/iter; left time: 363.2949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0496494 Vali Loss: 0.0579971 Test Loss: 0.0603009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0505238\n",
      "\tspeed: 0.0485s/iter; left time: 788.5522s\n",
      "\titers: 200, epoch: 28 | loss: 0.0463742\n",
      "\tspeed: 0.0220s/iter; left time: 354.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0497998 Vali Loss: 0.0577769 Test Loss: 0.0599692\n",
      "Validation loss decreased (0.057912 --> 0.057777).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0504089\n",
      "\tspeed: 0.0482s/iter; left time: 773.2761s\n",
      "\titers: 200, epoch: 29 | loss: 0.0454021\n",
      "\tspeed: 0.0219s/iter; left time: 348.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0504761 Vali Loss: 0.0579274 Test Loss: 0.0602867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0521598\n",
      "\tspeed: 0.0466s/iter; left time: 737.0820s\n",
      "\titers: 200, epoch: 30 | loss: 0.0467220\n",
      "\tspeed: 0.0219s/iter; left time: 344.1073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0495564 Vali Loss: 0.0576815 Test Loss: 0.0600906\n",
      "Validation loss decreased (0.057777 --> 0.057682).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0493723\n",
      "\tspeed: 0.0476s/iter; left time: 741.8108s\n",
      "\titers: 200, epoch: 31 | loss: 0.0491822\n",
      "\tspeed: 0.0218s/iter; left time: 338.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0498529 Vali Loss: 0.0577074 Test Loss: 0.0599608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0486430\n",
      "\tspeed: 0.0493s/iter; left time: 757.3346s\n",
      "\titers: 200, epoch: 32 | loss: 0.0494532\n",
      "\tspeed: 0.0219s/iter; left time: 334.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0496040 Vali Loss: 0.0576057 Test Loss: 0.0598874\n",
      "Validation loss decreased (0.057682 --> 0.057606).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0521381\n",
      "\tspeed: 0.0601s/iter; left time: 909.3992s\n",
      "\titers: 200, epoch: 33 | loss: 0.0496465\n",
      "\tspeed: 0.0224s/iter; left time: 337.4179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0495375 Vali Loss: 0.0575679 Test Loss: 0.0599047\n",
      "Validation loss decreased (0.057606 --> 0.057568).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0495186\n",
      "\tspeed: 0.0554s/iter; left time: 826.2716s\n",
      "\titers: 200, epoch: 34 | loss: 0.0505130\n",
      "\tspeed: 0.0236s/iter; left time: 349.1493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 224 | Train Loss: 0.0494590 Vali Loss: 0.0572821 Test Loss: 0.0598328\n",
      "Validation loss decreased (0.057568 --> 0.057282).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0497583\n",
      "\tspeed: 0.0492s/iter; left time: 722.4498s\n",
      "\titers: 200, epoch: 35 | loss: 0.0494283\n",
      "\tspeed: 0.0230s/iter; left time: 335.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0494937 Vali Loss: 0.0574199 Test Loss: 0.0597772\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0553845\n",
      "\tspeed: 0.0490s/iter; left time: 707.9229s\n",
      "\titers: 200, epoch: 36 | loss: 0.0485990\n",
      "\tspeed: 0.0229s/iter; left time: 328.9182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0494848 Vali Loss: 0.0574528 Test Loss: 0.0598290\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0499468\n",
      "\tspeed: 0.0522s/iter; left time: 743.0099s\n",
      "\titers: 200, epoch: 37 | loss: 0.0467454\n",
      "\tspeed: 0.0217s/iter; left time: 307.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0492623 Vali Loss: 0.0573258 Test Loss: 0.0596462\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0515565\n",
      "\tspeed: 0.0479s/iter; left time: 671.4395s\n",
      "\titers: 200, epoch: 38 | loss: 0.0490454\n",
      "\tspeed: 0.0220s/iter; left time: 306.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0493678 Vali Loss: 0.0575336 Test Loss: 0.0599693\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0484858\n",
      "\tspeed: 0.0518s/iter; left time: 713.7315s\n",
      "\titers: 200, epoch: 39 | loss: 0.0442455\n",
      "\tspeed: 0.0219s/iter; left time: 299.6128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0500937 Vali Loss: 0.0574429 Test Loss: 0.0596627\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0461038\n",
      "\tspeed: 0.1501s/iter; left time: 2036.6287s\n",
      "\titers: 200, epoch: 40 | loss: 0.0503352\n",
      "\tspeed: 0.0849s/iter; left time: 1142.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:19.47s\n",
      "Steps: 224 | Train Loss: 0.0495371 Vali Loss: 0.0574576 Test Loss: 0.0597609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0493464\n",
      "\tspeed: 0.2096s/iter; left time: 2796.4139s\n",
      "\titers: 200, epoch: 41 | loss: 0.0462544\n",
      "\tspeed: 0.0948s/iter; left time: 1255.7473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:21.90s\n",
      "Steps: 224 | Train Loss: 0.0492944 Vali Loss: 0.0575011 Test Loss: 0.0597424\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0488407\n",
      "\tspeed: 0.2330s/iter; left time: 3056.6766s\n",
      "\titers: 200, epoch: 42 | loss: 0.0512784\n",
      "\tspeed: 0.1033s/iter; left time: 1344.6906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:23.84s\n",
      "Steps: 224 | Train Loss: 0.0492729 Vali Loss: 0.0573449 Test Loss: 0.0596914\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0486517\n",
      "\tspeed: 0.2438s/iter; left time: 3143.4189s\n",
      "\titers: 200, epoch: 43 | loss: 0.0475234\n",
      "\tspeed: 0.1096s/iter; left time: 1402.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:25.14s\n",
      "Steps: 224 | Train Loss: 0.0492627 Vali Loss: 0.0573355 Test Loss: 0.0596530\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0479487\n",
      "\tspeed: 0.2491s/iter; left time: 3155.3380s\n",
      "\titers: 200, epoch: 44 | loss: 0.0517511\n",
      "\tspeed: 0.1237s/iter; left time: 1554.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:27.17s\n",
      "Steps: 224 | Train Loss: 0.0493188 Vali Loss: 0.0573661 Test Loss: 0.0596808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010692856274545193, rmse:0.10340626537799835, mae:0.05983283743262291, rse:0.39893850684165955\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2238776\n",
      "\tspeed: 0.1438s/iter; left time: 3207.2239s\n",
      "\titers: 200, epoch: 1 | loss: 0.2199372\n",
      "\tspeed: 0.1348s/iter; left time: 2992.8101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 224 | Train Loss: 0.2308412 Vali Loss: 0.1738702 Test Loss: 0.1778450\n",
      "Validation loss decreased (inf --> 0.173870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1397499\n",
      "\tspeed: 0.3244s/iter; left time: 7160.9088s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070898\n",
      "\tspeed: 0.1510s/iter; left time: 3319.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.76s\n",
      "Steps: 224 | Train Loss: 0.1410326 Vali Loss: 0.0851479 Test Loss: 0.0923280\n",
      "Validation loss decreased (0.173870 --> 0.085148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0844316\n",
      "\tspeed: 0.3156s/iter; left time: 6897.3151s\n",
      "\titers: 200, epoch: 3 | loss: 0.0732632\n",
      "\tspeed: 0.1415s/iter; left time: 3077.3625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.31s\n",
      "Steps: 224 | Train Loss: 0.0857306 Vali Loss: 0.0761224 Test Loss: 0.0807494\n",
      "Validation loss decreased (0.085148 --> 0.076122).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0688671\n",
      "\tspeed: 0.3335s/iter; left time: 7213.9760s\n",
      "\titers: 200, epoch: 4 | loss: 0.0646466\n",
      "\tspeed: 0.1455s/iter; left time: 3133.2291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.94s\n",
      "Steps: 224 | Train Loss: 0.0718340 Vali Loss: 0.0682892 Test Loss: 0.0719383\n",
      "Validation loss decreased (0.076122 --> 0.068289).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639480\n",
      "\tspeed: 0.3358s/iter; left time: 7188.5156s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652785\n",
      "\tspeed: 0.1518s/iter; left time: 3233.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.15s\n",
      "Steps: 224 | Train Loss: 0.0645230 Vali Loss: 0.0651082 Test Loss: 0.0669089\n",
      "Validation loss decreased (0.068289 --> 0.065108).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601370\n",
      "\tspeed: 0.3324s/iter; left time: 7039.5063s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599416\n",
      "\tspeed: 0.1346s/iter; left time: 2837.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.26s\n",
      "Steps: 224 | Train Loss: 0.0609692 Vali Loss: 0.0630643 Test Loss: 0.0658917\n",
      "Validation loss decreased (0.065108 --> 0.063064).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0618367\n",
      "\tspeed: 0.2052s/iter; left time: 4300.7352s\n",
      "\titers: 200, epoch: 7 | loss: 0.0621108\n",
      "\tspeed: 0.0636s/iter; left time: 1325.9109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0583880 Vali Loss: 0.0617803 Test Loss: 0.0647742\n",
      "Validation loss decreased (0.063064 --> 0.061780).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0603552\n",
      "\tspeed: 0.1114s/iter; left time: 2309.3989s\n",
      "\titers: 200, epoch: 8 | loss: 0.0552273\n",
      "\tspeed: 0.0419s/iter; left time: 863.6267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.0570003 Vali Loss: 0.0623857 Test Loss: 0.0651683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0580590\n",
      "\tspeed: 0.0712s/iter; left time: 1460.2524s\n",
      "\titers: 200, epoch: 9 | loss: 0.0558249\n",
      "\tspeed: 0.0222s/iter; left time: 453.6805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0554910 Vali Loss: 0.0606182 Test Loss: 0.0633043\n",
      "Validation loss decreased (0.061780 --> 0.060618).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514987\n",
      "\tspeed: 0.0638s/iter; left time: 1293.4871s\n",
      "\titers: 200, epoch: 10 | loss: 0.0537644\n",
      "\tspeed: 0.0221s/iter; left time: 446.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0547479 Vali Loss: 0.0604669 Test Loss: 0.0629814\n",
      "Validation loss decreased (0.060618 --> 0.060467).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0582203\n",
      "\tspeed: 0.0478s/iter; left time: 959.0280s\n",
      "\titers: 200, epoch: 11 | loss: 0.0510238\n",
      "\tspeed: 0.0227s/iter; left time: 453.8767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0535369 Vali Loss: 0.0600753 Test Loss: 0.0629466\n",
      "Validation loss decreased (0.060467 --> 0.060075).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0497893\n",
      "\tspeed: 0.0474s/iter; left time: 940.1629s\n",
      "\titers: 200, epoch: 12 | loss: 0.0549461\n",
      "\tspeed: 0.0219s/iter; left time: 432.9156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0530421 Vali Loss: 0.0598029 Test Loss: 0.0623554\n",
      "Validation loss decreased (0.060075 --> 0.059803).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0514712\n",
      "\tspeed: 0.0477s/iter; left time: 935.7059s\n",
      "\titers: 200, epoch: 13 | loss: 0.0519583\n",
      "\tspeed: 0.0221s/iter; left time: 431.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0524211 Vali Loss: 0.0599230 Test Loss: 0.0622225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0518662\n",
      "\tspeed: 0.0476s/iter; left time: 923.8851s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576374\n",
      "\tspeed: 0.0220s/iter; left time: 424.1745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0520754 Vali Loss: 0.0591416 Test Loss: 0.0620827\n",
      "Validation loss decreased (0.059803 --> 0.059142).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0500874\n",
      "\tspeed: 0.0512s/iter; left time: 982.1009s\n",
      "\titers: 200, epoch: 15 | loss: 0.0491530\n",
      "\tspeed: 0.0224s/iter; left time: 427.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0517628 Vali Loss: 0.0592827 Test Loss: 0.0617519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0495952\n",
      "\tspeed: 0.0501s/iter; left time: 948.5709s\n",
      "\titers: 200, epoch: 16 | loss: 0.0511160\n",
      "\tspeed: 0.0228s/iter; left time: 429.5733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0511870 Vali Loss: 0.0596020 Test Loss: 0.0618866\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0550806\n",
      "\tspeed: 0.0479s/iter; left time: 896.2188s\n",
      "\titers: 200, epoch: 17 | loss: 0.0539803\n",
      "\tspeed: 0.0220s/iter; left time: 410.0405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0509328 Vali Loss: 0.0591638 Test Loss: 0.0616277\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0543533\n",
      "\tspeed: 0.0487s/iter; left time: 901.1706s\n",
      "\titers: 200, epoch: 18 | loss: 0.0504614\n",
      "\tspeed: 0.0222s/iter; left time: 407.4950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0507323 Vali Loss: 0.0585130 Test Loss: 0.0611160\n",
      "Validation loss decreased (0.059142 --> 0.058513).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0503640\n",
      "\tspeed: 0.0486s/iter; left time: 887.2341s\n",
      "\titers: 200, epoch: 19 | loss: 0.0508841\n",
      "\tspeed: 0.0221s/iter; left time: 401.3528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0505779 Vali Loss: 0.0590454 Test Loss: 0.0613929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0510542\n",
      "\tspeed: 0.0465s/iter; left time: 839.5827s\n",
      "\titers: 200, epoch: 20 | loss: 0.0499415\n",
      "\tspeed: 0.0221s/iter; left time: 396.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0505025 Vali Loss: 0.0584744 Test Loss: 0.0609798\n",
      "Validation loss decreased (0.058513 --> 0.058474).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0507782\n",
      "\tspeed: 0.0488s/iter; left time: 870.1704s\n",
      "\titers: 200, epoch: 21 | loss: 0.0505576\n",
      "\tspeed: 0.0220s/iter; left time: 390.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0504429 Vali Loss: 0.0583836 Test Loss: 0.0609875\n",
      "Validation loss decreased (0.058474 --> 0.058384).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0523653\n",
      "\tspeed: 0.0481s/iter; left time: 846.9052s\n",
      "\titers: 200, epoch: 22 | loss: 0.0506558\n",
      "\tspeed: 0.0226s/iter; left time: 396.1410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0502916 Vali Loss: 0.0587589 Test Loss: 0.0612226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0502890\n",
      "\tspeed: 0.0481s/iter; left time: 835.2881s\n",
      "\titers: 200, epoch: 23 | loss: 0.0524690\n",
      "\tspeed: 0.0222s/iter; left time: 384.0273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0502929 Vali Loss: 0.0581677 Test Loss: 0.0607068\n",
      "Validation loss decreased (0.058384 --> 0.058168).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0478213\n",
      "\tspeed: 0.0486s/iter; left time: 832.8191s\n",
      "\titers: 200, epoch: 24 | loss: 0.0495805\n",
      "\tspeed: 0.0221s/iter; left time: 377.0914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0498449 Vali Loss: 0.0580927 Test Loss: 0.0607255\n",
      "Validation loss decreased (0.058168 --> 0.058093).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0524558\n",
      "\tspeed: 0.0477s/iter; left time: 806.8037s\n",
      "\titers: 200, epoch: 25 | loss: 0.0499604\n",
      "\tspeed: 0.0228s/iter; left time: 383.0036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0496702 Vali Loss: 0.0582178 Test Loss: 0.0607320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0508272\n",
      "\tspeed: 0.0461s/iter; left time: 770.6979s\n",
      "\titers: 200, epoch: 26 | loss: 0.0493832\n",
      "\tspeed: 0.0217s/iter; left time: 359.8553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0496571 Vali Loss: 0.0579094 Test Loss: 0.0605363\n",
      "Validation loss decreased (0.058093 --> 0.057909).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0494116\n",
      "\tspeed: 0.0467s/iter; left time: 769.3822s\n",
      "\titers: 200, epoch: 27 | loss: 0.0470841\n",
      "\tspeed: 0.0268s/iter; left time: 439.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0497032 Vali Loss: 0.0579863 Test Loss: 0.0605785\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0500381\n",
      "\tspeed: 0.0461s/iter; left time: 749.2422s\n",
      "\titers: 200, epoch: 28 | loss: 0.0467145\n",
      "\tspeed: 0.0218s/iter; left time: 352.2999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0495302 Vali Loss: 0.0579791 Test Loss: 0.0605632\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0508404\n",
      "\tspeed: 0.0463s/iter; left time: 741.9473s\n",
      "\titers: 200, epoch: 29 | loss: 0.0487442\n",
      "\tspeed: 0.0220s/iter; left time: 350.8613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0494444 Vali Loss: 0.0576994 Test Loss: 0.0602702\n",
      "Validation loss decreased (0.057909 --> 0.057699).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0509346\n",
      "\tspeed: 0.0515s/iter; left time: 814.2687s\n",
      "\titers: 200, epoch: 30 | loss: 0.0499654\n",
      "\tspeed: 0.0225s/iter; left time: 353.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0495514 Vali Loss: 0.0583604 Test Loss: 0.0607955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0472625\n",
      "\tspeed: 0.0780s/iter; left time: 1214.7451s\n",
      "\titers: 200, epoch: 31 | loss: 0.0488732\n",
      "\tspeed: 0.0458s/iter; left time: 709.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0494602 Vali Loss: 0.0578260 Test Loss: 0.0604986\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0475019\n",
      "\tspeed: 0.0792s/iter; left time: 1215.5292s\n",
      "\titers: 200, epoch: 32 | loss: 0.0472471\n",
      "\tspeed: 0.0284s/iter; left time: 433.4448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0493985 Vali Loss: 0.0577442 Test Loss: 0.0603134\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0515064\n",
      "\tspeed: 0.0815s/iter; left time: 1233.2785s\n",
      "\titers: 200, epoch: 33 | loss: 0.0511645\n",
      "\tspeed: 0.0231s/iter; left time: 347.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0494639 Vali Loss: 0.0578927 Test Loss: 0.0603282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0494170\n",
      "\tspeed: 0.0725s/iter; left time: 1080.9080s\n",
      "\titers: 200, epoch: 34 | loss: 0.0483500\n",
      "\tspeed: 0.0337s/iter; left time: 498.5423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0493969 Vali Loss: 0.0576735 Test Loss: 0.0601843\n",
      "Validation loss decreased (0.057699 --> 0.057674).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0513475\n",
      "\tspeed: 0.0916s/iter; left time: 1345.1856s\n",
      "\titers: 200, epoch: 35 | loss: 0.0497545\n",
      "\tspeed: 0.0492s/iter; left time: 717.5162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:10.88s\n",
      "Steps: 224 | Train Loss: 0.0492897 Vali Loss: 0.0577359 Test Loss: 0.0602614\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0486509\n",
      "\tspeed: 0.0820s/iter; left time: 1186.3009s\n",
      "\titers: 200, epoch: 36 | loss: 0.0486447\n",
      "\tspeed: 0.0324s/iter; left time: 465.2463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0491634 Vali Loss: 0.0581053 Test Loss: 0.0604686\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0504069\n",
      "\tspeed: 0.0544s/iter; left time: 774.4366s\n",
      "\titers: 200, epoch: 37 | loss: 0.0508944\n",
      "\tspeed: 0.0428s/iter; left time: 605.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0493389 Vali Loss: 0.0580694 Test Loss: 0.0605951\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0498142\n",
      "\tspeed: 0.0723s/iter; left time: 1013.6829s\n",
      "\titers: 200, epoch: 38 | loss: 0.0535306\n",
      "\tspeed: 0.0268s/iter; left time: 372.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0491768 Vali Loss: 0.0577984 Test Loss: 0.0603210\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0479649\n",
      "\tspeed: 0.0847s/iter; left time: 1168.4331s\n",
      "\titers: 200, epoch: 39 | loss: 0.0483298\n",
      "\tspeed: 0.0276s/iter; left time: 378.4172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 224 | Train Loss: 0.0491452 Vali Loss: 0.0577033 Test Loss: 0.0602172\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0549906\n",
      "\tspeed: 0.0586s/iter; left time: 794.7912s\n",
      "\titers: 200, epoch: 40 | loss: 0.0484521\n",
      "\tspeed: 0.0221s/iter; left time: 297.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0490414 Vali Loss: 0.0580225 Test Loss: 0.0605082\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0504148\n",
      "\tspeed: 0.0465s/iter; left time: 620.1265s\n",
      "\titers: 200, epoch: 41 | loss: 0.0520856\n",
      "\tspeed: 0.0241s/iter; left time: 318.5056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0492775 Vali Loss: 0.0578421 Test Loss: 0.0602738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0487371\n",
      "\tspeed: 0.0474s/iter; left time: 622.0906s\n",
      "\titers: 200, epoch: 42 | loss: 0.0480233\n",
      "\tspeed: 0.1175s/iter; left time: 1529.3307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:16.71s\n",
      "Steps: 224 | Train Loss: 0.0491841 Vali Loss: 0.0576177 Test Loss: 0.0601421\n",
      "Validation loss decreased (0.057674 --> 0.057618).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0469763\n",
      "\tspeed: 0.1284s/iter; left time: 1655.9647s\n",
      "\titers: 200, epoch: 43 | loss: 0.0462332\n",
      "\tspeed: 0.0224s/iter; left time: 286.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0491818 Vali Loss: 0.0580329 Test Loss: 0.0604734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0474150\n",
      "\tspeed: 0.0534s/iter; left time: 676.8829s\n",
      "\titers: 200, epoch: 44 | loss: 0.0497090\n",
      "\tspeed: 0.0220s/iter; left time: 276.0797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0489806 Vali Loss: 0.0576674 Test Loss: 0.0601253\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0541993\n",
      "\tspeed: 0.0502s/iter; left time: 624.5786s\n",
      "\titers: 200, epoch: 45 | loss: 0.0468344\n",
      "\tspeed: 0.0221s/iter; left time: 273.2984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0491557 Vali Loss: 0.0580009 Test Loss: 0.0605467\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0472145\n",
      "\tspeed: 0.0472s/iter; left time: 576.9023s\n",
      "\titers: 200, epoch: 46 | loss: 0.0499069\n",
      "\tspeed: 0.0230s/iter; left time: 279.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0491439 Vali Loss: 0.0577477 Test Loss: 0.0602472\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0478656\n",
      "\tspeed: 0.0498s/iter; left time: 597.6648s\n",
      "\titers: 200, epoch: 47 | loss: 0.0507970\n",
      "\tspeed: 0.0221s/iter; left time: 263.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0490501 Vali Loss: 0.0577089 Test Loss: 0.0601807\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0484469\n",
      "\tspeed: 0.0489s/iter; left time: 575.4132s\n",
      "\titers: 200, epoch: 48 | loss: 0.0460149\n",
      "\tspeed: 0.0230s/iter; left time: 267.9525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0489795 Vali Loss: 0.0576736 Test Loss: 0.0601960\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0465929\n",
      "\tspeed: 0.0459s/iter; left time: 530.6530s\n",
      "\titers: 200, epoch: 49 | loss: 0.0501260\n",
      "\tspeed: 0.0218s/iter; left time: 249.4104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0489428 Vali Loss: 0.0577261 Test Loss: 0.0603393\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0487732\n",
      "\tspeed: 0.0475s/iter; left time: 537.9460s\n",
      "\titers: 200, epoch: 50 | loss: 0.0506231\n",
      "\tspeed: 0.0223s/iter; left time: 250.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0490604 Vali Loss: 0.0577683 Test Loss: 0.0603072\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0501885\n",
      "\tspeed: 0.0462s/iter; left time: 512.3241s\n",
      "\titers: 200, epoch: 51 | loss: 0.0547067\n",
      "\tspeed: 0.0220s/iter; left time: 241.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0489707 Vali Loss: 0.0577308 Test Loss: 0.0602313\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0481584\n",
      "\tspeed: 0.0483s/iter; left time: 525.2650s\n",
      "\titers: 200, epoch: 52 | loss: 0.0509942\n",
      "\tspeed: 0.0219s/iter; left time: 236.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0489932 Vali Loss: 0.0576674 Test Loss: 0.0601333\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010759114287793636, rmse:0.10372614860534668, mae:0.060142070055007935, rse:0.400172621011734\n",
      "Intermediate time for FR and pred_len 24: 00h:20m:38.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2240245\n",
      "\tspeed: 0.0416s/iter; left time: 927.7392s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113192\n",
      "\tspeed: 0.0222s/iter; left time: 492.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.2283497 Vali Loss: 0.1739580 Test Loss: 0.1797017\n",
      "Validation loss decreased (inf --> 0.173958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1330688\n",
      "\tspeed: 0.0480s/iter; left time: 1060.2614s\n",
      "\titers: 200, epoch: 2 | loss: 0.0952607\n",
      "\tspeed: 0.0221s/iter; left time: 485.5419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.1327202 Vali Loss: 0.0966959 Test Loss: 0.1073981\n",
      "Validation loss decreased (0.173958 --> 0.096696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0883310\n",
      "\tspeed: 0.0488s/iter; left time: 1065.5016s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831665\n",
      "\tspeed: 0.0223s/iter; left time: 485.5828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0886843 Vali Loss: 0.0872609 Test Loss: 0.0957687\n",
      "Validation loss decreased (0.096696 --> 0.087261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0776227\n",
      "\tspeed: 0.0479s/iter; left time: 1036.5109s\n",
      "\titers: 200, epoch: 4 | loss: 0.0792914\n",
      "\tspeed: 0.0221s/iter; left time: 475.1677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0803742 Vali Loss: 0.0814710 Test Loss: 0.0886934\n",
      "Validation loss decreased (0.087261 --> 0.081471).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0765714\n",
      "\tspeed: 0.0479s/iter; left time: 1026.1248s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724871\n",
      "\tspeed: 0.0221s/iter; left time: 470.3463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0753350 Vali Loss: 0.0804394 Test Loss: 0.0878026\n",
      "Validation loss decreased (0.081471 --> 0.080439).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0765132\n",
      "\tspeed: 0.0487s/iter; left time: 1031.2926s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706679\n",
      "\tspeed: 0.0222s/iter; left time: 467.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0723140 Vali Loss: 0.0791895 Test Loss: 0.0866288\n",
      "Validation loss decreased (0.080439 --> 0.079189).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731258\n",
      "\tspeed: 0.0497s/iter; left time: 1040.6166s\n",
      "\titers: 200, epoch: 7 | loss: 0.0666939\n",
      "\tspeed: 0.0220s/iter; left time: 459.8172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0704234 Vali Loss: 0.0786359 Test Loss: 0.0859985\n",
      "Validation loss decreased (0.079189 --> 0.078636).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0726401\n",
      "\tspeed: 0.0489s/iter; left time: 1014.1302s\n",
      "\titers: 200, epoch: 8 | loss: 0.0644573\n",
      "\tspeed: 0.0224s/iter; left time: 462.7235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0691421 Vali Loss: 0.0781973 Test Loss: 0.0847168\n",
      "Validation loss decreased (0.078636 --> 0.078197).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0663860\n",
      "\tspeed: 0.0486s/iter; left time: 997.4943s\n",
      "\titers: 200, epoch: 9 | loss: 0.0692389\n",
      "\tspeed: 0.0222s/iter; left time: 454.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0680945 Vali Loss: 0.0776647 Test Loss: 0.0845357\n",
      "Validation loss decreased (0.078197 --> 0.077665).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0730154\n",
      "\tspeed: 0.0480s/iter; left time: 972.7246s\n",
      "\titers: 200, epoch: 10 | loss: 0.0654681\n",
      "\tspeed: 0.0220s/iter; left time: 444.3771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0673039 Vali Loss: 0.0768565 Test Loss: 0.0839240\n",
      "Validation loss decreased (0.077665 --> 0.076856).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0669478\n",
      "\tspeed: 0.0480s/iter; left time: 963.0611s\n",
      "\titers: 200, epoch: 11 | loss: 0.0670770\n",
      "\tspeed: 0.0221s/iter; left time: 441.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0664055 Vali Loss: 0.0757632 Test Loss: 0.0831133\n",
      "Validation loss decreased (0.076856 --> 0.075763).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0659748\n",
      "\tspeed: 0.0481s/iter; left time: 953.4734s\n",
      "\titers: 200, epoch: 12 | loss: 0.0649201\n",
      "\tspeed: 0.0222s/iter; left time: 437.3905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0657379 Vali Loss: 0.0752631 Test Loss: 0.0824693\n",
      "Validation loss decreased (0.075763 --> 0.075263).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0651626\n",
      "\tspeed: 0.0484s/iter; left time: 948.8708s\n",
      "\titers: 200, epoch: 13 | loss: 0.0642733\n",
      "\tspeed: 0.0222s/iter; left time: 432.8418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0655296 Vali Loss: 0.0755158 Test Loss: 0.0822028\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0641511\n",
      "\tspeed: 0.0487s/iter; left time: 943.4170s\n",
      "\titers: 200, epoch: 14 | loss: 0.0636778\n",
      "\tspeed: 0.0221s/iter; left time: 425.4525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0651803 Vali Loss: 0.0754950 Test Loss: 0.0828709\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597649\n",
      "\tspeed: 0.0469s/iter; left time: 898.3442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0671977\n",
      "\tspeed: 0.0222s/iter; left time: 422.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0648215 Vali Loss: 0.0749222 Test Loss: 0.0825845\n",
      "Validation loss decreased (0.075263 --> 0.074922).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0659904\n",
      "\tspeed: 0.0523s/iter; left time: 991.1458s\n",
      "\titers: 200, epoch: 16 | loss: 0.0663506\n",
      "\tspeed: 0.0221s/iter; left time: 416.5408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0646141 Vali Loss: 0.0747127 Test Loss: 0.0831591\n",
      "Validation loss decreased (0.074922 --> 0.074713).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0635233\n",
      "\tspeed: 0.0477s/iter; left time: 891.9304s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653920\n",
      "\tspeed: 0.0238s/iter; left time: 443.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0646924 Vali Loss: 0.0746150 Test Loss: 0.0824308\n",
      "Validation loss decreased (0.074713 --> 0.074615).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0638666\n",
      "\tspeed: 0.0500s/iter; left time: 924.2424s\n",
      "\titers: 200, epoch: 18 | loss: 0.0626611\n",
      "\tspeed: 0.0232s/iter; left time: 425.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0643123 Vali Loss: 0.0744744 Test Loss: 0.0818504\n",
      "Validation loss decreased (0.074615 --> 0.074474).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0657596\n",
      "\tspeed: 0.0528s/iter; left time: 964.4591s\n",
      "\titers: 200, epoch: 19 | loss: 0.0669883\n",
      "\tspeed: 0.0226s/iter; left time: 410.0647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0640575 Vali Loss: 0.0742902 Test Loss: 0.0825695\n",
      "Validation loss decreased (0.074474 --> 0.074290).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0678251\n",
      "\tspeed: 0.0478s/iter; left time: 862.4559s\n",
      "\titers: 200, epoch: 20 | loss: 0.0647803\n",
      "\tspeed: 0.0220s/iter; left time: 394.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0638947 Vali Loss: 0.0745984 Test Loss: 0.0827921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0684504\n",
      "\tspeed: 0.0480s/iter; left time: 855.8661s\n",
      "\titers: 200, epoch: 21 | loss: 0.0588741\n",
      "\tspeed: 0.0220s/iter; left time: 389.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0638984 Vali Loss: 0.0741406 Test Loss: 0.0819883\n",
      "Validation loss decreased (0.074290 --> 0.074141).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0637087\n",
      "\tspeed: 0.0566s/iter; left time: 995.1361s\n",
      "\titers: 200, epoch: 22 | loss: 0.0690711\n",
      "\tspeed: 0.0263s/iter; left time: 459.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0636500 Vali Loss: 0.0743338 Test Loss: 0.0825969\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0625623\n",
      "\tspeed: 0.2479s/iter; left time: 4306.8308s\n",
      "\titers: 200, epoch: 23 | loss: 0.0641554\n",
      "\tspeed: 0.0849s/iter; left time: 1465.7164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:19.39s\n",
      "Steps: 224 | Train Loss: 0.0634766 Vali Loss: 0.0740194 Test Loss: 0.0820352\n",
      "Validation loss decreased (0.074141 --> 0.074019).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0637390\n",
      "\tspeed: 0.3130s/iter; left time: 5368.1550s\n",
      "\titers: 200, epoch: 24 | loss: 0.0606070\n",
      "\tspeed: 0.1151s/iter; left time: 1961.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:25.51s\n",
      "Steps: 224 | Train Loss: 0.0635890 Vali Loss: 0.0742006 Test Loss: 0.0827429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0633780\n",
      "\tspeed: 0.3987s/iter; left time: 6747.6332s\n",
      "\titers: 200, epoch: 25 | loss: 0.0618385\n",
      "\tspeed: 0.1243s/iter; left time: 2091.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:28.84s\n",
      "Steps: 224 | Train Loss: 0.0633556 Vali Loss: 0.0741020 Test Loss: 0.0825217\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0609069\n",
      "\tspeed: 0.4256s/iter; left time: 7108.2215s\n",
      "\titers: 200, epoch: 26 | loss: 0.0658677\n",
      "\tspeed: 0.1384s/iter; left time: 2298.3380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 224 | Train Loss: 0.0632520 Vali Loss: 0.0740732 Test Loss: 0.0827943\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0617492\n",
      "\tspeed: 0.4468s/iter; left time: 7361.5735s\n",
      "\titers: 200, epoch: 27 | loss: 0.0640935\n",
      "\tspeed: 0.1481s/iter; left time: 2425.4712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:33.53s\n",
      "Steps: 224 | Train Loss: 0.0631660 Vali Loss: 0.0740148 Test Loss: 0.0825152\n",
      "Validation loss decreased (0.074019 --> 0.074015).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0631003\n",
      "\tspeed: 0.5189s/iter; left time: 8432.9106s\n",
      "\titers: 200, epoch: 28 | loss: 0.0642913\n",
      "\tspeed: 0.1586s/iter; left time: 2562.5899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:36.13s\n",
      "Steps: 224 | Train Loss: 0.0631812 Vali Loss: 0.0739217 Test Loss: 0.0823328\n",
      "Validation loss decreased (0.074015 --> 0.073922).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0616707\n",
      "\tspeed: 0.5634s/iter; left time: 9030.5401s\n",
      "\titers: 200, epoch: 29 | loss: 0.0669227\n",
      "\tspeed: 0.1665s/iter; left time: 2651.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 224 | Train Loss: 0.0630494 Vali Loss: 0.0739371 Test Loss: 0.0823464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0641048\n",
      "\tspeed: 0.6002s/iter; left time: 9486.7922s\n",
      "\titers: 200, epoch: 30 | loss: 0.0604357\n",
      "\tspeed: 0.1739s/iter; left time: 2730.5389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:38.86s\n",
      "Steps: 224 | Train Loss: 0.0641775 Vali Loss: 0.0742520 Test Loss: 0.0832336\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0660663\n",
      "\tspeed: 0.6060s/iter; left time: 9442.3751s\n",
      "\titers: 200, epoch: 31 | loss: 0.0622601\n",
      "\tspeed: 0.1706s/iter; left time: 2641.6507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:41.56s\n",
      "Steps: 224 | Train Loss: 0.0630109 Vali Loss: 0.0742410 Test Loss: 0.0831718\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0620665\n",
      "\tspeed: 0.6355s/iter; left time: 9760.0290s\n",
      "\titers: 200, epoch: 32 | loss: 0.0636683\n",
      "\tspeed: 0.1865s/iter; left time: 2844.8022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:41.63s\n",
      "Steps: 224 | Train Loss: 0.0629453 Vali Loss: 0.0737900 Test Loss: 0.0822646\n",
      "Validation loss decreased (0.073922 --> 0.073790).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0630421\n",
      "\tspeed: 0.6778s/iter; left time: 10257.8095s\n",
      "\titers: 200, epoch: 33 | loss: 0.0644787\n",
      "\tspeed: 0.1781s/iter; left time: 2677.0944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:43.01s\n",
      "Steps: 224 | Train Loss: 0.0628614 Vali Loss: 0.0739471 Test Loss: 0.0824428\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0632831\n",
      "\tspeed: 0.5310s/iter; left time: 7916.3074s\n",
      "\titers: 200, epoch: 34 | loss: 0.0623300\n",
      "\tspeed: 0.0778s/iter; left time: 1151.7777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.65s\n",
      "Steps: 224 | Train Loss: 0.0628739 Vali Loss: 0.0739185 Test Loss: 0.0825257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0610376\n",
      "\tspeed: 0.1789s/iter; left time: 2627.0455s\n",
      "\titers: 200, epoch: 35 | loss: 0.0646330\n",
      "\tspeed: 0.0501s/iter; left time: 731.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.30s\n",
      "Steps: 224 | Train Loss: 0.0629654 Vali Loss: 0.0736852 Test Loss: 0.0821136\n",
      "Validation loss decreased (0.073790 --> 0.073685).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0610374\n",
      "\tspeed: 0.0604s/iter; left time: 872.7934s\n",
      "\titers: 200, epoch: 36 | loss: 0.0597058\n",
      "\tspeed: 0.0310s/iter; left time: 445.6185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0628428 Vali Loss: 0.0738940 Test Loss: 0.0824627\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0640828\n",
      "\tspeed: 0.0566s/iter; left time: 806.2312s\n",
      "\titers: 200, epoch: 37 | loss: 0.0630297\n",
      "\tspeed: 0.0232s/iter; left time: 328.6434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0628334 Vali Loss: 0.0740189 Test Loss: 0.0828486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0609034\n",
      "\tspeed: 0.0522s/iter; left time: 731.2162s\n",
      "\titers: 200, epoch: 38 | loss: 0.0641180\n",
      "\tspeed: 0.0223s/iter; left time: 310.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0628331 Vali Loss: 0.0738035 Test Loss: 0.0823092\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0585223\n",
      "\tspeed: 0.0503s/iter; left time: 694.1082s\n",
      "\titers: 200, epoch: 39 | loss: 0.0686546\n",
      "\tspeed: 0.0221s/iter; left time: 303.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0627320 Vali Loss: 0.0737875 Test Loss: 0.0822878\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0641906\n",
      "\tspeed: 0.0510s/iter; left time: 691.6492s\n",
      "\titers: 200, epoch: 40 | loss: 0.0646643\n",
      "\tspeed: 0.0222s/iter; left time: 298.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0628855 Vali Loss: 0.0737326 Test Loss: 0.0820833\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0662549\n",
      "\tspeed: 0.0501s/iter; left time: 668.4277s\n",
      "\titers: 200, epoch: 41 | loss: 0.0582558\n",
      "\tspeed: 0.0221s/iter; left time: 292.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0627494 Vali Loss: 0.0740342 Test Loss: 0.0828347\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0630391\n",
      "\tspeed: 0.0504s/iter; left time: 661.0425s\n",
      "\titers: 200, epoch: 42 | loss: 0.0635225\n",
      "\tspeed: 0.0221s/iter; left time: 287.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0627333 Vali Loss: 0.0738710 Test Loss: 0.0824965\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0646420\n",
      "\tspeed: 0.0505s/iter; left time: 651.5405s\n",
      "\titers: 200, epoch: 43 | loss: 0.0631472\n",
      "\tspeed: 0.0225s/iter; left time: 287.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0627789 Vali Loss: 0.0737849 Test Loss: 0.0821379\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644815\n",
      "\tspeed: 0.0498s/iter; left time: 631.0076s\n",
      "\titers: 200, epoch: 44 | loss: 0.0613300\n",
      "\tspeed: 0.0225s/iter; left time: 283.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0627792 Vali Loss: 0.0738404 Test Loss: 0.0823312\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0640033\n",
      "\tspeed: 0.0504s/iter; left time: 627.6111s\n",
      "\titers: 200, epoch: 45 | loss: 0.0641519\n",
      "\tspeed: 0.0221s/iter; left time: 272.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0628419 Vali Loss: 0.0737427 Test Loss: 0.0821432\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01954476721584797, rmse:0.13980260491371155, mae:0.08211354166269302, rse:0.5407935976982117\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2294929\n",
      "\tspeed: 0.0254s/iter; left time: 565.6436s\n",
      "\titers: 200, epoch: 1 | loss: 0.2141254\n",
      "\tspeed: 0.0221s/iter; left time: 491.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.2334311 Vali Loss: 0.1722753 Test Loss: 0.1772561\n",
      "Validation loss decreased (inf --> 0.172275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1282267\n",
      "\tspeed: 0.0494s/iter; left time: 1091.2354s\n",
      "\titers: 200, epoch: 2 | loss: 0.1004032\n",
      "\tspeed: 0.0221s/iter; left time: 486.7634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.1324808 Vali Loss: 0.0985475 Test Loss: 0.1091164\n",
      "Validation loss decreased (0.172275 --> 0.098547).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0860634\n",
      "\tspeed: 0.0496s/iter; left time: 1083.1344s\n",
      "\titers: 200, epoch: 3 | loss: 0.0858575\n",
      "\tspeed: 0.0221s/iter; left time: 479.7255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0882981 Vali Loss: 0.0853176 Test Loss: 0.0929129\n",
      "Validation loss decreased (0.098547 --> 0.085318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0809617\n",
      "\tspeed: 0.0487s/iter; left time: 1054.0262s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768849\n",
      "\tspeed: 0.0220s/iter; left time: 474.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0794786 Vali Loss: 0.0823246 Test Loss: 0.0894653\n",
      "Validation loss decreased (0.085318 --> 0.082325).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0760063\n",
      "\tspeed: 0.0488s/iter; left time: 1044.0511s\n",
      "\titers: 200, epoch: 5 | loss: 0.0741239\n",
      "\tspeed: 0.0221s/iter; left time: 470.1240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0754624 Vali Loss: 0.0797599 Test Loss: 0.0867928\n",
      "Validation loss decreased (0.082325 --> 0.079760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0691110\n",
      "\tspeed: 0.0494s/iter; left time: 1046.5392s\n",
      "\titers: 200, epoch: 6 | loss: 0.0712478\n",
      "\tspeed: 0.0221s/iter; left time: 466.2563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0725687 Vali Loss: 0.0788398 Test Loss: 0.0863109\n",
      "Validation loss decreased (0.079760 --> 0.078840).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0669708\n",
      "\tspeed: 0.0492s/iter; left time: 1030.0945s\n",
      "\titers: 200, epoch: 7 | loss: 0.0698299\n",
      "\tspeed: 0.0220s/iter; left time: 459.8694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0704604 Vali Loss: 0.0786574 Test Loss: 0.0861561\n",
      "Validation loss decreased (0.078840 --> 0.078657).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0654070\n",
      "\tspeed: 0.0484s/iter; left time: 1003.2186s\n",
      "\titers: 200, epoch: 8 | loss: 0.0671207\n",
      "\tspeed: 0.0221s/iter; left time: 455.4992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0693980 Vali Loss: 0.0785316 Test Loss: 0.0860373\n",
      "Validation loss decreased (0.078657 --> 0.078532).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0718002\n",
      "\tspeed: 0.0487s/iter; left time: 999.6695s\n",
      "\titers: 200, epoch: 9 | loss: 0.0773943\n",
      "\tspeed: 0.0222s/iter; left time: 452.7229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0683717 Vali Loss: 0.0769011 Test Loss: 0.0839162\n",
      "Validation loss decreased (0.078532 --> 0.076901).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698994\n",
      "\tspeed: 0.0483s/iter; left time: 980.1023s\n",
      "\titers: 200, epoch: 10 | loss: 0.0656860\n",
      "\tspeed: 0.0220s/iter; left time: 443.5288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0674244 Vali Loss: 0.0768939 Test Loss: 0.0844743\n",
      "Validation loss decreased (0.076901 --> 0.076894).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0671276\n",
      "\tspeed: 0.0486s/iter; left time: 974.5661s\n",
      "\titers: 200, epoch: 11 | loss: 0.0659138\n",
      "\tspeed: 0.0222s/iter; left time: 442.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0668561 Vali Loss: 0.0759056 Test Loss: 0.0833722\n",
      "Validation loss decreased (0.076894 --> 0.075906).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0613027\n",
      "\tspeed: 0.0485s/iter; left time: 962.2508s\n",
      "\titers: 200, epoch: 12 | loss: 0.0642147\n",
      "\tspeed: 0.0222s/iter; left time: 437.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0664663 Vali Loss: 0.0763738 Test Loss: 0.0830978\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0677178\n",
      "\tspeed: 0.0482s/iter; left time: 945.9364s\n",
      "\titers: 200, epoch: 13 | loss: 0.0614443\n",
      "\tspeed: 0.0220s/iter; left time: 428.5029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0659990 Vali Loss: 0.0758844 Test Loss: 0.0834444\n",
      "Validation loss decreased (0.075906 --> 0.075884).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0634627\n",
      "\tspeed: 0.0491s/iter; left time: 951.0647s\n",
      "\titers: 200, epoch: 14 | loss: 0.0692620\n",
      "\tspeed: 0.0220s/iter; left time: 424.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0656032 Vali Loss: 0.0752800 Test Loss: 0.0831799\n",
      "Validation loss decreased (0.075884 --> 0.075280).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0672221\n",
      "\tspeed: 0.0488s/iter; left time: 934.5374s\n",
      "\titers: 200, epoch: 15 | loss: 0.0633345\n",
      "\tspeed: 0.0219s/iter; left time: 418.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0650491 Vali Loss: 0.0756333 Test Loss: 0.0840749\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0610732\n",
      "\tspeed: 0.0471s/iter; left time: 892.1804s\n",
      "\titers: 200, epoch: 16 | loss: 0.0700565\n",
      "\tspeed: 0.0219s/iter; left time: 412.1326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0650323 Vali Loss: 0.0750159 Test Loss: 0.0832009\n",
      "Validation loss decreased (0.075280 --> 0.075016).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0636975\n",
      "\tspeed: 0.0481s/iter; left time: 900.6692s\n",
      "\titers: 200, epoch: 17 | loss: 0.0597611\n",
      "\tspeed: 0.0219s/iter; left time: 408.2889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0648637 Vali Loss: 0.0746917 Test Loss: 0.0827398\n",
      "Validation loss decreased (0.075016 --> 0.074692).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0653481\n",
      "\tspeed: 0.0483s/iter; left time: 893.5987s\n",
      "\titers: 200, epoch: 18 | loss: 0.0641423\n",
      "\tspeed: 0.0219s/iter; left time: 402.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0644399 Vali Loss: 0.0746251 Test Loss: 0.0825982\n",
      "Validation loss decreased (0.074692 --> 0.074625).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0686329\n",
      "\tspeed: 0.0478s/iter; left time: 872.7393s\n",
      "\titers: 200, epoch: 19 | loss: 0.0665067\n",
      "\tspeed: 0.0218s/iter; left time: 396.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0644815 Vali Loss: 0.0744981 Test Loss: 0.0826726\n",
      "Validation loss decreased (0.074625 --> 0.074498).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0658588\n",
      "\tspeed: 0.0532s/iter; left time: 959.2962s\n",
      "\titers: 200, epoch: 20 | loss: 0.0638259\n",
      "\tspeed: 0.0220s/iter; left time: 394.8273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0642745 Vali Loss: 0.0742996 Test Loss: 0.0827153\n",
      "Validation loss decreased (0.074498 --> 0.074300).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0624551\n",
      "\tspeed: 0.0477s/iter; left time: 849.8152s\n",
      "\titers: 200, epoch: 21 | loss: 0.0660841\n",
      "\tspeed: 0.0219s/iter; left time: 388.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0640175 Vali Loss: 0.0742694 Test Loss: 0.0828999\n",
      "Validation loss decreased (0.074300 --> 0.074269).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0619114\n",
      "\tspeed: 0.0481s/iter; left time: 846.3375s\n",
      "\titers: 200, epoch: 22 | loss: 0.0643567\n",
      "\tspeed: 0.0268s/iter; left time: 468.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0640181 Vali Loss: 0.0741758 Test Loss: 0.0829286\n",
      "Validation loss decreased (0.074269 --> 0.074176).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0625725\n",
      "\tspeed: 0.0631s/iter; left time: 1096.3423s\n",
      "\titers: 200, epoch: 23 | loss: 0.0590775\n",
      "\tspeed: 0.0439s/iter; left time: 757.8422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 224 | Train Loss: 0.0639112 Vali Loss: 0.0740160 Test Loss: 0.0828236\n",
      "Validation loss decreased (0.074176 --> 0.074016).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0649727\n",
      "\tspeed: 0.0985s/iter; left time: 1689.3893s\n",
      "\titers: 200, epoch: 24 | loss: 0.0631907\n",
      "\tspeed: 0.0348s/iter; left time: 593.7492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 224 | Train Loss: 0.0637529 Vali Loss: 0.0739267 Test Loss: 0.0825191\n",
      "Validation loss decreased (0.074016 --> 0.073927).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0637167\n",
      "\tspeed: 0.0923s/iter; left time: 1562.5232s\n",
      "\titers: 200, epoch: 25 | loss: 0.0633136\n",
      "\tspeed: 0.0325s/iter; left time: 547.4488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0637175 Vali Loss: 0.0739865 Test Loss: 0.0828237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0652302\n",
      "\tspeed: 0.0959s/iter; left time: 1601.3982s\n",
      "\titers: 200, epoch: 26 | loss: 0.0637102\n",
      "\tspeed: 0.0540s/iter; left time: 896.8070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0635596 Vali Loss: 0.0740698 Test Loss: 0.0824577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0624344\n",
      "\tspeed: 0.1296s/iter; left time: 2136.1683s\n",
      "\titers: 200, epoch: 27 | loss: 0.0636434\n",
      "\tspeed: 0.0492s/iter; left time: 805.2769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.35s\n",
      "Steps: 224 | Train Loss: 0.0634665 Vali Loss: 0.0737717 Test Loss: 0.0822112\n",
      "Validation loss decreased (0.073927 --> 0.073772).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0671510\n",
      "\tspeed: 0.0521s/iter; left time: 846.5278s\n",
      "\titers: 200, epoch: 28 | loss: 0.0627728\n",
      "\tspeed: 0.0397s/iter; left time: 641.3040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0635948 Vali Loss: 0.0738380 Test Loss: 0.0822671\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0608605\n",
      "\tspeed: 0.0960s/iter; left time: 1539.2174s\n",
      "\titers: 200, epoch: 29 | loss: 0.0666260\n",
      "\tspeed: 0.0312s/iter; left time: 496.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0633621 Vali Loss: 0.0738937 Test Loss: 0.0823346\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0624807\n",
      "\tspeed: 0.0762s/iter; left time: 1204.2630s\n",
      "\titers: 200, epoch: 30 | loss: 0.0613603\n",
      "\tspeed: 0.0293s/iter; left time: 460.5447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0635463 Vali Loss: 0.0738404 Test Loss: 0.0825350\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0631546\n",
      "\tspeed: 0.1042s/iter; left time: 1623.5324s\n",
      "\titers: 200, epoch: 31 | loss: 0.0665270\n",
      "\tspeed: 0.0219s/iter; left time: 339.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0633463 Vali Loss: 0.0739144 Test Loss: 0.0829653\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0584389\n",
      "\tspeed: 0.0465s/iter; left time: 714.6513s\n",
      "\titers: 200, epoch: 32 | loss: 0.0629507\n",
      "\tspeed: 0.0219s/iter; left time: 334.0073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0634271 Vali Loss: 0.0737236 Test Loss: 0.0823442\n",
      "Validation loss decreased (0.073772 --> 0.073724).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0634116\n",
      "\tspeed: 0.0476s/iter; left time: 720.4429s\n",
      "\titers: 200, epoch: 33 | loss: 0.0655307\n",
      "\tspeed: 0.0762s/iter; left time: 1145.2220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0632614 Vali Loss: 0.0737668 Test Loss: 0.0827176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0609357\n",
      "\tspeed: 0.2995s/iter; left time: 4465.8943s\n",
      "\titers: 200, epoch: 34 | loss: 0.0634871\n",
      "\tspeed: 0.1313s/iter; left time: 1945.1318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:28.58s\n",
      "Steps: 224 | Train Loss: 0.0633259 Vali Loss: 0.0736853 Test Loss: 0.0824721\n",
      "Validation loss decreased (0.073724 --> 0.073685).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0658228\n",
      "\tspeed: 0.3888s/iter; left time: 5709.7782s\n",
      "\titers: 200, epoch: 35 | loss: 0.0621590\n",
      "\tspeed: 0.0397s/iter; left time: 579.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.18s\n",
      "Steps: 224 | Train Loss: 0.0631578 Vali Loss: 0.0737039 Test Loss: 0.0826853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0673323\n",
      "\tspeed: 0.0610s/iter; left time: 882.6185s\n",
      "\titers: 200, epoch: 36 | loss: 0.0604972\n",
      "\tspeed: 0.0229s/iter; left time: 328.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0630547 Vali Loss: 0.0736483 Test Loss: 0.0825203\n",
      "Validation loss decreased (0.073685 --> 0.073648).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0635277\n",
      "\tspeed: 0.0507s/iter; left time: 721.2296s\n",
      "\titers: 200, epoch: 37 | loss: 0.0611792\n",
      "\tspeed: 0.0223s/iter; left time: 314.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0632276 Vali Loss: 0.0736629 Test Loss: 0.0823932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0620902\n",
      "\tspeed: 0.0482s/iter; left time: 675.8526s\n",
      "\titers: 200, epoch: 38 | loss: 0.0666074\n",
      "\tspeed: 0.0231s/iter; left time: 321.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0630680 Vali Loss: 0.0736212 Test Loss: 0.0826019\n",
      "Validation loss decreased (0.073648 --> 0.073621).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0598154\n",
      "\tspeed: 0.0496s/iter; left time: 683.7204s\n",
      "\titers: 200, epoch: 39 | loss: 0.0604868\n",
      "\tspeed: 0.0221s/iter; left time: 302.1943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0631140 Vali Loss: 0.0736632 Test Loss: 0.0824528\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0615100\n",
      "\tspeed: 0.0477s/iter; left time: 646.4065s\n",
      "\titers: 200, epoch: 40 | loss: 0.0626080\n",
      "\tspeed: 0.0221s/iter; left time: 297.9971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0630364 Vali Loss: 0.0735574 Test Loss: 0.0826276\n",
      "Validation loss decreased (0.073621 --> 0.073557).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0580416\n",
      "\tspeed: 0.0486s/iter; left time: 649.0229s\n",
      "\titers: 200, epoch: 41 | loss: 0.0660710\n",
      "\tspeed: 0.0223s/iter; left time: 295.3818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0630894 Vali Loss: 0.0736317 Test Loss: 0.0825958\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0658373\n",
      "\tspeed: 0.0483s/iter; left time: 633.5021s\n",
      "\titers: 200, epoch: 42 | loss: 0.0628427\n",
      "\tspeed: 0.0222s/iter; left time: 288.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0631375 Vali Loss: 0.0736379 Test Loss: 0.0822467\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0600216\n",
      "\tspeed: 0.0472s/iter; left time: 607.9220s\n",
      "\titers: 200, epoch: 43 | loss: 0.0605232\n",
      "\tspeed: 0.0220s/iter; left time: 281.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0630474 Vali Loss: 0.0736033 Test Loss: 0.0821347\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0635931\n",
      "\tspeed: 0.0476s/iter; left time: 602.4242s\n",
      "\titers: 200, epoch: 44 | loss: 0.0638608\n",
      "\tspeed: 0.0219s/iter; left time: 275.6610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0630168 Vali Loss: 0.0735331 Test Loss: 0.0823951\n",
      "Validation loss decreased (0.073557 --> 0.073533).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0655058\n",
      "\tspeed: 0.0485s/iter; left time: 603.8482s\n",
      "\titers: 200, epoch: 45 | loss: 0.0630669\n",
      "\tspeed: 0.0221s/iter; left time: 272.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0629838 Vali Loss: 0.0735118 Test Loss: 0.0824546\n",
      "Validation loss decreased (0.073533 --> 0.073512).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0617724\n",
      "\tspeed: 0.0477s/iter; left time: 583.3207s\n",
      "\titers: 200, epoch: 46 | loss: 0.0633209\n",
      "\tspeed: 0.0219s/iter; left time: 265.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0631229 Vali Loss: 0.0735310 Test Loss: 0.0822719\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0604569\n",
      "\tspeed: 0.0473s/iter; left time: 567.3404s\n",
      "\titers: 200, epoch: 47 | loss: 0.0643957\n",
      "\tspeed: 0.0218s/iter; left time: 259.7840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0631294 Vali Loss: 0.0735828 Test Loss: 0.0824356\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0613695\n",
      "\tspeed: 0.0473s/iter; left time: 556.2885s\n",
      "\titers: 200, epoch: 48 | loss: 0.0632272\n",
      "\tspeed: 0.0219s/iter; left time: 255.4166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0630086 Vali Loss: 0.0735530 Test Loss: 0.0824805\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0598075\n",
      "\tspeed: 0.0477s/iter; left time: 550.9795s\n",
      "\titers: 200, epoch: 49 | loss: 0.0621441\n",
      "\tspeed: 0.0218s/iter; left time: 249.7595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0629597 Vali Loss: 0.0735895 Test Loss: 0.0826616\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0680106\n",
      "\tspeed: 0.0473s/iter; left time: 535.9361s\n",
      "\titers: 200, epoch: 50 | loss: 0.0589682\n",
      "\tspeed: 0.0219s/iter; left time: 245.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0630845 Vali Loss: 0.0736245 Test Loss: 0.0825281\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0629302\n",
      "\tspeed: 0.0472s/iter; left time: 523.9599s\n",
      "\titers: 200, epoch: 51 | loss: 0.0630434\n",
      "\tspeed: 0.0220s/iter; left time: 241.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0630434 Vali Loss: 0.0735503 Test Loss: 0.0823759\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0676790\n",
      "\tspeed: 0.0475s/iter; left time: 516.8913s\n",
      "\titers: 200, epoch: 52 | loss: 0.0644478\n",
      "\tspeed: 0.0219s/iter; left time: 236.0795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0628469 Vali Loss: 0.0736275 Test Loss: 0.0824844\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0628749\n",
      "\tspeed: 0.0473s/iter; left time: 503.9684s\n",
      "\titers: 200, epoch: 53 | loss: 0.0655811\n",
      "\tspeed: 0.0219s/iter; left time: 231.3781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0629909 Vali Loss: 0.0735519 Test Loss: 0.0825564\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0661383\n",
      "\tspeed: 0.0476s/iter; left time: 496.0919s\n",
      "\titers: 200, epoch: 54 | loss: 0.0616498\n",
      "\tspeed: 0.0220s/iter; left time: 227.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0629410 Vali Loss: 0.0735419 Test Loss: 0.0822997\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0658125\n",
      "\tspeed: 0.0472s/iter; left time: 481.4123s\n",
      "\titers: 200, epoch: 55 | loss: 0.0579743\n",
      "\tspeed: 0.0219s/iter; left time: 221.1717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0629055 Vali Loss: 0.0735505 Test Loss: 0.0824005\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019625447690486908, rmse:0.14009085297584534, mae:0.08245458453893661, rse:0.5419086217880249\n",
      "Intermediate time for FR and pred_len 96: 00h:25m:53.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2317283\n",
      "\tspeed: 0.0419s/iter; left time: 929.7325s\n",
      "\titers: 200, epoch: 1 | loss: 0.2119953\n",
      "\tspeed: 0.0222s/iter; left time: 491.0332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 223 | Train Loss: 0.2302330 Vali Loss: 0.1743387 Test Loss: 0.1786744\n",
      "Validation loss decreased (inf --> 0.174339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1314083\n",
      "\tspeed: 0.0480s/iter; left time: 1054.0578s\n",
      "\titers: 200, epoch: 2 | loss: 0.0985461\n",
      "\tspeed: 0.0222s/iter; left time: 486.7535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.1297914 Vali Loss: 0.0987522 Test Loss: 0.1098587\n",
      "Validation loss decreased (0.174339 --> 0.098752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945369\n",
      "\tspeed: 0.0523s/iter; left time: 1138.7334s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840309\n",
      "\tspeed: 0.0221s/iter; left time: 479.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0900157 Vali Loss: 0.0897248 Test Loss: 0.0989699\n",
      "Validation loss decreased (0.098752 --> 0.089725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0842518\n",
      "\tspeed: 0.0490s/iter; left time: 1055.2420s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829651\n",
      "\tspeed: 0.0222s/iter; left time: 475.1205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0823543 Vali Loss: 0.0845757 Test Loss: 0.0921284\n",
      "Validation loss decreased (0.089725 --> 0.084576).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813215\n",
      "\tspeed: 0.0505s/iter; left time: 1075.2825s\n",
      "\titers: 200, epoch: 5 | loss: 0.0763549\n",
      "\tspeed: 0.0236s/iter; left time: 500.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 223 | Train Loss: 0.0779761 Vali Loss: 0.0830024 Test Loss: 0.0916281\n",
      "Validation loss decreased (0.084576 --> 0.083002).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711770\n",
      "\tspeed: 0.0487s/iter; left time: 1026.4761s\n",
      "\titers: 200, epoch: 6 | loss: 0.0761437\n",
      "\tspeed: 0.0221s/iter; left time: 463.5132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0750340 Vali Loss: 0.0815916 Test Loss: 0.0903480\n",
      "Validation loss decreased (0.083002 --> 0.081592).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764776\n",
      "\tspeed: 0.0469s/iter; left time: 978.3045s\n",
      "\titers: 200, epoch: 7 | loss: 0.0722997\n",
      "\tspeed: 0.0221s/iter; left time: 458.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0733261 Vali Loss: 0.0810975 Test Loss: 0.0901351\n",
      "Validation loss decreased (0.081592 --> 0.081098).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0663537\n",
      "\tspeed: 0.0520s/iter; left time: 1073.1008s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752048\n",
      "\tspeed: 0.0220s/iter; left time: 451.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0722930 Vali Loss: 0.0804326 Test Loss: 0.0895729\n",
      "Validation loss decreased (0.081098 --> 0.080433).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726083\n",
      "\tspeed: 0.0509s/iter; left time: 1039.3875s\n",
      "\titers: 200, epoch: 9 | loss: 0.0662002\n",
      "\tspeed: 0.0949s/iter; left time: 1927.3419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.10s\n",
      "Steps: 223 | Train Loss: 0.0712899 Vali Loss: 0.0797627 Test Loss: 0.0913882\n",
      "Validation loss decreased (0.080433 --> 0.079763).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687232\n",
      "\tspeed: 0.5543s/iter; left time: 11193.5184s\n",
      "\titers: 200, epoch: 10 | loss: 0.0681385\n",
      "\tspeed: 0.1788s/iter; left time: 3592.9032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.81s\n",
      "Steps: 223 | Train Loss: 0.0703177 Vali Loss: 0.0791177 Test Loss: 0.0893971\n",
      "Validation loss decreased (0.079763 --> 0.079118).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0767913\n",
      "\tspeed: 0.3773s/iter; left time: 7534.2660s\n",
      "\titers: 200, epoch: 11 | loss: 0.0669642\n",
      "\tspeed: 0.0232s/iter; left time: 461.8834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.0698199 Vali Loss: 0.0786923 Test Loss: 0.0910984\n",
      "Validation loss decreased (0.079118 --> 0.078692).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0678120\n",
      "\tspeed: 0.0501s/iter; left time: 990.2408s\n",
      "\titers: 200, epoch: 12 | loss: 0.0690882\n",
      "\tspeed: 0.0222s/iter; left time: 435.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0692048 Vali Loss: 0.0783656 Test Loss: 0.0895246\n",
      "Validation loss decreased (0.078692 --> 0.078366).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0699115\n",
      "\tspeed: 0.0477s/iter; left time: 930.6391s\n",
      "\titers: 200, epoch: 13 | loss: 0.0689497\n",
      "\tspeed: 0.0220s/iter; left time: 427.5357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0689567 Vali Loss: 0.0782556 Test Loss: 0.0902306\n",
      "Validation loss decreased (0.078366 --> 0.078256).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689784\n",
      "\tspeed: 0.0461s/iter; left time: 890.6232s\n",
      "\titers: 200, epoch: 14 | loss: 0.0712334\n",
      "\tspeed: 0.0218s/iter; left time: 419.2342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0686478 Vali Loss: 0.0780328 Test Loss: 0.0894486\n",
      "Validation loss decreased (0.078256 --> 0.078033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0661036\n",
      "\tspeed: 0.0468s/iter; left time: 892.5463s\n",
      "\titers: 200, epoch: 15 | loss: 0.0705416\n",
      "\tspeed: 0.0219s/iter; left time: 415.5197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0685273 Vali Loss: 0.0779664 Test Loss: 0.0901319\n",
      "Validation loss decreased (0.078033 --> 0.077966).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0692449\n",
      "\tspeed: 0.0483s/iter; left time: 910.9337s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698579\n",
      "\tspeed: 0.0219s/iter; left time: 411.3843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0680099 Vali Loss: 0.0779450 Test Loss: 0.0912172\n",
      "Validation loss decreased (0.077966 --> 0.077945).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0666914\n",
      "\tspeed: 0.0472s/iter; left time: 879.8152s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702515\n",
      "\tspeed: 0.0264s/iter; left time: 488.8558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.0680035 Vali Loss: 0.0781178 Test Loss: 0.0910641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0680600\n",
      "\tspeed: 0.0514s/iter; left time: 947.0094s\n",
      "\titers: 200, epoch: 18 | loss: 0.0678294\n",
      "\tspeed: 0.0220s/iter; left time: 402.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0677992 Vali Loss: 0.0781043 Test Loss: 0.0910614\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0656894\n",
      "\tspeed: 0.0488s/iter; left time: 886.8078s\n",
      "\titers: 200, epoch: 19 | loss: 0.0676644\n",
      "\tspeed: 0.0219s/iter; left time: 395.6110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0676094 Vali Loss: 0.0776037 Test Loss: 0.0894377\n",
      "Validation loss decreased (0.077945 --> 0.077604).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685511\n",
      "\tspeed: 0.0465s/iter; left time: 834.7264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0641573\n",
      "\tspeed: 0.0220s/iter; left time: 393.6543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0675627 Vali Loss: 0.0778171 Test Loss: 0.0908302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0650135\n",
      "\tspeed: 0.0460s/iter; left time: 816.8365s\n",
      "\titers: 200, epoch: 21 | loss: 0.0678574\n",
      "\tspeed: 0.0223s/iter; left time: 393.5866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0672910 Vali Loss: 0.0779659 Test Loss: 0.0916981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0676335\n",
      "\tspeed: 0.0470s/iter; left time: 823.9679s\n",
      "\titers: 200, epoch: 22 | loss: 0.0747136\n",
      "\tspeed: 0.0227s/iter; left time: 395.6133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0672116 Vali Loss: 0.0773651 Test Loss: 0.0899247\n",
      "Validation loss decreased (0.077604 --> 0.077365).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0669376\n",
      "\tspeed: 0.0470s/iter; left time: 813.1126s\n",
      "\titers: 200, epoch: 23 | loss: 0.0675555\n",
      "\tspeed: 0.0220s/iter; left time: 377.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0670507 Vali Loss: 0.0776652 Test Loss: 0.0912330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0712600\n",
      "\tspeed: 0.0478s/iter; left time: 815.6306s\n",
      "\titers: 200, epoch: 24 | loss: 0.0657399\n",
      "\tspeed: 0.0220s/iter; left time: 374.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0670268 Vali Loss: 0.0775723 Test Loss: 0.0907516\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0673945\n",
      "\tspeed: 0.0471s/iter; left time: 793.3310s\n",
      "\titers: 200, epoch: 25 | loss: 0.0703666\n",
      "\tspeed: 0.0222s/iter; left time: 371.7494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0669197 Vali Loss: 0.0774367 Test Loss: 0.0903643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0706103\n",
      "\tspeed: 0.0470s/iter; left time: 781.7453s\n",
      "\titers: 200, epoch: 26 | loss: 0.0660480\n",
      "\tspeed: 0.0220s/iter; left time: 362.7732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0668781 Vali Loss: 0.0775632 Test Loss: 0.0908478\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0640762\n",
      "\tspeed: 0.0460s/iter; left time: 755.3207s\n",
      "\titers: 200, epoch: 27 | loss: 0.0670196\n",
      "\tspeed: 0.0220s/iter; left time: 358.8019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0668569 Vali Loss: 0.0774982 Test Loss: 0.0906081\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0639818\n",
      "\tspeed: 0.0470s/iter; left time: 760.6536s\n",
      "\titers: 200, epoch: 28 | loss: 0.0672523\n",
      "\tspeed: 0.0224s/iter; left time: 360.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0667927 Vali Loss: 0.0771706 Test Loss: 0.0893452\n",
      "Validation loss decreased (0.077365 --> 0.077171).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0658996\n",
      "\tspeed: 0.0510s/iter; left time: 813.0607s\n",
      "\titers: 200, epoch: 29 | loss: 0.0669276\n",
      "\tspeed: 0.0220s/iter; left time: 349.1493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0667988 Vali Loss: 0.0777658 Test Loss: 0.0917429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0668975\n",
      "\tspeed: 0.0462s/iter; left time: 727.5209s\n",
      "\titers: 200, epoch: 30 | loss: 0.0684645\n",
      "\tspeed: 0.0220s/iter; left time: 344.6252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0667102 Vali Loss: 0.0776424 Test Loss: 0.0913128\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0629755\n",
      "\tspeed: 0.0501s/iter; left time: 776.4016s\n",
      "\titers: 200, epoch: 31 | loss: 0.0660803\n",
      "\tspeed: 0.0221s/iter; left time: 341.1518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.0666626 Vali Loss: 0.0775424 Test Loss: 0.0906453\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0671377\n",
      "\tspeed: 0.0502s/iter; left time: 767.7252s\n",
      "\titers: 200, epoch: 32 | loss: 0.0686621\n",
      "\tspeed: 0.0220s/iter; left time: 333.4265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0665423 Vali Loss: 0.0774537 Test Loss: 0.0905649\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0632359\n",
      "\tspeed: 0.0912s/iter; left time: 1374.6761s\n",
      "\titers: 200, epoch: 33 | loss: 0.0663969\n",
      "\tspeed: 0.0235s/iter; left time: 352.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0665035 Vali Loss: 0.0776388 Test Loss: 0.0908128\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0658519\n",
      "\tspeed: 0.0506s/iter; left time: 750.5538s\n",
      "\titers: 200, epoch: 34 | loss: 0.0709227\n",
      "\tspeed: 0.0220s/iter; left time: 325.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 223 | Train Loss: 0.0665535 Vali Loss: 0.0772696 Test Loss: 0.0902845\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0645690\n",
      "\tspeed: 0.0454s/iter; left time: 663.1361s\n",
      "\titers: 200, epoch: 35 | loss: 0.0661122\n",
      "\tspeed: 0.0219s/iter; left time: 318.6395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0664603 Vali Loss: 0.0778828 Test Loss: 0.0916361\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0639788\n",
      "\tspeed: 0.0472s/iter; left time: 679.2795s\n",
      "\titers: 200, epoch: 36 | loss: 0.0686976\n",
      "\tspeed: 0.0240s/iter; left time: 343.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0665468 Vali Loss: 0.0774591 Test Loss: 0.0906879\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0655376\n",
      "\tspeed: 0.0483s/iter; left time: 684.6155s\n",
      "\titers: 200, epoch: 37 | loss: 0.0657179\n",
      "\tspeed: 0.0240s/iter; left time: 338.2750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0664091 Vali Loss: 0.0773421 Test Loss: 0.0903268\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0717241\n",
      "\tspeed: 0.0471s/iter; left time: 656.8142s\n",
      "\titers: 200, epoch: 38 | loss: 0.0667918\n",
      "\tspeed: 0.0220s/iter; left time: 304.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0663713 Vali Loss: 0.0772991 Test Loss: 0.0900583\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023250561207532883, rmse:0.152481347322464, mae:0.08934521675109863, rse:0.5905746817588806\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2254948\n",
      "\tspeed: 0.0676s/iter; left time: 1500.9200s\n",
      "\titers: 200, epoch: 1 | loss: 0.2089711\n",
      "\tspeed: 0.1278s/iter; left time: 2824.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.89s\n",
      "Steps: 223 | Train Loss: 0.2316177 Vali Loss: 0.1768054 Test Loss: 0.1802489\n",
      "Validation loss decreased (inf --> 0.176805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1204020\n",
      "\tspeed: 0.6510s/iter; left time: 14307.7268s\n",
      "\titers: 200, epoch: 2 | loss: 0.1047688\n",
      "\tspeed: 0.0321s/iter; left time: 701.9483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:20.44s\n",
      "Steps: 223 | Train Loss: 0.1304562 Vali Loss: 0.0986905 Test Loss: 0.1087013\n",
      "Validation loss decreased (0.176805 --> 0.098690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0886309\n",
      "\tspeed: 0.0487s/iter; left time: 1059.7583s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896669\n",
      "\tspeed: 0.0221s/iter; left time: 478.2736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0900223 Vali Loss: 0.0894369 Test Loss: 0.0992814\n",
      "Validation loss decreased (0.098690 --> 0.089437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856129\n",
      "\tspeed: 0.0478s/iter; left time: 1029.8206s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797408\n",
      "\tspeed: 0.0220s/iter; left time: 471.0564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0819482 Vali Loss: 0.0853961 Test Loss: 0.0927934\n",
      "Validation loss decreased (0.089437 --> 0.085396).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815468\n",
      "\tspeed: 0.0457s/iter; left time: 973.4219s\n",
      "\titers: 200, epoch: 5 | loss: 0.0814852\n",
      "\tspeed: 0.0220s/iter; left time: 465.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0783020 Vali Loss: 0.0841476 Test Loss: 0.0929229\n",
      "Validation loss decreased (0.085396 --> 0.084148).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0754093\n",
      "\tspeed: 0.0456s/iter; left time: 960.8492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0764751\n",
      "\tspeed: 0.0218s/iter; left time: 458.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0757417 Vali Loss: 0.0831923 Test Loss: 0.0922795\n",
      "Validation loss decreased (0.084148 --> 0.083192).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0740787\n",
      "\tspeed: 0.0502s/iter; left time: 1047.0985s\n",
      "\titers: 200, epoch: 7 | loss: 0.0730897\n",
      "\tspeed: 0.0219s/iter; left time: 454.3442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0739870 Vali Loss: 0.0809666 Test Loss: 0.0911169\n",
      "Validation loss decreased (0.083192 --> 0.080967).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0686533\n",
      "\tspeed: 0.0459s/iter; left time: 947.8846s\n",
      "\titers: 200, epoch: 8 | loss: 0.0749585\n",
      "\tspeed: 0.0219s/iter; left time: 449.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0725260 Vali Loss: 0.0803784 Test Loss: 0.0915120\n",
      "Validation loss decreased (0.080967 --> 0.080378).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0724952\n",
      "\tspeed: 0.0460s/iter; left time: 938.2571s\n",
      "\titers: 200, epoch: 9 | loss: 0.0711124\n",
      "\tspeed: 0.0223s/iter; left time: 452.3920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0715886 Vali Loss: 0.0800627 Test Loss: 0.0912529\n",
      "Validation loss decreased (0.080378 --> 0.080063).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0712858\n",
      "\tspeed: 0.0496s/iter; left time: 1002.3273s\n",
      "\titers: 200, epoch: 10 | loss: 0.0706808\n",
      "\tspeed: 0.0220s/iter; left time: 441.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0706921 Vali Loss: 0.0794149 Test Loss: 0.0921003\n",
      "Validation loss decreased (0.080063 --> 0.079415).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672549\n",
      "\tspeed: 0.0462s/iter; left time: 923.3993s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664750\n",
      "\tspeed: 0.0220s/iter; left time: 436.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0700090 Vali Loss: 0.0793510 Test Loss: 0.0934827\n",
      "Validation loss decreased (0.079415 --> 0.079351).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0636529\n",
      "\tspeed: 0.0472s/iter; left time: 932.3252s\n",
      "\titers: 200, epoch: 12 | loss: 0.0663576\n",
      "\tspeed: 0.0225s/iter; left time: 443.0218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0696431 Vali Loss: 0.0789604 Test Loss: 0.0925588\n",
      "Validation loss decreased (0.079351 --> 0.078960).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698583\n",
      "\tspeed: 0.0476s/iter; left time: 929.2751s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658346\n",
      "\tspeed: 0.0220s/iter; left time: 426.8051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0692430 Vali Loss: 0.0783537 Test Loss: 0.0909085\n",
      "Validation loss decreased (0.078960 --> 0.078354).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719903\n",
      "\tspeed: 0.0460s/iter; left time: 887.0499s\n",
      "\titers: 200, epoch: 14 | loss: 0.0748286\n",
      "\tspeed: 0.0220s/iter; left time: 423.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0688559 Vali Loss: 0.0788919 Test Loss: 0.0937054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0668124\n",
      "\tspeed: 0.0459s/iter; left time: 875.5293s\n",
      "\titers: 200, epoch: 15 | loss: 0.0677921\n",
      "\tspeed: 0.0220s/iter; left time: 418.0167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0691085 Vali Loss: 0.0784468 Test Loss: 0.0921480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0694731\n",
      "\tspeed: 0.0461s/iter; left time: 868.8752s\n",
      "\titers: 200, epoch: 16 | loss: 0.0662075\n",
      "\tspeed: 0.0223s/iter; left time: 418.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0684266 Vali Loss: 0.0786279 Test Loss: 0.0945559\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0721494\n",
      "\tspeed: 0.0485s/iter; left time: 903.6100s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703329\n",
      "\tspeed: 0.0224s/iter; left time: 415.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0681249 Vali Loss: 0.0779675 Test Loss: 0.0922431\n",
      "Validation loss decreased (0.078354 --> 0.077968).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677019\n",
      "\tspeed: 0.0491s/iter; left time: 904.5164s\n",
      "\titers: 200, epoch: 18 | loss: 0.0700197\n",
      "\tspeed: 0.0222s/iter; left time: 406.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0681090 Vali Loss: 0.0778762 Test Loss: 0.0930999\n",
      "Validation loss decreased (0.077968 --> 0.077876).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0661288\n",
      "\tspeed: 0.0470s/iter; left time: 855.4669s\n",
      "\titers: 200, epoch: 19 | loss: 0.0693792\n",
      "\tspeed: 0.0220s/iter; left time: 397.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0679404 Vali Loss: 0.0776933 Test Loss: 0.0916552\n",
      "Validation loss decreased (0.077876 --> 0.077693).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685285\n",
      "\tspeed: 0.0552s/iter; left time: 991.1316s\n",
      "\titers: 200, epoch: 20 | loss: 0.0708071\n",
      "\tspeed: 0.0220s/iter; left time: 392.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0677031 Vali Loss: 0.0778025 Test Loss: 0.0924273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0637514\n",
      "\tspeed: 0.0457s/iter; left time: 811.1554s\n",
      "\titers: 200, epoch: 21 | loss: 0.0648506\n",
      "\tspeed: 0.0218s/iter; left time: 385.3821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0677317 Vali Loss: 0.0777700 Test Loss: 0.0924312\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0695439\n",
      "\tspeed: 0.0865s/iter; left time: 1514.4766s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696051\n",
      "\tspeed: 0.0260s/iter; left time: 452.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.0674149 Vali Loss: 0.0780544 Test Loss: 0.0937120\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0710265\n",
      "\tspeed: 0.0451s/iter; left time: 780.5340s\n",
      "\titers: 200, epoch: 23 | loss: 0.0640255\n",
      "\tspeed: 0.0219s/iter; left time: 376.7585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0674414 Vali Loss: 0.0773848 Test Loss: 0.0900734\n",
      "Validation loss decreased (0.077693 --> 0.077385).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0665562\n",
      "\tspeed: 0.0482s/iter; left time: 822.1368s\n",
      "\titers: 200, epoch: 24 | loss: 0.0638807\n",
      "\tspeed: 0.0241s/iter; left time: 408.4248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.0674211 Vali Loss: 0.0780355 Test Loss: 0.0931235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0679073\n",
      "\tspeed: 0.0488s/iter; left time: 822.9557s\n",
      "\titers: 200, epoch: 25 | loss: 0.0673683\n",
      "\tspeed: 0.0230s/iter; left time: 385.7597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0672398 Vali Loss: 0.0782380 Test Loss: 0.0947364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0671922\n",
      "\tspeed: 0.0460s/iter; left time: 765.3417s\n",
      "\titers: 200, epoch: 26 | loss: 0.0680550\n",
      "\tspeed: 0.0222s/iter; left time: 367.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0671696 Vali Loss: 0.0782886 Test Loss: 0.0947017\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0645071\n",
      "\tspeed: 0.0468s/iter; left time: 767.0596s\n",
      "\titers: 200, epoch: 27 | loss: 0.0674032\n",
      "\tspeed: 0.0219s/iter; left time: 357.0445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0669790 Vali Loss: 0.0776945 Test Loss: 0.0929749\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0630683\n",
      "\tspeed: 0.0916s/iter; left time: 1482.7752s\n",
      "\titers: 200, epoch: 28 | loss: 0.0686370\n",
      "\tspeed: 0.1732s/iter; left time: 2785.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:26.46s\n",
      "Steps: 223 | Train Loss: 0.0670140 Vali Loss: 0.0778409 Test Loss: 0.0932657\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0647907\n",
      "\tspeed: 0.0665s/iter; left time: 1061.3560s\n",
      "\titers: 200, epoch: 29 | loss: 0.0636980\n",
      "\tspeed: 0.0259s/iter; left time: 410.5936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.0668772 Vali Loss: 0.0778030 Test Loss: 0.0935969\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0648133\n",
      "\tspeed: 0.0452s/iter; left time: 711.6610s\n",
      "\titers: 200, epoch: 30 | loss: 0.0652288\n",
      "\tspeed: 0.0218s/iter; left time: 340.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0668610 Vali Loss: 0.0780473 Test Loss: 0.0945063\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0654122\n",
      "\tspeed: 0.0453s/iter; left time: 702.1949s\n",
      "\titers: 200, epoch: 31 | loss: 0.0667105\n",
      "\tspeed: 0.0220s/iter; left time: 338.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0671501 Vali Loss: 0.0773408 Test Loss: 0.0913568\n",
      "Validation loss decreased (0.077385 --> 0.077341).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0670493\n",
      "\tspeed: 0.0477s/iter; left time: 729.0949s\n",
      "\titers: 200, epoch: 32 | loss: 0.0677307\n",
      "\tspeed: 0.0256s/iter; left time: 388.2189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 223 | Train Loss: 0.0668682 Vali Loss: 0.0777121 Test Loss: 0.0932346\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0641261\n",
      "\tspeed: 0.0483s/iter; left time: 728.0766s\n",
      "\titers: 200, epoch: 33 | loss: 0.0638911\n",
      "\tspeed: 0.0220s/iter; left time: 328.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0667531 Vali Loss: 0.0777565 Test Loss: 0.0936645\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0659660\n",
      "\tspeed: 0.0457s/iter; left time: 678.0325s\n",
      "\titers: 200, epoch: 34 | loss: 0.0686335\n",
      "\tspeed: 0.0220s/iter; left time: 324.7573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0667856 Vali Loss: 0.0776200 Test Loss: 0.0932053\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0687392\n",
      "\tspeed: 0.0459s/iter; left time: 670.3550s\n",
      "\titers: 200, epoch: 35 | loss: 0.0690497\n",
      "\tspeed: 0.0220s/iter; left time: 319.8788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0668176 Vali Loss: 0.0777510 Test Loss: 0.0938380\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702824\n",
      "\tspeed: 0.0457s/iter; left time: 658.4812s\n",
      "\titers: 200, epoch: 36 | loss: 0.0692371\n",
      "\tspeed: 0.0221s/iter; left time: 315.6635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0667884 Vali Loss: 0.0778013 Test Loss: 0.0936883\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0638370\n",
      "\tspeed: 0.0457s/iter; left time: 648.3586s\n",
      "\titers: 200, epoch: 37 | loss: 0.0651658\n",
      "\tspeed: 0.0219s/iter; left time: 308.6571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0666432 Vali Loss: 0.0777940 Test Loss: 0.0937219\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0693552\n",
      "\tspeed: 0.0474s/iter; left time: 660.8188s\n",
      "\titers: 200, epoch: 38 | loss: 0.0670007\n",
      "\tspeed: 0.0219s/iter; left time: 303.7690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0666645 Vali Loss: 0.0774632 Test Loss: 0.0924549\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0688250\n",
      "\tspeed: 0.0456s/iter; left time: 626.4022s\n",
      "\titers: 200, epoch: 39 | loss: 0.0682196\n",
      "\tspeed: 0.0220s/iter; left time: 299.6299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0665509 Vali Loss: 0.0774738 Test Loss: 0.0926666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0675138\n",
      "\tspeed: 0.0462s/iter; left time: 624.3812s\n",
      "\titers: 200, epoch: 40 | loss: 0.0659483\n",
      "\tspeed: 0.0221s/iter; left time: 296.2513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0666897 Vali Loss: 0.0774995 Test Loss: 0.0929280\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0673696\n",
      "\tspeed: 0.0455s/iter; left time: 604.5884s\n",
      "\titers: 200, epoch: 41 | loss: 0.0683117\n",
      "\tspeed: 0.0305s/iter; left time: 402.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0665603 Vali Loss: 0.0776642 Test Loss: 0.0936454\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02533787675201893, rmse:0.15917876362800598, mae:0.0913567990064621, rse:0.6165143847465515\n",
      "Intermediate time for FR and pred_len 168: 00h:13m:01.92s\n",
      "Intermediate time for FR: 00h:59m:32.94s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2558293\n",
      "\tspeed: 0.0583s/iter; left time: 1299.2008s\n",
      "\titers: 200, epoch: 1 | loss: 0.2381266\n",
      "\tspeed: 0.0264s/iter; left time: 586.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.2640084 Vali Loss: 0.1828401 Test Loss: 0.1919930\n",
      "Validation loss decreased (inf --> 0.182840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1497207\n",
      "\tspeed: 0.0447s/iter; left time: 986.0919s\n",
      "\titers: 200, epoch: 2 | loss: 0.1136334\n",
      "\tspeed: 0.0216s/iter; left time: 474.3113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.1526043 Vali Loss: 0.0876826 Test Loss: 0.0897644\n",
      "Validation loss decreased (0.182840 --> 0.087683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0962923\n",
      "\tspeed: 0.0474s/iter; left time: 1035.7281s\n",
      "\titers: 200, epoch: 3 | loss: 0.0930147\n",
      "\tspeed: 0.0216s/iter; left time: 470.0641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0976564 Vali Loss: 0.0842901 Test Loss: 0.0870943\n",
      "Validation loss decreased (0.087683 --> 0.084290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853350\n",
      "\tspeed: 0.0476s/iter; left time: 1030.3244s\n",
      "\titers: 200, epoch: 4 | loss: 0.0813772\n",
      "\tspeed: 0.0225s/iter; left time: 483.8457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0857653 Vali Loss: 0.0750860 Test Loss: 0.0777485\n",
      "Validation loss decreased (0.084290 --> 0.075086).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0786085\n",
      "\tspeed: 0.0448s/iter; left time: 959.5265s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775412\n",
      "\tspeed: 0.0216s/iter; left time: 461.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788653 Vali Loss: 0.0711707 Test Loss: 0.0729953\n",
      "Validation loss decreased (0.075086 --> 0.071171).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0713746\n",
      "\tspeed: 0.0492s/iter; left time: 1042.8112s\n",
      "\titers: 200, epoch: 6 | loss: 0.0699616\n",
      "\tspeed: 0.0215s/iter; left time: 453.6381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0746095 Vali Loss: 0.0693904 Test Loss: 0.0717842\n",
      "Validation loss decreased (0.071171 --> 0.069390).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0726239\n",
      "\tspeed: 0.0749s/iter; left time: 1569.8836s\n",
      "\titers: 200, epoch: 7 | loss: 0.0711424\n",
      "\tspeed: 0.1032s/iter; left time: 2152.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.69s\n",
      "Steps: 224 | Train Loss: 0.0717863 Vali Loss: 0.0668192 Test Loss: 0.0691673\n",
      "Validation loss decreased (0.069390 --> 0.066819).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0696084\n",
      "\tspeed: 0.0999s/iter; left time: 2071.2352s\n",
      "\titers: 200, epoch: 8 | loss: 0.0691015\n",
      "\tspeed: 0.0217s/iter; left time: 447.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0701057 Vali Loss: 0.0644864 Test Loss: 0.0668698\n",
      "Validation loss decreased (0.066819 --> 0.064486).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0651193\n",
      "\tspeed: 0.0519s/iter; left time: 1064.2497s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705513\n",
      "\tspeed: 0.0217s/iter; left time: 442.3955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0683687 Vali Loss: 0.0637326 Test Loss: 0.0665478\n",
      "Validation loss decreased (0.064486 --> 0.063733).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0670562\n",
      "\tspeed: 0.0469s/iter; left time: 950.4787s\n",
      "\titers: 200, epoch: 10 | loss: 0.0664813\n",
      "\tspeed: 0.0218s/iter; left time: 439.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0674084 Vali Loss: 0.0631605 Test Loss: 0.0655152\n",
      "Validation loss decreased (0.063733 --> 0.063161).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0687384\n",
      "\tspeed: 0.0450s/iter; left time: 902.5071s\n",
      "\titers: 200, epoch: 11 | loss: 0.0619850\n",
      "\tspeed: 0.0220s/iter; left time: 438.4017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0662015 Vali Loss: 0.0619426 Test Loss: 0.0644772\n",
      "Validation loss decreased (0.063161 --> 0.061943).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0613197\n",
      "\tspeed: 0.0454s/iter; left time: 900.5905s\n",
      "\titers: 200, epoch: 12 | loss: 0.0663613\n",
      "\tspeed: 0.0216s/iter; left time: 426.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0653727 Vali Loss: 0.0619607 Test Loss: 0.0646265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0630805\n",
      "\tspeed: 0.0451s/iter; left time: 884.7179s\n",
      "\titers: 200, epoch: 13 | loss: 0.0707275\n",
      "\tspeed: 0.0219s/iter; left time: 427.7477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0648825 Vali Loss: 0.0615020 Test Loss: 0.0639694\n",
      "Validation loss decreased (0.061943 --> 0.061502).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0660773\n",
      "\tspeed: 0.0456s/iter; left time: 884.3580s\n",
      "\titers: 200, epoch: 14 | loss: 0.0623470\n",
      "\tspeed: 0.0216s/iter; left time: 417.5535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0644683 Vali Loss: 0.0627952 Test Loss: 0.0651951\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0642073\n",
      "\tspeed: 0.0454s/iter; left time: 870.1513s\n",
      "\titers: 200, epoch: 15 | loss: 0.0644118\n",
      "\tspeed: 0.0216s/iter; left time: 412.6467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0637678 Vali Loss: 0.0605992 Test Loss: 0.0628750\n",
      "Validation loss decreased (0.061502 --> 0.060599).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0658147\n",
      "\tspeed: 0.0444s/iter; left time: 841.8252s\n",
      "\titers: 200, epoch: 16 | loss: 0.0652734\n",
      "\tspeed: 0.0216s/iter; left time: 406.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0638448 Vali Loss: 0.0616660 Test Loss: 0.0639011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0695060\n",
      "\tspeed: 0.0446s/iter; left time: 834.2657s\n",
      "\titers: 200, epoch: 17 | loss: 0.0646186\n",
      "\tspeed: 0.0215s/iter; left time: 400.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0632143 Vali Loss: 0.0603413 Test Loss: 0.0625113\n",
      "Validation loss decreased (0.060599 --> 0.060341).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0601193\n",
      "\tspeed: 0.0467s/iter; left time: 864.0151s\n",
      "\titers: 200, epoch: 18 | loss: 0.0671429\n",
      "\tspeed: 0.0218s/iter; left time: 400.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0628841 Vali Loss: 0.0598996 Test Loss: 0.0623332\n",
      "Validation loss decreased (0.060341 --> 0.059900).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0620406\n",
      "\tspeed: 0.0449s/iter; left time: 819.9029s\n",
      "\titers: 200, epoch: 19 | loss: 0.0675364\n",
      "\tspeed: 0.0248s/iter; left time: 449.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0626531 Vali Loss: 0.0598602 Test Loss: 0.0621414\n",
      "Validation loss decreased (0.059900 --> 0.059860).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0607891\n",
      "\tspeed: 0.0526s/iter; left time: 948.6349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0612117\n",
      "\tspeed: 0.0214s/iter; left time: 383.4019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0622245 Vali Loss: 0.0596845 Test Loss: 0.0620242\n",
      "Validation loss decreased (0.059860 --> 0.059684).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0640365\n",
      "\tspeed: 0.0480s/iter; left time: 855.6586s\n",
      "\titers: 200, epoch: 21 | loss: 0.0632473\n",
      "\tspeed: 0.0217s/iter; left time: 384.9036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0627094 Vali Loss: 0.0600732 Test Loss: 0.0623788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0593488\n",
      "\tspeed: 0.0504s/iter; left time: 887.1069s\n",
      "\titers: 200, epoch: 22 | loss: 0.0564405\n",
      "\tspeed: 0.0215s/iter; left time: 375.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0620199 Vali Loss: 0.0600471 Test Loss: 0.0623457\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0580876\n",
      "\tspeed: 0.0435s/iter; left time: 756.3923s\n",
      "\titers: 200, epoch: 23 | loss: 0.0581126\n",
      "\tspeed: 0.0215s/iter; left time: 371.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0619198 Vali Loss: 0.0602437 Test Loss: 0.0624897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0652360\n",
      "\tspeed: 0.0454s/iter; left time: 778.7168s\n",
      "\titers: 200, epoch: 24 | loss: 0.0625962\n",
      "\tspeed: 0.0241s/iter; left time: 411.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0616465 Vali Loss: 0.0594193 Test Loss: 0.0616776\n",
      "Validation loss decreased (0.059684 --> 0.059419).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0594608\n",
      "\tspeed: 0.0482s/iter; left time: 816.4209s\n",
      "\titers: 200, epoch: 25 | loss: 0.0646038\n",
      "\tspeed: 0.0217s/iter; left time: 365.8492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0616589 Vali Loss: 0.0592671 Test Loss: 0.0615980\n",
      "Validation loss decreased (0.059419 --> 0.059267).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0613646\n",
      "\tspeed: 0.0443s/iter; left time: 740.5675s\n",
      "\titers: 200, epoch: 26 | loss: 0.0630684\n",
      "\tspeed: 0.0217s/iter; left time: 359.6711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0613635 Vali Loss: 0.0597764 Test Loss: 0.0620253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0641902\n",
      "\tspeed: 0.0542s/iter; left time: 893.3979s\n",
      "\titers: 200, epoch: 27 | loss: 0.0659257\n",
      "\tspeed: 0.0216s/iter; left time: 353.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0615855 Vali Loss: 0.0591585 Test Loss: 0.0613262\n",
      "Validation loss decreased (0.059267 --> 0.059158).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0631174\n",
      "\tspeed: 0.1749s/iter; left time: 2842.6888s\n",
      "\titers: 200, epoch: 28 | loss: 0.0584812\n",
      "\tspeed: 0.0218s/iter; left time: 352.5141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:14.48s\n",
      "Steps: 224 | Train Loss: 0.0613162 Vali Loss: 0.0591988 Test Loss: 0.0614812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0645844\n",
      "\tspeed: 0.0483s/iter; left time: 773.6088s\n",
      "\titers: 200, epoch: 29 | loss: 0.0621652\n",
      "\tspeed: 0.0215s/iter; left time: 342.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0612787 Vali Loss: 0.0593957 Test Loss: 0.0615460\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0615049\n",
      "\tspeed: 0.0478s/iter; left time: 755.9328s\n",
      "\titers: 200, epoch: 30 | loss: 0.0633583\n",
      "\tspeed: 0.0215s/iter; left time: 336.8815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0613180 Vali Loss: 0.0593140 Test Loss: 0.0615583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0589669\n",
      "\tspeed: 0.0472s/iter; left time: 735.7737s\n",
      "\titers: 200, epoch: 31 | loss: 0.0624070\n",
      "\tspeed: 0.0220s/iter; left time: 340.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0613025 Vali Loss: 0.0590342 Test Loss: 0.0612142\n",
      "Validation loss decreased (0.059158 --> 0.059034).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0611178\n",
      "\tspeed: 0.0456s/iter; left time: 700.0957s\n",
      "\titers: 200, epoch: 32 | loss: 0.0641520\n",
      "\tspeed: 0.0215s/iter; left time: 328.5579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0610763 Vali Loss: 0.0592478 Test Loss: 0.0614585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0603973\n",
      "\tspeed: 0.0443s/iter; left time: 671.0215s\n",
      "\titers: 200, epoch: 33 | loss: 0.0601934\n",
      "\tspeed: 0.0216s/iter; left time: 324.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0611806 Vali Loss: 0.0590856 Test Loss: 0.0612788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0621883\n",
      "\tspeed: 0.0441s/iter; left time: 657.9643s\n",
      "\titers: 200, epoch: 34 | loss: 0.0625794\n",
      "\tspeed: 0.0215s/iter; left time: 318.3824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0609800 Vali Loss: 0.0593187 Test Loss: 0.0615730\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0602998\n",
      "\tspeed: 0.0447s/iter; left time: 656.3144s\n",
      "\titers: 200, epoch: 35 | loss: 0.0634709\n",
      "\tspeed: 0.0216s/iter; left time: 314.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0609945 Vali Loss: 0.0589900 Test Loss: 0.0612031\n",
      "Validation loss decreased (0.059034 --> 0.058990).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0627337\n",
      "\tspeed: 0.0451s/iter; left time: 651.5712s\n",
      "\titers: 200, epoch: 36 | loss: 0.0612281\n",
      "\tspeed: 0.0215s/iter; left time: 309.4335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0608968 Vali Loss: 0.0590414 Test Loss: 0.0612786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0608527\n",
      "\tspeed: 0.0445s/iter; left time: 633.1113s\n",
      "\titers: 200, epoch: 37 | loss: 0.0579833\n",
      "\tspeed: 0.0219s/iter; left time: 309.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0608606 Vali Loss: 0.0588656 Test Loss: 0.0610627\n",
      "Validation loss decreased (0.058990 --> 0.058866).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0588295\n",
      "\tspeed: 0.0444s/iter; left time: 621.4773s\n",
      "\titers: 200, epoch: 38 | loss: 0.0619932\n",
      "\tspeed: 0.0215s/iter; left time: 299.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0608767 Vali Loss: 0.0589144 Test Loss: 0.0611289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0576887\n",
      "\tspeed: 0.0441s/iter; left time: 607.8903s\n",
      "\titers: 200, epoch: 39 | loss: 0.0610248\n",
      "\tspeed: 0.0215s/iter; left time: 294.7627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0610182 Vali Loss: 0.0590282 Test Loss: 0.0611487\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0619670\n",
      "\tspeed: 0.0445s/iter; left time: 603.0828s\n",
      "\titers: 200, epoch: 40 | loss: 0.0582836\n",
      "\tspeed: 0.0216s/iter; left time: 290.2578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0606941 Vali Loss: 0.0588290 Test Loss: 0.0609829\n",
      "Validation loss decreased (0.058866 --> 0.058829).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0628615\n",
      "\tspeed: 0.0515s/iter; left time: 686.9675s\n",
      "\titers: 200, epoch: 41 | loss: 0.0571420\n",
      "\tspeed: 0.0215s/iter; left time: 284.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0608291 Vali Loss: 0.0590452 Test Loss: 0.0612850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0577372\n",
      "\tspeed: 0.0490s/iter; left time: 643.1951s\n",
      "\titers: 200, epoch: 42 | loss: 0.0628383\n",
      "\tspeed: 0.0215s/iter; left time: 279.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0606938 Vali Loss: 0.0590544 Test Loss: 0.0612045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0580428\n",
      "\tspeed: 0.0635s/iter; left time: 818.6499s\n",
      "\titers: 200, epoch: 43 | loss: 0.0571793\n",
      "\tspeed: 0.0215s/iter; left time: 274.9646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606902 Vali Loss: 0.0589120 Test Loss: 0.0610991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0621199\n",
      "\tspeed: 0.0436s/iter; left time: 552.2760s\n",
      "\titers: 200, epoch: 44 | loss: 0.0615903\n",
      "\tspeed: 0.0232s/iter; left time: 291.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0607055 Vali Loss: 0.0588038 Test Loss: 0.0609950\n",
      "Validation loss decreased (0.058829 --> 0.058804).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0636745\n",
      "\tspeed: 0.0466s/iter; left time: 579.5945s\n",
      "\titers: 200, epoch: 45 | loss: 0.0622497\n",
      "\tspeed: 0.0215s/iter; left time: 264.8532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0606451 Vali Loss: 0.0588683 Test Loss: 0.0609783\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0567975\n",
      "\tspeed: 0.0497s/iter; left time: 607.5732s\n",
      "\titers: 200, epoch: 46 | loss: 0.0648473\n",
      "\tspeed: 0.0216s/iter; left time: 261.5607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0606911 Vali Loss: 0.0589043 Test Loss: 0.0609757\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0655731\n",
      "\tspeed: 0.1096s/iter; left time: 1314.7853s\n",
      "\titers: 200, epoch: 47 | loss: 0.0558283\n",
      "\tspeed: 0.0217s/iter; left time: 258.5800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:11.81s\n",
      "Steps: 224 | Train Loss: 0.0607113 Vali Loss: 0.0588308 Test Loss: 0.0610066\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0652989\n",
      "\tspeed: 0.0495s/iter; left time: 582.8027s\n",
      "\titers: 200, epoch: 48 | loss: 0.0593095\n",
      "\tspeed: 0.0216s/iter; left time: 252.0905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0606000 Vali Loss: 0.0589230 Test Loss: 0.0610860\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0606117\n",
      "\tspeed: 0.0479s/iter; left time: 553.7672s\n",
      "\titers: 200, epoch: 49 | loss: 0.0589852\n",
      "\tspeed: 0.0213s/iter; left time: 244.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0607032 Vali Loss: 0.0588051 Test Loss: 0.0609059\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0605193\n",
      "\tspeed: 0.0478s/iter; left time: 540.9777s\n",
      "\titers: 200, epoch: 50 | loss: 0.0565179\n",
      "\tspeed: 0.0215s/iter; left time: 241.2160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0609300 Vali Loss: 0.0588004 Test Loss: 0.0609711\n",
      "Validation loss decreased (0.058804 --> 0.058800).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0593550\n",
      "\tspeed: 0.0441s/iter; left time: 489.9093s\n",
      "\titers: 200, epoch: 51 | loss: 0.0570721\n",
      "\tspeed: 0.0215s/iter; left time: 236.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0608113 Vali Loss: 0.0588238 Test Loss: 0.0609802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0575402\n",
      "\tspeed: 0.0443s/iter; left time: 481.7458s\n",
      "\titers: 200, epoch: 52 | loss: 0.0584760\n",
      "\tspeed: 0.0215s/iter; left time: 232.2068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0607779 Vali Loss: 0.0587641 Test Loss: 0.0609836\n",
      "Validation loss decreased (0.058800 --> 0.058764).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0609918\n",
      "\tspeed: 0.0448s/iter; left time: 476.8247s\n",
      "\titers: 200, epoch: 53 | loss: 0.0590186\n",
      "\tspeed: 0.0215s/iter; left time: 226.8618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0606655 Vali Loss: 0.0588417 Test Loss: 0.0610079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0603701\n",
      "\tspeed: 0.0450s/iter; left time: 469.8175s\n",
      "\titers: 200, epoch: 54 | loss: 0.0658668\n",
      "\tspeed: 0.0215s/iter; left time: 222.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0606217 Vali Loss: 0.0588372 Test Loss: 0.0610132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0622406\n",
      "\tspeed: 0.0444s/iter; left time: 452.9827s\n",
      "\titers: 200, epoch: 55 | loss: 0.0641512\n",
      "\tspeed: 0.0215s/iter; left time: 217.2053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0605781 Vali Loss: 0.0589146 Test Loss: 0.0610025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0589377\n",
      "\tspeed: 0.0442s/iter; left time: 440.9107s\n",
      "\titers: 200, epoch: 56 | loss: 0.0632462\n",
      "\tspeed: 0.0215s/iter; left time: 212.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0606404 Vali Loss: 0.0587906 Test Loss: 0.0609302\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0613924\n",
      "\tspeed: 0.0440s/iter; left time: 429.3505s\n",
      "\titers: 200, epoch: 57 | loss: 0.0598141\n",
      "\tspeed: 0.0219s/iter; left time: 211.2200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0606566 Vali Loss: 0.0587561 Test Loss: 0.0609242\n",
      "Validation loss decreased (0.058764 --> 0.058756).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0594092\n",
      "\tspeed: 0.0442s/iter; left time: 421.4016s\n",
      "\titers: 200, epoch: 58 | loss: 0.0611908\n",
      "\tspeed: 0.0215s/iter; left time: 202.5056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0605986 Vali Loss: 0.0588975 Test Loss: 0.0610290\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0619921\n",
      "\tspeed: 0.0520s/iter; left time: 483.6931s\n",
      "\titers: 200, epoch: 59 | loss: 0.0594159\n",
      "\tspeed: 0.0216s/iter; left time: 198.7216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0606584 Vali Loss: 0.0587411 Test Loss: 0.0609293\n",
      "Validation loss decreased (0.058756 --> 0.058741).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0633881\n",
      "\tspeed: 0.0515s/iter; left time: 468.2995s\n",
      "\titers: 200, epoch: 60 | loss: 0.0643513\n",
      "\tspeed: 0.0220s/iter; left time: 197.3073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0605124 Vali Loss: 0.0586002 Test Loss: 0.0609298\n",
      "Validation loss decreased (0.058741 --> 0.058600).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0633091\n",
      "\tspeed: 0.0527s/iter; left time: 467.2106s\n",
      "\titers: 200, epoch: 61 | loss: 0.0596545\n",
      "\tspeed: 0.0214s/iter; left time: 187.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0605479 Vali Loss: 0.0586904 Test Loss: 0.0609052\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0652157\n",
      "\tspeed: 0.0435s/iter; left time: 375.5910s\n",
      "\titers: 200, epoch: 62 | loss: 0.0628511\n",
      "\tspeed: 0.0223s/iter; left time: 190.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0606392 Vali Loss: 0.0587038 Test Loss: 0.0609069\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0592410\n",
      "\tspeed: 0.0440s/iter; left time: 369.8502s\n",
      "\titers: 200, epoch: 63 | loss: 0.0602573\n",
      "\tspeed: 0.0214s/iter; left time: 177.8203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0607000 Vali Loss: 0.0588222 Test Loss: 0.0609671\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0606475\n",
      "\tspeed: 0.0429s/iter; left time: 351.0335s\n",
      "\titers: 200, epoch: 64 | loss: 0.0611899\n",
      "\tspeed: 0.0217s/iter; left time: 175.1838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0605292 Vali Loss: 0.0587750 Test Loss: 0.0609327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0613783\n",
      "\tspeed: 0.0433s/iter; left time: 345.1782s\n",
      "\titers: 200, epoch: 65 | loss: 0.0627323\n",
      "\tspeed: 0.0218s/iter; left time: 171.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0606951 Vali Loss: 0.0587247 Test Loss: 0.0609034\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0610044\n",
      "\tspeed: 0.0439s/iter; left time: 339.7599s\n",
      "\titers: 200, epoch: 66 | loss: 0.0592297\n",
      "\tspeed: 0.0214s/iter; left time: 163.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0606284 Vali Loss: 0.0588143 Test Loss: 0.0609449\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0617437\n",
      "\tspeed: 0.0431s/iter; left time: 323.8011s\n",
      "\titers: 200, epoch: 67 | loss: 0.0565457\n",
      "\tspeed: 0.0216s/iter; left time: 159.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0605625 Vali Loss: 0.0589558 Test Loss: 0.0610351\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0595081\n",
      "\tspeed: 0.0434s/iter; left time: 316.7853s\n",
      "\titers: 200, epoch: 68 | loss: 0.0592488\n",
      "\tspeed: 0.0215s/iter; left time: 154.3736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0605613 Vali Loss: 0.0587373 Test Loss: 0.0609406\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0647204\n",
      "\tspeed: 0.0438s/iter; left time: 309.8727s\n",
      "\titers: 200, epoch: 69 | loss: 0.0647961\n",
      "\tspeed: 0.0215s/iter; left time: 149.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0606047 Vali Loss: 0.0588343 Test Loss: 0.0609680\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0613908\n",
      "\tspeed: 0.0442s/iter; left time: 302.3849s\n",
      "\titers: 200, epoch: 70 | loss: 0.0563481\n",
      "\tspeed: 0.0213s/iter; left time: 143.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0605339 Vali Loss: 0.0588707 Test Loss: 0.0610547\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010719235055148602, rmse:0.10353373736143112, mae:0.06092977151274681, rse:0.39120301604270935\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2611395\n",
      "\tspeed: 0.0237s/iter; left time: 528.0851s\n",
      "\titers: 200, epoch: 1 | loss: 0.2397694\n",
      "\tspeed: 0.0218s/iter; left time: 484.0669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.2637589 Vali Loss: 0.1774064 Test Loss: 0.1851594\n",
      "Validation loss decreased (inf --> 0.177406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1366976\n",
      "\tspeed: 0.0436s/iter; left time: 962.1698s\n",
      "\titers: 200, epoch: 2 | loss: 0.1116794\n",
      "\tspeed: 0.0217s/iter; left time: 476.9023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.1488811 Vali Loss: 0.0879994 Test Loss: 0.0902984\n",
      "Validation loss decreased (0.177406 --> 0.087999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924387\n",
      "\tspeed: 0.0435s/iter; left time: 949.9540s\n",
      "\titers: 200, epoch: 3 | loss: 0.0903097\n",
      "\tspeed: 0.0215s/iter; left time: 467.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0963001 Vali Loss: 0.0786247 Test Loss: 0.0805651\n",
      "Validation loss decreased (0.087999 --> 0.078625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0848974\n",
      "\tspeed: 0.0442s/iter; left time: 955.6952s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828546\n",
      "\tspeed: 0.0219s/iter; left time: 470.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0845441 Vali Loss: 0.0745141 Test Loss: 0.0760568\n",
      "Validation loss decreased (0.078625 --> 0.074514).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0806029\n",
      "\tspeed: 0.0433s/iter; left time: 927.3836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757570\n",
      "\tspeed: 0.0218s/iter; left time: 463.8280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0773773 Vali Loss: 0.0706822 Test Loss: 0.0728539\n",
      "Validation loss decreased (0.074514 --> 0.070682).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0805508\n",
      "\tspeed: 0.0438s/iter; left time: 926.9516s\n",
      "\titers: 200, epoch: 6 | loss: 0.0753293\n",
      "\tspeed: 0.0217s/iter; left time: 457.4310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0731062 Vali Loss: 0.0679298 Test Loss: 0.0692633\n",
      "Validation loss decreased (0.070682 --> 0.067930).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0717874\n",
      "\tspeed: 0.0442s/iter; left time: 926.4026s\n",
      "\titers: 200, epoch: 7 | loss: 0.0707016\n",
      "\tspeed: 0.0214s/iter; left time: 446.8923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0707317 Vali Loss: 0.0653223 Test Loss: 0.0674034\n",
      "Validation loss decreased (0.067930 --> 0.065322).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0637238\n",
      "\tspeed: 0.0440s/iter; left time: 911.3586s\n",
      "\titers: 200, epoch: 8 | loss: 0.0697301\n",
      "\tspeed: 0.0214s/iter; left time: 441.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0697945 Vali Loss: 0.0659213 Test Loss: 0.0686247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0715923\n",
      "\tspeed: 0.0431s/iter; left time: 883.5511s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697949\n",
      "\tspeed: 0.0217s/iter; left time: 442.0936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0680556 Vali Loss: 0.0638103 Test Loss: 0.0660263\n",
      "Validation loss decreased (0.065322 --> 0.063810).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0655236\n",
      "\tspeed: 0.0442s/iter; left time: 897.2221s\n",
      "\titers: 200, epoch: 10 | loss: 0.0690507\n",
      "\tspeed: 0.0215s/iter; left time: 433.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0668337 Vali Loss: 0.0628378 Test Loss: 0.0648429\n",
      "Validation loss decreased (0.063810 --> 0.062838).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657988\n",
      "\tspeed: 0.0444s/iter; left time: 889.7120s\n",
      "\titers: 200, epoch: 11 | loss: 0.0652519\n",
      "\tspeed: 0.0215s/iter; left time: 429.5429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0661722 Vali Loss: 0.0625293 Test Loss: 0.0645589\n",
      "Validation loss decreased (0.062838 --> 0.062529).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0695261\n",
      "\tspeed: 0.0428s/iter; left time: 849.0907s\n",
      "\titers: 200, epoch: 12 | loss: 0.0621382\n",
      "\tspeed: 0.0214s/iter; left time: 422.8587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0655198 Vali Loss: 0.0620551 Test Loss: 0.0644802\n",
      "Validation loss decreased (0.062529 --> 0.062055).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0651229\n",
      "\tspeed: 0.0445s/iter; left time: 872.7562s\n",
      "\titers: 200, epoch: 13 | loss: 0.0625030\n",
      "\tspeed: 0.0215s/iter; left time: 418.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0648721 Vali Loss: 0.0613815 Test Loss: 0.0635882\n",
      "Validation loss decreased (0.062055 --> 0.061382).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0631140\n",
      "\tspeed: 0.0430s/iter; left time: 833.2698s\n",
      "\titers: 200, epoch: 14 | loss: 0.0600395\n",
      "\tspeed: 0.0214s/iter; left time: 413.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0642741 Vali Loss: 0.0616729 Test Loss: 0.0638172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0626626\n",
      "\tspeed: 0.0431s/iter; left time: 826.7124s\n",
      "\titers: 200, epoch: 15 | loss: 0.0700633\n",
      "\tspeed: 0.0220s/iter; left time: 419.0628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0639949 Vali Loss: 0.0611219 Test Loss: 0.0631736\n",
      "Validation loss decreased (0.061382 --> 0.061122).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0637753\n",
      "\tspeed: 0.0454s/iter; left time: 860.3893s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626370\n",
      "\tspeed: 0.0216s/iter; left time: 406.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0636109 Vali Loss: 0.0605476 Test Loss: 0.0626584\n",
      "Validation loss decreased (0.061122 --> 0.060548).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0671551\n",
      "\tspeed: 0.0437s/iter; left time: 817.1891s\n",
      "\titers: 200, epoch: 17 | loss: 0.0654119\n",
      "\tspeed: 0.0215s/iter; left time: 400.5399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0631128 Vali Loss: 0.0606507 Test Loss: 0.0629274\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0674544\n",
      "\tspeed: 0.0435s/iter; left time: 803.8418s\n",
      "\titers: 200, epoch: 18 | loss: 0.0648333\n",
      "\tspeed: 0.0216s/iter; left time: 396.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0628133 Vali Loss: 0.0607794 Test Loss: 0.0631163\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0631847\n",
      "\tspeed: 0.0428s/iter; left time: 781.1902s\n",
      "\titers: 200, epoch: 19 | loss: 0.0636560\n",
      "\tspeed: 0.0215s/iter; left time: 391.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0627711 Vali Loss: 0.0604789 Test Loss: 0.0626157\n",
      "Validation loss decreased (0.060548 --> 0.060479).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0638389\n",
      "\tspeed: 0.0433s/iter; left time: 780.7489s\n",
      "\titers: 200, epoch: 20 | loss: 0.0623267\n",
      "\tspeed: 0.0217s/iter; left time: 389.6559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0622514 Vali Loss: 0.0599138 Test Loss: 0.0621311\n",
      "Validation loss decreased (0.060479 --> 0.059914).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0639950\n",
      "\tspeed: 0.0440s/iter; left time: 783.9777s\n",
      "\titers: 200, epoch: 21 | loss: 0.0571222\n",
      "\tspeed: 0.0216s/iter; left time: 382.0280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0626983 Vali Loss: 0.0600219 Test Loss: 0.0622247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0640250\n",
      "\tspeed: 0.0433s/iter; left time: 761.1040s\n",
      "\titers: 200, epoch: 22 | loss: 0.0594751\n",
      "\tspeed: 0.0215s/iter; left time: 375.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0619488 Vali Loss: 0.0598412 Test Loss: 0.0619801\n",
      "Validation loss decreased (0.059914 --> 0.059841).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0618583\n",
      "\tspeed: 0.0434s/iter; left time: 753.3231s\n",
      "\titers: 200, epoch: 23 | loss: 0.0659301\n",
      "\tspeed: 0.0214s/iter; left time: 370.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0617583 Vali Loss: 0.0594401 Test Loss: 0.0617894\n",
      "Validation loss decreased (0.059841 --> 0.059440).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0604866\n",
      "\tspeed: 0.0433s/iter; left time: 742.7957s\n",
      "\titers: 200, epoch: 24 | loss: 0.0597413\n",
      "\tspeed: 0.0216s/iter; left time: 368.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0618813 Vali Loss: 0.0599114 Test Loss: 0.0621233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0579213\n",
      "\tspeed: 0.0431s/iter; left time: 729.3066s\n",
      "\titers: 200, epoch: 25 | loss: 0.0592436\n",
      "\tspeed: 0.0214s/iter; left time: 360.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0616787 Vali Loss: 0.0593819 Test Loss: 0.0618338\n",
      "Validation loss decreased (0.059440 --> 0.059382).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0559742\n",
      "\tspeed: 0.0434s/iter; left time: 725.1603s\n",
      "\titers: 200, epoch: 26 | loss: 0.0588969\n",
      "\tspeed: 0.0212s/iter; left time: 352.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0613727 Vali Loss: 0.0593460 Test Loss: 0.0617737\n",
      "Validation loss decreased (0.059382 --> 0.059346).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0569330\n",
      "\tspeed: 0.0429s/iter; left time: 707.6190s\n",
      "\titers: 200, epoch: 27 | loss: 0.0633800\n",
      "\tspeed: 0.0215s/iter; left time: 351.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0613782 Vali Loss: 0.0592712 Test Loss: 0.0615616\n",
      "Validation loss decreased (0.059346 --> 0.059271).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0588916\n",
      "\tspeed: 0.0439s/iter; left time: 713.3463s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644964\n",
      "\tspeed: 0.0214s/iter; left time: 346.0272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0612562 Vali Loss: 0.0590498 Test Loss: 0.0614208\n",
      "Validation loss decreased (0.059271 --> 0.059050).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0596688\n",
      "\tspeed: 0.0431s/iter; left time: 690.4052s\n",
      "\titers: 200, epoch: 29 | loss: 0.0607262\n",
      "\tspeed: 0.0214s/iter; left time: 340.7331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0612384 Vali Loss: 0.0590770 Test Loss: 0.0615377\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0605518\n",
      "\tspeed: 0.0433s/iter; left time: 684.7770s\n",
      "\titers: 200, epoch: 30 | loss: 0.0619422\n",
      "\tspeed: 0.0214s/iter; left time: 335.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0611506 Vali Loss: 0.0591377 Test Loss: 0.0616194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0623615\n",
      "\tspeed: 0.0424s/iter; left time: 660.2194s\n",
      "\titers: 200, epoch: 31 | loss: 0.0581465\n",
      "\tspeed: 0.0217s/iter; left time: 335.8636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0610847 Vali Loss: 0.0591891 Test Loss: 0.0616577\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0555499\n",
      "\tspeed: 0.0424s/iter; left time: 650.7237s\n",
      "\titers: 200, epoch: 32 | loss: 0.0639617\n",
      "\tspeed: 0.0214s/iter; left time: 326.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0610630 Vali Loss: 0.0592702 Test Loss: 0.0615814\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0619429\n",
      "\tspeed: 0.0424s/iter; left time: 641.7239s\n",
      "\titers: 200, epoch: 33 | loss: 0.0569813\n",
      "\tspeed: 0.0214s/iter; left time: 322.0292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0616960 Vali Loss: 0.0591274 Test Loss: 0.0614636\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0605883\n",
      "\tspeed: 0.0433s/iter; left time: 645.1875s\n",
      "\titers: 200, epoch: 34 | loss: 0.0625567\n",
      "\tspeed: 0.0215s/iter; left time: 318.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0609926 Vali Loss: 0.0590364 Test Loss: 0.0613999\n",
      "Validation loss decreased (0.059050 --> 0.059036).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0572220\n",
      "\tspeed: 0.0441s/iter; left time: 647.5548s\n",
      "\titers: 200, epoch: 35 | loss: 0.0583723\n",
      "\tspeed: 0.0215s/iter; left time: 313.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0611139 Vali Loss: 0.0591306 Test Loss: 0.0615006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0609590\n",
      "\tspeed: 0.0437s/iter; left time: 631.2467s\n",
      "\titers: 200, epoch: 36 | loss: 0.0572566\n",
      "\tspeed: 0.0215s/iter; left time: 308.7305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0610636 Vali Loss: 0.0588201 Test Loss: 0.0612896\n",
      "Validation loss decreased (0.059036 --> 0.058820).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0612978\n",
      "\tspeed: 0.0436s/iter; left time: 620.1305s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619081\n",
      "\tspeed: 0.0215s/iter; left time: 303.4389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0609768 Vali Loss: 0.0590234 Test Loss: 0.0613470\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0651834\n",
      "\tspeed: 0.0427s/iter; left time: 598.6613s\n",
      "\titers: 200, epoch: 38 | loss: 0.0617437\n",
      "\tspeed: 0.0215s/iter; left time: 298.6442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0607935 Vali Loss: 0.0588588 Test Loss: 0.0612302\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0585084\n",
      "\tspeed: 0.0431s/iter; left time: 593.7338s\n",
      "\titers: 200, epoch: 39 | loss: 0.0598131\n",
      "\tspeed: 0.0214s/iter; left time: 293.2318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0608596 Vali Loss: 0.0588001 Test Loss: 0.0612345\n",
      "Validation loss decreased (0.058820 --> 0.058800).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0617629\n",
      "\tspeed: 0.0447s/iter; left time: 606.9361s\n",
      "\titers: 200, epoch: 40 | loss: 0.0632681\n",
      "\tspeed: 0.0215s/iter; left time: 289.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0609067 Vali Loss: 0.0589070 Test Loss: 0.0612779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0596814\n",
      "\tspeed: 0.0456s/iter; left time: 608.4195s\n",
      "\titers: 200, epoch: 41 | loss: 0.0628248\n",
      "\tspeed: 0.0220s/iter; left time: 291.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0607505 Vali Loss: 0.0588210 Test Loss: 0.0612365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0605137\n",
      "\tspeed: 0.0428s/iter; left time: 560.9766s\n",
      "\titers: 200, epoch: 42 | loss: 0.0597760\n",
      "\tspeed: 0.0217s/iter; left time: 282.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0607240 Vali Loss: 0.0589597 Test Loss: 0.0612811\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0635111\n",
      "\tspeed: 0.0427s/iter; left time: 550.7720s\n",
      "\titers: 200, epoch: 43 | loss: 0.0608119\n",
      "\tspeed: 0.0215s/iter; left time: 274.9047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0607631 Vali Loss: 0.0588552 Test Loss: 0.0612449\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0571789\n",
      "\tspeed: 0.0437s/iter; left time: 554.0629s\n",
      "\titers: 200, epoch: 44 | loss: 0.0547266\n",
      "\tspeed: 0.0217s/iter; left time: 272.2702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0613731 Vali Loss: 0.0588353 Test Loss: 0.0611756\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0639703\n",
      "\tspeed: 0.0433s/iter; left time: 539.1153s\n",
      "\titers: 200, epoch: 45 | loss: 0.0586866\n",
      "\tspeed: 0.0216s/iter; left time: 266.4211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0606743 Vali Loss: 0.0588826 Test Loss: 0.0612087\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0609062\n",
      "\tspeed: 0.0429s/iter; left time: 524.3040s\n",
      "\titers: 200, epoch: 46 | loss: 0.0616319\n",
      "\tspeed: 0.0215s/iter; left time: 260.7066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0606604 Vali Loss: 0.0588534 Test Loss: 0.0612595\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0569909\n",
      "\tspeed: 0.0431s/iter; left time: 517.4061s\n",
      "\titers: 200, epoch: 47 | loss: 0.0555084\n",
      "\tspeed: 0.0216s/iter; left time: 256.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606640 Vali Loss: 0.0591372 Test Loss: 0.0613547\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0585967\n",
      "\tspeed: 0.0438s/iter; left time: 516.2413s\n",
      "\titers: 200, epoch: 48 | loss: 0.0645832\n",
      "\tspeed: 0.0218s/iter; left time: 253.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606513 Vali Loss: 0.0587878 Test Loss: 0.0612191\n",
      "Validation loss decreased (0.058800 --> 0.058788).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0667182\n",
      "\tspeed: 0.0434s/iter; left time: 500.8918s\n",
      "\titers: 200, epoch: 49 | loss: 0.0592124\n",
      "\tspeed: 0.0216s/iter; left time: 247.8337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606127 Vali Loss: 0.0587384 Test Loss: 0.0611886\n",
      "Validation loss decreased (0.058788 --> 0.058738).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0632392\n",
      "\tspeed: 0.0437s/iter; left time: 495.2634s\n",
      "\titers: 200, epoch: 50 | loss: 0.0596401\n",
      "\tspeed: 0.0217s/iter; left time: 244.0535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606635 Vali Loss: 0.0589608 Test Loss: 0.0612556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0614918\n",
      "\tspeed: 0.0438s/iter; left time: 486.2412s\n",
      "\titers: 200, epoch: 51 | loss: 0.0594857\n",
      "\tspeed: 0.0216s/iter; left time: 237.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0607044 Vali Loss: 0.0588970 Test Loss: 0.0612139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0564673\n",
      "\tspeed: 0.0434s/iter; left time: 472.5366s\n",
      "\titers: 200, epoch: 52 | loss: 0.0573945\n",
      "\tspeed: 0.0220s/iter; left time: 237.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0608079 Vali Loss: 0.0589489 Test Loss: 0.0612592\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0597307\n",
      "\tspeed: 0.0466s/iter; left time: 496.2018s\n",
      "\titers: 200, epoch: 53 | loss: 0.0582788\n",
      "\tspeed: 0.0227s/iter; left time: 239.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0610792 Vali Loss: 0.0589152 Test Loss: 0.0612244\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0642910\n",
      "\tspeed: 0.0433s/iter; left time: 451.5143s\n",
      "\titers: 200, epoch: 54 | loss: 0.0603616\n",
      "\tspeed: 0.0217s/iter; left time: 224.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0607728 Vali Loss: 0.0587729 Test Loss: 0.0611971\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0600908\n",
      "\tspeed: 0.0447s/iter; left time: 456.5265s\n",
      "\titers: 200, epoch: 55 | loss: 0.0599116\n",
      "\tspeed: 0.0218s/iter; left time: 219.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0607213 Vali Loss: 0.0587583 Test Loss: 0.0611284\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0666340\n",
      "\tspeed: 0.0437s/iter; left time: 435.7018s\n",
      "\titers: 200, epoch: 56 | loss: 0.0604761\n",
      "\tspeed: 0.0215s/iter; left time: 212.9035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0607667 Vali Loss: 0.0587489 Test Loss: 0.0611228\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0571321\n",
      "\tspeed: 0.0443s/iter; left time: 431.8755s\n",
      "\titers: 200, epoch: 57 | loss: 0.0605484\n",
      "\tspeed: 0.0215s/iter; left time: 207.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0606934 Vali Loss: 0.0588651 Test Loss: 0.0611912\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0598596\n",
      "\tspeed: 0.0428s/iter; left time: 408.0776s\n",
      "\titers: 200, epoch: 58 | loss: 0.0604378\n",
      "\tspeed: 0.0216s/iter; left time: 203.4032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0606548 Vali Loss: 0.0588585 Test Loss: 0.0611659\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0597903\n",
      "\tspeed: 0.0438s/iter; left time: 407.7661s\n",
      "\titers: 200, epoch: 59 | loss: 0.0586092\n",
      "\tspeed: 0.0226s/iter; left time: 207.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0606029 Vali Loss: 0.0587847 Test Loss: 0.0611310\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010685726068913937, rmse:0.10337178409099579, mae:0.061188578605651855, rse:0.3905910551548004\n",
      "Intermediate time for IT and pred_len 24: 00h:15m:09.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2580695\n",
      "\tspeed: 0.0413s/iter; left time: 921.6375s\n",
      "\titers: 200, epoch: 1 | loss: 0.2417672\n",
      "\tspeed: 0.0219s/iter; left time: 485.4284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.2647959 Vali Loss: 0.1834477 Test Loss: 0.1930840\n",
      "Validation loss decreased (inf --> 0.183448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1441503\n",
      "\tspeed: 0.0468s/iter; left time: 1033.3766s\n",
      "\titers: 200, epoch: 2 | loss: 0.1145335\n",
      "\tspeed: 0.0219s/iter; left time: 480.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.1525592 Vali Loss: 0.1030724 Test Loss: 0.1084467\n",
      "Validation loss decreased (0.183448 --> 0.103072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089932\n",
      "\tspeed: 0.0466s/iter; left time: 1018.2314s\n",
      "\titers: 200, epoch: 3 | loss: 0.1033112\n",
      "\tspeed: 0.0219s/iter; left time: 476.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.1080724 Vali Loss: 0.0955559 Test Loss: 0.1006803\n",
      "Validation loss decreased (0.103072 --> 0.095556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0963017\n",
      "\tspeed: 0.0476s/iter; left time: 1030.5557s\n",
      "\titers: 200, epoch: 4 | loss: 0.0922064\n",
      "\tspeed: 0.0219s/iter; left time: 472.0341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0972062 Vali Loss: 0.0889518 Test Loss: 0.0936109\n",
      "Validation loss decreased (0.095556 --> 0.088952).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0930544\n",
      "\tspeed: 0.0467s/iter; left time: 998.6341s\n",
      "\titers: 200, epoch: 5 | loss: 0.0900929\n",
      "\tspeed: 0.0218s/iter; left time: 465.0539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0917243 Vali Loss: 0.0863351 Test Loss: 0.0895492\n",
      "Validation loss decreased (0.088952 --> 0.086335).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0915110\n",
      "\tspeed: 0.0475s/iter; left time: 1005.8222s\n",
      "\titers: 200, epoch: 6 | loss: 0.0871837\n",
      "\tspeed: 0.0219s/iter; left time: 462.1631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0882057 Vali Loss: 0.0828482 Test Loss: 0.0871179\n",
      "Validation loss decreased (0.086335 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0877318\n",
      "\tspeed: 0.0466s/iter; left time: 977.5162s\n",
      "\titers: 200, epoch: 7 | loss: 0.0843585\n",
      "\tspeed: 0.0218s/iter; left time: 454.3700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0864494 Vali Loss: 0.0828761 Test Loss: 0.0860294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0831594\n",
      "\tspeed: 0.0463s/iter; left time: 960.9155s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790139\n",
      "\tspeed: 0.0218s/iter; left time: 449.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0849781 Vali Loss: 0.0813643 Test Loss: 0.0859066\n",
      "Validation loss decreased (0.082848 --> 0.081364).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0836578\n",
      "\tspeed: 0.0471s/iter; left time: 965.8222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809430\n",
      "\tspeed: 0.0218s/iter; left time: 444.6781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0846447 Vali Loss: 0.0812173 Test Loss: 0.0855144\n",
      "Validation loss decreased (0.081364 --> 0.081217).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0812332\n",
      "\tspeed: 0.0467s/iter; left time: 946.9200s\n",
      "\titers: 200, epoch: 10 | loss: 0.0877896\n",
      "\tspeed: 0.0220s/iter; left time: 443.3351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0835148 Vali Loss: 0.0807275 Test Loss: 0.0849319\n",
      "Validation loss decreased (0.081217 --> 0.080727).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0848695\n",
      "\tspeed: 0.0464s/iter; left time: 930.5152s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809705\n",
      "\tspeed: 0.0218s/iter; left time: 435.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0830249 Vali Loss: 0.0807374 Test Loss: 0.0851396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819496\n",
      "\tspeed: 0.0464s/iter; left time: 921.0816s\n",
      "\titers: 200, epoch: 12 | loss: 0.0838790\n",
      "\tspeed: 0.0217s/iter; left time: 429.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0822118 Vali Loss: 0.0811784 Test Loss: 0.0850530\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0817864\n",
      "\tspeed: 0.0456s/iter; left time: 894.3661s\n",
      "\titers: 200, epoch: 13 | loss: 0.0844896\n",
      "\tspeed: 0.0218s/iter; left time: 424.4086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0819507 Vali Loss: 0.0804386 Test Loss: 0.0841491\n",
      "Validation loss decreased (0.080727 --> 0.080439).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0807772\n",
      "\tspeed: 0.0481s/iter; left time: 933.5466s\n",
      "\titers: 200, epoch: 14 | loss: 0.0788974\n",
      "\tspeed: 0.0218s/iter; left time: 421.1842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0816481 Vali Loss: 0.0800457 Test Loss: 0.0841762\n",
      "Validation loss decreased (0.080439 --> 0.080046).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0797461\n",
      "\tspeed: 0.0469s/iter; left time: 899.4349s\n",
      "\titers: 200, epoch: 15 | loss: 0.0825874\n",
      "\tspeed: 0.0218s/iter; left time: 414.7828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0812736 Vali Loss: 0.0792437 Test Loss: 0.0835542\n",
      "Validation loss decreased (0.080046 --> 0.079244).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0848858\n",
      "\tspeed: 0.0466s/iter; left time: 882.6790s\n",
      "\titers: 200, epoch: 16 | loss: 0.0824197\n",
      "\tspeed: 0.0218s/iter; left time: 410.6950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0811235 Vali Loss: 0.0790755 Test Loss: 0.0840130\n",
      "Validation loss decreased (0.079244 --> 0.079075).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0821639\n",
      "\tspeed: 0.0465s/iter; left time: 869.6015s\n",
      "\titers: 200, epoch: 17 | loss: 0.0795800\n",
      "\tspeed: 0.0217s/iter; left time: 404.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0807425 Vali Loss: 0.0796269 Test Loss: 0.0842229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787953\n",
      "\tspeed: 0.0464s/iter; left time: 857.6693s\n",
      "\titers: 200, epoch: 18 | loss: 0.0841330\n",
      "\tspeed: 0.0219s/iter; left time: 403.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0804603 Vali Loss: 0.0793510 Test Loss: 0.0838747\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0777121\n",
      "\tspeed: 0.0461s/iter; left time: 841.5085s\n",
      "\titers: 200, epoch: 19 | loss: 0.0797780\n",
      "\tspeed: 0.0218s/iter; left time: 395.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0804237 Vali Loss: 0.0798827 Test Loss: 0.0843925\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0815642\n",
      "\tspeed: 0.0464s/iter; left time: 836.6083s\n",
      "\titers: 200, epoch: 20 | loss: 0.0798553\n",
      "\tspeed: 0.0217s/iter; left time: 389.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0801151 Vali Loss: 0.0794501 Test Loss: 0.0842532\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0831490\n",
      "\tspeed: 0.0474s/iter; left time: 844.9527s\n",
      "\titers: 200, epoch: 21 | loss: 0.0741697\n",
      "\tspeed: 0.0218s/iter; left time: 386.8595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0804597 Vali Loss: 0.0792035 Test Loss: 0.0839015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0778923\n",
      "\tspeed: 0.0465s/iter; left time: 818.9803s\n",
      "\titers: 200, epoch: 22 | loss: 0.0797235\n",
      "\tspeed: 0.0220s/iter; left time: 384.4465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0798792 Vali Loss: 0.0791037 Test Loss: 0.0839395\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0785171\n",
      "\tspeed: 0.0455s/iter; left time: 790.0579s\n",
      "\titers: 200, epoch: 23 | loss: 0.0789667\n",
      "\tspeed: 0.0217s/iter; left time: 374.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0797583 Vali Loss: 0.0790717 Test Loss: 0.0836279\n",
      "Validation loss decreased (0.079075 --> 0.079072).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0815551\n",
      "\tspeed: 0.0464s/iter; left time: 795.8383s\n",
      "\titers: 200, epoch: 24 | loss: 0.0766816\n",
      "\tspeed: 0.0219s/iter; left time: 373.0618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0796146 Vali Loss: 0.0798074 Test Loss: 0.0846000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0778478\n",
      "\tspeed: 0.0461s/iter; left time: 780.5910s\n",
      "\titers: 200, epoch: 25 | loss: 0.0778329\n",
      "\tspeed: 0.0224s/iter; left time: 376.9188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0795955 Vali Loss: 0.0793961 Test Loss: 0.0840647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0786318\n",
      "\tspeed: 0.0460s/iter; left time: 768.9386s\n",
      "\titers: 200, epoch: 26 | loss: 0.0818022\n",
      "\tspeed: 0.0218s/iter; left time: 362.0867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0797851 Vali Loss: 0.0793151 Test Loss: 0.0839431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0803426\n",
      "\tspeed: 0.0464s/iter; left time: 765.1645s\n",
      "\titers: 200, epoch: 27 | loss: 0.0752964\n",
      "\tspeed: 0.0218s/iter; left time: 356.4932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0793590 Vali Loss: 0.0788792 Test Loss: 0.0837742\n",
      "Validation loss decreased (0.079072 --> 0.078879).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0803743\n",
      "\tspeed: 0.0464s/iter; left time: 754.1558s\n",
      "\titers: 200, epoch: 28 | loss: 0.0777649\n",
      "\tspeed: 0.0218s/iter; left time: 352.8462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0792849 Vali Loss: 0.0786742 Test Loss: 0.0838089\n",
      "Validation loss decreased (0.078879 --> 0.078674).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0825134\n",
      "\tspeed: 0.0454s/iter; left time: 727.2797s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788454\n",
      "\tspeed: 0.0215s/iter; left time: 342.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0792496 Vali Loss: 0.0790493 Test Loss: 0.0838136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0794239\n",
      "\tspeed: 0.0454s/iter; left time: 718.0415s\n",
      "\titers: 200, epoch: 30 | loss: 0.0799008\n",
      "\tspeed: 0.0217s/iter; left time: 340.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0795035 Vali Loss: 0.0788530 Test Loss: 0.0838181\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0800056\n",
      "\tspeed: 0.0457s/iter; left time: 712.6387s\n",
      "\titers: 200, epoch: 31 | loss: 0.0757689\n",
      "\tspeed: 0.0217s/iter; left time: 336.2269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0791669 Vali Loss: 0.0787831 Test Loss: 0.0837968\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0809065\n",
      "\tspeed: 0.0455s/iter; left time: 698.6614s\n",
      "\titers: 200, epoch: 32 | loss: 0.0841759\n",
      "\tspeed: 0.0217s/iter; left time: 330.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0790590 Test Loss: 0.0839365\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0780007\n",
      "\tspeed: 0.0459s/iter; left time: 693.8501s\n",
      "\titers: 200, epoch: 33 | loss: 0.0838579\n",
      "\tspeed: 0.0218s/iter; left time: 327.1926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0790995 Vali Loss: 0.0786118 Test Loss: 0.0835228\n",
      "Validation loss decreased (0.078674 --> 0.078612).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0775447\n",
      "\tspeed: 0.0463s/iter; left time: 691.0096s\n",
      "\titers: 200, epoch: 34 | loss: 0.0795887\n",
      "\tspeed: 0.0217s/iter; left time: 321.4039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0790968 Vali Loss: 0.0785501 Test Loss: 0.0836284\n",
      "Validation loss decreased (0.078612 --> 0.078550).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0764855\n",
      "\tspeed: 0.0462s/iter; left time: 678.5346s\n",
      "\titers: 200, epoch: 35 | loss: 0.0821868\n",
      "\tspeed: 0.0217s/iter; left time: 316.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0790602 Vali Loss: 0.0784518 Test Loss: 0.0834040\n",
      "Validation loss decreased (0.078550 --> 0.078452).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0769309\n",
      "\tspeed: 0.0470s/iter; left time: 679.8876s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770906\n",
      "\tspeed: 0.0218s/iter; left time: 313.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0797029 Vali Loss: 0.0786868 Test Loss: 0.0836559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0815985\n",
      "\tspeed: 0.0453s/iter; left time: 644.3152s\n",
      "\titers: 200, epoch: 37 | loss: 0.0793569\n",
      "\tspeed: 0.0217s/iter; left time: 306.3337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0790845 Vali Loss: 0.0785647 Test Loss: 0.0834830\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0751892\n",
      "\tspeed: 0.0444s/iter; left time: 622.0103s\n",
      "\titers: 200, epoch: 38 | loss: 0.0813473\n",
      "\tspeed: 0.0216s/iter; left time: 300.7106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0790720 Vali Loss: 0.0786881 Test Loss: 0.0836144\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0812576\n",
      "\tspeed: 0.0463s/iter; left time: 637.8750s\n",
      "\titers: 200, epoch: 39 | loss: 0.0778940\n",
      "\tspeed: 0.0217s/iter; left time: 297.0167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0790250 Vali Loss: 0.0786932 Test Loss: 0.0839777\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0793259\n",
      "\tspeed: 0.0462s/iter; left time: 626.1600s\n",
      "\titers: 200, epoch: 40 | loss: 0.0792196\n",
      "\tspeed: 0.0217s/iter; left time: 291.9825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0788296 Vali Loss: 0.0786599 Test Loss: 0.0837624\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0775406\n",
      "\tspeed: 0.0463s/iter; left time: 617.8394s\n",
      "\titers: 200, epoch: 41 | loss: 0.0767219\n",
      "\tspeed: 0.0217s/iter; left time: 287.5939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0789886 Vali Loss: 0.0783118 Test Loss: 0.0836967\n",
      "Validation loss decreased (0.078452 --> 0.078312).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0819803\n",
      "\tspeed: 0.0462s/iter; left time: 605.8045s\n",
      "\titers: 200, epoch: 42 | loss: 0.0767679\n",
      "\tspeed: 0.0218s/iter; left time: 283.2626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0788847 Vali Loss: 0.0788048 Test Loss: 0.0839608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0824770\n",
      "\tspeed: 0.0449s/iter; left time: 579.2412s\n",
      "\titers: 200, epoch: 43 | loss: 0.0828410\n",
      "\tspeed: 0.0216s/iter; left time: 276.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0788485 Vali Loss: 0.0787041 Test Loss: 0.0836403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0814335\n",
      "\tspeed: 0.0449s/iter; left time: 568.3762s\n",
      "\titers: 200, epoch: 44 | loss: 0.0798881\n",
      "\tspeed: 0.0217s/iter; left time: 272.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0789872 Vali Loss: 0.0787718 Test Loss: 0.0836522\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0803211\n",
      "\tspeed: 0.0459s/iter; left time: 571.4261s\n",
      "\titers: 200, epoch: 45 | loss: 0.0766883\n",
      "\tspeed: 0.0219s/iter; left time: 269.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0791085 Vali Loss: 0.0788773 Test Loss: 0.0837836\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0776779\n",
      "\tspeed: 0.0450s/iter; left time: 549.4992s\n",
      "\titers: 200, epoch: 46 | loss: 0.0785439\n",
      "\tspeed: 0.0217s/iter; left time: 262.9203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788168 Vali Loss: 0.0785216 Test Loss: 0.0836760\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0819852\n",
      "\tspeed: 0.0456s/iter; left time: 547.2081s\n",
      "\titers: 200, epoch: 47 | loss: 0.0764217\n",
      "\tspeed: 0.0217s/iter; left time: 258.1698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788838 Vali Loss: 0.0784394 Test Loss: 0.0835491\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0801561\n",
      "\tspeed: 0.0453s/iter; left time: 533.5707s\n",
      "\titers: 200, epoch: 48 | loss: 0.0759512\n",
      "\tspeed: 0.0217s/iter; left time: 253.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788972 Vali Loss: 0.0786097 Test Loss: 0.0835465\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0837191\n",
      "\tspeed: 0.0458s/iter; left time: 529.5029s\n",
      "\titers: 200, epoch: 49 | loss: 0.0782832\n",
      "\tspeed: 0.0217s/iter; left time: 248.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0787839 Vali Loss: 0.0786563 Test Loss: 0.0837891\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0809384\n",
      "\tspeed: 0.0472s/iter; left time: 534.0162s\n",
      "\titers: 200, epoch: 50 | loss: 0.0818458\n",
      "\tspeed: 0.0218s/iter; left time: 244.9204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0788235 Vali Loss: 0.0787580 Test Loss: 0.0837762\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0774208\n",
      "\tspeed: 0.0459s/iter; left time: 509.0606s\n",
      "\titers: 200, epoch: 51 | loss: 0.0799777\n",
      "\tspeed: 0.0217s/iter; left time: 238.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0788820 Vali Loss: 0.0786916 Test Loss: 0.0836173\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018824005499482155, rmse:0.13720060884952545, mae:0.08369677513837814, rse:0.5187702775001526\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2654191\n",
      "\tspeed: 0.0241s/iter; left time: 538.1012s\n",
      "\titers: 200, epoch: 1 | loss: 0.2492951\n",
      "\tspeed: 0.0217s/iter; left time: 480.9847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.2720975 Vali Loss: 0.1865720 Test Loss: 0.1956336\n",
      "Validation loss decreased (inf --> 0.186572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1399787\n",
      "\tspeed: 0.0458s/iter; left time: 1011.0653s\n",
      "\titers: 200, epoch: 2 | loss: 0.1225978\n",
      "\tspeed: 0.0218s/iter; left time: 479.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.1536042 Vali Loss: 0.1050887 Test Loss: 0.1120235\n",
      "Validation loss decreased (0.186572 --> 0.105089).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091442\n",
      "\tspeed: 0.0453s/iter; left time: 990.8433s\n",
      "\titers: 200, epoch: 3 | loss: 0.1053985\n",
      "\tspeed: 0.0217s/iter; left time: 472.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.1085688 Vali Loss: 0.0955726 Test Loss: 0.0993485\n",
      "Validation loss decreased (0.105089 --> 0.095573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0951333\n",
      "\tspeed: 0.0461s/iter; left time: 996.2139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0935304\n",
      "\tspeed: 0.0218s/iter; left time: 469.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0973197 Vali Loss: 0.0879738 Test Loss: 0.0907920\n",
      "Validation loss decreased (0.095573 --> 0.087974).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0927496\n",
      "\tspeed: 0.0473s/iter; left time: 1012.9622s\n",
      "\titers: 200, epoch: 5 | loss: 0.0889635\n",
      "\tspeed: 0.0217s/iter; left time: 462.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0919887 Vali Loss: 0.0847625 Test Loss: 0.0883146\n",
      "Validation loss decreased (0.087974 --> 0.084763).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0863985\n",
      "\tspeed: 0.0456s/iter; left time: 965.3170s\n",
      "\titers: 200, epoch: 6 | loss: 0.0812696\n",
      "\tspeed: 0.0218s/iter; left time: 459.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0887311 Vali Loss: 0.0829828 Test Loss: 0.0867898\n",
      "Validation loss decreased (0.084763 --> 0.082983).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0859024\n",
      "\tspeed: 0.0470s/iter; left time: 984.9223s\n",
      "\titers: 200, epoch: 7 | loss: 0.0824680\n",
      "\tspeed: 0.0220s/iter; left time: 458.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0867531 Vali Loss: 0.0823170 Test Loss: 0.0859335\n",
      "Validation loss decreased (0.082983 --> 0.082317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0829310\n",
      "\tspeed: 0.0457s/iter; left time: 948.4520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0867653\n",
      "\tspeed: 0.0218s/iter; left time: 449.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0859316 Vali Loss: 0.0816922 Test Loss: 0.0854676\n",
      "Validation loss decreased (0.082317 --> 0.081692).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843637\n",
      "\tspeed: 0.0474s/iter; left time: 972.4026s\n",
      "\titers: 200, epoch: 9 | loss: 0.0852142\n",
      "\tspeed: 0.0217s/iter; left time: 443.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0842771 Vali Loss: 0.0803814 Test Loss: 0.0849513\n",
      "Validation loss decreased (0.081692 --> 0.080381).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0870816\n",
      "\tspeed: 0.0464s/iter; left time: 940.4863s\n",
      "\titers: 200, epoch: 10 | loss: 0.0879768\n",
      "\tspeed: 0.0218s/iter; left time: 440.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0836242 Vali Loss: 0.0797547 Test Loss: 0.0844912\n",
      "Validation loss decreased (0.080381 --> 0.079755).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0812169\n",
      "\tspeed: 0.0461s/iter; left time: 925.5945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0777536\n",
      "\tspeed: 0.0217s/iter; left time: 432.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0829738 Vali Loss: 0.0804546 Test Loss: 0.0843853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0864148\n",
      "\tspeed: 0.0452s/iter; left time: 896.6602s\n",
      "\titers: 200, epoch: 12 | loss: 0.0833272\n",
      "\tspeed: 0.0217s/iter; left time: 428.4840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0828118 Vali Loss: 0.0791410 Test Loss: 0.0840591\n",
      "Validation loss decreased (0.079755 --> 0.079141).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0858637\n",
      "\tspeed: 0.0455s/iter; left time: 893.2174s\n",
      "\titers: 200, epoch: 13 | loss: 0.0811261\n",
      "\tspeed: 0.0217s/iter; left time: 423.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0820563 Vali Loss: 0.0792300 Test Loss: 0.0841731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0792796\n",
      "\tspeed: 0.0457s/iter; left time: 886.0508s\n",
      "\titers: 200, epoch: 14 | loss: 0.0850237\n",
      "\tspeed: 0.0218s/iter; left time: 420.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0819308 Vali Loss: 0.0791319 Test Loss: 0.0841701\n",
      "Validation loss decreased (0.079141 --> 0.079132).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0816897\n",
      "\tspeed: 0.0459s/iter; left time: 878.8331s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837741\n",
      "\tspeed: 0.0217s/iter; left time: 414.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0818446 Vali Loss: 0.0790949 Test Loss: 0.0838779\n",
      "Validation loss decreased (0.079132 --> 0.079095).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0772030\n",
      "\tspeed: 0.0458s/iter; left time: 867.5762s\n",
      "\titers: 200, epoch: 16 | loss: 0.0822015\n",
      "\tspeed: 0.0219s/iter; left time: 413.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0812685 Vali Loss: 0.0790294 Test Loss: 0.0839537\n",
      "Validation loss decreased (0.079095 --> 0.079029).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0825713\n",
      "\tspeed: 0.0471s/iter; left time: 882.2171s\n",
      "\titers: 200, epoch: 17 | loss: 0.0802149\n",
      "\tspeed: 0.0219s/iter; left time: 407.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0809672 Vali Loss: 0.0786991 Test Loss: 0.0841665\n",
      "Validation loss decreased (0.079029 --> 0.078699).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0789418\n",
      "\tspeed: 0.0461s/iter; left time: 851.8721s\n",
      "\titers: 200, epoch: 18 | loss: 0.0843566\n",
      "\tspeed: 0.0218s/iter; left time: 400.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0809835 Vali Loss: 0.0788321 Test Loss: 0.0836655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0792370\n",
      "\tspeed: 0.0459s/iter; left time: 838.3063s\n",
      "\titers: 200, epoch: 19 | loss: 0.0805640\n",
      "\tspeed: 0.0219s/iter; left time: 397.2642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0805153 Vali Loss: 0.0783761 Test Loss: 0.0838527\n",
      "Validation loss decreased (0.078699 --> 0.078376).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802716\n",
      "\tspeed: 0.0467s/iter; left time: 843.0910s\n",
      "\titers: 200, epoch: 20 | loss: 0.0811779\n",
      "\tspeed: 0.0218s/iter; left time: 391.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0803617 Vali Loss: 0.0781926 Test Loss: 0.0836971\n",
      "Validation loss decreased (0.078376 --> 0.078193).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814950\n",
      "\tspeed: 0.0459s/iter; left time: 817.4507s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779797\n",
      "\tspeed: 0.0218s/iter; left time: 386.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0803367 Vali Loss: 0.0780951 Test Loss: 0.0833912\n",
      "Validation loss decreased (0.078193 --> 0.078095).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0752782\n",
      "\tspeed: 0.0457s/iter; left time: 803.3243s\n",
      "\titers: 200, epoch: 22 | loss: 0.0836513\n",
      "\tspeed: 0.0217s/iter; left time: 380.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0799694 Vali Loss: 0.0783406 Test Loss: 0.0837624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772950\n",
      "\tspeed: 0.0454s/iter; left time: 787.8871s\n",
      "\titers: 200, epoch: 23 | loss: 0.0788521\n",
      "\tspeed: 0.0218s/iter; left time: 376.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0798195 Vali Loss: 0.0780636 Test Loss: 0.0836977\n",
      "Validation loss decreased (0.078095 --> 0.078064).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0814265\n",
      "\tspeed: 0.0452s/iter; left time: 774.2932s\n",
      "\titers: 200, epoch: 24 | loss: 0.0788700\n",
      "\tspeed: 0.0218s/iter; left time: 371.1320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0798068 Vali Loss: 0.0778582 Test Loss: 0.0834748\n",
      "Validation loss decreased (0.078064 --> 0.077858).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0803527\n",
      "\tspeed: 0.0461s/iter; left time: 779.8283s\n",
      "\titers: 200, epoch: 25 | loss: 0.0848269\n",
      "\tspeed: 0.0217s/iter; left time: 365.7078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0798114 Vali Loss: 0.0780343 Test Loss: 0.0838131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0838103\n",
      "\tspeed: 0.0454s/iter; left time: 757.7270s\n",
      "\titers: 200, epoch: 26 | loss: 0.0776953\n",
      "\tspeed: 0.0218s/iter; left time: 361.7082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0795814 Vali Loss: 0.0778576 Test Loss: 0.0835398\n",
      "Validation loss decreased (0.077858 --> 0.077858).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0771144\n",
      "\tspeed: 0.0471s/iter; left time: 776.1938s\n",
      "\titers: 200, epoch: 27 | loss: 0.0803550\n",
      "\tspeed: 0.0218s/iter; left time: 357.4137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0797561 Vali Loss: 0.0780170 Test Loss: 0.0836571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0777727\n",
      "\tspeed: 0.0451s/iter; left time: 733.4159s\n",
      "\titers: 200, epoch: 28 | loss: 0.0748627\n",
      "\tspeed: 0.0217s/iter; left time: 351.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0795140 Vali Loss: 0.0779177 Test Loss: 0.0836448\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0832448\n",
      "\tspeed: 0.0453s/iter; left time: 726.1415s\n",
      "\titers: 200, epoch: 29 | loss: 0.0789319\n",
      "\tspeed: 0.0218s/iter; left time: 346.9720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0795038 Vali Loss: 0.0777554 Test Loss: 0.0836502\n",
      "Validation loss decreased (0.077858 --> 0.077755).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0811197\n",
      "\tspeed: 0.0459s/iter; left time: 724.9185s\n",
      "\titers: 200, epoch: 30 | loss: 0.0765274\n",
      "\tspeed: 0.0218s/iter; left time: 342.4718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0794699 Vali Loss: 0.0783273 Test Loss: 0.0839464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0803536\n",
      "\tspeed: 0.0457s/iter; left time: 712.1239s\n",
      "\titers: 200, epoch: 31 | loss: 0.0779944\n",
      "\tspeed: 0.0217s/iter; left time: 336.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0793642 Vali Loss: 0.0775169 Test Loss: 0.0833227\n",
      "Validation loss decreased (0.077755 --> 0.077517).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0745973\n",
      "\tspeed: 0.0461s/iter; left time: 707.4138s\n",
      "\titers: 200, epoch: 32 | loss: 0.0782623\n",
      "\tspeed: 0.0218s/iter; left time: 332.0141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0792247 Vali Loss: 0.0776478 Test Loss: 0.0833616\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0801016\n",
      "\tspeed: 0.0451s/iter; left time: 682.5111s\n",
      "\titers: 200, epoch: 33 | loss: 0.0779588\n",
      "\tspeed: 0.0218s/iter; left time: 327.3951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0799833 Vali Loss: 0.0777766 Test Loss: 0.0834873\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0816889\n",
      "\tspeed: 0.0450s/iter; left time: 671.4194s\n",
      "\titers: 200, epoch: 34 | loss: 0.0831700\n",
      "\tspeed: 0.0217s/iter; left time: 321.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0792972 Vali Loss: 0.0779381 Test Loss: 0.0835514\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0768755\n",
      "\tspeed: 0.0452s/iter; left time: 663.1688s\n",
      "\titers: 200, epoch: 35 | loss: 0.0796030\n",
      "\tspeed: 0.0218s/iter; left time: 317.6736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0791943 Vali Loss: 0.0777968 Test Loss: 0.0835614\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0773502\n",
      "\tspeed: 0.0460s/iter; left time: 665.0932s\n",
      "\titers: 200, epoch: 36 | loss: 0.0780936\n",
      "\tspeed: 0.0220s/iter; left time: 315.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0791645 Vali Loss: 0.0775731 Test Loss: 0.0833945\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0796844\n",
      "\tspeed: 0.0457s/iter; left time: 650.1146s\n",
      "\titers: 200, epoch: 37 | loss: 0.0773664\n",
      "\tspeed: 0.0218s/iter; left time: 308.8219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0792220 Vali Loss: 0.0775868 Test Loss: 0.0835307\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0818282\n",
      "\tspeed: 0.0455s/iter; left time: 636.9339s\n",
      "\titers: 200, epoch: 38 | loss: 0.0762107\n",
      "\tspeed: 0.0219s/iter; left time: 304.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0790748 Vali Loss: 0.0777856 Test Loss: 0.0835588\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0811020\n",
      "\tspeed: 0.0455s/iter; left time: 626.8747s\n",
      "\titers: 200, epoch: 39 | loss: 0.0792930\n",
      "\tspeed: 0.0217s/iter; left time: 297.6207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0791693 Vali Loss: 0.0778655 Test Loss: 0.0836741\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0785080\n",
      "\tspeed: 0.0457s/iter; left time: 619.8744s\n",
      "\titers: 200, epoch: 40 | loss: 0.0768711\n",
      "\tspeed: 0.0218s/iter; left time: 292.8648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0789317 Vali Loss: 0.0776449 Test Loss: 0.0834714\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0819468\n",
      "\tspeed: 0.0463s/iter; left time: 617.9193s\n",
      "\titers: 200, epoch: 41 | loss: 0.0790669\n",
      "\tspeed: 0.0218s/iter; left time: 288.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0790118 Vali Loss: 0.0776679 Test Loss: 0.0834917\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018634524196386337, rmse:0.13650833070278168, mae:0.08332263678312302, rse:0.5161527395248413\n",
      "Intermediate time for IT and pred_len 96: 00h:10m:34.19s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2593685\n",
      "\tspeed: 0.0405s/iter; left time: 898.9807s\n",
      "\titers: 200, epoch: 1 | loss: 0.2436044\n",
      "\tspeed: 0.0220s/iter; left time: 486.0357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.2658861 Vali Loss: 0.1834447 Test Loss: 0.1922477\n",
      "Validation loss decreased (inf --> 0.183445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1407781\n",
      "\tspeed: 0.0461s/iter; left time: 1014.0556s\n",
      "\titers: 200, epoch: 2 | loss: 0.1193458\n",
      "\tspeed: 0.0221s/iter; left time: 482.6069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.1517239 Vali Loss: 0.1063502 Test Loss: 0.1113415\n",
      "Validation loss decreased (0.183445 --> 0.106350).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147257\n",
      "\tspeed: 0.0481s/iter; left time: 1046.0926s\n",
      "\titers: 200, epoch: 3 | loss: 0.1031990\n",
      "\tspeed: 0.0222s/iter; left time: 480.0104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.1103073 Vali Loss: 0.1010213 Test Loss: 0.1056513\n",
      "Validation loss decreased (0.106350 --> 0.101021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1029070\n",
      "\tspeed: 0.0472s/iter; left time: 1016.9723s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007020\n",
      "\tspeed: 0.0221s/iter; left time: 473.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.1000806 Vali Loss: 0.0917719 Test Loss: 0.0934857\n",
      "Validation loss decreased (0.101021 --> 0.091772).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0904802\n",
      "\tspeed: 0.0475s/iter; left time: 1012.0715s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915495\n",
      "\tspeed: 0.0221s/iter; left time: 469.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0945440 Vali Loss: 0.0885954 Test Loss: 0.0915012\n",
      "Validation loss decreased (0.091772 --> 0.088595).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913310\n",
      "\tspeed: 0.0465s/iter; left time: 981.2804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0933463\n",
      "\tspeed: 0.0220s/iter; left time: 462.0953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0920161 Vali Loss: 0.0871038 Test Loss: 0.0899142\n",
      "Validation loss decreased (0.088595 --> 0.087104).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0896496\n",
      "\tspeed: 0.0464s/iter; left time: 968.5718s\n",
      "\titers: 200, epoch: 7 | loss: 0.0911744\n",
      "\tspeed: 0.0221s/iter; left time: 458.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0899998 Vali Loss: 0.0861870 Test Loss: 0.0892110\n",
      "Validation loss decreased (0.087104 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0874285\n",
      "\tspeed: 0.0474s/iter; left time: 978.4582s\n",
      "\titers: 200, epoch: 8 | loss: 0.0868309\n",
      "\tspeed: 0.0222s/iter; left time: 455.2393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0887113 Vali Loss: 0.0859383 Test Loss: 0.0894966\n",
      "Validation loss decreased (0.086187 --> 0.085938).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0855003\n",
      "\tspeed: 0.0476s/iter; left time: 970.8596s\n",
      "\titers: 200, epoch: 9 | loss: 0.0856321\n",
      "\tspeed: 0.0222s/iter; left time: 450.5544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0878365 Vali Loss: 0.0863210 Test Loss: 0.0901244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0847125\n",
      "\tspeed: 0.0474s/iter; left time: 957.1523s\n",
      "\titers: 200, epoch: 10 | loss: 0.0874492\n",
      "\tspeed: 0.0222s/iter; left time: 445.1648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0870967 Vali Loss: 0.0845443 Test Loss: 0.0875666\n",
      "Validation loss decreased (0.085938 --> 0.084544).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0871908\n",
      "\tspeed: 0.0471s/iter; left time: 940.1918s\n",
      "\titers: 200, epoch: 11 | loss: 0.0818305\n",
      "\tspeed: 0.0221s/iter; left time: 439.5144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0863422 Vali Loss: 0.0841798 Test Loss: 0.0872976\n",
      "Validation loss decreased (0.084544 --> 0.084180).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837236\n",
      "\tspeed: 0.0473s/iter; left time: 933.5158s\n",
      "\titers: 200, epoch: 12 | loss: 0.0858295\n",
      "\tspeed: 0.0221s/iter; left time: 433.3770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0862503 Vali Loss: 0.0846573 Test Loss: 0.0883181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0840104\n",
      "\tspeed: 0.0463s/iter; left time: 903.0344s\n",
      "\titers: 200, epoch: 13 | loss: 0.0873080\n",
      "\tspeed: 0.0221s/iter; left time: 428.4650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0858051 Vali Loss: 0.0841540 Test Loss: 0.0875185\n",
      "Validation loss decreased (0.084180 --> 0.084154).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0842696\n",
      "\tspeed: 0.0473s/iter; left time: 912.9072s\n",
      "\titers: 200, epoch: 14 | loss: 0.0864293\n",
      "\tspeed: 0.0221s/iter; left time: 424.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0852016 Vali Loss: 0.0839391 Test Loss: 0.0871678\n",
      "Validation loss decreased (0.084154 --> 0.083939).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0835843\n",
      "\tspeed: 0.0468s/iter; left time: 893.7223s\n",
      "\titers: 200, epoch: 15 | loss: 0.0903612\n",
      "\tspeed: 0.0220s/iter; left time: 418.3282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0850153 Vali Loss: 0.0849698 Test Loss: 0.0885047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0866383\n",
      "\tspeed: 0.0467s/iter; left time: 881.0883s\n",
      "\titers: 200, epoch: 16 | loss: 0.0840572\n",
      "\tspeed: 0.0220s/iter; left time: 412.5113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0846479 Vali Loss: 0.0838537 Test Loss: 0.0874743\n",
      "Validation loss decreased (0.083939 --> 0.083854).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0856122\n",
      "\tspeed: 0.0471s/iter; left time: 878.2778s\n",
      "\titers: 200, epoch: 17 | loss: 0.0852672\n",
      "\tspeed: 0.0220s/iter; left time: 408.4244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0853350 Vali Loss: 0.0845202 Test Loss: 0.0880538\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0798638\n",
      "\tspeed: 0.0462s/iter; left time: 850.9026s\n",
      "\titers: 200, epoch: 18 | loss: 0.0865999\n",
      "\tspeed: 0.0220s/iter; left time: 402.8317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0847002 Vali Loss: 0.0843393 Test Loss: 0.0880147\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0824680\n",
      "\tspeed: 0.0460s/iter; left time: 836.3134s\n",
      "\titers: 200, epoch: 19 | loss: 0.0845451\n",
      "\tspeed: 0.0220s/iter; left time: 397.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0840779 Vali Loss: 0.0829712 Test Loss: 0.0871362\n",
      "Validation loss decreased (0.083854 --> 0.082971).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0837010\n",
      "\tspeed: 0.0460s/iter; left time: 826.4075s\n",
      "\titers: 200, epoch: 20 | loss: 0.0806240\n",
      "\tspeed: 0.0220s/iter; left time: 392.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0840868 Vali Loss: 0.0831228 Test Loss: 0.0872801\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0838653\n",
      "\tspeed: 0.0461s/iter; left time: 817.0826s\n",
      "\titers: 200, epoch: 21 | loss: 0.0840183\n",
      "\tspeed: 0.0220s/iter; left time: 388.1818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0838349 Vali Loss: 0.0828729 Test Loss: 0.0870302\n",
      "Validation loss decreased (0.082971 --> 0.082873).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0847097\n",
      "\tspeed: 0.0467s/iter; left time: 817.3500s\n",
      "\titers: 200, epoch: 22 | loss: 0.0875652\n",
      "\tspeed: 0.0221s/iter; left time: 384.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0837299 Vali Loss: 0.0827980 Test Loss: 0.0872208\n",
      "Validation loss decreased (0.082873 --> 0.082798).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0790841\n",
      "\tspeed: 0.0460s/iter; left time: 795.1605s\n",
      "\titers: 200, epoch: 23 | loss: 0.0829606\n",
      "\tspeed: 0.0219s/iter; left time: 377.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0837755 Vali Loss: 0.0830272 Test Loss: 0.0870533\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0868019\n",
      "\tspeed: 0.0460s/iter; left time: 784.4881s\n",
      "\titers: 200, epoch: 24 | loss: 0.0897313\n",
      "\tspeed: 0.0219s/iter; left time: 372.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0836040 Vali Loss: 0.0829900 Test Loss: 0.0873390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0835902\n",
      "\tspeed: 0.0455s/iter; left time: 766.2783s\n",
      "\titers: 200, epoch: 25 | loss: 0.0825780\n",
      "\tspeed: 0.0219s/iter; left time: 367.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0835581 Vali Loss: 0.0830822 Test Loss: 0.0870602\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0857956\n",
      "\tspeed: 0.0470s/iter; left time: 781.0885s\n",
      "\titers: 200, epoch: 26 | loss: 0.0841903\n",
      "\tspeed: 0.0220s/iter; left time: 363.4675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0834239 Vali Loss: 0.0828397 Test Loss: 0.0869646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0810797\n",
      "\tspeed: 0.0460s/iter; left time: 754.0497s\n",
      "\titers: 200, epoch: 27 | loss: 0.0865426\n",
      "\tspeed: 0.0219s/iter; left time: 357.7710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0834309 Vali Loss: 0.0834939 Test Loss: 0.0877459\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0841784\n",
      "\tspeed: 0.0462s/iter; left time: 747.3007s\n",
      "\titers: 200, epoch: 28 | loss: 0.0836473\n",
      "\tspeed: 0.0220s/iter; left time: 354.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0833612 Vali Loss: 0.0831791 Test Loss: 0.0874583\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0798603\n",
      "\tspeed: 0.0456s/iter; left time: 726.8698s\n",
      "\titers: 200, epoch: 29 | loss: 0.0834853\n",
      "\tspeed: 0.0220s/iter; left time: 349.2857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0831603 Vali Loss: 0.0829199 Test Loss: 0.0874351\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0816144\n",
      "\tspeed: 0.0469s/iter; left time: 737.3853s\n",
      "\titers: 200, epoch: 30 | loss: 0.0862560\n",
      "\tspeed: 0.0220s/iter; left time: 344.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0831205 Vali Loss: 0.0827721 Test Loss: 0.0871754\n",
      "Validation loss decreased (0.082798 --> 0.082772).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0850103\n",
      "\tspeed: 0.0476s/iter; left time: 738.3852s\n",
      "\titers: 200, epoch: 31 | loss: 0.0829719\n",
      "\tspeed: 0.0220s/iter; left time: 338.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0831990 Vali Loss: 0.0827966 Test Loss: 0.0871364\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0816215\n",
      "\tspeed: 0.0459s/iter; left time: 701.7504s\n",
      "\titers: 200, epoch: 32 | loss: 0.0827003\n",
      "\tspeed: 0.0220s/iter; left time: 334.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0830870 Vali Loss: 0.0832036 Test Loss: 0.0876115\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0822320\n",
      "\tspeed: 0.0455s/iter; left time: 685.9821s\n",
      "\titers: 200, epoch: 33 | loss: 0.0830600\n",
      "\tspeed: 0.0220s/iter; left time: 329.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0830390 Vali Loss: 0.0826716 Test Loss: 0.0873047\n",
      "Validation loss decreased (0.082772 --> 0.082672).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0803795\n",
      "\tspeed: 0.0465s/iter; left time: 689.9992s\n",
      "\titers: 200, epoch: 34 | loss: 0.0844212\n",
      "\tspeed: 0.0220s/iter; left time: 323.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0829971 Vali Loss: 0.0829689 Test Loss: 0.0872176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0836070\n",
      "\tspeed: 0.0464s/iter; left time: 678.1191s\n",
      "\titers: 200, epoch: 35 | loss: 0.0822811\n",
      "\tspeed: 0.0219s/iter; left time: 318.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0829739 Vali Loss: 0.0829763 Test Loss: 0.0873647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0822121\n",
      "\tspeed: 0.0456s/iter; left time: 656.3899s\n",
      "\titers: 200, epoch: 36 | loss: 0.0837157\n",
      "\tspeed: 0.0220s/iter; left time: 314.0795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0829454 Vali Loss: 0.0826224 Test Loss: 0.0870566\n",
      "Validation loss decreased (0.082672 --> 0.082622).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0821490\n",
      "\tspeed: 0.0465s/iter; left time: 659.3375s\n",
      "\titers: 200, epoch: 37 | loss: 0.0808399\n",
      "\tspeed: 0.0220s/iter; left time: 309.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0831293 Vali Loss: 0.0828235 Test Loss: 0.0872067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0868248\n",
      "\tspeed: 0.0467s/iter; left time: 651.4406s\n",
      "\titers: 200, epoch: 38 | loss: 0.0834173\n",
      "\tspeed: 0.0220s/iter; left time: 304.0136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0831270 Vali Loss: 0.0828858 Test Loss: 0.0871896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0833493\n",
      "\tspeed: 0.0470s/iter; left time: 645.0403s\n",
      "\titers: 200, epoch: 39 | loss: 0.0841909\n",
      "\tspeed: 0.0220s/iter; left time: 300.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0829811 Vali Loss: 0.0828958 Test Loss: 0.0873336\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0824400\n",
      "\tspeed: 0.0457s/iter; left time: 617.6108s\n",
      "\titers: 200, epoch: 40 | loss: 0.0821157\n",
      "\tspeed: 0.0220s/iter; left time: 294.8123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0830106 Vali Loss: 0.0828837 Test Loss: 0.0871975\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0823991\n",
      "\tspeed: 0.0464s/iter; left time: 615.7225s\n",
      "\titers: 200, epoch: 41 | loss: 0.0807214\n",
      "\tspeed: 0.0219s/iter; left time: 289.1728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0828080 Vali Loss: 0.0830184 Test Loss: 0.0873392\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0841578\n",
      "\tspeed: 0.0465s/iter; left time: 607.5300s\n",
      "\titers: 200, epoch: 42 | loss: 0.0809948\n",
      "\tspeed: 0.0221s/iter; left time: 285.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0828283 Vali Loss: 0.0825982 Test Loss: 0.0871560\n",
      "Validation loss decreased (0.082622 --> 0.082598).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0829908\n",
      "\tspeed: 0.0459s/iter; left time: 588.8886s\n",
      "\titers: 200, epoch: 43 | loss: 0.0835017\n",
      "\tspeed: 0.0220s/iter; left time: 279.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0828749 Vali Loss: 0.0826529 Test Loss: 0.0871838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0827640\n",
      "\tspeed: 0.0460s/iter; left time: 580.5419s\n",
      "\titers: 200, epoch: 44 | loss: 0.0828017\n",
      "\tspeed: 0.0220s/iter; left time: 275.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0828612 Vali Loss: 0.0826238 Test Loss: 0.0872305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0829563\n",
      "\tspeed: 0.0461s/iter; left time: 570.6787s\n",
      "\titers: 200, epoch: 45 | loss: 0.0845657\n",
      "\tspeed: 0.0219s/iter; left time: 269.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827854 Vali Loss: 0.0828263 Test Loss: 0.0873275\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0868040\n",
      "\tspeed: 0.0457s/iter; left time: 556.2922s\n",
      "\titers: 200, epoch: 46 | loss: 0.0862150\n",
      "\tspeed: 0.0221s/iter; left time: 266.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0827368 Vali Loss: 0.0827539 Test Loss: 0.0872403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0846043\n",
      "\tspeed: 0.0466s/iter; left time: 556.4608s\n",
      "\titers: 200, epoch: 47 | loss: 0.0840427\n",
      "\tspeed: 0.0220s/iter; left time: 260.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0826896 Vali Loss: 0.0826987 Test Loss: 0.0872980\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0892193\n",
      "\tspeed: 0.0459s/iter; left time: 538.0240s\n",
      "\titers: 200, epoch: 48 | loss: 0.0814552\n",
      "\tspeed: 0.0220s/iter; left time: 255.9023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0828820 Vali Loss: 0.0830107 Test Loss: 0.0873947\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0841394\n",
      "\tspeed: 0.0467s/iter; left time: 537.0289s\n",
      "\titers: 200, epoch: 49 | loss: 0.0814938\n",
      "\tspeed: 0.0220s/iter; left time: 250.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0828457 Vali Loss: 0.0824850 Test Loss: 0.0870350\n",
      "Validation loss decreased (0.082598 --> 0.082485).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0864921\n",
      "\tspeed: 0.0459s/iter; left time: 517.8780s\n",
      "\titers: 200, epoch: 50 | loss: 0.0840216\n",
      "\tspeed: 0.0220s/iter; left time: 246.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0827708 Vali Loss: 0.0827214 Test Loss: 0.0871683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0822083\n",
      "\tspeed: 0.0455s/iter; left time: 502.8970s\n",
      "\titers: 200, epoch: 51 | loss: 0.0828765\n",
      "\tspeed: 0.0219s/iter; left time: 240.0809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0827678 Vali Loss: 0.0828792 Test Loss: 0.0872527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0832035\n",
      "\tspeed: 0.0459s/iter; left time: 496.7346s\n",
      "\titers: 200, epoch: 52 | loss: 0.0844733\n",
      "\tspeed: 0.0220s/iter; left time: 235.7535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0826931 Vali Loss: 0.0825402 Test Loss: 0.0871795\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0801339\n",
      "\tspeed: 0.0453s/iter; left time: 480.5976s\n",
      "\titers: 200, epoch: 53 | loss: 0.0849573\n",
      "\tspeed: 0.0220s/iter; left time: 230.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827957 Vali Loss: 0.0825594 Test Loss: 0.0871752\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0821759\n",
      "\tspeed: 0.0453s/iter; left time: 470.1620s\n",
      "\titers: 200, epoch: 54 | loss: 0.0818415\n",
      "\tspeed: 0.0220s/iter; left time: 226.4498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0827428 Vali Loss: 0.0826589 Test Loss: 0.0872044\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0848550\n",
      "\tspeed: 0.0458s/iter; left time: 465.7023s\n",
      "\titers: 200, epoch: 55 | loss: 0.0852969\n",
      "\tspeed: 0.0220s/iter; left time: 221.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827881 Vali Loss: 0.0825741 Test Loss: 0.0872493\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0825167\n",
      "\tspeed: 0.0456s/iter; left time: 452.9776s\n",
      "\titers: 200, epoch: 56 | loss: 0.0810092\n",
      "\tspeed: 0.0219s/iter; left time: 215.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0826493 Vali Loss: 0.0825289 Test Loss: 0.0872128\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0799878\n",
      "\tspeed: 0.0456s/iter; left time: 442.9017s\n",
      "\titers: 200, epoch: 57 | loss: 0.0830834\n",
      "\tspeed: 0.0220s/iter; left time: 211.7394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0826917 Vali Loss: 0.0825688 Test Loss: 0.0871434\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0829910\n",
      "\tspeed: 0.0475s/iter; left time: 450.3544s\n",
      "\titers: 200, epoch: 58 | loss: 0.0806161\n",
      "\tspeed: 0.0220s/iter; left time: 206.1620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0826969 Vali Loss: 0.0825653 Test Loss: 0.0871960\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0799795\n",
      "\tspeed: 0.0457s/iter; left time: 423.5705s\n",
      "\titers: 200, epoch: 59 | loss: 0.0835380\n",
      "\tspeed: 0.0220s/iter; left time: 201.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0826923 Vali Loss: 0.0824179 Test Loss: 0.0871157\n",
      "Validation loss decreased (0.082485 --> 0.082418).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0828893\n",
      "\tspeed: 0.0464s/iter; left time: 419.4648s\n",
      "\titers: 200, epoch: 60 | loss: 0.0850512\n",
      "\tspeed: 0.0220s/iter; left time: 197.0472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0825990 Vali Loss: 0.0826143 Test Loss: 0.0871236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0886924\n",
      "\tspeed: 0.0455s/iter; left time: 401.0363s\n",
      "\titers: 200, epoch: 61 | loss: 0.0793289\n",
      "\tspeed: 0.0220s/iter; left time: 191.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0827438 Vali Loss: 0.0821354 Test Loss: 0.0871118\n",
      "Validation loss decreased (0.082418 --> 0.082135).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0824173\n",
      "\tspeed: 0.0457s/iter; left time: 392.7647s\n",
      "\titers: 200, epoch: 62 | loss: 0.0811318\n",
      "\tspeed: 0.0220s/iter; left time: 186.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827405 Vali Loss: 0.0824807 Test Loss: 0.0870766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0835284\n",
      "\tspeed: 0.0467s/iter; left time: 390.9252s\n",
      "\titers: 200, epoch: 63 | loss: 0.1137236\n",
      "\tspeed: 0.0221s/iter; left time: 182.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0828660 Vali Loss: 0.0826132 Test Loss: 0.0872791\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0830507\n",
      "\tspeed: 0.0467s/iter; left time: 380.5016s\n",
      "\titers: 200, epoch: 64 | loss: 0.0820392\n",
      "\tspeed: 0.0220s/iter; left time: 177.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0826460 Vali Loss: 0.0827017 Test Loss: 0.0873357\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0806877\n",
      "\tspeed: 0.0464s/iter; left time: 367.5741s\n",
      "\titers: 200, epoch: 65 | loss: 0.0851976\n",
      "\tspeed: 0.0220s/iter; left time: 172.5304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0826986 Vali Loss: 0.0823724 Test Loss: 0.0871242\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0820866\n",
      "\tspeed: 0.0458s/iter; left time: 353.2676s\n",
      "\titers: 200, epoch: 66 | loss: 0.0867027\n",
      "\tspeed: 0.0219s/iter; left time: 166.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827033 Vali Loss: 0.0826242 Test Loss: 0.0871462\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0812859\n",
      "\tspeed: 0.0450s/iter; left time: 336.5091s\n",
      "\titers: 200, epoch: 67 | loss: 0.0821370\n",
      "\tspeed: 0.0219s/iter; left time: 161.4200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0827175 Vali Loss: 0.0826630 Test Loss: 0.0871136\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0808324\n",
      "\tspeed: 0.0459s/iter; left time: 333.2064s\n",
      "\titers: 200, epoch: 68 | loss: 0.0796144\n",
      "\tspeed: 0.0219s/iter; left time: 156.8106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0827011 Vali Loss: 0.0825143 Test Loss: 0.0871246\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0830997\n",
      "\tspeed: 0.0446s/iter; left time: 314.0972s\n",
      "\titers: 200, epoch: 69 | loss: 0.0856903\n",
      "\tspeed: 0.0219s/iter; left time: 151.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0828258 Vali Loss: 0.0828641 Test Loss: 0.0873644\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0812915\n",
      "\tspeed: 0.0461s/iter; left time: 314.3249s\n",
      "\titers: 200, epoch: 70 | loss: 0.0829005\n",
      "\tspeed: 0.0220s/iter; left time: 147.9147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827522 Vali Loss: 0.0826536 Test Loss: 0.0871776\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0844976\n",
      "\tspeed: 0.0458s/iter; left time: 301.7250s\n",
      "\titers: 200, epoch: 71 | loss: 0.0787759\n",
      "\tspeed: 0.0219s/iter; left time: 142.3047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0826554 Vali Loss: 0.0824497 Test Loss: 0.0870941\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01985550858080387, rmse:0.1409095823764801, mae:0.08711183071136475, rse:0.53328937292099\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2663303\n",
      "\tspeed: 0.0241s/iter; left time: 534.3388s\n",
      "\titers: 200, epoch: 1 | loss: 0.2495897\n",
      "\tspeed: 0.0218s/iter; left time: 482.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.2699061 Vali Loss: 0.1853016 Test Loss: 0.1929747\n",
      "Validation loss decreased (inf --> 0.185302).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1406610\n",
      "\tspeed: 0.0461s/iter; left time: 1012.8444s\n",
      "\titers: 200, epoch: 2 | loss: 0.1205855\n",
      "\tspeed: 0.0221s/iter; left time: 482.4941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.1529040 Vali Loss: 0.1062459 Test Loss: 0.1111591\n",
      "Validation loss decreased (0.185302 --> 0.106246).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135620\n",
      "\tspeed: 0.0472s/iter; left time: 1027.5622s\n",
      "\titers: 200, epoch: 3 | loss: 0.1049397\n",
      "\tspeed: 0.0219s/iter; left time: 475.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.1101596 Vali Loss: 0.0964184 Test Loss: 0.0986221\n",
      "Validation loss decreased (0.106246 --> 0.096418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0955819\n",
      "\tspeed: 0.0466s/iter; left time: 1003.8268s\n",
      "\titers: 200, epoch: 4 | loss: 0.0951034\n",
      "\tspeed: 0.0219s/iter; left time: 469.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0991363 Vali Loss: 0.0909867 Test Loss: 0.0931468\n",
      "Validation loss decreased (0.096418 --> 0.090987).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0971086\n",
      "\tspeed: 0.0483s/iter; left time: 1030.2709s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963634\n",
      "\tspeed: 0.0219s/iter; left time: 465.1810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0943635 Vali Loss: 0.0883152 Test Loss: 0.0912352\n",
      "Validation loss decreased (0.090987 --> 0.088315).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913551\n",
      "\tspeed: 0.0466s/iter; left time: 982.0530s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931478\n",
      "\tspeed: 0.0219s/iter; left time: 460.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0915802 Vali Loss: 0.0879002 Test Loss: 0.0911573\n",
      "Validation loss decreased (0.088315 --> 0.087900).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0909168\n",
      "\tspeed: 0.0474s/iter; left time: 989.1074s\n",
      "\titers: 200, epoch: 7 | loss: 0.0904019\n",
      "\tspeed: 0.0219s/iter; left time: 455.2580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0903473 Vali Loss: 0.0862856 Test Loss: 0.0900857\n",
      "Validation loss decreased (0.087900 --> 0.086286).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0890367\n",
      "\tspeed: 0.0464s/iter; left time: 957.4247s\n",
      "\titers: 200, epoch: 8 | loss: 0.0926520\n",
      "\tspeed: 0.0219s/iter; left time: 449.9032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0889100 Vali Loss: 0.0848608 Test Loss: 0.0887103\n",
      "Validation loss decreased (0.086286 --> 0.084861).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864818\n",
      "\tspeed: 0.0470s/iter; left time: 960.5250s\n",
      "\titers: 200, epoch: 9 | loss: 0.0847912\n",
      "\tspeed: 0.0219s/iter; left time: 445.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0878572 Vali Loss: 0.0856829 Test Loss: 0.0890467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0902095\n",
      "\tspeed: 0.0462s/iter; left time: 933.7491s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849279\n",
      "\tspeed: 0.0219s/iter; left time: 439.7982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0872292 Vali Loss: 0.0849854 Test Loss: 0.0889889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811704\n",
      "\tspeed: 0.0461s/iter; left time: 920.5602s\n",
      "\titers: 200, epoch: 11 | loss: 0.0881951\n",
      "\tspeed: 0.0219s/iter; left time: 435.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0868251 Vali Loss: 0.0849550 Test Loss: 0.0886877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0847403\n",
      "\tspeed: 0.0458s/iter; left time: 903.8987s\n",
      "\titers: 200, epoch: 12 | loss: 0.0856506\n",
      "\tspeed: 0.0219s/iter; left time: 430.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0863239 Vali Loss: 0.0835640 Test Loss: 0.0883936\n",
      "Validation loss decreased (0.084861 --> 0.083564).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0884693\n",
      "\tspeed: 0.0465s/iter; left time: 907.5706s\n",
      "\titers: 200, epoch: 13 | loss: 0.0836527\n",
      "\tspeed: 0.0219s/iter; left time: 425.7883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0857635 Vali Loss: 0.0841969 Test Loss: 0.0885494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0834788\n",
      "\tspeed: 0.0458s/iter; left time: 883.7222s\n",
      "\titers: 200, epoch: 14 | loss: 0.0901838\n",
      "\tspeed: 0.0220s/iter; left time: 422.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0855193 Vali Loss: 0.0839952 Test Loss: 0.0887053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0869290\n",
      "\tspeed: 0.0461s/iter; left time: 879.5211s\n",
      "\titers: 200, epoch: 15 | loss: 0.0855318\n",
      "\tspeed: 0.0219s/iter; left time: 414.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0850765 Vali Loss: 0.0832955 Test Loss: 0.0882019\n",
      "Validation loss decreased (0.083564 --> 0.083296).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0821112\n",
      "\tspeed: 0.0463s/iter; left time: 873.0776s\n",
      "\titers: 200, epoch: 16 | loss: 0.0844743\n",
      "\tspeed: 0.0220s/iter; left time: 412.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0849393 Vali Loss: 0.0835920 Test Loss: 0.0881210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0907413\n",
      "\tspeed: 0.0457s/iter; left time: 850.7743s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843844\n",
      "\tspeed: 0.0219s/iter; left time: 405.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0845680 Vali Loss: 0.0829000 Test Loss: 0.0882578\n",
      "Validation loss decreased (0.083296 --> 0.082900).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0878235\n",
      "\tspeed: 0.0456s/iter; left time: 839.2290s\n",
      "\titers: 200, epoch: 18 | loss: 0.0827412\n",
      "\tspeed: 0.0219s/iter; left time: 400.3961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0844269 Vali Loss: 0.0832814 Test Loss: 0.0883249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869892\n",
      "\tspeed: 0.0454s/iter; left time: 825.8668s\n",
      "\titers: 200, epoch: 19 | loss: 0.0847519\n",
      "\tspeed: 0.0220s/iter; left time: 397.8060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0842619 Vali Loss: 0.0830225 Test Loss: 0.0879700\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0837383\n",
      "\tspeed: 0.0468s/iter; left time: 841.1474s\n",
      "\titers: 200, epoch: 20 | loss: 0.0859412\n",
      "\tspeed: 0.0219s/iter; left time: 391.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0842205 Vali Loss: 0.0827590 Test Loss: 0.0878483\n",
      "Validation loss decreased (0.082900 --> 0.082759).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0813399\n",
      "\tspeed: 0.0459s/iter; left time: 814.1196s\n",
      "\titers: 200, epoch: 21 | loss: 0.0846907\n",
      "\tspeed: 0.0219s/iter; left time: 386.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0838792 Vali Loss: 0.0828150 Test Loss: 0.0884018\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0840088\n",
      "\tspeed: 0.0453s/iter; left time: 794.3800s\n",
      "\titers: 200, epoch: 22 | loss: 0.0823603\n",
      "\tspeed: 0.0219s/iter; left time: 382.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0838453 Vali Loss: 0.0830889 Test Loss: 0.0882742\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0839935\n",
      "\tspeed: 0.0458s/iter; left time: 792.6348s\n",
      "\titers: 200, epoch: 23 | loss: 0.0839733\n",
      "\tspeed: 0.0219s/iter; left time: 376.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0835122 Vali Loss: 0.0826695 Test Loss: 0.0882341\n",
      "Validation loss decreased (0.082759 --> 0.082670).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0827538\n",
      "\tspeed: 0.0458s/iter; left time: 781.6747s\n",
      "\titers: 200, epoch: 24 | loss: 0.0846985\n",
      "\tspeed: 0.0219s/iter; left time: 370.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0835666 Vali Loss: 0.0826776 Test Loss: 0.0880646\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0829660\n",
      "\tspeed: 0.0458s/iter; left time: 772.1862s\n",
      "\titers: 200, epoch: 25 | loss: 0.0848448\n",
      "\tspeed: 0.0222s/iter; left time: 372.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0835243 Vali Loss: 0.0827565 Test Loss: 0.0883843\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0828879\n",
      "\tspeed: 0.0454s/iter; left time: 754.4651s\n",
      "\titers: 200, epoch: 26 | loss: 0.0840080\n",
      "\tspeed: 0.0219s/iter; left time: 361.7626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0834005 Vali Loss: 0.0826957 Test Loss: 0.0882677\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0852914\n",
      "\tspeed: 0.0456s/iter; left time: 748.4981s\n",
      "\titers: 200, epoch: 27 | loss: 0.0843093\n",
      "\tspeed: 0.0219s/iter; left time: 357.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0831468 Vali Loss: 0.0826491 Test Loss: 0.0884727\n",
      "Validation loss decreased (0.082670 --> 0.082649).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0855318\n",
      "\tspeed: 0.0463s/iter; left time: 748.9012s\n",
      "\titers: 200, epoch: 28 | loss: 0.0809674\n",
      "\tspeed: 0.0219s/iter; left time: 352.6394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0830994 Vali Loss: 0.0826731 Test Loss: 0.0883053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0818016\n",
      "\tspeed: 0.0468s/iter; left time: 746.9632s\n",
      "\titers: 200, epoch: 29 | loss: 0.0822558\n",
      "\tspeed: 0.0219s/iter; left time: 346.9320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0830391 Vali Loss: 0.0824894 Test Loss: 0.0879897\n",
      "Validation loss decreased (0.082649 --> 0.082489).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0802267\n",
      "\tspeed: 0.0463s/iter; left time: 729.1256s\n",
      "\titers: 200, epoch: 30 | loss: 0.0829845\n",
      "\tspeed: 0.0221s/iter; left time: 345.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0831334 Vali Loss: 0.0825363 Test Loss: 0.0881116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0839852\n",
      "\tspeed: 0.0470s/iter; left time: 729.6307s\n",
      "\titers: 200, epoch: 31 | loss: 0.0814398\n",
      "\tspeed: 0.0220s/iter; left time: 339.7769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0831460 Vali Loss: 0.0827973 Test Loss: 0.0882100\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0812603\n",
      "\tspeed: 0.0461s/iter; left time: 704.7270s\n",
      "\titers: 200, epoch: 32 | loss: 0.0818972\n",
      "\tspeed: 0.0219s/iter; left time: 333.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0829502 Vali Loss: 0.0825992 Test Loss: 0.0880885\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0834544\n",
      "\tspeed: 0.0459s/iter; left time: 691.6956s\n",
      "\titers: 200, epoch: 33 | loss: 0.0835315\n",
      "\tspeed: 0.0219s/iter; left time: 328.4681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0829364 Vali Loss: 0.0823315 Test Loss: 0.0881189\n",
      "Validation loss decreased (0.082489 --> 0.082332).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0862341\n",
      "\tspeed: 0.0461s/iter; left time: 684.7455s\n",
      "\titers: 200, epoch: 34 | loss: 0.0865677\n",
      "\tspeed: 0.0219s/iter; left time: 322.8449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0828982 Vali Loss: 0.0827680 Test Loss: 0.0883268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0824191\n",
      "\tspeed: 0.0458s/iter; left time: 669.8288s\n",
      "\titers: 200, epoch: 35 | loss: 0.0848275\n",
      "\tspeed: 0.0219s/iter; left time: 318.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0828251 Vali Loss: 0.0822350 Test Loss: 0.0883389\n",
      "Validation loss decreased (0.082332 --> 0.082235).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0823399\n",
      "\tspeed: 0.0462s/iter; left time: 665.1212s\n",
      "\titers: 200, epoch: 36 | loss: 0.0801759\n",
      "\tspeed: 0.0220s/iter; left time: 315.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0828478 Vali Loss: 0.0825154 Test Loss: 0.0881657\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0836879\n",
      "\tspeed: 0.0463s/iter; left time: 656.3157s\n",
      "\titers: 200, epoch: 37 | loss: 0.0847765\n",
      "\tspeed: 0.0220s/iter; left time: 308.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827734 Vali Loss: 0.0824253 Test Loss: 0.0882355\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0813420\n",
      "\tspeed: 0.0454s/iter; left time: 633.1072s\n",
      "\titers: 200, epoch: 38 | loss: 0.0832034\n",
      "\tspeed: 0.0219s/iter; left time: 303.0147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0827893 Vali Loss: 0.0825257 Test Loss: 0.0882378\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0781291\n",
      "\tspeed: 0.0460s/iter; left time: 632.1010s\n",
      "\titers: 200, epoch: 39 | loss: 0.0790620\n",
      "\tspeed: 0.0220s/iter; left time: 300.1258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0826738 Vali Loss: 0.0823739 Test Loss: 0.0882329\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0861765\n",
      "\tspeed: 0.0455s/iter; left time: 614.6231s\n",
      "\titers: 200, epoch: 40 | loss: 0.0769260\n",
      "\tspeed: 0.0219s/iter; left time: 293.7609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0827674 Vali Loss: 0.0825134 Test Loss: 0.0881216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0824871\n",
      "\tspeed: 0.0450s/iter; left time: 597.6093s\n",
      "\titers: 200, epoch: 41 | loss: 0.0781540\n",
      "\tspeed: 0.0219s/iter; left time: 288.6634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0825981 Vali Loss: 0.0824952 Test Loss: 0.0882609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0817961\n",
      "\tspeed: 0.0454s/iter; left time: 592.5179s\n",
      "\titers: 200, epoch: 42 | loss: 0.0831403\n",
      "\tspeed: 0.0219s/iter; left time: 284.1682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0826483 Vali Loss: 0.0823805 Test Loss: 0.0882437\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0845329\n",
      "\tspeed: 0.0462s/iter; left time: 593.2627s\n",
      "\titers: 200, epoch: 43 | loss: 0.0830000\n",
      "\tspeed: 0.0219s/iter; left time: 279.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0826157 Vali Loss: 0.0824634 Test Loss: 0.0882632\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0831473\n",
      "\tspeed: 0.0464s/iter; left time: 585.6305s\n",
      "\titers: 200, epoch: 44 | loss: 0.0868006\n",
      "\tspeed: 0.0219s/iter; left time: 273.6515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0826969 Vali Loss: 0.0823577 Test Loss: 0.0882242\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0828054\n",
      "\tspeed: 0.0449s/iter; left time: 556.0483s\n",
      "\titers: 200, epoch: 45 | loss: 0.0823779\n",
      "\tspeed: 0.0219s/iter; left time: 268.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0826836 Vali Loss: 0.0823471 Test Loss: 0.0883763\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0206295233219862, rmse:0.14362981915473938, mae:0.08833886682987213, rse:0.5435844659805298\n",
      "Intermediate time for IT and pred_len 168: 00h:13m:21.76s\n",
      "Intermediate time for IT: 00h:39m:05.36s\n",
      "Total time: 09h:18m:02.20s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.0835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0218  0.1477  0.0918\n",
       "        96        0.0405  0.2013  0.1327\n",
       "        168       0.0437  0.2092  0.1401\n",
       "ES      24        0.0128  0.1130  0.0731\n",
       "        96        0.0249  0.1579  0.1055\n",
       "        168       0.0311  0.1764  0.1167\n",
       "FR      24        0.0107  0.1036  0.0600\n",
       "        96        0.0196  0.1399  0.0823\n",
       "        168       0.0243  0.1558  0.0904\n",
       "GB      24        0.0261  0.1616  0.1044\n",
       "        96        0.0460  0.2144  0.1477\n",
       "        168       0.0494  0.2222  0.1537\n",
       "IT      24        0.0107  0.1035  0.0611\n",
       "        96        0.0187  0.1369  0.0835\n",
       "        168       0.0202  0.1423  0.0877"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)\n",
    "\n",
    "It is a channel mixing model, and therefore it needs more dimension of embeddings to capture complex patterns between features. \n",
    "\n",
    "Therefore, it is not fair to keep same d_model and d_ff as in channel mixing. In this regard, we scale them based on number of input features.\n",
    "\n",
    "In other words, for DE data with 5 columns, d_model = 128 x 5, and d_ff = 256 x 5.\n",
    "\n",
    "For ES: d_model = 128 x 3 and d_ff = 256 x 3, etc. It is adjusted automatically in code.\n",
    "\n",
    "Since it converges fast, we reduced max number of epochs and patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1288347\n",
      "\tspeed: 0.0621s/iter; left time: 271.8497s\n",
      "\titers: 200, epoch: 1 | loss: 0.1153558\n",
      "\tspeed: 0.0434s/iter; left time: 185.6252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 224 | Train Loss: 0.1386400 Vali Loss: 0.1264737 Test Loss: 0.1306201\n",
      "Validation loss decreased (inf --> 0.126474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0790193\n",
      "\tspeed: 0.0814s/iter; left time: 338.4901s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790826\n",
      "\tspeed: 0.0434s/iter; left time: 176.1489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0848311 Vali Loss: 0.0908782 Test Loss: 0.0928910\n",
      "Validation loss decreased (0.126474 --> 0.090878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0733861\n",
      "\tspeed: 0.0806s/iter; left time: 317.1256s\n",
      "\titers: 200, epoch: 3 | loss: 0.0763236\n",
      "\tspeed: 0.0433s/iter; left time: 166.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0745720 Vali Loss: 0.0889853 Test Loss: 0.0914121\n",
      "Validation loss decreased (0.090878 --> 0.088985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0697485\n",
      "\tspeed: 0.0788s/iter; left time: 292.3043s\n",
      "\titers: 200, epoch: 4 | loss: 0.0646489\n",
      "\tspeed: 0.0434s/iter; left time: 156.7062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0712106 Vali Loss: 0.0887275 Test Loss: 0.0919944\n",
      "Validation loss decreased (0.088985 --> 0.088728).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0703026\n",
      "\tspeed: 0.0788s/iter; left time: 274.5695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0676346\n",
      "\tspeed: 0.0435s/iter; left time: 147.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0672696 Vali Loss: 0.0913164 Test Loss: 0.0948952\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0655603\n",
      "\tspeed: 0.0766s/iter; left time: 249.7891s\n",
      "\titers: 200, epoch: 6 | loss: 0.0588298\n",
      "\tspeed: 0.0435s/iter; left time: 137.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0624329 Vali Loss: 0.0931622 Test Loss: 0.0983253\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0566716\n",
      "\tspeed: 0.0771s/iter; left time: 234.2919s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535484\n",
      "\tspeed: 0.0436s/iter; left time: 127.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0572146 Vali Loss: 0.0963221 Test Loss: 0.1005249\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0505644\n",
      "\tspeed: 0.0771s/iter; left time: 216.7448s\n",
      "\titers: 200, epoch: 8 | loss: 0.0515958\n",
      "\tspeed: 0.0436s/iter; left time: 118.1570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0530652 Vali Loss: 0.0984603 Test Loss: 0.1033134\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0509193\n",
      "\tspeed: 0.0771s/iter; left time: 199.6553s\n",
      "\titers: 200, epoch: 9 | loss: 0.0492906\n",
      "\tspeed: 0.0436s/iter; left time: 108.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0496132 Vali Loss: 0.0986490 Test Loss: 0.1038890\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021372228860855103, rmse:0.14619243144989014, mae:0.09199438244104385, rse:0.5159333348274231\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1415286\n",
      "\tspeed: 0.0455s/iter; left time: 199.4477s\n",
      "\titers: 200, epoch: 1 | loss: 0.1177186\n",
      "\tspeed: 0.0435s/iter; left time: 186.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.1398765 Vali Loss: 0.1292176 Test Loss: 0.1340619\n",
      "Validation loss decreased (inf --> 0.129218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0836441\n",
      "\tspeed: 0.0835s/iter; left time: 347.2026s\n",
      "\titers: 200, epoch: 2 | loss: 0.0809262\n",
      "\tspeed: 0.0435s/iter; left time: 176.6243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.46s\n",
      "Steps: 224 | Train Loss: 0.0844209 Vali Loss: 0.0905276 Test Loss: 0.0925714\n",
      "Validation loss decreased (0.129218 --> 0.090528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0768631\n",
      "\tspeed: 0.0790s/iter; left time: 310.6964s\n",
      "\titers: 200, epoch: 3 | loss: 0.0733880\n",
      "\tspeed: 0.0436s/iter; left time: 167.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0744031 Vali Loss: 0.0889989 Test Loss: 0.0919095\n",
      "Validation loss decreased (0.090528 --> 0.088999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0692604\n",
      "\tspeed: 0.0788s/iter; left time: 292.2920s\n",
      "\titers: 200, epoch: 4 | loss: 0.0709451\n",
      "\tspeed: 0.0436s/iter; left time: 157.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0706481 Vali Loss: 0.0892855 Test Loss: 0.0918443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620473\n",
      "\tspeed: 0.0770s/iter; left time: 268.2856s\n",
      "\titers: 200, epoch: 5 | loss: 0.0703997\n",
      "\tspeed: 0.0436s/iter; left time: 147.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0662776 Vali Loss: 0.0921095 Test Loss: 0.0963930\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0618102\n",
      "\tspeed: 0.0768s/iter; left time: 250.5855s\n",
      "\titers: 200, epoch: 6 | loss: 0.0612112\n",
      "\tspeed: 0.0435s/iter; left time: 137.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0609258 Vali Loss: 0.0947462 Test Loss: 0.0991559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0528752\n",
      "\tspeed: 0.0777s/iter; left time: 236.0680s\n",
      "\titers: 200, epoch: 7 | loss: 0.0571331\n",
      "\tspeed: 0.0435s/iter; left time: 127.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0557489 Vali Loss: 0.0972916 Test Loss: 0.1027085\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0492335\n",
      "\tspeed: 0.0782s/iter; left time: 219.8889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0513884\n",
      "\tspeed: 0.0436s/iter; left time: 118.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.0512173 Vali Loss: 0.0977964 Test Loss: 0.1046530\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02161523513495922, rmse:0.14702120423316956, mae:0.0919095128774643, rse:0.5188581943511963\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:37.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1431927\n",
      "\tspeed: 0.0619s/iter; left time: 271.3939s\n",
      "\titers: 200, epoch: 1 | loss: 0.1289140\n",
      "\tspeed: 0.0437s/iter; left time: 186.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 224 | Train Loss: 0.1487396 Vali Loss: 0.1405490 Test Loss: 0.1488965\n",
      "Validation loss decreased (inf --> 0.140549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1077801\n",
      "\tspeed: 0.0797s/iter; left time: 331.2474s\n",
      "\titers: 200, epoch: 2 | loss: 0.0963636\n",
      "\tspeed: 0.0437s/iter; left time: 177.2322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.1068755 Vali Loss: 0.1224208 Test Loss: 0.1325869\n",
      "Validation loss decreased (0.140549 --> 0.122421).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0926780\n",
      "\tspeed: 0.0803s/iter; left time: 315.7715s\n",
      "\titers: 200, epoch: 3 | loss: 0.0843681\n",
      "\tspeed: 0.0437s/iter; left time: 167.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0893946 Vali Loss: 0.1247966 Test Loss: 0.1377297\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0736906\n",
      "\tspeed: 0.0782s/iter; left time: 289.9745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0699906\n",
      "\tspeed: 0.0438s/iter; left time: 157.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0746758 Vali Loss: 0.1276431 Test Loss: 0.1399731\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639692\n",
      "\tspeed: 0.0775s/iter; left time: 270.0486s\n",
      "\titers: 200, epoch: 5 | loss: 0.0590412\n",
      "\tspeed: 0.0438s/iter; left time: 148.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0646408 Vali Loss: 0.1299467 Test Loss: 0.1427322\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569997\n",
      "\tspeed: 0.0782s/iter; left time: 255.0126s\n",
      "\titers: 200, epoch: 6 | loss: 0.0539131\n",
      "\tspeed: 0.0439s/iter; left time: 138.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0580533 Vali Loss: 0.1302402 Test Loss: 0.1435865\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0529144\n",
      "\tspeed: 0.0785s/iter; left time: 238.5008s\n",
      "\titers: 200, epoch: 7 | loss: 0.0503044\n",
      "\tspeed: 0.0440s/iter; left time: 129.0835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0534348 Vali Loss: 0.1301299 Test Loss: 0.1424773\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04040202498435974, rmse:0.2010025531053543, mae:0.13258694112300873, rse:0.7117906808853149\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1446730\n",
      "\tspeed: 0.0495s/iter; left time: 216.8344s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379150\n",
      "\tspeed: 0.0437s/iter; left time: 187.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.41s\n",
      "Steps: 224 | Train Loss: 0.1482707 Vali Loss: 0.1405652 Test Loss: 0.1491016\n",
      "Validation loss decreased (inf --> 0.140565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1060695\n",
      "\tspeed: 0.0804s/iter; left time: 334.4022s\n",
      "\titers: 200, epoch: 2 | loss: 0.0933992\n",
      "\tspeed: 0.0439s/iter; left time: 178.1298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.1067035 Vali Loss: 0.1217589 Test Loss: 0.1363821\n",
      "Validation loss decreased (0.140565 --> 0.121759).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0944410\n",
      "\tspeed: 0.0800s/iter; left time: 314.5728s\n",
      "\titers: 200, epoch: 3 | loss: 0.0786479\n",
      "\tspeed: 0.0437s/iter; left time: 167.6827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.0873720 Vali Loss: 0.1261233 Test Loss: 0.1370733\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0743208\n",
      "\tspeed: 0.0786s/iter; left time: 291.3874s\n",
      "\titers: 200, epoch: 4 | loss: 0.0682476\n",
      "\tspeed: 0.0438s/iter; left time: 157.9232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0722580 Vali Loss: 0.1309307 Test Loss: 0.1429823\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630023\n",
      "\tspeed: 0.0780s/iter; left time: 271.8135s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619667\n",
      "\tspeed: 0.0437s/iter; left time: 147.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0632695 Vali Loss: 0.1294827 Test Loss: 0.1430689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0583094\n",
      "\tspeed: 0.0784s/iter; left time: 255.6968s\n",
      "\titers: 200, epoch: 6 | loss: 0.0569461\n",
      "\tspeed: 0.0437s/iter; left time: 138.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0574156 Vali Loss: 0.1289199 Test Loss: 0.1438109\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0540976\n",
      "\tspeed: 0.0786s/iter; left time: 238.7198s\n",
      "\titers: 200, epoch: 7 | loss: 0.0510037\n",
      "\tspeed: 0.0437s/iter; left time: 128.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0531317 Vali Loss: 0.1288909 Test Loss: 0.1443605\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043257858604192734, rmse:0.20798523724079132, mae:0.1363820880651474, rse:0.7365177869796753\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:02.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1518797\n",
      "\tspeed: 0.0609s/iter; left time: 265.7029s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341218\n",
      "\tspeed: 0.0438s/iter; left time: 186.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1515815 Vali Loss: 0.1431780 Test Loss: 0.1525715\n",
      "Validation loss decreased (inf --> 0.143178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1105171\n",
      "\tspeed: 0.0810s/iter; left time: 335.2319s\n",
      "\titers: 200, epoch: 2 | loss: 0.1020385\n",
      "\tspeed: 0.0439s/iter; left time: 177.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.1109439 Vali Loss: 0.1256638 Test Loss: 0.1443070\n",
      "Validation loss decreased (0.143178 --> 0.125664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0909588\n",
      "\tspeed: 0.0809s/iter; left time: 316.8799s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823636\n",
      "\tspeed: 0.0439s/iter; left time: 167.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.0895617 Vali Loss: 0.1273583 Test Loss: 0.1470855\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744034\n",
      "\tspeed: 0.0785s/iter; left time: 289.7581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0707802\n",
      "\tspeed: 0.0440s/iter; left time: 157.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.0744996 Vali Loss: 0.1302383 Test Loss: 0.1442910\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0646706\n",
      "\tspeed: 0.0779s/iter; left time: 270.2656s\n",
      "\titers: 200, epoch: 5 | loss: 0.0608316\n",
      "\tspeed: 0.0441s/iter; left time: 148.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0651669 Vali Loss: 0.1310407 Test Loss: 0.1438465\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0574107\n",
      "\tspeed: 0.0790s/iter; left time: 256.3127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0584476\n",
      "\tspeed: 0.0440s/iter; left time: 138.2686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.0592617 Vali Loss: 0.1324312 Test Loss: 0.1442218\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0558157\n",
      "\tspeed: 0.0785s/iter; left time: 237.2210s\n",
      "\titers: 200, epoch: 7 | loss: 0.0557166\n",
      "\tspeed: 0.0440s/iter; left time: 128.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 223 | Train Loss: 0.0549841 Vali Loss: 0.1323213 Test Loss: 0.1434522\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04741961508989334, rmse:0.21776045858860016, mae:0.14430703222751617, rse:0.7713250517845154\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1513522\n",
      "\tspeed: 0.0464s/iter; left time: 202.2887s\n",
      "\titers: 200, epoch: 1 | loss: 0.1385211\n",
      "\tspeed: 0.0439s/iter; left time: 187.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 223 | Train Loss: 0.1521855 Vali Loss: 0.1438601 Test Loss: 0.1531233\n",
      "Validation loss decreased (inf --> 0.143860).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1064229\n",
      "\tspeed: 0.0815s/iter; left time: 337.4412s\n",
      "\titers: 200, epoch: 2 | loss: 0.1020931\n",
      "\tspeed: 0.0440s/iter; left time: 177.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.1112131 Vali Loss: 0.1247842 Test Loss: 0.1412956\n",
      "Validation loss decreased (0.143860 --> 0.124784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0937691\n",
      "\tspeed: 0.0820s/iter; left time: 321.1670s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833023\n",
      "\tspeed: 0.0439s/iter; left time: 167.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.0891496 Vali Loss: 0.1302273 Test Loss: 0.1467150\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755298\n",
      "\tspeed: 0.0787s/iter; left time: 290.5388s\n",
      "\titers: 200, epoch: 4 | loss: 0.0678074\n",
      "\tspeed: 0.0440s/iter; left time: 158.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0731834 Vali Loss: 0.1329896 Test Loss: 0.1487310\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0666101\n",
      "\tspeed: 0.0788s/iter; left time: 273.4192s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610430\n",
      "\tspeed: 0.0440s/iter; left time: 148.1712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.0643469 Vali Loss: 0.1333733 Test Loss: 0.1499041\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0585870\n",
      "\tspeed: 0.0789s/iter; left time: 256.0959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0568665\n",
      "\tspeed: 0.0440s/iter; left time: 138.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.0583537 Vali Loss: 0.1314956 Test Loss: 0.1464267\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0525444\n",
      "\tspeed: 0.0790s/iter; left time: 238.9590s\n",
      "\titers: 200, epoch: 7 | loss: 0.0518316\n",
      "\tspeed: 0.0439s/iter; left time: 128.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0540509 Vali Loss: 0.1317015 Test Loss: 0.1481518\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04486357793211937, rmse:0.21181024610996246, mae:0.14129573106765747, rse:0.7502489686012268\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:04.36s\n",
      "Intermediate time for DE: 00h:09m:44.80s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1249031\n",
      "\tspeed: 0.0601s/iter; left time: 263.2734s\n",
      "\titers: 200, epoch: 1 | loss: 0.1127680\n",
      "\tspeed: 0.0432s/iter; left time: 184.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.1274041 Vali Loss: 0.1188559 Test Loss: 0.1365499\n",
      "Validation loss decreased (inf --> 0.118856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0752068\n",
      "\tspeed: 0.0804s/iter; left time: 334.0770s\n",
      "\titers: 200, epoch: 2 | loss: 0.0756959\n",
      "\tspeed: 0.0433s/iter; left time: 175.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0829447 Vali Loss: 0.0909307 Test Loss: 0.1030746\n",
      "Validation loss decreased (0.118856 --> 0.090931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0754961\n",
      "\tspeed: 0.0784s/iter; left time: 308.3153s\n",
      "\titers: 200, epoch: 3 | loss: 0.0801942\n",
      "\tspeed: 0.0433s/iter; left time: 166.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0758008 Vali Loss: 0.0894891 Test Loss: 0.1017765\n",
      "Validation loss decreased (0.090931 --> 0.089489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0749308\n",
      "\tspeed: 0.0787s/iter; left time: 291.7423s\n",
      "\titers: 200, epoch: 4 | loss: 0.0664703\n",
      "\tspeed: 0.0433s/iter; left time: 156.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0732703 Vali Loss: 0.0913262 Test Loss: 0.1023002\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0723235\n",
      "\tspeed: 0.0758s/iter; left time: 264.2858s\n",
      "\titers: 200, epoch: 5 | loss: 0.0701183\n",
      "\tspeed: 0.0433s/iter; left time: 146.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0703901 Vali Loss: 0.0899382 Test Loss: 0.1038470\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0694546\n",
      "\tspeed: 0.0756s/iter; left time: 246.6922s\n",
      "\titers: 200, epoch: 6 | loss: 0.0659585\n",
      "\tspeed: 0.0433s/iter; left time: 136.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0664127 Vali Loss: 0.0935771 Test Loss: 0.1056621\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577669\n",
      "\tspeed: 0.0760s/iter; left time: 230.8019s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580327\n",
      "\tspeed: 0.0434s/iter; left time: 127.3561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0617652 Vali Loss: 0.0964528 Test Loss: 0.1120393\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0580244\n",
      "\tspeed: 0.0781s/iter; left time: 219.7505s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549745\n",
      "\tspeed: 0.0434s/iter; left time: 117.6108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0575566 Vali Loss: 0.0996388 Test Loss: 0.1158492\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025332890450954437, rmse:0.15916308760643005, mae:0.10177655518054962, rse:0.5490675568580627\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1193750\n",
      "\tspeed: 0.0450s/iter; left time: 197.2874s\n",
      "\titers: 200, epoch: 1 | loss: 0.1060155\n",
      "\tspeed: 0.0434s/iter; left time: 185.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.1250374 Vali Loss: 0.1174057 Test Loss: 0.1348697\n",
      "Validation loss decreased (inf --> 0.117406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0799368\n",
      "\tspeed: 0.0782s/iter; left time: 325.0579s\n",
      "\titers: 200, epoch: 2 | loss: 0.0795878\n",
      "\tspeed: 0.0434s/iter; left time: 176.0104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0825805 Vali Loss: 0.0911475 Test Loss: 0.1029994\n",
      "Validation loss decreased (0.117406 --> 0.091147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0756929\n",
      "\tspeed: 0.0784s/iter; left time: 308.3488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774784\n",
      "\tspeed: 0.0434s/iter; left time: 166.2460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0757685 Vali Loss: 0.0891861 Test Loss: 0.1012558\n",
      "Validation loss decreased (0.091147 --> 0.089186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0707852\n",
      "\tspeed: 0.0825s/iter; left time: 306.1245s\n",
      "\titers: 200, epoch: 4 | loss: 0.0715328\n",
      "\tspeed: 0.0434s/iter; left time: 156.7667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0732520 Vali Loss: 0.0898914 Test Loss: 0.1021442\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689220\n",
      "\tspeed: 0.0771s/iter; left time: 268.8159s\n",
      "\titers: 200, epoch: 5 | loss: 0.0702394\n",
      "\tspeed: 0.0435s/iter; left time: 147.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0703283 Vali Loss: 0.0914296 Test Loss: 0.1033106\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0662516\n",
      "\tspeed: 0.0764s/iter; left time: 249.0542s\n",
      "\titers: 200, epoch: 6 | loss: 0.0679668\n",
      "\tspeed: 0.0434s/iter; left time: 137.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0663290 Vali Loss: 0.0943815 Test Loss: 0.1062462\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0596283\n",
      "\tspeed: 0.0761s/iter; left time: 231.1431s\n",
      "\titers: 200, epoch: 7 | loss: 0.0606526\n",
      "\tspeed: 0.0434s/iter; left time: 127.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0616254 Vali Loss: 0.0968927 Test Loss: 0.1100579\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0565274\n",
      "\tspeed: 0.0763s/iter; left time: 214.5441s\n",
      "\titers: 200, epoch: 8 | loss: 0.0578602\n",
      "\tspeed: 0.0434s/iter; left time: 117.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0571208 Vali Loss: 0.1001299 Test Loss: 0.1126765\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02496434934437275, rmse:0.158001109957695, mae:0.10125575959682465, rse:0.5450590252876282\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:23.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1300309\n",
      "\tspeed: 0.0619s/iter; left time: 271.1114s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175259\n",
      "\tspeed: 0.0437s/iter; left time: 187.1140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 224 | Train Loss: 0.1356121 Vali Loss: 0.1320696 Test Loss: 0.1547136\n",
      "Validation loss decreased (inf --> 0.132070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1107192\n",
      "\tspeed: 0.0793s/iter; left time: 329.5753s\n",
      "\titers: 200, epoch: 2 | loss: 0.0974107\n",
      "\tspeed: 0.0437s/iter; left time: 177.3589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.1059472 Vali Loss: 0.1207289 Test Loss: 0.1423227\n",
      "Validation loss decreased (0.132070 --> 0.120729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921785\n",
      "\tspeed: 0.0789s/iter; left time: 310.4888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906572\n",
      "\tspeed: 0.0436s/iter; left time: 167.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0932772 Vali Loss: 0.1250454 Test Loss: 0.1396944\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0780643\n",
      "\tspeed: 0.0772s/iter; left time: 286.1969s\n",
      "\titers: 200, epoch: 4 | loss: 0.0736055\n",
      "\tspeed: 0.0436s/iter; left time: 157.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0790285 Vali Loss: 0.1302246 Test Loss: 0.1424275\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0678155\n",
      "\tspeed: 0.0771s/iter; left time: 268.8162s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652552\n",
      "\tspeed: 0.0435s/iter; left time: 147.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0684898 Vali Loss: 0.1330113 Test Loss: 0.1475625\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0595127\n",
      "\tspeed: 0.0765s/iter; left time: 249.4589s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599183\n",
      "\tspeed: 0.0436s/iter; left time: 137.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0620094 Vali Loss: 0.1328093 Test Loss: 0.1456130\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590672\n",
      "\tspeed: 0.0760s/iter; left time: 230.7722s\n",
      "\titers: 200, epoch: 7 | loss: 0.0578840\n",
      "\tspeed: 0.0436s/iter; left time: 128.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0574334 Vali Loss: 0.1333681 Test Loss: 0.1477004\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04291878640651703, rmse:0.20716850459575653, mae:0.14232265949249268, rse:0.7164175510406494\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1369909\n",
      "\tspeed: 0.0452s/iter; left time: 198.1251s\n",
      "\titers: 200, epoch: 1 | loss: 0.1235660\n",
      "\tspeed: 0.0436s/iter; left time: 186.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.1355126 Vali Loss: 0.1321635 Test Loss: 0.1548172\n",
      "Validation loss decreased (inf --> 0.132164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1024315\n",
      "\tspeed: 0.0822s/iter; left time: 341.8837s\n",
      "\titers: 200, epoch: 2 | loss: 0.0971463\n",
      "\tspeed: 0.0436s/iter; left time: 176.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.1058134 Vali Loss: 0.1206499 Test Loss: 0.1399352\n",
      "Validation loss decreased (0.132164 --> 0.120650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0939326\n",
      "\tspeed: 0.0953s/iter; left time: 374.8068s\n",
      "\titers: 200, epoch: 3 | loss: 0.0851375\n",
      "\tspeed: 0.0436s/iter; left time: 166.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0934879 Vali Loss: 0.1276292 Test Loss: 0.1426655\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788433\n",
      "\tspeed: 0.0770s/iter; left time: 285.4099s\n",
      "\titers: 200, epoch: 4 | loss: 0.0714974\n",
      "\tspeed: 0.0435s/iter; left time: 157.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0783464 Vali Loss: 0.1301064 Test Loss: 0.1484889\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0670597\n",
      "\tspeed: 0.0768s/iter; left time: 267.4897s\n",
      "\titers: 200, epoch: 5 | loss: 0.0632937\n",
      "\tspeed: 0.1556s/iter; left time: 526.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.12s\n",
      "Steps: 224 | Train Loss: 0.0674435 Vali Loss: 0.1301742 Test Loss: 0.1560793\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0597854\n",
      "\tspeed: 0.0763s/iter; left time: 248.9769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592995\n",
      "\tspeed: 0.0435s/iter; left time: 137.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0609915 Vali Loss: 0.1312574 Test Loss: 0.1548149\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571895\n",
      "\tspeed: 0.0767s/iter; left time: 233.0420s\n",
      "\titers: 200, epoch: 7 | loss: 0.0534755\n",
      "\tspeed: 0.0437s/iter; left time: 128.4914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0563500 Vali Loss: 0.1323618 Test Loss: 0.1562927\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042682863771915436, rmse:0.20659831166267395, mae:0.1399351954460144, rse:0.7144457697868347\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:13.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1341277\n",
      "\tspeed: 0.0614s/iter; left time: 267.8026s\n",
      "\titers: 200, epoch: 1 | loss: 0.1240424\n",
      "\tspeed: 0.0436s/iter; left time: 185.8316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 223 | Train Loss: 0.1377349 Vali Loss: 0.1347460 Test Loss: 0.1585737\n",
      "Validation loss decreased (inf --> 0.134746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1115550\n",
      "\tspeed: 0.0794s/iter; left time: 328.6687s\n",
      "\titers: 200, epoch: 2 | loss: 0.1019396\n",
      "\tspeed: 0.0439s/iter; left time: 177.0813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.1095999 Vali Loss: 0.1251576 Test Loss: 0.1528900\n",
      "Validation loss decreased (0.134746 --> 0.125158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0949040\n",
      "\tspeed: 0.0798s/iter; left time: 312.4155s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896047\n",
      "\tspeed: 0.0439s/iter; left time: 167.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0943391 Vali Loss: 0.1325155 Test Loss: 0.1532334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0794888\n",
      "\tspeed: 0.0785s/iter; left time: 289.9586s\n",
      "\titers: 200, epoch: 4 | loss: 0.0751732\n",
      "\tspeed: 0.0439s/iter; left time: 157.7071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 223 | Train Loss: 0.0793516 Vali Loss: 0.1352002 Test Loss: 0.1513123\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0718923\n",
      "\tspeed: 0.0780s/iter; left time: 270.5778s\n",
      "\titers: 200, epoch: 5 | loss: 0.0654820\n",
      "\tspeed: 0.0440s/iter; left time: 148.1064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 223 | Train Loss: 0.0696418 Vali Loss: 0.1345929 Test Loss: 0.1558284\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637268\n",
      "\tspeed: 0.0777s/iter; left time: 252.2374s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619536\n",
      "\tspeed: 0.0440s/iter; left time: 138.4949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0636521 Vali Loss: 0.1361301 Test Loss: 0.1573202\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0584776\n",
      "\tspeed: 0.0777s/iter; left time: 234.7740s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590519\n",
      "\tspeed: 0.0440s/iter; left time: 128.6523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0592529 Vali Loss: 0.1356159 Test Loss: 0.1559382\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.052469152957201004, rmse:0.22906145453453064, mae:0.15288984775543213, rse:0.7941889762878418\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1340767\n",
      "\tspeed: 0.0507s/iter; left time: 221.1755s\n",
      "\titers: 200, epoch: 1 | loss: 0.1268893\n",
      "\tspeed: 0.0439s/iter; left time: 187.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 223 | Train Loss: 0.1382299 Vali Loss: 0.1351098 Test Loss: 0.1589990\n",
      "Validation loss decreased (inf --> 0.135110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1089100\n",
      "\tspeed: 0.0820s/iter; left time: 339.4382s\n",
      "\titers: 200, epoch: 2 | loss: 0.1047608\n",
      "\tspeed: 0.0439s/iter; left time: 177.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.1098012 Vali Loss: 0.1272498 Test Loss: 0.1492751\n",
      "Validation loss decreased (0.135110 --> 0.127250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0957372\n",
      "\tspeed: 0.0820s/iter; left time: 321.1154s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877633\n",
      "\tspeed: 0.0440s/iter; left time: 167.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.0951678 Vali Loss: 0.1317861 Test Loss: 0.1500311\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0815844\n",
      "\tspeed: 0.0793s/iter; left time: 292.7075s\n",
      "\titers: 200, epoch: 4 | loss: 0.0720776\n",
      "\tspeed: 0.0440s/iter; left time: 157.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.0793402 Vali Loss: 0.1376163 Test Loss: 0.1564661\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0674153\n",
      "\tspeed: 0.0795s/iter; left time: 275.6132s\n",
      "\titers: 200, epoch: 5 | loss: 0.0677345\n",
      "\tspeed: 0.0440s/iter; left time: 148.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 223 | Train Loss: 0.0688048 Vali Loss: 0.1402889 Test Loss: 0.1571947\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0602527\n",
      "\tspeed: 0.0797s/iter; left time: 258.7197s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598245\n",
      "\tspeed: 0.0441s/iter; left time: 138.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.0624292 Vali Loss: 0.1399303 Test Loss: 0.1577230\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0568240\n",
      "\tspeed: 0.0793s/iter; left time: 239.7509s\n",
      "\titers: 200, epoch: 7 | loss: 0.0553108\n",
      "\tspeed: 0.0441s/iter; left time: 128.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 223 | Train Loss: 0.0579504 Vali Loss: 0.1376240 Test Loss: 0.1562205\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.047632455825805664, rmse:0.21824860572814941, mae:0.1492750644683838, rse:0.75669926404953\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:05.15s\n",
      "Intermediate time for GB: 00h:09m:41.67s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1197053\n",
      "\tspeed: 0.0389s/iter; left time: 170.4659s\n",
      "\titers: 200, epoch: 1 | loss: 0.1074361\n",
      "\tspeed: 0.0220s/iter; left time: 94.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.1288011 Vali Loss: 0.0958644 Test Loss: 0.1084929\n",
      "Validation loss decreased (inf --> 0.095864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0743673\n",
      "\tspeed: 0.0438s/iter; left time: 181.9416s\n",
      "\titers: 200, epoch: 2 | loss: 0.0671951\n",
      "\tspeed: 0.0220s/iter; left time: 89.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0732195 Vali Loss: 0.0619111 Test Loss: 0.0689737\n",
      "Validation loss decreased (0.095864 --> 0.061911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636132\n",
      "\tspeed: 0.0443s/iter; left time: 174.4196s\n",
      "\titers: 200, epoch: 3 | loss: 0.0605463\n",
      "\tspeed: 0.0220s/iter; left time: 84.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0620891 Vali Loss: 0.0585566 Test Loss: 0.0651297\n",
      "Validation loss decreased (0.061911 --> 0.058557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0559345\n",
      "\tspeed: 0.0444s/iter; left time: 164.5139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0574044\n",
      "\tspeed: 0.0220s/iter; left time: 79.4318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0591701 Vali Loss: 0.0568301 Test Loss: 0.0641761\n",
      "Validation loss decreased (0.058557 --> 0.056830).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0585900\n",
      "\tspeed: 0.0441s/iter; left time: 153.7485s\n",
      "\titers: 200, epoch: 5 | loss: 0.0586798\n",
      "\tspeed: 0.0220s/iter; left time: 74.5159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0574670 Vali Loss: 0.0560226 Test Loss: 0.0631666\n",
      "Validation loss decreased (0.056830 --> 0.056023).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0571813\n",
      "\tspeed: 0.0442s/iter; left time: 143.9950s\n",
      "\titers: 200, epoch: 6 | loss: 0.0582810\n",
      "\tspeed: 0.0220s/iter; left time: 69.6702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0561205 Vali Loss: 0.0555882 Test Loss: 0.0626708\n",
      "Validation loss decreased (0.056023 --> 0.055588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0552973\n",
      "\tspeed: 0.0447s/iter; left time: 135.8377s\n",
      "\titers: 200, epoch: 7 | loss: 0.0541853\n",
      "\tspeed: 0.0221s/iter; left time: 64.7821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0551273 Vali Loss: 0.0547986 Test Loss: 0.0620969\n",
      "Validation loss decreased (0.055588 --> 0.054799).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0540874\n",
      "\tspeed: 0.0443s/iter; left time: 124.6580s\n",
      "\titers: 200, epoch: 8 | loss: 0.0545249\n",
      "\tspeed: 0.0221s/iter; left time: 59.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0540969 Vali Loss: 0.0546852 Test Loss: 0.0622704\n",
      "Validation loss decreased (0.054799 --> 0.054685).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0535808\n",
      "\tspeed: 0.0438s/iter; left time: 113.4066s\n",
      "\titers: 200, epoch: 9 | loss: 0.0510668\n",
      "\tspeed: 0.0220s/iter; left time: 54.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0533764 Vali Loss: 0.0539643 Test Loss: 0.0610771\n",
      "Validation loss decreased (0.054685 --> 0.053964).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0544953\n",
      "\tspeed: 0.0444s/iter; left time: 105.0310s\n",
      "\titers: 200, epoch: 10 | loss: 0.0548255\n",
      "\tspeed: 0.0220s/iter; left time: 49.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0525270 Vali Loss: 0.0542821 Test Loss: 0.0614841\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0498544\n",
      "\tspeed: 0.0431s/iter; left time: 92.3523s\n",
      "\titers: 200, epoch: 11 | loss: 0.0507155\n",
      "\tspeed: 0.0220s/iter; left time: 44.9447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0518580 Vali Loss: 0.0541489 Test Loss: 0.0618145\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0490863\n",
      "\tspeed: 0.0439s/iter; left time: 84.2093s\n",
      "\titers: 200, epoch: 12 | loss: 0.0500919\n",
      "\tspeed: 0.0221s/iter; left time: 40.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0512090 Vali Loss: 0.0545745 Test Loss: 0.0619080\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0565618\n",
      "\tspeed: 0.0441s/iter; left time: 74.6360s\n",
      "\titers: 200, epoch: 13 | loss: 0.0477618\n",
      "\tspeed: 0.0221s/iter; left time: 35.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0505550 Vali Loss: 0.0545160 Test Loss: 0.0619966\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0485411\n",
      "\tspeed: 0.0446s/iter; left time: 65.5215s\n",
      "\titers: 200, epoch: 14 | loss: 0.0494428\n",
      "\tspeed: 0.0221s/iter; left time: 30.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0499811 Vali Loss: 0.0538818 Test Loss: 0.0613545\n",
      "Validation loss decreased (0.053964 --> 0.053882).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0486182\n",
      "\tspeed: 0.0441s/iter; left time: 54.9210s\n",
      "\titers: 200, epoch: 15 | loss: 0.0522056\n",
      "\tspeed: 0.0220s/iter; left time: 25.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0493475 Vali Loss: 0.0540712 Test Loss: 0.0617006\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0517759\n",
      "\tspeed: 0.0428s/iter; left time: 43.6968s\n",
      "\titers: 200, epoch: 16 | loss: 0.0503656\n",
      "\tspeed: 0.0220s/iter; left time: 20.2887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0488575 Vali Loss: 0.0544644 Test Loss: 0.0622188\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0497399\n",
      "\tspeed: 0.0442s/iter; left time: 35.2565s\n",
      "\titers: 200, epoch: 17 | loss: 0.0500861\n",
      "\tspeed: 0.0221s/iter; left time: 15.3767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0484129 Vali Loss: 0.0545549 Test Loss: 0.0625807\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0462332\n",
      "\tspeed: 0.0443s/iter; left time: 25.4011s\n",
      "\titers: 200, epoch: 18 | loss: 0.0489886\n",
      "\tspeed: 0.0221s/iter; left time: 10.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0480003 Vali Loss: 0.0545118 Test Loss: 0.0624015\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0488784\n",
      "\tspeed: 0.0429s/iter; left time: 14.9608s\n",
      "\titers: 200, epoch: 19 | loss: 0.0505258\n",
      "\tspeed: 0.0220s/iter; left time: 5.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0475646 Vali Loss: 0.0548550 Test Loss: 0.0625891\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00992313027381897, rmse:0.09961491078138351, mae:0.06135452166199684, rse:0.29315462708473206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1214782\n",
      "\tspeed: 0.0264s/iter; left time: 115.7879s\n",
      "\titers: 200, epoch: 1 | loss: 0.1079467\n",
      "\tspeed: 0.0220s/iter; left time: 94.2519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.1318527 Vali Loss: 0.0977142 Test Loss: 0.1096083\n",
      "Validation loss decreased (inf --> 0.097714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0695145\n",
      "\tspeed: 0.0431s/iter; left time: 179.1939s\n",
      "\titers: 200, epoch: 2 | loss: 0.0641104\n",
      "\tspeed: 0.0221s/iter; left time: 89.4813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0732974 Vali Loss: 0.0619658 Test Loss: 0.0686749\n",
      "Validation loss decreased (0.097714 --> 0.061966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0587519\n",
      "\tspeed: 0.0433s/iter; left time: 170.3049s\n",
      "\titers: 200, epoch: 3 | loss: 0.0618919\n",
      "\tspeed: 0.0220s/iter; left time: 84.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0621301 Vali Loss: 0.0587658 Test Loss: 0.0654708\n",
      "Validation loss decreased (0.061966 --> 0.058766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0594057\n",
      "\tspeed: 0.0432s/iter; left time: 160.3581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0569952\n",
      "\tspeed: 0.0220s/iter; left time: 79.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0592448 Vali Loss: 0.0570653 Test Loss: 0.0638682\n",
      "Validation loss decreased (0.058766 --> 0.057065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0583459\n",
      "\tspeed: 0.0432s/iter; left time: 150.4146s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606583\n",
      "\tspeed: 0.0220s/iter; left time: 74.4017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0573962 Vali Loss: 0.0562197 Test Loss: 0.0633890\n",
      "Validation loss decreased (0.057065 --> 0.056220).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0551197\n",
      "\tspeed: 0.0432s/iter; left time: 140.8077s\n",
      "\titers: 200, epoch: 6 | loss: 0.0542481\n",
      "\tspeed: 0.0221s/iter; left time: 69.7244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0560827 Vali Loss: 0.0551677 Test Loss: 0.0620240\n",
      "Validation loss decreased (0.056220 --> 0.055168).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0546338\n",
      "\tspeed: 0.0433s/iter; left time: 131.3840s\n",
      "\titers: 200, epoch: 7 | loss: 0.0557244\n",
      "\tspeed: 0.0220s/iter; left time: 64.6994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0550370 Vali Loss: 0.0549158 Test Loss: 0.0618460\n",
      "Validation loss decreased (0.055168 --> 0.054916).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0533591\n",
      "\tspeed: 0.0432s/iter; left time: 121.5712s\n",
      "\titers: 200, epoch: 8 | loss: 0.0514893\n",
      "\tspeed: 0.0221s/iter; left time: 59.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0541582 Vali Loss: 0.0542985 Test Loss: 0.0613999\n",
      "Validation loss decreased (0.054916 --> 0.054299).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0519505\n",
      "\tspeed: 0.0448s/iter; left time: 116.0249s\n",
      "\titers: 200, epoch: 9 | loss: 0.0505060\n",
      "\tspeed: 0.0221s/iter; left time: 54.9988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0532708 Vali Loss: 0.0543194 Test Loss: 0.0613890\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0501624\n",
      "\tspeed: 0.0442s/iter; left time: 104.6277s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489627\n",
      "\tspeed: 0.0220s/iter; left time: 49.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0524889 Vali Loss: 0.0542982 Test Loss: 0.0611642\n",
      "Validation loss decreased (0.054299 --> 0.054298).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0491599\n",
      "\tspeed: 0.0436s/iter; left time: 93.2524s\n",
      "\titers: 200, epoch: 11 | loss: 0.0504890\n",
      "\tspeed: 0.0220s/iter; left time: 44.9858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0518310 Vali Loss: 0.0544719 Test Loss: 0.0615248\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0504733\n",
      "\tspeed: 0.0420s/iter; left time: 80.4454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0517810\n",
      "\tspeed: 0.0220s/iter; left time: 39.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0511032 Vali Loss: 0.0544304 Test Loss: 0.0618145\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0491990\n",
      "\tspeed: 0.0424s/iter; left time: 71.7644s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494348\n",
      "\tspeed: 0.0221s/iter; left time: 35.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0505439 Vali Loss: 0.0546408 Test Loss: 0.0613864\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0487825\n",
      "\tspeed: 0.0423s/iter; left time: 62.0977s\n",
      "\titers: 200, epoch: 14 | loss: 0.0486977\n",
      "\tspeed: 0.0220s/iter; left time: 30.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0499626 Vali Loss: 0.0548986 Test Loss: 0.0617785\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0492183\n",
      "\tspeed: 0.0421s/iter; left time: 52.4408s\n",
      "\titers: 200, epoch: 15 | loss: 0.0466172\n",
      "\tspeed: 0.0221s/iter; left time: 25.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0494497 Vali Loss: 0.0548974 Test Loss: 0.0618186\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009944847784936428, rmse:0.09972386062145233, mae:0.061164192855358124, rse:0.29347527027130127\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:51.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1327750\n",
      "\tspeed: 0.0392s/iter; left time: 171.5321s\n",
      "\titers: 200, epoch: 1 | loss: 0.1151738\n",
      "\tspeed: 0.0222s/iter; left time: 94.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.1380184 Vali Loss: 0.1075002 Test Loss: 0.1211424\n",
      "Validation loss decreased (inf --> 0.107500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0898748\n",
      "\tspeed: 0.0455s/iter; left time: 189.0479s\n",
      "\titers: 200, epoch: 2 | loss: 0.0794849\n",
      "\tspeed: 0.0221s/iter; left time: 89.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0905244 Vali Loss: 0.0823172 Test Loss: 0.0928391\n",
      "Validation loss decreased (0.107500 --> 0.082317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804560\n",
      "\tspeed: 0.0464s/iter; left time: 182.6691s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776050\n",
      "\tspeed: 0.0222s/iter; left time: 85.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0808929 Vali Loss: 0.0794616 Test Loss: 0.0906161\n",
      "Validation loss decreased (0.082317 --> 0.079462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755306\n",
      "\tspeed: 0.0460s/iter; left time: 170.4463s\n",
      "\titers: 200, epoch: 4 | loss: 0.0755394\n",
      "\tspeed: 0.0222s/iter; left time: 80.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0769380 Vali Loss: 0.0798931 Test Loss: 0.0919429\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0722298\n",
      "\tspeed: 0.0439s/iter; left time: 153.0381s\n",
      "\titers: 200, epoch: 5 | loss: 0.0743159\n",
      "\tspeed: 0.0222s/iter; left time: 75.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0732500 Vali Loss: 0.0803050 Test Loss: 0.0922237\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0681314\n",
      "\tspeed: 0.0445s/iter; left time: 145.0482s\n",
      "\titers: 200, epoch: 6 | loss: 0.0714724\n",
      "\tspeed: 0.0222s/iter; left time: 70.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0696609 Vali Loss: 0.0804545 Test Loss: 0.0929369\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0662445\n",
      "\tspeed: 0.0446s/iter; left time: 135.3941s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645176\n",
      "\tspeed: 0.0222s/iter; left time: 65.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0663182 Vali Loss: 0.0819036 Test Loss: 0.0936721\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0646453\n",
      "\tspeed: 0.0446s/iter; left time: 125.4376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0620963\n",
      "\tspeed: 0.0222s/iter; left time: 60.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0630618 Vali Loss: 0.0830514 Test Loss: 0.0945923\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019271597266197205, rmse:0.13882218301296234, mae:0.09061609208583832, rse:0.4078177809715271\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1359011\n",
      "\tspeed: 0.0239s/iter; left time: 104.8345s\n",
      "\titers: 200, epoch: 1 | loss: 0.1179544\n",
      "\tspeed: 0.0222s/iter; left time: 95.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.1384543 Vali Loss: 0.1076759 Test Loss: 0.1211382\n",
      "Validation loss decreased (inf --> 0.107676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0889097\n",
      "\tspeed: 0.0449s/iter; left time: 186.7324s\n",
      "\titers: 200, epoch: 2 | loss: 0.0868934\n",
      "\tspeed: 0.0222s/iter; left time: 90.2563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0903999 Vali Loss: 0.0819206 Test Loss: 0.0922778\n",
      "Validation loss decreased (0.107676 --> 0.081921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819837\n",
      "\tspeed: 0.0461s/iter; left time: 181.4797s\n",
      "\titers: 200, epoch: 3 | loss: 0.0790465\n",
      "\tspeed: 0.0222s/iter; left time: 85.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0806006 Vali Loss: 0.0789759 Test Loss: 0.0910454\n",
      "Validation loss decreased (0.081921 --> 0.078976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0802818\n",
      "\tspeed: 0.0450s/iter; left time: 167.0762s\n",
      "\titers: 200, epoch: 4 | loss: 0.0744955\n",
      "\tspeed: 0.0223s/iter; left time: 80.4399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0764292 Vali Loss: 0.0790067 Test Loss: 0.0904807\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0730120\n",
      "\tspeed: 0.0473s/iter; left time: 164.8390s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737626\n",
      "\tspeed: 0.0223s/iter; left time: 75.4142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0720678 Vali Loss: 0.0799713 Test Loss: 0.0924472\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0680700\n",
      "\tspeed: 0.0442s/iter; left time: 144.1804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0682947\n",
      "\tspeed: 0.0223s/iter; left time: 70.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0677571 Vali Loss: 0.0811187 Test Loss: 0.0937446\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0656267\n",
      "\tspeed: 0.0441s/iter; left time: 134.0765s\n",
      "\titers: 200, epoch: 7 | loss: 0.0630400\n",
      "\tspeed: 0.0223s/iter; left time: 65.5494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0640458 Vali Loss: 0.0827304 Test Loss: 0.0952476\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0612878\n",
      "\tspeed: 0.0439s/iter; left time: 123.4383s\n",
      "\titers: 200, epoch: 8 | loss: 0.0583994\n",
      "\tspeed: 0.0223s/iter; left time: 60.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0610601 Vali Loss: 0.0839228 Test Loss: 0.0960289\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019083218649029732, rmse:0.13814201951026917, mae:0.09104538708925247, rse:0.40581971406936646\n",
      "Intermediate time for ES and pred_len 96: 00h:01m:56.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1385189\n",
      "\tspeed: 0.0407s/iter; left time: 177.6641s\n",
      "\titers: 200, epoch: 1 | loss: 0.1222085\n",
      "\tspeed: 0.0226s/iter; left time: 96.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.1415203 Vali Loss: 0.1107488 Test Loss: 0.1235423\n",
      "Validation loss decreased (inf --> 0.110749).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0943981\n",
      "\tspeed: 0.0462s/iter; left time: 191.3232s\n",
      "\titers: 200, epoch: 2 | loss: 0.0923413\n",
      "\tspeed: 0.0226s/iter; left time: 91.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0948072 Vali Loss: 0.0882457 Test Loss: 0.0986240\n",
      "Validation loss decreased (0.110749 --> 0.088246).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0849652\n",
      "\tspeed: 0.0468s/iter; left time: 183.2532s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840910\n",
      "\tspeed: 0.0226s/iter; left time: 86.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0844714 Vali Loss: 0.0858070 Test Loss: 0.0971049\n",
      "Validation loss decreased (0.088246 --> 0.085807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0787158\n",
      "\tspeed: 0.0466s/iter; left time: 171.8860s\n",
      "\titers: 200, epoch: 4 | loss: 0.0773474\n",
      "\tspeed: 0.0226s/iter; left time: 81.0493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0792804 Vali Loss: 0.0866306 Test Loss: 0.0979837\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0746874\n",
      "\tspeed: 0.0449s/iter; left time: 155.7042s\n",
      "\titers: 200, epoch: 5 | loss: 0.0745576\n",
      "\tspeed: 0.0224s/iter; left time: 75.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0749708 Vali Loss: 0.0876147 Test Loss: 0.0982907\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734099\n",
      "\tspeed: 0.0442s/iter; left time: 143.3839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0726197\n",
      "\tspeed: 0.0224s/iter; left time: 70.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0713834 Vali Loss: 0.0886993 Test Loss: 0.0983842\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0680743\n",
      "\tspeed: 0.0443s/iter; left time: 133.8580s\n",
      "\titers: 200, epoch: 7 | loss: 0.0658535\n",
      "\tspeed: 0.0223s/iter; left time: 65.2824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0679162 Vali Loss: 0.0891556 Test Loss: 0.0995721\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0637082\n",
      "\tspeed: 0.0452s/iter; left time: 126.6094s\n",
      "\titers: 200, epoch: 8 | loss: 0.0638428\n",
      "\tspeed: 0.0223s/iter; left time: 60.1778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0645114 Vali Loss: 0.0891259 Test Loss: 0.1003027\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02172878384590149, rmse:0.14740686118602753, mae:0.09710493683815002, rse:0.4330681264400482\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1338054\n",
      "\tspeed: 0.0246s/iter; left time: 107.0937s\n",
      "\titers: 200, epoch: 1 | loss: 0.1172974\n",
      "\tspeed: 0.0226s/iter; left time: 96.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.1397129 Vali Loss: 0.1100905 Test Loss: 0.1230639\n",
      "Validation loss decreased (inf --> 0.110091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0909255\n",
      "\tspeed: 0.0458s/iter; left time: 189.6162s\n",
      "\titers: 200, epoch: 2 | loss: 0.0843903\n",
      "\tspeed: 0.0224s/iter; left time: 90.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0946380 Vali Loss: 0.0877320 Test Loss: 0.0977113\n",
      "Validation loss decreased (0.110091 --> 0.087732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0839579\n",
      "\tspeed: 0.0458s/iter; left time: 179.1708s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794685\n",
      "\tspeed: 0.0223s/iter; left time: 85.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0840396 Vali Loss: 0.0863901 Test Loss: 0.0984656\n",
      "Validation loss decreased (0.087732 --> 0.086390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788893\n",
      "\tspeed: 0.0458s/iter; left time: 169.1486s\n",
      "\titers: 200, epoch: 4 | loss: 0.0761613\n",
      "\tspeed: 0.0224s/iter; left time: 80.5832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0789190 Vali Loss: 0.0869178 Test Loss: 0.0986370\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0742886\n",
      "\tspeed: 0.0478s/iter; left time: 165.6836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0743236\n",
      "\tspeed: 0.0223s/iter; left time: 75.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0746482 Vali Loss: 0.0868706 Test Loss: 0.0991525\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0722558\n",
      "\tspeed: 0.0442s/iter; left time: 143.5750s\n",
      "\titers: 200, epoch: 6 | loss: 0.0707610\n",
      "\tspeed: 0.0223s/iter; left time: 70.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0706094 Vali Loss: 0.0871155 Test Loss: 0.1002640\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0670408\n",
      "\tspeed: 0.0439s/iter; left time: 132.6848s\n",
      "\titers: 200, epoch: 7 | loss: 0.0647997\n",
      "\tspeed: 0.0224s/iter; left time: 65.4284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0668925 Vali Loss: 0.0879370 Test Loss: 0.1000142\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0650123\n",
      "\tspeed: 0.0447s/iter; left time: 125.0898s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613846\n",
      "\tspeed: 0.0224s/iter; left time: 60.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0635497 Vali Loss: 0.0889210 Test Loss: 0.1020326\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021894296631217003, rmse:0.14796721935272217, mae:0.09846556931734085, rse:0.43471434712409973\n",
      "Intermediate time for ES and pred_len 168: 00h:01m:58.41s\n",
      "Intermediate time for ES: 00h:07m:47.25s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0911608\n",
      "\tspeed: 0.0395s/iter; left time: 173.2211s\n",
      "\titers: 200, epoch: 1 | loss: 0.0807561\n",
      "\tspeed: 0.0220s/iter; left time: 93.9694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0953799 Vali Loss: 0.0820948 Test Loss: 0.0894879\n",
      "Validation loss decreased (inf --> 0.082095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0561930\n",
      "\tspeed: 0.0444s/iter; left time: 184.7348s\n",
      "\titers: 200, epoch: 2 | loss: 0.0492035\n",
      "\tspeed: 0.0220s/iter; left time: 89.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0542452 Vali Loss: 0.0557568 Test Loss: 0.0594116\n",
      "Validation loss decreased (0.082095 --> 0.055757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0486324\n",
      "\tspeed: 0.0473s/iter; left time: 185.8351s\n",
      "\titers: 200, epoch: 3 | loss: 0.0475799\n",
      "\tspeed: 0.0220s/iter; left time: 84.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0461456 Vali Loss: 0.0538717 Test Loss: 0.0575684\n",
      "Validation loss decreased (0.055757 --> 0.053872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0437132\n",
      "\tspeed: 0.0439s/iter; left time: 162.6741s\n",
      "\titers: 200, epoch: 4 | loss: 0.0451161\n",
      "\tspeed: 0.0220s/iter; left time: 79.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0440538 Vali Loss: 0.0533928 Test Loss: 0.0573033\n",
      "Validation loss decreased (0.053872 --> 0.053393).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0390914\n",
      "\tspeed: 0.0439s/iter; left time: 152.9549s\n",
      "\titers: 200, epoch: 5 | loss: 0.0422770\n",
      "\tspeed: 0.0220s/iter; left time: 74.5831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0426606 Vali Loss: 0.0522712 Test Loss: 0.0566506\n",
      "Validation loss decreased (0.053393 --> 0.052271).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0419594\n",
      "\tspeed: 0.0464s/iter; left time: 151.1885s\n",
      "\titers: 200, epoch: 6 | loss: 0.0421335\n",
      "\tspeed: 0.0220s/iter; left time: 69.6026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0415427 Vali Loss: 0.0521313 Test Loss: 0.0565895\n",
      "Validation loss decreased (0.052271 --> 0.052131).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0394318\n",
      "\tspeed: 0.0437s/iter; left time: 132.7002s\n",
      "\titers: 200, epoch: 7 | loss: 0.0366648\n",
      "\tspeed: 0.0220s/iter; left time: 64.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0405039 Vali Loss: 0.0522789 Test Loss: 0.0569994\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0414733\n",
      "\tspeed: 0.0435s/iter; left time: 122.3514s\n",
      "\titers: 200, epoch: 8 | loss: 0.0397425\n",
      "\tspeed: 0.0220s/iter; left time: 59.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0396449 Vali Loss: 0.0521628 Test Loss: 0.0571179\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0387222\n",
      "\tspeed: 0.0429s/iter; left time: 111.0310s\n",
      "\titers: 200, epoch: 9 | loss: 0.0377659\n",
      "\tspeed: 0.0220s/iter; left time: 54.7764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0387779 Vali Loss: 0.0524518 Test Loss: 0.0580054\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0399559\n",
      "\tspeed: 0.0440s/iter; left time: 103.9845s\n",
      "\titers: 200, epoch: 10 | loss: 0.0383337\n",
      "\tspeed: 0.0221s/iter; left time: 50.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0379001 Vali Loss: 0.0528825 Test Loss: 0.0582209\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0369181\n",
      "\tspeed: 0.0455s/iter; left time: 97.4036s\n",
      "\titers: 200, epoch: 11 | loss: 0.0370933\n",
      "\tspeed: 0.0222s/iter; left time: 45.3939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0371930 Vali Loss: 0.0523042 Test Loss: 0.0584522\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01019241288304329, rmse:0.1009574830532074, mae:0.056589506566524506, rse:0.38949114084243774\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0983568\n",
      "\tspeed: 0.0247s/iter; left time: 108.3098s\n",
      "\titers: 200, epoch: 1 | loss: 0.0811648\n",
      "\tspeed: 0.0220s/iter; left time: 94.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0986384 Vali Loss: 0.0830617 Test Loss: 0.0900622\n",
      "Validation loss decreased (inf --> 0.083062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0534172\n",
      "\tspeed: 0.0459s/iter; left time: 190.8347s\n",
      "\titers: 200, epoch: 2 | loss: 0.0459291\n",
      "\tspeed: 0.0220s/iter; left time: 89.4148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0541714 Vali Loss: 0.0558285 Test Loss: 0.0595404\n",
      "Validation loss decreased (0.083062 --> 0.055828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0488589\n",
      "\tspeed: 0.0455s/iter; left time: 179.1443s\n",
      "\titers: 200, epoch: 3 | loss: 0.0440432\n",
      "\tspeed: 0.0220s/iter; left time: 84.2449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0462337 Vali Loss: 0.0534941 Test Loss: 0.0573518\n",
      "Validation loss decreased (0.055828 --> 0.053494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0463716\n",
      "\tspeed: 0.0472s/iter; left time: 175.1546s\n",
      "\titers: 200, epoch: 4 | loss: 0.0456805\n",
      "\tspeed: 0.0220s/iter; left time: 79.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0441008 Vali Loss: 0.0527866 Test Loss: 0.0569766\n",
      "Validation loss decreased (0.053494 --> 0.052787).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0462096\n",
      "\tspeed: 0.0456s/iter; left time: 158.7527s\n",
      "\titers: 200, epoch: 5 | loss: 0.0410608\n",
      "\tspeed: 0.0220s/iter; left time: 74.5178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0427795 Vali Loss: 0.0525542 Test Loss: 0.0569405\n",
      "Validation loss decreased (0.052787 --> 0.052554).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0407355\n",
      "\tspeed: 0.0498s/iter; left time: 162.4428s\n",
      "\titers: 200, epoch: 6 | loss: 0.0419847\n",
      "\tspeed: 0.0221s/iter; left time: 70.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0416694 Vali Loss: 0.0518883 Test Loss: 0.0565364\n",
      "Validation loss decreased (0.052554 --> 0.051888).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0414056\n",
      "\tspeed: 0.0486s/iter; left time: 147.6256s\n",
      "\titers: 200, epoch: 7 | loss: 0.0415133\n",
      "\tspeed: 0.0221s/iter; left time: 64.8389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0407206 Vali Loss: 0.0519327 Test Loss: 0.0568358\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0397163\n",
      "\tspeed: 0.0451s/iter; left time: 126.8378s\n",
      "\titers: 200, epoch: 8 | loss: 0.0388439\n",
      "\tspeed: 0.0221s/iter; left time: 60.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0398980 Vali Loss: 0.0518868 Test Loss: 0.0571416\n",
      "Validation loss decreased (0.051888 --> 0.051887).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0371764\n",
      "\tspeed: 0.0451s/iter; left time: 116.6879s\n",
      "\titers: 200, epoch: 9 | loss: 0.0366343\n",
      "\tspeed: 0.0220s/iter; left time: 54.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0390674 Vali Loss: 0.0520276 Test Loss: 0.0576413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0378093\n",
      "\tspeed: 0.0440s/iter; left time: 103.9488s\n",
      "\titers: 200, epoch: 10 | loss: 0.0378744\n",
      "\tspeed: 0.0220s/iter; left time: 49.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0382958 Vali Loss: 0.0521671 Test Loss: 0.0580638\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0378447\n",
      "\tspeed: 0.0425s/iter; left time: 90.9655s\n",
      "\titers: 200, epoch: 11 | loss: 0.0375221\n",
      "\tspeed: 0.0220s/iter; left time: 44.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0375433 Vali Loss: 0.0524383 Test Loss: 0.0580152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0369047\n",
      "\tspeed: 0.0426s/iter; left time: 81.6378s\n",
      "\titers: 200, epoch: 12 | loss: 0.0374718\n",
      "\tspeed: 0.0220s/iter; left time: 40.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0368759 Vali Loss: 0.0522108 Test Loss: 0.0584778\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0371997\n",
      "\tspeed: 0.0426s/iter; left time: 72.0876s\n",
      "\titers: 200, epoch: 13 | loss: 0.0384833\n",
      "\tspeed: 0.0220s/iter; left time: 35.0443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0362783 Vali Loss: 0.0522735 Test Loss: 0.0587735\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010431569069623947, rmse:0.1021350547671318, mae:0.057141587138175964, rse:0.394034206867218\n",
      "Intermediate time for FR and pred_len 24: 00h:02m:50.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1006848\n",
      "\tspeed: 0.0397s/iter; left time: 174.0005s\n",
      "\titers: 200, epoch: 1 | loss: 0.0841898\n",
      "\tspeed: 0.0221s/iter; left time: 94.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.1028407 Vali Loss: 0.0909074 Test Loss: 0.1000355\n",
      "Validation loss decreased (inf --> 0.090907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0667737\n",
      "\tspeed: 0.0449s/iter; left time: 186.6393s\n",
      "\titers: 200, epoch: 2 | loss: 0.0597491\n",
      "\tspeed: 0.0222s/iter; left time: 90.1540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0683883 Vali Loss: 0.0734551 Test Loss: 0.0820000\n",
      "Validation loss decreased (0.090907 --> 0.073455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0597644\n",
      "\tspeed: 0.0536s/iter; left time: 210.6612s\n",
      "\titers: 200, epoch: 3 | loss: 0.0573469\n",
      "\tspeed: 0.0222s/iter; left time: 85.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0604713 Vali Loss: 0.0728116 Test Loss: 0.0829389\n",
      "Validation loss decreased (0.073455 --> 0.072812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0543406\n",
      "\tspeed: 0.0467s/iter; left time: 173.1935s\n",
      "\titers: 200, epoch: 4 | loss: 0.0559489\n",
      "\tspeed: 0.0222s/iter; left time: 80.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0555894 Vali Loss: 0.0726943 Test Loss: 0.0856126\n",
      "Validation loss decreased (0.072812 --> 0.072694).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0521473\n",
      "\tspeed: 0.0458s/iter; left time: 159.5019s\n",
      "\titers: 200, epoch: 5 | loss: 0.0497508\n",
      "\tspeed: 0.0222s/iter; left time: 75.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0508938 Vali Loss: 0.0734280 Test Loss: 0.0868193\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0467287\n",
      "\tspeed: 0.0453s/iter; left time: 147.8227s\n",
      "\titers: 200, epoch: 6 | loss: 0.0474530\n",
      "\tspeed: 0.0222s/iter; left time: 70.2187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0473731 Vali Loss: 0.0740491 Test Loss: 0.0903171\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0445259\n",
      "\tspeed: 0.0460s/iter; left time: 139.7311s\n",
      "\titers: 200, epoch: 7 | loss: 0.0429022\n",
      "\tspeed: 0.0222s/iter; left time: 65.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0449064 Vali Loss: 0.0749877 Test Loss: 0.0900412\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0447864\n",
      "\tspeed: 0.0459s/iter; left time: 129.0161s\n",
      "\titers: 200, epoch: 8 | loss: 0.0412697\n",
      "\tspeed: 0.0223s/iter; left time: 60.5712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0427259 Vali Loss: 0.0744871 Test Loss: 0.0900806\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0412090\n",
      "\tspeed: 0.0458s/iter; left time: 118.6480s\n",
      "\titers: 200, epoch: 9 | loss: 0.0411860\n",
      "\tspeed: 0.0225s/iter; left time: 55.9844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0410810 Vali Loss: 0.0739628 Test Loss: 0.0906877\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022053049877285957, rmse:0.14850269258022308, mae:0.08561256527900696, rse:0.5744478702545166\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1005642\n",
      "\tspeed: 0.0244s/iter; left time: 106.7894s\n",
      "\titers: 200, epoch: 1 | loss: 0.0917427\n",
      "\tspeed: 0.0221s/iter; left time: 94.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.1031050 Vali Loss: 0.0911626 Test Loss: 0.1002582\n",
      "Validation loss decreased (inf --> 0.091163).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0699997\n",
      "\tspeed: 0.0464s/iter; left time: 192.8545s\n",
      "\titers: 200, epoch: 2 | loss: 0.0637312\n",
      "\tspeed: 0.0222s/iter; left time: 90.1859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0683236 Vali Loss: 0.0735162 Test Loss: 0.0822804\n",
      "Validation loss decreased (0.091163 --> 0.073516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0605401\n",
      "\tspeed: 0.0471s/iter; left time: 185.0752s\n",
      "\titers: 200, epoch: 3 | loss: 0.0607821\n",
      "\tspeed: 0.0223s/iter; left time: 85.4301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0604257 Vali Loss: 0.0721129 Test Loss: 0.0824257\n",
      "Validation loss decreased (0.073516 --> 0.072113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0555506\n",
      "\tspeed: 0.0492s/iter; left time: 182.4720s\n",
      "\titers: 200, epoch: 4 | loss: 0.0568947\n",
      "\tspeed: 0.0222s/iter; left time: 80.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0552945 Vali Loss: 0.0730396 Test Loss: 0.0871446\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0492285\n",
      "\tspeed: 0.0458s/iter; left time: 159.7724s\n",
      "\titers: 200, epoch: 5 | loss: 0.0476777\n",
      "\tspeed: 0.0223s/iter; left time: 75.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0505104 Vali Loss: 0.0731663 Test Loss: 0.0874221\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0488765\n",
      "\tspeed: 0.0447s/iter; left time: 145.7902s\n",
      "\titers: 200, epoch: 6 | loss: 0.0477134\n",
      "\tspeed: 0.0222s/iter; left time: 70.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0469335 Vali Loss: 0.0743040 Test Loss: 0.0891248\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0456722\n",
      "\tspeed: 0.0447s/iter; left time: 135.6284s\n",
      "\titers: 200, epoch: 7 | loss: 0.0439361\n",
      "\tspeed: 0.0224s/iter; left time: 65.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0442663 Vali Loss: 0.0741631 Test Loss: 0.0898651\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0420532\n",
      "\tspeed: 0.0447s/iter; left time: 125.8808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0395115\n",
      "\tspeed: 0.0224s/iter; left time: 60.7868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0422339 Vali Loss: 0.0745660 Test Loss: 0.0915339\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019726678729057312, rmse:0.14045169949531555, mae:0.08242567628622055, rse:0.543304443359375\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:06.23s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1056457\n",
      "\tspeed: 0.0398s/iter; left time: 173.6812s\n",
      "\titers: 200, epoch: 1 | loss: 0.0920094\n",
      "\tspeed: 0.0224s/iter; left time: 95.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 223 | Train Loss: 0.1057240 Vali Loss: 0.0936650 Test Loss: 0.1019153\n",
      "Validation loss decreased (inf --> 0.093665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0718475\n",
      "\tspeed: 0.0447s/iter; left time: 185.1133s\n",
      "\titers: 200, epoch: 2 | loss: 0.0731005\n",
      "\tspeed: 0.0224s/iter; left time: 90.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0723086 Vali Loss: 0.0779335 Test Loss: 0.0873305\n",
      "Validation loss decreased (0.093665 --> 0.077934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0632716\n",
      "\tspeed: 0.0459s/iter; left time: 179.8549s\n",
      "\titers: 200, epoch: 3 | loss: 0.0641079\n",
      "\tspeed: 0.0224s/iter; left time: 85.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0631816 Vali Loss: 0.0758860 Test Loss: 0.0896951\n",
      "Validation loss decreased (0.077934 --> 0.075886).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0551088\n",
      "\tspeed: 0.0459s/iter; left time: 169.5448s\n",
      "\titers: 200, epoch: 4 | loss: 0.0547754\n",
      "\tspeed: 0.0225s/iter; left time: 80.7396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0568533 Vali Loss: 0.0776557 Test Loss: 0.0928236\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0526990\n",
      "\tspeed: 0.0449s/iter; left time: 155.9181s\n",
      "\titers: 200, epoch: 5 | loss: 0.0493257\n",
      "\tspeed: 0.0224s/iter; left time: 75.5719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0520216 Vali Loss: 0.0776104 Test Loss: 0.0933026\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0494825\n",
      "\tspeed: 0.0439s/iter; left time: 142.5911s\n",
      "\titers: 200, epoch: 6 | loss: 0.0487090\n",
      "\tspeed: 0.0225s/iter; left time: 70.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0485547 Vali Loss: 0.0779353 Test Loss: 0.0935854\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0466170\n",
      "\tspeed: 0.0443s/iter; left time: 133.9005s\n",
      "\titers: 200, epoch: 7 | loss: 0.0462868\n",
      "\tspeed: 0.0224s/iter; left time: 65.4560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0459587 Vali Loss: 0.0782540 Test Loss: 0.0941730\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0445945\n",
      "\tspeed: 0.0442s/iter; left time: 123.8177s\n",
      "\titers: 200, epoch: 8 | loss: 0.0431015\n",
      "\tspeed: 0.0225s/iter; left time: 60.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0438796 Vali Loss: 0.0789876 Test Loss: 0.0948573\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021620899438858032, rmse:0.1470404714345932, mae:0.08969511091709137, rse:0.5695016980171204\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0991714\n",
      "\tspeed: 0.0242s/iter; left time: 105.4279s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885712\n",
      "\tspeed: 0.0224s/iter; left time: 95.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.1043165 Vali Loss: 0.0933984 Test Loss: 0.1014372\n",
      "Validation loss decreased (inf --> 0.093398).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0710609\n",
      "\tspeed: 0.0452s/iter; left time: 187.1805s\n",
      "\titers: 200, epoch: 2 | loss: 0.0618889\n",
      "\tspeed: 0.0225s/iter; left time: 90.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0721745 Vali Loss: 0.0774508 Test Loss: 0.0867138\n",
      "Validation loss decreased (0.093398 --> 0.077451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0610502\n",
      "\tspeed: 0.0455s/iter; left time: 178.2605s\n",
      "\titers: 200, epoch: 3 | loss: 0.0590557\n",
      "\tspeed: 0.0225s/iter; left time: 85.7997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0635017 Vali Loss: 0.0759463 Test Loss: 0.0875126\n",
      "Validation loss decreased (0.077451 --> 0.075946).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0575557\n",
      "\tspeed: 0.0448s/iter; left time: 165.3782s\n",
      "\titers: 200, epoch: 4 | loss: 0.0550404\n",
      "\tspeed: 0.0224s/iter; left time: 80.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0579271 Vali Loss: 0.0790097 Test Loss: 0.0919720\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0552282\n",
      "\tspeed: 0.0460s/iter; left time: 159.5844s\n",
      "\titers: 200, epoch: 5 | loss: 0.0517130\n",
      "\tspeed: 0.0225s/iter; left time: 75.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0529827 Vali Loss: 0.0791752 Test Loss: 0.0956786\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0491072\n",
      "\tspeed: 0.0445s/iter; left time: 144.5271s\n",
      "\titers: 200, epoch: 6 | loss: 0.0490277\n",
      "\tspeed: 0.0225s/iter; left time: 70.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0493609 Vali Loss: 0.0793608 Test Loss: 0.0970479\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0464880\n",
      "\tspeed: 0.0440s/iter; left time: 132.9713s\n",
      "\titers: 200, epoch: 7 | loss: 0.0456919\n",
      "\tspeed: 0.0224s/iter; left time: 65.5195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0465144 Vali Loss: 0.0802678 Test Loss: 0.0969906\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0447792\n",
      "\tspeed: 0.0438s/iter; left time: 122.5531s\n",
      "\titers: 200, epoch: 8 | loss: 0.0422901\n",
      "\tspeed: 0.0225s/iter; left time: 60.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0443371 Vali Loss: 0.0795111 Test Loss: 0.0977988\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02099021151661873, rmse:0.1448799967765808, mae:0.08751260489225388, rse:0.5611339211463928\n",
      "Intermediate time for FR and pred_len 168: 00h:01m:56.97s\n",
      "Intermediate time for FR: 00h:06m:53.36s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1278432\n",
      "\tspeed: 0.0403s/iter; left time: 176.4808s\n",
      "\titers: 200, epoch: 1 | loss: 0.1199756\n",
      "\tspeed: 0.0221s/iter; left time: 94.6191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.1362877 Vali Loss: 0.0958211 Test Loss: 0.0981545\n",
      "Validation loss decreased (inf --> 0.095821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0730210\n",
      "\tspeed: 0.0448s/iter; left time: 186.1073s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685680\n",
      "\tspeed: 0.0221s/iter; left time: 89.8356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0737874 Vali Loss: 0.0606424 Test Loss: 0.0634204\n",
      "Validation loss decreased (0.095821 --> 0.060642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0679964\n",
      "\tspeed: 0.0455s/iter; left time: 179.1425s\n",
      "\titers: 200, epoch: 3 | loss: 0.0627244\n",
      "\tspeed: 0.0221s/iter; left time: 84.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0626436 Vali Loss: 0.0585590 Test Loss: 0.0609500\n",
      "Validation loss decreased (0.060642 --> 0.058559).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0576157\n",
      "\tspeed: 0.0441s/iter; left time: 163.6331s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638441\n",
      "\tspeed: 0.0221s/iter; left time: 79.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0600721 Vali Loss: 0.0572869 Test Loss: 0.0595370\n",
      "Validation loss decreased (0.058559 --> 0.057287).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0601263\n",
      "\tspeed: 0.0447s/iter; left time: 155.6338s\n",
      "\titers: 200, epoch: 5 | loss: 0.0590720\n",
      "\tspeed: 0.0222s/iter; left time: 75.0241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0583885 Vali Loss: 0.0561951 Test Loss: 0.0586180\n",
      "Validation loss decreased (0.057287 --> 0.056195).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568630\n",
      "\tspeed: 0.0444s/iter; left time: 144.7807s\n",
      "\titers: 200, epoch: 6 | loss: 0.0588873\n",
      "\tspeed: 0.0221s/iter; left time: 69.9577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0571105 Vali Loss: 0.0560492 Test Loss: 0.0585387\n",
      "Validation loss decreased (0.056195 --> 0.056049).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0534128\n",
      "\tspeed: 0.0449s/iter; left time: 136.3684s\n",
      "\titers: 200, epoch: 7 | loss: 0.0566401\n",
      "\tspeed: 0.0221s/iter; left time: 65.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0559917 Vali Loss: 0.0559686 Test Loss: 0.0586595\n",
      "Validation loss decreased (0.056049 --> 0.055969).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0540253\n",
      "\tspeed: 0.0445s/iter; left time: 125.2643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0523734\n",
      "\tspeed: 0.0221s/iter; left time: 59.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0550626 Vali Loss: 0.0557020 Test Loss: 0.0581373\n",
      "Validation loss decreased (0.055969 --> 0.055702).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0549227\n",
      "\tspeed: 0.0441s/iter; left time: 114.2035s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555563\n",
      "\tspeed: 0.0220s/iter; left time: 54.8628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0541545 Vali Loss: 0.0554387 Test Loss: 0.0579014\n",
      "Validation loss decreased (0.055702 --> 0.055439).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0573516\n",
      "\tspeed: 0.0443s/iter; left time: 104.8230s\n",
      "\titers: 200, epoch: 10 | loss: 0.0533080\n",
      "\tspeed: 0.0223s/iter; left time: 50.6226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0534064 Vali Loss: 0.0554795 Test Loss: 0.0580060\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0537935\n",
      "\tspeed: 0.0433s/iter; left time: 92.7225s\n",
      "\titers: 200, epoch: 11 | loss: 0.0519395\n",
      "\tspeed: 0.0221s/iter; left time: 45.1442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0526716 Vali Loss: 0.0553332 Test Loss: 0.0582383\n",
      "Validation loss decreased (0.055439 --> 0.055333).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494004\n",
      "\tspeed: 0.0442s/iter; left time: 84.6628s\n",
      "\titers: 200, epoch: 12 | loss: 0.0503696\n",
      "\tspeed: 0.0222s/iter; left time: 40.3168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0519590 Vali Loss: 0.0552357 Test Loss: 0.0584522\n",
      "Validation loss decreased (0.055333 --> 0.055236).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0522351\n",
      "\tspeed: 0.0446s/iter; left time: 75.5378s\n",
      "\titers: 200, epoch: 13 | loss: 0.0554844\n",
      "\tspeed: 0.0221s/iter; left time: 35.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0512310 Vali Loss: 0.0556980 Test Loss: 0.0582841\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0527922\n",
      "\tspeed: 0.0441s/iter; left time: 64.7681s\n",
      "\titers: 200, epoch: 14 | loss: 0.0496648\n",
      "\tspeed: 0.0221s/iter; left time: 30.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0505910 Vali Loss: 0.0554339 Test Loss: 0.0585908\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0505742\n",
      "\tspeed: 0.0428s/iter; left time: 53.3226s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552145\n",
      "\tspeed: 0.0221s/iter; left time: 25.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0499754 Vali Loss: 0.0557357 Test Loss: 0.0589469\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0501169\n",
      "\tspeed: 0.0435s/iter; left time: 44.3919s\n",
      "\titers: 200, epoch: 16 | loss: 0.0476602\n",
      "\tspeed: 0.0223s/iter; left time: 20.5843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0494236 Vali Loss: 0.0556930 Test Loss: 0.0588406\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0540575\n",
      "\tspeed: 0.0434s/iter; left time: 34.5807s\n",
      "\titers: 200, epoch: 17 | loss: 0.0460231\n",
      "\tspeed: 0.0221s/iter; left time: 15.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0488599 Vali Loss: 0.0560844 Test Loss: 0.0593362\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010351636447012424, rmse:0.10174299031496048, mae:0.05845222249627113, rse:0.3844366669654846\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1312290\n",
      "\tspeed: 0.0239s/iter; left time: 104.5800s\n",
      "\titers: 200, epoch: 1 | loss: 0.1132838\n",
      "\tspeed: 0.0221s/iter; left time: 94.6417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.1434084 Vali Loss: 0.0982049 Test Loss: 0.1005447\n",
      "Validation loss decreased (inf --> 0.098205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0674736\n",
      "\tspeed: 0.0449s/iter; left time: 186.7286s\n",
      "\titers: 200, epoch: 2 | loss: 0.0681145\n",
      "\tspeed: 0.0221s/iter; left time: 89.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0744928 Vali Loss: 0.0611276 Test Loss: 0.0633811\n",
      "Validation loss decreased (0.098205 --> 0.061128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0622577\n",
      "\tspeed: 0.0485s/iter; left time: 190.7232s\n",
      "\titers: 200, epoch: 3 | loss: 0.0642815\n",
      "\tspeed: 0.0221s/iter; left time: 84.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0627514 Vali Loss: 0.0584585 Test Loss: 0.0605055\n",
      "Validation loss decreased (0.061128 --> 0.058458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0570491\n",
      "\tspeed: 0.0435s/iter; left time: 161.3850s\n",
      "\titers: 200, epoch: 4 | loss: 0.0608197\n",
      "\tspeed: 0.0221s/iter; left time: 79.7839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0602316 Vali Loss: 0.0581894 Test Loss: 0.0604754\n",
      "Validation loss decreased (0.058458 --> 0.058189).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0571427\n",
      "\tspeed: 0.0434s/iter; left time: 151.1813s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591655\n",
      "\tspeed: 0.0221s/iter; left time: 74.7114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0585666 Vali Loss: 0.0570316 Test Loss: 0.0593375\n",
      "Validation loss decreased (0.058189 --> 0.057032).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569229\n",
      "\tspeed: 0.0446s/iter; left time: 145.4980s\n",
      "\titers: 200, epoch: 6 | loss: 0.0601685\n",
      "\tspeed: 0.0221s/iter; left time: 69.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0572205 Vali Loss: 0.0561985 Test Loss: 0.0586197\n",
      "Validation loss decreased (0.057032 --> 0.056198).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0528390\n",
      "\tspeed: 0.0443s/iter; left time: 134.6254s\n",
      "\titers: 200, epoch: 7 | loss: 0.0560399\n",
      "\tspeed: 0.0220s/iter; left time: 64.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0561812 Vali Loss: 0.0559815 Test Loss: 0.0584007\n",
      "Validation loss decreased (0.056198 --> 0.055982).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0566561\n",
      "\tspeed: 0.0432s/iter; left time: 121.5715s\n",
      "\titers: 200, epoch: 8 | loss: 0.0531043\n",
      "\tspeed: 0.0220s/iter; left time: 59.6308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0552645 Vali Loss: 0.0561232 Test Loss: 0.0582675\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0574572\n",
      "\tspeed: 0.0422s/iter; left time: 109.1267s\n",
      "\titers: 200, epoch: 9 | loss: 0.0525047\n",
      "\tspeed: 0.0221s/iter; left time: 55.0661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0542702 Vali Loss: 0.0558798 Test Loss: 0.0580742\n",
      "Validation loss decreased (0.055982 --> 0.055880).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514821\n",
      "\tspeed: 0.0442s/iter; left time: 104.4473s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550405\n",
      "\tspeed: 0.0222s/iter; left time: 50.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0534769 Vali Loss: 0.0561165 Test Loss: 0.0583153\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0494045\n",
      "\tspeed: 0.0429s/iter; left time: 91.7487s\n",
      "\titers: 200, epoch: 11 | loss: 0.0544998\n",
      "\tspeed: 0.0222s/iter; left time: 45.3403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0527047 Vali Loss: 0.0559758 Test Loss: 0.0582508\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558888\n",
      "\tspeed: 0.0430s/iter; left time: 82.4352s\n",
      "\titers: 200, epoch: 12 | loss: 0.0501107\n",
      "\tspeed: 0.0223s/iter; left time: 40.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0519439 Vali Loss: 0.0558040 Test Loss: 0.0584697\n",
      "Validation loss decreased (0.055880 --> 0.055804).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0464681\n",
      "\tspeed: 0.0440s/iter; left time: 74.4818s\n",
      "\titers: 200, epoch: 13 | loss: 0.0487312\n",
      "\tspeed: 0.0221s/iter; left time: 35.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0512102 Vali Loss: 0.0558723 Test Loss: 0.0584111\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0515612\n",
      "\tspeed: 0.0426s/iter; left time: 62.5964s\n",
      "\titers: 200, epoch: 14 | loss: 0.0508993\n",
      "\tspeed: 0.0221s/iter; left time: 30.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0505620 Vali Loss: 0.0561245 Test Loss: 0.0586363\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0493988\n",
      "\tspeed: 0.0426s/iter; left time: 53.0185s\n",
      "\titers: 200, epoch: 15 | loss: 0.0481921\n",
      "\tspeed: 0.0222s/iter; left time: 25.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0499058 Vali Loss: 0.0561699 Test Loss: 0.0588772\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0517682\n",
      "\tspeed: 0.0428s/iter; left time: 43.7099s\n",
      "\titers: 200, epoch: 16 | loss: 0.0486397\n",
      "\tspeed: 0.0223s/iter; left time: 20.5641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0493334 Vali Loss: 0.0565590 Test Loss: 0.0592585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0502274\n",
      "\tspeed: 0.0428s/iter; left time: 34.1402s\n",
      "\titers: 200, epoch: 17 | loss: 0.0491273\n",
      "\tspeed: 0.0221s/iter; left time: 15.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0487718 Vali Loss: 0.0566396 Test Loss: 0.0595277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010335784405469894, rmse:0.10166505724191666, mae:0.05846967175602913, rse:0.3841421902179718\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:53.46s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1406602\n",
      "\tspeed: 0.0396s/iter; left time: 173.4839s\n",
      "\titers: 200, epoch: 1 | loss: 0.1232709\n",
      "\tspeed: 0.0222s/iter; left time: 95.2344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.1463149 Vali Loss: 0.1063972 Test Loss: 0.1096973\n",
      "Validation loss decreased (inf --> 0.106397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0882624\n",
      "\tspeed: 0.0446s/iter; left time: 185.3561s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824391\n",
      "\tspeed: 0.0223s/iter; left time: 90.2859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0918562 Vali Loss: 0.0795108 Test Loss: 0.0841194\n",
      "Validation loss decreased (0.106397 --> 0.079511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0812526\n",
      "\tspeed: 0.0456s/iter; left time: 179.2393s\n",
      "\titers: 200, epoch: 3 | loss: 0.0784772\n",
      "\tspeed: 0.0222s/iter; left time: 85.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0820270 Vali Loss: 0.0783789 Test Loss: 0.0819392\n",
      "Validation loss decreased (0.079511 --> 0.078379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744383\n",
      "\tspeed: 0.0454s/iter; left time: 168.5465s\n",
      "\titers: 200, epoch: 4 | loss: 0.0777021\n",
      "\tspeed: 0.0223s/iter; left time: 80.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0783910 Vali Loss: 0.0788257 Test Loss: 0.0830169\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0753594\n",
      "\tspeed: 0.0442s/iter; left time: 153.9169s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750151\n",
      "\tspeed: 0.0223s/iter; left time: 75.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0734081 Vali Loss: 0.0819957 Test Loss: 0.0856044\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0659106\n",
      "\tspeed: 0.0441s/iter; left time: 143.8063s\n",
      "\titers: 200, epoch: 6 | loss: 0.0659576\n",
      "\tspeed: 0.0222s/iter; left time: 70.1749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0686825 Vali Loss: 0.0842883 Test Loss: 0.0852429\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0648111\n",
      "\tspeed: 0.0444s/iter; left time: 134.8696s\n",
      "\titers: 200, epoch: 7 | loss: 0.0614157\n",
      "\tspeed: 0.0222s/iter; left time: 65.2844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0650621 Vali Loss: 0.0839392 Test Loss: 0.0866236\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0651447\n",
      "\tspeed: 0.0440s/iter; left time: 123.8320s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613163\n",
      "\tspeed: 0.0222s/iter; left time: 60.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0623451 Vali Loss: 0.0845894 Test Loss: 0.0871178\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018120603635907173, rmse:0.1346127986907959, mae:0.08193915337324142, rse:0.5089855194091797\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1431607\n",
      "\tspeed: 0.0244s/iter; left time: 106.7205s\n",
      "\titers: 200, epoch: 1 | loss: 0.1226398\n",
      "\tspeed: 0.0223s/iter; left time: 95.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.1465745 Vali Loss: 0.1063707 Test Loss: 0.1097031\n",
      "Validation loss decreased (inf --> 0.106371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0898145\n",
      "\tspeed: 0.0452s/iter; left time: 188.1016s\n",
      "\titers: 200, epoch: 2 | loss: 0.0898023\n",
      "\tspeed: 0.0223s/iter; left time: 90.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0918464 Vali Loss: 0.0796784 Test Loss: 0.0837768\n",
      "Validation loss decreased (0.106371 --> 0.079678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820685\n",
      "\tspeed: 0.0451s/iter; left time: 177.2884s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804370\n",
      "\tspeed: 0.0223s/iter; left time: 85.3903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0818808 Vali Loss: 0.0782289 Test Loss: 0.0822492\n",
      "Validation loss decreased (0.079678 --> 0.078229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801883\n",
      "\tspeed: 0.0466s/iter; left time: 172.7831s\n",
      "\titers: 200, epoch: 4 | loss: 0.0770322\n",
      "\tspeed: 0.0222s/iter; left time: 80.2333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0781260 Vali Loss: 0.0790618 Test Loss: 0.0833921\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0714568\n",
      "\tspeed: 0.0439s/iter; left time: 152.9201s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724024\n",
      "\tspeed: 0.0222s/iter; left time: 75.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0734421 Vali Loss: 0.0818351 Test Loss: 0.0865005\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0687422\n",
      "\tspeed: 0.0441s/iter; left time: 143.6745s\n",
      "\titers: 200, epoch: 6 | loss: 0.0683053\n",
      "\tspeed: 0.0223s/iter; left time: 70.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0687262 Vali Loss: 0.0829564 Test Loss: 0.0874128\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0646902\n",
      "\tspeed: 0.0443s/iter; left time: 134.5349s\n",
      "\titers: 200, epoch: 7 | loss: 0.0637687\n",
      "\tspeed: 0.0223s/iter; left time: 65.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0650412 Vali Loss: 0.0835494 Test Loss: 0.0889566\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0622228\n",
      "\tspeed: 0.0437s/iter; left time: 123.0097s\n",
      "\titers: 200, epoch: 8 | loss: 0.0603192\n",
      "\tspeed: 0.0223s/iter; left time: 60.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0619382 Vali Loss: 0.0838071 Test Loss: 0.0882461\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01840209774672985, rmse:0.13565433025360107, mae:0.08224920183420181, rse:0.5129236578941345\n",
      "Intermediate time for IT and pred_len 96: 00h:01m:55.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1423591\n",
      "\tspeed: 0.0387s/iter; left time: 168.9553s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247035\n",
      "\tspeed: 0.0224s/iter; left time: 95.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.1496753 Vali Loss: 0.1086939 Test Loss: 0.1115384\n",
      "Validation loss decreased (inf --> 0.108694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0945189\n",
      "\tspeed: 0.0450s/iter; left time: 186.0453s\n",
      "\titers: 200, epoch: 2 | loss: 0.0915999\n",
      "\tspeed: 0.0224s/iter; left time: 90.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0958328 Vali Loss: 0.0841946 Test Loss: 0.0881004\n",
      "Validation loss decreased (0.108694 --> 0.084195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0892303\n",
      "\tspeed: 0.0455s/iter; left time: 178.0036s\n",
      "\titers: 200, epoch: 3 | loss: 0.0885527\n",
      "\tspeed: 0.0224s/iter; left time: 85.4416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0856628 Vali Loss: 0.0844716 Test Loss: 0.0865444\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801477\n",
      "\tspeed: 0.0441s/iter; left time: 162.6857s\n",
      "\titers: 200, epoch: 4 | loss: 0.0779318\n",
      "\tspeed: 0.0224s/iter; left time: 80.4699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0803572 Vali Loss: 0.0860760 Test Loss: 0.0882949\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0737198\n",
      "\tspeed: 0.0444s/iter; left time: 153.9110s\n",
      "\titers: 200, epoch: 5 | loss: 0.0765113\n",
      "\tspeed: 0.0225s/iter; left time: 75.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0744970 Vali Loss: 0.0889429 Test Loss: 0.0900481\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0701593\n",
      "\tspeed: 0.0447s/iter; left time: 145.1644s\n",
      "\titers: 200, epoch: 6 | loss: 0.0692381\n",
      "\tspeed: 0.0224s/iter; left time: 70.6155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0699709 Vali Loss: 0.0898496 Test Loss: 0.0908735\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0679185\n",
      "\tspeed: 0.0456s/iter; left time: 137.7382s\n",
      "\titers: 200, epoch: 7 | loss: 0.0630262\n",
      "\tspeed: 0.0225s/iter; left time: 65.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0663681 Vali Loss: 0.0885903 Test Loss: 0.0913930\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019992955029010773, rmse:0.1413964480161667, mae:0.08810041099786758, rse:0.5351320505142212\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1404880\n",
      "\tspeed: 0.0284s/iter; left time: 123.7550s\n",
      "\titers: 200, epoch: 1 | loss: 0.1218658\n",
      "\tspeed: 0.0225s/iter; left time: 95.6780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 223 | Train Loss: 0.1495159 Vali Loss: 0.1086430 Test Loss: 0.1113816\n",
      "Validation loss decreased (inf --> 0.108643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0947164\n",
      "\tspeed: 0.0464s/iter; left time: 191.8074s\n",
      "\titers: 200, epoch: 2 | loss: 0.0872592\n",
      "\tspeed: 0.0224s/iter; left time: 90.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0958824 Vali Loss: 0.0842354 Test Loss: 0.0879539\n",
      "Validation loss decreased (0.108643 --> 0.084235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0828680\n",
      "\tspeed: 0.0454s/iter; left time: 177.6948s\n",
      "\titers: 200, epoch: 3 | loss: 0.0856310\n",
      "\tspeed: 0.0225s/iter; left time: 85.6719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0855720 Vali Loss: 0.0846827 Test Loss: 0.0879662\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820475\n",
      "\tspeed: 0.0441s/iter; left time: 162.7253s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760696\n",
      "\tspeed: 0.0224s/iter; left time: 80.5821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0801973 Vali Loss: 0.0866909 Test Loss: 0.0899356\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758944\n",
      "\tspeed: 0.0441s/iter; left time: 152.8667s\n",
      "\titers: 200, epoch: 5 | loss: 0.0725707\n",
      "\tspeed: 0.0225s/iter; left time: 75.7098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0741449 Vali Loss: 0.0878185 Test Loss: 0.0923809\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0708352\n",
      "\tspeed: 0.0441s/iter; left time: 143.0451s\n",
      "\titers: 200, epoch: 6 | loss: 0.0676354\n",
      "\tspeed: 0.0225s/iter; left time: 70.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0694595 Vali Loss: 0.0874840 Test Loss: 0.0934459\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0662269\n",
      "\tspeed: 0.0439s/iter; left time: 132.7135s\n",
      "\titers: 200, epoch: 7 | loss: 0.0632087\n",
      "\tspeed: 0.0225s/iter; left time: 65.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0656503 Vali Loss: 0.0889737 Test Loss: 0.0943873\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019958944991230965, rmse:0.14127613604068756, mae:0.08795391023159027, rse:0.5346766710281372\n",
      "Intermediate time for IT and pred_len 168: 00h:01m:43.60s\n",
      "Intermediate time for IT: 00h:07m:33.05s\n",
      "Total time: 00h:41m:40.27s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'DE',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.021372228860855103,\n",
       "  'RMSE': 0.14619243144989014,\n",
       "  'MAE': 0.09199438244104385},\n",
       " {'Country': 'DE',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.02161523513495922,\n",
       "  'RMSE': 0.14702120423316956,\n",
       "  'MAE': 0.0919095128774643},\n",
       " {'Country': 'DE',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.04040202498435974,\n",
       "  'RMSE': 0.2010025531053543,\n",
       "  'MAE': 0.13258694112300873},\n",
       " {'Country': 'DE',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.043257858604192734,\n",
       "  'RMSE': 0.20798523724079132,\n",
       "  'MAE': 0.1363820880651474},\n",
       " {'Country': 'DE',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.04741961508989334,\n",
       "  'RMSE': 0.21776045858860016,\n",
       "  'MAE': 0.14430703222751617},\n",
       " {'Country': 'DE',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.04486357793211937,\n",
       "  'RMSE': 0.21181024610996246,\n",
       "  'MAE': 0.14129573106765747},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.025332890450954437,\n",
       "  'RMSE': 0.15916308760643005,\n",
       "  'MAE': 0.10177655518054962},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.02496434934437275,\n",
       "  'RMSE': 0.158001109957695,\n",
       "  'MAE': 0.10125575959682465},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.04291878640651703,\n",
       "  'RMSE': 0.20716850459575653,\n",
       "  'MAE': 0.14232265949249268},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.042682863771915436,\n",
       "  'RMSE': 0.20659831166267395,\n",
       "  'MAE': 0.1399351954460144},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.052469152957201004,\n",
       "  'RMSE': 0.22906145453453064,\n",
       "  'MAE': 0.15288984775543213},\n",
       " {'Country': 'GB',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.047632455825805664,\n",
       "  'RMSE': 0.21824860572814941,\n",
       "  'MAE': 0.1492750644683838},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.00992313027381897,\n",
       "  'RMSE': 0.09961491078138351,\n",
       "  'MAE': 0.06135452166199684},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.009944847784936428,\n",
       "  'RMSE': 0.09972386062145233,\n",
       "  'MAE': 0.061164192855358124},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.019271597266197205,\n",
       "  'RMSE': 0.13882218301296234,\n",
       "  'MAE': 0.09061609208583832},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.019083218649029732,\n",
       "  'RMSE': 0.13814201951026917,\n",
       "  'MAE': 0.09104538708925247},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.02172878384590149,\n",
       "  'RMSE': 0.14740686118602753,\n",
       "  'MAE': 0.09710493683815002},\n",
       " {'Country': 'ES',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.021894296631217003,\n",
       "  'RMSE': 0.14796721935272217,\n",
       "  'MAE': 0.09846556931734085},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.01019241288304329,\n",
       "  'RMSE': 0.1009574830532074,\n",
       "  'MAE': 0.056589506566524506},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.010431569069623947,\n",
       "  'RMSE': 0.1021350547671318,\n",
       "  'MAE': 0.057141587138175964},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.022053049877285957,\n",
       "  'RMSE': 0.14850269258022308,\n",
       "  'MAE': 0.08561256527900696},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.019726678729057312,\n",
       "  'RMSE': 0.14045169949531555,\n",
       "  'MAE': 0.08242567628622055},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.021620899438858032,\n",
       "  'RMSE': 0.1470404714345932,\n",
       "  'MAE': 0.08969511091709137},\n",
       " {'Country': 'FR',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.02099021151661873,\n",
       "  'RMSE': 0.1448799967765808,\n",
       "  'MAE': 0.08751260489225388},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.010351636447012424,\n",
       "  'RMSE': 0.10174299031496048,\n",
       "  'MAE': 0.05845222249627113},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.010335784405469894,\n",
       "  'RMSE': 0.10166505724191666,\n",
       "  'MAE': 0.05846967175602913},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.018120603635907173,\n",
       "  'RMSE': 0.1346127986907959,\n",
       "  'MAE': 0.08193915337324142},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.01840209774672985,\n",
       "  'RMSE': 0.13565433025360107,\n",
       "  'MAE': 0.08224920183420181},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.019992955029010773,\n",
       "  'RMSE': 0.1413964480161667,\n",
       "  'MAE': 0.08810041099786758},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.019958944991230965,\n",
       "  'RMSE': 0.14127613604068756,\n",
       "  'MAE': 0.08795391023159027}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>0.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.0569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.0840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.0821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0215  0.1466  0.0920\n",
       "        96        0.0418  0.2045  0.1345\n",
       "        168       0.0461  0.2148  0.1428\n",
       "ES      24        0.0099  0.0997  0.0613\n",
       "        96        0.0192  0.1385  0.0908\n",
       "        168       0.0218  0.1477  0.0978\n",
       "FR      24        0.0103  0.1015  0.0569\n",
       "        96        0.0209  0.1445  0.0840\n",
       "        168       0.0213  0.1460  0.0886\n",
       "GB      24        0.0251  0.1586  0.1015\n",
       "        96        0.0428  0.2069  0.1411\n",
       "        168       0.0501  0.2237  0.1511\n",
       "IT      24        0.0103  0.1017  0.0585\n",
       "        96        0.0183  0.1351  0.0821\n",
       "        168       0.0200  0.1413  0.0880"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No channel independence (channel-mixing) and no ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2657478\n",
      "\tspeed: 0.0637s/iter; left time: 279.1245s\n",
      "\titers: 200, epoch: 1 | loss: 0.2527280\n",
      "\tspeed: 0.0430s/iter; left time: 184.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.2740265 Vali Loss: 0.2340106 Test Loss: 0.2342555\n",
      "Validation loss decreased (inf --> 0.234011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1404758\n",
      "\tspeed: 0.0790s/iter; left time: 328.5442s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105321\n",
      "\tspeed: 0.0446s/iter; left time: 181.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.09s\n",
      "Steps: 224 | Train Loss: 0.1482110 Vali Loss: 0.1070340 Test Loss: 0.1076059\n",
      "Validation loss decreased (0.234011 --> 0.107034).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1003839\n",
      "\tspeed: 0.0777s/iter; left time: 305.4986s\n",
      "\titers: 200, epoch: 3 | loss: 0.0967904\n",
      "\tspeed: 0.0441s/iter; left time: 168.8494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0992747 Vali Loss: 0.0978758 Test Loss: 0.1021475\n",
      "Validation loss decreased (0.107034 --> 0.097876).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0855676\n",
      "\tspeed: 0.0795s/iter; left time: 294.8223s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763040\n",
      "\tspeed: 0.0433s/iter; left time: 156.3166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0898730 Vali Loss: 0.0921396 Test Loss: 0.0954524\n",
      "Validation loss decreased (0.097876 --> 0.092140).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0896402\n",
      "\tspeed: 0.0771s/iter; left time: 268.7935s\n",
      "\titers: 200, epoch: 5 | loss: 0.0937465\n",
      "\tspeed: 0.0434s/iter; left time: 146.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 224 | Train Loss: 0.0896085 Vali Loss: 0.0953803 Test Loss: 0.0979037\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0859100\n",
      "\tspeed: 0.0760s/iter; left time: 247.8759s\n",
      "\titers: 200, epoch: 6 | loss: 0.0856707\n",
      "\tspeed: 0.0460s/iter; left time: 145.2937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.14s\n",
      "Steps: 224 | Train Loss: 0.0832405 Vali Loss: 0.0926656 Test Loss: 0.0953805\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0790576\n",
      "\tspeed: 0.0779s/iter; left time: 236.6758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0800128\n",
      "\tspeed: 0.0434s/iter; left time: 127.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0805757 Vali Loss: 0.0921244 Test Loss: 0.0938409\n",
      "Validation loss decreased (0.092140 --> 0.092124).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729286\n",
      "\tspeed: 0.0802s/iter; left time: 225.4682s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751025\n",
      "\tspeed: 0.0434s/iter; left time: 117.7795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0787485 Vali Loss: 0.0908563 Test Loss: 0.0939367\n",
      "Validation loss decreased (0.092124 --> 0.090856).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0812296\n",
      "\tspeed: 0.0786s/iter; left time: 203.5397s\n",
      "\titers: 200, epoch: 9 | loss: 0.0747850\n",
      "\tspeed: 0.0433s/iter; left time: 107.8861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0778406 Vali Loss: 0.0901872 Test Loss: 0.0923344\n",
      "Validation loss decreased (0.090856 --> 0.090187).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758798\n",
      "\tspeed: 0.0777s/iter; left time: 183.8605s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783221\n",
      "\tspeed: 0.0437s/iter; left time: 99.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0766764 Vali Loss: 0.0908238 Test Loss: 0.0928830\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0801620\n",
      "\tspeed: 0.0794s/iter; left time: 169.9499s\n",
      "\titers: 200, epoch: 11 | loss: 0.0847010\n",
      "\tspeed: 0.0475s/iter; left time: 96.9949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.95s\n",
      "Steps: 224 | Train Loss: 0.0800920 Vali Loss: 0.0897619 Test Loss: 0.0931990\n",
      "Validation loss decreased (0.090187 --> 0.089762).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0768841\n",
      "\tspeed: 0.0947s/iter; left time: 181.5105s\n",
      "\titers: 200, epoch: 12 | loss: 0.0749555\n",
      "\tspeed: 0.0433s/iter; left time: 78.6812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0756699 Vali Loss: 0.0915122 Test Loss: 0.0943724\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0792854\n",
      "\tspeed: 0.0764s/iter; left time: 129.2944s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741391\n",
      "\tspeed: 0.0433s/iter; left time: 69.0312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 224 | Train Loss: 0.0740692 Vali Loss: 0.0903656 Test Loss: 0.0930762\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0788646\n",
      "\tspeed: 0.0761s/iter; left time: 111.8306s\n",
      "\titers: 200, epoch: 14 | loss: 0.0824332\n",
      "\tspeed: 0.0433s/iter; left time: 59.3083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 224 | Train Loss: 0.0744290 Vali Loss: 0.0900930 Test Loss: 0.0921499\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0723943\n",
      "\tspeed: 0.0799s/iter; left time: 99.5316s\n",
      "\titers: 200, epoch: 15 | loss: 0.1042471\n",
      "\tspeed: 0.0434s/iter; left time: 49.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.12s\n",
      "Steps: 224 | Train Loss: 0.0726559 Vali Loss: 0.0918415 Test Loss: 0.0923088\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0719769\n",
      "\tspeed: 0.0766s/iter; left time: 78.2192s\n",
      "\titers: 200, epoch: 16 | loss: 0.0649376\n",
      "\tspeed: 0.0445s/iter; left time: 40.9945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0725160 Vali Loss: 0.0906236 Test Loss: 0.0943109\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021456871181726456, rmse:0.14648164808750153, mae:0.09319896996021271, rse:0.5169540047645569\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2791396\n",
      "\tspeed: 0.0447s/iter; left time: 196.0192s\n",
      "\titers: 200, epoch: 1 | loss: 0.2618844\n",
      "\tspeed: 0.0433s/iter; left time: 185.2905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.2725621 Vali Loss: 0.2341813 Test Loss: 0.2355237\n",
      "Validation loss decreased (inf --> 0.234181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1501929\n",
      "\tspeed: 0.0799s/iter; left time: 332.2870s\n",
      "\titers: 200, epoch: 2 | loss: 0.1128257\n",
      "\tspeed: 0.0433s/iter; left time: 175.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.1500030 Vali Loss: 0.1051124 Test Loss: 0.1097043\n",
      "Validation loss decreased (0.234181 --> 0.105112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1110219\n",
      "\tspeed: 0.0785s/iter; left time: 308.6786s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091781\n",
      "\tspeed: 0.0467s/iter; left time: 179.1398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 224 | Train Loss: 0.1016917 Vali Loss: 0.0973428 Test Loss: 0.1010508\n",
      "Validation loss decreased (0.105112 --> 0.097343).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0860147\n",
      "\tspeed: 0.0792s/iter; left time: 293.7659s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797995\n",
      "\tspeed: 0.0434s/iter; left time: 156.6222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0891722 Vali Loss: 0.0929730 Test Loss: 0.0958077\n",
      "Validation loss decreased (0.097343 --> 0.092973).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0848356\n",
      "\tspeed: 0.0788s/iter; left time: 274.7135s\n",
      "\titers: 200, epoch: 5 | loss: 0.1123861\n",
      "\tspeed: 0.0433s/iter; left time: 146.7078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.0859896 Vali Loss: 0.0938694 Test Loss: 0.0979496\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0963809\n",
      "\tspeed: 0.0753s/iter; left time: 245.6833s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816114\n",
      "\tspeed: 0.0433s/iter; left time: 137.0024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0839937 Vali Loss: 0.0920368 Test Loss: 0.0959087\n",
      "Validation loss decreased (0.092973 --> 0.092037).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0861100\n",
      "\tspeed: 0.0780s/iter; left time: 236.7637s\n",
      "\titers: 200, epoch: 7 | loss: 0.0898114\n",
      "\tspeed: 0.0460s/iter; left time: 135.1029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.16s\n",
      "Steps: 224 | Train Loss: 0.0836511 Vali Loss: 0.0908973 Test Loss: 0.0938695\n",
      "Validation loss decreased (0.092037 --> 0.090897).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776859\n",
      "\tspeed: 0.0808s/iter; left time: 227.3705s\n",
      "\titers: 200, epoch: 8 | loss: 0.0842635\n",
      "\tspeed: 0.0437s/iter; left time: 118.6881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0827466 Vali Loss: 0.0920693 Test Loss: 0.0942901\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0804933\n",
      "\tspeed: 0.0777s/iter; left time: 201.2910s\n",
      "\titers: 200, epoch: 9 | loss: 0.0808199\n",
      "\tspeed: 0.0433s/iter; left time: 107.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 224 | Train Loss: 0.0787848 Vali Loss: 0.0926485 Test Loss: 0.0931043\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0736704\n",
      "\tspeed: 0.0754s/iter; left time: 178.4021s\n",
      "\titers: 200, epoch: 10 | loss: 0.0733153\n",
      "\tspeed: 0.0433s/iter; left time: 98.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.0766879 Vali Loss: 0.0925296 Test Loss: 0.0935938\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0791207\n",
      "\tspeed: 0.0752s/iter; left time: 160.9502s\n",
      "\titers: 200, epoch: 11 | loss: 0.0727043\n",
      "\tspeed: 0.0437s/iter; left time: 89.2854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0754194 Vali Loss: 0.0910019 Test Loss: 0.0932023\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0734317\n",
      "\tspeed: 0.0763s/iter; left time: 146.2188s\n",
      "\titers: 200, epoch: 12 | loss: 0.0696118\n",
      "\tspeed: 0.0434s/iter; left time: 78.8817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 224 | Train Loss: 0.0744974 Vali Loss: 0.0937302 Test Loss: 0.0951772\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021224495023489, rmse:0.1456862837076187, mae:0.09386950731277466, rse:0.5141470432281494\n",
      "Intermediate time for DE and pred_len 24: 00h:05m:53.33s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2730873\n",
      "\tspeed: 0.0652s/iter; left time: 285.8303s\n",
      "\titers: 200, epoch: 1 | loss: 0.2538673\n",
      "\tspeed: 0.0434s/iter; left time: 185.6018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.21s\n",
      "Steps: 224 | Train Loss: 0.2809971 Vali Loss: 0.2470283 Test Loss: 0.2500944\n",
      "Validation loss decreased (inf --> 0.247028).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1551152\n",
      "\tspeed: 0.0787s/iter; left time: 327.0738s\n",
      "\titers: 200, epoch: 2 | loss: 0.1271153\n",
      "\tspeed: 0.0462s/iter; left time: 187.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.18s\n",
      "Steps: 224 | Train Loss: 0.1593509 Vali Loss: 0.1270712 Test Loss: 0.1395510\n",
      "Validation loss decreased (0.247028 --> 0.127071).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1136904\n",
      "\tspeed: 0.0841s/iter; left time: 330.8180s\n",
      "\titers: 200, epoch: 3 | loss: 0.1113406\n",
      "\tspeed: 0.0435s/iter; left time: 166.7859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.1165348 Vali Loss: 0.1245620 Test Loss: 0.1349613\n",
      "Validation loss decreased (0.127071 --> 0.124562).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1037097\n",
      "\tspeed: 0.0795s/iter; left time: 294.9638s\n",
      "\titers: 200, epoch: 4 | loss: 0.1054394\n",
      "\tspeed: 0.0436s/iter; left time: 157.4971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.1092363 Vali Loss: 0.1226258 Test Loss: 0.1358402\n",
      "Validation loss decreased (0.124562 --> 0.122626).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1024584\n",
      "\tspeed: 0.0818s/iter; left time: 284.9739s\n",
      "\titers: 200, epoch: 5 | loss: 0.1020275\n",
      "\tspeed: 0.0437s/iter; left time: 147.9488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.1061287 Vali Loss: 0.1251618 Test Loss: 0.1321045\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0974805\n",
      "\tspeed: 0.0778s/iter; left time: 253.7090s\n",
      "\titers: 200, epoch: 6 | loss: 0.0992048\n",
      "\tspeed: 0.0437s/iter; left time: 138.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.1002767 Vali Loss: 0.1372568 Test Loss: 0.1412834\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1008290\n",
      "\tspeed: 0.0783s/iter; left time: 237.6502s\n",
      "\titers: 200, epoch: 7 | loss: 0.0886084\n",
      "\tspeed: 0.0438s/iter; left time: 128.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 224 | Train Loss: 0.0975853 Vali Loss: 0.1345281 Test Loss: 0.1409604\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1032455\n",
      "\tspeed: 0.0789s/iter; left time: 221.8269s\n",
      "\titers: 200, epoch: 8 | loss: 0.0975695\n",
      "\tspeed: 0.0437s/iter; left time: 118.5722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 224 | Train Loss: 0.0983386 Vali Loss: 0.1322534 Test Loss: 0.1427822\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0961038\n",
      "\tspeed: 0.0775s/iter; left time: 200.6767s\n",
      "\titers: 200, epoch: 9 | loss: 0.0868186\n",
      "\tspeed: 0.0438s/iter; left time: 108.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0925883 Vali Loss: 0.1385784 Test Loss: 0.1417706\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03961241617798805, rmse:0.19902868568897247, mae:0.13584020733833313, rse:0.7048007845878601\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2853234\n",
      "\tspeed: 0.0453s/iter; left time: 198.5118s\n",
      "\titers: 200, epoch: 1 | loss: 0.2567188\n",
      "\tspeed: 0.0437s/iter; left time: 186.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.2827791 Vali Loss: 0.2489964 Test Loss: 0.2515210\n",
      "Validation loss decreased (inf --> 0.248996).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1529949\n",
      "\tspeed: 0.0835s/iter; left time: 347.0798s\n",
      "\titers: 200, epoch: 2 | loss: 0.1307123\n",
      "\tspeed: 0.0438s/iter; left time: 177.5324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.1600343 Vali Loss: 0.1260020 Test Loss: 0.1377422\n",
      "Validation loss decreased (0.248996 --> 0.126002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1094839\n",
      "\tspeed: 0.0839s/iter; left time: 330.0524s\n",
      "\titers: 200, epoch: 3 | loss: 0.1172766\n",
      "\tspeed: 0.0438s/iter; left time: 167.9243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.45s\n",
      "Steps: 224 | Train Loss: 0.1164512 Vali Loss: 0.1248183 Test Loss: 0.1410902\n",
      "Validation loss decreased (0.126002 --> 0.124818).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1164681\n",
      "\tspeed: 0.0813s/iter; left time: 301.7182s\n",
      "\titers: 200, epoch: 4 | loss: 0.1105429\n",
      "\tspeed: 0.0437s/iter; left time: 157.8894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 224 | Train Loss: 0.1110355 Vali Loss: 0.1224463 Test Loss: 0.1335366\n",
      "Validation loss decreased (0.124818 --> 0.122446).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1044262\n",
      "\tspeed: 0.0808s/iter; left time: 281.6522s\n",
      "\titers: 200, epoch: 5 | loss: 0.1096567\n",
      "\tspeed: 0.0438s/iter; left time: 148.1881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.1068748 Vali Loss: 0.1256038 Test Loss: 0.1346750\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0989933\n",
      "\tspeed: 0.0784s/iter; left time: 255.7786s\n",
      "\titers: 200, epoch: 6 | loss: 0.0999053\n",
      "\tspeed: 0.0438s/iter; left time: 138.4036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.1014248 Vali Loss: 0.1265093 Test Loss: 0.1341052\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0974638\n",
      "\tspeed: 0.0784s/iter; left time: 238.1001s\n",
      "\titers: 200, epoch: 7 | loss: 0.0934854\n",
      "\tspeed: 0.0438s/iter; left time: 128.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0968336 Vali Loss: 0.1306096 Test Loss: 0.1391942\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0949293\n",
      "\tspeed: 0.0794s/iter; left time: 223.4391s\n",
      "\titers: 200, epoch: 8 | loss: 0.0910449\n",
      "\tspeed: 0.0438s/iter; left time: 118.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.09s\n",
      "Steps: 224 | Train Loss: 0.0924517 Vali Loss: 0.1325007 Test Loss: 0.1434555\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0952373\n",
      "\tspeed: 0.0779s/iter; left time: 201.6728s\n",
      "\titers: 200, epoch: 9 | loss: 0.0926787\n",
      "\tspeed: 0.0438s/iter; left time: 109.0497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0911426 Vali Loss: 0.1361132 Test Loss: 0.1456762\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03638024628162384, rmse:0.1907360702753067, mae:0.13353656232357025, rse:0.675434947013855\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:54.23s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2853565\n",
      "\tspeed: 0.0642s/iter; left time: 280.0647s\n",
      "\titers: 200, epoch: 1 | loss: 0.2559099\n",
      "\tspeed: 0.0435s/iter; left time: 185.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.12s\n",
      "Steps: 223 | Train Loss: 0.2821086 Vali Loss: 0.2474755 Test Loss: 0.2521143\n",
      "Validation loss decreased (inf --> 0.247475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1499281\n",
      "\tspeed: 0.0801s/iter; left time: 331.5607s\n",
      "\titers: 200, epoch: 2 | loss: 0.1303470\n",
      "\tspeed: 0.0437s/iter; left time: 176.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.1604536 Vali Loss: 0.1277511 Test Loss: 0.1454333\n",
      "Validation loss decreased (0.247475 --> 0.127751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1163019\n",
      "\tspeed: 0.0797s/iter; left time: 311.8527s\n",
      "\titers: 200, epoch: 3 | loss: 0.1183457\n",
      "\tspeed: 0.0436s/iter; left time: 166.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 223 | Train Loss: 0.1199755 Vali Loss: 0.1310069 Test Loss: 0.1587249\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1110048\n",
      "\tspeed: 0.0777s/iter; left time: 286.8470s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097203\n",
      "\tspeed: 0.0435s/iter; left time: 156.4100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.1118111 Vali Loss: 0.1323642 Test Loss: 0.1410458\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1119740\n",
      "\tspeed: 0.0765s/iter; left time: 265.5214s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012542\n",
      "\tspeed: 0.0436s/iter; left time: 147.0447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 223 | Train Loss: 0.1104220 Vali Loss: 0.1292856 Test Loss: 0.1460954\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0990335\n",
      "\tspeed: 0.0773s/iter; left time: 250.8421s\n",
      "\titers: 200, epoch: 6 | loss: 0.1047234\n",
      "\tspeed: 0.0437s/iter; left time: 137.4215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.1025609 Vali Loss: 0.1345252 Test Loss: 0.1477569\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1073229\n",
      "\tspeed: 0.0768s/iter; left time: 232.1747s\n",
      "\titers: 200, epoch: 7 | loss: 0.1006755\n",
      "\tspeed: 0.0437s/iter; left time: 127.6570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 223 | Train Loss: 0.0989095 Vali Loss: 0.1364546 Test Loss: 0.1504117\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0431598499417305, rmse:0.20774948596954346, mae:0.14543332159519196, rse:0.7358654141426086\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2833874\n",
      "\tspeed: 0.0459s/iter; left time: 200.1507s\n",
      "\titers: 200, epoch: 1 | loss: 0.2553921\n",
      "\tspeed: 0.0435s/iter; left time: 185.4057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.2825317 Vali Loss: 0.2488845 Test Loss: 0.2522277\n",
      "Validation loss decreased (inf --> 0.248884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1488476\n",
      "\tspeed: 0.0799s/iter; left time: 330.7596s\n",
      "\titers: 200, epoch: 2 | loss: 0.1307713\n",
      "\tspeed: 0.0436s/iter; left time: 175.9102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 223 | Train Loss: 0.1593443 Vali Loss: 0.1286614 Test Loss: 0.1465336\n",
      "Validation loss decreased (0.248884 --> 0.128661).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1256443\n",
      "\tspeed: 0.0814s/iter; left time: 318.8384s\n",
      "\titers: 200, epoch: 3 | loss: 0.1168443\n",
      "\tspeed: 0.0437s/iter; left time: 166.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 223 | Train Loss: 0.1225479 Vali Loss: 0.1280301 Test Loss: 0.1479301\n",
      "Validation loss decreased (0.128661 --> 0.128030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1124252\n",
      "\tspeed: 0.0804s/iter; left time: 296.9555s\n",
      "\titers: 200, epoch: 4 | loss: 0.1114279\n",
      "\tspeed: 0.0437s/iter; left time: 157.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.1123386 Vali Loss: 0.1278808 Test Loss: 0.1472634\n",
      "Validation loss decreased (0.128030 --> 0.127881).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1132831\n",
      "\tspeed: 0.0823s/iter; left time: 285.4171s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008963\n",
      "\tspeed: 0.0442s/iter; left time: 148.9521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 223 | Train Loss: 0.1083648 Vali Loss: 0.1295516 Test Loss: 0.1517673\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0999050\n",
      "\tspeed: 0.0780s/iter; left time: 253.1828s\n",
      "\titers: 200, epoch: 6 | loss: 0.1013834\n",
      "\tspeed: 0.0437s/iter; left time: 137.4065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 223 | Train Loss: 0.1028882 Vali Loss: 0.1321101 Test Loss: 0.1491762\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0943886\n",
      "\tspeed: 0.0775s/iter; left time: 234.4007s\n",
      "\titers: 200, epoch: 7 | loss: 0.1018143\n",
      "\tspeed: 0.0437s/iter; left time: 127.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 223 | Train Loss: 0.0987547 Vali Loss: 0.1341385 Test Loss: 0.1451681\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1030471\n",
      "\tspeed: 0.0779s/iter; left time: 218.0865s\n",
      "\titers: 200, epoch: 8 | loss: 0.0923919\n",
      "\tspeed: 0.0438s/iter; left time: 118.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0966735 Vali Loss: 0.1315038 Test Loss: 0.1471234\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0929826\n",
      "\tspeed: 0.0790s/iter; left time: 203.5935s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878524\n",
      "\tspeed: 0.0439s/iter; left time: 108.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.0921295 Vali Loss: 0.1339946 Test Loss: 0.1444971\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.047324687242507935, rmse:0.2175423800945282, mae:0.1472633183002472, rse:0.7705525755882263\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:30.07s\n",
      "Intermediate time for DE: 00h:13m:17.62s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2952728\n",
      "\tspeed: 0.0596s/iter; left time: 261.0675s\n",
      "\titers: 200, epoch: 1 | loss: 0.2747920\n",
      "\tspeed: 0.0431s/iter; left time: 184.6133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.2991270 Vali Loss: 0.2664879 Test Loss: 0.2850167\n",
      "Validation loss decreased (inf --> 0.266488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1333511\n",
      "\tspeed: 0.0785s/iter; left time: 326.5055s\n",
      "\titers: 200, epoch: 2 | loss: 0.1149944\n",
      "\tspeed: 0.0432s/iter; left time: 175.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.1523953 Vali Loss: 0.1058776 Test Loss: 0.1183221\n",
      "Validation loss decreased (0.266488 --> 0.105878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0949538\n",
      "\tspeed: 0.0912s/iter; left time: 358.7167s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011911\n",
      "\tspeed: 0.0432s/iter; left time: 165.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0974832 Vali Loss: 0.0976792 Test Loss: 0.1104174\n",
      "Validation loss decreased (0.105878 --> 0.097679).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944573\n",
      "\tspeed: 0.0914s/iter; left time: 339.0688s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819249\n",
      "\tspeed: 0.0439s/iter; left time: 158.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.0911944 Vali Loss: 0.0962131 Test Loss: 0.1094936\n",
      "Validation loss decreased (0.097679 --> 0.096213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0942272\n",
      "\tspeed: 0.0783s/iter; left time: 272.8714s\n",
      "\titers: 200, epoch: 5 | loss: 0.0873916\n",
      "\tspeed: 0.0432s/iter; left time: 146.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 224 | Train Loss: 0.0882437 Vali Loss: 0.0966588 Test Loss: 0.1123214\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0960606\n",
      "\tspeed: 0.0749s/iter; left time: 244.3390s\n",
      "\titers: 200, epoch: 6 | loss: 0.0825499\n",
      "\tspeed: 0.0433s/iter; left time: 136.7274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.84s\n",
      "Steps: 224 | Train Loss: 0.0865048 Vali Loss: 0.0942511 Test Loss: 0.1080337\n",
      "Validation loss decreased (0.096213 --> 0.094251).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764552\n",
      "\tspeed: 0.0837s/iter; left time: 254.2101s\n",
      "\titers: 200, epoch: 7 | loss: 0.0814195\n",
      "\tspeed: 0.0432s/iter; left time: 126.9880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.84s\n",
      "Steps: 224 | Train Loss: 0.0849666 Vali Loss: 0.0919900 Test Loss: 0.1072875\n",
      "Validation loss decreased (0.094251 --> 0.091990).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0783165\n",
      "\tspeed: 0.1065s/iter; left time: 299.6050s\n",
      "\titers: 200, epoch: 8 | loss: 0.0859738\n",
      "\tspeed: 0.0432s/iter; left time: 117.1534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0828471 Vali Loss: 0.0920106 Test Loss: 0.1067988\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0819397\n",
      "\tspeed: 0.0757s/iter; left time: 195.8967s\n",
      "\titers: 200, epoch: 9 | loss: 0.0822372\n",
      "\tspeed: 0.0431s/iter; left time: 107.3325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0803673 Vali Loss: 0.0913322 Test Loss: 0.1067272\n",
      "Validation loss decreased (0.091990 --> 0.091332).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0788942\n",
      "\tspeed: 0.0800s/iter; left time: 189.1188s\n",
      "\titers: 200, epoch: 10 | loss: 0.0848821\n",
      "\tspeed: 0.0433s/iter; left time: 98.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0793486 Vali Loss: 0.0904661 Test Loss: 0.1065233\n",
      "Validation loss decreased (0.091332 --> 0.090466).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764371\n",
      "\tspeed: 0.0802s/iter; left time: 171.6715s\n",
      "\titers: 200, epoch: 11 | loss: 0.0775877\n",
      "\tspeed: 0.0442s/iter; left time: 90.2069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0781930 Vali Loss: 0.0904146 Test Loss: 0.1065323\n",
      "Validation loss decreased (0.090466 --> 0.090415).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0736814\n",
      "\tspeed: 0.0863s/iter; left time: 165.3430s\n",
      "\titers: 200, epoch: 12 | loss: 0.0703000\n",
      "\tspeed: 0.0433s/iter; left time: 78.6303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0778499 Vali Loss: 0.0906770 Test Loss: 0.1092151\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0796573\n",
      "\tspeed: 0.0763s/iter; left time: 129.0933s\n",
      "\titers: 200, epoch: 13 | loss: 0.0737792\n",
      "\tspeed: 0.0433s/iter; left time: 68.9101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0778502 Vali Loss: 0.0900919 Test Loss: 0.1084580\n",
      "Validation loss decreased (0.090415 --> 0.090092).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0770185\n",
      "\tspeed: 0.0836s/iter; left time: 122.8159s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772571\n",
      "\tspeed: 0.0432s/iter; left time: 59.2087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0770753 Vali Loss: 0.0913468 Test Loss: 0.1096559\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0776991\n",
      "\tspeed: 0.0760s/iter; left time: 94.6060s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837207\n",
      "\tspeed: 0.0433s/iter; left time: 49.5434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.0770132 Vali Loss: 0.0909589 Test Loss: 0.1092222\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779530\n",
      "\tspeed: 0.0763s/iter; left time: 77.8610s\n",
      "\titers: 200, epoch: 16 | loss: 0.0778276\n",
      "\tspeed: 0.0432s/iter; left time: 39.8011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0756235 Vali Loss: 0.0910666 Test Loss: 0.1092218\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0839102\n",
      "\tspeed: 0.0765s/iter; left time: 60.9845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0753359\n",
      "\tspeed: 0.0432s/iter; left time: 30.0980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0748436 Vali Loss: 0.0907682 Test Loss: 0.1099176\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0781862\n",
      "\tspeed: 0.0772s/iter; left time: 44.2349s\n",
      "\titers: 200, epoch: 18 | loss: 0.0769275\n",
      "\tspeed: 0.0433s/iter; left time: 20.4934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0747008 Vali Loss: 0.0910484 Test Loss: 0.1105967\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028406532481312752, rmse:0.16854237020015717, mae:0.10845804214477539, rse:0.5814234614372253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2958814\n",
      "\tspeed: 0.0450s/iter; left time: 196.9268s\n",
      "\titers: 200, epoch: 1 | loss: 0.2927144\n",
      "\tspeed: 0.0437s/iter; left time: 186.8701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.3021490 Vali Loss: 0.2713902 Test Loss: 0.2867366\n",
      "Validation loss decreased (inf --> 0.271390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1379587\n",
      "\tspeed: 0.0985s/iter; left time: 409.2933s\n",
      "\titers: 200, epoch: 2 | loss: 0.1080436\n",
      "\tspeed: 0.0432s/iter; left time: 175.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.1526126 Vali Loss: 0.1071798 Test Loss: 0.1220685\n",
      "Validation loss decreased (0.271390 --> 0.107180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0941868\n",
      "\tspeed: 0.0868s/iter; left time: 341.5310s\n",
      "\titers: 200, epoch: 3 | loss: 0.0890978\n",
      "\tspeed: 0.0431s/iter; left time: 165.0610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0958368 Vali Loss: 0.0992877 Test Loss: 0.1063506\n",
      "Validation loss decreased (0.107180 --> 0.099288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0905196\n",
      "\tspeed: 0.0823s/iter; left time: 305.2160s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888255\n",
      "\tspeed: 0.0432s/iter; left time: 155.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 224 | Train Loss: 0.0907252 Vali Loss: 0.0967359 Test Loss: 0.1068533\n",
      "Validation loss decreased (0.099288 --> 0.096736).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0849316\n",
      "\tspeed: 0.0818s/iter; left time: 285.1464s\n",
      "\titers: 200, epoch: 5 | loss: 0.0890873\n",
      "\tspeed: 0.0431s/iter; left time: 145.9762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 224 | Train Loss: 0.0876783 Vali Loss: 0.0936576 Test Loss: 0.1322193\n",
      "Validation loss decreased (0.096736 --> 0.093658).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897238\n",
      "\tspeed: 0.0828s/iter; left time: 269.9474s\n",
      "\titers: 200, epoch: 6 | loss: 0.0836014\n",
      "\tspeed: 0.0431s/iter; left time: 136.3918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.0856275 Vali Loss: 0.0928177 Test Loss: 0.1055312\n",
      "Validation loss decreased (0.093658 --> 0.092818).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0893011\n",
      "\tspeed: 0.0941s/iter; left time: 285.8250s\n",
      "\titers: 200, epoch: 7 | loss: 0.0779938\n",
      "\tspeed: 0.0439s/iter; left time: 129.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.0835752 Vali Loss: 0.0916757 Test Loss: 0.1049846\n",
      "Validation loss decreased (0.092818 --> 0.091676).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0858822\n",
      "\tspeed: 0.0987s/iter; left time: 277.7614s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751795\n",
      "\tspeed: 0.0431s/iter; left time: 116.9003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0807432 Vali Loss: 0.0921146 Test Loss: 0.1048104\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0778011\n",
      "\tspeed: 0.0756s/iter; left time: 195.7713s\n",
      "\titers: 200, epoch: 9 | loss: 0.0795755\n",
      "\tspeed: 0.0431s/iter; left time: 107.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0800091 Vali Loss: 0.0905733 Test Loss: 0.1036594\n",
      "Validation loss decreased (0.091676 --> 0.090573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0780049\n",
      "\tspeed: 0.0887s/iter; left time: 209.7440s\n",
      "\titers: 200, epoch: 10 | loss: 0.0741170\n",
      "\tspeed: 0.0431s/iter; left time: 97.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.0785737 Vali Loss: 0.0910328 Test Loss: 0.1060888\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0794722\n",
      "\tspeed: 0.0761s/iter; left time: 162.9796s\n",
      "\titers: 200, epoch: 11 | loss: 0.0739447\n",
      "\tspeed: 0.0432s/iter; left time: 88.1449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0801226 Vali Loss: 0.0908452 Test Loss: 0.1051785\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710330\n",
      "\tspeed: 0.0756s/iter; left time: 144.8457s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799103\n",
      "\tspeed: 0.0433s/iter; left time: 78.6598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0776090 Vali Loss: 0.0912056 Test Loss: 0.1060131\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0733333\n",
      "\tspeed: 0.0777s/iter; left time: 131.5626s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782616\n",
      "\tspeed: 0.0433s/iter; left time: 69.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0771852 Vali Loss: 0.0907077 Test Loss: 0.1052774\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0735675\n",
      "\tspeed: 0.0764s/iter; left time: 112.2018s\n",
      "\titers: 200, epoch: 14 | loss: 0.0747638\n",
      "\tspeed: 0.0437s/iter; left time: 59.8227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0762925 Vali Loss: 0.0911823 Test Loss: 0.1053580\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025833044201135635, rmse:0.1607266068458557, mae:0.10365934669971466, rse:0.5544612407684326\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:58.33s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3005074\n",
      "\tspeed: 0.0604s/iter; left time: 264.5442s\n",
      "\titers: 200, epoch: 1 | loss: 0.2781322\n",
      "\tspeed: 0.0433s/iter; left time: 185.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.14s\n",
      "Steps: 224 | Train Loss: 0.3050074 Vali Loss: 0.2794930 Test Loss: 0.2981934\n",
      "Validation loss decreased (inf --> 0.279493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1449333\n",
      "\tspeed: 0.1214s/iter; left time: 504.7039s\n",
      "\titers: 200, epoch: 2 | loss: 0.1182448\n",
      "\tspeed: 0.0433s/iter; left time: 175.5550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.1586646 Vali Loss: 0.1313744 Test Loss: 0.1651722\n",
      "Validation loss decreased (0.279493 --> 0.131374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1207419\n",
      "\tspeed: 0.0847s/iter; left time: 333.2309s\n",
      "\titers: 200, epoch: 3 | loss: 0.1175503\n",
      "\tspeed: 0.0441s/iter; left time: 169.1135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.1176094 Vali Loss: 0.1254666 Test Loss: 0.1616030\n",
      "Validation loss decreased (0.131374 --> 0.125467).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1194554\n",
      "\tspeed: 0.0912s/iter; left time: 338.1571s\n",
      "\titers: 200, epoch: 4 | loss: 0.1182918\n",
      "\tspeed: 0.0439s/iter; left time: 158.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.1150991 Vali Loss: 0.1259882 Test Loss: 0.1583312\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1148795\n",
      "\tspeed: 0.0772s/iter; left time: 268.9275s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008998\n",
      "\tspeed: 0.0434s/iter; left time: 146.9179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.1083126 Vali Loss: 0.1201831 Test Loss: 0.1510535\n",
      "Validation loss decreased (0.125467 --> 0.120183).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1071014\n",
      "\tspeed: 0.0819s/iter; left time: 266.9990s\n",
      "\titers: 200, epoch: 6 | loss: 0.1053732\n",
      "\tspeed: 0.0436s/iter; left time: 137.6746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.1060991 Vali Loss: 0.1225376 Test Loss: 0.1485327\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1031661\n",
      "\tspeed: 0.0773s/iter; left time: 234.6898s\n",
      "\titers: 200, epoch: 7 | loss: 0.0985593\n",
      "\tspeed: 0.0434s/iter; left time: 127.5873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.1025775 Vali Loss: 0.1234514 Test Loss: 0.1528421\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0963565\n",
      "\tspeed: 0.0779s/iter; left time: 219.0745s\n",
      "\titers: 200, epoch: 8 | loss: 0.0939079\n",
      "\tspeed: 0.0442s/iter; left time: 120.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0989484 Vali Loss: 0.1273047 Test Loss: 0.1529603\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1067882\n",
      "\tspeed: 0.0813s/iter; left time: 210.5233s\n",
      "\titers: 200, epoch: 9 | loss: 0.0947769\n",
      "\tspeed: 0.0441s/iter; left time: 109.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0969405 Vali Loss: 0.1252949 Test Loss: 0.1608775\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0919494\n",
      "\tspeed: 0.0788s/iter; left time: 186.3383s\n",
      "\titers: 200, epoch: 10 | loss: 0.0917634\n",
      "\tspeed: 0.0436s/iter; left time: 98.7016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 224 | Train Loss: 0.0951933 Vali Loss: 0.1281306 Test Loss: 0.1897068\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.048782672733068466, rmse:0.22086799144744873, mae:0.1510535031557083, rse:0.7637923359870911\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3059277\n",
      "\tspeed: 0.0461s/iter; left time: 202.0602s\n",
      "\titers: 200, epoch: 1 | loss: 0.2818570\n",
      "\tspeed: 0.0434s/iter; left time: 185.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.3046419 Vali Loss: 0.2747135 Test Loss: 0.2947595\n",
      "Validation loss decreased (inf --> 0.274713).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1419084\n",
      "\tspeed: 0.0827s/iter; left time: 343.9784s\n",
      "\titers: 200, epoch: 2 | loss: 0.1220847\n",
      "\tspeed: 0.0442s/iter; left time: 179.3379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.1558279 Vali Loss: 0.1298376 Test Loss: 0.1533051\n",
      "Validation loss decreased (0.274713 --> 0.129838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1121801\n",
      "\tspeed: 0.0884s/iter; left time: 347.8601s\n",
      "\titers: 200, epoch: 3 | loss: 0.1160159\n",
      "\tspeed: 0.0435s/iter; left time: 166.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 224 | Train Loss: 0.1170699 Vali Loss: 0.1227396 Test Loss: 0.1526552\n",
      "Validation loss decreased (0.129838 --> 0.122740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115150\n",
      "\tspeed: 0.0824s/iter; left time: 305.8012s\n",
      "\titers: 200, epoch: 4 | loss: 0.1010807\n",
      "\tspeed: 0.0434s/iter; left time: 156.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.1100550 Vali Loss: 0.1264605 Test Loss: 0.1446267\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1102801\n",
      "\tspeed: 0.0785s/iter; left time: 273.4508s\n",
      "\titers: 200, epoch: 5 | loss: 0.0989220\n",
      "\tspeed: 0.0436s/iter; left time: 147.4778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.1058444 Vali Loss: 0.1229618 Test Loss: 0.1476580\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1093562\n",
      "\tspeed: 0.0788s/iter; left time: 256.8106s\n",
      "\titers: 200, epoch: 6 | loss: 0.0981288\n",
      "\tspeed: 0.0435s/iter; left time: 137.3533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.1048303 Vali Loss: 0.1257552 Test Loss: 0.1480152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1041544\n",
      "\tspeed: 0.0795s/iter; left time: 241.5271s\n",
      "\titers: 200, epoch: 7 | loss: 0.1086753\n",
      "\tspeed: 0.0442s/iter; left time: 129.8255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.1018840 Vali Loss: 0.1255411 Test Loss: 0.1498836\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1006141\n",
      "\tspeed: 0.0793s/iter; left time: 223.0391s\n",
      "\titers: 200, epoch: 8 | loss: 0.0971707\n",
      "\tspeed: 0.0436s/iter; left time: 118.2193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0976718 Vali Loss: 0.1256114 Test Loss: 0.1507998\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05146760866045952, rmse:0.2268647402524948, mae:0.152655228972435, rse:0.7845298647880554\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:03.84s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3099446\n",
      "\tspeed: 0.0602s/iter; left time: 262.3838s\n",
      "\titers: 200, epoch: 1 | loss: 0.2827969\n",
      "\tspeed: 0.0435s/iter; left time: 185.5411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.12s\n",
      "Steps: 223 | Train Loss: 0.3056327 Vali Loss: 0.2804452 Test Loss: 0.2980855\n",
      "Validation loss decreased (inf --> 0.280445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1457663\n",
      "\tspeed: 0.0825s/iter; left time: 341.3359s\n",
      "\titers: 200, epoch: 2 | loss: 0.1287655\n",
      "\tspeed: 0.0448s/iter; left time: 180.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.1598732 Vali Loss: 0.1436398 Test Loss: 0.1867228\n",
      "Validation loss decreased (0.280445 --> 0.143640).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1257603\n",
      "\tspeed: 0.1006s/iter; left time: 394.0148s\n",
      "\titers: 200, epoch: 3 | loss: 0.1229001\n",
      "\tspeed: 0.0437s/iter; left time: 166.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 223 | Train Loss: 0.1222888 Vali Loss: 0.1344821 Test Loss: 0.1599541\n",
      "Validation loss decreased (0.143640 --> 0.134482).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1168864\n",
      "\tspeed: 0.0854s/iter; left time: 315.2610s\n",
      "\titers: 200, epoch: 4 | loss: 0.1159761\n",
      "\tspeed: 0.0440s/iter; left time: 158.0296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.1173413 Vali Loss: 0.1285489 Test Loss: 0.1617913\n",
      "Validation loss decreased (0.134482 --> 0.128549).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1101996\n",
      "\tspeed: 0.0826s/iter; left time: 286.4945s\n",
      "\titers: 200, epoch: 5 | loss: 0.1119654\n",
      "\tspeed: 0.0440s/iter; left time: 148.2012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 223 | Train Loss: 0.1120714 Vali Loss: 0.1289616 Test Loss: 0.1516355\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1028626\n",
      "\tspeed: 0.0792s/iter; left time: 257.0971s\n",
      "\titers: 200, epoch: 6 | loss: 0.1103455\n",
      "\tspeed: 0.0441s/iter; left time: 138.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 223 | Train Loss: 0.1099370 Vali Loss: 0.1242144 Test Loss: 0.1516560\n",
      "Validation loss decreased (0.128549 --> 0.124214).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1124968\n",
      "\tspeed: 0.0869s/iter; left time: 262.6471s\n",
      "\titers: 200, epoch: 7 | loss: 0.1099664\n",
      "\tspeed: 0.0441s/iter; left time: 128.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.09s\n",
      "Steps: 223 | Train Loss: 0.1062896 Vali Loss: 0.1280807 Test Loss: 0.1544155\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1093859\n",
      "\tspeed: 0.0774s/iter; left time: 216.5993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0992466\n",
      "\tspeed: 0.0439s/iter; left time: 118.6344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.1034258 Vali Loss: 0.1240586 Test Loss: 0.1576906\n",
      "Validation loss decreased (0.124214 --> 0.124059).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1012699\n",
      "\tspeed: 0.0805s/iter; left time: 207.4794s\n",
      "\titers: 200, epoch: 9 | loss: 0.1015645\n",
      "\tspeed: 0.0440s/iter; left time: 108.9277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 223 | Train Loss: 0.1019081 Vali Loss: 0.1246566 Test Loss: 0.1628513\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0973849\n",
      "\tspeed: 0.0780s/iter; left time: 183.5728s\n",
      "\titers: 200, epoch: 10 | loss: 0.0999147\n",
      "\tspeed: 0.0440s/iter; left time: 99.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.0990177 Vali Loss: 0.1252363 Test Loss: 0.1603817\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0967646\n",
      "\tspeed: 0.0782s/iter; left time: 166.6674s\n",
      "\titers: 200, epoch: 11 | loss: 0.0990560\n",
      "\tspeed: 0.0441s/iter; left time: 89.5649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 223 | Train Loss: 0.0957688 Vali Loss: 0.1255099 Test Loss: 0.1658352\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0928999\n",
      "\tspeed: 0.0787s/iter; left time: 150.1244s\n",
      "\titers: 200, epoch: 12 | loss: 0.0931583\n",
      "\tspeed: 0.0440s/iter; left time: 79.4825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.0940927 Vali Loss: 0.1298321 Test Loss: 0.1676592\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0929952\n",
      "\tspeed: 0.0779s/iter; left time: 131.2135s\n",
      "\titers: 200, epoch: 13 | loss: 0.0902641\n",
      "\tspeed: 0.0439s/iter; left time: 69.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.0912617 Vali Loss: 0.1266622 Test Loss: 0.1671925\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05669492483139038, rmse:0.23810696601867676, mae:0.1576906442642212, rse:0.8255510330200195\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3016178\n",
      "\tspeed: 0.0463s/iter; left time: 201.9846s\n",
      "\titers: 200, epoch: 1 | loss: 0.2875957\n",
      "\tspeed: 0.0440s/iter; left time: 187.5238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.09s\n",
      "Steps: 223 | Train Loss: 0.3062646 Vali Loss: 0.2825918 Test Loss: 0.2992807\n",
      "Validation loss decreased (inf --> 0.282592).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482316\n",
      "\tspeed: 0.0814s/iter; left time: 336.8346s\n",
      "\titers: 200, epoch: 2 | loss: 0.1253926\n",
      "\tspeed: 0.0440s/iter; left time: 177.6235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 223 | Train Loss: 0.1592309 Vali Loss: 0.1312893 Test Loss: 0.1704609\n",
      "Validation loss decreased (0.282592 --> 0.131289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1256601\n",
      "\tspeed: 0.0887s/iter; left time: 347.1133s\n",
      "\titers: 200, epoch: 3 | loss: 0.1252660\n",
      "\tspeed: 0.0439s/iter; left time: 167.6372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.45s\n",
      "Steps: 223 | Train Loss: 0.1264098 Vali Loss: 0.1280755 Test Loss: 0.1628211\n",
      "Validation loss decreased (0.131289 --> 0.128075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1225498\n",
      "\tspeed: 0.0824s/iter; left time: 304.2260s\n",
      "\titers: 200, epoch: 4 | loss: 0.1167320\n",
      "\tspeed: 0.0438s/iter; left time: 157.4436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.1198024 Vali Loss: 0.1259580 Test Loss: 0.1527559\n",
      "Validation loss decreased (0.128075 --> 0.125958).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1066734\n",
      "\tspeed: 0.0817s/iter; left time: 283.3063s\n",
      "\titers: 200, epoch: 5 | loss: 0.1173575\n",
      "\tspeed: 0.0438s/iter; left time: 147.6704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 223 | Train Loss: 0.1134356 Vali Loss: 0.1243751 Test Loss: 0.1546929\n",
      "Validation loss decreased (0.125958 --> 0.124375).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114003\n",
      "\tspeed: 0.0814s/iter; left time: 264.3128s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048710\n",
      "\tspeed: 0.0437s/iter; left time: 137.5018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 223 | Train Loss: 0.1098652 Vali Loss: 0.1243997 Test Loss: 0.1520432\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072541\n",
      "\tspeed: 0.0781s/iter; left time: 235.9648s\n",
      "\titers: 200, epoch: 7 | loss: 0.1110060\n",
      "\tspeed: 0.0438s/iter; left time: 128.0828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 223 | Train Loss: 0.1086118 Vali Loss: 0.1262357 Test Loss: 0.1583461\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1079650\n",
      "\tspeed: 0.0782s/iter; left time: 218.9921s\n",
      "\titers: 200, epoch: 8 | loss: 0.1063423\n",
      "\tspeed: 0.0439s/iter; left time: 118.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.1063413 Vali Loss: 0.1262465 Test Loss: 0.1579049\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1017840\n",
      "\tspeed: 0.0783s/iter; left time: 201.7424s\n",
      "\titers: 200, epoch: 9 | loss: 0.1110077\n",
      "\tspeed: 0.0439s/iter; left time: 108.6262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.1033296 Vali Loss: 0.1282620 Test Loss: 0.1551146\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1025019\n",
      "\tspeed: 0.0787s/iter; left time: 185.3020s\n",
      "\titers: 200, epoch: 10 | loss: 0.0958419\n",
      "\tspeed: 0.0439s/iter; left time: 98.9886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 223 | Train Loss: 0.1018505 Vali Loss: 0.1295341 Test Loss: 0.1561655\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.051818374544382095, rmse:0.22763650119304657, mae:0.15469281375408173, rse:0.7892484068870544\n",
      "Intermediate time for GB and pred_len 168: 00h:04m:59.49s\n",
      "Intermediate time for GB: 00h:16m:01.66s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2784523\n",
      "\tspeed: 0.0433s/iter; left time: 189.7718s\n",
      "\titers: 200, epoch: 1 | loss: 0.2594245\n",
      "\tspeed: 0.0218s/iter; left time: 93.1873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.2816938 Vali Loss: 0.2119999 Test Loss: 0.2245511\n",
      "Validation loss decreased (inf --> 0.212000).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1664514\n",
      "\tspeed: 0.0438s/iter; left time: 181.9830s\n",
      "\titers: 200, epoch: 2 | loss: 0.1178160\n",
      "\tspeed: 0.0218s/iter; left time: 88.3915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.1663702 Vali Loss: 0.0881689 Test Loss: 0.0946264\n",
      "Validation loss decreased (0.212000 --> 0.088169).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0996790\n",
      "\tspeed: 0.0441s/iter; left time: 173.4357s\n",
      "\titers: 200, epoch: 3 | loss: 0.0907922\n",
      "\tspeed: 0.0218s/iter; left time: 83.5255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.1005311 Vali Loss: 0.0780944 Test Loss: 0.0890903\n",
      "Validation loss decreased (0.088169 --> 0.078094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0878856\n",
      "\tspeed: 0.0434s/iter; left time: 160.9080s\n",
      "\titers: 200, epoch: 4 | loss: 0.0810588\n",
      "\tspeed: 0.0219s/iter; left time: 78.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0861823 Vali Loss: 0.0694505 Test Loss: 0.0813895\n",
      "Validation loss decreased (0.078094 --> 0.069451).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0804923\n",
      "\tspeed: 0.0435s/iter; left time: 151.5916s\n",
      "\titers: 200, epoch: 5 | loss: 0.0732130\n",
      "\tspeed: 0.0218s/iter; left time: 73.9023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0756816 Vali Loss: 0.0687196 Test Loss: 0.1208841\n",
      "Validation loss decreased (0.069451 --> 0.068720).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0690319\n",
      "\tspeed: 0.0439s/iter; left time: 143.1571s\n",
      "\titers: 200, epoch: 6 | loss: 0.0774042\n",
      "\tspeed: 0.0219s/iter; left time: 69.2896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0746245 Vali Loss: 0.0643959 Test Loss: 0.1393897\n",
      "Validation loss decreased (0.068720 --> 0.064396).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0683768\n",
      "\tspeed: 0.0454s/iter; left time: 137.8521s\n",
      "\titers: 200, epoch: 7 | loss: 0.0651156\n",
      "\tspeed: 0.0221s/iter; left time: 65.0173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0707999 Vali Loss: 0.0642491 Test Loss: 0.0967521\n",
      "Validation loss decreased (0.064396 --> 0.064249).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0673953\n",
      "\tspeed: 0.0454s/iter; left time: 127.6219s\n",
      "\titers: 200, epoch: 8 | loss: 0.0673339\n",
      "\tspeed: 0.0222s/iter; left time: 60.3336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0687304 Vali Loss: 0.0617610 Test Loss: 0.0856199\n",
      "Validation loss decreased (0.064249 --> 0.061761).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0702689\n",
      "\tspeed: 0.0481s/iter; left time: 124.6395s\n",
      "\titers: 200, epoch: 9 | loss: 0.0651908\n",
      "\tspeed: 0.0221s/iter; left time: 55.1109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0673297 Vali Loss: 0.0635185 Test Loss: 0.0875772\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0717403\n",
      "\tspeed: 0.0460s/iter; left time: 108.8674s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699324\n",
      "\tspeed: 0.0221s/iter; left time: 50.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0667145 Vali Loss: 0.0606794 Test Loss: 0.0736973\n",
      "Validation loss decreased (0.061761 --> 0.060679).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0583581\n",
      "\tspeed: 0.0436s/iter; left time: 93.2482s\n",
      "\titers: 200, epoch: 11 | loss: 0.0600022\n",
      "\tspeed: 0.0218s/iter; left time: 44.5552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0656464 Vali Loss: 0.0616243 Test Loss: 0.0769117\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0673255\n",
      "\tspeed: 0.0425s/iter; left time: 81.5300s\n",
      "\titers: 200, epoch: 12 | loss: 0.0685402\n",
      "\tspeed: 0.0219s/iter; left time: 39.7278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0650388 Vali Loss: 0.0614751 Test Loss: 0.0838700\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0720293\n",
      "\tspeed: 0.0427s/iter; left time: 72.3572s\n",
      "\titers: 200, epoch: 13 | loss: 0.0620396\n",
      "\tspeed: 0.0219s/iter; left time: 34.8525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0643219 Vali Loss: 0.0593467 Test Loss: 0.0803183\n",
      "Validation loss decreased (0.060679 --> 0.059347).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0600013\n",
      "\tspeed: 0.0437s/iter; left time: 64.2161s\n",
      "\titers: 200, epoch: 14 | loss: 0.0607039\n",
      "\tspeed: 0.0219s/iter; left time: 29.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0637876 Vali Loss: 0.0590356 Test Loss: 0.0828475\n",
      "Validation loss decreased (0.059347 --> 0.059036).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0649631\n",
      "\tspeed: 0.0446s/iter; left time: 55.5450s\n",
      "\titers: 200, epoch: 15 | loss: 0.0662191\n",
      "\tspeed: 0.0219s/iter; left time: 25.0472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0628678 Vali Loss: 0.0589834 Test Loss: 0.0855842\n",
      "Validation loss decreased (0.059036 --> 0.058983).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0674409\n",
      "\tspeed: 0.0437s/iter; left time: 44.6589s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633558\n",
      "\tspeed: 0.0219s/iter; left time: 20.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0624128 Vali Loss: 0.0579030 Test Loss: 0.0786713\n",
      "Validation loss decreased (0.058983 --> 0.057903).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0599468\n",
      "\tspeed: 0.0436s/iter; left time: 34.7468s\n",
      "\titers: 200, epoch: 17 | loss: 0.0644323\n",
      "\tspeed: 0.0219s/iter; left time: 15.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0627192 Vali Loss: 0.0581710 Test Loss: 0.0928723\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0600523\n",
      "\tspeed: 0.0438s/iter; left time: 25.0810s\n",
      "\titers: 200, epoch: 18 | loss: 0.0653517\n",
      "\tspeed: 0.0223s/iter; left time: 10.5436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0620464 Vali Loss: 0.0585200 Test Loss: 0.1093179\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726355\n",
      "\tspeed: 0.0439s/iter; left time: 15.3279s\n",
      "\titers: 200, epoch: 19 | loss: 0.0686155\n",
      "\tspeed: 0.0223s/iter; left time: 5.5487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0619397 Vali Loss: 0.0582809 Test Loss: 0.0866418\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0578950\n",
      "\tspeed: 0.0435s/iter; left time: 5.4405s\n",
      "\titers: 200, epoch: 20 | loss: 0.0645387\n",
      "\tspeed: 0.0223s/iter; left time: 0.5566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0612354 Vali Loss: 0.0575388 Test Loss: 0.0808357\n",
      "Validation loss decreased (0.057903 --> 0.057539).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.016111280769109726, rmse:0.12693022191524506, mae:0.08083570748567581, rse:0.3735402822494507\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2716082\n",
      "\tspeed: 0.0236s/iter; left time: 103.4035s\n",
      "\titers: 200, epoch: 1 | loss: 0.2667636\n",
      "\tspeed: 0.0219s/iter; left time: 93.6792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.2827194 Vali Loss: 0.2138033 Test Loss: 0.2281318\n",
      "Validation loss decreased (inf --> 0.213803).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1667796\n",
      "\tspeed: 0.0437s/iter; left time: 181.6325s\n",
      "\titers: 200, epoch: 2 | loss: 0.1228404\n",
      "\tspeed: 0.0219s/iter; left time: 88.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.1702197 Vali Loss: 0.0895715 Test Loss: 0.0958070\n",
      "Validation loss decreased (0.213803 --> 0.089571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1014828\n",
      "\tspeed: 0.0430s/iter; left time: 169.1741s\n",
      "\titers: 200, epoch: 3 | loss: 0.1025054\n",
      "\tspeed: 0.0219s/iter; left time: 83.9039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.1031128 Vali Loss: 0.0784932 Test Loss: 0.0831520\n",
      "Validation loss decreased (0.089571 --> 0.078493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0883840\n",
      "\tspeed: 0.0432s/iter; left time: 160.3826s\n",
      "\titers: 200, epoch: 4 | loss: 0.0856889\n",
      "\tspeed: 0.0220s/iter; left time: 79.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0860826 Vali Loss: 0.0714873 Test Loss: 0.0785411\n",
      "Validation loss decreased (0.078493 --> 0.071487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0770675\n",
      "\tspeed: 0.0431s/iter; left time: 150.1780s\n",
      "\titers: 200, epoch: 5 | loss: 0.0738935\n",
      "\tspeed: 0.0219s/iter; left time: 74.0910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0769741 Vali Loss: 0.0669564 Test Loss: 0.1000176\n",
      "Validation loss decreased (0.071487 --> 0.066956).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0720208\n",
      "\tspeed: 0.0427s/iter; left time: 139.3538s\n",
      "\titers: 200, epoch: 6 | loss: 0.0720134\n",
      "\tspeed: 0.0219s/iter; left time: 69.2420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0744912 Vali Loss: 0.0656166 Test Loss: 0.0889697\n",
      "Validation loss decreased (0.066956 --> 0.065617).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0676624\n",
      "\tspeed: 0.0444s/iter; left time: 134.9249s\n",
      "\titers: 200, epoch: 7 | loss: 0.0692077\n",
      "\tspeed: 0.0221s/iter; left time: 65.0311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0713687 Vali Loss: 0.0653028 Test Loss: 0.0891432\n",
      "Validation loss decreased (0.065617 --> 0.065303).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0655541\n",
      "\tspeed: 0.0444s/iter; left time: 124.9160s\n",
      "\titers: 200, epoch: 8 | loss: 0.0690785\n",
      "\tspeed: 0.0221s/iter; left time: 59.9908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0714592 Vali Loss: 0.0639301 Test Loss: 0.0770096\n",
      "Validation loss decreased (0.065303 --> 0.063930).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0623338\n",
      "\tspeed: 0.0440s/iter; left time: 113.9198s\n",
      "\titers: 200, epoch: 9 | loss: 0.0668094\n",
      "\tspeed: 0.0221s/iter; left time: 55.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0688016 Vali Loss: 0.0633491 Test Loss: 0.0958828\n",
      "Validation loss decreased (0.063930 --> 0.063349).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0593434\n",
      "\tspeed: 0.0444s/iter; left time: 104.8963s\n",
      "\titers: 200, epoch: 10 | loss: 0.0626989\n",
      "\tspeed: 0.0222s/iter; left time: 50.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0664561 Vali Loss: 0.0609659 Test Loss: 0.1284374\n",
      "Validation loss decreased (0.063349 --> 0.060966).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0622944\n",
      "\tspeed: 0.0463s/iter; left time: 99.1656s\n",
      "\titers: 200, epoch: 11 | loss: 0.0658644\n",
      "\tspeed: 0.0220s/iter; left time: 44.8312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0656484 Vali Loss: 0.0612249 Test Loss: 0.1009870\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0637960\n",
      "\tspeed: 0.0423s/iter; left time: 81.0024s\n",
      "\titers: 200, epoch: 12 | loss: 0.0612931\n",
      "\tspeed: 0.0223s/iter; left time: 40.4451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0650874 Vali Loss: 0.0604871 Test Loss: 0.0902161\n",
      "Validation loss decreased (0.060966 --> 0.060487).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0628829\n",
      "\tspeed: 0.0462s/iter; left time: 78.2460s\n",
      "\titers: 200, epoch: 13 | loss: 0.0650562\n",
      "\tspeed: 0.0222s/iter; left time: 35.3783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0650263 Vali Loss: 0.0608885 Test Loss: 0.1286077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0619630\n",
      "\tspeed: 0.0436s/iter; left time: 64.0061s\n",
      "\titers: 200, epoch: 14 | loss: 0.0586796\n",
      "\tspeed: 0.0222s/iter; left time: 30.3438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0642797 Vali Loss: 0.0603918 Test Loss: 0.1178168\n",
      "Validation loss decreased (0.060487 --> 0.060392).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0605762\n",
      "\tspeed: 0.0444s/iter; left time: 55.3076s\n",
      "\titers: 200, epoch: 15 | loss: 0.0586561\n",
      "\tspeed: 0.0222s/iter; left time: 25.4668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0630984 Vali Loss: 0.0596061 Test Loss: 0.1186898\n",
      "Validation loss decreased (0.060392 --> 0.059606).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0632095\n",
      "\tspeed: 0.0454s/iter; left time: 46.3732s\n",
      "\titers: 200, epoch: 16 | loss: 0.0630129\n",
      "\tspeed: 0.0223s/iter; left time: 20.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0629462 Vali Loss: 0.0602369 Test Loss: 0.1098268\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0585979\n",
      "\tspeed: 0.0435s/iter; left time: 34.6492s\n",
      "\titers: 200, epoch: 17 | loss: 0.0659088\n",
      "\tspeed: 0.0222s/iter; left time: 15.4812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0626899 Vali Loss: 0.0595607 Test Loss: 0.1000965\n",
      "Validation loss decreased (0.059606 --> 0.059561).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0601105\n",
      "\tspeed: 0.0445s/iter; left time: 25.5212s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681729\n",
      "\tspeed: 0.0221s/iter; left time: 10.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0624221 Vali Loss: 0.0592252 Test Loss: 0.0863669\n",
      "Validation loss decreased (0.059561 --> 0.059225).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0631182\n",
      "\tspeed: 0.0444s/iter; left time: 15.4945s\n",
      "\titers: 200, epoch: 19 | loss: 0.0669753\n",
      "\tspeed: 0.0222s/iter; left time: 5.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0623056 Vali Loss: 0.0602179 Test Loss: 0.1199070\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0603992\n",
      "\tspeed: 0.0441s/iter; left time: 5.5074s\n",
      "\titers: 200, epoch: 20 | loss: 0.0625038\n",
      "\tspeed: 0.0223s/iter; left time: 0.5570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0622894 Vali Loss: 0.0608442 Test Loss: 0.1072595\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02006576769053936, rmse:0.14165368676185608, mae:0.0863669291138649, rse:0.4168696701526642\n",
      "Intermediate time for ES and pred_len 24: 00h:04m:34.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2779510\n",
      "\tspeed: 0.0456s/iter; left time: 199.6227s\n",
      "\titers: 200, epoch: 1 | loss: 0.2662928\n",
      "\tspeed: 0.0221s/iter; left time: 94.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.2877052 Vali Loss: 0.2208774 Test Loss: 0.2320454\n",
      "Validation loss decreased (inf --> 0.220877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1714785\n",
      "\tspeed: 0.0458s/iter; left time: 190.4214s\n",
      "\titers: 200, epoch: 2 | loss: 0.1204575\n",
      "\tspeed: 0.0221s/iter; left time: 89.4676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.1703069 Vali Loss: 0.1102910 Test Loss: 0.1248516\n",
      "Validation loss decreased (0.220877 --> 0.110291).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1106902\n",
      "\tspeed: 0.0462s/iter; left time: 181.8655s\n",
      "\titers: 200, epoch: 3 | loss: 0.1012254\n",
      "\tspeed: 0.0221s/iter; left time: 84.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.1087193 Vali Loss: 0.0905843 Test Loss: 0.1114859\n",
      "Validation loss decreased (0.110291 --> 0.090584).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0953543\n",
      "\tspeed: 0.0452s/iter; left time: 167.5305s\n",
      "\titers: 200, epoch: 4 | loss: 0.0925708\n",
      "\tspeed: 0.0221s/iter; left time: 79.7526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0957539 Vali Loss: 0.0862527 Test Loss: 0.1100703\n",
      "Validation loss decreased (0.090584 --> 0.086253).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901138\n",
      "\tspeed: 0.0462s/iter; left time: 161.1185s\n",
      "\titers: 200, epoch: 5 | loss: 0.0889515\n",
      "\tspeed: 0.0223s/iter; left time: 75.3616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0903572 Vali Loss: 0.0848034 Test Loss: 0.1118849\n",
      "Validation loss decreased (0.086253 --> 0.084803).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0895829\n",
      "\tspeed: 0.0455s/iter; left time: 148.2252s\n",
      "\titers: 200, epoch: 6 | loss: 0.0945022\n",
      "\tspeed: 0.0221s/iter; left time: 69.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0881008 Vali Loss: 0.0833008 Test Loss: 0.1092947\n",
      "Validation loss decreased (0.084803 --> 0.083301).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0820630\n",
      "\tspeed: 0.0451s/iter; left time: 136.8534s\n",
      "\titers: 200, epoch: 7 | loss: 0.0877493\n",
      "\tspeed: 0.0222s/iter; left time: 65.2164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0872355 Vali Loss: 0.0850944 Test Loss: 0.1230013\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0902622\n",
      "\tspeed: 0.0449s/iter; left time: 126.3637s\n",
      "\titers: 200, epoch: 8 | loss: 0.0894334\n",
      "\tspeed: 0.0222s/iter; left time: 60.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0841310 Vali Loss: 0.0824422 Test Loss: 0.1658185\n",
      "Validation loss decreased (0.083301 --> 0.082442).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0727782\n",
      "\tspeed: 0.0457s/iter; left time: 118.1910s\n",
      "\titers: 200, epoch: 9 | loss: 0.0787030\n",
      "\tspeed: 0.0221s/iter; left time: 54.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0818198 Vali Loss: 0.0837497 Test Loss: 0.1472127\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0843167\n",
      "\tspeed: 0.0446s/iter; left time: 105.4856s\n",
      "\titers: 200, epoch: 10 | loss: 0.0814335\n",
      "\tspeed: 0.0222s/iter; left time: 50.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0806563 Vali Loss: 0.0854115 Test Loss: 0.1548048\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0801080\n",
      "\tspeed: 0.0462s/iter; left time: 98.8793s\n",
      "\titers: 200, epoch: 11 | loss: 0.0824506\n",
      "\tspeed: 0.0221s/iter; left time: 45.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0802750 Vali Loss: 0.0853699 Test Loss: 0.2191359\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1150936\n",
      "\tspeed: 0.0438s/iter; left time: 84.0170s\n",
      "\titers: 200, epoch: 12 | loss: 0.0810694\n",
      "\tspeed: 0.0221s/iter; left time: 40.1724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0795385 Vali Loss: 0.0859113 Test Loss: 0.1787235\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0797916\n",
      "\tspeed: 0.0444s/iter; left time: 75.1746s\n",
      "\titers: 200, epoch: 13 | loss: 0.0761708\n",
      "\tspeed: 0.0222s/iter; left time: 35.2927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0779235 Vali Loss: 0.0851290 Test Loss: 0.1653772\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.06969329714775085, rmse:0.26399487257003784, mae:0.1658184826374054, rse:0.7755374908447266\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2882525\n",
      "\tspeed: 0.0239s/iter; left time: 104.8752s\n",
      "\titers: 200, epoch: 1 | loss: 0.2702966\n",
      "\tspeed: 0.0221s/iter; left time: 94.6469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.2918393 Vali Loss: 0.2230387 Test Loss: 0.2340999\n",
      "Validation loss decreased (inf --> 0.223039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1724803\n",
      "\tspeed: 0.0445s/iter; left time: 184.8373s\n",
      "\titers: 200, epoch: 2 | loss: 0.1259222\n",
      "\tspeed: 0.0221s/iter; left time: 89.7297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.1708843 Vali Loss: 0.1144324 Test Loss: 0.1239187\n",
      "Validation loss decreased (0.223039 --> 0.114432).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089810\n",
      "\tspeed: 0.0448s/iter; left time: 176.2836s\n",
      "\titers: 200, epoch: 3 | loss: 0.0959702\n",
      "\tspeed: 0.0221s/iter; left time: 84.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.1066757 Vali Loss: 0.0898940 Test Loss: 0.1101385\n",
      "Validation loss decreased (0.114432 --> 0.089894).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0974123\n",
      "\tspeed: 0.0481s/iter; left time: 178.3827s\n",
      "\titers: 200, epoch: 4 | loss: 0.0927210\n",
      "\tspeed: 0.0221s/iter; left time: 79.7064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0986006 Vali Loss: 0.0887170 Test Loss: 0.1061965\n",
      "Validation loss decreased (0.089894 --> 0.088717).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0890924\n",
      "\tspeed: 0.0455s/iter; left time: 158.4345s\n",
      "\titers: 200, epoch: 5 | loss: 0.0846362\n",
      "\tspeed: 0.0221s/iter; left time: 74.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0907484 Vali Loss: 0.0874797 Test Loss: 0.1125249\n",
      "Validation loss decreased (0.088717 --> 0.087480).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0934634\n",
      "\tspeed: 0.0448s/iter; left time: 146.1601s\n",
      "\titers: 200, epoch: 6 | loss: 0.0882517\n",
      "\tspeed: 0.0221s/iter; left time: 69.9514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0889666 Vali Loss: 0.0880787 Test Loss: 0.1452554\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0888718\n",
      "\tspeed: 0.0442s/iter; left time: 134.1046s\n",
      "\titers: 200, epoch: 7 | loss: 0.0804312\n",
      "\tspeed: 0.0221s/iter; left time: 64.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0856903 Vali Loss: 0.0821111 Test Loss: 0.1242850\n",
      "Validation loss decreased (0.087480 --> 0.082111).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0830433\n",
      "\tspeed: 0.0447s/iter; left time: 125.8536s\n",
      "\titers: 200, epoch: 8 | loss: 0.0839619\n",
      "\tspeed: 0.0223s/iter; left time: 60.3700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0845545 Vali Loss: 0.0850671 Test Loss: 0.1229060\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0817148\n",
      "\tspeed: 0.0443s/iter; left time: 114.7789s\n",
      "\titers: 200, epoch: 9 | loss: 0.0811879\n",
      "\tspeed: 0.0222s/iter; left time: 55.3626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0832928 Vali Loss: 0.0841072 Test Loss: 0.1214423\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0797094\n",
      "\tspeed: 0.0448s/iter; left time: 106.0013s\n",
      "\titers: 200, epoch: 10 | loss: 0.0776386\n",
      "\tspeed: 0.0221s/iter; left time: 50.0737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0812140 Vali Loss: 0.0835792 Test Loss: 0.1330764\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0819243\n",
      "\tspeed: 0.0440s/iter; left time: 94.1956s\n",
      "\titers: 200, epoch: 11 | loss: 0.0855949\n",
      "\tspeed: 0.0221s/iter; left time: 45.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0800313 Vali Loss: 0.0842944 Test Loss: 0.1348395\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0855771\n",
      "\tspeed: 0.0436s/iter; left time: 83.5293s\n",
      "\titers: 200, epoch: 12 | loss: 0.0804714\n",
      "\tspeed: 0.0232s/iter; left time: 42.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0794614 Vali Loss: 0.0872393 Test Loss: 0.1322525\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03414180874824524, rmse:0.18477502465248108, mae:0.12428495287895203, rse:0.5428134202957153\n",
      "Intermediate time for ES and pred_len 96: 00h:02m:58.32s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2884141\n",
      "\tspeed: 0.0439s/iter; left time: 191.6140s\n",
      "\titers: 200, epoch: 1 | loss: 0.2721840\n",
      "\tspeed: 0.0224s/iter; left time: 95.3248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.2894571 Vali Loss: 0.2230498 Test Loss: 0.2330582\n",
      "Validation loss decreased (inf --> 0.223050).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1718768\n",
      "\tspeed: 0.0462s/iter; left time: 191.1444s\n",
      "\titers: 200, epoch: 2 | loss: 0.1280817\n",
      "\tspeed: 0.0224s/iter; left time: 90.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.1695284 Vali Loss: 0.1172812 Test Loss: 0.1317446\n",
      "Validation loss decreased (0.223050 --> 0.117281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108097\n",
      "\tspeed: 0.0485s/iter; left time: 189.7558s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096972\n",
      "\tspeed: 0.0225s/iter; left time: 85.7194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.1098236 Vali Loss: 0.0974858 Test Loss: 0.1109126\n",
      "Validation loss decreased (0.117281 --> 0.097486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0999061\n",
      "\tspeed: 0.0467s/iter; left time: 172.2412s\n",
      "\titers: 200, epoch: 4 | loss: 0.0950652\n",
      "\tspeed: 0.0224s/iter; left time: 80.3263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0987645 Vali Loss: 0.0924309 Test Loss: 0.1213958\n",
      "Validation loss decreased (0.097486 --> 0.092431).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0945968\n",
      "\tspeed: 0.0464s/iter; left time: 160.9542s\n",
      "\titers: 200, epoch: 5 | loss: 0.0932133\n",
      "\tspeed: 0.0225s/iter; left time: 75.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0931140 Vali Loss: 0.0914762 Test Loss: 0.1194703\n",
      "Validation loss decreased (0.092431 --> 0.091476).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0935682\n",
      "\tspeed: 0.0460s/iter; left time: 149.3982s\n",
      "\titers: 200, epoch: 6 | loss: 0.0867682\n",
      "\tspeed: 0.0225s/iter; left time: 70.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0897159 Vali Loss: 0.0916975 Test Loss: 0.1324923\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0902168\n",
      "\tspeed: 0.0441s/iter; left time: 133.2364s\n",
      "\titers: 200, epoch: 7 | loss: 0.0876394\n",
      "\tspeed: 0.0224s/iter; left time: 65.5821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0894500 Vali Loss: 0.0915102 Test Loss: 0.1257991\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0817703\n",
      "\tspeed: 0.0447s/iter; left time: 125.0611s\n",
      "\titers: 200, epoch: 8 | loss: 0.1488592\n",
      "\tspeed: 0.0225s/iter; left time: 60.7722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0867855 Vali Loss: 0.0929095 Test Loss: 0.1727925\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0880843\n",
      "\tspeed: 0.0447s/iter; left time: 115.0641s\n",
      "\titers: 200, epoch: 9 | loss: 0.0863457\n",
      "\tspeed: 0.0224s/iter; left time: 55.4525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0855714 Vali Loss: 0.0895623 Test Loss: 0.1364955\n",
      "Validation loss decreased (0.091476 --> 0.089562).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809476\n",
      "\tspeed: 0.0458s/iter; left time: 107.8403s\n",
      "\titers: 200, epoch: 10 | loss: 0.0853404\n",
      "\tspeed: 0.0224s/iter; left time: 50.5213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0834427 Vali Loss: 0.0899317 Test Loss: 0.1396821\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0796672\n",
      "\tspeed: 0.0452s/iter; left time: 96.2613s\n",
      "\titers: 200, epoch: 11 | loss: 0.0835209\n",
      "\tspeed: 0.0225s/iter; left time: 45.6645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0828722 Vali Loss: 0.0899457 Test Loss: 0.1539323\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0797938\n",
      "\tspeed: 0.0447s/iter; left time: 85.3035s\n",
      "\titers: 200, epoch: 12 | loss: 0.0824027\n",
      "\tspeed: 0.0224s/iter; left time: 40.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0817429 Vali Loss: 0.0896569 Test Loss: 0.1508317\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0820883\n",
      "\tspeed: 0.0477s/iter; left time: 80.4563s\n",
      "\titers: 200, epoch: 13 | loss: 0.0833454\n",
      "\tspeed: 0.0225s/iter; left time: 35.5899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0808136 Vali Loss: 0.0922953 Test Loss: 0.2121722\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0760487\n",
      "\tspeed: 0.0473s/iter; left time: 69.1735s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800035\n",
      "\tspeed: 0.0231s/iter; left time: 31.4646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0802912 Vali Loss: 0.0903109 Test Loss: 0.1444134\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.041546378284692764, rmse:0.20382928848266602, mae:0.13649548590183258, rse:0.5988320708274841\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2879668\n",
      "\tspeed: 0.0247s/iter; left time: 107.6323s\n",
      "\titers: 200, epoch: 1 | loss: 0.2681984\n",
      "\tspeed: 0.0224s/iter; left time: 95.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.2897532 Vali Loss: 0.2259216 Test Loss: 0.2360817\n",
      "Validation loss decreased (inf --> 0.225922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1724761\n",
      "\tspeed: 0.0465s/iter; left time: 192.3566s\n",
      "\titers: 200, epoch: 2 | loss: 0.1250581\n",
      "\tspeed: 0.0225s/iter; left time: 90.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.1680656 Vali Loss: 0.1126142 Test Loss: 0.1261792\n",
      "Validation loss decreased (0.225922 --> 0.112614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1088576\n",
      "\tspeed: 0.0494s/iter; left time: 193.4501s\n",
      "\titers: 200, epoch: 3 | loss: 0.1004390\n",
      "\tspeed: 0.0225s/iter; left time: 85.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.1097199 Vali Loss: 0.0933417 Test Loss: 0.1227824\n",
      "Validation loss decreased (0.112614 --> 0.093342).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1057407\n",
      "\tspeed: 0.0484s/iter; left time: 178.6490s\n",
      "\titers: 200, epoch: 4 | loss: 0.1000712\n",
      "\tspeed: 0.0224s/iter; left time: 80.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.1005792 Vali Loss: 0.0925170 Test Loss: 0.1261913\n",
      "Validation loss decreased (0.093342 --> 0.092517).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0955518\n",
      "\tspeed: 0.0467s/iter; left time: 161.9519s\n",
      "\titers: 200, epoch: 5 | loss: 0.0909226\n",
      "\tspeed: 0.0224s/iter; left time: 75.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0933445 Vali Loss: 0.0930082 Test Loss: 0.1282270\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0908047\n",
      "\tspeed: 0.0448s/iter; left time: 145.4466s\n",
      "\titers: 200, epoch: 6 | loss: 0.0907078\n",
      "\tspeed: 0.0224s/iter; left time: 70.4977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0912812 Vali Loss: 0.0929883 Test Loss: 0.1334669\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0860710\n",
      "\tspeed: 0.0446s/iter; left time: 134.7509s\n",
      "\titers: 200, epoch: 7 | loss: 0.0829603\n",
      "\tspeed: 0.0224s/iter; left time: 65.5858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0879431 Vali Loss: 0.0934159 Test Loss: 0.1357392\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816696\n",
      "\tspeed: 0.0444s/iter; left time: 124.2430s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831505\n",
      "\tspeed: 0.0224s/iter; left time: 60.6131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0862290 Vali Loss: 0.0914387 Test Loss: 0.1351718\n",
      "Validation loss decreased (0.092517 --> 0.091439).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0812769\n",
      "\tspeed: 0.0458s/iter; left time: 117.9249s\n",
      "\titers: 200, epoch: 9 | loss: 0.0813826\n",
      "\tspeed: 0.0224s/iter; left time: 55.5222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0850432 Vali Loss: 0.0911525 Test Loss: 0.1545677\n",
      "Validation loss decreased (0.091439 --> 0.091153).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0800448\n",
      "\tspeed: 0.0457s/iter; left time: 107.6599s\n",
      "\titers: 200, epoch: 10 | loss: 0.0841363\n",
      "\tspeed: 0.0225s/iter; left time: 50.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0829844 Vali Loss: 0.0900035 Test Loss: 0.1389300\n",
      "Validation loss decreased (0.091153 --> 0.090004).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0807706\n",
      "\tspeed: 0.0469s/iter; left time: 99.9348s\n",
      "\titers: 200, epoch: 11 | loss: 0.0783596\n",
      "\tspeed: 0.0224s/iter; left time: 45.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0818478 Vali Loss: 0.0906859 Test Loss: 0.1587413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0775775\n",
      "\tspeed: 0.0459s/iter; left time: 87.5842s\n",
      "\titers: 200, epoch: 12 | loss: 0.0843701\n",
      "\tspeed: 0.0225s/iter; left time: 40.5942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0821294 Vali Loss: 0.0912500 Test Loss: 0.1846673\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0785934\n",
      "\tspeed: 0.0447s/iter; left time: 75.2406s\n",
      "\titers: 200, epoch: 13 | loss: 0.0780096\n",
      "\tspeed: 0.0222s/iter; left time: 35.1533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0807252 Vali Loss: 0.0907561 Test Loss: 0.1609640\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0812282\n",
      "\tspeed: 0.0451s/iter; left time: 65.9334s\n",
      "\titers: 200, epoch: 14 | loss: 0.0815143\n",
      "\tspeed: 0.0223s/iter; left time: 30.4231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0797209 Vali Loss: 0.0898094 Test Loss: 0.1567131\n",
      "Validation loss decreased (0.090004 --> 0.089809).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0763150\n",
      "\tspeed: 0.0459s/iter; left time: 56.9248s\n",
      "\titers: 200, epoch: 15 | loss: 0.0757347\n",
      "\tspeed: 0.0225s/iter; left time: 25.5819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0787860 Vali Loss: 0.0913521 Test Loss: 0.1512309\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0749770\n",
      "\tspeed: 0.0448s/iter; left time: 45.5416s\n",
      "\titers: 200, epoch: 16 | loss: 0.0770923\n",
      "\tspeed: 0.0224s/iter; left time: 20.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0778389 Vali Loss: 0.0909030 Test Loss: 0.1461935\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0768276\n",
      "\tspeed: 0.0450s/iter; left time: 35.7227s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780471\n",
      "\tspeed: 0.0224s/iter; left time: 15.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0777160 Vali Loss: 0.0913935 Test Loss: 0.1592692\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0745970\n",
      "\tspeed: 0.0445s/iter; left time: 25.3723s\n",
      "\titers: 200, epoch: 18 | loss: 0.0779933\n",
      "\tspeed: 0.0225s/iter; left time: 10.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0772676 Vali Loss: 0.0914678 Test Loss: 0.1629128\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0751199\n",
      "\tspeed: 0.0448s/iter; left time: 15.5469s\n",
      "\titers: 200, epoch: 19 | loss: 0.0747144\n",
      "\tspeed: 0.0224s/iter; left time: 5.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0771401 Vali Loss: 0.0919162 Test Loss: 0.1518773\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06135386601090431, rmse:0.2476971298456192, mae:0.15671306848526, rse:0.7277118563652039\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:55.06s\n",
      "Intermediate time for ES: 00h:11m:28.32s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2307332\n",
      "\tspeed: 0.0425s/iter; left time: 186.0553s\n",
      "\titers: 200, epoch: 1 | loss: 0.2188236\n",
      "\tspeed: 0.0217s/iter; left time: 92.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.2352672 Vali Loss: 0.1780650 Test Loss: 0.1857867\n",
      "Validation loss decreased (inf --> 0.178065).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1276939\n",
      "\tspeed: 0.0454s/iter; left time: 188.7196s\n",
      "\titers: 200, epoch: 2 | loss: 0.1078538\n",
      "\tspeed: 0.0217s/iter; left time: 88.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.1335138 Vali Loss: 0.0994966 Test Loss: 0.1148157\n",
      "Validation loss decreased (0.178065 --> 0.099497).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0991110\n",
      "\tspeed: 0.0443s/iter; left time: 174.0713s\n",
      "\titers: 200, epoch: 3 | loss: 0.0892021\n",
      "\tspeed: 0.0218s/iter; left time: 83.4912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0944535 Vali Loss: 0.0894826 Test Loss: 0.0946018\n",
      "Validation loss decreased (0.099497 --> 0.089483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0715061\n",
      "\tspeed: 0.0471s/iter; left time: 174.7431s\n",
      "\titers: 200, epoch: 4 | loss: 0.0783062\n",
      "\tspeed: 0.0227s/iter; left time: 81.8407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0746069 Vali Loss: 0.0781283 Test Loss: 0.0833192\n",
      "Validation loss decreased (0.089483 --> 0.078128).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0561440\n",
      "\tspeed: 0.0476s/iter; left time: 165.7580s\n",
      "\titers: 200, epoch: 5 | loss: 0.0611114\n",
      "\tspeed: 0.0218s/iter; left time: 73.7090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0631937 Vali Loss: 0.0716930 Test Loss: 0.0762888\n",
      "Validation loss decreased (0.078128 --> 0.071693).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0718566\n",
      "\tspeed: 0.0438s/iter; left time: 142.7872s\n",
      "\titers: 200, epoch: 6 | loss: 0.0595315\n",
      "\tspeed: 0.0218s/iter; left time: 68.8011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0611923 Vali Loss: 0.0665766 Test Loss: 0.0710205\n",
      "Validation loss decreased (0.071693 --> 0.066577).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0506662\n",
      "\tspeed: 0.0458s/iter; left time: 138.9978s\n",
      "\titers: 200, epoch: 7 | loss: 0.0547227\n",
      "\tspeed: 0.0218s/iter; left time: 63.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0576479 Vali Loss: 0.0674027 Test Loss: 0.0715833\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0565726\n",
      "\tspeed: 0.0437s/iter; left time: 122.9114s\n",
      "\titers: 200, epoch: 8 | loss: 0.0543823\n",
      "\tspeed: 0.0218s/iter; left time: 59.1042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0557143 Vali Loss: 0.0690601 Test Loss: 0.0720639\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0505910\n",
      "\tspeed: 0.0428s/iter; left time: 110.8501s\n",
      "\titers: 200, epoch: 9 | loss: 0.0520933\n",
      "\tspeed: 0.0218s/iter; left time: 54.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0534683 Vali Loss: 0.0607580 Test Loss: 0.0665711\n",
      "Validation loss decreased (0.066577 --> 0.060758).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0612324\n",
      "\tspeed: 0.0440s/iter; left time: 103.9919s\n",
      "\titers: 200, epoch: 10 | loss: 0.0518169\n",
      "\tspeed: 0.0218s/iter; left time: 49.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0521842 Vali Loss: 0.0631759 Test Loss: 0.0674634\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0520187\n",
      "\tspeed: 0.0433s/iter; left time: 92.7685s\n",
      "\titers: 200, epoch: 11 | loss: 0.0558920\n",
      "\tspeed: 0.0219s/iter; left time: 44.7115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0519736 Vali Loss: 0.0665905 Test Loss: 0.0699502\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0528975\n",
      "\tspeed: 0.0427s/iter; left time: 81.8525s\n",
      "\titers: 200, epoch: 12 | loss: 0.0472861\n",
      "\tspeed: 0.0218s/iter; left time: 39.5999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0514177 Vali Loss: 0.0631215 Test Loss: 0.0679155\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0511928\n",
      "\tspeed: 0.0423s/iter; left time: 71.5404s\n",
      "\titers: 200, epoch: 13 | loss: 0.0549785\n",
      "\tspeed: 0.0219s/iter; left time: 34.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0502972 Vali Loss: 0.0624751 Test Loss: 0.0671346\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0507330\n",
      "\tspeed: 0.0432s/iter; left time: 63.4423s\n",
      "\titers: 200, epoch: 14 | loss: 0.0514416\n",
      "\tspeed: 0.0218s/iter; left time: 29.8887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0508942 Vali Loss: 0.0620408 Test Loss: 0.0669009\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013849814422428608, rmse:0.1176852360367775, mae:0.06657112389802933, rse:0.45402637124061584\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2342003\n",
      "\tspeed: 0.0235s/iter; left time: 103.1275s\n",
      "\titers: 200, epoch: 1 | loss: 0.2195695\n",
      "\tspeed: 0.0218s/iter; left time: 93.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.2385762 Vali Loss: 0.1803954 Test Loss: 0.1847107\n",
      "Validation loss decreased (inf --> 0.180395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1320264\n",
      "\tspeed: 0.0479s/iter; left time: 199.3259s\n",
      "\titers: 200, epoch: 2 | loss: 0.1017433\n",
      "\tspeed: 0.0230s/iter; left time: 93.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.1358368 Vali Loss: 0.1065679 Test Loss: 0.1213365\n",
      "Validation loss decreased (0.180395 --> 0.106568).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0886370\n",
      "\tspeed: 0.0451s/iter; left time: 177.4816s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785015\n",
      "\tspeed: 0.0218s/iter; left time: 83.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0915298 Vali Loss: 0.0848858 Test Loss: 0.0889135\n",
      "Validation loss decreased (0.106568 --> 0.084886).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0710863\n",
      "\tspeed: 0.0437s/iter; left time: 161.9927s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696915\n",
      "\tspeed: 0.0218s/iter; left time: 78.6214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0707708 Vali Loss: 0.0836984 Test Loss: 0.0880668\n",
      "Validation loss decreased (0.084886 --> 0.083698).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0602405\n",
      "\tspeed: 0.0443s/iter; left time: 154.5239s\n",
      "\titers: 200, epoch: 5 | loss: 0.0667563\n",
      "\tspeed: 0.0218s/iter; left time: 73.7938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0657583 Vali Loss: 0.0779197 Test Loss: 0.0836077\n",
      "Validation loss decreased (0.083698 --> 0.077920).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0571358\n",
      "\tspeed: 0.0431s/iter; left time: 140.5245s\n",
      "\titers: 200, epoch: 6 | loss: 0.0567764\n",
      "\tspeed: 0.0218s/iter; left time: 68.8314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0610634 Vali Loss: 0.0758140 Test Loss: 0.0810740\n",
      "Validation loss decreased (0.077920 --> 0.075814).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0560079\n",
      "\tspeed: 0.0429s/iter; left time: 130.1365s\n",
      "\titers: 200, epoch: 7 | loss: 0.0567243\n",
      "\tspeed: 0.0218s/iter; left time: 64.0398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0591307 Vali Loss: 0.0649608 Test Loss: 0.0721913\n",
      "Validation loss decreased (0.075814 --> 0.064961).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0483910\n",
      "\tspeed: 0.0439s/iter; left time: 123.4003s\n",
      "\titers: 200, epoch: 8 | loss: 0.0645380\n",
      "\tspeed: 0.0218s/iter; left time: 59.1938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0548397 Vali Loss: 0.0660846 Test Loss: 0.0727932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0531390\n",
      "\tspeed: 0.0422s/iter; left time: 109.1668s\n",
      "\titers: 200, epoch: 9 | loss: 0.0580643\n",
      "\tspeed: 0.0219s/iter; left time: 54.5884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0549900 Vali Loss: 0.0604435 Test Loss: 0.0681838\n",
      "Validation loss decreased (0.064961 --> 0.060443).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0557801\n",
      "\tspeed: 0.0435s/iter; left time: 102.9473s\n",
      "\titers: 200, epoch: 10 | loss: 0.0549503\n",
      "\tspeed: 0.0218s/iter; left time: 49.4213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0525124 Vali Loss: 0.0585037 Test Loss: 0.0667228\n",
      "Validation loss decreased (0.060443 --> 0.058504).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0583270\n",
      "\tspeed: 0.0432s/iter; left time: 92.5155s\n",
      "\titers: 200, epoch: 11 | loss: 0.0520659\n",
      "\tspeed: 0.0218s/iter; left time: 44.5176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0521159 Vali Loss: 0.0596896 Test Loss: 0.0676897\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0522579\n",
      "\tspeed: 0.0433s/iter; left time: 83.0850s\n",
      "\titers: 200, epoch: 12 | loss: 0.0494867\n",
      "\tspeed: 0.0218s/iter; left time: 39.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0521619 Vali Loss: 0.0590573 Test Loss: 0.0664986\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0495107\n",
      "\tspeed: 0.0441s/iter; left time: 74.5939s\n",
      "\titers: 200, epoch: 13 | loss: 0.0483238\n",
      "\tspeed: 0.0218s/iter; left time: 34.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0513100 Vali Loss: 0.0586669 Test Loss: 0.0666888\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0503986\n",
      "\tspeed: 0.0423s/iter; left time: 62.1659s\n",
      "\titers: 200, epoch: 14 | loss: 0.0489387\n",
      "\tspeed: 0.0218s/iter; left time: 29.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0500956 Vali Loss: 0.0584284 Test Loss: 0.0664305\n",
      "Validation loss decreased (0.058504 --> 0.058428).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0473530\n",
      "\tspeed: 0.0430s/iter; left time: 53.5746s\n",
      "\titers: 200, epoch: 15 | loss: 0.0476578\n",
      "\tspeed: 0.0218s/iter; left time: 24.9844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0507379 Vali Loss: 0.0628125 Test Loss: 0.0696656\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0524591\n",
      "\tspeed: 0.0422s/iter; left time: 43.0800s\n",
      "\titers: 200, epoch: 16 | loss: 0.0483818\n",
      "\tspeed: 0.0218s/iter; left time: 20.1098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0504605 Vali Loss: 0.0628848 Test Loss: 0.0692015\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0457780\n",
      "\tspeed: 0.0421s/iter; left time: 33.5334s\n",
      "\titers: 200, epoch: 17 | loss: 0.0484187\n",
      "\tspeed: 0.0218s/iter; left time: 15.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0497183 Vali Loss: 0.0591106 Test Loss: 0.0672565\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0483973\n",
      "\tspeed: 0.0420s/iter; left time: 24.0500s\n",
      "\titers: 200, epoch: 18 | loss: 0.0480527\n",
      "\tspeed: 0.0218s/iter; left time: 10.3143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0494533 Vali Loss: 0.0593876 Test Loss: 0.0668421\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0469934\n",
      "\tspeed: 0.0421s/iter; left time: 14.6953s\n",
      "\titers: 200, epoch: 19 | loss: 0.0511846\n",
      "\tspeed: 0.0219s/iter; left time: 5.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0489351 Vali Loss: 0.0585901 Test Loss: 0.0659441\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013898561708629131, rmse:0.11789216101169586, mae:0.06643046438694, rse:0.45482465624809265\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:46.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2369412\n",
      "\tspeed: 0.0397s/iter; left time: 173.7844s\n",
      "\titers: 200, epoch: 1 | loss: 0.2122669\n",
      "\tspeed: 0.0220s/iter; left time: 94.1068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.2418674 Vali Loss: 0.1837639 Test Loss: 0.1905375\n",
      "Validation loss decreased (inf --> 0.183764).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1257792\n",
      "\tspeed: 0.0459s/iter; left time: 190.9317s\n",
      "\titers: 200, epoch: 2 | loss: 0.1021315\n",
      "\tspeed: 0.0220s/iter; left time: 89.3586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.1315831 Vali Loss: 0.1165160 Test Loss: 0.1267975\n",
      "Validation loss decreased (0.183764 --> 0.116516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0865192\n",
      "\tspeed: 0.0454s/iter; left time: 178.6218s\n",
      "\titers: 200, epoch: 3 | loss: 0.0858783\n",
      "\tspeed: 0.0220s/iter; left time: 84.4774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0901357 Vali Loss: 0.0940685 Test Loss: 0.1047554\n",
      "Validation loss decreased (0.116516 --> 0.094069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1342189\n",
      "\tspeed: 0.0450s/iter; left time: 166.7949s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828184\n",
      "\tspeed: 0.0222s/iter; left time: 80.0874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0794933 Vali Loss: 0.0903961 Test Loss: 0.1008743\n",
      "Validation loss decreased (0.094069 --> 0.090396).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693270\n",
      "\tspeed: 0.0448s/iter; left time: 156.0588s\n",
      "\titers: 200, epoch: 5 | loss: 0.0682257\n",
      "\tspeed: 0.0221s/iter; left time: 74.6571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0725258 Vali Loss: 0.0934349 Test Loss: 0.1025979\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0729666\n",
      "\tspeed: 0.0434s/iter; left time: 141.4056s\n",
      "\titers: 200, epoch: 6 | loss: 0.0776474\n",
      "\tspeed: 0.0221s/iter; left time: 69.7702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0708520 Vali Loss: 0.0924688 Test Loss: 0.1050015\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0687674\n",
      "\tspeed: 0.0432s/iter; left time: 131.2968s\n",
      "\titers: 200, epoch: 7 | loss: 0.0621396\n",
      "\tspeed: 0.0221s/iter; left time: 64.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0683007 Vali Loss: 0.0860715 Test Loss: 0.0959162\n",
      "Validation loss decreased (0.090396 --> 0.086071).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0709300\n",
      "\tspeed: 0.0459s/iter; left time: 129.2089s\n",
      "\titers: 200, epoch: 8 | loss: 0.0654566\n",
      "\tspeed: 0.0221s/iter; left time: 59.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0662035 Vali Loss: 0.0908218 Test Loss: 0.1002795\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0675367\n",
      "\tspeed: 0.0476s/iter; left time: 123.3393s\n",
      "\titers: 200, epoch: 9 | loss: 0.0646982\n",
      "\tspeed: 0.0221s/iter; left time: 54.9667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0655005 Vali Loss: 0.0869091 Test Loss: 0.0970476\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0667992\n",
      "\tspeed: 0.0435s/iter; left time: 102.9860s\n",
      "\titers: 200, epoch: 10 | loss: 0.0651742\n",
      "\tspeed: 0.0220s/iter; left time: 49.8868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0651657 Vali Loss: 0.0908798 Test Loss: 0.1029084\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0633251\n",
      "\tspeed: 0.0437s/iter; left time: 93.6207s\n",
      "\titers: 200, epoch: 11 | loss: 0.0643180\n",
      "\tspeed: 0.0220s/iter; left time: 44.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0642172 Vali Loss: 0.0859047 Test Loss: 0.0982167\n",
      "Validation loss decreased (0.086071 --> 0.085905).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0616662\n",
      "\tspeed: 0.0449s/iter; left time: 86.1565s\n",
      "\titers: 200, epoch: 12 | loss: 0.0608980\n",
      "\tspeed: 0.0221s/iter; left time: 40.0847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0642643 Vali Loss: 0.0911969 Test Loss: 0.1024524\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0630219\n",
      "\tspeed: 0.0444s/iter; left time: 75.1693s\n",
      "\titers: 200, epoch: 13 | loss: 0.0641841\n",
      "\tspeed: 0.0221s/iter; left time: 35.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0640982 Vali Loss: 0.0879321 Test Loss: 0.0995764\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0632726\n",
      "\tspeed: 0.0434s/iter; left time: 63.7822s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605950\n",
      "\tspeed: 0.0220s/iter; left time: 30.1616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0631210 Vali Loss: 0.0863073 Test Loss: 0.0965441\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0630132\n",
      "\tspeed: 0.0435s/iter; left time: 54.2056s\n",
      "\titers: 200, epoch: 15 | loss: 0.0640035\n",
      "\tspeed: 0.0220s/iter; left time: 25.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0624868 Vali Loss: 0.0870750 Test Loss: 0.0975026\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0603293\n",
      "\tspeed: 0.0443s/iter; left time: 45.2016s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626675\n",
      "\tspeed: 0.0221s/iter; left time: 20.3107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0622458 Vali Loss: 0.0853640 Test Loss: 0.0977398\n",
      "Validation loss decreased (0.085905 --> 0.085364).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0564711\n",
      "\tspeed: 0.0488s/iter; left time: 38.9165s\n",
      "\titers: 200, epoch: 17 | loss: 0.0576669\n",
      "\tspeed: 0.0220s/iter; left time: 15.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0619298 Vali Loss: 0.0843820 Test Loss: 0.0946780\n",
      "Validation loss decreased (0.085364 --> 0.084382).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0602980\n",
      "\tspeed: 0.0453s/iter; left time: 25.9297s\n",
      "\titers: 200, epoch: 18 | loss: 0.0627710\n",
      "\tspeed: 0.0220s/iter; left time: 10.4165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0613833 Vali Loss: 0.0847854 Test Loss: 0.0956770\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0606245\n",
      "\tspeed: 0.0435s/iter; left time: 15.1902s\n",
      "\titers: 200, epoch: 19 | loss: 0.0572327\n",
      "\tspeed: 0.0220s/iter; left time: 5.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0610392 Vali Loss: 0.0832209 Test Loss: 0.0943832\n",
      "Validation loss decreased (0.084382 --> 0.083221).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0592465\n",
      "\tspeed: 0.0445s/iter; left time: 5.5582s\n",
      "\titers: 200, epoch: 20 | loss: 0.0571044\n",
      "\tspeed: 0.0220s/iter; left time: 0.5501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0612109 Vali Loss: 0.0839022 Test Loss: 0.0950387\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02627297304570675, rmse:0.16208939254283905, mae:0.09438323974609375, rse:0.627004861831665\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2436506\n",
      "\tspeed: 0.0241s/iter; left time: 105.5383s\n",
      "\titers: 200, epoch: 1 | loss: 0.2244409\n",
      "\tspeed: 0.0222s/iter; left time: 94.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.2439070 Vali Loss: 0.1858458 Test Loss: 0.1920338\n",
      "Validation loss decreased (inf --> 0.185846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1265370\n",
      "\tspeed: 0.0445s/iter; left time: 184.9839s\n",
      "\titers: 200, epoch: 2 | loss: 0.1088523\n",
      "\tspeed: 0.0221s/iter; left time: 89.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.1329499 Vali Loss: 0.1156757 Test Loss: 0.1247158\n",
      "Validation loss decreased (0.185846 --> 0.115676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0872440\n",
      "\tspeed: 0.0444s/iter; left time: 174.7467s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785187\n",
      "\tspeed: 0.0220s/iter; left time: 84.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0882275 Vali Loss: 0.0891856 Test Loss: 0.1003631\n",
      "Validation loss decreased (0.115676 --> 0.089186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0714049\n",
      "\tspeed: 0.0450s/iter; left time: 167.0862s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647975\n",
      "\tspeed: 0.0220s/iter; left time: 79.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0771611 Vali Loss: 0.0937423 Test Loss: 0.1025211\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0775864\n",
      "\tspeed: 0.0437s/iter; left time: 152.3506s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721694\n",
      "\tspeed: 0.0221s/iter; left time: 74.8028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0723639 Vali Loss: 0.0877462 Test Loss: 0.0959205\n",
      "Validation loss decreased (0.089186 --> 0.087746).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0659977\n",
      "\tspeed: 0.0444s/iter; left time: 144.8900s\n",
      "\titers: 200, epoch: 6 | loss: 0.0677758\n",
      "\tspeed: 0.0221s/iter; left time: 69.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0688738 Vali Loss: 0.0837844 Test Loss: 0.0921934\n",
      "Validation loss decreased (0.087746 --> 0.083784).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0683554\n",
      "\tspeed: 0.0455s/iter; left time: 138.3039s\n",
      "\titers: 200, epoch: 7 | loss: 0.0593066\n",
      "\tspeed: 0.0220s/iter; left time: 64.7457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0666696 Vali Loss: 0.0823039 Test Loss: 0.0925712\n",
      "Validation loss decreased (0.083784 --> 0.082304).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0628498\n",
      "\tspeed: 0.0446s/iter; left time: 125.3796s\n",
      "\titers: 200, epoch: 8 | loss: 0.0651701\n",
      "\tspeed: 0.0221s/iter; left time: 59.9800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0657603 Vali Loss: 0.0856413 Test Loss: 0.0965851\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0622366\n",
      "\tspeed: 0.0431s/iter; left time: 111.7098s\n",
      "\titers: 200, epoch: 9 | loss: 0.0669970\n",
      "\tspeed: 0.0220s/iter; left time: 54.8064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0646630 Vali Loss: 0.0838287 Test Loss: 0.0943326\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0597370\n",
      "\tspeed: 0.0432s/iter; left time: 102.1030s\n",
      "\titers: 200, epoch: 10 | loss: 0.0657365\n",
      "\tspeed: 0.0221s/iter; left time: 50.0879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0639826 Vali Loss: 0.0798803 Test Loss: 0.0911437\n",
      "Validation loss decreased (0.082304 --> 0.079880).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0629131\n",
      "\tspeed: 0.0450s/iter; left time: 96.3978s\n",
      "\titers: 200, epoch: 11 | loss: 0.0666725\n",
      "\tspeed: 0.0220s/iter; left time: 44.9506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0628958 Vali Loss: 0.0786128 Test Loss: 0.0902487\n",
      "Validation loss decreased (0.079880 --> 0.078613).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0665884\n",
      "\tspeed: 0.0441s/iter; left time: 84.5517s\n",
      "\titers: 200, epoch: 12 | loss: 0.0628731\n",
      "\tspeed: 0.0229s/iter; left time: 41.6741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0631226 Vali Loss: 0.0862236 Test Loss: 0.0969112\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0649870\n",
      "\tspeed: 0.0432s/iter; left time: 73.1894s\n",
      "\titers: 200, epoch: 13 | loss: 0.0599431\n",
      "\tspeed: 0.0239s/iter; left time: 38.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0630173 Vali Loss: 0.0849199 Test Loss: 0.0955088\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0628982\n",
      "\tspeed: 0.0436s/iter; left time: 64.0845s\n",
      "\titers: 200, epoch: 14 | loss: 0.0677818\n",
      "\tspeed: 0.0221s/iter; left time: 30.1993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0631725 Vali Loss: 0.0843122 Test Loss: 0.0963807\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0628599\n",
      "\tspeed: 0.0443s/iter; left time: 55.1252s\n",
      "\titers: 200, epoch: 15 | loss: 0.0679907\n",
      "\tspeed: 0.0227s/iter; left time: 25.9687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0630617 Vali Loss: 0.0834866 Test Loss: 0.0948363\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0611753\n",
      "\tspeed: 0.0429s/iter; left time: 43.7978s\n",
      "\titers: 200, epoch: 16 | loss: 0.0628044\n",
      "\tspeed: 0.0220s/iter; left time: 20.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0612560 Vali Loss: 0.0798668 Test Loss: 0.0918402\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.024410352110862732, rmse:0.1562381237745285, mae:0.09024864435195923, rse:0.6043705940246582\n",
      "Intermediate time for FR and pred_len 96: 00h:04m:10.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2450827\n",
      "\tspeed: 0.0428s/iter; left time: 186.5673s\n",
      "\titers: 200, epoch: 1 | loss: 0.2232394\n",
      "\tspeed: 0.0222s/iter; left time: 94.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 223 | Train Loss: 0.2425776 Vali Loss: 0.1851182 Test Loss: 0.1906380\n",
      "Validation loss decreased (inf --> 0.185118).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1263140\n",
      "\tspeed: 0.0481s/iter; left time: 199.2159s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105815\n",
      "\tspeed: 0.0225s/iter; left time: 90.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.1306283 Vali Loss: 0.1178915 Test Loss: 0.1303284\n",
      "Validation loss decreased (0.185118 --> 0.117892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0894098\n",
      "\tspeed: 0.0495s/iter; left time: 193.6382s\n",
      "\titers: 200, epoch: 3 | loss: 0.0884992\n",
      "\tspeed: 0.0236s/iter; left time: 90.1023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 223 | Train Loss: 0.0891048 Vali Loss: 0.0974357 Test Loss: 0.1104511\n",
      "Validation loss decreased (0.117892 --> 0.097436).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0789324\n",
      "\tspeed: 0.0479s/iter; left time: 176.8268s\n",
      "\titers: 200, epoch: 4 | loss: 0.0726246\n",
      "\tspeed: 0.0221s/iter; left time: 79.4852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0823288 Vali Loss: 0.0989923 Test Loss: 0.1118010\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791261\n",
      "\tspeed: 0.0455s/iter; left time: 157.7964s\n",
      "\titers: 200, epoch: 5 | loss: 0.0725767\n",
      "\tspeed: 0.0223s/iter; left time: 75.1616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0744926 Vali Loss: 0.0980025 Test Loss: 0.1128348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753126\n",
      "\tspeed: 0.0450s/iter; left time: 146.0671s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721922\n",
      "\tspeed: 0.0222s/iter; left time: 69.9884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0730602 Vali Loss: 0.1001740 Test Loss: 0.1147152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0693790\n",
      "\tspeed: 0.0446s/iter; left time: 134.8641s\n",
      "\titers: 200, epoch: 7 | loss: 0.0719367\n",
      "\tspeed: 0.0221s/iter; left time: 64.6470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0707280 Vali Loss: 0.1044237 Test Loss: 0.1229521\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0710538\n",
      "\tspeed: 0.0439s/iter; left time: 122.8373s\n",
      "\titers: 200, epoch: 8 | loss: 0.0700390\n",
      "\tspeed: 0.0222s/iter; left time: 60.0270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0711045 Vali Loss: 0.0921897 Test Loss: 0.1092077\n",
      "Validation loss decreased (0.097436 --> 0.092190).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0678998\n",
      "\tspeed: 0.0460s/iter; left time: 118.4789s\n",
      "\titers: 200, epoch: 9 | loss: 0.0627986\n",
      "\tspeed: 0.0221s/iter; left time: 54.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0680211 Vali Loss: 0.0882488 Test Loss: 0.1041000\n",
      "Validation loss decreased (0.092190 --> 0.088249).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0664097\n",
      "\tspeed: 0.0458s/iter; left time: 107.8735s\n",
      "\titers: 200, epoch: 10 | loss: 0.0654123\n",
      "\tspeed: 0.0221s/iter; left time: 49.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0677171 Vali Loss: 0.0896360 Test Loss: 0.1058916\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0662063\n",
      "\tspeed: 0.0440s/iter; left time: 93.6960s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664764\n",
      "\tspeed: 0.0228s/iter; left time: 46.2249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0668746 Vali Loss: 0.0881367 Test Loss: 0.1048586\n",
      "Validation loss decreased (0.088249 --> 0.088137).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0672655\n",
      "\tspeed: 0.0469s/iter; left time: 89.5499s\n",
      "\titers: 200, epoch: 12 | loss: 0.1237411\n",
      "\tspeed: 0.0230s/iter; left time: 41.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0676209 Vali Loss: 0.0914715 Test Loss: 0.1078338\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718676\n",
      "\tspeed: 0.0443s/iter; left time: 74.6867s\n",
      "\titers: 200, epoch: 13 | loss: 0.0653212\n",
      "\tspeed: 0.0222s/iter; left time: 35.1284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0668662 Vali Loss: 0.0878323 Test Loss: 0.1035503\n",
      "Validation loss decreased (0.088137 --> 0.087832).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0678798\n",
      "\tspeed: 0.0462s/iter; left time: 67.5382s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605167\n",
      "\tspeed: 0.0236s/iter; left time: 32.1448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0652489 Vali Loss: 0.0857076 Test Loss: 0.1016851\n",
      "Validation loss decreased (0.087832 --> 0.085708).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0646477\n",
      "\tspeed: 0.0454s/iter; left time: 56.2195s\n",
      "\titers: 200, epoch: 15 | loss: 0.0643937\n",
      "\tspeed: 0.0222s/iter; left time: 25.2755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0650849 Vali Loss: 0.0874076 Test Loss: 0.1049856\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0643480\n",
      "\tspeed: 0.0444s/iter; left time: 45.0833s\n",
      "\titers: 200, epoch: 16 | loss: 0.0665739\n",
      "\tspeed: 0.0222s/iter; left time: 20.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0644672 Vali Loss: 0.0880397 Test Loss: 0.1050579\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0665336\n",
      "\tspeed: 0.0443s/iter; left time: 35.1010s\n",
      "\titers: 200, epoch: 17 | loss: 0.0641688\n",
      "\tspeed: 0.0222s/iter; left time: 15.4019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0638258 Vali Loss: 0.0893924 Test Loss: 0.1074544\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0663109\n",
      "\tspeed: 0.0442s/iter; left time: 25.1869s\n",
      "\titers: 200, epoch: 18 | loss: 0.0638131\n",
      "\tspeed: 0.0221s/iter; left time: 10.4103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0635449 Vali Loss: 0.0882289 Test Loss: 0.1052522\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0640724\n",
      "\tspeed: 0.0444s/iter; left time: 15.3929s\n",
      "\titers: 200, epoch: 19 | loss: 0.0634638\n",
      "\tspeed: 0.0222s/iter; left time: 5.4912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0636200 Vali Loss: 0.0876704 Test Loss: 0.1039964\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.028948942199349403, rmse:0.17014388740062714, mae:0.10168507695198059, rse:0.6589833498001099\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2393148\n",
      "\tspeed: 0.0241s/iter; left time: 104.9230s\n",
      "\titers: 200, epoch: 1 | loss: 0.2251539\n",
      "\tspeed: 0.0222s/iter; left time: 94.7472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.2437242 Vali Loss: 0.1837633 Test Loss: 0.1894132\n",
      "Validation loss decreased (inf --> 0.183763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1222711\n",
      "\tspeed: 0.0493s/iter; left time: 203.8594s\n",
      "\titers: 200, epoch: 2 | loss: 0.0992713\n",
      "\tspeed: 0.0223s/iter; left time: 89.9731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.1284960 Vali Loss: 0.1039123 Test Loss: 0.1181367\n",
      "Validation loss decreased (0.183763 --> 0.103912).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0874233\n",
      "\tspeed: 0.0456s/iter; left time: 178.5631s\n",
      "\titers: 200, epoch: 3 | loss: 0.0850490\n",
      "\tspeed: 0.0237s/iter; left time: 90.3683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 223 | Train Loss: 0.0900394 Vali Loss: 0.0887873 Test Loss: 0.1049814\n",
      "Validation loss decreased (0.103912 --> 0.088787).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1153088\n",
      "\tspeed: 0.0459s/iter; left time: 169.4738s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910632\n",
      "\tspeed: 0.0222s/iter; left time: 79.6186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0829122 Vali Loss: 0.0852180 Test Loss: 0.1014225\n",
      "Validation loss decreased (0.088787 --> 0.085218).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918156\n",
      "\tspeed: 0.0446s/iter; left time: 154.6200s\n",
      "\titers: 200, epoch: 5 | loss: 0.0734999\n",
      "\tspeed: 0.0222s/iter; left time: 74.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0773530 Vali Loss: 0.0883350 Test Loss: 0.1030016\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0689697\n",
      "\tspeed: 0.0469s/iter; left time: 152.2016s\n",
      "\titers: 200, epoch: 6 | loss: 0.0642136\n",
      "\tspeed: 0.0228s/iter; left time: 71.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0726183 Vali Loss: 0.0872648 Test Loss: 0.1007812\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0733844\n",
      "\tspeed: 0.0455s/iter; left time: 137.4770s\n",
      "\titers: 200, epoch: 7 | loss: 0.0677591\n",
      "\tspeed: 0.0221s/iter; left time: 64.7040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0725060 Vali Loss: 0.0919477 Test Loss: 0.1038592\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0632805\n",
      "\tspeed: 0.0436s/iter; left time: 121.9409s\n",
      "\titers: 200, epoch: 8 | loss: 0.0642115\n",
      "\tspeed: 0.0221s/iter; left time: 59.7680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0687425 Vali Loss: 0.0845239 Test Loss: 0.0980092\n",
      "Validation loss decreased (0.085218 --> 0.084524).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0717224\n",
      "\tspeed: 0.0448s/iter; left time: 115.5181s\n",
      "\titers: 200, epoch: 9 | loss: 0.0677242\n",
      "\tspeed: 0.0222s/iter; left time: 54.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0701707 Vali Loss: 0.0879279 Test Loss: 0.1015858\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0652043\n",
      "\tspeed: 0.0434s/iter; left time: 102.1702s\n",
      "\titers: 200, epoch: 10 | loss: 0.0677404\n",
      "\tspeed: 0.0222s/iter; left time: 49.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0689476 Vali Loss: 0.0891008 Test Loss: 0.1024643\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0686301\n",
      "\tspeed: 0.0438s/iter; left time: 93.3299s\n",
      "\titers: 200, epoch: 11 | loss: 0.0706209\n",
      "\tspeed: 0.0223s/iter; left time: 45.2950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0678396 Vali Loss: 0.0876408 Test Loss: 0.1000011\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0666585\n",
      "\tspeed: 0.0435s/iter; left time: 83.0872s\n",
      "\titers: 200, epoch: 12 | loss: 0.0647646\n",
      "\tspeed: 0.0221s/iter; left time: 40.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0664620 Vali Loss: 0.0892970 Test Loss: 0.1014474\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0686257\n",
      "\tspeed: 0.0446s/iter; left time: 75.1565s\n",
      "\titers: 200, epoch: 13 | loss: 0.0652345\n",
      "\tspeed: 0.0238s/iter; left time: 37.6901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0661453 Vali Loss: 0.0888269 Test Loss: 0.1024094\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.027923544868826866, rmse:0.16710339486598969, mae:0.09800918400287628, rse:0.6472072601318359\n",
      "Intermediate time for FR and pred_len 168: 00h:03m:47.22s\n",
      "Intermediate time for FR: 00h:11m:43.22s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2644858\n",
      "\tspeed: 0.0430s/iter; left time: 188.3081s\n",
      "\titers: 200, epoch: 1 | loss: 0.2525286\n",
      "\tspeed: 0.0220s/iter; left time: 94.1062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.2697739 Vali Loss: 0.1932511 Test Loss: 0.1934469\n",
      "Validation loss decreased (inf --> 0.193251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1653932\n",
      "\tspeed: 0.0455s/iter; left time: 189.2883s\n",
      "\titers: 200, epoch: 2 | loss: 0.1243809\n",
      "\tspeed: 0.0219s/iter; left time: 88.8215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.1634016 Vali Loss: 0.0901100 Test Loss: 0.0902622\n",
      "Validation loss decreased (0.193251 --> 0.090110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1136874\n",
      "\tspeed: 0.0444s/iter; left time: 174.7791s\n",
      "\titers: 200, epoch: 3 | loss: 0.0992532\n",
      "\tspeed: 0.0219s/iter; left time: 84.1210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.1082277 Vali Loss: 0.0900471 Test Loss: 0.0822559\n",
      "Validation loss decreased (0.090110 --> 0.090047).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0846324\n",
      "\tspeed: 0.0438s/iter; left time: 162.5900s\n",
      "\titers: 200, epoch: 4 | loss: 0.0896305\n",
      "\tspeed: 0.0219s/iter; left time: 79.1664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0872221 Vali Loss: 0.0748613 Test Loss: 0.0751619\n",
      "Validation loss decreased (0.090047 --> 0.074861).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0759350\n",
      "\tspeed: 0.0440s/iter; left time: 153.5076s\n",
      "\titers: 200, epoch: 5 | loss: 0.0688918\n",
      "\tspeed: 0.0219s/iter; left time: 74.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0775812 Vali Loss: 0.0721913 Test Loss: 0.0746255\n",
      "Validation loss decreased (0.074861 --> 0.072191).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0760107\n",
      "\tspeed: 0.0440s/iter; left time: 143.3217s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736323\n",
      "\tspeed: 0.0219s/iter; left time: 69.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0751104 Vali Loss: 0.0667890 Test Loss: 0.0665889\n",
      "Validation loss decreased (0.072191 --> 0.066789).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0697826\n",
      "\tspeed: 0.0440s/iter; left time: 133.6995s\n",
      "\titers: 200, epoch: 7 | loss: 0.0676500\n",
      "\tspeed: 0.0220s/iter; left time: 64.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0709417 Vali Loss: 0.0650752 Test Loss: 0.0643798\n",
      "Validation loss decreased (0.066789 --> 0.065075).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0727799\n",
      "\tspeed: 0.0432s/iter; left time: 121.4002s\n",
      "\titers: 200, epoch: 8 | loss: 0.0617668\n",
      "\tspeed: 0.0220s/iter; left time: 59.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0702671 Vali Loss: 0.0651257 Test Loss: 0.0670292\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0700698\n",
      "\tspeed: 0.0452s/iter; left time: 117.0586s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697164\n",
      "\tspeed: 0.0233s/iter; left time: 57.9545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0668713 Vali Loss: 0.0639733 Test Loss: 0.0671300\n",
      "Validation loss decreased (0.065075 --> 0.063973).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0712916\n",
      "\tspeed: 0.0439s/iter; left time: 103.9195s\n",
      "\titers: 200, epoch: 10 | loss: 0.0850901\n",
      "\tspeed: 0.0220s/iter; left time: 49.7660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0673222 Vali Loss: 0.0638646 Test Loss: 0.0652986\n",
      "Validation loss decreased (0.063973 --> 0.063865).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0650985\n",
      "\tspeed: 0.0436s/iter; left time: 93.2437s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640639\n",
      "\tspeed: 0.0219s/iter; left time: 44.7317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0653089 Vali Loss: 0.0634767 Test Loss: 0.0643057\n",
      "Validation loss decreased (0.063865 --> 0.063477).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0662407\n",
      "\tspeed: 0.0454s/iter; left time: 87.0932s\n",
      "\titers: 200, epoch: 12 | loss: 0.0645976\n",
      "\tspeed: 0.0219s/iter; left time: 39.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0666560 Vali Loss: 0.0618579 Test Loss: 0.0613874\n",
      "Validation loss decreased (0.063477 --> 0.061858).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0676636\n",
      "\tspeed: 0.0435s/iter; left time: 73.6014s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713414\n",
      "\tspeed: 0.0219s/iter; left time: 34.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0636472 Vali Loss: 0.0611089 Test Loss: 0.0613010\n",
      "Validation loss decreased (0.061858 --> 0.061109).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0630407\n",
      "\tspeed: 0.0440s/iter; left time: 64.6778s\n",
      "\titers: 200, epoch: 14 | loss: 0.0598784\n",
      "\tspeed: 0.0219s/iter; left time: 30.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0635762 Vali Loss: 0.0603308 Test Loss: 0.0613058\n",
      "Validation loss decreased (0.061109 --> 0.060331).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0624879\n",
      "\tspeed: 0.0438s/iter; left time: 54.5632s\n",
      "\titers: 200, epoch: 15 | loss: 0.0734186\n",
      "\tspeed: 0.0219s/iter; left time: 25.0411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0622689 Vali Loss: 0.0607864 Test Loss: 0.0623094\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0613480\n",
      "\tspeed: 0.0434s/iter; left time: 44.3447s\n",
      "\titers: 200, epoch: 16 | loss: 0.0593483\n",
      "\tspeed: 0.0219s/iter; left time: 20.1810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0616758 Vali Loss: 0.0601074 Test Loss: 0.0616837\n",
      "Validation loss decreased (0.060331 --> 0.060107).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0637593\n",
      "\tspeed: 0.0435s/iter; left time: 34.6874s\n",
      "\titers: 200, epoch: 17 | loss: 0.0584749\n",
      "\tspeed: 0.0220s/iter; left time: 15.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0616735 Vali Loss: 0.0595909 Test Loss: 0.0606947\n",
      "Validation loss decreased (0.060107 --> 0.059591).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0605917\n",
      "\tspeed: 0.0441s/iter; left time: 25.2690s\n",
      "\titers: 200, epoch: 18 | loss: 0.0652699\n",
      "\tspeed: 0.0219s/iter; left time: 10.3618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0610312 Vali Loss: 0.0595370 Test Loss: 0.0616706\n",
      "Validation loss decreased (0.059591 --> 0.059537).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0632215\n",
      "\tspeed: 0.0499s/iter; left time: 17.4163s\n",
      "\titers: 200, epoch: 19 | loss: 0.0609598\n",
      "\tspeed: 0.0226s/iter; left time: 5.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0601916 Vali Loss: 0.0588899 Test Loss: 0.0610462\n",
      "Validation loss decreased (0.059537 --> 0.058890).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0579334\n",
      "\tspeed: 0.0442s/iter; left time: 5.5254s\n",
      "\titers: 200, epoch: 20 | loss: 0.0613532\n",
      "\tspeed: 0.0219s/iter; left time: 0.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0607767 Vali Loss: 0.0592128 Test Loss: 0.0604090\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010517884977161884, rmse:0.1025567427277565, mae:0.061046164482831955, rse:0.3875114321708679\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2616690\n",
      "\tspeed: 0.0236s/iter; left time: 103.3111s\n",
      "\titers: 200, epoch: 1 | loss: 0.2577299\n",
      "\tspeed: 0.0227s/iter; left time: 97.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.2712010 Vali Loss: 0.1948339 Test Loss: 0.1942110\n",
      "Validation loss decreased (inf --> 0.194834).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645562\n",
      "\tspeed: 0.0434s/iter; left time: 180.2400s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265022\n",
      "\tspeed: 0.0219s/iter; left time: 88.8841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.1653373 Vali Loss: 0.0953222 Test Loss: 0.0951285\n",
      "Validation loss decreased (0.194834 --> 0.095322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1060924\n",
      "\tspeed: 0.0435s/iter; left time: 170.8907s\n",
      "\titers: 200, epoch: 3 | loss: 0.0990390\n",
      "\tspeed: 0.0220s/iter; left time: 84.3282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.1084975 Vali Loss: 0.0877712 Test Loss: 0.0797486\n",
      "Validation loss decreased (0.095322 --> 0.087771).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0844334\n",
      "\tspeed: 0.0435s/iter; left time: 161.4855s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768000\n",
      "\tspeed: 0.0220s/iter; left time: 79.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0866212 Vali Loss: 0.0733217 Test Loss: 0.0717105\n",
      "Validation loss decreased (0.087771 --> 0.073322).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0771845\n",
      "\tspeed: 0.0433s/iter; left time: 150.9204s\n",
      "\titers: 200, epoch: 5 | loss: 0.0728950\n",
      "\tspeed: 0.0219s/iter; left time: 74.0097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0770658 Vali Loss: 0.0728356 Test Loss: 0.0730916\n",
      "Validation loss decreased (0.073322 --> 0.072836).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0791636\n",
      "\tspeed: 0.0447s/iter; left time: 145.7642s\n",
      "\titers: 200, epoch: 6 | loss: 0.0704616\n",
      "\tspeed: 0.0219s/iter; left time: 69.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0733234 Vali Loss: 0.0718773 Test Loss: 0.0699946\n",
      "Validation loss decreased (0.072836 --> 0.071877).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0647813\n",
      "\tspeed: 0.0429s/iter; left time: 130.3531s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664929\n",
      "\tspeed: 0.0219s/iter; left time: 64.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0687425 Vali Loss: 0.0647166 Test Loss: 0.0646714\n",
      "Validation loss decreased (0.071877 --> 0.064717).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0687204\n",
      "\tspeed: 0.0430s/iter; left time: 120.9758s\n",
      "\titers: 200, epoch: 8 | loss: 0.0687477\n",
      "\tspeed: 0.0225s/iter; left time: 61.0394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0695530 Vali Loss: 0.0670445 Test Loss: 0.0672540\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0689678\n",
      "\tspeed: 0.0439s/iter; left time: 113.6898s\n",
      "\titers: 200, epoch: 9 | loss: 0.0657141\n",
      "\tspeed: 0.0221s/iter; left time: 54.9454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0672086 Vali Loss: 0.0651749 Test Loss: 0.0653277\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0641778\n",
      "\tspeed: 0.0417s/iter; left time: 98.6686s\n",
      "\titers: 200, epoch: 10 | loss: 0.0646603\n",
      "\tspeed: 0.0220s/iter; left time: 49.8015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0657642 Vali Loss: 0.0631435 Test Loss: 0.0641546\n",
      "Validation loss decreased (0.064717 --> 0.063143).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0686169\n",
      "\tspeed: 0.0447s/iter; left time: 95.6756s\n",
      "\titers: 200, epoch: 11 | loss: 0.0603649\n",
      "\tspeed: 0.0231s/iter; left time: 47.0485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0643690 Vali Loss: 0.0603439 Test Loss: 0.0625303\n",
      "Validation loss decreased (0.063143 --> 0.060344).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0591850\n",
      "\tspeed: 0.0435s/iter; left time: 83.3841s\n",
      "\titers: 200, epoch: 12 | loss: 0.0624043\n",
      "\tspeed: 0.0219s/iter; left time: 39.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0631572 Vali Loss: 0.0603744 Test Loss: 0.0632560\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0601538\n",
      "\tspeed: 0.0421s/iter; left time: 71.2735s\n",
      "\titers: 200, epoch: 13 | loss: 0.0628299\n",
      "\tspeed: 0.0219s/iter; left time: 34.9027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0626518 Vali Loss: 0.0582887 Test Loss: 0.0621652\n",
      "Validation loss decreased (0.060344 --> 0.058289).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0645716\n",
      "\tspeed: 0.0433s/iter; left time: 63.6489s\n",
      "\titers: 200, epoch: 14 | loss: 0.0652576\n",
      "\tspeed: 0.0219s/iter; left time: 29.9250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0620676 Vali Loss: 0.0591243 Test Loss: 0.0627315\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0602157\n",
      "\tspeed: 0.0428s/iter; left time: 53.3279s\n",
      "\titers: 200, epoch: 15 | loss: 0.0670046\n",
      "\tspeed: 0.0219s/iter; left time: 25.0622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0621807 Vali Loss: 0.0604780 Test Loss: 0.0624099\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0621572\n",
      "\tspeed: 0.0419s/iter; left time: 42.7577s\n",
      "\titers: 200, epoch: 16 | loss: 0.0551633\n",
      "\tspeed: 0.0219s/iter; left time: 20.1743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0615664 Vali Loss: 0.0651473 Test Loss: 0.0634937\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0688966\n",
      "\tspeed: 0.0423s/iter; left time: 33.7128s\n",
      "\titers: 200, epoch: 17 | loss: 0.0677648\n",
      "\tspeed: 0.0232s/iter; left time: 16.1357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0618339 Vali Loss: 0.0577654 Test Loss: 0.0614785\n",
      "Validation loss decreased (0.058289 --> 0.057765).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0604759\n",
      "\tspeed: 0.0443s/iter; left time: 25.3771s\n",
      "\titers: 200, epoch: 18 | loss: 0.0625863\n",
      "\tspeed: 0.0219s/iter; left time: 10.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0609128 Vali Loss: 0.0585986 Test Loss: 0.0620717\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0613188\n",
      "\tspeed: 0.0425s/iter; left time: 14.8307s\n",
      "\titers: 200, epoch: 19 | loss: 0.0599678\n",
      "\tspeed: 0.0231s/iter; left time: 5.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0603439 Vali Loss: 0.0577445 Test Loss: 0.0613020\n",
      "Validation loss decreased (0.057765 --> 0.057744).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1265133\n",
      "\tspeed: 0.0441s/iter; left time: 5.5151s\n",
      "\titers: 200, epoch: 20 | loss: 0.0597734\n",
      "\tspeed: 0.0219s/iter; left time: 0.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0609015 Vali Loss: 0.0584780 Test Loss: 0.0618295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01060976181179285, rmse:0.10300369560718536, mae:0.061301980167627335, rse:0.38920024037361145\n",
      "Intermediate time for IT and pred_len 24: 00h:04m:33.25s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2678861\n",
      "\tspeed: 0.0419s/iter; left time: 183.4943s\n",
      "\titers: 200, epoch: 1 | loss: 0.2556669\n",
      "\tspeed: 0.0221s/iter; left time: 94.5900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.2770235 Vali Loss: 0.2032852 Test Loss: 0.2010552\n",
      "Validation loss decreased (inf --> 0.203285).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1725451\n",
      "\tspeed: 0.0464s/iter; left time: 192.8435s\n",
      "\titers: 200, epoch: 2 | loss: 0.1326063\n",
      "\tspeed: 0.0221s/iter; left time: 89.4979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.1703007 Vali Loss: 0.1097575 Test Loss: 0.1112346\n",
      "Validation loss decreased (0.203285 --> 0.109757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069967\n",
      "\tspeed: 0.0481s/iter; left time: 189.1849s\n",
      "\titers: 200, epoch: 3 | loss: 0.0998206\n",
      "\tspeed: 0.0243s/iter; left time: 93.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.1128902 Vali Loss: 0.0926980 Test Loss: 0.0971389\n",
      "Validation loss decreased (0.109757 --> 0.092698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857075\n",
      "\tspeed: 0.0477s/iter; left time: 177.0143s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954103\n",
      "\tspeed: 0.0220s/iter; left time: 79.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0965898 Vali Loss: 0.0858996 Test Loss: 0.0936744\n",
      "Validation loss decreased (0.092698 --> 0.085900).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931517\n",
      "\tspeed: 0.0476s/iter; left time: 165.7622s\n",
      "\titers: 200, epoch: 5 | loss: 0.0981214\n",
      "\tspeed: 0.0226s/iter; left time: 76.3563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0927467 Vali Loss: 0.0893960 Test Loss: 0.0939581\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0895684\n",
      "\tspeed: 0.0470s/iter; left time: 153.2249s\n",
      "\titers: 200, epoch: 6 | loss: 0.0866774\n",
      "\tspeed: 0.0221s/iter; left time: 69.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0882037 Vali Loss: 0.0817460 Test Loss: 0.0887657\n",
      "Validation loss decreased (0.085900 --> 0.081746).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0837600\n",
      "\tspeed: 0.0457s/iter; left time: 138.6698s\n",
      "\titers: 200, epoch: 7 | loss: 0.0802160\n",
      "\tspeed: 0.0221s/iter; left time: 64.9076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0844118 Vali Loss: 0.0807597 Test Loss: 0.0864091\n",
      "Validation loss decreased (0.081746 --> 0.080760).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0860149\n",
      "\tspeed: 0.0451s/iter; left time: 126.8155s\n",
      "\titers: 200, epoch: 8 | loss: 0.0817288\n",
      "\tspeed: 0.0221s/iter; left time: 59.9428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0830574 Vali Loss: 0.0797342 Test Loss: 0.0876896\n",
      "Validation loss decreased (0.080760 --> 0.079734).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0922660\n",
      "\tspeed: 0.0456s/iter; left time: 118.1136s\n",
      "\titers: 200, epoch: 9 | loss: 0.0769206\n",
      "\tspeed: 0.0221s/iter; left time: 55.0139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0813511 Vali Loss: 0.0806066 Test Loss: 0.0895992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0785341\n",
      "\tspeed: 0.0444s/iter; left time: 104.9013s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783738\n",
      "\tspeed: 0.0221s/iter; left time: 50.1203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0806815 Vali Loss: 0.0792573 Test Loss: 0.0872566\n",
      "Validation loss decreased (0.079734 --> 0.079257).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0809444\n",
      "\tspeed: 0.0455s/iter; left time: 97.5014s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791757\n",
      "\tspeed: 0.0227s/iter; left time: 46.3660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0797711 Vali Loss: 0.0798893 Test Loss: 0.0880431\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0801159\n",
      "\tspeed: 0.0470s/iter; left time: 90.0293s\n",
      "\titers: 200, epoch: 12 | loss: 0.0787398\n",
      "\tspeed: 0.0221s/iter; left time: 40.1458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0808247 Vali Loss: 0.0791586 Test Loss: 0.0894406\n",
      "Validation loss decreased (0.079257 --> 0.079159).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0854876\n",
      "\tspeed: 0.0462s/iter; left time: 78.1744s\n",
      "\titers: 200, epoch: 13 | loss: 0.0742494\n",
      "\tspeed: 0.0221s/iter; left time: 35.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0788146 Vali Loss: 0.0813426 Test Loss: 0.0917747\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0799204\n",
      "\tspeed: 0.0460s/iter; left time: 67.6389s\n",
      "\titers: 200, epoch: 14 | loss: 0.0792594\n",
      "\tspeed: 0.0222s/iter; left time: 30.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0781279 Vali Loss: 0.0792173 Test Loss: 0.0888208\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0799895\n",
      "\tspeed: 0.0468s/iter; left time: 58.2573s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769653\n",
      "\tspeed: 0.0223s/iter; left time: 25.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0773005 Vali Loss: 0.0809927 Test Loss: 0.0910446\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0721111\n",
      "\tspeed: 0.0447s/iter; left time: 45.6176s\n",
      "\titers: 200, epoch: 16 | loss: 0.0796860\n",
      "\tspeed: 0.0221s/iter; left time: 20.3435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0768022 Vali Loss: 0.0801239 Test Loss: 0.0918634\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0758011\n",
      "\tspeed: 0.0449s/iter; left time: 35.7786s\n",
      "\titers: 200, epoch: 17 | loss: 0.0751005\n",
      "\tspeed: 0.0221s/iter; left time: 15.4298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0766982 Vali Loss: 0.0813362 Test Loss: 0.0920668\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02045058272778988, rmse:0.14300553500652313, mae:0.08944061398506165, rse:0.5407193899154663\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2744107\n",
      "\tspeed: 0.0240s/iter; left time: 105.3003s\n",
      "\titers: 200, epoch: 1 | loss: 0.2597336\n",
      "\tspeed: 0.0221s/iter; left time: 94.4631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.2789369 Vali Loss: 0.2040274 Test Loss: 0.2014670\n",
      "Validation loss decreased (inf --> 0.204027).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1673944\n",
      "\tspeed: 0.0449s/iter; left time: 186.6263s\n",
      "\titers: 200, epoch: 2 | loss: 0.1362840\n",
      "\tspeed: 0.0221s/iter; left time: 89.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.1695909 Vali Loss: 0.1190329 Test Loss: 0.1154322\n",
      "Validation loss decreased (0.204027 --> 0.119033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1096091\n",
      "\tspeed: 0.0471s/iter; left time: 185.2272s\n",
      "\titers: 200, epoch: 3 | loss: 0.1018378\n",
      "\tspeed: 0.0225s/iter; left time: 86.2877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.1110941 Vali Loss: 0.0905080 Test Loss: 0.0935550\n",
      "Validation loss decreased (0.119033 --> 0.090508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0914941\n",
      "\tspeed: 0.0512s/iter; left time: 190.0646s\n",
      "\titers: 200, epoch: 4 | loss: 0.0876786\n",
      "\tspeed: 0.0221s/iter; left time: 79.8236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0946844 Vali Loss: 0.0982393 Test Loss: 0.0958268\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0887321\n",
      "\tspeed: 0.0450s/iter; left time: 156.7475s\n",
      "\titers: 200, epoch: 5 | loss: 0.0862809\n",
      "\tspeed: 0.0232s/iter; left time: 78.5078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0904761 Vali Loss: 0.0930129 Test Loss: 0.0936024\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0818227\n",
      "\tspeed: 0.0439s/iter; left time: 143.2753s\n",
      "\titers: 200, epoch: 6 | loss: 0.0840514\n",
      "\tspeed: 0.0221s/iter; left time: 69.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0862363 Vali Loss: 0.0820779 Test Loss: 0.0903179\n",
      "Validation loss decreased (0.090508 --> 0.082078).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770592\n",
      "\tspeed: 0.0450s/iter; left time: 136.5623s\n",
      "\titers: 200, epoch: 7 | loss: 0.0821056\n",
      "\tspeed: 0.0221s/iter; left time: 64.8986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0845656 Vali Loss: 0.0816757 Test Loss: 0.0906315\n",
      "Validation loss decreased (0.082078 --> 0.081676).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823506\n",
      "\tspeed: 0.0454s/iter; left time: 127.7896s\n",
      "\titers: 200, epoch: 8 | loss: 0.0803395\n",
      "\tspeed: 0.0221s/iter; left time: 60.0097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0822360 Vali Loss: 0.0797999 Test Loss: 0.0895469\n",
      "Validation loss decreased (0.081676 --> 0.079800).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0790545\n",
      "\tspeed: 0.0449s/iter; left time: 116.3315s\n",
      "\titers: 200, epoch: 9 | loss: 0.0825170\n",
      "\tspeed: 0.0221s/iter; left time: 54.9066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0815986 Vali Loss: 0.0797294 Test Loss: 0.0901352\n",
      "Validation loss decreased (0.079800 --> 0.079729).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0814384\n",
      "\tspeed: 0.0452s/iter; left time: 106.9949s\n",
      "\titers: 200, epoch: 10 | loss: 0.0802344\n",
      "\tspeed: 0.0234s/iter; left time: 52.9570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0796865 Vali Loss: 0.0794256 Test Loss: 0.0888397\n",
      "Validation loss decreased (0.079729 --> 0.079426).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0796518\n",
      "\tspeed: 0.0474s/iter; left time: 101.4566s\n",
      "\titers: 200, epoch: 11 | loss: 0.0783373\n",
      "\tspeed: 0.0221s/iter; left time: 45.0330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0785491 Vali Loss: 0.0794486 Test Loss: 0.0903518\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0741438\n",
      "\tspeed: 0.0442s/iter; left time: 84.7818s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814474\n",
      "\tspeed: 0.0222s/iter; left time: 40.3212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0772360 Vali Loss: 0.0783494 Test Loss: 0.0911403\n",
      "Validation loss decreased (0.079426 --> 0.078349).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722096\n",
      "\tspeed: 0.0455s/iter; left time: 77.0235s\n",
      "\titers: 200, epoch: 13 | loss: 0.0802439\n",
      "\tspeed: 0.0221s/iter; left time: 35.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0769021 Vali Loss: 0.0793272 Test Loss: 0.0920936\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0692660\n",
      "\tspeed: 0.0447s/iter; left time: 65.7286s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751704\n",
      "\tspeed: 0.0225s/iter; left time: 30.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0754218 Vali Loss: 0.0789840 Test Loss: 0.0910401\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0776006\n",
      "\tspeed: 0.0447s/iter; left time: 55.6269s\n",
      "\titers: 200, epoch: 15 | loss: 0.0758078\n",
      "\tspeed: 0.0224s/iter; left time: 25.6775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0746425 Vali Loss: 0.0790471 Test Loss: 0.0904158\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0745141\n",
      "\tspeed: 0.0443s/iter; left time: 45.2488s\n",
      "\titers: 200, epoch: 16 | loss: 0.0755180\n",
      "\tspeed: 0.0224s/iter; left time: 20.6397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0741311 Vali Loss: 0.0795916 Test Loss: 0.0927281\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0744950\n",
      "\tspeed: 0.0444s/iter; left time: 35.4012s\n",
      "\titers: 200, epoch: 17 | loss: 0.0761095\n",
      "\tspeed: 0.0224s/iter; left time: 15.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0731692 Vali Loss: 0.0794279 Test Loss: 0.0915057\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021965112537145615, rmse:0.14820632338523865, mae:0.09114028513431549, rse:0.5603840351104736\n",
      "Intermediate time for IT and pred_len 96: 00h:04m:01.32s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2730416\n",
      "\tspeed: 0.0432s/iter; left time: 188.5021s\n",
      "\titers: 200, epoch: 1 | loss: 0.2592554\n",
      "\tspeed: 0.0222s/iter; left time: 94.7405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.2786405 Vali Loss: 0.2054210 Test Loss: 0.2011719\n",
      "Validation loss decreased (inf --> 0.205421).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1658103\n",
      "\tspeed: 0.0450s/iter; left time: 186.0428s\n",
      "\titers: 200, epoch: 2 | loss: 0.1352759\n",
      "\tspeed: 0.0224s/iter; left time: 90.3991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.1692526 Vali Loss: 0.1239768 Test Loss: 0.1202084\n",
      "Validation loss decreased (0.205421 --> 0.123977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1235937\n",
      "\tspeed: 0.0452s/iter; left time: 177.1377s\n",
      "\titers: 200, epoch: 3 | loss: 0.1068063\n",
      "\tspeed: 0.0223s/iter; left time: 84.9315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.1112624 Vali Loss: 0.1038054 Test Loss: 0.0999319\n",
      "Validation loss decreased (0.123977 --> 0.103805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915078\n",
      "\tspeed: 0.0458s/iter; left time: 169.2601s\n",
      "\titers: 200, epoch: 4 | loss: 0.0964072\n",
      "\tspeed: 0.0223s/iter; left time: 80.0859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0986349 Vali Loss: 0.0906630 Test Loss: 0.0964892\n",
      "Validation loss decreased (0.103805 --> 0.090663).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0849220\n",
      "\tspeed: 0.0454s/iter; left time: 157.3728s\n",
      "\titers: 200, epoch: 5 | loss: 0.0939386\n",
      "\tspeed: 0.0223s/iter; left time: 75.0482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0936691 Vali Loss: 0.0852127 Test Loss: 0.0943537\n",
      "Validation loss decreased (0.090663 --> 0.085213).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0871018\n",
      "\tspeed: 0.0448s/iter; left time: 145.2591s\n",
      "\titers: 200, epoch: 6 | loss: 0.0891406\n",
      "\tspeed: 0.0223s/iter; left time: 70.0593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0891017 Vali Loss: 0.0842781 Test Loss: 0.0928212\n",
      "Validation loss decreased (0.085213 --> 0.084278).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0888925\n",
      "\tspeed: 0.0448s/iter; left time: 135.5427s\n",
      "\titers: 200, epoch: 7 | loss: 0.1502620\n",
      "\tspeed: 0.0223s/iter; left time: 65.1293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0877358 Vali Loss: 0.0957610 Test Loss: 0.0949406\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0905250\n",
      "\tspeed: 0.0437s/iter; left time: 122.4332s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891334\n",
      "\tspeed: 0.0222s/iter; left time: 60.0615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0869272 Vali Loss: 0.0833202 Test Loss: 0.0946570\n",
      "Validation loss decreased (0.084278 --> 0.083320).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0818469\n",
      "\tspeed: 0.0452s/iter; left time: 116.4138s\n",
      "\titers: 200, epoch: 9 | loss: 0.0800102\n",
      "\tspeed: 0.0223s/iter; left time: 55.2812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0845862 Vali Loss: 0.0894172 Test Loss: 0.0978493\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0861173\n",
      "\tspeed: 0.0438s/iter; left time: 103.2038s\n",
      "\titers: 200, epoch: 10 | loss: 0.0850260\n",
      "\tspeed: 0.0222s/iter; left time: 50.1380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0846500 Vali Loss: 0.0839243 Test Loss: 0.0933235\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0817036\n",
      "\tspeed: 0.0440s/iter; left time: 93.7956s\n",
      "\titers: 200, epoch: 11 | loss: 0.0780879\n",
      "\tspeed: 0.0223s/iter; left time: 45.2152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827392 Vali Loss: 0.0832857 Test Loss: 0.0937812\n",
      "Validation loss decreased (0.083320 --> 0.083286).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0813625\n",
      "\tspeed: 0.0455s/iter; left time: 86.7714s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757814\n",
      "\tspeed: 0.0223s/iter; left time: 40.2828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0821611 Vali Loss: 0.0831051 Test Loss: 0.0944612\n",
      "Validation loss decreased (0.083286 --> 0.083105).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0813534\n",
      "\tspeed: 0.0447s/iter; left time: 75.2950s\n",
      "\titers: 200, epoch: 13 | loss: 0.0806212\n",
      "\tspeed: 0.0223s/iter; left time: 35.3178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0810789 Vali Loss: 0.0827165 Test Loss: 0.0954814\n",
      "Validation loss decreased (0.083105 --> 0.082716).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0777659\n",
      "\tspeed: 0.0467s/iter; left time: 68.2807s\n",
      "\titers: 200, epoch: 14 | loss: 0.0806790\n",
      "\tspeed: 0.0223s/iter; left time: 30.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0819149 Vali Loss: 0.0831785 Test Loss: 0.0968587\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0783155\n",
      "\tspeed: 0.0445s/iter; left time: 55.0792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0748747\n",
      "\tspeed: 0.0224s/iter; left time: 25.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0805248 Vali Loss: 0.0831031 Test Loss: 0.0960171\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0820770\n",
      "\tspeed: 0.0447s/iter; left time: 45.3772s\n",
      "\titers: 200, epoch: 16 | loss: 0.0764026\n",
      "\tspeed: 0.0224s/iter; left time: 20.4891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0793205 Vali Loss: 0.0829908 Test Loss: 0.0950366\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0809550\n",
      "\tspeed: 0.0433s/iter; left time: 34.3492s\n",
      "\titers: 200, epoch: 17 | loss: 0.0821369\n",
      "\tspeed: 0.0223s/iter; left time: 15.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0787383 Vali Loss: 0.0827974 Test Loss: 0.0967471\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0779091\n",
      "\tspeed: 0.0449s/iter; left time: 25.5865s\n",
      "\titers: 200, epoch: 18 | loss: 0.0825687\n",
      "\tspeed: 0.0224s/iter; left time: 10.5488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0782434 Vali Loss: 0.0829786 Test Loss: 0.0973720\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022476181387901306, rmse:0.14992058277130127, mae:0.09548146277666092, rse:0.5673926472663879\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2786283\n",
      "\tspeed: 0.0241s/iter; left time: 105.2090s\n",
      "\titers: 200, epoch: 1 | loss: 0.2623035\n",
      "\tspeed: 0.0223s/iter; left time: 95.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.2810908 Vali Loss: 0.2085833 Test Loss: 0.2036909\n",
      "Validation loss decreased (inf --> 0.208583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1602791\n",
      "\tspeed: 0.0486s/iter; left time: 201.3006s\n",
      "\titers: 200, epoch: 2 | loss: 0.1255490\n",
      "\tspeed: 0.0223s/iter; left time: 90.0044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 223 | Train Loss: 0.1648176 Vali Loss: 0.1360064 Test Loss: 0.1155227\n",
      "Validation loss decreased (0.208583 --> 0.136006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1087265\n",
      "\tspeed: 0.0457s/iter; left time: 178.8125s\n",
      "\titers: 200, epoch: 3 | loss: 0.0999855\n",
      "\tspeed: 0.0226s/iter; left time: 86.0704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.1091319 Vali Loss: 0.1022404 Test Loss: 0.0989347\n",
      "Validation loss decreased (0.136006 --> 0.102240).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0947517\n",
      "\tspeed: 0.0451s/iter; left time: 166.4307s\n",
      "\titers: 200, epoch: 4 | loss: 0.0928877\n",
      "\tspeed: 0.0223s/iter; left time: 79.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0961895 Vali Loss: 0.0874606 Test Loss: 0.0942407\n",
      "Validation loss decreased (0.102240 --> 0.087461).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0942169\n",
      "\tspeed: 0.0450s/iter; left time: 155.9336s\n",
      "\titers: 200, epoch: 5 | loss: 0.0860327\n",
      "\tspeed: 0.0225s/iter; left time: 75.7221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0912762 Vali Loss: 0.0891886 Test Loss: 0.0942474\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889476\n",
      "\tspeed: 0.0436s/iter; left time: 141.5513s\n",
      "\titers: 200, epoch: 6 | loss: 0.0912364\n",
      "\tspeed: 0.0223s/iter; left time: 70.2997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0885059 Vali Loss: 0.0866368 Test Loss: 0.0948643\n",
      "Validation loss decreased (0.087461 --> 0.086637).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0866606\n",
      "\tspeed: 0.0448s/iter; left time: 135.3226s\n",
      "\titers: 200, epoch: 7 | loss: 0.0857783\n",
      "\tspeed: 0.0223s/iter; left time: 65.1221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0877741 Vali Loss: 0.0848937 Test Loss: 0.0928090\n",
      "Validation loss decreased (0.086637 --> 0.084894).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0843493\n",
      "\tspeed: 0.0444s/iter; left time: 124.4301s\n",
      "\titers: 200, epoch: 8 | loss: 0.0832671\n",
      "\tspeed: 0.0223s/iter; left time: 60.2136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0860574 Vali Loss: 0.0842649 Test Loss: 0.0934985\n",
      "Validation loss decreased (0.084894 --> 0.084265).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0859894\n",
      "\tspeed: 0.0447s/iter; left time: 115.1487s\n",
      "\titers: 200, epoch: 9 | loss: 0.0801199\n",
      "\tspeed: 0.0223s/iter; left time: 55.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0847294 Vali Loss: 0.0828027 Test Loss: 0.0962668\n",
      "Validation loss decreased (0.084265 --> 0.082803).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0868278\n",
      "\tspeed: 0.0448s/iter; left time: 105.5519s\n",
      "\titers: 200, epoch: 10 | loss: 0.0827358\n",
      "\tspeed: 0.0223s/iter; left time: 50.2428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0834973 Vali Loss: 0.0815120 Test Loss: 0.0920261\n",
      "Validation loss decreased (0.082803 --> 0.081512).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0858488\n",
      "\tspeed: 0.0453s/iter; left time: 96.5723s\n",
      "\titers: 200, epoch: 11 | loss: 0.0834687\n",
      "\tspeed: 0.0225s/iter; left time: 45.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0834233 Vali Loss: 0.0845529 Test Loss: 0.0950303\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0785937\n",
      "\tspeed: 0.0434s/iter; left time: 82.7426s\n",
      "\titers: 200, epoch: 12 | loss: 0.0840880\n",
      "\tspeed: 0.0223s/iter; left time: 40.2630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0822717 Vali Loss: 0.0825722 Test Loss: 0.0953230\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0786060\n",
      "\tspeed: 0.0433s/iter; left time: 72.9364s\n",
      "\titers: 200, epoch: 13 | loss: 0.0828456\n",
      "\tspeed: 0.0223s/iter; left time: 35.2866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0821805 Vali Loss: 0.0843168 Test Loss: 0.0938389\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0792990\n",
      "\tspeed: 0.0433s/iter; left time: 63.2904s\n",
      "\titers: 200, epoch: 14 | loss: 0.0804447\n",
      "\tspeed: 0.0223s/iter; left time: 30.3057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0818000 Vali Loss: 0.0821064 Test Loss: 0.0952276\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0805193\n",
      "\tspeed: 0.0432s/iter; left time: 53.4676s\n",
      "\titers: 200, epoch: 15 | loss: 0.0782928\n",
      "\tspeed: 0.0223s/iter; left time: 25.3516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0804257 Vali Loss: 0.0822731 Test Loss: 0.0942002\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02179568260908127, rmse:0.1476336121559143, mae:0.09202606976032257, rse:0.5587372779846191\n",
      "Intermediate time for IT and pred_len 168: 00h:03m:51.65s\n",
      "Intermediate time for IT: 00h:12m:26.22s\n",
      "Total time: 01h:04m:57.05s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_no_revin.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- RevIn &amp; CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>0.0935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>0.1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.0923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.1686</td>\n",
       "      <td>0.0998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>0.1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.0612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.0938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            - RevIn & CM                \n",
       "Metrics                   MSE    RMSE     MAE\n",
       "Country Pred_len                             \n",
       "DE      24             0.0213  0.1461  0.0935\n",
       "        96             0.0380  0.1949  0.1347\n",
       "        168            0.0452  0.2126  0.1463\n",
       "ES      24             0.0181  0.1343  0.0836\n",
       "        96             0.0519  0.2244  0.1451\n",
       "        168            0.0515  0.2258  0.1466\n",
       "FR      24             0.0139  0.1178  0.0665\n",
       "        96             0.0253  0.1592  0.0923\n",
       "        168            0.0284  0.1686  0.0998\n",
       "GB      24             0.0271  0.1646  0.1061\n",
       "        96             0.0501  0.2239  0.1519\n",
       "        168            0.0543  0.2329  0.1562\n",
       "IT      24             0.0106  0.1028  0.0612\n",
       "        96             0.0212  0.1456  0.0903\n",
       "        168            0.0221  0.1488  0.0938"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- RevIn & CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1185825\n",
      "\tspeed: 0.6688s/iter; left time: 2929.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1090781\n",
      "\tspeed: 0.6481s/iter; left time: 2774.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:25.38s\n",
      "Steps: 224 | Train Loss: 0.1187725 Vali Loss: 0.1100739 Test Loss: 0.1098653\n",
      "Validation loss decreased (inf --> 0.110074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894905\n",
      "\tspeed: 1.0742s/iter; left time: 4465.5195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864838\n",
      "\tspeed: 0.6444s/iter; left time: 2614.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:26.19s\n",
      "Steps: 224 | Train Loss: 0.0909381 Vali Loss: 0.1002815 Test Loss: 0.1011409\n",
      "Validation loss decreased (0.110074 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831252\n",
      "\tspeed: 1.0301s/iter; left time: 4051.2992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806472\n",
      "\tspeed: 0.6468s/iter; left time: 2479.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:25.18s\n",
      "Steps: 224 | Train Loss: 0.0837995 Vali Loss: 0.0962656 Test Loss: 0.0981424\n",
      "Validation loss decreased (0.100282 --> 0.096266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774977\n",
      "\tspeed: 1.0416s/iter; left time: 3863.3389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760295\n",
      "\tspeed: 0.6417s/iter; left time: 2315.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.62s\n",
      "Steps: 224 | Train Loss: 0.0802265 Vali Loss: 0.0948865 Test Loss: 0.0951428\n",
      "Validation loss decreased (0.096266 --> 0.094887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776035\n",
      "\tspeed: 1.0485s/iter; left time: 3653.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754470\n",
      "\tspeed: 0.6488s/iter; left time: 2196.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0781352 Vali Loss: 0.0920579 Test Loss: 0.0930737\n",
      "Validation loss decreased (0.094887 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768398\n",
      "\tspeed: 1.0371s/iter; left time: 3381.9026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745844\n",
      "\tspeed: 0.6492s/iter; left time: 2052.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0772739 Vali Loss: 0.0921749 Test Loss: 0.0929615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779816\n",
      "\tspeed: 1.0322s/iter; left time: 3134.9141s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759176\n",
      "\tspeed: 0.6528s/iter; left time: 1917.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:26.20s\n",
      "Steps: 224 | Train Loss: 0.0761425 Vali Loss: 0.0916203 Test Loss: 0.0923960\n",
      "Validation loss decreased (0.092058 --> 0.091620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725002\n",
      "\tspeed: 1.0339s/iter; left time: 2908.4458s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762453\n",
      "\tspeed: 0.6654s/iter; left time: 1805.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:26.01s\n",
      "Steps: 224 | Train Loss: 0.0752119 Vali Loss: 0.0908312 Test Loss: 0.0916540\n",
      "Validation loss decreased (0.091620 --> 0.090831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725041\n",
      "\tspeed: 1.0305s/iter; left time: 2667.9906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683068\n",
      "\tspeed: 0.6454s/iter; left time: 1606.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0745990 Vali Loss: 0.0904099 Test Loss: 0.0917372\n",
      "Validation loss decreased (0.090831 --> 0.090410).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700386\n",
      "\tspeed: 1.0345s/iter; left time: 2446.5496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721033\n",
      "\tspeed: 0.6512s/iter; left time: 1474.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:25.67s\n",
      "Steps: 224 | Train Loss: 0.0740525 Vali Loss: 0.0897951 Test Loss: 0.0912578\n",
      "Validation loss decreased (0.090410 --> 0.089795).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0666174\n",
      "\tspeed: 1.0623s/iter; left time: 2274.3769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760651\n",
      "\tspeed: 0.6506s/iter; left time: 1327.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:27.15s\n",
      "Steps: 224 | Train Loss: 0.0736123 Vali Loss: 0.0899318 Test Loss: 0.0916627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0749207\n",
      "\tspeed: 1.0237s/iter; left time: 1962.4604s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740589\n",
      "\tspeed: 0.7478s/iter; left time: 1358.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:02m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0732611 Vali Loss: 0.0894925 Test Loss: 0.0912984\n",
      "Validation loss decreased (0.089795 --> 0.089493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0752842\n",
      "\tspeed: 1.2674s/iter; left time: 2145.6531s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713753\n",
      "\tspeed: 0.8199s/iter; left time: 1306.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:02m:58.25s\n",
      "Steps: 224 | Train Loss: 0.0728936 Vali Loss: 0.0895770 Test Loss: 0.0911928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732628\n",
      "\tspeed: 1.4032s/iter; left time: 2061.2683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0704660\n",
      "\tspeed: 0.7742s/iter; left time: 1059.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:02m:53.68s\n",
      "Steps: 224 | Train Loss: 0.0725533 Vali Loss: 0.0897301 Test Loss: 0.0914722\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720317\n",
      "\tspeed: 1.3729s/iter; left time: 1709.2980s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720388\n",
      "\tspeed: 0.7695s/iter; left time: 881.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:00.35s\n",
      "Steps: 224 | Train Loss: 0.0724398 Vali Loss: 0.0893662 Test Loss: 0.0911104\n",
      "Validation loss decreased (0.089493 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741066\n",
      "\tspeed: 1.4951s/iter; left time: 1526.4775s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676593\n",
      "\tspeed: 0.8263s/iter; left time: 761.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0721958 Vali Loss: 0.0895748 Test Loss: 0.0918992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727639\n",
      "\tspeed: 1.3470s/iter; left time: 1073.5445s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744767\n",
      "\tspeed: 0.8282s/iter; left time: 577.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0720195 Vali Loss: 0.0894382 Test Loss: 0.0920587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706366\n",
      "\tspeed: 1.3400s/iter; left time: 767.7954s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681392\n",
      "\tspeed: 0.7862s/iter; left time: 371.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:00.68s\n",
      "Steps: 224 | Train Loss: 0.0717208 Vali Loss: 0.0891432 Test Loss: 0.0911035\n",
      "Validation loss decreased (0.089366 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0646649\n",
      "\tspeed: 1.3424s/iter; left time: 468.4852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705285\n",
      "\tspeed: 0.8197s/iter; left time: 204.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:02.57s\n",
      "Steps: 224 | Train Loss: 0.0716752 Vali Loss: 0.0893801 Test Loss: 0.0916932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748916\n",
      "\tspeed: 1.3266s/iter; left time: 165.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762143\n",
      "\tspeed: 0.9504s/iter; left time: 23.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:03m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0715203 Vali Loss: 0.0894523 Test Loss: 0.0925765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1201662\n",
      "\tspeed: 0.6902s/iter; left time: 3023.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083984\n",
      "\tspeed: 0.8199s/iter; left time: 3510.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:51.51s\n",
      "Steps: 224 | Train Loss: 0.1197711 Vali Loss: 0.1104640 Test Loss: 0.1099900\n",
      "Validation loss decreased (inf --> 0.110464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871584\n",
      "\tspeed: 1.5188s/iter; left time: 6313.7035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852323\n",
      "\tspeed: 0.8325s/iter; left time: 3377.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0910880 Vali Loss: 0.0981202 Test Loss: 0.1009802\n",
      "Validation loss decreased (0.110464 --> 0.098120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853115\n",
      "\tspeed: 1.4874s/iter; left time: 5850.0365s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795056\n",
      "\tspeed: 0.8492s/iter; left time: 3254.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0834218 Vali Loss: 0.0952579 Test Loss: 0.0964131\n",
      "Validation loss decreased (0.098120 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764321\n",
      "\tspeed: 1.4849s/iter; left time: 5507.3214s\n",
      "\titers: 200, epoch: 4 | loss: 0.0704273\n",
      "\tspeed: 0.8500s/iter; left time: 3067.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.02s\n",
      "Steps: 224 | Train Loss: 0.0803541 Vali Loss: 0.0942130 Test Loss: 0.0944882\n",
      "Validation loss decreased (0.095258 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812252\n",
      "\tspeed: 1.4917s/iter; left time: 5198.6443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723357\n",
      "\tspeed: 0.8511s/iter; left time: 2880.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0780411 Vali Loss: 0.0926510 Test Loss: 0.0935687\n",
      "Validation loss decreased (0.094213 --> 0.092651).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0705587\n",
      "\tspeed: 1.4860s/iter; left time: 4845.7223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729282\n",
      "\tspeed: 0.8480s/iter; left time: 2680.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0770898 Vali Loss: 0.0913223 Test Loss: 0.0926111\n",
      "Validation loss decreased (0.092651 --> 0.091322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752742\n",
      "\tspeed: 1.4621s/iter; left time: 4440.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756757\n",
      "\tspeed: 0.8388s/iter; left time: 2463.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0762828 Vali Loss: 0.0902402 Test Loss: 0.0915751\n",
      "Validation loss decreased (0.091322 --> 0.090240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777563\n",
      "\tspeed: 1.4495s/iter; left time: 4077.5128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748446\n",
      "\tspeed: 0.8418s/iter; left time: 2283.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0754152 Vali Loss: 0.0899461 Test Loss: 0.0914084\n",
      "Validation loss decreased (0.090240 --> 0.089946).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721380\n",
      "\tspeed: 1.4680s/iter; left time: 3800.5822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728657\n",
      "\tspeed: 0.8333s/iter; left time: 2074.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0746742 Vali Loss: 0.0903633 Test Loss: 0.0908017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710530\n",
      "\tspeed: 1.4918s/iter; left time: 3528.1873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705148\n",
      "\tspeed: 0.8472s/iter; left time: 1919.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0740754 Vali Loss: 0.0897875 Test Loss: 0.0912357\n",
      "Validation loss decreased (0.089946 --> 0.089788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720897\n",
      "\tspeed: 1.4902s/iter; left time: 3190.4692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687625\n",
      "\tspeed: 0.8463s/iter; left time: 1727.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0735199 Vali Loss: 0.0899521 Test Loss: 0.0915615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725851\n",
      "\tspeed: 1.4774s/iter; left time: 2832.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756204\n",
      "\tspeed: 0.8193s/iter; left time: 1488.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0731441 Vali Loss: 0.0894233 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.089788 --> 0.089423).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718960\n",
      "\tspeed: 1.4565s/iter; left time: 2465.8815s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757970\n",
      "\tspeed: 0.8378s/iter; left time: 1334.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0727348 Vali Loss: 0.0896581 Test Loss: 0.0914745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0716447\n",
      "\tspeed: 1.5150s/iter; left time: 2225.6009s\n",
      "\titers: 200, epoch: 14 | loss: 0.0759265\n",
      "\tspeed: 0.8626s/iter; left time: 1180.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.92s\n",
      "Steps: 224 | Train Loss: 0.0725364 Vali Loss: 0.0889910 Test Loss: 0.0906905\n",
      "Validation loss decreased (0.089423 --> 0.088991).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730583\n",
      "\tspeed: 1.5198s/iter; left time: 1892.1442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691186\n",
      "\tspeed: 0.8478s/iter; left time: 970.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0723537 Vali Loss: 0.0896075 Test Loss: 0.0918515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0712389\n",
      "\tspeed: 1.4952s/iter; left time: 1526.6150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0701750\n",
      "\tspeed: 0.8390s/iter; left time: 772.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0719971 Vali Loss: 0.0890231 Test Loss: 0.0908993\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748366\n",
      "\tspeed: 1.4536s/iter; left time: 1158.4845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762918\n",
      "\tspeed: 0.8353s/iter; left time: 582.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0718654 Vali Loss: 0.0890983 Test Loss: 0.0911705\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735894\n",
      "\tspeed: 1.4531s/iter; left time: 832.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0716164\n",
      "\tspeed: 0.8461s/iter; left time: 400.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0716082 Vali Loss: 0.0896960 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675492\n",
      "\tspeed: 1.4522s/iter; left time: 506.8123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709308\n",
      "\tspeed: 0.8435s/iter; left time: 210.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0714599 Vali Loss: 0.0893303 Test Loss: 0.0912627\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
      "Intermediate time for DE and pred_len 24: 02h:17m:12.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1286584\n",
      "\tspeed: 0.9340s/iter; left time: 4091.8390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283274\n",
      "\tspeed: 0.8474s/iter; left time: 3627.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1345625 Vali Loss: 0.1315352 Test Loss: 0.1368086\n",
      "Validation loss decreased (inf --> 0.131535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160355\n",
      "\tspeed: 1.5376s/iter; left time: 6391.8059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159737\n",
      "\tspeed: 0.7543s/iter; left time: 3060.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:51.93s\n",
      "Steps: 224 | Train Loss: 0.1175694 Vali Loss: 0.1254385 Test Loss: 0.1331406\n",
      "Validation loss decreased (0.131535 --> 0.125439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108091\n",
      "\tspeed: 1.5735s/iter; left time: 6188.4592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1001122\n",
      "\tspeed: 0.8370s/iter; left time: 3208.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1085928 Vali Loss: 0.1210968 Test Loss: 0.1298962\n",
      "Validation loss decreased (0.125439 --> 0.121097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040234\n",
      "\tspeed: 1.5905s/iter; left time: 5899.3342s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003075\n",
      "\tspeed: 0.8453s/iter; left time: 3050.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1052479 Vali Loss: 0.1204925 Test Loss: 0.1286892\n",
      "Validation loss decreased (0.121097 --> 0.120492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077605\n",
      "\tspeed: 1.5720s/iter; left time: 5478.3663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053044\n",
      "\tspeed: 0.8029s/iter; left time: 2717.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:03.00s\n",
      "Steps: 224 | Train Loss: 0.1037430 Vali Loss: 0.1204495 Test Loss: 0.1279174\n",
      "Validation loss decreased (0.120492 --> 0.120449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021977\n",
      "\tspeed: 1.5619s/iter; left time: 5093.3130s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977674\n",
      "\tspeed: 0.7894s/iter; left time: 2495.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:59.61s\n",
      "Steps: 224 | Train Loss: 0.1024423 Vali Loss: 0.1194088 Test Loss: 0.1291354\n",
      "Validation loss decreased (0.120449 --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003975\n",
      "\tspeed: 1.5046s/iter; left time: 4569.3553s\n",
      "\titers: 200, epoch: 7 | loss: 0.1074992\n",
      "\tspeed: 0.8332s/iter; left time: 2447.0527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1017708 Vali Loss: 0.1194237 Test Loss: 0.1292074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023403\n",
      "\tspeed: 1.6401s/iter; left time: 4613.7078s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019197\n",
      "\tspeed: 0.8487s/iter; left time: 2302.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1011935 Vali Loss: 0.1189429 Test Loss: 0.1283226\n",
      "Validation loss decreased (0.119409 --> 0.118943).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991009\n",
      "\tspeed: 1.6411s/iter; left time: 4248.7852s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018876\n",
      "\tspeed: 0.8182s/iter; left time: 2036.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1006589 Vali Loss: 0.1188852 Test Loss: 0.1294801\n",
      "Validation loss decreased (0.118943 --> 0.118885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1020254\n",
      "\tspeed: 1.5694s/iter; left time: 3711.5246s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003808\n",
      "\tspeed: 0.8315s/iter; left time: 1883.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1001412 Vali Loss: 0.1185911 Test Loss: 0.1275851\n",
      "Validation loss decreased (0.118885 --> 0.118591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003736\n",
      "\tspeed: 1.5670s/iter; left time: 3355.0398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0996785\n",
      "\tspeed: 0.7831s/iter; left time: 1598.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0998360 Vali Loss: 0.1192170 Test Loss: 0.1295892\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1009651\n",
      "\tspeed: 1.6085s/iter; left time: 3083.4932s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002403\n",
      "\tspeed: 0.8107s/iter; left time: 1472.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0993493 Vali Loss: 0.1186539 Test Loss: 0.1287528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009898\n",
      "\tspeed: 1.5807s/iter; left time: 2676.0931s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007161\n",
      "\tspeed: 0.8221s/iter; left time: 1309.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0989542 Vali Loss: 0.1189050 Test Loss: 0.1297899\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981157\n",
      "\tspeed: 1.5740s/iter; left time: 2312.2567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043117\n",
      "\tspeed: 0.8439s/iter; left time: 1155.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0986829 Vali Loss: 0.1192963 Test Loss: 0.1300762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1003836\n",
      "\tspeed: 1.5546s/iter; left time: 1935.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967155\n",
      "\tspeed: 0.8249s/iter; left time: 944.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0983634 Vali Loss: 0.1188927 Test Loss: 0.1290997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364218\n",
      "\tspeed: 0.8214s/iter; left time: 3598.3893s\n",
      "\titers: 200, epoch: 1 | loss: 0.1313399\n",
      "\tspeed: 0.7984s/iter; left time: 3418.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.06s\n",
      "Steps: 224 | Train Loss: 0.1353756 Vali Loss: 0.1317179 Test Loss: 0.1366934\n",
      "Validation loss decreased (inf --> 0.131718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200846\n",
      "\tspeed: 1.6313s/iter; left time: 6781.3599s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105273\n",
      "\tspeed: 0.8539s/iter; left time: 3464.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:10.31s\n",
      "Steps: 224 | Train Loss: 0.1165046 Vali Loss: 0.1257103 Test Loss: 0.1339367\n",
      "Validation loss decreased (0.131718 --> 0.125710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135974\n",
      "\tspeed: 1.6437s/iter; left time: 6464.8500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066958\n",
      "\tspeed: 0.8525s/iter; left time: 3267.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:13.84s\n",
      "Steps: 224 | Train Loss: 0.1087123 Vali Loss: 0.1218007 Test Loss: 0.1306605\n",
      "Validation loss decreased (0.125710 --> 0.121801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062235\n",
      "\tspeed: 1.6802s/iter; left time: 6231.7454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1012442\n",
      "\tspeed: 0.8510s/iter; left time: 3071.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:12.08s\n",
      "Steps: 224 | Train Loss: 0.1057830 Vali Loss: 0.1204576 Test Loss: 0.1288750\n",
      "Validation loss decreased (0.121801 --> 0.120458).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029572\n",
      "\tspeed: 1.7320s/iter; left time: 6036.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097937\n",
      "\tspeed: 0.8764s/iter; left time: 2966.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.04s\n",
      "Steps: 224 | Train Loss: 0.1041747 Vali Loss: 0.1198968 Test Loss: 0.1290881\n",
      "Validation loss decreased (0.120458 --> 0.119897).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044354\n",
      "\tspeed: 1.7541s/iter; left time: 5720.0084s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042368\n",
      "\tspeed: 0.8483s/iter; left time: 2681.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.34s\n",
      "Steps: 224 | Train Loss: 0.1030439 Vali Loss: 0.1198872 Test Loss: 0.1294045\n",
      "Validation loss decreased (0.119897 --> 0.119887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028243\n",
      "\tspeed: 1.7801s/iter; left time: 5406.1527s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059746\n",
      "\tspeed: 0.8741s/iter; left time: 2567.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1019859 Vali Loss: 0.1196817 Test Loss: 0.1293018\n",
      "Validation loss decreased (0.119887 --> 0.119682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1014663\n",
      "\tspeed: 2.3313s/iter; left time: 6557.8122s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035754\n",
      "\tspeed: 0.7724s/iter; left time: 2095.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:38.54s\n",
      "Steps: 224 | Train Loss: 0.1013703 Vali Loss: 0.1194906 Test Loss: 0.1304186\n",
      "Validation loss decreased (0.119682 --> 0.119491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996586\n",
      "\tspeed: 1.5930s/iter; left time: 4124.2748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0992961\n",
      "\tspeed: 0.8279s/iter; left time: 2060.5846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1008033 Vali Loss: 0.1198257 Test Loss: 0.1310487\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048882\n",
      "\tspeed: 1.6737s/iter; left time: 3958.2572s\n",
      "\titers: 200, epoch: 10 | loss: 0.1055110\n",
      "\tspeed: 0.8171s/iter; left time: 1850.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1001401 Vali Loss: 0.1198027 Test Loss: 0.1308678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0972710\n",
      "\tspeed: 1.6763s/iter; left time: 3588.9164s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006895\n",
      "\tspeed: 0.8502s/iter; left time: 1735.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0996930 Vali Loss: 0.1197501 Test Loss: 0.1311171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987459\n",
      "\tspeed: 1.6857s/iter; left time: 3231.5802s\n",
      "\titers: 200, epoch: 12 | loss: 0.1033765\n",
      "\tspeed: 0.8450s/iter; left time: 1535.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0991635 Vali Loss: 0.1197549 Test Loss: 0.1314769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1000874\n",
      "\tspeed: 1.7511s/iter; left time: 2964.6524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997200\n",
      "\tspeed: 0.8513s/iter; left time: 1356.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0988495 Vali Loss: 0.1200454 Test Loss: 0.1321729\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038512662053108215, rmse:0.1962464302778244, mae:0.13041862845420837, rse:0.6949483156204224\n",
      "Intermediate time for DE and pred_len 96: 01h:57m:14.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1400413\n",
      "\tspeed: 0.8899s/iter; left time: 3880.7776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308107\n",
      "\tspeed: 0.8546s/iter; left time: 3641.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1382469 Vali Loss: 0.1349166 Test Loss: 0.1416962\n",
      "Validation loss decreased (inf --> 0.134917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1242591\n",
      "\tspeed: 1.8069s/iter; left time: 7476.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.1166725\n",
      "\tspeed: 0.8570s/iter; left time: 3460.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:14.33s\n",
      "Steps: 223 | Train Loss: 0.1226699 Vali Loss: 0.1295651 Test Loss: 0.1393560\n",
      "Validation loss decreased (0.134917 --> 0.129565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1153209\n",
      "\tspeed: 1.7485s/iter; left time: 6845.2142s\n",
      "\titers: 200, epoch: 3 | loss: 0.1126005\n",
      "\tspeed: 0.8771s/iter; left time: 3345.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:15.27s\n",
      "Steps: 223 | Train Loss: 0.1139000 Vali Loss: 0.1261486 Test Loss: 0.1358930\n",
      "Validation loss decreased (0.129565 --> 0.126149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062162\n",
      "\tspeed: 1.7090s/iter; left time: 6309.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107251\n",
      "\tspeed: 0.8831s/iter; left time: 3172.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:15.11s\n",
      "Steps: 223 | Train Loss: 0.1110505 Vali Loss: 0.1244184 Test Loss: 0.1335864\n",
      "Validation loss decreased (0.126149 --> 0.124418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1084757\n",
      "\tspeed: 1.7248s/iter; left time: 5983.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.1087421\n",
      "\tspeed: 0.8599s/iter; left time: 2897.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.65s\n",
      "Steps: 223 | Train Loss: 0.1094183 Vali Loss: 0.1241783 Test Loss: 0.1338822\n",
      "Validation loss decreased (0.124418 --> 0.124178).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141112\n",
      "\tspeed: 1.8323s/iter; left time: 5947.5092s\n",
      "\titers: 200, epoch: 6 | loss: 0.1091668\n",
      "\tspeed: 0.8817s/iter; left time: 2773.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:16.80s\n",
      "Steps: 223 | Train Loss: 0.1086366 Vali Loss: 0.1237398 Test Loss: 0.1352959\n",
      "Validation loss decreased (0.124178 --> 0.123740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1066006\n",
      "\tspeed: 1.8825s/iter; left time: 5690.6879s\n",
      "\titers: 200, epoch: 7 | loss: 0.1082050\n",
      "\tspeed: 0.8714s/iter; left time: 2547.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:18.07s\n",
      "Steps: 223 | Train Loss: 0.1077990 Vali Loss: 0.1234855 Test Loss: 0.1357112\n",
      "Validation loss decreased (0.123740 --> 0.123486).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045769\n",
      "\tspeed: 1.7335s/iter; left time: 4853.6769s\n",
      "\titers: 200, epoch: 8 | loss: 0.1086057\n",
      "\tspeed: 0.8623s/iter; left time: 2328.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.69s\n",
      "Steps: 223 | Train Loss: 0.1074179 Vali Loss: 0.1231780 Test Loss: 0.1348252\n",
      "Validation loss decreased (0.123486 --> 0.123178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 1.7192s/iter; left time: 4430.4052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060561\n",
      "\tspeed: 0.8545s/iter; left time: 2116.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:09.60s\n",
      "Steps: 223 | Train Loss: 0.1069891 Vali Loss: 0.1235725 Test Loss: 0.1355295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018216\n",
      "\tspeed: 1.7313s/iter; left time: 4075.4651s\n",
      "\titers: 200, epoch: 10 | loss: 0.1136913\n",
      "\tspeed: 0.8794s/iter; left time: 1982.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:14.36s\n",
      "Steps: 223 | Train Loss: 0.1066360 Vali Loss: 0.1234050 Test Loss: 0.1363396\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071401\n",
      "\tspeed: 1.7654s/iter; left time: 3762.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049976\n",
      "\tspeed: 0.8746s/iter; left time: 1776.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:14.34s\n",
      "Steps: 223 | Train Loss: 0.1062648 Vali Loss: 0.1234758 Test Loss: 0.1363748\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1055855\n",
      "\tspeed: 1.7604s/iter; left time: 3358.8136s\n",
      "\titers: 200, epoch: 12 | loss: 0.1099972\n",
      "\tspeed: 0.8517s/iter; left time: 1539.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:11.70s\n",
      "Steps: 223 | Train Loss: 0.1059586 Vali Loss: 0.1235797 Test Loss: 0.1368409\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016340\n",
      "\tspeed: 1.7306s/iter; left time: 2915.9802s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034260\n",
      "\tspeed: 0.8518s/iter; left time: 1350.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.89s\n",
      "Steps: 223 | Train Loss: 0.1056342 Vali Loss: 0.1233136 Test Loss: 0.1364277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.040120694786310196, rmse:0.20030151307582855, mae:0.13482515513896942, rse:0.7094841003417969\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343999\n",
      "\tspeed: 0.8474s/iter; left time: 3695.5296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272989\n",
      "\tspeed: 0.8469s/iter; left time: 3608.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1386628 Vali Loss: 0.1349369 Test Loss: 0.1415361\n",
      "Validation loss decreased (inf --> 0.134937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219488\n",
      "\tspeed: 1.7101s/iter; left time: 7076.1974s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157697\n",
      "\tspeed: 0.7994s/iter; left time: 3227.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1217117 Vali Loss: 0.1286630 Test Loss: 0.1371584\n",
      "Validation loss decreased (0.134937 --> 0.128663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1134495\n",
      "\tspeed: 1.6744s/iter; left time: 6555.3014s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091854\n",
      "\tspeed: 0.8857s/iter; left time: 3379.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:12.57s\n",
      "Steps: 223 | Train Loss: 0.1140187 Vali Loss: 0.1251376 Test Loss: 0.1358937\n",
      "Validation loss decreased (0.128663 --> 0.125138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115679\n",
      "\tspeed: 1.6663s/iter; left time: 6152.1628s\n",
      "\titers: 200, epoch: 4 | loss: 0.1115438\n",
      "\tspeed: 0.8562s/iter; left time: 3075.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:10.74s\n",
      "Steps: 223 | Train Loss: 0.1116452 Vali Loss: 0.1244681 Test Loss: 0.1350853\n",
      "Validation loss decreased (0.125138 --> 0.124468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106175\n",
      "\tspeed: 1.7480s/iter; left time: 6063.7318s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095825\n",
      "\tspeed: 0.8591s/iter; left time: 2894.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.89s\n",
      "Steps: 223 | Train Loss: 0.1102210 Vali Loss: 0.1239026 Test Loss: 0.1343044\n",
      "Validation loss decreased (0.124468 --> 0.123903).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118471\n",
      "\tspeed: 1.7579s/iter; left time: 5706.1713s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098318\n",
      "\tspeed: 0.8545s/iter; left time: 2688.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.79s\n",
      "Steps: 223 | Train Loss: 0.1090337 Vali Loss: 0.1244645 Test Loss: 0.1359817\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072461\n",
      "\tspeed: 1.8050s/iter; left time: 5456.6141s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047308\n",
      "\tspeed: 0.8728s/iter; left time: 2551.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.02s\n",
      "Steps: 223 | Train Loss: 0.1081847 Vali Loss: 0.1242444 Test Loss: 0.1349455\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977734\n",
      "\tspeed: 1.7448s/iter; left time: 4885.3021s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037813\n",
      "\tspeed: 0.8489s/iter; left time: 2292.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.29s\n",
      "Steps: 223 | Train Loss: 0.1075828 Vali Loss: 0.1239628 Test Loss: 0.1348020\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006511\n",
      "\tspeed: 1.7049s/iter; left time: 4393.5337s\n",
      "\titers: 200, epoch: 9 | loss: 0.1090960\n",
      "\tspeed: 0.8624s/iter; left time: 2136.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.65s\n",
      "Steps: 223 | Train Loss: 0.1071309 Vali Loss: 0.1239745 Test Loss: 0.1353526\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043709\n",
      "\tspeed: 1.6966s/iter; left time: 3993.7451s\n",
      "\titers: 200, epoch: 10 | loss: 0.1067678\n",
      "\tspeed: 0.8641s/iter; left time: 1947.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:13.35s\n",
      "Steps: 223 | Train Loss: 0.1066391 Vali Loss: 0.1235742 Test Loss: 0.1350486\n",
      "Validation loss decreased (0.123903 --> 0.123574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088294\n",
      "\tspeed: 1.7244s/iter; left time: 3674.6979s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030726\n",
      "\tspeed: 0.8540s/iter; left time: 1734.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:11.19s\n",
      "Steps: 223 | Train Loss: 0.1062802 Vali Loss: 0.1233648 Test Loss: 0.1349831\n",
      "Validation loss decreased (0.123574 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034573\n",
      "\tspeed: 1.8148s/iter; left time: 3462.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029600\n",
      "\tspeed: 0.8572s/iter; left time: 1549.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1059580 Vali Loss: 0.1236015 Test Loss: 0.1355882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1070623\n",
      "\tspeed: 1.7590s/iter; left time: 2963.9161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071535\n",
      "\tspeed: 0.8557s/iter; left time: 1356.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.45s\n",
      "Steps: 223 | Train Loss: 0.1056516 Vali Loss: 0.1236461 Test Loss: 0.1358070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007426\n",
      "\tspeed: 1.7315s/iter; left time: 2531.5073s\n",
      "\titers: 200, epoch: 14 | loss: 0.1061819\n",
      "\tspeed: 0.8401s/iter; left time: 1144.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.12s\n",
      "Steps: 223 | Train Loss: 0.1053684 Vali Loss: 0.1238686 Test Loss: 0.1371689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1087525\n",
      "\tspeed: 1.7272s/iter; left time: 2139.9453s\n",
      "\titers: 200, epoch: 15 | loss: 0.1041255\n",
      "\tspeed: 0.8668s/iter; left time: 987.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.73s\n",
      "Steps: 223 | Train Loss: 0.1050500 Vali Loss: 0.1236121 Test Loss: 0.1367470\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058608\n",
      "\tspeed: 1.7639s/iter; left time: 1792.1227s\n",
      "\titers: 200, epoch: 16 | loss: 0.1124790\n",
      "\tspeed: 0.8965s/iter; left time: 821.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:16.09s\n",
      "Steps: 223 | Train Loss: 0.1047191 Vali Loss: 0.1237539 Test Loss: 0.1365166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04019937664270401, rmse:0.2004978209733963, mae:0.1349831074476242, rse:0.7101793885231018\n",
      "Intermediate time for DE and pred_len 168: 02h:07m:10.52s\n",
      "Intermediate time for DE: 06h:21m:37.55s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116893\n",
      "\tspeed: 0.8959s/iter; left time: 3925.1028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038978\n",
      "\tspeed: 0.8831s/iter; left time: 3780.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:14.71s\n",
      "Steps: 224 | Train Loss: 0.1110849 Vali Loss: 0.1032261 Test Loss: 0.1155894\n",
      "Validation loss decreased (inf --> 0.103226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0890798\n",
      "\tspeed: 1.5255s/iter; left time: 6341.4464s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849172\n",
      "\tspeed: 0.8737s/iter; left time: 3544.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0889122 Vali Loss: 0.0968059 Test Loss: 0.1091108\n",
      "Validation loss decreased (0.103226 --> 0.096806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819009\n",
      "\tspeed: 1.5297s/iter; left time: 6016.2809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776293\n",
      "\tspeed: 0.8688s/iter; left time: 3330.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0812004 Vali Loss: 0.0940494 Test Loss: 0.1048684\n",
      "Validation loss decreased (0.096806 --> 0.094049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770025\n",
      "\tspeed: 1.5063s/iter; left time: 5586.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848865\n",
      "\tspeed: 0.8648s/iter; left time: 3121.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0796152 Vali Loss: 0.0937369 Test Loss: 0.1047043\n",
      "Validation loss decreased (0.094049 --> 0.093737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734676\n",
      "\tspeed: 1.5334s/iter; left time: 5343.9518s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762912\n",
      "\tspeed: 0.8661s/iter; left time: 2931.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0783571 Vali Loss: 0.0932249 Test Loss: 0.1037360\n",
      "Validation loss decreased (0.093737 --> 0.093225).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782692\n",
      "\tspeed: 1.4208s/iter; left time: 4633.1158s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721411\n",
      "\tspeed: 0.8070s/iter; left time: 2550.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:02.02s\n",
      "Steps: 224 | Train Loss: 0.0774817 Vali Loss: 0.0925879 Test Loss: 0.1041476\n",
      "Validation loss decreased (0.093225 --> 0.092588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812348\n",
      "\tspeed: 1.5342s/iter; left time: 4659.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759008\n",
      "\tspeed: 0.8840s/iter; left time: 2596.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0769514 Vali Loss: 0.0922961 Test Loss: 0.1031611\n",
      "Validation loss decreased (0.092588 --> 0.092296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749917\n",
      "\tspeed: 1.5055s/iter; left time: 4234.8770s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806865\n",
      "\tspeed: 0.8563s/iter; left time: 2323.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0766532 Vali Loss: 0.0923761 Test Loss: 0.1039077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769141\n",
      "\tspeed: 1.5225s/iter; left time: 3941.8340s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745924\n",
      "\tspeed: 0.8558s/iter; left time: 2130.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0921174 Test Loss: 0.1033806\n",
      "Validation loss decreased (0.092296 --> 0.092117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747170\n",
      "\tspeed: 1.4998s/iter; left time: 3546.9952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790516\n",
      "\tspeed: 0.8371s/iter; left time: 1895.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758396 Vali Loss: 0.0917899 Test Loss: 0.1031209\n",
      "Validation loss decreased (0.092117 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702004\n",
      "\tspeed: 1.4857s/iter; left time: 3180.9334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749110\n",
      "\tspeed: 0.8391s/iter; left time: 1712.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.92s\n",
      "Steps: 224 | Train Loss: 0.0755050 Vali Loss: 0.0919418 Test Loss: 0.1042525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728829\n",
      "\tspeed: 1.4704s/iter; left time: 2818.7016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757767\n",
      "\tspeed: 0.8425s/iter; left time: 1530.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0751960 Vali Loss: 0.0917938 Test Loss: 0.1037975\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698661\n",
      "\tspeed: 1.4651s/iter; left time: 2480.3355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741580\n",
      "\tspeed: 0.8403s/iter; left time: 1338.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0749474 Vali Loss: 0.0923169 Test Loss: 0.1042981\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734728\n",
      "\tspeed: 1.4869s/iter; left time: 2184.3007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667883\n",
      "\tspeed: 0.8433s/iter; left time: 1154.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0747666 Vali Loss: 0.0917064 Test Loss: 0.1039197\n",
      "Validation loss decreased (0.091790 --> 0.091706).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662220\n",
      "\tspeed: 1.4713s/iter; left time: 1831.7687s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799081\n",
      "\tspeed: 0.8449s/iter; left time: 967.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0746049 Vali Loss: 0.0917562 Test Loss: 0.1039334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779508\n",
      "\tspeed: 1.5109s/iter; left time: 1542.6142s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741158\n",
      "\tspeed: 0.8687s/iter; left time: 800.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0744549 Vali Loss: 0.0919189 Test Loss: 0.1040348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0742268\n",
      "\tspeed: 1.5145s/iter; left time: 1207.0217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780587\n",
      "\tspeed: 0.8582s/iter; left time: 598.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:11.58s\n",
      "Steps: 224 | Train Loss: 0.0742948 Vali Loss: 0.0919655 Test Loss: 0.1043945\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706386\n",
      "\tspeed: 1.5120s/iter; left time: 866.3568s\n",
      "\titers: 200, epoch: 18 | loss: 0.0753198\n",
      "\tspeed: 0.8484s/iter; left time: 401.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0741458 Vali Loss: 0.0919789 Test Loss: 0.1042754\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694558\n",
      "\tspeed: 1.3137s/iter; left time: 458.4893s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766510\n",
      "\tspeed: 0.6998s/iter; left time: 174.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:02m:44.93s\n",
      "Steps: 224 | Train Loss: 0.0740221 Vali Loss: 0.0918603 Test Loss: 0.1038902\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026621254161000252, rmse:0.16316020488739014, mae:0.10391969978809357, rse:0.5628564953804016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1084992\n",
      "\tspeed: 0.6800s/iter; left time: 2979.1896s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999074\n",
      "\tspeed: 0.6846s/iter; left time: 2930.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:33.04s\n",
      "Steps: 224 | Train Loss: 0.1116735 Vali Loss: 0.1036351 Test Loss: 0.1160170\n",
      "Validation loss decreased (inf --> 0.103635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0966203\n",
      "\tspeed: 1.2673s/iter; left time: 5268.3150s\n",
      "\titers: 200, epoch: 2 | loss: 0.0817607\n",
      "\tspeed: 0.8231s/iter; left time: 3339.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0888987 Vali Loss: 0.0972792 Test Loss: 0.1101744\n",
      "Validation loss decreased (0.103635 --> 0.097279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799150\n",
      "\tspeed: 1.4437s/iter; left time: 5677.8835s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805758\n",
      "\tspeed: 0.8110s/iter; left time: 3108.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0818355 Vali Loss: 0.0941807 Test Loss: 0.1062411\n",
      "Validation loss decreased (0.097279 --> 0.094181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784878\n",
      "\tspeed: 1.4282s/iter; left time: 5297.1938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763587\n",
      "\tspeed: 0.8138s/iter; left time: 2936.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:01.52s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0929848 Test Loss: 0.1047919\n",
      "Validation loss decreased (0.094181 --> 0.092985).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749025\n",
      "\tspeed: 1.3683s/iter; left time: 4768.4074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754450\n",
      "\tspeed: 0.8028s/iter; left time: 2717.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:58.70s\n",
      "Steps: 224 | Train Loss: 0.0782957 Vali Loss: 0.0929606 Test Loss: 0.1038269\n",
      "Validation loss decreased (0.092985 --> 0.092961).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793271\n",
      "\tspeed: 1.5037s/iter; left time: 4903.4140s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813081\n",
      "\tspeed: 0.8539s/iter; left time: 2699.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:12.12s\n",
      "Steps: 224 | Train Loss: 0.0773415 Vali Loss: 0.0923607 Test Loss: 0.1038644\n",
      "Validation loss decreased (0.092961 --> 0.092361).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782389\n",
      "\tspeed: 1.5050s/iter; left time: 4570.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773057\n",
      "\tspeed: 0.8308s/iter; left time: 2440.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769673 Vali Loss: 0.0921593 Test Loss: 0.1032822\n",
      "Validation loss decreased (0.092361 --> 0.092159).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770141\n",
      "\tspeed: 1.4834s/iter; left time: 4172.8993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750573\n",
      "\tspeed: 0.8219s/iter; left time: 2229.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0764386 Vali Loss: 0.0918024 Test Loss: 0.1035269\n",
      "Validation loss decreased (0.092159 --> 0.091802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0684199\n",
      "\tspeed: 1.4720s/iter; left time: 3811.0929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699812\n",
      "\tspeed: 0.8387s/iter; left time: 2087.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0761223 Vali Loss: 0.0920349 Test Loss: 0.1038026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787783\n",
      "\tspeed: 1.4548s/iter; left time: 3440.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783952\n",
      "\tspeed: 0.7669s/iter; left time: 1736.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:58.88s\n",
      "Steps: 224 | Train Loss: 0.0757484 Vali Loss: 0.0919563 Test Loss: 0.1029629\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753692\n",
      "\tspeed: 1.4349s/iter; left time: 3072.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728229\n",
      "\tspeed: 0.8486s/iter; left time: 1731.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0755147 Vali Loss: 0.0919968 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715075\n",
      "\tspeed: 1.5133s/iter; left time: 2900.9155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739322\n",
      "\tspeed: 0.8266s/iter; left time: 1501.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0752598 Vali Loss: 0.0923253 Test Loss: 0.1040638\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775367\n",
      "\tspeed: 1.4810s/iter; left time: 2507.3889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0789441\n",
      "\tspeed: 0.8396s/iter; left time: 1337.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0750797 Vali Loss: 0.0919649 Test Loss: 0.1041826\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02626371942460537, rmse:0.16206085681915283, mae:0.10352689772844315, rse:0.5590639710426331\n",
      "Intermediate time for GB and pred_len 24: 02h:03m:14.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252335\n",
      "\tspeed: 0.8947s/iter; left time: 3919.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201171\n",
      "\tspeed: 0.8332s/iter; left time: 3567.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1246595 Vali Loss: 0.1228046 Test Loss: 0.1431150\n",
      "Validation loss decreased (inf --> 0.122805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1149061\n",
      "\tspeed: 1.6577s/iter; left time: 6891.1368s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042059\n",
      "\tspeed: 0.8480s/iter; left time: 3440.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1117659 Vali Loss: 0.1201113 Test Loss: 0.1403482\n",
      "Validation loss decreased (0.122805 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069597\n",
      "\tspeed: 1.7151s/iter; left time: 6745.3664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021630\n",
      "\tspeed: 0.8387s/iter; left time: 3214.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.73s\n",
      "Steps: 224 | Train Loss: 0.1052783 Vali Loss: 0.1193737 Test Loss: 0.1403535\n",
      "Validation loss decreased (0.120111 --> 0.119374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045493\n",
      "\tspeed: 1.7337s/iter; left time: 6430.3361s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997706\n",
      "\tspeed: 0.8424s/iter; left time: 3040.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.74s\n",
      "Steps: 224 | Train Loss: 0.1036617 Vali Loss: 0.1194295 Test Loss: 0.1381266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030175\n",
      "\tspeed: 1.7161s/iter; left time: 5980.4878s\n",
      "\titers: 200, epoch: 5 | loss: 0.1078746\n",
      "\tspeed: 0.8664s/iter; left time: 2932.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.60s\n",
      "Steps: 224 | Train Loss: 0.1025570 Vali Loss: 0.1188874 Test Loss: 0.1394207\n",
      "Validation loss decreased (0.119374 --> 0.118887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021968\n",
      "\tspeed: 1.7392s/iter; left time: 5671.6279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011541\n",
      "\tspeed: 0.8588s/iter; left time: 2714.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:15.16s\n",
      "Steps: 224 | Train Loss: 0.1016647 Vali Loss: 0.1199620 Test Loss: 0.1390563\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985276\n",
      "\tspeed: 1.7798s/iter; left time: 5405.3696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043604\n",
      "\tspeed: 0.8527s/iter; left time: 2504.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:12.22s\n",
      "Steps: 224 | Train Loss: 0.1007115 Vali Loss: 0.1197896 Test Loss: 0.1403841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001039\n",
      "\tspeed: 1.7219s/iter; left time: 4843.8043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033350\n",
      "\tspeed: 0.8533s/iter; left time: 2315.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.03s\n",
      "Steps: 224 | Train Loss: 0.1001557 Vali Loss: 0.1202944 Test Loss: 0.1393946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982785\n",
      "\tspeed: 1.6656s/iter; left time: 4312.2334s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042185\n",
      "\tspeed: 0.8577s/iter; left time: 2134.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:10.93s\n",
      "Steps: 224 | Train Loss: 0.0997188 Vali Loss: 0.1200153 Test Loss: 0.1401132\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954204\n",
      "\tspeed: 1.7502s/iter; left time: 4139.2094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010626\n",
      "\tspeed: 0.8743s/iter; left time: 1980.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0993233 Vali Loss: 0.1199207 Test Loss: 0.1392622\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04243852570652962, rmse:0.20600612461566925, mae:0.13942068815231323, rse:0.7123979330062866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213994\n",
      "\tspeed: 0.8481s/iter; left time: 3715.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157816\n",
      "\tspeed: 0.8547s/iter; left time: 3659.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.57s\n",
      "Steps: 224 | Train Loss: 0.1246331 Vali Loss: 0.1226478 Test Loss: 0.1431716\n",
      "Validation loss decreased (inf --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097208\n",
      "\tspeed: 1.6775s/iter; left time: 6973.5719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1022605\n",
      "\tspeed: 0.8425s/iter; left time: 3417.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:09.36s\n",
      "Steps: 224 | Train Loss: 0.1115726 Vali Loss: 0.1201536 Test Loss: 0.1400796\n",
      "Validation loss decreased (0.122648 --> 0.120154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1016258\n",
      "\tspeed: 1.7072s/iter; left time: 6714.4824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017843\n",
      "\tspeed: 0.8483s/iter; left time: 3251.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:09.16s\n",
      "Steps: 224 | Train Loss: 0.1053649 Vali Loss: 0.1187505 Test Loss: 0.1394587\n",
      "Validation loss decreased (0.120154 --> 0.118751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072599\n",
      "\tspeed: 1.7390s/iter; left time: 6450.0632s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007376\n",
      "\tspeed: 0.8765s/iter; left time: 3163.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:16.15s\n",
      "Steps: 224 | Train Loss: 0.1034409 Vali Loss: 0.1196524 Test Loss: 0.1391735\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053430\n",
      "\tspeed: 1.7610s/iter; left time: 6137.0463s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057364\n",
      "\tspeed: 0.8451s/iter; left time: 2860.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.68s\n",
      "Steps: 224 | Train Loss: 0.1023294 Vali Loss: 0.1185409 Test Loss: 0.1385030\n",
      "Validation loss decreased (0.118751 --> 0.118541).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058340\n",
      "\tspeed: 1.6907s/iter; left time: 5513.3094s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048339\n",
      "\tspeed: 1.0748s/iter; left time: 3397.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:46.13s\n",
      "Steps: 224 | Train Loss: 0.1016991 Vali Loss: 0.1183163 Test Loss: 0.1388204\n",
      "Validation loss decreased (0.118541 --> 0.118316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021866\n",
      "\tspeed: 1.6960s/iter; left time: 5150.9019s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028333\n",
      "\tspeed: 0.7745s/iter; left time: 2274.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:54.27s\n",
      "Steps: 224 | Train Loss: 0.1008699 Vali Loss: 0.1182164 Test Loss: 0.1383967\n",
      "Validation loss decreased (0.118316 --> 0.118216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997323\n",
      "\tspeed: 1.7355s/iter; left time: 4881.9588s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055382\n",
      "\tspeed: 0.8556s/iter; left time: 2321.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:10.32s\n",
      "Steps: 224 | Train Loss: 0.1004637 Vali Loss: 0.1179797 Test Loss: 0.1388233\n",
      "Validation loss decreased (0.118216 --> 0.117980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006353\n",
      "\tspeed: 1.7252s/iter; left time: 4466.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000371\n",
      "\tspeed: 0.8375s/iter; left time: 2084.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.54s\n",
      "Steps: 224 | Train Loss: 0.1000307 Vali Loss: 0.1185631 Test Loss: 0.1388896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983968\n",
      "\tspeed: 1.7024s/iter; left time: 4026.1124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0981454\n",
      "\tspeed: 0.8492s/iter; left time: 1923.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0995587 Vali Loss: 0.1187217 Test Loss: 0.1394587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945402\n",
      "\tspeed: 1.6826s/iter; left time: 3602.5143s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004767\n",
      "\tspeed: 0.8392s/iter; left time: 1712.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0991112 Vali Loss: 0.1180590 Test Loss: 0.1385924\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008899\n",
      "\tspeed: 1.7303s/iter; left time: 3316.9489s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023057\n",
      "\tspeed: 0.8639s/iter; left time: 1569.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0988884 Vali Loss: 0.1189626 Test Loss: 0.1391280\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995492\n",
      "\tspeed: 1.7523s/iter; left time: 2966.6760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980858\n",
      "\tspeed: 0.8459s/iter; left time: 1347.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0985649 Vali Loss: 0.1183671 Test Loss: 0.1400267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04178399592638016, rmse:0.2044113427400589, mae:0.13882331550121307, rse:0.706882894039154\n",
      "Intermediate time for GB and pred_len 96: 01h:39m:54.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262437\n",
      "\tspeed: 0.8650s/iter; left time: 3772.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1255427\n",
      "\tspeed: 0.8030s/iter; left time: 3421.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.82s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize empty list\n",
    "patchtst_results = []\n",
    "\n",
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0380  0.1949  0.1290\n",
       "        168       0.0402  0.2004  0.1349\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1040  0.0585\n",
       "        96        0.0205  0.1432  0.0837\n",
       "        168       0.0216  0.1471  0.0878\n",
       "GB      24        0.0264  0.1626  0.1037\n",
       "        96        0.0421  0.2052  0.1391\n",
       "        168       0.0444  0.2106  0.1445\n",
       "IT      24        0.0109  0.1044  0.0594\n",
       "        96        0.0192  0.1387  0.0825\n",
       "        168       0.0202  0.1422  0.0865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1461562\n",
      "\tspeed: 0.0870s/iter; left time: 1939.9968s\n",
      "\titers: 200, epoch: 1 | loss: 0.1378466\n",
      "\tspeed: 0.0681s/iter; left time: 1512.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 224 | Train Loss: 0.1492350 Vali Loss: 0.1491234 Test Loss: 0.1573499\n",
      "Validation loss decreased (inf --> 0.149123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0934312\n",
      "\tspeed: 0.1174s/iter; left time: 2592.4927s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790701\n",
      "\tspeed: 0.0682s/iter; left time: 1498.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0957774 Vali Loss: 0.0962578 Test Loss: 0.0969347\n",
      "Validation loss decreased (0.149123 --> 0.096258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799299\n",
      "\tspeed: 0.1177s/iter; left time: 2571.7666s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831469\n",
      "\tspeed: 0.0682s/iter; left time: 1483.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0800204 Vali Loss: 0.0912525 Test Loss: 0.0925209\n",
      "Validation loss decreased (0.096258 --> 0.091253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0719650\n",
      "\tspeed: 0.1174s/iter; left time: 2538.3949s\n",
      "\titers: 200, epoch: 4 | loss: 0.0779148\n",
      "\tspeed: 0.0682s/iter; left time: 1467.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0767896 Vali Loss: 0.0894866 Test Loss: 0.0911194\n",
      "Validation loss decreased (0.091253 --> 0.089487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0700634\n",
      "\tspeed: 0.1163s/iter; left time: 2489.1998s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721898\n",
      "\tspeed: 0.0682s/iter; left time: 1452.4432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0751648 Vali Loss: 0.0887144 Test Loss: 0.0904107\n",
      "Validation loss decreased (0.089487 --> 0.088714).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0749286\n",
      "\tspeed: 0.1160s/iter; left time: 2458.0185s\n",
      "\titers: 200, epoch: 6 | loss: 0.0738826\n",
      "\tspeed: 0.0681s/iter; left time: 1436.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0741185 Vali Loss: 0.0878579 Test Loss: 0.0896857\n",
      "Validation loss decreased (0.088714 --> 0.087858).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0773617\n",
      "\tspeed: 0.1159s/iter; left time: 2428.6779s\n",
      "\titers: 200, epoch: 7 | loss: 0.0697817\n",
      "\tspeed: 0.0682s/iter; left time: 1422.8361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0732767 Vali Loss: 0.0878588 Test Loss: 0.0896681\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0730642\n",
      "\tspeed: 0.1162s/iter; left time: 2409.5194s\n",
      "\titers: 200, epoch: 8 | loss: 0.0692202\n",
      "\tspeed: 0.0682s/iter; left time: 1407.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0726633 Vali Loss: 0.0872458 Test Loss: 0.0892158\n",
      "Validation loss decreased (0.087858 --> 0.087246).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729467\n",
      "\tspeed: 0.1163s/iter; left time: 2385.3545s\n",
      "\titers: 200, epoch: 9 | loss: 0.0744857\n",
      "\tspeed: 0.0681s/iter; left time: 1390.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0721623 Vali Loss: 0.0872867 Test Loss: 0.0896076\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0656316\n",
      "\tspeed: 0.1169s/iter; left time: 2370.6480s\n",
      "\titers: 200, epoch: 10 | loss: 0.0678511\n",
      "\tspeed: 0.0681s/iter; left time: 1374.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0717752 Vali Loss: 0.0871055 Test Loss: 0.0893893\n",
      "Validation loss decreased (0.087246 --> 0.087106).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0707091\n",
      "\tspeed: 0.1165s/iter; left time: 2336.5772s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774499\n",
      "\tspeed: 0.0682s/iter; left time: 1360.7911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0715148 Vali Loss: 0.0870615 Test Loss: 0.0894800\n",
      "Validation loss decreased (0.087106 --> 0.087061).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0717980\n",
      "\tspeed: 0.1170s/iter; left time: 2321.4775s\n",
      "\titers: 200, epoch: 12 | loss: 0.0725807\n",
      "\tspeed: 0.0682s/iter; left time: 1345.7667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0711614 Vali Loss: 0.0869605 Test Loss: 0.0890957\n",
      "Validation loss decreased (0.087061 --> 0.086960).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0668585\n",
      "\tspeed: 0.1175s/iter; left time: 2305.2279s\n",
      "\titers: 200, epoch: 13 | loss: 0.0692727\n",
      "\tspeed: 0.0681s/iter; left time: 1329.0050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0709143 Vali Loss: 0.0864946 Test Loss: 0.0891141\n",
      "Validation loss decreased (0.086960 --> 0.086495).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0735727\n",
      "\tspeed: 0.1174s/iter; left time: 2277.1140s\n",
      "\titers: 200, epoch: 14 | loss: 0.0707164\n",
      "\tspeed: 0.0682s/iter; left time: 1314.7134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0707176 Vali Loss: 0.0864244 Test Loss: 0.0890591\n",
      "Validation loss decreased (0.086495 --> 0.086424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733102\n",
      "\tspeed: 0.1170s/iter; left time: 2243.1031s\n",
      "\titers: 200, epoch: 15 | loss: 0.0694377\n",
      "\tspeed: 0.0682s/iter; left time: 1299.6779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0704899 Vali Loss: 0.0864086 Test Loss: 0.0890507\n",
      "Validation loss decreased (0.086424 --> 0.086409).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683793\n",
      "\tspeed: 0.1172s/iter; left time: 2219.2491s\n",
      "\titers: 200, epoch: 16 | loss: 0.0738790\n",
      "\tspeed: 0.0682s/iter; left time: 1284.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0703185 Vali Loss: 0.0864727 Test Loss: 0.0892115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0669841\n",
      "\tspeed: 0.1164s/iter; left time: 2178.4624s\n",
      "\titers: 200, epoch: 17 | loss: 0.0688473\n",
      "\tspeed: 0.0682s/iter; left time: 1270.1758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0701495 Vali Loss: 0.0867436 Test Loss: 0.0892003\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0703127\n",
      "\tspeed: 0.1166s/iter; left time: 2157.1552s\n",
      "\titers: 200, epoch: 18 | loss: 0.0680623\n",
      "\tspeed: 0.0682s/iter; left time: 1253.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0700702 Vali Loss: 0.0863745 Test Loss: 0.0892077\n",
      "Validation loss decreased (0.086409 --> 0.086374).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0690351\n",
      "\tspeed: 0.1182s/iter; left time: 2158.8575s\n",
      "\titers: 200, epoch: 19 | loss: 0.0699728\n",
      "\tspeed: 0.0685s/iter; left time: 1244.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0698759 Vali Loss: 0.0863962 Test Loss: 0.0891723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747989\n",
      "\tspeed: 0.1163s/iter; left time: 2099.3134s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701621\n",
      "\tspeed: 0.0681s/iter; left time: 1222.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0698077 Vali Loss: 0.0862366 Test Loss: 0.0890738\n",
      "Validation loss decreased (0.086374 --> 0.086237).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0651559\n",
      "\tspeed: 0.1188s/iter; left time: 2117.8094s\n",
      "\titers: 200, epoch: 21 | loss: 0.0728592\n",
      "\tspeed: 0.0682s/iter; left time: 1208.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0696717 Vali Loss: 0.0862255 Test Loss: 0.0889388\n",
      "Validation loss decreased (0.086237 --> 0.086225).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0660903\n",
      "\tspeed: 0.1169s/iter; left time: 2057.1570s\n",
      "\titers: 200, epoch: 22 | loss: 0.0671541\n",
      "\tspeed: 0.0682s/iter; left time: 1193.7144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0695768 Vali Loss: 0.0863444 Test Loss: 0.0891108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0654175\n",
      "\tspeed: 0.1160s/iter; left time: 2015.2371s\n",
      "\titers: 200, epoch: 23 | loss: 0.0723482\n",
      "\tspeed: 0.0681s/iter; left time: 1176.3975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0695305 Vali Loss: 0.0861597 Test Loss: 0.0890979\n",
      "Validation loss decreased (0.086225 --> 0.086160).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0697307\n",
      "\tspeed: 0.1174s/iter; left time: 2013.1403s\n",
      "\titers: 200, epoch: 24 | loss: 0.0650538\n",
      "\tspeed: 0.0682s/iter; left time: 1162.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0694439 Vali Loss: 0.0862999 Test Loss: 0.0889981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0687164\n",
      "\tspeed: 0.1167s/iter; left time: 1974.7961s\n",
      "\titers: 200, epoch: 25 | loss: 0.0703700\n",
      "\tspeed: 0.0682s/iter; left time: 1147.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0694621 Vali Loss: 0.0863222 Test Loss: 0.0891119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0651680\n",
      "\tspeed: 0.1168s/iter; left time: 1950.1423s\n",
      "\titers: 200, epoch: 26 | loss: 0.0651452\n",
      "\tspeed: 0.0683s/iter; left time: 1134.6086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0693130 Vali Loss: 0.0863219 Test Loss: 0.0892911\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0680985\n",
      "\tspeed: 0.1161s/iter; left time: 1913.5918s\n",
      "\titers: 200, epoch: 27 | loss: 0.0710439\n",
      "\tspeed: 0.0682s/iter; left time: 1117.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692731 Vali Loss: 0.0861376 Test Loss: 0.0890480\n",
      "Validation loss decreased (0.086160 --> 0.086138).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662021\n",
      "\tspeed: 0.1180s/iter; left time: 1917.0443s\n",
      "\titers: 200, epoch: 28 | loss: 0.0719197\n",
      "\tspeed: 0.0681s/iter; left time: 1100.6756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0692632 Vali Loss: 0.0861789 Test Loss: 0.0889845\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0666632\n",
      "\tspeed: 0.1166s/iter; left time: 1868.4072s\n",
      "\titers: 200, epoch: 29 | loss: 0.0693237\n",
      "\tspeed: 0.0682s/iter; left time: 1086.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0691389 Vali Loss: 0.0861610 Test Loss: 0.0891781\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0710969\n",
      "\tspeed: 0.1165s/iter; left time: 1841.6270s\n",
      "\titers: 200, epoch: 30 | loss: 0.0695848\n",
      "\tspeed: 0.0682s/iter; left time: 1071.3898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0692292 Vali Loss: 0.0863213 Test Loss: 0.0891762\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0700110\n",
      "\tspeed: 0.1158s/iter; left time: 1804.9240s\n",
      "\titers: 200, epoch: 31 | loss: 0.0660521\n",
      "\tspeed: 0.0683s/iter; left time: 1057.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0691260 Vali Loss: 0.0860816 Test Loss: 0.0891049\n",
      "Validation loss decreased (0.086138 --> 0.086082).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0688812\n",
      "\tspeed: 0.1164s/iter; left time: 1787.8197s\n",
      "\titers: 200, epoch: 32 | loss: 0.0697777\n",
      "\tspeed: 0.0682s/iter; left time: 1041.0817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0691065 Vali Loss: 0.0862049 Test Loss: 0.0891521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0682049\n",
      "\tspeed: 0.1170s/iter; left time: 1770.2912s\n",
      "\titers: 200, epoch: 33 | loss: 0.0652785\n",
      "\tspeed: 0.0682s/iter; left time: 1025.1237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0689881 Vali Loss: 0.0863302 Test Loss: 0.0892339\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697649\n",
      "\tspeed: 0.1185s/iter; left time: 1767.0506s\n",
      "\titers: 200, epoch: 34 | loss: 0.0742545\n",
      "\tspeed: 0.0683s/iter; left time: 1011.9585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0690200 Vali Loss: 0.0862837 Test Loss: 0.0892433\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0694564\n",
      "\tspeed: 0.1176s/iter; left time: 1727.2184s\n",
      "\titers: 200, epoch: 35 | loss: 0.0653591\n",
      "\tspeed: 0.0682s/iter; left time: 994.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0689881 Vali Loss: 0.0861455 Test Loss: 0.0891630\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0664618\n",
      "\tspeed: 0.1166s/iter; left time: 1685.7674s\n",
      "\titers: 200, epoch: 36 | loss: 0.0715217\n",
      "\tspeed: 0.0682s/iter; left time: 979.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0689417 Vali Loss: 0.0861939 Test Loss: 0.0891584\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0691396\n",
      "\tspeed: 0.1169s/iter; left time: 1663.9450s\n",
      "\titers: 200, epoch: 37 | loss: 0.0702624\n",
      "\tspeed: 0.0682s/iter; left time: 963.9357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0689000 Vali Loss: 0.0863010 Test Loss: 0.0891434\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0753347\n",
      "\tspeed: 0.1163s/iter; left time: 1630.1800s\n",
      "\titers: 200, epoch: 38 | loss: 0.0695233\n",
      "\tspeed: 0.0682s/iter; left time: 948.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0689737 Vali Loss: 0.0862217 Test Loss: 0.0891257\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0725676\n",
      "\tspeed: 0.1169s/iter; left time: 1612.2869s\n",
      "\titers: 200, epoch: 39 | loss: 0.0694272\n",
      "\tspeed: 0.0681s/iter; left time: 932.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0688931 Vali Loss: 0.0861030 Test Loss: 0.0891194\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0669012\n",
      "\tspeed: 0.1167s/iter; left time: 1583.0745s\n",
      "\titers: 200, epoch: 40 | loss: 0.0678386\n",
      "\tspeed: 0.0682s/iter; left time: 918.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0689278 Vali Loss: 0.0861022 Test Loss: 0.0891052\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0652631\n",
      "\tspeed: 0.1166s/iter; left time: 1555.1809s\n",
      "\titers: 200, epoch: 41 | loss: 0.0645099\n",
      "\tspeed: 0.0681s/iter; left time: 902.1476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0689060 Vali Loss: 0.0861354 Test Loss: 0.0891289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021332554519176483, rmse:0.14605668187141418, mae:0.08910492062568665, rse:0.5154542922973633\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1481339\n",
      "\tspeed: 0.0695s/iter; left time: 1549.3538s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375552\n",
      "\tspeed: 0.0681s/iter; left time: 1512.1521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.1479610 Vali Loss: 0.1469265 Test Loss: 0.1552719\n",
      "Validation loss decreased (inf --> 0.146926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0865266\n",
      "\tspeed: 0.1168s/iter; left time: 2579.1506s\n",
      "\titers: 200, epoch: 2 | loss: 0.0838551\n",
      "\tspeed: 0.0682s/iter; left time: 1498.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0964700 Vali Loss: 0.0967222 Test Loss: 0.0970902\n",
      "Validation loss decreased (0.146926 --> 0.096722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0791053\n",
      "\tspeed: 0.1175s/iter; left time: 2567.7102s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794358\n",
      "\tspeed: 0.0682s/iter; left time: 1483.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0806912 Vali Loss: 0.0917135 Test Loss: 0.0933135\n",
      "Validation loss decreased (0.096722 --> 0.091714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0691623\n",
      "\tspeed: 0.1166s/iter; left time: 2521.8402s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749935\n",
      "\tspeed: 0.0681s/iter; left time: 1465.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0772206 Vali Loss: 0.0896696 Test Loss: 0.0914560\n",
      "Validation loss decreased (0.091714 --> 0.089670).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0780290\n",
      "\tspeed: 0.1169s/iter; left time: 2502.3026s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737418\n",
      "\tspeed: 0.0681s/iter; left time: 1451.2782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0753263 Vali Loss: 0.0887567 Test Loss: 0.0905667\n",
      "Validation loss decreased (0.089670 --> 0.088757).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0728102\n",
      "\tspeed: 0.1166s/iter; left time: 2470.7172s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751472\n",
      "\tspeed: 0.0681s/iter; left time: 1435.7969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0740903 Vali Loss: 0.0880040 Test Loss: 0.0901668\n",
      "Validation loss decreased (0.088757 --> 0.088004).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0700100\n",
      "\tspeed: 0.1165s/iter; left time: 2441.6990s\n",
      "\titers: 200, epoch: 7 | loss: 0.0719608\n",
      "\tspeed: 0.0682s/iter; left time: 1422.7946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0733094 Vali Loss: 0.0876565 Test Loss: 0.0895658\n",
      "Validation loss decreased (0.088004 --> 0.087656).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736883\n",
      "\tspeed: 0.1163s/iter; left time: 2411.0395s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753195\n",
      "\tspeed: 0.0681s/iter; left time: 1404.8808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0726421 Vali Loss: 0.0870508 Test Loss: 0.0893122\n",
      "Validation loss decreased (0.087656 --> 0.087051).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0736136\n",
      "\tspeed: 0.1163s/iter; left time: 2385.7227s\n",
      "\titers: 200, epoch: 9 | loss: 0.0743958\n",
      "\tspeed: 0.0681s/iter; left time: 1390.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0721928 Vali Loss: 0.0869639 Test Loss: 0.0890566\n",
      "Validation loss decreased (0.087051 --> 0.086964).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751010\n",
      "\tspeed: 0.1164s/iter; left time: 2360.5034s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675038\n",
      "\tspeed: 0.0681s/iter; left time: 1374.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0717584 Vali Loss: 0.0868287 Test Loss: 0.0892483\n",
      "Validation loss decreased (0.086964 --> 0.086829).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0670119\n",
      "\tspeed: 0.1167s/iter; left time: 2341.7488s\n",
      "\titers: 200, epoch: 11 | loss: 0.0717888\n",
      "\tspeed: 0.0681s/iter; left time: 1359.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0714888 Vali Loss: 0.0868792 Test Loss: 0.0891389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712271\n",
      "\tspeed: 0.1159s/iter; left time: 2299.0788s\n",
      "\titers: 200, epoch: 12 | loss: 0.0672809\n",
      "\tspeed: 0.0681s/iter; left time: 1343.3915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0712019 Vali Loss: 0.0867305 Test Loss: 0.0890825\n",
      "Validation loss decreased (0.086829 --> 0.086731).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719725\n",
      "\tspeed: 0.1167s/iter; left time: 2289.5881s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728667\n",
      "\tspeed: 0.0681s/iter; left time: 1328.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0709423 Vali Loss: 0.0863669 Test Loss: 0.0889514\n",
      "Validation loss decreased (0.086731 --> 0.086367).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0692876\n",
      "\tspeed: 0.1167s/iter; left time: 2262.4731s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697647\n",
      "\tspeed: 0.0681s/iter; left time: 1313.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0707196 Vali Loss: 0.0867283 Test Loss: 0.0890393\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662864\n",
      "\tspeed: 0.1161s/iter; left time: 2224.9158s\n",
      "\titers: 200, epoch: 15 | loss: 0.0771343\n",
      "\tspeed: 0.0682s/iter; left time: 1299.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0705296 Vali Loss: 0.0863529 Test Loss: 0.0889915\n",
      "Validation loss decreased (0.086367 --> 0.086353).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746282\n",
      "\tspeed: 0.1165s/iter; left time: 2206.4443s\n",
      "\titers: 200, epoch: 16 | loss: 0.0754090\n",
      "\tspeed: 0.0680s/iter; left time: 1282.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0703587 Vali Loss: 0.0864495 Test Loss: 0.0889058\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0699291\n",
      "\tspeed: 0.1157s/iter; left time: 2166.3741s\n",
      "\titers: 200, epoch: 17 | loss: 0.0712281\n",
      "\tspeed: 0.0681s/iter; left time: 1268.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0701812 Vali Loss: 0.0863386 Test Loss: 0.0889277\n",
      "Validation loss decreased (0.086353 --> 0.086339).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0725383\n",
      "\tspeed: 0.1164s/iter; left time: 2153.0135s\n",
      "\titers: 200, epoch: 18 | loss: 0.0666652\n",
      "\tspeed: 0.0681s/iter; left time: 1252.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0700965 Vali Loss: 0.0862578 Test Loss: 0.0888635\n",
      "Validation loss decreased (0.086339 --> 0.086258).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0668497\n",
      "\tspeed: 0.1165s/iter; left time: 2129.1404s\n",
      "\titers: 200, epoch: 19 | loss: 0.0658489\n",
      "\tspeed: 0.0681s/iter; left time: 1237.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0699537 Vali Loss: 0.0863137 Test Loss: 0.0890127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0738967\n",
      "\tspeed: 0.1177s/iter; left time: 2123.9244s\n",
      "\titers: 200, epoch: 20 | loss: 0.0694792\n",
      "\tspeed: 0.0685s/iter; left time: 1229.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0698415 Vali Loss: 0.0861164 Test Loss: 0.0890737\n",
      "Validation loss decreased (0.086258 --> 0.086116).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683504\n",
      "\tspeed: 0.1182s/iter; left time: 2106.3686s\n",
      "\titers: 200, epoch: 21 | loss: 0.0662834\n",
      "\tspeed: 0.0681s/iter; left time: 1206.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0697480 Vali Loss: 0.0862716 Test Loss: 0.0891779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0703220\n",
      "\tspeed: 0.1164s/iter; left time: 2047.8510s\n",
      "\titers: 200, epoch: 22 | loss: 0.0745794\n",
      "\tspeed: 0.0681s/iter; left time: 1191.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0696553 Vali Loss: 0.0863418 Test Loss: 0.0890533\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0711524\n",
      "\tspeed: 0.1162s/iter; left time: 2019.3311s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714321\n",
      "\tspeed: 0.0681s/iter; left time: 1176.8547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0695627 Vali Loss: 0.0861240 Test Loss: 0.0890432\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0750200\n",
      "\tspeed: 0.1159s/iter; left time: 1987.3924s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680464\n",
      "\tspeed: 0.0681s/iter; left time: 1160.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0695156 Vali Loss: 0.0861897 Test Loss: 0.0889316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0634025\n",
      "\tspeed: 0.1160s/iter; left time: 1963.0234s\n",
      "\titers: 200, epoch: 25 | loss: 0.0649181\n",
      "\tspeed: 0.0681s/iter; left time: 1145.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0694371 Vali Loss: 0.0860986 Test Loss: 0.0890105\n",
      "Validation loss decreased (0.086116 --> 0.086099).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0696129\n",
      "\tspeed: 0.1165s/iter; left time: 1945.9701s\n",
      "\titers: 200, epoch: 26 | loss: 0.0687395\n",
      "\tspeed: 0.0681s/iter; left time: 1130.1663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0693808 Vali Loss: 0.0860134 Test Loss: 0.0890921\n",
      "Validation loss decreased (0.086099 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0684652\n",
      "\tspeed: 0.1167s/iter; left time: 1923.3255s\n",
      "\titers: 200, epoch: 27 | loss: 0.0704379\n",
      "\tspeed: 0.0681s/iter; left time: 1115.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692557 Vali Loss: 0.0860665 Test Loss: 0.0890185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0660548\n",
      "\tspeed: 0.1157s/iter; left time: 1880.1403s\n",
      "\titers: 200, epoch: 28 | loss: 0.0695759\n",
      "\tspeed: 0.0681s/iter; left time: 1099.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0692245 Vali Loss: 0.0860535 Test Loss: 0.0891044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0729185\n",
      "\tspeed: 0.1158s/iter; left time: 1855.9955s\n",
      "\titers: 200, epoch: 29 | loss: 0.0718815\n",
      "\tspeed: 0.0681s/iter; left time: 1084.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0692287 Vali Loss: 0.0860219 Test Loss: 0.0890628\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0671238\n",
      "\tspeed: 0.1159s/iter; left time: 1831.8557s\n",
      "\titers: 200, epoch: 30 | loss: 0.0673873\n",
      "\tspeed: 0.0681s/iter; left time: 1069.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692022 Vali Loss: 0.0860136 Test Loss: 0.0890284\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0704793\n",
      "\tspeed: 0.1178s/iter; left time: 1835.7009s\n",
      "\titers: 200, epoch: 31 | loss: 0.0718422\n",
      "\tspeed: 0.0684s/iter; left time: 1058.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0691225 Vali Loss: 0.0860802 Test Loss: 0.0890919\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725498\n",
      "\tspeed: 0.1185s/iter; left time: 1819.2180s\n",
      "\titers: 200, epoch: 32 | loss: 0.0676495\n",
      "\tspeed: 0.0681s/iter; left time: 1039.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0691134 Vali Loss: 0.0860155 Test Loss: 0.0890442\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0670726\n",
      "\tspeed: 0.1166s/iter; left time: 1764.2981s\n",
      "\titers: 200, epoch: 33 | loss: 0.0635491\n",
      "\tspeed: 0.0682s/iter; left time: 1025.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0691029 Vali Loss: 0.0859950 Test Loss: 0.0890772\n",
      "Validation loss decreased (0.086013 --> 0.085995).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0719834\n",
      "\tspeed: 0.1168s/iter; left time: 1741.3619s\n",
      "\titers: 200, epoch: 34 | loss: 0.0686517\n",
      "\tspeed: 0.0682s/iter; left time: 1009.6711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0690270 Vali Loss: 0.0861514 Test Loss: 0.0890609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0703810\n",
      "\tspeed: 0.1165s/iter; left time: 1711.0968s\n",
      "\titers: 200, epoch: 35 | loss: 0.0672738\n",
      "\tspeed: 0.0682s/iter; left time: 994.4350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0690094 Vali Loss: 0.0860701 Test Loss: 0.0889734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0648728\n",
      "\tspeed: 0.1180s/iter; left time: 1705.8382s\n",
      "\titers: 200, epoch: 36 | loss: 0.0674613\n",
      "\tspeed: 0.0688s/iter; left time: 988.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 224 | Train Loss: 0.0689744 Vali Loss: 0.0859692 Test Loss: 0.0889376\n",
      "Validation loss decreased (0.085995 --> 0.085969).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0744139\n",
      "\tspeed: 0.1181s/iter; left time: 1682.0318s\n",
      "\titers: 200, epoch: 37 | loss: 0.0644355\n",
      "\tspeed: 0.0682s/iter; left time: 963.9878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0689775 Vali Loss: 0.0860912 Test Loss: 0.0890521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0704839\n",
      "\tspeed: 0.1166s/iter; left time: 1633.4715s\n",
      "\titers: 200, epoch: 38 | loss: 0.0659875\n",
      "\tspeed: 0.0682s/iter; left time: 948.3701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0689991 Vali Loss: 0.0860307 Test Loss: 0.0890244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0652285\n",
      "\tspeed: 0.1163s/iter; left time: 1603.7897s\n",
      "\titers: 200, epoch: 39 | loss: 0.0635228\n",
      "\tspeed: 0.0682s/iter; left time: 932.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0689129 Vali Loss: 0.0860817 Test Loss: 0.0890117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0707843\n",
      "\tspeed: 0.1163s/iter; left time: 1576.9634s\n",
      "\titers: 200, epoch: 40 | loss: 0.0744735\n",
      "\tspeed: 0.0682s/iter; left time: 917.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0688853 Vali Loss: 0.0859151 Test Loss: 0.0890057\n",
      "Validation loss decreased (0.085969 --> 0.085915).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0651298\n",
      "\tspeed: 0.1174s/iter; left time: 1566.6230s\n",
      "\titers: 200, epoch: 41 | loss: 0.0705316\n",
      "\tspeed: 0.0685s/iter; left time: 906.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0688910 Vali Loss: 0.0860872 Test Loss: 0.0890310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0715486\n",
      "\tspeed: 0.1173s/iter; left time: 1537.9944s\n",
      "\titers: 200, epoch: 42 | loss: 0.0710283\n",
      "\tspeed: 0.0681s/iter; left time: 886.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0688885 Vali Loss: 0.0859699 Test Loss: 0.0890445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0740932\n",
      "\tspeed: 0.1165s/iter; left time: 1501.5440s\n",
      "\titers: 200, epoch: 43 | loss: 0.0689263\n",
      "\tspeed: 0.0682s/iter; left time: 871.9792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0688816 Vali Loss: 0.0860015 Test Loss: 0.0890182\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0642701\n",
      "\tspeed: 0.1166s/iter; left time: 1476.6701s\n",
      "\titers: 200, epoch: 44 | loss: 0.0692235\n",
      "\tspeed: 0.0684s/iter; left time: 859.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0688794 Vali Loss: 0.0860575 Test Loss: 0.0890519\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0663138\n",
      "\tspeed: 0.1179s/iter; left time: 1466.8916s\n",
      "\titers: 200, epoch: 45 | loss: 0.0658265\n",
      "\tspeed: 0.0682s/iter; left time: 842.2911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0688699 Vali Loss: 0.0860186 Test Loss: 0.0890270\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0702913\n",
      "\tspeed: 0.1172s/iter; left time: 1431.8558s\n",
      "\titers: 200, epoch: 46 | loss: 0.0666724\n",
      "\tspeed: 0.0684s/iter; left time: 828.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0688977 Vali Loss: 0.0860817 Test Loss: 0.0890611\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0673764\n",
      "\tspeed: 0.1164s/iter; left time: 1396.2169s\n",
      "\titers: 200, epoch: 47 | loss: 0.0681927\n",
      "\tspeed: 0.0682s/iter; left time: 810.8225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0688601 Vali Loss: 0.0859702 Test Loss: 0.0890412\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0663044\n",
      "\tspeed: 0.1161s/iter; left time: 1367.3692s\n",
      "\titers: 200, epoch: 48 | loss: 0.0695243\n",
      "\tspeed: 0.0681s/iter; left time: 794.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0687945 Vali Loss: 0.0859358 Test Loss: 0.0890456\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0653680\n",
      "\tspeed: 0.1171s/iter; left time: 1352.6229s\n",
      "\titers: 200, epoch: 49 | loss: 0.0728765\n",
      "\tspeed: 0.0684s/iter; left time: 782.9867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0688531 Vali Loss: 0.0860522 Test Loss: 0.0890502\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0683106\n",
      "\tspeed: 0.1173s/iter; left time: 1328.5994s\n",
      "\titers: 200, epoch: 50 | loss: 0.0671068\n",
      "\tspeed: 0.0683s/iter; left time: 767.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0688381 Vali Loss: 0.0860414 Test Loss: 0.0890929\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021220816299319267, rmse:0.14567366242408752, mae:0.08900570124387741, rse:0.5141025185585022\n",
      "Intermediate time for DE and pred_len 24: 00h:28m:14.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1553198\n",
      "\tspeed: 0.0894s/iter; left time: 1993.5704s\n",
      "\titers: 200, epoch: 1 | loss: 0.1476482\n",
      "\tspeed: 0.0686s/iter; left time: 1523.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.82s\n",
      "Steps: 224 | Train Loss: 0.1587726 Vali Loss: 0.1620284 Test Loss: 0.1741853\n",
      "Validation loss decreased (inf --> 0.162028).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1152195\n",
      "\tspeed: 0.1189s/iter; left time: 2625.1259s\n",
      "\titers: 200, epoch: 2 | loss: 0.1058429\n",
      "\tspeed: 0.0687s/iter; left time: 1509.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1189176 Vali Loss: 0.1228653 Test Loss: 0.1296490\n",
      "Validation loss decreased (0.162028 --> 0.122865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1058418\n",
      "\tspeed: 0.1196s/iter; left time: 2614.5310s\n",
      "\titers: 200, epoch: 3 | loss: 0.1070150\n",
      "\tspeed: 0.0686s/iter; left time: 1492.3288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.1064492 Vali Loss: 0.1198202 Test Loss: 0.1269938\n",
      "Validation loss decreased (0.122865 --> 0.119820).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1012271\n",
      "\tspeed: 0.1207s/iter; left time: 2611.6478s\n",
      "\titers: 200, epoch: 4 | loss: 0.0987478\n",
      "\tspeed: 0.0686s/iter; left time: 1476.6372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1033720 Vali Loss: 0.1182980 Test Loss: 0.1268990\n",
      "Validation loss decreased (0.119820 --> 0.118298).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1041800\n",
      "\tspeed: 0.1203s/iter; left time: 2573.9606s\n",
      "\titers: 200, epoch: 5 | loss: 0.0997182\n",
      "\tspeed: 0.0686s/iter; left time: 1461.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.1016296 Vali Loss: 0.1186564 Test Loss: 0.1272689\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994423\n",
      "\tspeed: 0.1177s/iter; left time: 2492.6164s\n",
      "\titers: 200, epoch: 6 | loss: 0.1013170\n",
      "\tspeed: 0.0686s/iter; left time: 1445.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1003724 Vali Loss: 0.1183913 Test Loss: 0.1269911\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0949351\n",
      "\tspeed: 0.1187s/iter; left time: 2488.1407s\n",
      "\titers: 200, epoch: 7 | loss: 0.1020790\n",
      "\tspeed: 0.0686s/iter; left time: 1430.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 224 | Train Loss: 0.0993798 Vali Loss: 0.1190878 Test Loss: 0.1270349\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977151\n",
      "\tspeed: 0.1187s/iter; left time: 2460.3847s\n",
      "\titers: 200, epoch: 8 | loss: 0.0957019\n",
      "\tspeed: 0.0685s/iter; left time: 1414.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0985318 Vali Loss: 0.1188884 Test Loss: 0.1277997\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0936474\n",
      "\tspeed: 0.1172s/iter; left time: 2403.2456s\n",
      "\titers: 200, epoch: 9 | loss: 0.0981991\n",
      "\tspeed: 0.0686s/iter; left time: 1400.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0976707 Vali Loss: 0.1194609 Test Loss: 0.1275967\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0972934\n",
      "\tspeed: 0.1186s/iter; left time: 2406.3673s\n",
      "\titers: 200, epoch: 10 | loss: 0.0945473\n",
      "\tspeed: 0.0685s/iter; left time: 1383.2447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0969444 Vali Loss: 0.1195559 Test Loss: 0.1284629\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0940746\n",
      "\tspeed: 0.1174s/iter; left time: 2355.8651s\n",
      "\titers: 200, epoch: 11 | loss: 0.0956078\n",
      "\tspeed: 0.0685s/iter; left time: 1367.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0961737 Vali Loss: 0.1201853 Test Loss: 0.1291677\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987268\n",
      "\tspeed: 0.1186s/iter; left time: 2353.6459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0970581\n",
      "\tspeed: 0.0686s/iter; left time: 1354.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0955070 Vali Loss: 0.1205458 Test Loss: 0.1305023\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0955645\n",
      "\tspeed: 0.1199s/iter; left time: 2351.4552s\n",
      "\titers: 200, epoch: 13 | loss: 0.0935065\n",
      "\tspeed: 0.0688s/iter; left time: 1343.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0948097 Vali Loss: 0.1206527 Test Loss: 0.1302494\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0937597\n",
      "\tspeed: 0.1196s/iter; left time: 2318.3649s\n",
      "\titers: 200, epoch: 14 | loss: 0.0950699\n",
      "\tspeed: 0.0687s/iter; left time: 1325.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.0941970 Vali Loss: 0.1206340 Test Loss: 0.1308207\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03608657419681549, rmse:0.1899646669626236, mae:0.12689906358718872, rse:0.6727032661437988\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1584245\n",
      "\tspeed: 0.0702s/iter; left time: 1566.2615s\n",
      "\titers: 200, epoch: 1 | loss: 0.1467351\n",
      "\tspeed: 0.0685s/iter; left time: 1520.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1586937 Vali Loss: 0.1618374 Test Loss: 0.1740249\n",
      "Validation loss decreased (inf --> 0.161837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1216307\n",
      "\tspeed: 0.1204s/iter; left time: 2658.2494s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122305\n",
      "\tspeed: 0.0686s/iter; left time: 1507.3866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1201242 Vali Loss: 0.1231106 Test Loss: 0.1303863\n",
      "Validation loss decreased (0.161837 --> 0.123111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1122966\n",
      "\tspeed: 0.1206s/iter; left time: 2635.8908s\n",
      "\titers: 200, epoch: 3 | loss: 0.1102855\n",
      "\tspeed: 0.0690s/iter; left time: 1500.6184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.1063538 Vali Loss: 0.1198373 Test Loss: 0.1280635\n",
      "Validation loss decreased (0.123111 --> 0.119837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1058941\n",
      "\tspeed: 0.1215s/iter; left time: 2628.3113s\n",
      "\titers: 200, epoch: 4 | loss: 0.1058972\n",
      "\tspeed: 0.0693s/iter; left time: 1491.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 224 | Train Loss: 0.1034576 Vali Loss: 0.1186996 Test Loss: 0.1267959\n",
      "Validation loss decreased (0.119837 --> 0.118700).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032637\n",
      "\tspeed: 0.1213s/iter; left time: 2596.4239s\n",
      "\titers: 200, epoch: 5 | loss: 0.0977947\n",
      "\tspeed: 0.0689s/iter; left time: 1467.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.1017239 Vali Loss: 0.1180575 Test Loss: 0.1264388\n",
      "Validation loss decreased (0.118700 --> 0.118057).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1026086\n",
      "\tspeed: 0.1203s/iter; left time: 2547.2596s\n",
      "\titers: 200, epoch: 6 | loss: 0.1012904\n",
      "\tspeed: 0.0688s/iter; left time: 1451.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.1004415 Vali Loss: 0.1183241 Test Loss: 0.1264702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0958061\n",
      "\tspeed: 0.1198s/iter; left time: 2509.7809s\n",
      "\titers: 200, epoch: 7 | loss: 0.0977835\n",
      "\tspeed: 0.0686s/iter; left time: 1431.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0993413 Vali Loss: 0.1187937 Test Loss: 0.1269252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0999358\n",
      "\tspeed: 0.1198s/iter; left time: 2484.6183s\n",
      "\titers: 200, epoch: 8 | loss: 0.0953013\n",
      "\tspeed: 0.0685s/iter; left time: 1412.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0984381 Vali Loss: 0.1188546 Test Loss: 0.1268269\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1026255\n",
      "\tspeed: 0.1182s/iter; left time: 2424.0537s\n",
      "\titers: 200, epoch: 9 | loss: 0.0962968\n",
      "\tspeed: 0.0685s/iter; left time: 1398.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0976047 Vali Loss: 0.1191079 Test Loss: 0.1277792\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0980087\n",
      "\tspeed: 0.1189s/iter; left time: 2411.6126s\n",
      "\titers: 200, epoch: 10 | loss: 0.0934485\n",
      "\tspeed: 0.0686s/iter; left time: 1384.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0967829 Vali Loss: 0.1193806 Test Loss: 0.1285394\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0947366\n",
      "\tspeed: 0.1187s/iter; left time: 2380.3778s\n",
      "\titers: 200, epoch: 11 | loss: 0.0951942\n",
      "\tspeed: 0.0684s/iter; left time: 1366.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0961140 Vali Loss: 0.1194274 Test Loss: 0.1278090\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0942025\n",
      "\tspeed: 0.1182s/iter; left time: 2344.6639s\n",
      "\titers: 200, epoch: 12 | loss: 0.0922594\n",
      "\tspeed: 0.0685s/iter; left time: 1351.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0954150 Vali Loss: 0.1197382 Test Loss: 0.1294381\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0935657\n",
      "\tspeed: 0.1185s/iter; left time: 2323.2796s\n",
      "\titers: 200, epoch: 13 | loss: 0.0939974\n",
      "\tspeed: 0.0685s/iter; left time: 1337.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0947779 Vali Loss: 0.1200896 Test Loss: 0.1289643\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0945294\n",
      "\tspeed: 0.1196s/iter; left time: 2319.0838s\n",
      "\titers: 200, epoch: 14 | loss: 0.0924002\n",
      "\tspeed: 0.0691s/iter; left time: 1331.9483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0942263 Vali Loss: 0.1200542 Test Loss: 0.1291798\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0901726\n",
      "\tspeed: 0.1184s/iter; left time: 2269.0467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943275\n",
      "\tspeed: 0.0685s/iter; left time: 1305.9293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0936829 Vali Loss: 0.1200363 Test Loss: 0.1297049\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036072153598070145, rmse:0.18992669880390167, mae:0.12643878161907196, rse:0.6725688576698303\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:17.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1549753\n",
      "\tspeed: 0.0902s/iter; left time: 2002.2874s\n",
      "\titers: 200, epoch: 1 | loss: 0.1490488\n",
      "\tspeed: 0.0690s/iter; left time: 1525.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.90s\n",
      "Steps: 223 | Train Loss: 0.1608003 Vali Loss: 0.1642570 Test Loss: 0.1773680\n",
      "Validation loss decreased (inf --> 0.164257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1214390\n",
      "\tspeed: 0.1193s/iter; left time: 2622.3446s\n",
      "\titers: 200, epoch: 2 | loss: 0.1186189\n",
      "\tspeed: 0.0694s/iter; left time: 1517.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.82s\n",
      "Steps: 223 | Train Loss: 0.1239646 Vali Loss: 0.1269783 Test Loss: 0.1358851\n",
      "Validation loss decreased (0.164257 --> 0.126978).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1172384\n",
      "\tspeed: 0.1224s/iter; left time: 2663.5086s\n",
      "\titers: 200, epoch: 3 | loss: 0.1076551\n",
      "\tspeed: 0.0691s/iter; left time: 1497.2145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1123203 Vali Loss: 0.1241126 Test Loss: 0.1345313\n",
      "Validation loss decreased (0.126978 --> 0.124113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1120366\n",
      "\tspeed: 0.1222s/iter; left time: 2630.9343s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102021\n",
      "\tspeed: 0.0710s/iter; left time: 1521.1182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.85s\n",
      "Steps: 223 | Train Loss: 0.1094738 Vali Loss: 0.1237527 Test Loss: 0.1338149\n",
      "Validation loss decreased (0.124113 --> 0.123753).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1105729\n",
      "\tspeed: 0.1208s/iter; left time: 2574.8094s\n",
      "\titers: 200, epoch: 5 | loss: 0.1061440\n",
      "\tspeed: 0.0692s/iter; left time: 1468.5090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1077770 Vali Loss: 0.1238218 Test Loss: 0.1339873\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1095262\n",
      "\tspeed: 0.1194s/iter; left time: 2517.6188s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042345\n",
      "\tspeed: 0.0691s/iter; left time: 1451.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1063676 Vali Loss: 0.1235585 Test Loss: 0.1348094\n",
      "Validation loss decreased (0.123753 --> 0.123558).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1005648\n",
      "\tspeed: 0.1203s/iter; left time: 2509.2368s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043318\n",
      "\tspeed: 0.0692s/iter; left time: 1436.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1052716 Vali Loss: 0.1240842 Test Loss: 0.1343348\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1054658\n",
      "\tspeed: 0.1199s/iter; left time: 2474.3814s\n",
      "\titers: 200, epoch: 8 | loss: 0.1059599\n",
      "\tspeed: 0.0693s/iter; left time: 1423.1761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1042885 Vali Loss: 0.1244867 Test Loss: 0.1349613\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1038408\n",
      "\tspeed: 0.1191s/iter; left time: 2431.4259s\n",
      "\titers: 200, epoch: 9 | loss: 0.1002405\n",
      "\tspeed: 0.0691s/iter; left time: 1403.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.1032768 Vali Loss: 0.1248526 Test Loss: 0.1349830\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0949917\n",
      "\tspeed: 0.1200s/iter; left time: 2424.1421s\n",
      "\titers: 200, epoch: 10 | loss: 0.1013010\n",
      "\tspeed: 0.0691s/iter; left time: 1388.8820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1024455 Vali Loss: 0.1252553 Test Loss: 0.1358568\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1012795\n",
      "\tspeed: 0.1207s/iter; left time: 2410.1695s\n",
      "\titers: 200, epoch: 11 | loss: 0.1041970\n",
      "\tspeed: 0.0691s/iter; left time: 1372.8264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1017006 Vali Loss: 0.1258108 Test Loss: 0.1355357\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0993979\n",
      "\tspeed: 0.1187s/iter; left time: 2344.6987s\n",
      "\titers: 200, epoch: 12 | loss: 0.1057732\n",
      "\tspeed: 0.0691s/iter; left time: 1358.4099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1009501 Vali Loss: 0.1261189 Test Loss: 0.1361108\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020337\n",
      "\tspeed: 0.1192s/iter; left time: 2328.0625s\n",
      "\titers: 200, epoch: 13 | loss: 0.0951053\n",
      "\tspeed: 0.0692s/iter; left time: 1343.7230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1002808 Vali Loss: 0.1269347 Test Loss: 0.1376551\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0966744\n",
      "\tspeed: 0.1189s/iter; left time: 2294.7735s\n",
      "\titers: 200, epoch: 14 | loss: 0.1020604\n",
      "\tspeed: 0.0692s/iter; left time: 1328.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.0994902 Vali Loss: 0.1274046 Test Loss: 0.1371823\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0936168\n",
      "\tspeed: 0.1190s/iter; left time: 2270.1035s\n",
      "\titers: 200, epoch: 15 | loss: 0.0942707\n",
      "\tspeed: 0.0692s/iter; left time: 1312.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.0989118 Vali Loss: 0.1278043 Test Loss: 0.1380977\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0972000\n",
      "\tspeed: 0.1190s/iter; left time: 2244.6240s\n",
      "\titers: 200, epoch: 16 | loss: 0.1007343\n",
      "\tspeed: 0.0691s/iter; left time: 1296.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.0983926 Vali Loss: 0.1279984 Test Loss: 0.1382564\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03949786722660065, rmse:0.19874070584774017, mae:0.1348094493150711, rse:0.7039555311203003\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1588997\n",
      "\tspeed: 0.0746s/iter; left time: 1656.7000s\n",
      "\titers: 200, epoch: 1 | loss: 0.1519462\n",
      "\tspeed: 0.0692s/iter; left time: 1530.3420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.02s\n",
      "Steps: 223 | Train Loss: 0.1616140 Vali Loss: 0.1641594 Test Loss: 0.1773060\n",
      "Validation loss decreased (inf --> 0.164159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1188093\n",
      "\tspeed: 0.1200s/iter; left time: 2638.3913s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157238\n",
      "\tspeed: 0.0692s/iter; left time: 1513.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1240953 Vali Loss: 0.1277020 Test Loss: 0.1362368\n",
      "Validation loss decreased (0.164159 --> 0.127702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1087447\n",
      "\tspeed: 0.1214s/iter; left time: 2640.9385s\n",
      "\titers: 200, epoch: 3 | loss: 0.1102369\n",
      "\tspeed: 0.0692s/iter; left time: 1498.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 223 | Train Loss: 0.1123339 Vali Loss: 0.1243157 Test Loss: 0.1344908\n",
      "Validation loss decreased (0.127702 --> 0.124316).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040820\n",
      "\tspeed: 0.1211s/iter; left time: 2607.6138s\n",
      "\titers: 200, epoch: 4 | loss: 0.1147634\n",
      "\tspeed: 0.0691s/iter; left time: 1481.7361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1095129 Vali Loss: 0.1235023 Test Loss: 0.1340304\n",
      "Validation loss decreased (0.124316 --> 0.123502).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1062547\n",
      "\tspeed: 0.1199s/iter; left time: 2554.4991s\n",
      "\titers: 200, epoch: 5 | loss: 0.1056936\n",
      "\tspeed: 0.0691s/iter; left time: 1464.8847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1076909 Vali Loss: 0.1228546 Test Loss: 0.1347191\n",
      "Validation loss decreased (0.123502 --> 0.122855).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1069995\n",
      "\tspeed: 0.1212s/iter; left time: 2556.1518s\n",
      "\titers: 200, epoch: 6 | loss: 0.1051202\n",
      "\tspeed: 0.0692s/iter; left time: 1451.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.1062499 Vali Loss: 0.1232824 Test Loss: 0.1350140\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1089477\n",
      "\tspeed: 0.1197s/iter; left time: 2497.3162s\n",
      "\titers: 200, epoch: 7 | loss: 0.1064909\n",
      "\tspeed: 0.0691s/iter; left time: 1434.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1049699 Vali Loss: 0.1233181 Test Loss: 0.1350354\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1094153\n",
      "\tspeed: 0.1181s/iter; left time: 2437.8416s\n",
      "\titers: 200, epoch: 8 | loss: 0.1034480\n",
      "\tspeed: 0.0691s/iter; left time: 1419.8368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1039009 Vali Loss: 0.1239157 Test Loss: 0.1360014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1056654\n",
      "\tspeed: 0.1205s/iter; left time: 2459.8758s\n",
      "\titers: 200, epoch: 9 | loss: 0.1067714\n",
      "\tspeed: 0.0691s/iter; left time: 1403.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.1028753 Vali Loss: 0.1241723 Test Loss: 0.1362410\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1025408\n",
      "\tspeed: 0.1186s/iter; left time: 2394.6312s\n",
      "\titers: 200, epoch: 10 | loss: 0.1066732\n",
      "\tspeed: 0.0691s/iter; left time: 1388.5267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1018622 Vali Loss: 0.1249785 Test Loss: 0.1366130\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0992114\n",
      "\tspeed: 0.1194s/iter; left time: 2384.6691s\n",
      "\titers: 200, epoch: 11 | loss: 0.0965374\n",
      "\tspeed: 0.0694s/iter; left time: 1378.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.1008964 Vali Loss: 0.1254471 Test Loss: 0.1377246\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1030749\n",
      "\tspeed: 0.1204s/iter; left time: 2378.5863s\n",
      "\titers: 200, epoch: 12 | loss: 0.1003793\n",
      "\tspeed: 0.0694s/iter; left time: 1364.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 223 | Train Loss: 0.1000783 Vali Loss: 0.1260959 Test Loss: 0.1375503\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1018916\n",
      "\tspeed: 0.1194s/iter; left time: 2330.8392s\n",
      "\titers: 200, epoch: 13 | loss: 0.0990939\n",
      "\tspeed: 0.0691s/iter; left time: 1342.6949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0993299 Vali Loss: 0.1267395 Test Loss: 0.1381821\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0967322\n",
      "\tspeed: 0.1191s/iter; left time: 2298.5401s\n",
      "\titers: 200, epoch: 14 | loss: 0.0990912\n",
      "\tspeed: 0.0691s/iter; left time: 1327.2921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0985874 Vali Loss: 0.1270754 Test Loss: 0.1382004\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0972180\n",
      "\tspeed: 0.1186s/iter; left time: 2263.4286s\n",
      "\titers: 200, epoch: 15 | loss: 0.0954075\n",
      "\tspeed: 0.0692s/iter; left time: 1312.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.0980638 Vali Loss: 0.1273433 Test Loss: 0.1388922\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03948056325316429, rmse:0.19869716465473175, mae:0.13471922278404236, rse:0.7038013339042664\n",
      "Intermediate time for DE and pred_len 168: 00h:10m:01.92s\n",
      "Intermediate time for DE: 00h:47m:34.52s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1333680\n",
      "\tspeed: 0.0888s/iter; left time: 1980.9873s\n",
      "\titers: 200, epoch: 1 | loss: 0.1306122\n",
      "\tspeed: 0.0683s/iter; left time: 1515.7879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 224 | Train Loss: 0.1369647 Vali Loss: 0.1359312 Test Loss: 0.1559038\n",
      "Validation loss decreased (inf --> 0.135931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0914119\n",
      "\tspeed: 0.1171s/iter; left time: 2584.8234s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847467\n",
      "\tspeed: 0.0681s/iter; left time: 1496.7916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0923135 Vali Loss: 0.0929183 Test Loss: 0.1049555\n",
      "Validation loss decreased (0.135931 --> 0.092918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0800922\n",
      "\tspeed: 0.1174s/iter; left time: 2565.4313s\n",
      "\titers: 200, epoch: 3 | loss: 0.0858246\n",
      "\tspeed: 0.0681s/iter; left time: 1480.4954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0791665 Vali Loss: 0.0912677 Test Loss: 0.1042033\n",
      "Validation loss decreased (0.092918 --> 0.091268).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731348\n",
      "\tspeed: 0.1169s/iter; left time: 2528.4876s\n",
      "\titers: 200, epoch: 4 | loss: 0.0773949\n",
      "\tspeed: 0.0681s/iter; left time: 1466.4106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0772773 Vali Loss: 0.0907929 Test Loss: 0.1035567\n",
      "Validation loss decreased (0.091268 --> 0.090793).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0722893\n",
      "\tspeed: 0.1167s/iter; left time: 2498.1122s\n",
      "\titers: 200, epoch: 5 | loss: 0.0714369\n",
      "\tspeed: 0.0681s/iter; left time: 1450.4836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0761371 Vali Loss: 0.0896728 Test Loss: 0.1029171\n",
      "Validation loss decreased (0.090793 --> 0.089673).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774925\n",
      "\tspeed: 0.1166s/iter; left time: 2468.8454s\n",
      "\titers: 200, epoch: 6 | loss: 0.0720026\n",
      "\tspeed: 0.0681s/iter; left time: 1435.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0753417 Vali Loss: 0.0894101 Test Loss: 0.1027032\n",
      "Validation loss decreased (0.089673 --> 0.089410).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0786619\n",
      "\tspeed: 0.1173s/iter; left time: 2457.3267s\n",
      "\titers: 200, epoch: 7 | loss: 0.0714008\n",
      "\tspeed: 0.0681s/iter; left time: 1420.4751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0747525 Vali Loss: 0.0894637 Test Loss: 0.1024739\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758944\n",
      "\tspeed: 0.1173s/iter; left time: 2431.3588s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728859\n",
      "\tspeed: 0.0681s/iter; left time: 1405.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0743224 Vali Loss: 0.0890427 Test Loss: 0.1023517\n",
      "Validation loss decreased (0.089410 --> 0.089043).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774943\n",
      "\tspeed: 0.1169s/iter; left time: 2396.5468s\n",
      "\titers: 200, epoch: 9 | loss: 0.0751756\n",
      "\tspeed: 0.0681s/iter; left time: 1389.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0738270 Vali Loss: 0.0888496 Test Loss: 0.1026962\n",
      "Validation loss decreased (0.089043 --> 0.088850).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0729855\n",
      "\tspeed: 0.1173s/iter; left time: 2378.8617s\n",
      "\titers: 200, epoch: 10 | loss: 0.0749506\n",
      "\tspeed: 0.0681s/iter; left time: 1374.4904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0735145 Vali Loss: 0.0884768 Test Loss: 0.1022387\n",
      "Validation loss decreased (0.088850 --> 0.088477).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0703702\n",
      "\tspeed: 0.1176s/iter; left time: 2359.1218s\n",
      "\titers: 200, epoch: 11 | loss: 0.0753163\n",
      "\tspeed: 0.0683s/iter; left time: 1362.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0731616 Vali Loss: 0.0884949 Test Loss: 0.1025441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0697689\n",
      "\tspeed: 0.1169s/iter; left time: 2319.5251s\n",
      "\titers: 200, epoch: 12 | loss: 0.0717288\n",
      "\tspeed: 0.0681s/iter; left time: 1343.7840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0729910 Vali Loss: 0.0885811 Test Loss: 0.1023816\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0769481\n",
      "\tspeed: 0.1164s/iter; left time: 2283.3286s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731467\n",
      "\tspeed: 0.0683s/iter; left time: 1332.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0726464 Vali Loss: 0.0884182 Test Loss: 0.1019948\n",
      "Validation loss decreased (0.088477 --> 0.088418).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0727538\n",
      "\tspeed: 0.1170s/iter; left time: 2269.4322s\n",
      "\titers: 200, epoch: 14 | loss: 0.0745294\n",
      "\tspeed: 0.0680s/iter; left time: 1311.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0724863 Vali Loss: 0.0884307 Test Loss: 0.1020039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0743532\n",
      "\tspeed: 0.1165s/iter; left time: 2231.7804s\n",
      "\titers: 200, epoch: 15 | loss: 0.0696489\n",
      "\tspeed: 0.0683s/iter; left time: 1301.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0722417 Vali Loss: 0.0881380 Test Loss: 0.1021411\n",
      "Validation loss decreased (0.088418 --> 0.088138).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0769881\n",
      "\tspeed: 0.1170s/iter; left time: 2216.1289s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698817\n",
      "\tspeed: 0.0680s/iter; left time: 1282.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0721133 Vali Loss: 0.0881289 Test Loss: 0.1024259\n",
      "Validation loss decreased (0.088138 --> 0.088129).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0659922\n",
      "\tspeed: 0.1169s/iter; left time: 2188.1816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0688582\n",
      "\tspeed: 0.0683s/iter; left time: 1270.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0719713 Vali Loss: 0.0882590 Test Loss: 0.1025742\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0732577\n",
      "\tspeed: 0.1169s/iter; left time: 2161.5882s\n",
      "\titers: 200, epoch: 18 | loss: 0.0694320\n",
      "\tspeed: 0.0681s/iter; left time: 1252.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0717804 Vali Loss: 0.0882470 Test Loss: 0.1023746\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0679316\n",
      "\tspeed: 0.1165s/iter; left time: 2127.4974s\n",
      "\titers: 200, epoch: 19 | loss: 0.0690580\n",
      "\tspeed: 0.0681s/iter; left time: 1237.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0716955 Vali Loss: 0.0879507 Test Loss: 0.1025331\n",
      "Validation loss decreased (0.088129 --> 0.087951).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747656\n",
      "\tspeed: 0.1189s/iter; left time: 2144.7055s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723538\n",
      "\tspeed: 0.0683s/iter; left time: 1225.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0715595 Vali Loss: 0.0880102 Test Loss: 0.1024311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0675295\n",
      "\tspeed: 0.1172s/iter; left time: 2088.5393s\n",
      "\titers: 200, epoch: 21 | loss: 0.0754626\n",
      "\tspeed: 0.0683s/iter; left time: 1210.4040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0714036 Vali Loss: 0.0880359 Test Loss: 0.1027101\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0747559\n",
      "\tspeed: 0.1183s/iter; left time: 2081.4978s\n",
      "\titers: 200, epoch: 22 | loss: 0.0735652\n",
      "\tspeed: 0.0686s/iter; left time: 1199.7925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0714004 Vali Loss: 0.0880514 Test Loss: 0.1024467\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0726551\n",
      "\tspeed: 0.1188s/iter; left time: 2064.5593s\n",
      "\titers: 200, epoch: 23 | loss: 0.0736888\n",
      "\tspeed: 0.0685s/iter; left time: 1183.3531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0712337 Vali Loss: 0.0878681 Test Loss: 0.1021830\n",
      "Validation loss decreased (0.087951 --> 0.087868).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0731569\n",
      "\tspeed: 0.1173s/iter; left time: 2011.1946s\n",
      "\titers: 200, epoch: 24 | loss: 0.0654764\n",
      "\tspeed: 0.0682s/iter; left time: 1163.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0711718 Vali Loss: 0.0880312 Test Loss: 0.1023722\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0753586\n",
      "\tspeed: 0.1162s/iter; left time: 1966.9141s\n",
      "\titers: 200, epoch: 25 | loss: 0.0715960\n",
      "\tspeed: 0.0683s/iter; left time: 1149.0157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0711529 Vali Loss: 0.0877999 Test Loss: 0.1024489\n",
      "Validation loss decreased (0.087868 --> 0.087800).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0729085\n",
      "\tspeed: 0.1171s/iter; left time: 1955.7698s\n",
      "\titers: 200, epoch: 26 | loss: 0.0663390\n",
      "\tspeed: 0.0681s/iter; left time: 1130.9998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0709616 Vali Loss: 0.0879779 Test Loss: 0.1026313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0700807\n",
      "\tspeed: 0.1165s/iter; left time: 1919.8403s\n",
      "\titers: 200, epoch: 27 | loss: 0.0744579\n",
      "\tspeed: 0.0681s/iter; left time: 1115.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0710200 Vali Loss: 0.0879474 Test Loss: 0.1024743\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0730878\n",
      "\tspeed: 0.1156s/iter; left time: 1878.7285s\n",
      "\titers: 200, epoch: 28 | loss: 0.0696250\n",
      "\tspeed: 0.0681s/iter; left time: 1099.6188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0708943 Vali Loss: 0.0878046 Test Loss: 0.1025338\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0729829\n",
      "\tspeed: 0.1160s/iter; left time: 1859.3250s\n",
      "\titers: 200, epoch: 29 | loss: 0.0762085\n",
      "\tspeed: 0.0681s/iter; left time: 1084.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0708806 Vali Loss: 0.0878422 Test Loss: 0.1025320\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0690114\n",
      "\tspeed: 0.1164s/iter; left time: 1840.2345s\n",
      "\titers: 200, epoch: 30 | loss: 0.0681642\n",
      "\tspeed: 0.0681s/iter; left time: 1069.1820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0708473 Vali Loss: 0.0879095 Test Loss: 0.1024646\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0675929\n",
      "\tspeed: 0.1159s/iter; left time: 1805.7393s\n",
      "\titers: 200, epoch: 31 | loss: 0.0703068\n",
      "\tspeed: 0.0683s/iter; left time: 1057.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0707743 Vali Loss: 0.0877124 Test Loss: 0.1025452\n",
      "Validation loss decreased (0.087800 --> 0.087712).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0713335\n",
      "\tspeed: 0.1181s/iter; left time: 1813.2451s\n",
      "\titers: 200, epoch: 32 | loss: 0.0659095\n",
      "\tspeed: 0.0681s/iter; left time: 1038.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0708065 Vali Loss: 0.0878161 Test Loss: 0.1026590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0685042\n",
      "\tspeed: 0.1154s/iter; left time: 1746.8283s\n",
      "\titers: 200, epoch: 33 | loss: 0.0746160\n",
      "\tspeed: 0.0682s/iter; left time: 1025.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0707395 Vali Loss: 0.0878438 Test Loss: 0.1025891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0687872\n",
      "\tspeed: 0.1167s/iter; left time: 1739.5423s\n",
      "\titers: 200, epoch: 34 | loss: 0.0705506\n",
      "\tspeed: 0.0681s/iter; left time: 1008.0078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0707021 Vali Loss: 0.0877845 Test Loss: 0.1025829\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0705029\n",
      "\tspeed: 0.1164s/iter; left time: 1710.0465s\n",
      "\titers: 200, epoch: 35 | loss: 0.0674875\n",
      "\tspeed: 0.0681s/iter; left time: 993.0985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0707380 Vali Loss: 0.0878009 Test Loss: 0.1025980\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0722462\n",
      "\tspeed: 0.1161s/iter; left time: 1678.9166s\n",
      "\titers: 200, epoch: 36 | loss: 0.0744660\n",
      "\tspeed: 0.0681s/iter; left time: 977.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0707073 Vali Loss: 0.0878338 Test Loss: 0.1025811\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0681205\n",
      "\tspeed: 0.1160s/iter; left time: 1652.0876s\n",
      "\titers: 200, epoch: 37 | loss: 0.0667671\n",
      "\tspeed: 0.0681s/iter; left time: 962.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0706651 Vali Loss: 0.0877007 Test Loss: 0.1025965\n",
      "Validation loss decreased (0.087712 --> 0.087701).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0699443\n",
      "\tspeed: 0.1170s/iter; left time: 1639.0840s\n",
      "\titers: 200, epoch: 38 | loss: 0.0756920\n",
      "\tspeed: 0.0681s/iter; left time: 947.3254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0705406 Vali Loss: 0.0878251 Test Loss: 0.1026505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0680239\n",
      "\tspeed: 0.1161s/iter; left time: 1600.7003s\n",
      "\titers: 200, epoch: 39 | loss: 0.0739465\n",
      "\tspeed: 0.0683s/iter; left time: 935.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0705888 Vali Loss: 0.0879452 Test Loss: 0.1026051\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0695183\n",
      "\tspeed: 0.1158s/iter; left time: 1571.4075s\n",
      "\titers: 200, epoch: 40 | loss: 0.0666538\n",
      "\tspeed: 0.0681s/iter; left time: 917.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0706275 Vali Loss: 0.0877649 Test Loss: 0.1026028\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0692699\n",
      "\tspeed: 0.1162s/iter; left time: 1549.9471s\n",
      "\titers: 200, epoch: 41 | loss: 0.0674599\n",
      "\tspeed: 0.0685s/iter; left time: 906.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0706151 Vali Loss: 0.0878319 Test Loss: 0.1026039\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0714812\n",
      "\tspeed: 0.1163s/iter; left time: 1525.8277s\n",
      "\titers: 200, epoch: 42 | loss: 0.0698971\n",
      "\tspeed: 0.0681s/iter; left time: 886.1202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0706012 Vali Loss: 0.0877543 Test Loss: 0.1026634\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0722987\n",
      "\tspeed: 0.1180s/iter; left time: 1521.8007s\n",
      "\titers: 200, epoch: 43 | loss: 0.0705802\n",
      "\tspeed: 0.0681s/iter; left time: 871.2431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0705847 Vali Loss: 0.0877952 Test Loss: 0.1026460\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0699486\n",
      "\tspeed: 0.1177s/iter; left time: 1490.5583s\n",
      "\titers: 200, epoch: 44 | loss: 0.0705507\n",
      "\tspeed: 0.0682s/iter; left time: 857.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0705450 Vali Loss: 0.0878588 Test Loss: 0.1026352\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0747878\n",
      "\tspeed: 0.1161s/iter; left time: 1444.6048s\n",
      "\titers: 200, epoch: 45 | loss: 0.0717317\n",
      "\tspeed: 0.0682s/iter; left time: 841.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0705373 Vali Loss: 0.0876339 Test Loss: 0.1025996\n",
      "Validation loss decreased (0.087701 --> 0.087634).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0752051\n",
      "\tspeed: 0.1168s/iter; left time: 1427.5335s\n",
      "\titers: 200, epoch: 46 | loss: 0.0732657\n",
      "\tspeed: 0.0683s/iter; left time: 827.7650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0705972 Vali Loss: 0.0877636 Test Loss: 0.1026519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0670457\n",
      "\tspeed: 0.1167s/iter; left time: 1400.1929s\n",
      "\titers: 200, epoch: 47 | loss: 0.0690192\n",
      "\tspeed: 0.0682s/iter; left time: 810.9715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0705293 Vali Loss: 0.0877585 Test Loss: 0.1026266\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0698591\n",
      "\tspeed: 0.1162s/iter; left time: 1368.0350s\n",
      "\titers: 200, epoch: 48 | loss: 0.0677563\n",
      "\tspeed: 0.0681s/iter; left time: 794.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0705553 Vali Loss: 0.0878443 Test Loss: 0.1026310\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0700425\n",
      "\tspeed: 0.1159s/iter; left time: 1338.1389s\n",
      "\titers: 200, epoch: 49 | loss: 0.0663642\n",
      "\tspeed: 0.0683s/iter; left time: 781.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0705249 Vali Loss: 0.0877746 Test Loss: 0.1026161\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0729307\n",
      "\tspeed: 0.1162s/iter; left time: 1316.4437s\n",
      "\titers: 200, epoch: 50 | loss: 0.0685636\n",
      "\tspeed: 0.0683s/iter; left time: 767.1826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0705094 Vali Loss: 0.0878694 Test Loss: 0.1026199\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0732157\n",
      "\tspeed: 0.1163s/iter; left time: 1291.0775s\n",
      "\titers: 200, epoch: 51 | loss: 0.0650010\n",
      "\tspeed: 0.0682s/iter; left time: 749.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0705308 Vali Loss: 0.0877515 Test Loss: 0.1026408\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0707113\n",
      "\tspeed: 0.1155s/iter; left time: 1256.6665s\n",
      "\titers: 200, epoch: 52 | loss: 0.0763716\n",
      "\tspeed: 0.0681s/iter; left time: 733.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0705010 Vali Loss: 0.0877244 Test Loss: 0.1026250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0712100\n",
      "\tspeed: 0.1159s/iter; left time: 1235.0412s\n",
      "\titers: 200, epoch: 53 | loss: 0.0675191\n",
      "\tspeed: 0.0681s/iter; left time: 718.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0705063 Vali Loss: 0.0877397 Test Loss: 0.1026659\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0707961\n",
      "\tspeed: 0.1174s/iter; left time: 1224.0732s\n",
      "\titers: 200, epoch: 54 | loss: 0.0701372\n",
      "\tspeed: 0.0685s/iter; left time: 707.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0704876 Vali Loss: 0.0878127 Test Loss: 0.1026263\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0696509\n",
      "\tspeed: 0.1187s/iter; left time: 1211.0421s\n",
      "\titers: 200, epoch: 55 | loss: 0.0660280\n",
      "\tspeed: 0.0685s/iter; left time: 692.6424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.0704608 Vali Loss: 0.0878102 Test Loss: 0.1026641\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02609824575483799, rmse:0.16154950857162476, mae:0.10259955376386642, rse:0.5573000311851501\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1350485\n",
      "\tspeed: 0.0704s/iter; left time: 1569.2453s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283367\n",
      "\tspeed: 0.0686s/iter; left time: 1523.3137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1371332 Vali Loss: 0.1359186 Test Loss: 0.1564243\n",
      "Validation loss decreased (inf --> 0.135919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0985610\n",
      "\tspeed: 0.1199s/iter; left time: 2648.1026s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824623\n",
      "\tspeed: 0.0685s/iter; left time: 1504.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0930008 Vali Loss: 0.0932679 Test Loss: 0.1046689\n",
      "Validation loss decreased (0.135919 --> 0.093268).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804342\n",
      "\tspeed: 0.1198s/iter; left time: 2618.8854s\n",
      "\titers: 200, epoch: 3 | loss: 0.0779750\n",
      "\tspeed: 0.0685s/iter; left time: 1490.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0793289 Vali Loss: 0.0914860 Test Loss: 0.1031895\n",
      "Validation loss decreased (0.093268 --> 0.091486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0806159\n",
      "\tspeed: 0.1188s/iter; left time: 2570.4593s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749596\n",
      "\tspeed: 0.0685s/iter; left time: 1474.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0774207 Vali Loss: 0.0906169 Test Loss: 0.1029897\n",
      "Validation loss decreased (0.091486 --> 0.090617).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734674\n",
      "\tspeed: 0.1187s/iter; left time: 2540.1744s\n",
      "\titers: 200, epoch: 5 | loss: 0.0709467\n",
      "\tspeed: 0.0682s/iter; left time: 1453.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0763811 Vali Loss: 0.0900442 Test Loss: 0.1027449\n",
      "Validation loss decreased (0.090617 --> 0.090044).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0769009\n",
      "\tspeed: 0.1191s/iter; left time: 2522.2977s\n",
      "\titers: 200, epoch: 6 | loss: 0.0798781\n",
      "\tspeed: 0.0687s/iter; left time: 1447.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0755034 Vali Loss: 0.0893161 Test Loss: 0.1025999\n",
      "Validation loss decreased (0.090044 --> 0.089316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748013\n",
      "\tspeed: 0.1195s/iter; left time: 2503.5218s\n",
      "\titers: 200, epoch: 7 | loss: 0.0699343\n",
      "\tspeed: 0.0685s/iter; left time: 1428.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0749898 Vali Loss: 0.0891517 Test Loss: 0.1022313\n",
      "Validation loss decreased (0.089316 --> 0.089152).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0731926\n",
      "\tspeed: 0.1191s/iter; left time: 2469.1667s\n",
      "\titers: 200, epoch: 8 | loss: 0.0763248\n",
      "\tspeed: 0.0681s/iter; left time: 1406.0134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0744346 Vali Loss: 0.0888427 Test Loss: 0.1025807\n",
      "Validation loss decreased (0.089152 --> 0.088843).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749135\n",
      "\tspeed: 0.1190s/iter; left time: 2439.6769s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725394\n",
      "\tspeed: 0.0686s/iter; left time: 1399.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0740005 Vali Loss: 0.0889117 Test Loss: 0.1022311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735895\n",
      "\tspeed: 0.1182s/iter; left time: 2398.2413s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685794\n",
      "\tspeed: 0.0685s/iter; left time: 1381.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0736818 Vali Loss: 0.0882763 Test Loss: 0.1021831\n",
      "Validation loss decreased (0.088843 --> 0.088276).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0686587\n",
      "\tspeed: 0.1188s/iter; left time: 2383.4469s\n",
      "\titers: 200, epoch: 11 | loss: 0.0753800\n",
      "\tspeed: 0.0685s/iter; left time: 1366.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0733869 Vali Loss: 0.0885128 Test Loss: 0.1024305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0699067\n",
      "\tspeed: 0.1183s/iter; left time: 2347.2859s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729937\n",
      "\tspeed: 0.0685s/iter; left time: 1352.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0730673 Vali Loss: 0.0883502 Test Loss: 0.1023613\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0723066\n",
      "\tspeed: 0.1181s/iter; left time: 2317.2114s\n",
      "\titers: 200, epoch: 13 | loss: 0.0696954\n",
      "\tspeed: 0.0685s/iter; left time: 1337.5893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0728639 Vali Loss: 0.0880580 Test Loss: 0.1021787\n",
      "Validation loss decreased (0.088276 --> 0.088058).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0684518\n",
      "\tspeed: 0.1194s/iter; left time: 2315.5890s\n",
      "\titers: 200, epoch: 14 | loss: 0.0723450\n",
      "\tspeed: 0.0685s/iter; left time: 1321.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0726623 Vali Loss: 0.0878234 Test Loss: 0.1023084\n",
      "Validation loss decreased (0.088058 --> 0.087823).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0754770\n",
      "\tspeed: 0.1187s/iter; left time: 2273.9481s\n",
      "\titers: 200, epoch: 15 | loss: 0.0705056\n",
      "\tspeed: 0.0685s/iter; left time: 1305.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0723844 Vali Loss: 0.0882556 Test Loss: 0.1023628\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741688\n",
      "\tspeed: 0.1181s/iter; left time: 2237.4073s\n",
      "\titers: 200, epoch: 16 | loss: 0.0731742\n",
      "\tspeed: 0.0687s/iter; left time: 1293.9790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 224 | Train Loss: 0.0722727 Vali Loss: 0.0880262 Test Loss: 0.1020618\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704471\n",
      "\tspeed: 0.1202s/iter; left time: 2249.0798s\n",
      "\titers: 200, epoch: 17 | loss: 0.0648888\n",
      "\tspeed: 0.0688s/iter; left time: 1281.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.98s\n",
      "Steps: 224 | Train Loss: 0.0721046 Vali Loss: 0.0878210 Test Loss: 0.1022013\n",
      "Validation loss decreased (0.087823 --> 0.087821).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0698321\n",
      "\tspeed: 0.3378s/iter; left time: 6246.4706s\n",
      "\titers: 200, epoch: 18 | loss: 0.0738711\n",
      "\tspeed: 0.0691s/iter; left time: 1271.8617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:16.22s\n",
      "Steps: 224 | Train Loss: 0.0719306 Vali Loss: 0.0880854 Test Loss: 0.1021067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720899\n",
      "\tspeed: 0.1193s/iter; left time: 2178.8884s\n",
      "\titers: 200, epoch: 19 | loss: 0.0801290\n",
      "\tspeed: 0.0685s/iter; left time: 1244.6685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 224 | Train Loss: 0.0718406 Vali Loss: 0.0880833 Test Loss: 0.1023844\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0720547\n",
      "\tspeed: 0.1183s/iter; left time: 2135.5429s\n",
      "\titers: 200, epoch: 20 | loss: 0.0702580\n",
      "\tspeed: 0.0683s/iter; left time: 1225.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0717006 Vali Loss: 0.0878402 Test Loss: 0.1021511\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0730690\n",
      "\tspeed: 0.1192s/iter; left time: 2124.3285s\n",
      "\titers: 200, epoch: 21 | loss: 0.0687931\n",
      "\tspeed: 0.0683s/iter; left time: 1210.8138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0716337 Vali Loss: 0.0878857 Test Loss: 0.1023159\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0694852\n",
      "\tspeed: 0.1197s/iter; left time: 2106.9395s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696693\n",
      "\tspeed: 0.0685s/iter; left time: 1198.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.0714591 Vali Loss: 0.0878322 Test Loss: 0.1021257\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0696523\n",
      "\tspeed: 0.1184s/iter; left time: 2057.1705s\n",
      "\titers: 200, epoch: 23 | loss: 0.0666929\n",
      "\tspeed: 0.0687s/iter; left time: 1186.2567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0714148 Vali Loss: 0.0878777 Test Loss: 0.1024495\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0707410\n",
      "\tspeed: 0.1182s/iter; left time: 2027.5832s\n",
      "\titers: 200, epoch: 24 | loss: 0.0696989\n",
      "\tspeed: 0.0686s/iter; left time: 1168.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0713207 Vali Loss: 0.0879480 Test Loss: 0.1023523\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0666071\n",
      "\tspeed: 0.1201s/iter; left time: 2033.0903s\n",
      "\titers: 200, epoch: 25 | loss: 0.0697921\n",
      "\tspeed: 0.0686s/iter; left time: 1154.5325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0712574 Vali Loss: 0.0878814 Test Loss: 0.1024345\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0692760\n",
      "\tspeed: 0.1190s/iter; left time: 1986.8559s\n",
      "\titers: 200, epoch: 26 | loss: 0.0700209\n",
      "\tspeed: 0.0682s/iter; left time: 1132.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0711826 Vali Loss: 0.0878382 Test Loss: 0.1024064\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0691675\n",
      "\tspeed: 0.1180s/iter; left time: 1944.3105s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724144\n",
      "\tspeed: 0.0686s/iter; left time: 1123.7788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0711065 Vali Loss: 0.0878209 Test Loss: 0.1023688\n",
      "Validation loss decreased (0.087821 --> 0.087821).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0745372\n",
      "\tspeed: 0.1227s/iter; left time: 1994.7667s\n",
      "\titers: 200, epoch: 28 | loss: 0.0677864\n",
      "\tspeed: 0.0685s/iter; left time: 1107.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.0710921 Vali Loss: 0.0877655 Test Loss: 0.1024723\n",
      "Validation loss decreased (0.087821 --> 0.087765).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0683585\n",
      "\tspeed: 0.1193s/iter; left time: 1912.0059s\n",
      "\titers: 200, epoch: 29 | loss: 0.0687528\n",
      "\tspeed: 0.0683s/iter; left time: 1088.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0710071 Vali Loss: 0.0878820 Test Loss: 0.1025295\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0688418\n",
      "\tspeed: 0.1184s/iter; left time: 1872.0666s\n",
      "\titers: 200, epoch: 30 | loss: 0.0696204\n",
      "\tspeed: 0.0684s/iter; left time: 1074.3598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0709781 Vali Loss: 0.0878687 Test Loss: 0.1024631\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0681575\n",
      "\tspeed: 0.1190s/iter; left time: 1853.9655s\n",
      "\titers: 200, epoch: 31 | loss: 0.0685834\n",
      "\tspeed: 0.0681s/iter; left time: 1054.3868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0709512 Vali Loss: 0.0877548 Test Loss: 0.1024851\n",
      "Validation loss decreased (0.087765 --> 0.087755).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0706097\n",
      "\tspeed: 0.1185s/iter; left time: 1819.6040s\n",
      "\titers: 200, epoch: 32 | loss: 0.0708976\n",
      "\tspeed: 0.0684s/iter; left time: 1043.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0709215 Vali Loss: 0.0878163 Test Loss: 0.1024806\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0749903\n",
      "\tspeed: 0.1187s/iter; left time: 1796.5819s\n",
      "\titers: 200, epoch: 33 | loss: 0.0708938\n",
      "\tspeed: 0.0694s/iter; left time: 1043.9415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 224 | Train Loss: 0.0708929 Vali Loss: 0.0878683 Test Loss: 0.1023930\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0706175\n",
      "\tspeed: 0.1176s/iter; left time: 1753.4913s\n",
      "\titers: 200, epoch: 34 | loss: 0.0725679\n",
      "\tspeed: 0.0681s/iter; left time: 1008.2804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0708099 Vali Loss: 0.0878590 Test Loss: 0.1025046\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0732726\n",
      "\tspeed: 0.1176s/iter; left time: 1726.7687s\n",
      "\titers: 200, epoch: 35 | loss: 0.0754984\n",
      "\tspeed: 0.0681s/iter; left time: 993.2986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:16.92s\n",
      "Steps: 224 | Train Loss: 0.0708670 Vali Loss: 0.0877823 Test Loss: 0.1024617\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0774366\n",
      "\tspeed: 0.2177s/iter; left time: 3147.5712s\n",
      "\titers: 200, epoch: 36 | loss: 0.0740482\n",
      "\tspeed: 0.0682s/iter; left time: 978.7392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:16.04s\n",
      "Steps: 224 | Train Loss: 0.0708381 Vali Loss: 0.0878741 Test Loss: 0.1024432\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0760511\n",
      "\tspeed: 0.1696s/iter; left time: 2415.1887s\n",
      "\titers: 200, epoch: 37 | loss: 0.0682933\n",
      "\tspeed: 0.1863s/iter; left time: 2633.1164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:35.32s\n",
      "Steps: 224 | Train Loss: 0.0707611 Vali Loss: 0.0878462 Test Loss: 0.1025407\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0697511\n",
      "\tspeed: 0.1913s/iter; left time: 2680.5915s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706254\n",
      "\tspeed: 0.0718s/iter; left time: 998.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.93s\n",
      "Steps: 224 | Train Loss: 0.0708227 Vali Loss: 0.0878476 Test Loss: 0.1025691\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0684740\n",
      "\tspeed: 0.1177s/iter; left time: 1622.8936s\n",
      "\titers: 200, epoch: 39 | loss: 0.0708653\n",
      "\tspeed: 0.0680s/iter; left time: 931.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0707966 Vali Loss: 0.0878813 Test Loss: 0.1024478\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0717423\n",
      "\tspeed: 0.1179s/iter; left time: 1599.3272s\n",
      "\titers: 200, epoch: 40 | loss: 0.0685868\n",
      "\tspeed: 0.0680s/iter; left time: 915.0396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0707911 Vali Loss: 0.0877578 Test Loss: 0.1024289\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0677724\n",
      "\tspeed: 0.1179s/iter; left time: 1573.0796s\n",
      "\titers: 200, epoch: 41 | loss: 0.0708079\n",
      "\tspeed: 0.0687s/iter; left time: 910.0566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0707299 Vali Loss: 0.0878519 Test Loss: 0.1024545\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025986187160015106, rmse:0.1612023115158081, mae:0.10248507559299469, rse:0.5561022758483887\n",
      "Intermediate time for GB and pred_len 24: 00h:30m:54.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1405991\n",
      "\tspeed: 0.0894s/iter; left time: 1994.2111s\n",
      "\titers: 200, epoch: 1 | loss: 0.1340275\n",
      "\tspeed: 0.0687s/iter; left time: 1524.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.81s\n",
      "Steps: 224 | Train Loss: 0.1448432 Vali Loss: 0.1478213 Test Loss: 0.1730928\n",
      "Validation loss decreased (inf --> 0.147821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138117\n",
      "\tspeed: 0.1213s/iter; left time: 2678.6025s\n",
      "\titers: 200, epoch: 2 | loss: 0.1045887\n",
      "\tspeed: 0.0686s/iter; left time: 1507.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 224 | Train Loss: 0.1130604 Vali Loss: 0.1190637 Test Loss: 0.1405119\n",
      "Validation loss decreased (0.147821 --> 0.119064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055495\n",
      "\tspeed: 0.1203s/iter; left time: 2627.9081s\n",
      "\titers: 200, epoch: 3 | loss: 0.0997061\n",
      "\tspeed: 0.0686s/iter; left time: 1492.3047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1032594 Vali Loss: 0.1175504 Test Loss: 0.1404777\n",
      "Validation loss decreased (0.119064 --> 0.117550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0996446\n",
      "\tspeed: 0.1195s/iter; left time: 2583.9106s\n",
      "\titers: 200, epoch: 4 | loss: 0.1002228\n",
      "\tspeed: 0.0687s/iter; left time: 1479.2544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1012278 Vali Loss: 0.1170777 Test Loss: 0.1409550\n",
      "Validation loss decreased (0.117550 --> 0.117078).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1005896\n",
      "\tspeed: 0.1204s/iter; left time: 2577.1258s\n",
      "\titers: 200, epoch: 5 | loss: 0.1019444\n",
      "\tspeed: 0.0705s/iter; left time: 1501.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.88s\n",
      "Steps: 224 | Train Loss: 0.0999217 Vali Loss: 0.1165160 Test Loss: 0.1420076\n",
      "Validation loss decreased (0.117078 --> 0.116516).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0982100\n",
      "\tspeed: 0.1232s/iter; left time: 2609.0948s\n",
      "\titers: 200, epoch: 6 | loss: 0.1017919\n",
      "\tspeed: 0.0685s/iter; left time: 1444.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 224 | Train Loss: 0.0987352 Vali Loss: 0.1165895 Test Loss: 0.1424067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0939507\n",
      "\tspeed: 0.1228s/iter; left time: 2573.0127s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043875\n",
      "\tspeed: 0.0686s/iter; left time: 1430.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.0976624 Vali Loss: 0.1166685 Test Loss: 0.1426034\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0960657\n",
      "\tspeed: 0.1201s/iter; left time: 2490.8351s\n",
      "\titers: 200, epoch: 8 | loss: 0.0936981\n",
      "\tspeed: 0.0686s/iter; left time: 1415.1463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0965947 Vali Loss: 0.1169973 Test Loss: 0.1427235\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0966231\n",
      "\tspeed: 0.1194s/iter; left time: 2448.7314s\n",
      "\titers: 200, epoch: 9 | loss: 0.0959772\n",
      "\tspeed: 0.0687s/iter; left time: 1401.3378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0956147 Vali Loss: 0.1171770 Test Loss: 0.1436713\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0897570\n",
      "\tspeed: 0.1188s/iter; left time: 2410.0226s\n",
      "\titers: 200, epoch: 10 | loss: 0.0925299\n",
      "\tspeed: 0.0685s/iter; left time: 1382.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0947032 Vali Loss: 0.1173011 Test Loss: 0.1430885\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0937624\n",
      "\tspeed: 0.1179s/iter; left time: 2365.5809s\n",
      "\titers: 200, epoch: 11 | loss: 0.0942345\n",
      "\tspeed: 0.0687s/iter; left time: 1371.6999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0939199 Vali Loss: 0.1177284 Test Loss: 0.1446626\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0962773\n",
      "\tspeed: 0.1184s/iter; left time: 2348.8117s\n",
      "\titers: 200, epoch: 12 | loss: 0.0923434\n",
      "\tspeed: 0.0687s/iter; left time: 1355.4154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0932281 Vali Loss: 0.1179432 Test Loss: 0.1441796\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0915588\n",
      "\tspeed: 0.1190s/iter; left time: 2334.1176s\n",
      "\titers: 200, epoch: 13 | loss: 0.0947063\n",
      "\tspeed: 0.0685s/iter; left time: 1336.9325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0925696 Vali Loss: 0.1184001 Test Loss: 0.1446941\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0948453\n",
      "\tspeed: 0.1207s/iter; left time: 2340.5900s\n",
      "\titers: 200, epoch: 14 | loss: 0.0923975\n",
      "\tspeed: 0.0688s/iter; left time: 1327.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0918646 Vali Loss: 0.1180691 Test Loss: 0.1447409\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0889596\n",
      "\tspeed: 0.1223s/iter; left time: 2343.2314s\n",
      "\titers: 200, epoch: 15 | loss: 0.0921152\n",
      "\tspeed: 0.0687s/iter; left time: 1309.3565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0913107 Vali Loss: 0.1185684 Test Loss: 0.1451798\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04291575402021408, rmse:0.20716117322444916, mae:0.14200760424137115, rse:0.7163922190666199\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1487318\n",
      "\tspeed: 0.0704s/iter; left time: 1570.4113s\n",
      "\titers: 200, epoch: 1 | loss: 0.1370086\n",
      "\tspeed: 0.0686s/iter; left time: 1522.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1440499 Vali Loss: 0.1468293 Test Loss: 0.1719950\n",
      "Validation loss decreased (inf --> 0.146829).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138063\n",
      "\tspeed: 0.1286s/iter; left time: 2838.4423s\n",
      "\titers: 200, epoch: 2 | loss: 0.1064841\n",
      "\tspeed: 0.1335s/iter; left time: 2934.2487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.05s\n",
      "Steps: 224 | Train Loss: 0.1139268 Vali Loss: 0.1199203 Test Loss: 0.1413460\n",
      "Validation loss decreased (0.146829 --> 0.119920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1038082\n",
      "\tspeed: 0.1272s/iter; left time: 2780.0861s\n",
      "\titers: 200, epoch: 3 | loss: 0.1057726\n",
      "\tspeed: 0.0703s/iter; left time: 1529.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:16.10s\n",
      "Steps: 224 | Train Loss: 0.1035078 Vali Loss: 0.1172815 Test Loss: 0.1411853\n",
      "Validation loss decreased (0.119920 --> 0.117282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1052683\n",
      "\tspeed: 0.2809s/iter; left time: 6075.1382s\n",
      "\titers: 200, epoch: 4 | loss: 0.0991758\n",
      "\tspeed: 0.2453s/iter; left time: 5281.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.55s\n",
      "Steps: 224 | Train Loss: 0.1012741 Vali Loss: 0.1170539 Test Loss: 0.1416775\n",
      "Validation loss decreased (0.117282 --> 0.117054).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1004815\n",
      "\tspeed: 0.8175s/iter; left time: 17498.1451s\n",
      "\titers: 200, epoch: 5 | loss: 0.0980172\n",
      "\tspeed: 0.2404s/iter; left time: 5122.3728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:56.31s\n",
      "Steps: 224 | Train Loss: 0.0997677 Vali Loss: 0.1162018 Test Loss: 0.1421025\n",
      "Validation loss decreased (0.117054 --> 0.116202).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0961827\n",
      "\tspeed: 0.8096s/iter; left time: 17147.9534s\n",
      "\titers: 200, epoch: 6 | loss: 0.0999542\n",
      "\tspeed: 0.2562s/iter; left time: 5400.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.70s\n",
      "Steps: 224 | Train Loss: 0.0984421 Vali Loss: 0.1164734 Test Loss: 0.1426005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0981211\n",
      "\tspeed: 0.6218s/iter; left time: 13030.5121s\n",
      "\titers: 200, epoch: 7 | loss: 0.0941548\n",
      "\tspeed: 0.0852s/iter; left time: 1776.4255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:23.08s\n",
      "Steps: 224 | Train Loss: 0.0972705 Vali Loss: 0.1162785 Test Loss: 0.1422600\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0962675\n",
      "\tspeed: 0.1340s/iter; left time: 2778.7869s\n",
      "\titers: 200, epoch: 8 | loss: 0.0931595\n",
      "\tspeed: 0.0697s/iter; left time: 1438.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.91s\n",
      "Steps: 224 | Train Loss: 0.0962770 Vali Loss: 0.1164722 Test Loss: 0.1422352\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0926272\n",
      "\tspeed: 0.1242s/iter; left time: 2546.9365s\n",
      "\titers: 200, epoch: 9 | loss: 0.0948652\n",
      "\tspeed: 0.0695s/iter; left time: 1418.0947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.88s\n",
      "Steps: 224 | Train Loss: 0.0952981 Vali Loss: 0.1172631 Test Loss: 0.1434910\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920814\n",
      "\tspeed: 0.1228s/iter; left time: 2491.7438s\n",
      "\titers: 200, epoch: 10 | loss: 0.0969522\n",
      "\tspeed: 0.0693s/iter; left time: 1398.8327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.78s\n",
      "Steps: 224 | Train Loss: 0.0944917 Vali Loss: 0.1168175 Test Loss: 0.1432077\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0946180\n",
      "\tspeed: 0.1229s/iter; left time: 2465.5769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0920481\n",
      "\tspeed: 0.0695s/iter; left time: 1387.4037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.81s\n",
      "Steps: 224 | Train Loss: 0.0936815 Vali Loss: 0.1166289 Test Loss: 0.1433958\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0943805\n",
      "\tspeed: 0.1222s/iter; left time: 2423.8897s\n",
      "\titers: 200, epoch: 12 | loss: 0.0935987\n",
      "\tspeed: 0.0692s/iter; left time: 1364.9152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 224 | Train Loss: 0.0930455 Vali Loss: 0.1179340 Test Loss: 0.1440605\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0935798\n",
      "\tspeed: 0.1215s/iter; left time: 2383.7646s\n",
      "\titers: 200, epoch: 13 | loss: 0.0908417\n",
      "\tspeed: 0.0690s/iter; left time: 1347.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.72s\n",
      "Steps: 224 | Train Loss: 0.0923338 Vali Loss: 0.1177619 Test Loss: 0.1443216\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0884786\n",
      "\tspeed: 0.1203s/iter; left time: 2333.2899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0921750\n",
      "\tspeed: 0.0691s/iter; left time: 1333.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 224 | Train Loss: 0.0917843 Vali Loss: 0.1178600 Test Loss: 0.1436017\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0891715\n",
      "\tspeed: 0.1201s/iter; left time: 2301.0858s\n",
      "\titers: 200, epoch: 15 | loss: 0.0895614\n",
      "\tspeed: 0.0689s/iter; left time: 1313.2524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.0912016 Vali Loss: 0.1195128 Test Loss: 0.1452190\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04321127384901047, rmse:0.20787321031093597, mae:0.14210249483585358, rse:0.718854546546936\n",
      "Intermediate time for GB and pred_len 96: 00h:14m:10.38s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1382906\n",
      "\tspeed: 0.0873s/iter; left time: 1939.0829s\n",
      "\titers: 200, epoch: 1 | loss: 0.1395264\n",
      "\tspeed: 0.0694s/iter; left time: 1534.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.96s\n",
      "Steps: 223 | Train Loss: 0.1463332 Vali Loss: 0.1503430 Test Loss: 0.1766358\n",
      "Validation loss decreased (inf --> 0.150343).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1166224\n",
      "\tspeed: 0.1210s/iter; left time: 2659.6390s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143445\n",
      "\tspeed: 0.0693s/iter; left time: 1515.5847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.72s\n",
      "Steps: 223 | Train Loss: 0.1172942 Vali Loss: 0.1232760 Test Loss: 0.1470696\n",
      "Validation loss decreased (0.150343 --> 0.123276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1106884\n",
      "\tspeed: 0.1217s/iter; left time: 2647.4163s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059793\n",
      "\tspeed: 0.0693s/iter; left time: 1500.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.1077958 Vali Loss: 0.1214558 Test Loss: 0.1481016\n",
      "Validation loss decreased (0.123276 --> 0.121456).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1101232\n",
      "\tspeed: 0.1220s/iter; left time: 2625.9509s\n",
      "\titers: 200, epoch: 4 | loss: 0.1033802\n",
      "\tspeed: 0.0693s/iter; left time: 1485.2224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1054731 Vali Loss: 0.1212433 Test Loss: 0.1480350\n",
      "Validation loss decreased (0.121456 --> 0.121243).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1055346\n",
      "\tspeed: 0.1208s/iter; left time: 2573.2861s\n",
      "\titers: 200, epoch: 5 | loss: 0.1031732\n",
      "\tspeed: 0.0692s/iter; left time: 1467.1504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1035302 Vali Loss: 0.1213536 Test Loss: 0.1497387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1046123\n",
      "\tspeed: 0.1209s/iter; left time: 2549.2983s\n",
      "\titers: 200, epoch: 6 | loss: 0.1001897\n",
      "\tspeed: 0.0691s/iter; left time: 1450.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1017962 Vali Loss: 0.1209992 Test Loss: 0.1488341\n",
      "Validation loss decreased (0.121243 --> 0.120999).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0978718\n",
      "\tspeed: 0.1242s/iter; left time: 2591.1679s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973325\n",
      "\tspeed: 0.0692s/iter; left time: 1437.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.1003711 Vali Loss: 0.1218036 Test Loss: 0.1504623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0989455\n",
      "\tspeed: 0.1191s/iter; left time: 2458.1201s\n",
      "\titers: 200, epoch: 8 | loss: 0.1002991\n",
      "\tspeed: 0.0693s/iter; left time: 1422.6369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.0990875 Vali Loss: 0.1218348 Test Loss: 0.1500351\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0976945\n",
      "\tspeed: 0.1187s/iter; left time: 2422.8535s\n",
      "\titers: 200, epoch: 9 | loss: 0.0966081\n",
      "\tspeed: 0.0691s/iter; left time: 1404.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0978859 Vali Loss: 0.1225475 Test Loss: 0.1525755\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0926314\n",
      "\tspeed: 0.1191s/iter; left time: 2405.5362s\n",
      "\titers: 200, epoch: 10 | loss: 0.0951924\n",
      "\tspeed: 0.0691s/iter; left time: 1389.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0968670 Vali Loss: 0.1221416 Test Loss: 0.1514783\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0938441\n",
      "\tspeed: 0.1191s/iter; left time: 2378.9691s\n",
      "\titers: 200, epoch: 11 | loss: 0.0952162\n",
      "\tspeed: 0.0695s/iter; left time: 1380.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0958730 Vali Loss: 0.1224927 Test Loss: 0.1522670\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0958836\n",
      "\tspeed: 0.1193s/iter; left time: 2355.6395s\n",
      "\titers: 200, epoch: 12 | loss: 0.0952033\n",
      "\tspeed: 0.0692s/iter; left time: 1360.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.0949836 Vali Loss: 0.1231256 Test Loss: 0.1527645\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0955233\n",
      "\tspeed: 0.1200s/iter; left time: 2343.5379s\n",
      "\titers: 200, epoch: 13 | loss: 0.0914457\n",
      "\tspeed: 0.0693s/iter; left time: 1346.2415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.0941686 Vali Loss: 0.1234475 Test Loss: 0.1532591\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0911015\n",
      "\tspeed: 0.1193s/iter; left time: 2301.7760s\n",
      "\titers: 200, epoch: 14 | loss: 0.0922876\n",
      "\tspeed: 0.0691s/iter; left time: 1327.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.0934280 Vali Loss: 0.1233402 Test Loss: 0.1538700\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0898075\n",
      "\tspeed: 0.1189s/iter; left time: 2267.6586s\n",
      "\titers: 200, epoch: 15 | loss: 0.0903602\n",
      "\tspeed: 0.0692s/iter; left time: 1313.0621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.0927919 Vali Loss: 0.1235200 Test Loss: 0.1532498\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0931074\n",
      "\tspeed: 0.1192s/iter; left time: 2247.1640s\n",
      "\titers: 200, epoch: 16 | loss: 0.0941772\n",
      "\tspeed: 0.0691s/iter; left time: 1296.6019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.0921870 Vali Loss: 0.1240861 Test Loss: 0.1538316\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04635089635848999, rmse:0.21529258787631989, mae:0.14883416891098022, rse:0.7464503049850464\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1435386\n",
      "\tspeed: 0.0709s/iter; left time: 1574.5806s\n",
      "\titers: 200, epoch: 1 | loss: 0.1412452\n",
      "\tspeed: 0.0693s/iter; left time: 1531.2761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1469587 Vali Loss: 0.1503619 Test Loss: 0.1767886\n",
      "Validation loss decreased (inf --> 0.150362).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1120439\n",
      "\tspeed: 0.1237s/iter; left time: 2717.7933s\n",
      "\titers: 200, epoch: 2 | loss: 0.1109545\n",
      "\tspeed: 0.0697s/iter; left time: 1525.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.1172456 Vali Loss: 0.1231335 Test Loss: 0.1470964\n",
      "Validation loss decreased (0.150362 --> 0.123134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1074619\n",
      "\tspeed: 0.1203s/iter; left time: 2618.0072s\n",
      "\titers: 200, epoch: 3 | loss: 0.1085829\n",
      "\tspeed: 0.0693s/iter; left time: 1499.8180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1079589 Vali Loss: 0.1217438 Test Loss: 0.1472394\n",
      "Validation loss decreased (0.123134 --> 0.121744).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1029040\n",
      "\tspeed: 0.1198s/iter; left time: 2579.2513s\n",
      "\titers: 200, epoch: 4 | loss: 0.1092405\n",
      "\tspeed: 0.0693s/iter; left time: 1484.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1056315 Vali Loss: 0.1210526 Test Loss: 0.1478875\n",
      "Validation loss decreased (0.121744 --> 0.121053).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1050835\n",
      "\tspeed: 0.1224s/iter; left time: 2608.6936s\n",
      "\titers: 200, epoch: 5 | loss: 0.1013691\n",
      "\tspeed: 0.0692s/iter; left time: 1467.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1037747 Vali Loss: 0.1207483 Test Loss: 0.1486701\n",
      "Validation loss decreased (0.121053 --> 0.120748).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023986\n",
      "\tspeed: 0.1197s/iter; left time: 2524.9708s\n",
      "\titers: 200, epoch: 6 | loss: 0.1022196\n",
      "\tspeed: 0.0693s/iter; left time: 1454.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1021649 Vali Loss: 0.1210408 Test Loss: 0.1488155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028455\n",
      "\tspeed: 0.1203s/iter; left time: 2509.4943s\n",
      "\titers: 200, epoch: 7 | loss: 0.1001752\n",
      "\tspeed: 0.0692s/iter; left time: 1437.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 223 | Train Loss: 0.1008448 Vali Loss: 0.1212449 Test Loss: 0.1488863\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1033451\n",
      "\tspeed: 0.1190s/iter; left time: 2456.3905s\n",
      "\titers: 200, epoch: 8 | loss: 0.0971676\n",
      "\tspeed: 0.0694s/iter; left time: 1424.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.0996199 Vali Loss: 0.1219015 Test Loss: 0.1491982\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0990058\n",
      "\tspeed: 0.1190s/iter; left time: 2428.9481s\n",
      "\titers: 200, epoch: 9 | loss: 0.1007090\n",
      "\tspeed: 0.0694s/iter; left time: 1409.2702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0985102 Vali Loss: 0.1213971 Test Loss: 0.1493594\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0975233\n",
      "\tspeed: 0.1187s/iter; left time: 2397.7097s\n",
      "\titers: 200, epoch: 10 | loss: 0.0986166\n",
      "\tspeed: 0.0694s/iter; left time: 1394.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.0975176 Vali Loss: 0.1219288 Test Loss: 0.1506020\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0978751\n",
      "\tspeed: 0.1197s/iter; left time: 2391.2975s\n",
      "\titers: 200, epoch: 11 | loss: 0.0927297\n",
      "\tspeed: 0.0694s/iter; left time: 1378.0695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.0966755 Vali Loss: 0.1223882 Test Loss: 0.1509488\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987984\n",
      "\tspeed: 0.1190s/iter; left time: 2349.5385s\n",
      "\titers: 200, epoch: 12 | loss: 0.0944003\n",
      "\tspeed: 0.0693s/iter; left time: 1361.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.0959382 Vali Loss: 0.1223772 Test Loss: 0.1499679\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0941867\n",
      "\tspeed: 0.1187s/iter; left time: 2317.9481s\n",
      "\titers: 200, epoch: 13 | loss: 0.0910453\n",
      "\tspeed: 0.0693s/iter; left time: 1346.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.0952061 Vali Loss: 0.1230551 Test Loss: 0.1518901\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0943975\n",
      "\tspeed: 0.1193s/iter; left time: 2302.1516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0946359\n",
      "\tspeed: 0.0693s/iter; left time: 1331.5176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.0946333 Vali Loss: 0.1231219 Test Loss: 0.1512958\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0915139\n",
      "\tspeed: 0.1197s/iter; left time: 2283.2056s\n",
      "\titers: 200, epoch: 15 | loss: 0.0912506\n",
      "\tspeed: 0.0693s/iter; left time: 1315.7765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 223 | Train Loss: 0.0940620 Vali Loss: 0.1231321 Test Loss: 0.1521490\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.046182967722415924, rmse:0.21490222215652466, mae:0.14867003262043, rse:0.7450969219207764\n",
      "Intermediate time for GB and pred_len 168: 00h:10m:00.72s\n",
      "Intermediate time for GB: 00h:55m:05.11s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1529711\n",
      "\tspeed: 0.0596s/iter; left time: 1329.7049s\n",
      "\titers: 200, epoch: 1 | loss: 0.1360108\n",
      "\tspeed: 0.0421s/iter; left time: 935.5135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 224 | Train Loss: 0.1550293 Vali Loss: 0.1393889 Test Loss: 0.1681391\n",
      "Validation loss decreased (inf --> 0.139389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0734895\n",
      "\tspeed: 0.0764s/iter; left time: 1687.5220s\n",
      "\titers: 200, epoch: 2 | loss: 0.0732423\n",
      "\tspeed: 0.0421s/iter; left time: 925.2124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0805362 Vali Loss: 0.0644472 Test Loss: 0.0716057\n",
      "Validation loss decreased (0.139389 --> 0.064447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670037\n",
      "\tspeed: 0.0765s/iter; left time: 1670.8438s\n",
      "\titers: 200, epoch: 3 | loss: 0.0633987\n",
      "\tspeed: 0.0421s/iter; left time: 915.5253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0639687 Vali Loss: 0.0604835 Test Loss: 0.0676901\n",
      "Validation loss decreased (0.064447 --> 0.060484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0613006\n",
      "\tspeed: 0.0761s/iter; left time: 1646.4538s\n",
      "\titers: 200, epoch: 4 | loss: 0.0589914\n",
      "\tspeed: 0.0422s/iter; left time: 907.8062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0607848 Vali Loss: 0.0584154 Test Loss: 0.0650347\n",
      "Validation loss decreased (0.060484 --> 0.058415).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0590660\n",
      "\tspeed: 0.0762s/iter; left time: 1631.6562s\n",
      "\titers: 200, epoch: 5 | loss: 0.0541014\n",
      "\tspeed: 0.0421s/iter; left time: 897.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0585594 Vali Loss: 0.0570394 Test Loss: 0.0637940\n",
      "Validation loss decreased (0.058415 --> 0.057039).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569912\n",
      "\tspeed: 0.0761s/iter; left time: 1611.4262s\n",
      "\titers: 200, epoch: 6 | loss: 0.0541913\n",
      "\tspeed: 0.0421s/iter; left time: 887.0130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0571212 Vali Loss: 0.0560755 Test Loss: 0.0628937\n",
      "Validation loss decreased (0.057039 --> 0.056075).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585085\n",
      "\tspeed: 0.0759s/iter; left time: 1591.1244s\n",
      "\titers: 200, epoch: 7 | loss: 0.0523225\n",
      "\tspeed: 0.0421s/iter; left time: 879.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0562777 Vali Loss: 0.0558876 Test Loss: 0.0626064\n",
      "Validation loss decreased (0.056075 --> 0.055888).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0545201\n",
      "\tspeed: 0.0761s/iter; left time: 1577.9117s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590803\n",
      "\tspeed: 0.0420s/iter; left time: 867.6134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0555750 Vali Loss: 0.0552337 Test Loss: 0.0619180\n",
      "Validation loss decreased (0.055888 --> 0.055234).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0534203\n",
      "\tspeed: 0.0769s/iter; left time: 1577.3118s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581229\n",
      "\tspeed: 0.0421s/iter; left time: 858.7538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0550523 Vali Loss: 0.0547637 Test Loss: 0.0615436\n",
      "Validation loss decreased (0.055234 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546895\n",
      "\tspeed: 0.0768s/iter; left time: 1557.8429s\n",
      "\titers: 200, epoch: 10 | loss: 0.0517974\n",
      "\tspeed: 0.0421s/iter; left time: 850.1216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0545337 Vali Loss: 0.0549140 Test Loss: 0.0615433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0547254\n",
      "\tspeed: 0.0753s/iter; left time: 1510.6060s\n",
      "\titers: 200, epoch: 11 | loss: 0.0556244\n",
      "\tspeed: 0.0420s/iter; left time: 839.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0541035 Vali Loss: 0.0542901 Test Loss: 0.0609592\n",
      "Validation loss decreased (0.054764 --> 0.054290).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0526986\n",
      "\tspeed: 0.0749s/iter; left time: 1484.9537s\n",
      "\titers: 200, epoch: 12 | loss: 0.0537033\n",
      "\tspeed: 0.0421s/iter; left time: 830.4634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0538599 Vali Loss: 0.0542014 Test Loss: 0.0608091\n",
      "Validation loss decreased (0.054290 --> 0.054201).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0556784\n",
      "\tspeed: 0.0758s/iter; left time: 1487.0728s\n",
      "\titers: 200, epoch: 13 | loss: 0.0531932\n",
      "\tspeed: 0.0421s/iter; left time: 821.9467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0536762 Vali Loss: 0.0541160 Test Loss: 0.0608011\n",
      "Validation loss decreased (0.054201 --> 0.054116).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0536481\n",
      "\tspeed: 0.0760s/iter; left time: 1474.4599s\n",
      "\titers: 200, epoch: 14 | loss: 0.0535595\n",
      "\tspeed: 0.0422s/iter; left time: 814.6818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0534330 Vali Loss: 0.0540443 Test Loss: 0.0607316\n",
      "Validation loss decreased (0.054116 --> 0.054044).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0523399\n",
      "\tspeed: 0.0756s/iter; left time: 1449.4713s\n",
      "\titers: 200, epoch: 15 | loss: 0.0528310\n",
      "\tspeed: 0.0420s/iter; left time: 801.5816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0531772 Vali Loss: 0.0539118 Test Loss: 0.0605432\n",
      "Validation loss decreased (0.054044 --> 0.053912).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0517506\n",
      "\tspeed: 0.0768s/iter; left time: 1455.2459s\n",
      "\titers: 200, epoch: 16 | loss: 0.0502353\n",
      "\tspeed: 0.0419s/iter; left time: 789.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0530458 Vali Loss: 0.0537179 Test Loss: 0.0605205\n",
      "Validation loss decreased (0.053912 --> 0.053718).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0516205\n",
      "\tspeed: 0.0748s/iter; left time: 1400.1206s\n",
      "\titers: 200, epoch: 17 | loss: 0.0487740\n",
      "\tspeed: 0.0419s/iter; left time: 780.3893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0528856 Vali Loss: 0.0536976 Test Loss: 0.0603235\n",
      "Validation loss decreased (0.053718 --> 0.053698).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0495635\n",
      "\tspeed: 0.0745s/iter; left time: 1376.9593s\n",
      "\titers: 200, epoch: 18 | loss: 0.0475049\n",
      "\tspeed: 0.0419s/iter; left time: 771.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0527332 Vali Loss: 0.0535530 Test Loss: 0.0601319\n",
      "Validation loss decreased (0.053698 --> 0.053553).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0542793\n",
      "\tspeed: 0.0751s/iter; left time: 1372.8692s\n",
      "\titers: 200, epoch: 19 | loss: 0.0542914\n",
      "\tspeed: 0.0419s/iter; left time: 761.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0526262 Vali Loss: 0.0534551 Test Loss: 0.0600646\n",
      "Validation loss decreased (0.053553 --> 0.053455).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0502990\n",
      "\tspeed: 0.0747s/iter; left time: 1348.6633s\n",
      "\titers: 200, epoch: 20 | loss: 0.0520770\n",
      "\tspeed: 0.0419s/iter; left time: 751.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0525189 Vali Loss: 0.0534990 Test Loss: 0.0601889\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0514833\n",
      "\tspeed: 0.0742s/iter; left time: 1322.9144s\n",
      "\titers: 200, epoch: 21 | loss: 0.0518561\n",
      "\tspeed: 0.0419s/iter; left time: 743.0023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0523950 Vali Loss: 0.0533594 Test Loss: 0.0600421\n",
      "Validation loss decreased (0.053455 --> 0.053359).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0482492\n",
      "\tspeed: 0.0751s/iter; left time: 1321.4273s\n",
      "\titers: 200, epoch: 22 | loss: 0.0523444\n",
      "\tspeed: 0.0418s/iter; left time: 731.3011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0523219 Vali Loss: 0.0532337 Test Loss: 0.0598630\n",
      "Validation loss decreased (0.053359 --> 0.053234).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0495374\n",
      "\tspeed: 0.0742s/iter; left time: 1289.0237s\n",
      "\titers: 200, epoch: 23 | loss: 0.0533514\n",
      "\tspeed: 0.0419s/iter; left time: 723.5867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0522467 Vali Loss: 0.0533042 Test Loss: 0.0599243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0537487\n",
      "\tspeed: 0.0740s/iter; left time: 1269.3511s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510432\n",
      "\tspeed: 0.0419s/iter; left time: 713.5077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0522055 Vali Loss: 0.0532749 Test Loss: 0.0598150\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0508326\n",
      "\tspeed: 0.0740s/iter; left time: 1252.8814s\n",
      "\titers: 200, epoch: 25 | loss: 0.0547152\n",
      "\tspeed: 0.0419s/iter; left time: 704.1299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0521477 Vali Loss: 0.0531669 Test Loss: 0.0598374\n",
      "Validation loss decreased (0.053234 --> 0.053167).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0478256\n",
      "\tspeed: 0.0753s/iter; left time: 1257.8698s\n",
      "\titers: 200, epoch: 26 | loss: 0.0542118\n",
      "\tspeed: 0.0419s/iter; left time: 695.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0520078 Vali Loss: 0.0532341 Test Loss: 0.0598802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0524855\n",
      "\tspeed: 0.0745s/iter; left time: 1227.8457s\n",
      "\titers: 200, epoch: 27 | loss: 0.0518160\n",
      "\tspeed: 0.0419s/iter; left time: 685.8340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0520100 Vali Loss: 0.0530923 Test Loss: 0.0596831\n",
      "Validation loss decreased (0.053167 --> 0.053092).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0535040\n",
      "\tspeed: 0.0744s/iter; left time: 1209.1036s\n",
      "\titers: 200, epoch: 28 | loss: 0.0530858\n",
      "\tspeed: 0.0419s/iter; left time: 676.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0519409 Vali Loss: 0.0530335 Test Loss: 0.0596972\n",
      "Validation loss decreased (0.053092 --> 0.053034).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0497071\n",
      "\tspeed: 0.0748s/iter; left time: 1199.3714s\n",
      "\titers: 200, epoch: 29 | loss: 0.0555924\n",
      "\tspeed: 0.0419s/iter; left time: 666.9074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0519867 Vali Loss: 0.0531298 Test Loss: 0.0597869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0511343\n",
      "\tspeed: 0.0743s/iter; left time: 1174.7319s\n",
      "\titers: 200, epoch: 30 | loss: 0.0550379\n",
      "\tspeed: 0.0418s/iter; left time: 657.1449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0519589 Vali Loss: 0.0530690 Test Loss: 0.0597366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0516089\n",
      "\tspeed: 0.0742s/iter; left time: 1156.6521s\n",
      "\titers: 200, epoch: 31 | loss: 0.0502292\n",
      "\tspeed: 0.0418s/iter; left time: 647.8643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0518643 Vali Loss: 0.0530980 Test Loss: 0.0596929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0494124\n",
      "\tspeed: 0.0739s/iter; left time: 1135.3118s\n",
      "\titers: 200, epoch: 32 | loss: 0.0510262\n",
      "\tspeed: 0.0419s/iter; left time: 638.8566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0517700 Vali Loss: 0.0531316 Test Loss: 0.0597132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0485354\n",
      "\tspeed: 0.0741s/iter; left time: 1121.3862s\n",
      "\titers: 200, epoch: 33 | loss: 0.0532829\n",
      "\tspeed: 0.0419s/iter; left time: 630.3779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0518294 Vali Loss: 0.0531285 Test Loss: 0.0597745\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0523017\n",
      "\tspeed: 0.0740s/iter; left time: 1103.3919s\n",
      "\titers: 200, epoch: 34 | loss: 0.0521809\n",
      "\tspeed: 0.0419s/iter; left time: 620.3057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0517885 Vali Loss: 0.0531236 Test Loss: 0.0595324\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0526446\n",
      "\tspeed: 0.0743s/iter; left time: 1091.8115s\n",
      "\titers: 200, epoch: 35 | loss: 0.0531692\n",
      "\tspeed: 0.0419s/iter; left time: 610.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0517643 Vali Loss: 0.0528842 Test Loss: 0.0594883\n",
      "Validation loss decreased (0.053034 --> 0.052884).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0511099\n",
      "\tspeed: 0.0750s/iter; left time: 1084.8478s\n",
      "\titers: 200, epoch: 36 | loss: 0.0518669\n",
      "\tspeed: 0.0419s/iter; left time: 601.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0517620 Vali Loss: 0.0530359 Test Loss: 0.0596728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0513136\n",
      "\tspeed: 0.0747s/iter; left time: 1063.3120s\n",
      "\titers: 200, epoch: 37 | loss: 0.0500350\n",
      "\tspeed: 0.0419s/iter; left time: 592.5705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0517964 Vali Loss: 0.0530424 Test Loss: 0.0596265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0505333\n",
      "\tspeed: 0.0748s/iter; left time: 1048.5269s\n",
      "\titers: 200, epoch: 38 | loss: 0.0558573\n",
      "\tspeed: 0.0419s/iter; left time: 582.8466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0517588 Vali Loss: 0.0529814 Test Loss: 0.0595264\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0490988\n",
      "\tspeed: 0.0739s/iter; left time: 1018.3320s\n",
      "\titers: 200, epoch: 39 | loss: 0.0539161\n",
      "\tspeed: 0.0418s/iter; left time: 572.6839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0517282 Vali Loss: 0.0530113 Test Loss: 0.0595206\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0515784\n",
      "\tspeed: 0.0745s/iter; left time: 1010.0002s\n",
      "\titers: 200, epoch: 40 | loss: 0.0517620\n",
      "\tspeed: 0.0418s/iter; left time: 563.0598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516523 Vali Loss: 0.0530574 Test Loss: 0.0596935\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0514502\n",
      "\tspeed: 0.0742s/iter; left time: 989.3825s\n",
      "\titers: 200, epoch: 41 | loss: 0.0488613\n",
      "\tspeed: 0.0419s/iter; left time: 554.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0516880 Vali Loss: 0.0528703 Test Loss: 0.0594812\n",
      "Validation loss decreased (0.052884 --> 0.052870).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0496368\n",
      "\tspeed: 0.0750s/iter; left time: 983.8314s\n",
      "\titers: 200, epoch: 42 | loss: 0.0539314\n",
      "\tspeed: 0.0418s/iter; left time: 544.2283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516577 Vali Loss: 0.0529605 Test Loss: 0.0594789\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0520530\n",
      "\tspeed: 0.0736s/iter; left time: 949.4889s\n",
      "\titers: 200, epoch: 43 | loss: 0.0479843\n",
      "\tspeed: 0.0419s/iter; left time: 535.4067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0516277 Vali Loss: 0.0529979 Test Loss: 0.0595466\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0522960\n",
      "\tspeed: 0.0744s/iter; left time: 942.7700s\n",
      "\titers: 200, epoch: 44 | loss: 0.0505055\n",
      "\tspeed: 0.0418s/iter; left time: 525.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0516367 Vali Loss: 0.0529722 Test Loss: 0.0595264\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0533356\n",
      "\tspeed: 0.0746s/iter; left time: 929.0001s\n",
      "\titers: 200, epoch: 45 | loss: 0.0502352\n",
      "\tspeed: 0.0419s/iter; left time: 516.7945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0515927 Vali Loss: 0.0530458 Test Loss: 0.0596104\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0517692\n",
      "\tspeed: 0.0746s/iter; left time: 911.5233s\n",
      "\titers: 200, epoch: 46 | loss: 0.0498136\n",
      "\tspeed: 0.0418s/iter; left time: 507.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0516503 Vali Loss: 0.0529150 Test Loss: 0.0594626\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0508997\n",
      "\tspeed: 0.0740s/iter; left time: 887.9165s\n",
      "\titers: 200, epoch: 47 | loss: 0.0512915\n",
      "\tspeed: 0.0418s/iter; left time: 497.5828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516404 Vali Loss: 0.0531144 Test Loss: 0.0597561\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0517852\n",
      "\tspeed: 0.0739s/iter; left time: 870.2552s\n",
      "\titers: 200, epoch: 48 | loss: 0.0506876\n",
      "\tspeed: 0.0419s/iter; left time: 488.5519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516248 Vali Loss: 0.0530044 Test Loss: 0.0595320\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0547697\n",
      "\tspeed: 0.0741s/iter; left time: 855.5929s\n",
      "\titers: 200, epoch: 49 | loss: 0.0555677\n",
      "\tspeed: 0.0420s/iter; left time: 480.3530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0516264 Vali Loss: 0.0528984 Test Loss: 0.0594791\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0482547\n",
      "\tspeed: 0.0742s/iter; left time: 840.1247s\n",
      "\titers: 200, epoch: 50 | loss: 0.0517692\n",
      "\tspeed: 0.0418s/iter; left time: 469.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0516105 Vali Loss: 0.0528318 Test Loss: 0.0594671\n",
      "Validation loss decreased (0.052870 --> 0.052832).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0545435\n",
      "\tspeed: 0.0746s/iter; left time: 828.3088s\n",
      "\titers: 200, epoch: 51 | loss: 0.0500720\n",
      "\tspeed: 0.0418s/iter; left time: 459.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0516374 Vali Loss: 0.0529633 Test Loss: 0.0595131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0499847\n",
      "\tspeed: 0.0750s/iter; left time: 816.1339s\n",
      "\titers: 200, epoch: 52 | loss: 0.0503403\n",
      "\tspeed: 0.0419s/iter; left time: 451.2977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0516169 Vali Loss: 0.0529436 Test Loss: 0.0595761\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0509274\n",
      "\tspeed: 0.0744s/iter; left time: 792.6976s\n",
      "\titers: 200, epoch: 53 | loss: 0.0516314\n",
      "\tspeed: 0.0419s/iter; left time: 441.6514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0516119 Vali Loss: 0.0528572 Test Loss: 0.0594418\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0558771\n",
      "\tspeed: 0.0739s/iter; left time: 770.8764s\n",
      "\titers: 200, epoch: 54 | loss: 0.0494262\n",
      "\tspeed: 0.0419s/iter; left time: 432.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0516379 Vali Loss: 0.0529400 Test Loss: 0.0595203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0516943\n",
      "\tspeed: 0.0738s/iter; left time: 753.2285s\n",
      "\titers: 200, epoch: 55 | loss: 0.0511932\n",
      "\tspeed: 0.0418s/iter; left time: 422.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0515673 Vali Loss: 0.0529744 Test Loss: 0.0596210\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0525783\n",
      "\tspeed: 0.0742s/iter; left time: 740.6482s\n",
      "\titers: 200, epoch: 56 | loss: 0.0492389\n",
      "\tspeed: 0.0421s/iter; left time: 415.5411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0516370 Vali Loss: 0.0529574 Test Loss: 0.0595281\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0545935\n",
      "\tspeed: 0.0746s/iter; left time: 727.7998s\n",
      "\titers: 200, epoch: 57 | loss: 0.0523759\n",
      "\tspeed: 0.0420s/iter; left time: 405.2712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0516061 Vali Loss: 0.0529795 Test Loss: 0.0595364\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0511875\n",
      "\tspeed: 0.0751s/iter; left time: 715.6339s\n",
      "\titers: 200, epoch: 58 | loss: 0.0533470\n",
      "\tspeed: 0.0419s/iter; left time: 394.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0515821 Vali Loss: 0.0529342 Test Loss: 0.0595035\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0510884\n",
      "\tspeed: 0.0738s/iter; left time: 687.2696s\n",
      "\titers: 200, epoch: 59 | loss: 0.0499370\n",
      "\tspeed: 0.0419s/iter; left time: 385.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0515440 Vali Loss: 0.0529809 Test Loss: 0.0596370\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0486272\n",
      "\tspeed: 0.0737s/iter; left time: 669.5302s\n",
      "\titers: 200, epoch: 60 | loss: 0.0515719\n",
      "\tspeed: 0.0418s/iter; left time: 375.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0516205 Vali Loss: 0.0529591 Test Loss: 0.0596179\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009799639694392681, rmse:0.09899313002824783, mae:0.05946708470582962, rse:0.29132479429244995\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1476018\n",
      "\tspeed: 0.0434s/iter; left time: 967.3401s\n",
      "\titers: 200, epoch: 1 | loss: 0.1437213\n",
      "\tspeed: 0.0418s/iter; left time: 928.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.1531461 Vali Loss: 0.1377213 Test Loss: 0.1661581\n",
      "Validation loss decreased (inf --> 0.137721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746912\n",
      "\tspeed: 0.0756s/iter; left time: 1669.1042s\n",
      "\titers: 200, epoch: 2 | loss: 0.0647650\n",
      "\tspeed: 0.0418s/iter; left time: 919.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0809738 Vali Loss: 0.0644596 Test Loss: 0.0714945\n",
      "Validation loss decreased (0.137721 --> 0.064460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0640776\n",
      "\tspeed: 0.0745s/iter; left time: 1627.5040s\n",
      "\titers: 200, epoch: 3 | loss: 0.0653341\n",
      "\tspeed: 0.0419s/iter; left time: 910.8863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0643923 Vali Loss: 0.0610661 Test Loss: 0.0680844\n",
      "Validation loss decreased (0.064460 --> 0.061066).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0614698\n",
      "\tspeed: 0.0750s/iter; left time: 1622.1674s\n",
      "\titers: 200, epoch: 4 | loss: 0.0615958\n",
      "\tspeed: 0.0420s/iter; left time: 904.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0611753 Vali Loss: 0.0585783 Test Loss: 0.0655559\n",
      "Validation loss decreased (0.061066 --> 0.058578).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0570497\n",
      "\tspeed: 0.0744s/iter; left time: 1592.0999s\n",
      "\titers: 200, epoch: 5 | loss: 0.0569669\n",
      "\tspeed: 0.0418s/iter; left time: 891.5242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0590486 Vali Loss: 0.0571490 Test Loss: 0.0639000\n",
      "Validation loss decreased (0.058578 --> 0.057149).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0563935\n",
      "\tspeed: 0.0741s/iter; left time: 1569.2281s\n",
      "\titers: 200, epoch: 6 | loss: 0.0545689\n",
      "\tspeed: 0.0418s/iter; left time: 881.2645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0574238 Vali Loss: 0.0563478 Test Loss: 0.0633337\n",
      "Validation loss decreased (0.057149 --> 0.056348).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0543616\n",
      "\tspeed: 0.0742s/iter; left time: 1554.6276s\n",
      "\titers: 200, epoch: 7 | loss: 0.0533362\n",
      "\tspeed: 0.0419s/iter; left time: 873.9551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0563506 Vali Loss: 0.0555214 Test Loss: 0.0626752\n",
      "Validation loss decreased (0.056348 --> 0.055521).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0559180\n",
      "\tspeed: 0.0741s/iter; left time: 1536.6109s\n",
      "\titers: 200, epoch: 8 | loss: 0.0533546\n",
      "\tspeed: 0.0418s/iter; left time: 863.1065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0556354 Vali Loss: 0.0550512 Test Loss: 0.0623097\n",
      "Validation loss decreased (0.055521 --> 0.055051).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521461\n",
      "\tspeed: 0.0744s/iter; left time: 1525.2461s\n",
      "\titers: 200, epoch: 9 | loss: 0.0539520\n",
      "\tspeed: 0.0419s/iter; left time: 854.1595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0550924 Vali Loss: 0.0547789 Test Loss: 0.0615542\n",
      "Validation loss decreased (0.055051 --> 0.054779).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0549681\n",
      "\tspeed: 0.0745s/iter; left time: 1510.4364s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536708\n",
      "\tspeed: 0.0418s/iter; left time: 844.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0546157 Vali Loss: 0.0545722 Test Loss: 0.0614398\n",
      "Validation loss decreased (0.054779 --> 0.054572).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0526006\n",
      "\tspeed: 0.0746s/iter; left time: 1497.1449s\n",
      "\titers: 200, epoch: 11 | loss: 0.0524122\n",
      "\tspeed: 0.0419s/iter; left time: 836.6517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0542620 Vali Loss: 0.0542749 Test Loss: 0.0611336\n",
      "Validation loss decreased (0.054572 --> 0.054275).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0543727\n",
      "\tspeed: 0.0744s/iter; left time: 1476.5967s\n",
      "\titers: 200, epoch: 12 | loss: 0.0528240\n",
      "\tspeed: 0.0418s/iter; left time: 825.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0538929 Vali Loss: 0.0541811 Test Loss: 0.0609238\n",
      "Validation loss decreased (0.054275 --> 0.054181).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580260\n",
      "\tspeed: 0.0746s/iter; left time: 1462.7228s\n",
      "\titers: 200, epoch: 13 | loss: 0.0543900\n",
      "\tspeed: 0.0418s/iter; left time: 816.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0536706 Vali Loss: 0.0540516 Test Loss: 0.0607060\n",
      "Validation loss decreased (0.054181 --> 0.054052).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0565432\n",
      "\tspeed: 0.0740s/iter; left time: 1433.8208s\n",
      "\titers: 200, epoch: 14 | loss: 0.0505316\n",
      "\tspeed: 0.0418s/iter; left time: 805.6353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0535040 Vali Loss: 0.0538637 Test Loss: 0.0606829\n",
      "Validation loss decreased (0.054052 --> 0.053864).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0581060\n",
      "\tspeed: 0.0741s/iter; left time: 1420.0279s\n",
      "\titers: 200, epoch: 15 | loss: 0.0532165\n",
      "\tspeed: 0.0418s/iter; left time: 796.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0531955 Vali Loss: 0.0537251 Test Loss: 0.0603922\n",
      "Validation loss decreased (0.053864 --> 0.053725).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0522039\n",
      "\tspeed: 0.0742s/iter; left time: 1404.7267s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557981\n",
      "\tspeed: 0.0418s/iter; left time: 788.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0530805 Vali Loss: 0.0535555 Test Loss: 0.0602422\n",
      "Validation loss decreased (0.053725 --> 0.053556).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0513855\n",
      "\tspeed: 0.0741s/iter; left time: 1387.5643s\n",
      "\titers: 200, epoch: 17 | loss: 0.0546825\n",
      "\tspeed: 0.0418s/iter; left time: 778.9856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0529455 Vali Loss: 0.0536849 Test Loss: 0.0604115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0556174\n",
      "\tspeed: 0.0737s/iter; left time: 1362.4725s\n",
      "\titers: 200, epoch: 18 | loss: 0.0520927\n",
      "\tspeed: 0.0418s/iter; left time: 769.4816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0527236 Vali Loss: 0.0535271 Test Loss: 0.0601175\n",
      "Validation loss decreased (0.053556 --> 0.053527).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0525549\n",
      "\tspeed: 0.0744s/iter; left time: 1359.2558s\n",
      "\titers: 200, epoch: 19 | loss: 0.0489624\n",
      "\tspeed: 0.0418s/iter; left time: 759.3568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0527059 Vali Loss: 0.0535655 Test Loss: 0.0602358\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0496512\n",
      "\tspeed: 0.0737s/iter; left time: 1330.0334s\n",
      "\titers: 200, epoch: 20 | loss: 0.0536459\n",
      "\tspeed: 0.0419s/iter; left time: 751.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0525997 Vali Loss: 0.0534788 Test Loss: 0.0601111\n",
      "Validation loss decreased (0.053527 --> 0.053479).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0562994\n",
      "\tspeed: 0.0744s/iter; left time: 1326.1666s\n",
      "\titers: 200, epoch: 21 | loss: 0.0519681\n",
      "\tspeed: 0.0418s/iter; left time: 741.5935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0524832 Vali Loss: 0.0533591 Test Loss: 0.0600647\n",
      "Validation loss decreased (0.053479 --> 0.053359).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0498014\n",
      "\tspeed: 0.0740s/iter; left time: 1302.2149s\n",
      "\titers: 200, epoch: 22 | loss: 0.0511340\n",
      "\tspeed: 0.0418s/iter; left time: 731.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0524015 Vali Loss: 0.0533194 Test Loss: 0.0599013\n",
      "Validation loss decreased (0.053359 --> 0.053319).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0511480\n",
      "\tspeed: 0.0752s/iter; left time: 1307.2778s\n",
      "\titers: 200, epoch: 23 | loss: 0.0547260\n",
      "\tspeed: 0.0426s/iter; left time: 736.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0523454 Vali Loss: 0.0532531 Test Loss: 0.0598640\n",
      "Validation loss decreased (0.053319 --> 0.053253).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0494056\n",
      "\tspeed: 0.0741s/iter; left time: 1270.1937s\n",
      "\titers: 200, epoch: 24 | loss: 0.0505622\n",
      "\tspeed: 0.0418s/iter; left time: 712.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0522534 Vali Loss: 0.0532340 Test Loss: 0.0598475\n",
      "Validation loss decreased (0.053253 --> 0.053234).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0507696\n",
      "\tspeed: 0.0740s/iter; left time: 1252.1243s\n",
      "\titers: 200, epoch: 25 | loss: 0.0518188\n",
      "\tspeed: 0.0417s/iter; left time: 702.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0521564 Vali Loss: 0.0531983 Test Loss: 0.0597164\n",
      "Validation loss decreased (0.053234 --> 0.053198).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0543133\n",
      "\tspeed: 0.0739s/iter; left time: 1234.9556s\n",
      "\titers: 200, epoch: 26 | loss: 0.0491244\n",
      "\tspeed: 0.0418s/iter; left time: 694.0445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0521741 Vali Loss: 0.0532081 Test Loss: 0.0597476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0529002\n",
      "\tspeed: 0.0736s/iter; left time: 1212.4261s\n",
      "\titers: 200, epoch: 27 | loss: 0.0531516\n",
      "\tspeed: 0.0418s/iter; left time: 684.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0520485 Vali Loss: 0.0532592 Test Loss: 0.0598365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0536259\n",
      "\tspeed: 0.0738s/iter; left time: 1199.2121s\n",
      "\titers: 200, epoch: 28 | loss: 0.0525920\n",
      "\tspeed: 0.0418s/iter; left time: 675.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0520732 Vali Loss: 0.0530898 Test Loss: 0.0597077\n",
      "Validation loss decreased (0.053198 --> 0.053090).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0543261\n",
      "\tspeed: 0.0741s/iter; left time: 1187.1689s\n",
      "\titers: 200, epoch: 29 | loss: 0.0550454\n",
      "\tspeed: 0.0418s/iter; left time: 665.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0519956 Vali Loss: 0.0531452 Test Loss: 0.0597517\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523805\n",
      "\tspeed: 0.0735s/iter; left time: 1162.1472s\n",
      "\titers: 200, epoch: 30 | loss: 0.0516562\n",
      "\tspeed: 0.0418s/iter; left time: 656.2511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0519390 Vali Loss: 0.0532631 Test Loss: 0.0597923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0534631\n",
      "\tspeed: 0.0739s/iter; left time: 1152.0264s\n",
      "\titers: 200, epoch: 31 | loss: 0.0478987\n",
      "\tspeed: 0.0418s/iter; left time: 646.6618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0519516 Vali Loss: 0.0530886 Test Loss: 0.0596565\n",
      "Validation loss decreased (0.053090 --> 0.053089).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0525212\n",
      "\tspeed: 0.0745s/iter; left time: 1143.6131s\n",
      "\titers: 200, epoch: 32 | loss: 0.0448811\n",
      "\tspeed: 0.0419s/iter; left time: 638.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0519044 Vali Loss: 0.0531356 Test Loss: 0.0596514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0543640\n",
      "\tspeed: 0.0737s/iter; left time: 1115.7017s\n",
      "\titers: 200, epoch: 33 | loss: 0.0521232\n",
      "\tspeed: 0.0418s/iter; left time: 629.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0518768 Vali Loss: 0.0530850 Test Loss: 0.0596694\n",
      "Validation loss decreased (0.053089 --> 0.053085).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0533725\n",
      "\tspeed: 0.0742s/iter; left time: 1106.4521s\n",
      "\titers: 200, epoch: 34 | loss: 0.0530695\n",
      "\tspeed: 0.0418s/iter; left time: 619.5560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0518850 Vali Loss: 0.0531215 Test Loss: 0.0596977\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0490373\n",
      "\tspeed: 0.0737s/iter; left time: 1082.1185s\n",
      "\titers: 200, epoch: 35 | loss: 0.0513428\n",
      "\tspeed: 0.0418s/iter; left time: 609.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0518383 Vali Loss: 0.0530350 Test Loss: 0.0596393\n",
      "Validation loss decreased (0.053085 --> 0.053035).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0535707\n",
      "\tspeed: 0.0742s/iter; left time: 1072.6000s\n",
      "\titers: 200, epoch: 36 | loss: 0.0524036\n",
      "\tspeed: 0.0418s/iter; left time: 600.4129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0517890 Vali Loss: 0.0530882 Test Loss: 0.0596071\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0524593\n",
      "\tspeed: 0.0737s/iter; left time: 1049.1655s\n",
      "\titers: 200, epoch: 37 | loss: 0.0530749\n",
      "\tspeed: 0.0418s/iter; left time: 590.8150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0517949 Vali Loss: 0.0530463 Test Loss: 0.0596028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0532010\n",
      "\tspeed: 0.0738s/iter; left time: 1033.7296s\n",
      "\titers: 200, epoch: 38 | loss: 0.0495975\n",
      "\tspeed: 0.0418s/iter; left time: 582.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0517682 Vali Loss: 0.0529934 Test Loss: 0.0595207\n",
      "Validation loss decreased (0.053035 --> 0.052993).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0499899\n",
      "\tspeed: 0.0740s/iter; left time: 1020.9604s\n",
      "\titers: 200, epoch: 39 | loss: 0.0538907\n",
      "\tspeed: 0.0418s/iter; left time: 572.7981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0517210 Vali Loss: 0.0530056 Test Loss: 0.0595864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0525996\n",
      "\tspeed: 0.0738s/iter; left time: 1000.8883s\n",
      "\titers: 200, epoch: 40 | loss: 0.0529549\n",
      "\tspeed: 0.0419s/iter; left time: 564.1836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0517723 Vali Loss: 0.0530561 Test Loss: 0.0595950\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0519737\n",
      "\tspeed: 0.0736s/iter; left time: 981.2992s\n",
      "\titers: 200, epoch: 41 | loss: 0.0519630\n",
      "\tspeed: 0.0417s/iter; left time: 552.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0517834 Vali Loss: 0.0530609 Test Loss: 0.0596149\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0509723\n",
      "\tspeed: 0.0745s/iter; left time: 977.7813s\n",
      "\titers: 200, epoch: 42 | loss: 0.0524476\n",
      "\tspeed: 0.0544s/iter; left time: 708.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:12.03s\n",
      "Steps: 224 | Train Loss: 0.0518105 Vali Loss: 0.0530046 Test Loss: 0.0595797\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0503187\n",
      "\tspeed: 0.1446s/iter; left time: 1863.8645s\n",
      "\titers: 200, epoch: 43 | loss: 0.0504047\n",
      "\tspeed: 0.0854s/iter; left time: 1092.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:19.29s\n",
      "Steps: 224 | Train Loss: 0.0516899 Vali Loss: 0.0529767 Test Loss: 0.0595138\n",
      "Validation loss decreased (0.052993 --> 0.052977).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0527615\n",
      "\tspeed: 0.1431s/iter; left time: 1812.5550s\n",
      "\titers: 200, epoch: 44 | loss: 0.0524022\n",
      "\tspeed: 0.0886s/iter; left time: 1113.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:19.16s\n",
      "Steps: 224 | Train Loss: 0.0517289 Vali Loss: 0.0530944 Test Loss: 0.0597356\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0513969\n",
      "\tspeed: 0.1463s/iter; left time: 1820.3994s\n",
      "\titers: 200, epoch: 45 | loss: 0.0538382\n",
      "\tspeed: 0.0826s/iter; left time: 1020.2987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:19.45s\n",
      "Steps: 224 | Train Loss: 0.0517787 Vali Loss: 0.0529584 Test Loss: 0.0594981\n",
      "Validation loss decreased (0.052977 --> 0.052958).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0507074\n",
      "\tspeed: 0.1467s/iter; left time: 1792.9198s\n",
      "\titers: 200, epoch: 46 | loss: 0.0531654\n",
      "\tspeed: 0.0863s/iter; left time: 1046.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:19.48s\n",
      "Steps: 224 | Train Loss: 0.0517703 Vali Loss: 0.0530363 Test Loss: 0.0595716\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0526433\n",
      "\tspeed: 0.1428s/iter; left time: 1712.7029s\n",
      "\titers: 200, epoch: 47 | loss: 0.0482868\n",
      "\tspeed: 0.0886s/iter; left time: 1054.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:19.20s\n",
      "Steps: 224 | Train Loss: 0.0516642 Vali Loss: 0.0530231 Test Loss: 0.0595973\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0503860\n",
      "\tspeed: 0.1457s/iter; left time: 1715.0696s\n",
      "\titers: 200, epoch: 48 | loss: 0.0495362\n",
      "\tspeed: 0.0832s/iter; left time: 970.8828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:19.51s\n",
      "Steps: 224 | Train Loss: 0.0516952 Vali Loss: 0.0530382 Test Loss: 0.0595692\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0528319\n",
      "\tspeed: 0.1448s/iter; left time: 1672.3772s\n",
      "\titers: 200, epoch: 49 | loss: 0.0522983\n",
      "\tspeed: 0.0861s/iter; left time: 986.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:19.33s\n",
      "Steps: 224 | Train Loss: 0.0517189 Vali Loss: 0.0530699 Test Loss: 0.0596293\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0519786\n",
      "\tspeed: 0.1439s/iter; left time: 1629.4182s\n",
      "\titers: 200, epoch: 50 | loss: 0.0511020\n",
      "\tspeed: 0.0886s/iter; left time: 994.1350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:19.22s\n",
      "Steps: 224 | Train Loss: 0.0516822 Vali Loss: 0.0529885 Test Loss: 0.0594989\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0557232\n",
      "\tspeed: 0.1467s/iter; left time: 1628.4150s\n",
      "\titers: 200, epoch: 51 | loss: 0.0520977\n",
      "\tspeed: 0.0824s/iter; left time: 906.3230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:19.39s\n",
      "Steps: 224 | Train Loss: 0.0516774 Vali Loss: 0.0530646 Test Loss: 0.0595811\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0513555\n",
      "\tspeed: 0.1452s/iter; left time: 1578.9646s\n",
      "\titers: 200, epoch: 52 | loss: 0.0545720\n",
      "\tspeed: 0.0716s/iter; left time: 771.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:17.84s\n",
      "Steps: 224 | Train Loss: 0.0517186 Vali Loss: 0.0529541 Test Loss: 0.0595378\n",
      "Validation loss decreased (0.052958 --> 0.052954).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548120\n",
      "\tspeed: 0.1379s/iter; left time: 1468.8587s\n",
      "\titers: 200, epoch: 53 | loss: 0.0506285\n",
      "\tspeed: 0.0885s/iter; left time: 934.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:18.77s\n",
      "Steps: 224 | Train Loss: 0.0516620 Vali Loss: 0.0529870 Test Loss: 0.0596300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0522626\n",
      "\tspeed: 0.1423s/iter; left time: 1484.1139s\n",
      "\titers: 200, epoch: 54 | loss: 0.0501850\n",
      "\tspeed: 0.0875s/iter; left time: 903.4580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:19.05s\n",
      "Steps: 224 | Train Loss: 0.0517069 Vali Loss: 0.0530255 Test Loss: 0.0595458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0548283\n",
      "\tspeed: 0.1429s/iter; left time: 1458.1575s\n",
      "\titers: 200, epoch: 55 | loss: 0.0515203\n",
      "\tspeed: 0.0821s/iter; left time: 829.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:19.58s\n",
      "Steps: 224 | Train Loss: 0.0517627 Vali Loss: 0.0529545 Test Loss: 0.0594461\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0473725\n",
      "\tspeed: 0.1991s/iter; left time: 1987.2282s\n",
      "\titers: 200, epoch: 56 | loss: 0.0474448\n",
      "\tspeed: 0.1268s/iter; left time: 1252.9267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:27.83s\n",
      "Steps: 224 | Train Loss: 0.0516708 Vali Loss: 0.0529323 Test Loss: 0.0594687\n",
      "Validation loss decreased (0.052954 --> 0.052932).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0475008\n",
      "\tspeed: 0.2073s/iter; left time: 2022.5499s\n",
      "\titers: 200, epoch: 57 | loss: 0.0523390\n",
      "\tspeed: 0.1267s/iter; left time: 1223.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:27.66s\n",
      "Steps: 224 | Train Loss: 0.0516606 Vali Loss: 0.0529457 Test Loss: 0.0595112\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0514652\n",
      "\tspeed: 0.0937s/iter; left time: 893.5721s\n",
      "\titers: 200, epoch: 58 | loss: 0.0510385\n",
      "\tspeed: 0.0419s/iter; left time: 394.7933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0516258 Vali Loss: 0.0530078 Test Loss: 0.0594691\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0523517\n",
      "\tspeed: 0.0745s/iter; left time: 693.8714s\n",
      "\titers: 200, epoch: 59 | loss: 0.0503257\n",
      "\tspeed: 0.0419s/iter; left time: 385.6757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0516860 Vali Loss: 0.0529880 Test Loss: 0.0595234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0493156\n",
      "\tspeed: 0.0738s/iter; left time: 670.6898s\n",
      "\titers: 200, epoch: 60 | loss: 0.0500680\n",
      "\tspeed: 0.0418s/iter; left time: 375.9259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0516414 Vali Loss: 0.0530047 Test Loss: 0.0595303\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0520709\n",
      "\tspeed: 0.0737s/iter; left time: 652.8748s\n",
      "\titers: 200, epoch: 61 | loss: 0.0485221\n",
      "\tspeed: 0.0430s/iter; left time: 376.4587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0516731 Vali Loss: 0.0530099 Test Loss: 0.0595771\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0494203\n",
      "\tspeed: 0.0783s/iter; left time: 676.1625s\n",
      "\titers: 200, epoch: 62 | loss: 0.0503813\n",
      "\tspeed: 0.0434s/iter; left time: 370.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0516423 Vali Loss: 0.0530357 Test Loss: 0.0595844\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0526378\n",
      "\tspeed: 0.0798s/iter; left time: 671.5980s\n",
      "\titers: 200, epoch: 63 | loss: 0.0479659\n",
      "\tspeed: 0.0433s/iter; left time: 359.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0516823 Vali Loss: 0.0529699 Test Loss: 0.0594978\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0508766\n",
      "\tspeed: 0.0800s/iter; left time: 655.4513s\n",
      "\titers: 200, epoch: 64 | loss: 0.0505792\n",
      "\tspeed: 0.0438s/iter; left time: 353.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.0516600 Vali Loss: 0.0530094 Test Loss: 0.0595359\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0496024\n",
      "\tspeed: 0.0792s/iter; left time: 630.9550s\n",
      "\titers: 200, epoch: 65 | loss: 0.0513106\n",
      "\tspeed: 0.0437s/iter; left time: 343.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0516431 Vali Loss: 0.0529733 Test Loss: 0.0594781\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0553750\n",
      "\tspeed: 0.0802s/iter; left time: 620.7282s\n",
      "\titers: 200, epoch: 66 | loss: 0.0515449\n",
      "\tspeed: 0.0441s/iter; left time: 336.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.0517339 Vali Loss: 0.0529650 Test Loss: 0.0594281\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00978555716574192, rmse:0.09892197698354721, mae:0.05946873873472214, rse:0.291115403175354\n",
      "Intermediate time for ES and pred_len 24: 00h:27m:52.50s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1586270\n",
      "\tspeed: 0.0609s/iter; left time: 1358.5171s\n",
      "\titers: 200, epoch: 1 | loss: 0.1450784\n",
      "\tspeed: 0.0443s/iter; left time: 983.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 224 | Train Loss: 0.1628915 Vali Loss: 0.1497857 Test Loss: 0.1802254\n",
      "Validation loss decreased (inf --> 0.149786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0918277\n",
      "\tspeed: 0.0842s/iter; left time: 1859.3174s\n",
      "\titers: 200, epoch: 2 | loss: 0.0816794\n",
      "\tspeed: 0.0447s/iter; left time: 983.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.23s\n",
      "Steps: 224 | Train Loss: 0.0973313 Vali Loss: 0.0838464 Test Loss: 0.0949164\n",
      "Validation loss decreased (0.149786 --> 0.083846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829089\n",
      "\tspeed: 0.0812s/iter; left time: 1775.2768s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840276\n",
      "\tspeed: 0.0423s/iter; left time: 919.7388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0835588 Vali Loss: 0.0806199 Test Loss: 0.0917724\n",
      "Validation loss decreased (0.083846 --> 0.080620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0808573\n",
      "\tspeed: 0.0795s/iter; left time: 1718.6657s\n",
      "\titers: 200, epoch: 4 | loss: 0.0771366\n",
      "\tspeed: 0.0432s/iter; left time: 929.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0804146 Vali Loss: 0.0785956 Test Loss: 0.0899684\n",
      "Validation loss decreased (0.080620 --> 0.078596).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0811141\n",
      "\tspeed: 0.0808s/iter; left time: 1729.7450s\n",
      "\titers: 200, epoch: 5 | loss: 0.0803113\n",
      "\tspeed: 0.0432s/iter; left time: 919.8680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0785678 Vali Loss: 0.0775166 Test Loss: 0.0890404\n",
      "Validation loss decreased (0.078596 --> 0.077517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0755782\n",
      "\tspeed: 0.0802s/iter; left time: 1697.9951s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813857\n",
      "\tspeed: 0.0430s/iter; left time: 906.3293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 224 | Train Loss: 0.0773221 Vali Loss: 0.0770633 Test Loss: 0.0883174\n",
      "Validation loss decreased (0.077517 --> 0.077063).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0746969\n",
      "\tspeed: 0.0807s/iter; left time: 1690.2621s\n",
      "\titers: 200, epoch: 7 | loss: 0.0766782\n",
      "\tspeed: 0.0432s/iter; left time: 901.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.0764304 Vali Loss: 0.0768258 Test Loss: 0.0879041\n",
      "Validation loss decreased (0.077063 --> 0.076826).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0754822\n",
      "\tspeed: 0.0839s/iter; left time: 1739.1228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0759594\n",
      "\tspeed: 0.0433s/iter; left time: 892.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0758011 Vali Loss: 0.0766668 Test Loss: 0.0877922\n",
      "Validation loss decreased (0.076826 --> 0.076667).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726592\n",
      "\tspeed: 0.0867s/iter; left time: 1777.7424s\n",
      "\titers: 200, epoch: 9 | loss: 0.0735152\n",
      "\tspeed: 0.0432s/iter; left time: 882.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0752415 Vali Loss: 0.0766290 Test Loss: 0.0876217\n",
      "Validation loss decreased (0.076667 --> 0.076629).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0743559\n",
      "\tspeed: 0.0794s/iter; left time: 1610.5306s\n",
      "\titers: 200, epoch: 10 | loss: 0.0777107\n",
      "\tspeed: 0.0439s/iter; left time: 885.8302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.0747904 Vali Loss: 0.0761793 Test Loss: 0.0872853\n",
      "Validation loss decreased (0.076629 --> 0.076179).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0745435\n",
      "\tspeed: 0.0863s/iter; left time: 1730.5839s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774285\n",
      "\tspeed: 0.0434s/iter; left time: 866.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0744887 Vali Loss: 0.0758530 Test Loss: 0.0868568\n",
      "Validation loss decreased (0.076179 --> 0.075853).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0747768\n",
      "\tspeed: 0.0824s/iter; left time: 1635.5455s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704287\n",
      "\tspeed: 0.0432s/iter; left time: 852.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0741229 Vali Loss: 0.0759289 Test Loss: 0.0864838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0732824\n",
      "\tspeed: 0.0816s/iter; left time: 1601.0958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723793\n",
      "\tspeed: 0.0432s/iter; left time: 843.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0738578 Vali Loss: 0.0760315 Test Loss: 0.0870588\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0701876\n",
      "\tspeed: 0.0790s/iter; left time: 1532.5645s\n",
      "\titers: 200, epoch: 14 | loss: 0.0745867\n",
      "\tspeed: 0.0440s/iter; left time: 849.2533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0736512 Vali Loss: 0.0758688 Test Loss: 0.0869034\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0756198\n",
      "\tspeed: 0.0778s/iter; left time: 1490.6806s\n",
      "\titers: 200, epoch: 15 | loss: 0.0735717\n",
      "\tspeed: 0.0440s/iter; left time: 838.4463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0732935 Vali Loss: 0.0758132 Test Loss: 0.0868040\n",
      "Validation loss decreased (0.075853 --> 0.075813).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0714306\n",
      "\tspeed: 0.0801s/iter; left time: 1517.3447s\n",
      "\titers: 200, epoch: 16 | loss: 0.0736407\n",
      "\tspeed: 0.0432s/iter; left time: 812.9986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0731359 Vali Loss: 0.0755762 Test Loss: 0.0866504\n",
      "Validation loss decreased (0.075813 --> 0.075576).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0714845\n",
      "\tspeed: 0.1059s/iter; left time: 1982.6248s\n",
      "\titers: 200, epoch: 17 | loss: 0.0719373\n",
      "\tspeed: 0.0435s/iter; left time: 809.4978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0729409 Vali Loss: 0.0758209 Test Loss: 0.0867814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735483\n",
      "\tspeed: 0.0798s/iter; left time: 1475.8235s\n",
      "\titers: 200, epoch: 18 | loss: 0.0718875\n",
      "\tspeed: 0.0433s/iter; left time: 797.1745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0727708 Vali Loss: 0.0758975 Test Loss: 0.0866312\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726891\n",
      "\tspeed: 0.0794s/iter; left time: 1450.2026s\n",
      "\titers: 200, epoch: 19 | loss: 0.0692141\n",
      "\tspeed: 0.0434s/iter; left time: 789.3982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0727016 Vali Loss: 0.0755487 Test Loss: 0.0864635\n",
      "Validation loss decreased (0.075576 --> 0.075549).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0737528\n",
      "\tspeed: 0.0862s/iter; left time: 1556.2331s\n",
      "\titers: 200, epoch: 20 | loss: 0.0728427\n",
      "\tspeed: 0.0439s/iter; left time: 788.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0724692 Vali Loss: 0.0755976 Test Loss: 0.0864065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0726215\n",
      "\tspeed: 0.0788s/iter; left time: 1404.9209s\n",
      "\titers: 200, epoch: 21 | loss: 0.0720892\n",
      "\tspeed: 0.0431s/iter; left time: 763.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0724086 Vali Loss: 0.0755949 Test Loss: 0.0864117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0723771\n",
      "\tspeed: 0.0784s/iter; left time: 1380.1135s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696119\n",
      "\tspeed: 0.0434s/iter; left time: 759.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0722944 Vali Loss: 0.0755619 Test Loss: 0.0864713\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0689607\n",
      "\tspeed: 0.0802s/iter; left time: 1392.7066s\n",
      "\titers: 200, epoch: 23 | loss: 0.0684920\n",
      "\tspeed: 0.0435s/iter; left time: 752.2158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0722183 Vali Loss: 0.0756311 Test Loss: 0.0865839\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0713682\n",
      "\tspeed: 0.0802s/iter; left time: 1375.7347s\n",
      "\titers: 200, epoch: 24 | loss: 0.0739676\n",
      "\tspeed: 0.0434s/iter; left time: 739.8116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0721205 Vali Loss: 0.0753485 Test Loss: 0.0863606\n",
      "Validation loss decreased (0.075549 --> 0.075348).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0724736\n",
      "\tspeed: 0.0805s/iter; left time: 1363.2252s\n",
      "\titers: 200, epoch: 25 | loss: 0.0702187\n",
      "\tspeed: 0.0436s/iter; left time: 733.6587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0720138 Vali Loss: 0.0755377 Test Loss: 0.0865106\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0746010\n",
      "\tspeed: 0.0790s/iter; left time: 1318.5786s\n",
      "\titers: 200, epoch: 26 | loss: 0.0682516\n",
      "\tspeed: 0.0439s/iter; left time: 729.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0719424 Vali Loss: 0.0755066 Test Loss: 0.0864553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0756939\n",
      "\tspeed: 0.0788s/iter; left time: 1297.7518s\n",
      "\titers: 200, epoch: 27 | loss: 0.0694480\n",
      "\tspeed: 0.0431s/iter; left time: 706.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0719031 Vali Loss: 0.0754957 Test Loss: 0.0865196\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0707726\n",
      "\tspeed: 0.0786s/iter; left time: 1278.0298s\n",
      "\titers: 200, epoch: 28 | loss: 0.0729235\n",
      "\tspeed: 0.0432s/iter; left time: 697.0378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0718348 Vali Loss: 0.0756311 Test Loss: 0.0866816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0716222\n",
      "\tspeed: 0.0825s/iter; left time: 1321.7298s\n",
      "\titers: 200, epoch: 29 | loss: 0.0678281\n",
      "\tspeed: 0.0435s/iter; left time: 692.9117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0718101 Vali Loss: 0.0753566 Test Loss: 0.0863243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0712663\n",
      "\tspeed: 0.0787s/iter; left time: 1243.0862s\n",
      "\titers: 200, epoch: 30 | loss: 0.0745299\n",
      "\tspeed: 0.0442s/iter; left time: 693.6122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0718021 Vali Loss: 0.0753349 Test Loss: 0.0863798\n",
      "Validation loss decreased (0.075348 --> 0.075335).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0724587\n",
      "\tspeed: 0.0914s/iter; left time: 1423.6349s\n",
      "\titers: 200, epoch: 31 | loss: 0.0724711\n",
      "\tspeed: 0.0432s/iter; left time: 668.3824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0716330 Vali Loss: 0.0754693 Test Loss: 0.0865439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0730980\n",
      "\tspeed: 0.0812s/iter; left time: 1247.6069s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705433\n",
      "\tspeed: 0.0439s/iter; left time: 669.1235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0716719 Vali Loss: 0.0754019 Test Loss: 0.0864273\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0715316\n",
      "\tspeed: 0.0783s/iter; left time: 1184.4293s\n",
      "\titers: 200, epoch: 33 | loss: 0.0711717\n",
      "\tspeed: 0.0436s/iter; left time: 654.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0715782 Vali Loss: 0.0754586 Test Loss: 0.0865546\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697430\n",
      "\tspeed: 0.0785s/iter; left time: 1169.7244s\n",
      "\titers: 200, epoch: 34 | loss: 0.0722043\n",
      "\tspeed: 0.0435s/iter; left time: 644.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0716041 Vali Loss: 0.0755848 Test Loss: 0.0867919\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0753731\n",
      "\tspeed: 0.0797s/iter; left time: 1170.0707s\n",
      "\titers: 200, epoch: 35 | loss: 0.0724049\n",
      "\tspeed: 0.0431s/iter; left time: 629.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0716068 Vali Loss: 0.0754728 Test Loss: 0.0866043\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0714311\n",
      "\tspeed: 0.0792s/iter; left time: 1144.7564s\n",
      "\titers: 200, epoch: 36 | loss: 0.0718317\n",
      "\tspeed: 0.0433s/iter; left time: 621.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.0714898 Vali Loss: 0.0754767 Test Loss: 0.0865963\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0701757\n",
      "\tspeed: 0.0813s/iter; left time: 1156.8416s\n",
      "\titers: 200, epoch: 37 | loss: 0.0718206\n",
      "\tspeed: 0.0439s/iter; left time: 620.6708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0715510 Vali Loss: 0.0754377 Test Loss: 0.0864953\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0731241\n",
      "\tspeed: 0.0784s/iter; left time: 1098.6226s\n",
      "\titers: 200, epoch: 38 | loss: 0.0693968\n",
      "\tspeed: 0.0438s/iter; left time: 608.7576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0715072 Vali Loss: 0.0754432 Test Loss: 0.0865382\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0723001\n",
      "\tspeed: 0.0799s/iter; left time: 1101.7771s\n",
      "\titers: 200, epoch: 39 | loss: 0.0704393\n",
      "\tspeed: 0.0432s/iter; left time: 591.3525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 224 | Train Loss: 0.0714562 Vali Loss: 0.0755303 Test Loss: 0.0867850\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0707888\n",
      "\tspeed: 0.0814s/iter; left time: 1104.0422s\n",
      "\titers: 200, epoch: 40 | loss: 0.0684797\n",
      "\tspeed: 0.0439s/iter; left time: 591.1543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.0714900 Vali Loss: 0.0754403 Test Loss: 0.0864604\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01853589527308941, rmse:0.13614659011363983, mae:0.086379773914814, rse:0.39995771646499634\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1595100\n",
      "\tspeed: 0.0460s/iter; left time: 1026.6767s\n",
      "\titers: 200, epoch: 1 | loss: 0.1464803\n",
      "\tspeed: 0.0435s/iter; left time: 966.7590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.14s\n",
      "Steps: 224 | Train Loss: 0.1623900 Vali Loss: 0.1494924 Test Loss: 0.1800590\n",
      "Validation loss decreased (inf --> 0.149492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0974927\n",
      "\tspeed: 0.0972s/iter; left time: 2146.4310s\n",
      "\titers: 200, epoch: 2 | loss: 0.0831096\n",
      "\tspeed: 0.0442s/iter; left time: 972.0529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.13s\n",
      "Steps: 224 | Train Loss: 0.0989482 Vali Loss: 0.0836564 Test Loss: 0.0951239\n",
      "Validation loss decreased (0.149492 --> 0.083656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0859427\n",
      "\tspeed: 0.0882s/iter; left time: 1926.3782s\n",
      "\titers: 200, epoch: 3 | loss: 0.0827934\n",
      "\tspeed: 0.0432s/iter; left time: 940.1842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 224 | Train Loss: 0.0840580 Vali Loss: 0.0804858 Test Loss: 0.0919310\n",
      "Validation loss decreased (0.083656 --> 0.080486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0809943\n",
      "\tspeed: 0.0853s/iter; left time: 1844.2546s\n",
      "\titers: 200, epoch: 4 | loss: 0.0824453\n",
      "\tspeed: 0.0485s/iter; left time: 1044.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.68s\n",
      "Steps: 224 | Train Loss: 0.0809367 Vali Loss: 0.0787052 Test Loss: 0.0902697\n",
      "Validation loss decreased (0.080486 --> 0.078705).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0784219\n",
      "\tspeed: 0.0865s/iter; left time: 1852.5851s\n",
      "\titers: 200, epoch: 5 | loss: 0.0777955\n",
      "\tspeed: 0.0441s/iter; left time: 938.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.38s\n",
      "Steps: 224 | Train Loss: 0.0786152 Vali Loss: 0.0776663 Test Loss: 0.0886390\n",
      "Validation loss decreased (0.078705 --> 0.077666).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0771296\n",
      "\tspeed: 0.0928s/iter; left time: 1965.7520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751691\n",
      "\tspeed: 0.0476s/iter; left time: 1003.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.36s\n",
      "Steps: 224 | Train Loss: 0.0773966 Vali Loss: 0.0769601 Test Loss: 0.0882143\n",
      "Validation loss decreased (0.077666 --> 0.076960).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770102\n",
      "\tspeed: 0.0869s/iter; left time: 1820.4239s\n",
      "\titers: 200, epoch: 7 | loss: 0.0743075\n",
      "\tspeed: 0.0467s/iter; left time: 974.1946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 224 | Train Loss: 0.0765820 Vali Loss: 0.0765978 Test Loss: 0.0877772\n",
      "Validation loss decreased (0.076960 --> 0.076598).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0752847\n",
      "\tspeed: 0.0853s/iter; left time: 1767.8104s\n",
      "\titers: 200, epoch: 8 | loss: 0.0798416\n",
      "\tspeed: 0.0458s/iter; left time: 944.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0758869 Vali Loss: 0.0762154 Test Loss: 0.0875819\n",
      "Validation loss decreased (0.076598 --> 0.076215).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779041\n",
      "\tspeed: 0.0852s/iter; left time: 1747.8906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0767852\n",
      "\tspeed: 0.0475s/iter; left time: 969.5431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 224 | Train Loss: 0.0753483 Vali Loss: 0.0761540 Test Loss: 0.0874702\n",
      "Validation loss decreased (0.076215 --> 0.076154).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0750211\n",
      "\tspeed: 0.0876s/iter; left time: 1777.6915s\n",
      "\titers: 200, epoch: 10 | loss: 0.0759499\n",
      "\tspeed: 0.0439s/iter; left time: 886.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.25s\n",
      "Steps: 224 | Train Loss: 0.0748687 Vali Loss: 0.0757517 Test Loss: 0.0869395\n",
      "Validation loss decreased (0.076154 --> 0.075752).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0746947\n",
      "\tspeed: 0.0864s/iter; left time: 1733.4514s\n",
      "\titers: 200, epoch: 11 | loss: 0.0727347\n",
      "\tspeed: 0.0441s/iter; left time: 879.8236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.48s\n",
      "Steps: 224 | Train Loss: 0.0744353 Vali Loss: 0.0759637 Test Loss: 0.0869859\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0743605\n",
      "\tspeed: 0.0840s/iter; left time: 1665.7074s\n",
      "\titers: 200, epoch: 12 | loss: 0.0748632\n",
      "\tspeed: 0.0430s/iter; left time: 847.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 224 | Train Loss: 0.0740608 Vali Loss: 0.0756004 Test Loss: 0.0868234\n",
      "Validation loss decreased (0.075752 --> 0.075600).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698201\n",
      "\tspeed: 0.1110s/iter; left time: 2177.4018s\n",
      "\titers: 200, epoch: 13 | loss: 0.0715147\n",
      "\tspeed: 0.0495s/iter; left time: 965.4046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 224 | Train Loss: 0.0737650 Vali Loss: 0.0755211 Test Loss: 0.0866745\n",
      "Validation loss decreased (0.075600 --> 0.075521).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0690998\n",
      "\tspeed: 0.0907s/iter; left time: 1757.6743s\n",
      "\titers: 200, epoch: 14 | loss: 0.0740039\n",
      "\tspeed: 0.0427s/iter; left time: 822.8919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.57s\n",
      "Steps: 224 | Train Loss: 0.0734863 Vali Loss: 0.0755634 Test Loss: 0.0866108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0747141\n",
      "\tspeed: 0.0898s/iter; left time: 1721.8217s\n",
      "\titers: 200, epoch: 15 | loss: 0.0715218\n",
      "\tspeed: 0.0449s/iter; left time: 856.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.33s\n",
      "Steps: 224 | Train Loss: 0.0732544 Vali Loss: 0.0754703 Test Loss: 0.0863815\n",
      "Validation loss decreased (0.075521 --> 0.075470).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0757171\n",
      "\tspeed: 0.1318s/iter; left time: 2496.1738s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741671\n",
      "\tspeed: 0.0439s/iter; left time: 826.9063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 224 | Train Loss: 0.0730401 Vali Loss: 0.0754147 Test Loss: 0.0865284\n",
      "Validation loss decreased (0.075470 --> 0.075415).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0738392\n",
      "\tspeed: 0.0886s/iter; left time: 1658.1517s\n",
      "\titers: 200, epoch: 17 | loss: 0.0738164\n",
      "\tspeed: 0.0532s/iter; left time: 990.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.22s\n",
      "Steps: 224 | Train Loss: 0.0727451 Vali Loss: 0.0753884 Test Loss: 0.0866636\n",
      "Validation loss decreased (0.075415 --> 0.075388).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0709763\n",
      "\tspeed: 0.0946s/iter; left time: 1749.5390s\n",
      "\titers: 200, epoch: 18 | loss: 0.0730822\n",
      "\tspeed: 0.0481s/iter; left time: 884.0656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.17s\n",
      "Steps: 224 | Train Loss: 0.0725751 Vali Loss: 0.0753965 Test Loss: 0.0865688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0742952\n",
      "\tspeed: 0.0884s/iter; left time: 1614.6894s\n",
      "\titers: 200, epoch: 19 | loss: 0.0760767\n",
      "\tspeed: 0.0481s/iter; left time: 874.2227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.80s\n",
      "Steps: 224 | Train Loss: 0.0724123 Vali Loss: 0.0755017 Test Loss: 0.0866896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0718111\n",
      "\tspeed: 0.0877s/iter; left time: 1582.9746s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710565\n",
      "\tspeed: 0.0445s/iter; left time: 797.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.69s\n",
      "Steps: 224 | Train Loss: 0.0723087 Vali Loss: 0.0754631 Test Loss: 0.0866524\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0719257\n",
      "\tspeed: 0.0792s/iter; left time: 1412.1959s\n",
      "\titers: 200, epoch: 21 | loss: 0.0696810\n",
      "\tspeed: 0.0440s/iter; left time: 780.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:10.04s\n",
      "Steps: 224 | Train Loss: 0.0721695 Vali Loss: 0.0753144 Test Loss: 0.0863799\n",
      "Validation loss decreased (0.075388 --> 0.075314).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0725704\n",
      "\tspeed: 0.0797s/iter; left time: 1402.1948s\n",
      "\titers: 200, epoch: 22 | loss: 0.0757288\n",
      "\tspeed: 0.0451s/iter; left time: 789.4212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.0720685 Vali Loss: 0.0754024 Test Loss: 0.0867224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0705284\n",
      "\tspeed: 0.0779s/iter; left time: 1353.3379s\n",
      "\titers: 200, epoch: 23 | loss: 0.0728130\n",
      "\tspeed: 0.0435s/iter; left time: 750.8516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0718940 Vali Loss: 0.0753721 Test Loss: 0.0865993\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0695775\n",
      "\tspeed: 0.0795s/iter; left time: 1364.1229s\n",
      "\titers: 200, epoch: 24 | loss: 0.0694624\n",
      "\tspeed: 0.0442s/iter; left time: 754.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 224 | Train Loss: 0.0718041 Vali Loss: 0.0755413 Test Loss: 0.0868192\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0702295\n",
      "\tspeed: 0.0801s/iter; left time: 1355.2470s\n",
      "\titers: 200, epoch: 25 | loss: 0.0673121\n",
      "\tspeed: 0.0441s/iter; left time: 741.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0717452 Vali Loss: 0.0753333 Test Loss: 0.0865029\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0699733\n",
      "\tspeed: 0.0797s/iter; left time: 1330.2455s\n",
      "\titers: 200, epoch: 26 | loss: 0.0694492\n",
      "\tspeed: 0.0441s/iter; left time: 732.8181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.0716570 Vali Loss: 0.0753502 Test Loss: 0.0866323\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0750768\n",
      "\tspeed: 0.0805s/iter; left time: 1326.4382s\n",
      "\titers: 200, epoch: 27 | loss: 0.0676697\n",
      "\tspeed: 0.0434s/iter; left time: 711.0155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 224 | Train Loss: 0.0715888 Vali Loss: 0.0753193 Test Loss: 0.0866331\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0697221\n",
      "\tspeed: 0.0787s/iter; left time: 1279.2560s\n",
      "\titers: 200, epoch: 28 | loss: 0.0742003\n",
      "\tspeed: 0.0445s/iter; left time: 718.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0714908 Vali Loss: 0.0753599 Test Loss: 0.0865416\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0737176\n",
      "\tspeed: 0.0802s/iter; left time: 1286.2247s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728098\n",
      "\tspeed: 0.0435s/iter; left time: 692.9588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.0714532 Vali Loss: 0.0753859 Test Loss: 0.0867439\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0677266\n",
      "\tspeed: 0.0799s/iter; left time: 1263.2798s\n",
      "\titers: 200, epoch: 30 | loss: 0.0682861\n",
      "\tspeed: 0.0440s/iter; left time: 691.6303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0713848 Vali Loss: 0.0754361 Test Loss: 0.0865617\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0686235\n",
      "\tspeed: 0.0793s/iter; left time: 1235.7145s\n",
      "\titers: 200, epoch: 31 | loss: 0.0683744\n",
      "\tspeed: 0.0431s/iter; left time: 667.1399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0713562 Vali Loss: 0.0753999 Test Loss: 0.0868126\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018505122512578964, rmse:0.1360335350036621, mae:0.08637991547584534, rse:0.39962559938430786\n",
      "Intermediate time for ES and pred_len 96: 00h:15m:23.53s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1582002\n",
      "\tspeed: 0.0627s/iter; left time: 1392.8210s\n",
      "\titers: 200, epoch: 1 | loss: 0.1504422\n",
      "\tspeed: 0.0426s/iter; left time: 941.7732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 223 | Train Loss: 0.1638853 Vali Loss: 0.1523434 Test Loss: 0.1819368\n",
      "Validation loss decreased (inf --> 0.152343).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0989957\n",
      "\tspeed: 0.0782s/iter; left time: 1719.1541s\n",
      "\titers: 200, epoch: 2 | loss: 0.0933139\n",
      "\tspeed: 0.0427s/iter; left time: 933.3875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.1013221 Vali Loss: 0.0892732 Test Loss: 0.1013731\n",
      "Validation loss decreased (0.152343 --> 0.089273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0939221\n",
      "\tspeed: 0.0775s/iter; left time: 1685.8470s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870873\n",
      "\tspeed: 0.0426s/iter; left time: 922.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0888086 Vali Loss: 0.0861637 Test Loss: 0.0980787\n",
      "Validation loss decreased (0.089273 --> 0.086164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0854114\n",
      "\tspeed: 0.0776s/iter; left time: 1670.6925s\n",
      "\titers: 200, epoch: 4 | loss: 0.0838073\n",
      "\tspeed: 0.0426s/iter; left time: 912.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0857859 Vali Loss: 0.0842218 Test Loss: 0.0960832\n",
      "Validation loss decreased (0.086164 --> 0.084222).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0821497\n",
      "\tspeed: 0.0772s/iter; left time: 1645.1318s\n",
      "\titers: 200, epoch: 5 | loss: 0.0822526\n",
      "\tspeed: 0.0426s/iter; left time: 902.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0838813 Vali Loss: 0.0834715 Test Loss: 0.0949565\n",
      "Validation loss decreased (0.084222 --> 0.083471).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0830588\n",
      "\tspeed: 0.0779s/iter; left time: 1642.6264s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822484\n",
      "\tspeed: 0.0425s/iter; left time: 892.9373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0827285 Vali Loss: 0.0832899 Test Loss: 0.0945786\n",
      "Validation loss decreased (0.083471 --> 0.083290).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0846333\n",
      "\tspeed: 0.0770s/iter; left time: 1606.7264s\n",
      "\titers: 200, epoch: 7 | loss: 0.0803458\n",
      "\tspeed: 0.0426s/iter; left time: 884.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0819744 Vali Loss: 0.0828027 Test Loss: 0.0940958\n",
      "Validation loss decreased (0.083290 --> 0.082803).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823168\n",
      "\tspeed: 0.0771s/iter; left time: 1591.3274s\n",
      "\titers: 200, epoch: 8 | loss: 0.0828552\n",
      "\tspeed: 0.0426s/iter; left time: 875.5362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0813660 Vali Loss: 0.0828556 Test Loss: 0.0939133\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0780621\n",
      "\tspeed: 0.0768s/iter; left time: 1567.9788s\n",
      "\titers: 200, epoch: 9 | loss: 0.0816576\n",
      "\tspeed: 0.0427s/iter; left time: 867.6342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0808007 Vali Loss: 0.0826950 Test Loss: 0.0937721\n",
      "Validation loss decreased (0.082803 --> 0.082695).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0775661\n",
      "\tspeed: 0.0964s/iter; left time: 1947.1080s\n",
      "\titers: 200, epoch: 10 | loss: 0.0774189\n",
      "\tspeed: 0.0426s/iter; left time: 856.2542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 223 | Train Loss: 0.0802986 Vali Loss: 0.0825369 Test Loss: 0.0934516\n",
      "Validation loss decreased (0.082695 --> 0.082537).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0796763\n",
      "\tspeed: 0.0781s/iter; left time: 1560.4622s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782240\n",
      "\tspeed: 0.0429s/iter; left time: 852.5089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 223 | Train Loss: 0.0798780 Vali Loss: 0.0824189 Test Loss: 0.0934367\n",
      "Validation loss decreased (0.082537 --> 0.082419).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0813513\n",
      "\tspeed: 0.0784s/iter; left time: 1548.8565s\n",
      "\titers: 200, epoch: 12 | loss: 0.0797516\n",
      "\tspeed: 0.0426s/iter; left time: 837.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0794918 Vali Loss: 0.0824583 Test Loss: 0.0934083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0798676\n",
      "\tspeed: 0.0767s/iter; left time: 1498.4231s\n",
      "\titers: 200, epoch: 13 | loss: 0.0763271\n",
      "\tspeed: 0.0427s/iter; left time: 828.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0791038 Vali Loss: 0.0821107 Test Loss: 0.0937554\n",
      "Validation loss decreased (0.082419 --> 0.082111).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0794068\n",
      "\tspeed: 0.0782s/iter; left time: 1509.0850s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772176\n",
      "\tspeed: 0.0429s/iter; left time: 824.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 223 | Train Loss: 0.0787783 Vali Loss: 0.0821921 Test Loss: 0.0937325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0795014\n",
      "\tspeed: 0.0776s/iter; left time: 1479.8416s\n",
      "\titers: 200, epoch: 15 | loss: 0.0759366\n",
      "\tspeed: 0.0426s/iter; left time: 808.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0784788 Vali Loss: 0.0824661 Test Loss: 0.0939714\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786937\n",
      "\tspeed: 0.0771s/iter; left time: 1452.9907s\n",
      "\titers: 200, epoch: 16 | loss: 0.0787571\n",
      "\tspeed: 0.0426s/iter; left time: 798.9364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0782784 Vali Loss: 0.0822087 Test Loss: 0.0945132\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0774266\n",
      "\tspeed: 0.0768s/iter; left time: 1430.4289s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766618\n",
      "\tspeed: 0.0426s/iter; left time: 788.8493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0780505 Vali Loss: 0.0822913 Test Loss: 0.0946241\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0793561\n",
      "\tspeed: 0.0764s/iter; left time: 1405.9621s\n",
      "\titers: 200, epoch: 18 | loss: 0.0766027\n",
      "\tspeed: 0.0427s/iter; left time: 781.6684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0778071 Vali Loss: 0.0824921 Test Loss: 0.0951358\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0807288\n",
      "\tspeed: 0.0761s/iter; left time: 1383.5080s\n",
      "\titers: 200, epoch: 19 | loss: 0.0765183\n",
      "\tspeed: 0.0426s/iter; left time: 771.2372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0776330 Vali Loss: 0.0822682 Test Loss: 0.0952981\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0763897\n",
      "\tspeed: 0.0766s/iter; left time: 1375.7542s\n",
      "\titers: 200, epoch: 20 | loss: 0.0792303\n",
      "\tspeed: 0.0426s/iter; left time: 760.7483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0775091 Vali Loss: 0.0822907 Test Loss: 0.0952427\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0762942\n",
      "\tspeed: 0.0763s/iter; left time: 1354.1459s\n",
      "\titers: 200, epoch: 21 | loss: 0.0771212\n",
      "\tspeed: 0.0426s/iter; left time: 750.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0773324 Vali Loss: 0.0822556 Test Loss: 0.0953331\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0753811\n",
      "\tspeed: 0.0762s/iter; left time: 1335.6703s\n",
      "\titers: 200, epoch: 22 | loss: 0.0768200\n",
      "\tspeed: 0.0426s/iter; left time: 741.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0772267 Vali Loss: 0.0820854 Test Loss: 0.0957104\n",
      "Validation loss decreased (0.082111 --> 0.082085).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0765416\n",
      "\tspeed: 0.0770s/iter; left time: 1332.0961s\n",
      "\titers: 200, epoch: 23 | loss: 0.0776889\n",
      "\tspeed: 0.0426s/iter; left time: 732.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0770907 Vali Loss: 0.0822180 Test Loss: 0.0957075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0802181\n",
      "\tspeed: 0.0778s/iter; left time: 1327.7908s\n",
      "\titers: 200, epoch: 24 | loss: 0.0708010\n",
      "\tspeed: 0.0428s/iter; left time: 725.5914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 223 | Train Loss: 0.0769400 Vali Loss: 0.0820887 Test Loss: 0.0957013\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0785841\n",
      "\tspeed: 0.0768s/iter; left time: 1293.5946s\n",
      "\titers: 200, epoch: 25 | loss: 0.0719926\n",
      "\tspeed: 0.0426s/iter; left time: 713.7501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0768448 Vali Loss: 0.0822283 Test Loss: 0.0959574\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0766644\n",
      "\tspeed: 0.0760s/iter; left time: 1263.3435s\n",
      "\titers: 200, epoch: 26 | loss: 0.0741731\n",
      "\tspeed: 0.0425s/iter; left time: 702.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0767627 Vali Loss: 0.0821415 Test Loss: 0.0960435\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0779996\n",
      "\tspeed: 0.0758s/iter; left time: 1244.1082s\n",
      "\titers: 200, epoch: 27 | loss: 0.0773505\n",
      "\tspeed: 0.0426s/iter; left time: 694.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0766876 Vali Loss: 0.0821087 Test Loss: 0.0960073\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762004\n",
      "\tspeed: 0.0762s/iter; left time: 1233.6128s\n",
      "\titers: 200, epoch: 28 | loss: 0.0732721\n",
      "\tspeed: 0.0426s/iter; left time: 684.3079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0766399 Vali Loss: 0.0821509 Test Loss: 0.0961446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0777855\n",
      "\tspeed: 0.0757s/iter; left time: 1207.1792s\n",
      "\titers: 200, epoch: 29 | loss: 0.0782245\n",
      "\tspeed: 0.0425s/iter; left time: 674.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0765682 Vali Loss: 0.0822768 Test Loss: 0.0963000\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0783652\n",
      "\tspeed: 0.0757s/iter; left time: 1191.0149s\n",
      "\titers: 200, epoch: 30 | loss: 0.0760999\n",
      "\tspeed: 0.0426s/iter; left time: 665.4889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0765361 Vali Loss: 0.0823724 Test Loss: 0.0966561\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0737685\n",
      "\tspeed: 0.0761s/iter; left time: 1179.6887s\n",
      "\titers: 200, epoch: 31 | loss: 0.0757145\n",
      "\tspeed: 0.0426s/iter; left time: 656.4695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0764457 Vali Loss: 0.0821356 Test Loss: 0.0963666\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0770690\n",
      "\tspeed: 0.0760s/iter; left time: 1162.2512s\n",
      "\titers: 200, epoch: 32 | loss: 0.0798712\n",
      "\tspeed: 0.0426s/iter; left time: 646.8957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0763819 Vali Loss: 0.0822384 Test Loss: 0.0966226\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021373990923166275, rmse:0.14619846642017365, mae:0.09571041911840439, rse:0.4295179545879364\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1623213\n",
      "\tspeed: 0.0443s/iter; left time: 983.0044s\n",
      "\titers: 200, epoch: 1 | loss: 0.1507847\n",
      "\tspeed: 0.0424s/iter; left time: 937.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.1635632 Vali Loss: 0.1513731 Test Loss: 0.1804650\n",
      "Validation loss decreased (inf --> 0.151373).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0967694\n",
      "\tspeed: 0.0798s/iter; left time: 1753.0825s\n",
      "\titers: 200, epoch: 2 | loss: 0.0900421\n",
      "\tspeed: 0.0425s/iter; left time: 929.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.1009800 Vali Loss: 0.0887405 Test Loss: 0.1008240\n",
      "Validation loss decreased (0.151373 --> 0.088740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0906517\n",
      "\tspeed: 0.1047s/iter; left time: 2278.7332s\n",
      "\titers: 200, epoch: 3 | loss: 0.0844556\n",
      "\tspeed: 0.0425s/iter; left time: 921.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0886283 Vali Loss: 0.0860639 Test Loss: 0.0981020\n",
      "Validation loss decreased (0.088740 --> 0.086064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0862825\n",
      "\tspeed: 0.0946s/iter; left time: 2036.0942s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867988\n",
      "\tspeed: 0.0424s/iter; left time: 909.2479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0857093 Vali Loss: 0.0843615 Test Loss: 0.0962627\n",
      "Validation loss decreased (0.086064 --> 0.084361).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0855029\n",
      "\tspeed: 0.0833s/iter; left time: 1775.0499s\n",
      "\titers: 200, epoch: 5 | loss: 0.0834127\n",
      "\tspeed: 0.0425s/iter; left time: 901.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0839361 Vali Loss: 0.0838893 Test Loss: 0.0956411\n",
      "Validation loss decreased (0.084361 --> 0.083889).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834710\n",
      "\tspeed: 0.0783s/iter; left time: 1651.8429s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811198\n",
      "\tspeed: 0.0425s/iter; left time: 891.7014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0828296 Vali Loss: 0.0837776 Test Loss: 0.0951267\n",
      "Validation loss decreased (0.083889 --> 0.083778).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0861155\n",
      "\tspeed: 0.0770s/iter; left time: 1605.6841s\n",
      "\titers: 200, epoch: 7 | loss: 0.0855570\n",
      "\tspeed: 0.0425s/iter; left time: 882.7584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0820855 Vali Loss: 0.0831758 Test Loss: 0.0944226\n",
      "Validation loss decreased (0.083778 --> 0.083176).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0832355\n",
      "\tspeed: 0.0770s/iter; left time: 1589.2364s\n",
      "\titers: 200, epoch: 8 | loss: 0.0795388\n",
      "\tspeed: 0.0425s/iter; left time: 873.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0814745 Vali Loss: 0.0831434 Test Loss: 0.0941327\n",
      "Validation loss decreased (0.083176 --> 0.083143).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0795199\n",
      "\tspeed: 0.0766s/iter; left time: 1563.0382s\n",
      "\titers: 200, epoch: 9 | loss: 0.0825877\n",
      "\tspeed: 0.0425s/iter; left time: 862.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0809013 Vali Loss: 0.0832683 Test Loss: 0.0939217\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0840776\n",
      "\tspeed: 0.0758s/iter; left time: 1530.1837s\n",
      "\titers: 200, epoch: 10 | loss: 0.0821245\n",
      "\tspeed: 0.0425s/iter; left time: 854.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0804636 Vali Loss: 0.0829914 Test Loss: 0.0936194\n",
      "Validation loss decreased (0.083143 --> 0.082991).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0797929\n",
      "\tspeed: 0.0770s/iter; left time: 1538.2168s\n",
      "\titers: 200, epoch: 11 | loss: 0.0799730\n",
      "\tspeed: 0.0425s/iter; left time: 844.1887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0800309 Vali Loss: 0.0829647 Test Loss: 0.0932871\n",
      "Validation loss decreased (0.082991 --> 0.082965).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810702\n",
      "\tspeed: 0.0768s/iter; left time: 1515.7670s\n",
      "\titers: 200, epoch: 12 | loss: 0.0835351\n",
      "\tspeed: 0.0425s/iter; left time: 835.8600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0796978 Vali Loss: 0.0829677 Test Loss: 0.0933932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0758945\n",
      "\tspeed: 0.0757s/iter; left time: 1479.0157s\n",
      "\titers: 200, epoch: 13 | loss: 0.0817818\n",
      "\tspeed: 0.0425s/iter; left time: 825.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0793328 Vali Loss: 0.0829195 Test Loss: 0.0931888\n",
      "Validation loss decreased (0.082965 --> 0.082920).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0800635\n",
      "\tspeed: 0.0772s/iter; left time: 1490.3276s\n",
      "\titers: 200, epoch: 14 | loss: 0.0825971\n",
      "\tspeed: 0.0426s/iter; left time: 817.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0789841 Vali Loss: 0.0826235 Test Loss: 0.0933784\n",
      "Validation loss decreased (0.082920 --> 0.082624).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0811006\n",
      "\tspeed: 0.0766s/iter; left time: 1461.9138s\n",
      "\titers: 200, epoch: 15 | loss: 0.0775294\n",
      "\tspeed: 0.0425s/iter; left time: 806.5005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0787673 Vali Loss: 0.0826715 Test Loss: 0.0933170\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789641\n",
      "\tspeed: 0.0757s/iter; left time: 1428.3418s\n",
      "\titers: 200, epoch: 16 | loss: 0.0824256\n",
      "\tspeed: 0.0425s/iter; left time: 797.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0785044 Vali Loss: 0.0825806 Test Loss: 0.0933613\n",
      "Validation loss decreased (0.082624 --> 0.082581).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0765666\n",
      "\tspeed: 0.0785s/iter; left time: 1461.7693s\n",
      "\titers: 200, epoch: 17 | loss: 0.0772372\n",
      "\tspeed: 0.0425s/iter; left time: 788.3513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0781951 Vali Loss: 0.0824544 Test Loss: 0.0936698\n",
      "Validation loss decreased (0.082581 --> 0.082454).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735902\n",
      "\tspeed: 0.0769s/iter; left time: 1415.0900s\n",
      "\titers: 200, epoch: 18 | loss: 0.0794902\n",
      "\tspeed: 0.0425s/iter; left time: 777.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0779698 Vali Loss: 0.0825212 Test Loss: 0.0938011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0772863\n",
      "\tspeed: 0.0757s/iter; left time: 1377.1688s\n",
      "\titers: 200, epoch: 19 | loss: 0.0747855\n",
      "\tspeed: 0.0425s/iter; left time: 769.3198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0777663 Vali Loss: 0.0825519 Test Loss: 0.0940492\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0817482\n",
      "\tspeed: 0.0752s/iter; left time: 1350.6536s\n",
      "\titers: 200, epoch: 20 | loss: 0.0781768\n",
      "\tspeed: 0.0425s/iter; left time: 758.9742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0776105 Vali Loss: 0.0823942 Test Loss: 0.0938594\n",
      "Validation loss decreased (0.082454 --> 0.082394).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749328\n",
      "\tspeed: 0.0770s/iter; left time: 1366.7279s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789955\n",
      "\tspeed: 0.0425s/iter; left time: 749.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0774189 Vali Loss: 0.0823355 Test Loss: 0.0942890\n",
      "Validation loss decreased (0.082394 --> 0.082336).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0805455\n",
      "\tspeed: 0.0782s/iter; left time: 1369.4373s\n",
      "\titers: 200, epoch: 22 | loss: 0.0754221\n",
      "\tspeed: 0.0425s/iter; left time: 741.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0773240 Vali Loss: 0.0822265 Test Loss: 0.0943614\n",
      "Validation loss decreased (0.082336 --> 0.082226).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0787228\n",
      "\tspeed: 0.0766s/iter; left time: 1324.1679s\n",
      "\titers: 200, epoch: 23 | loss: 0.0742987\n",
      "\tspeed: 0.0425s/iter; left time: 731.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0772184 Vali Loss: 0.0823955 Test Loss: 0.0947567\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0775053\n",
      "\tspeed: 0.0755s/iter; left time: 1289.7837s\n",
      "\titers: 200, epoch: 24 | loss: 0.0773024\n",
      "\tspeed: 0.0425s/iter; left time: 720.7688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0770285 Vali Loss: 0.0822210 Test Loss: 0.0943585\n",
      "Validation loss decreased (0.082226 --> 0.082221).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0765192\n",
      "\tspeed: 0.0774s/iter; left time: 1304.1396s\n",
      "\titers: 200, epoch: 25 | loss: 0.0779399\n",
      "\tspeed: 0.0425s/iter; left time: 711.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0769189 Vali Loss: 0.0821099 Test Loss: 0.0946129\n",
      "Validation loss decreased (0.082221 --> 0.082110).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0753684\n",
      "\tspeed: 0.0765s/iter; left time: 1271.9256s\n",
      "\titers: 200, epoch: 26 | loss: 0.0782473\n",
      "\tspeed: 0.0425s/iter; left time: 702.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0768195 Vali Loss: 0.0822617 Test Loss: 0.0949533\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0764916\n",
      "\tspeed: 0.0759s/iter; left time: 1244.3974s\n",
      "\titers: 200, epoch: 27 | loss: 0.0755978\n",
      "\tspeed: 0.0425s/iter; left time: 692.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0767680 Vali Loss: 0.0822143 Test Loss: 0.0950215\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0734486\n",
      "\tspeed: 0.0756s/iter; left time: 1222.4507s\n",
      "\titers: 200, epoch: 28 | loss: 0.0753237\n",
      "\tspeed: 0.0425s/iter; left time: 683.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0767142 Vali Loss: 0.0821859 Test Loss: 0.0945747\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0775932\n",
      "\tspeed: 0.0753s/iter; left time: 1201.2036s\n",
      "\titers: 200, epoch: 29 | loss: 0.0780666\n",
      "\tspeed: 0.0425s/iter; left time: 673.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0765791 Vali Loss: 0.0820457 Test Loss: 0.0951564\n",
      "Validation loss decreased (0.082110 --> 0.082046).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0747046\n",
      "\tspeed: 0.0762s/iter; left time: 1199.6400s\n",
      "\titers: 200, epoch: 30 | loss: 0.0805135\n",
      "\tspeed: 0.0425s/iter; left time: 665.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0765586 Vali Loss: 0.0822913 Test Loss: 0.0951025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0762359\n",
      "\tspeed: 0.0764s/iter; left time: 1185.5860s\n",
      "\titers: 200, epoch: 31 | loss: 0.0755212\n",
      "\tspeed: 0.0426s/iter; left time: 655.8050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0764912 Vali Loss: 0.0820334 Test Loss: 0.0949782\n",
      "Validation loss decreased (0.082046 --> 0.082033).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0777004\n",
      "\tspeed: 0.0774s/iter; left time: 1183.8726s\n",
      "\titers: 200, epoch: 32 | loss: 0.0789844\n",
      "\tspeed: 0.0425s/iter; left time: 645.8433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0763796 Vali Loss: 0.0821568 Test Loss: 0.0956396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0738203\n",
      "\tspeed: 0.0753s/iter; left time: 1133.8288s\n",
      "\titers: 200, epoch: 33 | loss: 0.0756400\n",
      "\tspeed: 0.0425s/iter; left time: 636.0645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0763773 Vali Loss: 0.0821474 Test Loss: 0.0955317\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754073\n",
      "\tspeed: 0.0756s/iter; left time: 1121.8630s\n",
      "\titers: 200, epoch: 34 | loss: 0.0707455\n",
      "\tspeed: 0.0424s/iter; left time: 625.6582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0763250 Vali Loss: 0.0821367 Test Loss: 0.0955293\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0779735\n",
      "\tspeed: 0.0761s/iter; left time: 1113.0678s\n",
      "\titers: 200, epoch: 35 | loss: 0.0737309\n",
      "\tspeed: 0.0425s/iter; left time: 617.1891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0762472 Vali Loss: 0.0820737 Test Loss: 0.0954533\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0777511\n",
      "\tspeed: 0.0757s/iter; left time: 1089.2019s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743867\n",
      "\tspeed: 0.0425s/iter; left time: 607.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0762374 Vali Loss: 0.0821034 Test Loss: 0.0954588\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752488\n",
      "\tspeed: 0.0754s/iter; left time: 1069.0803s\n",
      "\titers: 200, epoch: 37 | loss: 0.0746293\n",
      "\tspeed: 0.0425s/iter; left time: 597.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0762136 Vali Loss: 0.0821561 Test Loss: 0.0956381\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0745010\n",
      "\tspeed: 0.0755s/iter; left time: 1053.0512s\n",
      "\titers: 200, epoch: 38 | loss: 0.0772252\n",
      "\tspeed: 0.0425s/iter; left time: 589.0239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0762028 Vali Loss: 0.0821295 Test Loss: 0.0955146\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0767802\n",
      "\tspeed: 0.0757s/iter; left time: 1038.6736s\n",
      "\titers: 200, epoch: 39 | loss: 0.0752683\n",
      "\tspeed: 0.0426s/iter; left time: 579.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0761856 Vali Loss: 0.0820946 Test Loss: 0.0955351\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0760245\n",
      "\tspeed: 0.0756s/iter; left time: 1021.2602s\n",
      "\titers: 200, epoch: 40 | loss: 0.0747323\n",
      "\tspeed: 0.0425s/iter; left time: 569.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0761252 Vali Loss: 0.0821186 Test Loss: 0.0957213\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0742132\n",
      "\tspeed: 0.0755s/iter; left time: 1002.3750s\n",
      "\titers: 200, epoch: 41 | loss: 0.0766348\n",
      "\tspeed: 0.0425s/iter; left time: 559.5432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0760819 Vali Loss: 0.0822180 Test Loss: 0.0961468\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021038100123405457, rmse:0.14504516124725342, mae:0.09497818350791931, rse:0.42612963914871216\n",
      "Intermediate time for ES and pred_len 168: 00h:14m:49.56s\n",
      "Intermediate time for ES: 00h:58m:05.59s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1121947\n",
      "\tspeed: 0.0616s/iter; left time: 1374.4072s\n",
      "\titers: 200, epoch: 1 | loss: 0.1003998\n",
      "\tspeed: 0.0419s/iter; left time: 930.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 224 | Train Loss: 0.1124252 Vali Loss: 0.1140230 Test Loss: 0.1257952\n",
      "Validation loss decreased (inf --> 0.114023).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0552393\n",
      "\tspeed: 0.0758s/iter; left time: 1672.7063s\n",
      "\titers: 200, epoch: 2 | loss: 0.0489163\n",
      "\tspeed: 0.0419s/iter; left time: 920.0890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0612217 Vali Loss: 0.0596655 Test Loss: 0.0627740\n",
      "Validation loss decreased (0.114023 --> 0.059665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0480090\n",
      "\tspeed: 0.0751s/iter; left time: 1642.0388s\n",
      "\titers: 200, epoch: 3 | loss: 0.0485542\n",
      "\tspeed: 0.0419s/iter; left time: 911.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0487076 Vali Loss: 0.0571585 Test Loss: 0.0603112\n",
      "Validation loss decreased (0.059665 --> 0.057158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0447154\n",
      "\tspeed: 0.0762s/iter; left time: 1648.6851s\n",
      "\titers: 200, epoch: 4 | loss: 0.0429314\n",
      "\tspeed: 0.0419s/iter; left time: 902.9101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0464313 Vali Loss: 0.0554574 Test Loss: 0.0589497\n",
      "Validation loss decreased (0.057158 --> 0.055457).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0423501\n",
      "\tspeed: 0.0769s/iter; left time: 1645.4209s\n",
      "\titers: 200, epoch: 5 | loss: 0.0467467\n",
      "\tspeed: 0.0419s/iter; left time: 892.0272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0449963 Vali Loss: 0.0544936 Test Loss: 0.0579954\n",
      "Validation loss decreased (0.055457 --> 0.054494).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0428498\n",
      "\tspeed: 0.0767s/iter; left time: 1624.9825s\n",
      "\titers: 200, epoch: 6 | loss: 0.0431722\n",
      "\tspeed: 0.0419s/iter; left time: 882.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0438708 Vali Loss: 0.0535841 Test Loss: 0.0572606\n",
      "Validation loss decreased (0.054494 --> 0.053584).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0450463\n",
      "\tspeed: 0.0750s/iter; left time: 1571.3184s\n",
      "\titers: 200, epoch: 7 | loss: 0.0422882\n",
      "\tspeed: 0.0419s/iter; left time: 873.1714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0432172 Vali Loss: 0.0532738 Test Loss: 0.0568294\n",
      "Validation loss decreased (0.053584 --> 0.053274).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0423689\n",
      "\tspeed: 0.0750s/iter; left time: 1555.0621s\n",
      "\titers: 200, epoch: 8 | loss: 0.0431759\n",
      "\tspeed: 0.0418s/iter; left time: 863.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0426508 Vali Loss: 0.0527346 Test Loss: 0.0564877\n",
      "Validation loss decreased (0.053274 --> 0.052735).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0423538\n",
      "\tspeed: 0.0751s/iter; left time: 1539.7498s\n",
      "\titers: 200, epoch: 9 | loss: 0.0434452\n",
      "\tspeed: 0.0418s/iter; left time: 853.9411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0422342 Vali Loss: 0.0526336 Test Loss: 0.0563798\n",
      "Validation loss decreased (0.052735 --> 0.052634).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0398495\n",
      "\tspeed: 0.0748s/iter; left time: 1517.5962s\n",
      "\titers: 200, epoch: 10 | loss: 0.0404127\n",
      "\tspeed: 0.0419s/iter; left time: 845.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0419349 Vali Loss: 0.0524291 Test Loss: 0.0560434\n",
      "Validation loss decreased (0.052634 --> 0.052429).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0450116\n",
      "\tspeed: 0.0759s/iter; left time: 1522.7725s\n",
      "\titers: 200, epoch: 11 | loss: 0.0409348\n",
      "\tspeed: 0.0419s/iter; left time: 835.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0416426 Vali Loss: 0.0523388 Test Loss: 0.0560597\n",
      "Validation loss decreased (0.052429 --> 0.052339).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0402090\n",
      "\tspeed: 0.0752s/iter; left time: 1491.2999s\n",
      "\titers: 200, epoch: 12 | loss: 0.0399124\n",
      "\tspeed: 0.0419s/iter; left time: 826.9813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0414412 Vali Loss: 0.0522899 Test Loss: 0.0560075\n",
      "Validation loss decreased (0.052339 --> 0.052290).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0402795\n",
      "\tspeed: 0.0752s/iter; left time: 1474.5507s\n",
      "\titers: 200, epoch: 13 | loss: 0.0442635\n",
      "\tspeed: 0.0419s/iter; left time: 816.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0412266 Vali Loss: 0.0521753 Test Loss: 0.0559162\n",
      "Validation loss decreased (0.052290 --> 0.052175).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0446919\n",
      "\tspeed: 0.0757s/iter; left time: 1467.3655s\n",
      "\titers: 200, epoch: 14 | loss: 0.0414494\n",
      "\tspeed: 0.0418s/iter; left time: 806.5237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0410329 Vali Loss: 0.0520798 Test Loss: 0.0556257\n",
      "Validation loss decreased (0.052175 --> 0.052080).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0421744\n",
      "\tspeed: 0.0752s/iter; left time: 1440.4107s\n",
      "\titers: 200, epoch: 15 | loss: 0.0421534\n",
      "\tspeed: 0.0418s/iter; left time: 797.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0408562 Vali Loss: 0.0522112 Test Loss: 0.0558546\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0408129\n",
      "\tspeed: 0.0745s/iter; left time: 1410.9069s\n",
      "\titers: 200, epoch: 16 | loss: 0.0392103\n",
      "\tspeed: 0.0419s/iter; left time: 788.7272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0407342 Vali Loss: 0.0521150 Test Loss: 0.0556049\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0377135\n",
      "\tspeed: 0.0743s/iter; left time: 1390.6428s\n",
      "\titers: 200, epoch: 17 | loss: 0.0385958\n",
      "\tspeed: 0.0419s/iter; left time: 779.2561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0406220 Vali Loss: 0.0520192 Test Loss: 0.0556480\n",
      "Validation loss decreased (0.052080 --> 0.052019).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0409500\n",
      "\tspeed: 0.0752s/iter; left time: 1390.7876s\n",
      "\titers: 200, epoch: 18 | loss: 0.0358631\n",
      "\tspeed: 0.0419s/iter; left time: 770.1107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0404933 Vali Loss: 0.0520228 Test Loss: 0.0554515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0379888\n",
      "\tspeed: 0.0744s/iter; left time: 1359.0458s\n",
      "\titers: 200, epoch: 19 | loss: 0.0403270\n",
      "\tspeed: 0.0418s/iter; left time: 759.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0404586 Vali Loss: 0.0519224 Test Loss: 0.0554611\n",
      "Validation loss decreased (0.052019 --> 0.051922).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0409930\n",
      "\tspeed: 0.0752s/iter; left time: 1356.5940s\n",
      "\titers: 200, epoch: 20 | loss: 0.0405406\n",
      "\tspeed: 0.0418s/iter; left time: 749.5649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0403426 Vali Loss: 0.0520369 Test Loss: 0.0555618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0371660\n",
      "\tspeed: 0.0744s/iter; left time: 1326.5618s\n",
      "\titers: 200, epoch: 21 | loss: 0.0402139\n",
      "\tspeed: 0.0419s/iter; left time: 742.1534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0402404 Vali Loss: 0.0519488 Test Loss: 0.0553637\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0398164\n",
      "\tspeed: 0.0742s/iter; left time: 1304.9531s\n",
      "\titers: 200, epoch: 22 | loss: 0.0436726\n",
      "\tspeed: 0.0418s/iter; left time: 731.1433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0401827 Vali Loss: 0.0519050 Test Loss: 0.0553965\n",
      "Validation loss decreased (0.051922 --> 0.051905).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0383529\n",
      "\tspeed: 0.0755s/iter; left time: 1312.1832s\n",
      "\titers: 200, epoch: 23 | loss: 0.0441570\n",
      "\tspeed: 0.0418s/iter; left time: 721.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0400947 Vali Loss: 0.0519855 Test Loss: 0.0553256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0421799\n",
      "\tspeed: 0.0747s/iter; left time: 1280.7122s\n",
      "\titers: 200, epoch: 24 | loss: 0.0399955\n",
      "\tspeed: 0.0419s/iter; left time: 714.2296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0400648 Vali Loss: 0.0518750 Test Loss: 0.0554042\n",
      "Validation loss decreased (0.051905 --> 0.051875).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0394646\n",
      "\tspeed: 0.0755s/iter; left time: 1278.0270s\n",
      "\titers: 200, epoch: 25 | loss: 0.0383344\n",
      "\tspeed: 0.0418s/iter; left time: 703.8966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0400411 Vali Loss: 0.0519205 Test Loss: 0.0554544\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0413884\n",
      "\tspeed: 0.0747s/iter; left time: 1247.6525s\n",
      "\titers: 200, epoch: 26 | loss: 0.0399774\n",
      "\tspeed: 0.0418s/iter; left time: 694.4407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0399985 Vali Loss: 0.0519550 Test Loss: 0.0554619\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0379206\n",
      "\tspeed: 0.0743s/iter; left time: 1223.5739s\n",
      "\titers: 200, epoch: 27 | loss: 0.0381168\n",
      "\tspeed: 0.0418s/iter; left time: 685.0295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0399392 Vali Loss: 0.0518430 Test Loss: 0.0552859\n",
      "Validation loss decreased (0.051875 --> 0.051843).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0418810\n",
      "\tspeed: 0.0751s/iter; left time: 1220.8654s\n",
      "\titers: 200, epoch: 28 | loss: 0.0435387\n",
      "\tspeed: 0.0418s/iter; left time: 675.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0399106 Vali Loss: 0.0518326 Test Loss: 0.0552616\n",
      "Validation loss decreased (0.051843 --> 0.051833).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0398603\n",
      "\tspeed: 0.0751s/iter; left time: 1203.2948s\n",
      "\titers: 200, epoch: 29 | loss: 0.0391199\n",
      "\tspeed: 0.0418s/iter; left time: 666.2721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0398559 Vali Loss: 0.0517640 Test Loss: 0.0552997\n",
      "Validation loss decreased (0.051833 --> 0.051764).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0415632\n",
      "\tspeed: 0.0750s/iter; left time: 1184.8973s\n",
      "\titers: 200, epoch: 30 | loss: 0.0422339\n",
      "\tspeed: 0.0419s/iter; left time: 657.5951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0398787 Vali Loss: 0.0519103 Test Loss: 0.0553084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0399636\n",
      "\tspeed: 0.0751s/iter; left time: 1169.8527s\n",
      "\titers: 200, epoch: 31 | loss: 0.0369008\n",
      "\tspeed: 0.0419s/iter; left time: 648.5113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0398472 Vali Loss: 0.0518308 Test Loss: 0.0553513\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0412430\n",
      "\tspeed: 0.0745s/iter; left time: 1144.2156s\n",
      "\titers: 200, epoch: 32 | loss: 0.0370305\n",
      "\tspeed: 0.0419s/iter; left time: 639.0005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0398461 Vali Loss: 0.0517918 Test Loss: 0.0553053\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0375985\n",
      "\tspeed: 0.0746s/iter; left time: 1128.6510s\n",
      "\titers: 200, epoch: 33 | loss: 0.0408965\n",
      "\tspeed: 0.0419s/iter; left time: 629.4461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0397410 Vali Loss: 0.0518667 Test Loss: 0.0553178\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0425997\n",
      "\tspeed: 0.0745s/iter; left time: 1111.3305s\n",
      "\titers: 200, epoch: 34 | loss: 0.0426921\n",
      "\tspeed: 0.0418s/iter; left time: 619.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0397880 Vali Loss: 0.0518058 Test Loss: 0.0552537\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0403167\n",
      "\tspeed: 0.0752s/iter; left time: 1104.1239s\n",
      "\titers: 200, epoch: 35 | loss: 0.0391564\n",
      "\tspeed: 0.0419s/iter; left time: 611.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0397668 Vali Loss: 0.0518420 Test Loss: 0.0553296\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0378390\n",
      "\tspeed: 0.0743s/iter; left time: 1074.8417s\n",
      "\titers: 200, epoch: 36 | loss: 0.0453756\n",
      "\tspeed: 0.0419s/iter; left time: 602.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0397611 Vali Loss: 0.0517751 Test Loss: 0.0553614\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0439057\n",
      "\tspeed: 0.0750s/iter; left time: 1067.3460s\n",
      "\titers: 200, epoch: 37 | loss: 0.0392089\n",
      "\tspeed: 0.0419s/iter; left time: 591.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0397189 Vali Loss: 0.0518174 Test Loss: 0.0553212\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0399152\n",
      "\tspeed: 0.0763s/iter; left time: 1068.7099s\n",
      "\titers: 200, epoch: 38 | loss: 0.0420879\n",
      "\tspeed: 0.0419s/iter; left time: 582.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0397264 Vali Loss: 0.0517921 Test Loss: 0.0552313\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0389435\n",
      "\tspeed: 0.0745s/iter; left time: 1027.9415s\n",
      "\titers: 200, epoch: 39 | loss: 0.0397875\n",
      "\tspeed: 0.0419s/iter; left time: 573.4031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0396921 Vali Loss: 0.0518452 Test Loss: 0.0552375\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01012234017252922, rmse:0.10060983896255493, mae:0.05529971793293953, rse:0.3881499767303467\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1097454\n",
      "\tspeed: 0.0434s/iter; left time: 968.2699s\n",
      "\titers: 200, epoch: 1 | loss: 0.1002832\n",
      "\tspeed: 0.0419s/iter; left time: 929.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.1106880 Vali Loss: 0.1126629 Test Loss: 0.1250687\n",
      "Validation loss decreased (inf --> 0.112663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0544365\n",
      "\tspeed: 0.0749s/iter; left time: 1654.1496s\n",
      "\titers: 200, epoch: 2 | loss: 0.0556558\n",
      "\tspeed: 0.0418s/iter; left time: 918.7284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0617991 Vali Loss: 0.0603117 Test Loss: 0.0635018\n",
      "Validation loss decreased (0.112663 --> 0.060312).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0518334\n",
      "\tspeed: 0.0751s/iter; left time: 1640.6910s\n",
      "\titers: 200, epoch: 3 | loss: 0.0479707\n",
      "\tspeed: 0.0419s/iter; left time: 910.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0490852 Vali Loss: 0.0573255 Test Loss: 0.0607568\n",
      "Validation loss decreased (0.060312 --> 0.057326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0464834\n",
      "\tspeed: 0.0750s/iter; left time: 1621.4002s\n",
      "\titers: 200, epoch: 4 | loss: 0.0456835\n",
      "\tspeed: 0.0418s/iter; left time: 900.5722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0467785 Vali Loss: 0.0556423 Test Loss: 0.0590097\n",
      "Validation loss decreased (0.057326 --> 0.055642).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0453287\n",
      "\tspeed: 0.0748s/iter; left time: 1601.1447s\n",
      "\titers: 200, epoch: 5 | loss: 0.0429152\n",
      "\tspeed: 0.0419s/iter; left time: 892.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0452205 Vali Loss: 0.0545473 Test Loss: 0.0580783\n",
      "Validation loss decreased (0.055642 --> 0.054547).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0394759\n",
      "\tspeed: 0.0765s/iter; left time: 1620.3665s\n",
      "\titers: 200, epoch: 6 | loss: 0.0427372\n",
      "\tspeed: 0.0419s/iter; left time: 882.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0442165 Vali Loss: 0.0534045 Test Loss: 0.0573112\n",
      "Validation loss decreased (0.054547 --> 0.053404).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0455463\n",
      "\tspeed: 0.0749s/iter; left time: 1569.5681s\n",
      "\titers: 200, epoch: 7 | loss: 0.0445603\n",
      "\tspeed: 0.0419s/iter; left time: 874.4966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0433700 Vali Loss: 0.0530924 Test Loss: 0.0570183\n",
      "Validation loss decreased (0.053404 --> 0.053092).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0449817\n",
      "\tspeed: 0.0751s/iter; left time: 1556.6396s\n",
      "\titers: 200, epoch: 8 | loss: 0.0429298\n",
      "\tspeed: 0.0420s/iter; left time: 865.7288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0428334 Vali Loss: 0.0531420 Test Loss: 0.0565075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0423502\n",
      "\tspeed: 0.0743s/iter; left time: 1524.5959s\n",
      "\titers: 200, epoch: 9 | loss: 0.0445846\n",
      "\tspeed: 0.0418s/iter; left time: 853.8493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0424026 Vali Loss: 0.0525870 Test Loss: 0.0563246\n",
      "Validation loss decreased (0.053092 --> 0.052587).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0425135\n",
      "\tspeed: 0.0749s/iter; left time: 1518.9674s\n",
      "\titers: 200, epoch: 10 | loss: 0.0457547\n",
      "\tspeed: 0.0419s/iter; left time: 845.5109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0419955 Vali Loss: 0.0525711 Test Loss: 0.0565309\n",
      "Validation loss decreased (0.052587 --> 0.052571).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0431648\n",
      "\tspeed: 0.0745s/iter; left time: 1494.6285s\n",
      "\titers: 200, epoch: 11 | loss: 0.0424161\n",
      "\tspeed: 0.0419s/iter; left time: 835.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0417232 Vali Loss: 0.0522938 Test Loss: 0.0558724\n",
      "Validation loss decreased (0.052571 --> 0.052294).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0447426\n",
      "\tspeed: 0.0749s/iter; left time: 1486.5755s\n",
      "\titers: 200, epoch: 12 | loss: 0.0382844\n",
      "\tspeed: 0.0419s/iter; left time: 827.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0414626 Vali Loss: 0.0523507 Test Loss: 0.0559838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0380325\n",
      "\tspeed: 0.0741s/iter; left time: 1454.0632s\n",
      "\titers: 200, epoch: 13 | loss: 0.0404050\n",
      "\tspeed: 0.0419s/iter; left time: 817.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0412239 Vali Loss: 0.0520597 Test Loss: 0.0557181\n",
      "Validation loss decreased (0.052294 --> 0.052060).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0420314\n",
      "\tspeed: 0.0746s/iter; left time: 1446.5701s\n",
      "\titers: 200, epoch: 14 | loss: 0.0441814\n",
      "\tspeed: 0.0418s/iter; left time: 807.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0410656 Vali Loss: 0.0517921 Test Loss: 0.0556048\n",
      "Validation loss decreased (0.052060 --> 0.051792).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0390570\n",
      "\tspeed: 0.0755s/iter; left time: 1447.3233s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447538\n",
      "\tspeed: 0.0419s/iter; left time: 798.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0408988 Vali Loss: 0.0519798 Test Loss: 0.0555771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0387387\n",
      "\tspeed: 0.0742s/iter; left time: 1406.3297s\n",
      "\titers: 200, epoch: 16 | loss: 0.0386383\n",
      "\tspeed: 0.0419s/iter; left time: 789.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0407904 Vali Loss: 0.0519261 Test Loss: 0.0554437\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0408869\n",
      "\tspeed: 0.0740s/iter; left time: 1385.1167s\n",
      "\titers: 200, epoch: 17 | loss: 0.0388287\n",
      "\tspeed: 0.0418s/iter; left time: 778.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0407096 Vali Loss: 0.0518903 Test Loss: 0.0554077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0411886\n",
      "\tspeed: 0.0740s/iter; left time: 1368.3384s\n",
      "\titers: 200, epoch: 18 | loss: 0.0390267\n",
      "\tspeed: 0.0419s/iter; left time: 770.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0405676 Vali Loss: 0.0518208 Test Loss: 0.0553516\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0415021\n",
      "\tspeed: 0.0747s/iter; left time: 1364.7439s\n",
      "\titers: 200, epoch: 19 | loss: 0.0406355\n",
      "\tspeed: 0.0419s/iter; left time: 761.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0404403 Vali Loss: 0.0518093 Test Loss: 0.0553732\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0448347\n",
      "\tspeed: 0.0742s/iter; left time: 1339.4886s\n",
      "\titers: 200, epoch: 20 | loss: 0.0391173\n",
      "\tspeed: 0.0419s/iter; left time: 752.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0403546 Vali Loss: 0.0517789 Test Loss: 0.0553628\n",
      "Validation loss decreased (0.051792 --> 0.051779).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0398589\n",
      "\tspeed: 0.0749s/iter; left time: 1333.9295s\n",
      "\titers: 200, epoch: 21 | loss: 0.0381496\n",
      "\tspeed: 0.0418s/iter; left time: 741.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0402457 Vali Loss: 0.0518312 Test Loss: 0.0552614\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0385531\n",
      "\tspeed: 0.0744s/iter; left time: 1308.5965s\n",
      "\titers: 200, epoch: 22 | loss: 0.0400891\n",
      "\tspeed: 0.0419s/iter; left time: 732.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0401808 Vali Loss: 0.0517388 Test Loss: 0.0554081\n",
      "Validation loss decreased (0.051779 --> 0.051739).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0384819\n",
      "\tspeed: 0.0749s/iter; left time: 1300.4983s\n",
      "\titers: 200, epoch: 23 | loss: 0.0368943\n",
      "\tspeed: 0.0418s/iter; left time: 722.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0401281 Vali Loss: 0.0517458 Test Loss: 0.0554174\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0401000\n",
      "\tspeed: 0.0740s/iter; left time: 1268.9119s\n",
      "\titers: 200, epoch: 24 | loss: 0.0394788\n",
      "\tspeed: 0.0418s/iter; left time: 713.4735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0401284 Vali Loss: 0.0517721 Test Loss: 0.0554288\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0411244\n",
      "\tspeed: 0.0742s/iter; left time: 1255.8286s\n",
      "\titers: 200, epoch: 25 | loss: 0.0381236\n",
      "\tspeed: 0.0419s/iter; left time: 704.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0400445 Vali Loss: 0.0515828 Test Loss: 0.0552302\n",
      "Validation loss decreased (0.051739 --> 0.051583).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0426891\n",
      "\tspeed: 0.0745s/iter; left time: 1244.0759s\n",
      "\titers: 200, epoch: 26 | loss: 0.0411633\n",
      "\tspeed: 0.0420s/iter; left time: 696.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0399843 Vali Loss: 0.0516705 Test Loss: 0.0553208\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0387271\n",
      "\tspeed: 0.0741s/iter; left time: 1220.1777s\n",
      "\titers: 200, epoch: 27 | loss: 0.0394193\n",
      "\tspeed: 0.0418s/iter; left time: 685.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0399810 Vali Loss: 0.0517005 Test Loss: 0.0552868\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0415462\n",
      "\tspeed: 0.0742s/iter; left time: 1206.3162s\n",
      "\titers: 200, epoch: 28 | loss: 0.0391410\n",
      "\tspeed: 0.0418s/iter; left time: 675.3667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0399579 Vali Loss: 0.0515849 Test Loss: 0.0552142\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0436352\n",
      "\tspeed: 0.0745s/iter; left time: 1194.7335s\n",
      "\titers: 200, epoch: 29 | loss: 0.0375349\n",
      "\tspeed: 0.0419s/iter; left time: 667.0952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0398951 Vali Loss: 0.0516627 Test Loss: 0.0551619\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0356513\n",
      "\tspeed: 0.0740s/iter; left time: 1169.8539s\n",
      "\titers: 200, epoch: 30 | loss: 0.0385870\n",
      "\tspeed: 0.0419s/iter; left time: 657.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0398974 Vali Loss: 0.0516312 Test Loss: 0.0551637\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0412497\n",
      "\tspeed: 0.0741s/iter; left time: 1153.7925s\n",
      "\titers: 200, epoch: 31 | loss: 0.0410214\n",
      "\tspeed: 0.0419s/iter; left time: 647.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0398423 Vali Loss: 0.0515021 Test Loss: 0.0551850\n",
      "Validation loss decreased (0.051583 --> 0.051502).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0411650\n",
      "\tspeed: 0.0746s/iter; left time: 1145.7192s\n",
      "\titers: 200, epoch: 32 | loss: 0.0411897\n",
      "\tspeed: 0.0419s/iter; left time: 638.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0398447 Vali Loss: 0.0516524 Test Loss: 0.0552015\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0414264\n",
      "\tspeed: 0.0740s/iter; left time: 1120.0349s\n",
      "\titers: 200, epoch: 33 | loss: 0.0373195\n",
      "\tspeed: 0.0418s/iter; left time: 628.1793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0398136 Vali Loss: 0.0515943 Test Loss: 0.0551456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0420447\n",
      "\tspeed: 0.0739s/iter; left time: 1102.4725s\n",
      "\titers: 200, epoch: 34 | loss: 0.0418415\n",
      "\tspeed: 0.0419s/iter; left time: 620.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0397582 Vali Loss: 0.0515836 Test Loss: 0.0551158\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0439957\n",
      "\tspeed: 0.0738s/iter; left time: 1083.5330s\n",
      "\titers: 200, epoch: 35 | loss: 0.0377602\n",
      "\tspeed: 0.0418s/iter; left time: 609.9313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0398037 Vali Loss: 0.0516123 Test Loss: 0.0551900\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0440431\n",
      "\tspeed: 0.0744s/iter; left time: 1075.2332s\n",
      "\titers: 200, epoch: 36 | loss: 0.0373870\n",
      "\tspeed: 0.0419s/iter; left time: 601.3410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0397717 Vali Loss: 0.0515656 Test Loss: 0.0551841\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0430282\n",
      "\tspeed: 0.0740s/iter; left time: 1053.7770s\n",
      "\titers: 200, epoch: 37 | loss: 0.0413177\n",
      "\tspeed: 0.0418s/iter; left time: 590.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0397954 Vali Loss: 0.0515806 Test Loss: 0.0551719\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0357447\n",
      "\tspeed: 0.0741s/iter; left time: 1038.3779s\n",
      "\titers: 200, epoch: 38 | loss: 0.0371809\n",
      "\tspeed: 0.0419s/iter; left time: 582.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0397360 Vali Loss: 0.0515720 Test Loss: 0.0551558\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0388872\n",
      "\tspeed: 0.0741s/iter; left time: 1021.1464s\n",
      "\titers: 200, epoch: 39 | loss: 0.0369145\n",
      "\tspeed: 0.0419s/iter; left time: 573.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0397296 Vali Loss: 0.0516767 Test Loss: 0.0551596\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0407941\n",
      "\tspeed: 0.0740s/iter; left time: 1003.7769s\n",
      "\titers: 200, epoch: 40 | loss: 0.0428946\n",
      "\tspeed: 0.0419s/iter; left time: 564.1471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0397577 Vali Loss: 0.0515838 Test Loss: 0.0551644\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0428438\n",
      "\tspeed: 0.0740s/iter; left time: 986.6249s\n",
      "\titers: 200, epoch: 41 | loss: 0.0403244\n",
      "\tspeed: 0.0419s/iter; left time: 554.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0397225 Vali Loss: 0.0517354 Test Loss: 0.0551707\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010068370029330254, rmse:0.10034126788377762, mae:0.05518501251935959, rse:0.3871138393878937\n",
      "Intermediate time for FR and pred_len 24: 00h:15m:43.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1153915\n",
      "\tspeed: 0.0624s/iter; left time: 1391.7446s\n",
      "\titers: 200, epoch: 1 | loss: 0.1060928\n",
      "\tspeed: 0.0421s/iter; left time: 935.7581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.1190758 Vali Loss: 0.1222350 Test Loss: 0.1367866\n",
      "Validation loss decreased (inf --> 0.122235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0703590\n",
      "\tspeed: 0.0772s/iter; left time: 1704.1421s\n",
      "\titers: 200, epoch: 2 | loss: 0.0631227\n",
      "\tspeed: 0.0422s/iter; left time: 927.1204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0741752 Vali Loss: 0.0765218 Test Loss: 0.0841672\n",
      "Validation loss decreased (0.122235 --> 0.076522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638842\n",
      "\tspeed: 0.0775s/iter; left time: 1693.0687s\n",
      "\titers: 200, epoch: 3 | loss: 0.0638510\n",
      "\tspeed: 0.0422s/iter; left time: 918.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0637024 Vali Loss: 0.0740111 Test Loss: 0.0829004\n",
      "Validation loss decreased (0.076522 --> 0.074011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0599669\n",
      "\tspeed: 0.0774s/iter; left time: 1673.1504s\n",
      "\titers: 200, epoch: 4 | loss: 0.0602428\n",
      "\tspeed: 0.0422s/iter; left time: 907.7448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0613726 Vali Loss: 0.0729702 Test Loss: 0.0828571\n",
      "Validation loss decreased (0.074011 --> 0.072970).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0608108\n",
      "\tspeed: 0.0765s/iter; left time: 1637.6600s\n",
      "\titers: 200, epoch: 5 | loss: 0.0596332\n",
      "\tspeed: 0.0421s/iter; left time: 897.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0599371 Vali Loss: 0.0722665 Test Loss: 0.0831574\n",
      "Validation loss decreased (0.072970 --> 0.072266).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0591320\n",
      "\tspeed: 0.0770s/iter; left time: 1630.0226s\n",
      "\titers: 200, epoch: 6 | loss: 0.0609036\n",
      "\tspeed: 0.0422s/iter; left time: 889.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0590100 Vali Loss: 0.0717653 Test Loss: 0.0822677\n",
      "Validation loss decreased (0.072266 --> 0.071765).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0570013\n",
      "\tspeed: 0.0778s/iter; left time: 1630.2538s\n",
      "\titers: 200, epoch: 7 | loss: 0.0558092\n",
      "\tspeed: 0.0423s/iter; left time: 881.5445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0583290 Vali Loss: 0.0718643 Test Loss: 0.0817473\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0584184\n",
      "\tspeed: 0.0772s/iter; left time: 1601.3778s\n",
      "\titers: 200, epoch: 8 | loss: 0.0561043\n",
      "\tspeed: 0.0422s/iter; left time: 870.5535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 224 | Train Loss: 0.0577498 Vali Loss: 0.0716929 Test Loss: 0.0819808\n",
      "Validation loss decreased (0.071765 --> 0.071693).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547079\n",
      "\tspeed: 0.0776s/iter; left time: 1590.5815s\n",
      "\titers: 200, epoch: 9 | loss: 0.0589732\n",
      "\tspeed: 0.0422s/iter; left time: 861.0019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0572604 Vali Loss: 0.0716615 Test Loss: 0.0817608\n",
      "Validation loss decreased (0.071693 --> 0.071662).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0549507\n",
      "\tspeed: 0.0771s/iter; left time: 1563.3897s\n",
      "\titers: 200, epoch: 10 | loss: 0.0595628\n",
      "\tspeed: 0.0421s/iter; left time: 850.5176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0569233 Vali Loss: 0.0713719 Test Loss: 0.0818009\n",
      "Validation loss decreased (0.071662 --> 0.071372).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0583551\n",
      "\tspeed: 0.0763s/iter; left time: 1531.2724s\n",
      "\titers: 200, epoch: 11 | loss: 0.0565592\n",
      "\tspeed: 0.0422s/iter; left time: 842.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0565333 Vali Loss: 0.0717262 Test Loss: 0.0822539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0552871\n",
      "\tspeed: 0.0763s/iter; left time: 1513.4371s\n",
      "\titers: 200, epoch: 12 | loss: 0.0534210\n",
      "\tspeed: 0.0422s/iter; left time: 833.0360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0562415 Vali Loss: 0.0716062 Test Loss: 0.0821118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0572377\n",
      "\tspeed: 0.0761s/iter; left time: 1491.5899s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547919\n",
      "\tspeed: 0.0422s/iter; left time: 822.9085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0560026 Vali Loss: 0.0715299 Test Loss: 0.0820022\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0594103\n",
      "\tspeed: 0.0772s/iter; left time: 1496.0266s\n",
      "\titers: 200, epoch: 14 | loss: 0.0563948\n",
      "\tspeed: 0.0424s/iter; left time: 818.5080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 224 | Train Loss: 0.0557053 Vali Loss: 0.0715743 Test Loss: 0.0825353\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0562952\n",
      "\tspeed: 0.0766s/iter; left time: 1468.4562s\n",
      "\titers: 200, epoch: 15 | loss: 0.0543950\n",
      "\tspeed: 0.0422s/iter; left time: 805.1294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0554924 Vali Loss: 0.0715357 Test Loss: 0.0822632\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0568288\n",
      "\tspeed: 0.0767s/iter; left time: 1453.3149s\n",
      "\titers: 200, epoch: 16 | loss: 0.0553723\n",
      "\tspeed: 0.0422s/iter; left time: 795.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0552482 Vali Loss: 0.0717300 Test Loss: 0.0825441\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0568050\n",
      "\tspeed: 0.0768s/iter; left time: 1437.3798s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549970\n",
      "\tspeed: 0.0422s/iter; left time: 786.3956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0550776 Vali Loss: 0.0714888 Test Loss: 0.0823092\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0559789\n",
      "\tspeed: 0.0767s/iter; left time: 1419.1503s\n",
      "\titers: 200, epoch: 18 | loss: 0.0549825\n",
      "\tspeed: 0.0421s/iter; left time: 774.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0549379 Vali Loss: 0.0716566 Test Loss: 0.0824809\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0559283\n",
      "\tspeed: 0.0768s/iter; left time: 1403.8936s\n",
      "\titers: 200, epoch: 19 | loss: 0.0576035\n",
      "\tspeed: 0.0421s/iter; left time: 765.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 224 | Train Loss: 0.0547359 Vali Loss: 0.0717991 Test Loss: 0.0826052\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0550359\n",
      "\tspeed: 0.0766s/iter; left time: 1381.6697s\n",
      "\titers: 200, epoch: 20 | loss: 0.0536892\n",
      "\tspeed: 0.0422s/iter; left time: 756.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0545703 Vali Loss: 0.0716234 Test Loss: 0.0824642\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019618265330791473, rmse:0.14006522297859192, mae:0.08180088549852371, rse:0.5418094992637634\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1183382\n",
      "\tspeed: 0.0437s/iter; left time: 974.3214s\n",
      "\titers: 200, epoch: 1 | loss: 0.1067132\n",
      "\tspeed: 0.0421s/iter; left time: 935.1136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.1185646 Vali Loss: 0.1221652 Test Loss: 0.1369242\n",
      "Validation loss decreased (inf --> 0.122165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0710205\n",
      "\tspeed: 0.0773s/iter; left time: 1707.0127s\n",
      "\titers: 200, epoch: 2 | loss: 0.0608164\n",
      "\tspeed: 0.0421s/iter; left time: 926.3223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0749036 Vali Loss: 0.0765365 Test Loss: 0.0847675\n",
      "Validation loss decreased (0.122165 --> 0.076536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0649917\n",
      "\tspeed: 0.0764s/iter; left time: 1668.8608s\n",
      "\titers: 200, epoch: 3 | loss: 0.0605547\n",
      "\tspeed: 0.0421s/iter; left time: 916.4090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0638909 Vali Loss: 0.0741018 Test Loss: 0.0832592\n",
      "Validation loss decreased (0.076536 --> 0.074102).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0593064\n",
      "\tspeed: 0.0761s/iter; left time: 1647.0304s\n",
      "\titers: 200, epoch: 4 | loss: 0.0614190\n",
      "\tspeed: 0.0421s/iter; left time: 905.8797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0614330 Vali Loss: 0.0730869 Test Loss: 0.0835192\n",
      "Validation loss decreased (0.074102 --> 0.073087).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0564989\n",
      "\tspeed: 0.0767s/iter; left time: 1642.1587s\n",
      "\titers: 200, epoch: 5 | loss: 0.0585219\n",
      "\tspeed: 0.0421s/iter; left time: 897.7183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0599615 Vali Loss: 0.0721415 Test Loss: 0.0823667\n",
      "Validation loss decreased (0.073087 --> 0.072142).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0572291\n",
      "\tspeed: 0.0759s/iter; left time: 1608.0054s\n",
      "\titers: 200, epoch: 6 | loss: 0.0590202\n",
      "\tspeed: 0.0422s/iter; left time: 888.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0590873 Vali Loss: 0.0719854 Test Loss: 0.0822540\n",
      "Validation loss decreased (0.072142 --> 0.071985).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0584348\n",
      "\tspeed: 0.0762s/iter; left time: 1597.6538s\n",
      "\titers: 200, epoch: 7 | loss: 0.0593594\n",
      "\tspeed: 0.0422s/iter; left time: 879.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0583521 Vali Loss: 0.0719110 Test Loss: 0.0827368\n",
      "Validation loss decreased (0.071985 --> 0.071911).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0565943\n",
      "\tspeed: 0.0763s/iter; left time: 1581.1418s\n",
      "\titers: 200, epoch: 8 | loss: 0.0581434\n",
      "\tspeed: 0.0422s/iter; left time: 869.9349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0577961 Vali Loss: 0.0715724 Test Loss: 0.0823652\n",
      "Validation loss decreased (0.071911 --> 0.071572).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559165\n",
      "\tspeed: 0.0762s/iter; left time: 1562.1366s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555138\n",
      "\tspeed: 0.0421s/iter; left time: 860.1257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0573474 Vali Loss: 0.0714440 Test Loss: 0.0819069\n",
      "Validation loss decreased (0.071572 --> 0.071444).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0537653\n",
      "\tspeed: 0.0892s/iter; left time: 1808.9242s\n",
      "\titers: 200, epoch: 10 | loss: 0.0534346\n",
      "\tspeed: 0.0422s/iter; left time: 851.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0569286 Vali Loss: 0.0715755 Test Loss: 0.0818373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0572650\n",
      "\tspeed: 0.0752s/iter; left time: 1509.2995s\n",
      "\titers: 200, epoch: 11 | loss: 0.0564079\n",
      "\tspeed: 0.0422s/iter; left time: 842.0089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0565144 Vali Loss: 0.0715929 Test Loss: 0.0819250\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553930\n",
      "\tspeed: 0.0754s/iter; left time: 1495.0413s\n",
      "\titers: 200, epoch: 12 | loss: 0.0512815\n",
      "\tspeed: 0.0421s/iter; left time: 831.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0562026 Vali Loss: 0.0716908 Test Loss: 0.0820340\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0598023\n",
      "\tspeed: 0.0754s/iter; left time: 1477.9890s\n",
      "\titers: 200, epoch: 13 | loss: 0.0541688\n",
      "\tspeed: 0.0421s/iter; left time: 821.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0559420 Vali Loss: 0.0715412 Test Loss: 0.0819712\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0563550\n",
      "\tspeed: 0.0755s/iter; left time: 1464.3693s\n",
      "\titers: 200, epoch: 14 | loss: 0.0574557\n",
      "\tspeed: 0.0422s/iter; left time: 813.4812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0556303 Vali Loss: 0.0716937 Test Loss: 0.0818968\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0598165\n",
      "\tspeed: 0.0754s/iter; left time: 1445.4423s\n",
      "\titers: 200, epoch: 15 | loss: 0.0571043\n",
      "\tspeed: 0.0421s/iter; left time: 803.5626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0553934 Vali Loss: 0.0717617 Test Loss: 0.0820680\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0545634\n",
      "\tspeed: 0.0752s/iter; left time: 1424.8424s\n",
      "\titers: 200, epoch: 16 | loss: 0.0518719\n",
      "\tspeed: 0.0421s/iter; left time: 793.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0552036 Vali Loss: 0.0718749 Test Loss: 0.0818940\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0536293\n",
      "\tspeed: 0.0756s/iter; left time: 1414.3057s\n",
      "\titers: 200, epoch: 17 | loss: 0.0532682\n",
      "\tspeed: 0.0421s/iter; left time: 783.4398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0549504 Vali Loss: 0.0719338 Test Loss: 0.0821902\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0550838\n",
      "\tspeed: 0.0757s/iter; left time: 1400.5497s\n",
      "\titers: 200, epoch: 18 | loss: 0.0541445\n",
      "\tspeed: 0.0422s/iter; left time: 775.9720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0547627 Vali Loss: 0.0717970 Test Loss: 0.0820770\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0564983\n",
      "\tspeed: 0.0757s/iter; left time: 1382.5145s\n",
      "\titers: 200, epoch: 19 | loss: 0.0564426\n",
      "\tspeed: 0.0421s/iter; left time: 765.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0546047 Vali Loss: 0.0719225 Test Loss: 0.0821915\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019422350451350212, rmse:0.139364093542099, mae:0.08190689235925674, rse:0.5390973091125488\n",
      "Intermediate time for FR and pred_len 96: 00h:07m:54.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1155179\n",
      "\tspeed: 0.0637s/iter; left time: 1413.8900s\n",
      "\titers: 200, epoch: 1 | loss: 0.1100524\n",
      "\tspeed: 0.0425s/iter; left time: 940.3430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 223 | Train Loss: 0.1203775 Vali Loss: 0.1246447 Test Loss: 0.1390694\n",
      "Validation loss decreased (inf --> 0.124645).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0748355\n",
      "\tspeed: 0.0768s/iter; left time: 1688.8321s\n",
      "\titers: 200, epoch: 2 | loss: 0.0722877\n",
      "\tspeed: 0.0426s/iter; left time: 931.1336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0777110 Vali Loss: 0.0800677 Test Loss: 0.0888488\n",
      "Validation loss decreased (0.124645 --> 0.080068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0673887\n",
      "\tspeed: 0.0769s/iter; left time: 1673.5104s\n",
      "\titers: 200, epoch: 3 | loss: 0.0638294\n",
      "\tspeed: 0.0426s/iter; left time: 921.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0680442 Vali Loss: 0.0776311 Test Loss: 0.0878397\n",
      "Validation loss decreased (0.080068 --> 0.077631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0655597\n",
      "\tspeed: 0.0765s/iter; left time: 1648.0794s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643643\n",
      "\tspeed: 0.0426s/iter; left time: 912.3251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0657154 Vali Loss: 0.0768263 Test Loss: 0.0878044\n",
      "Validation loss decreased (0.077631 --> 0.076826).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0671170\n",
      "\tspeed: 0.0771s/iter; left time: 1642.3895s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653071\n",
      "\tspeed: 0.0426s/iter; left time: 903.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0642069 Vali Loss: 0.0759690 Test Loss: 0.0875316\n",
      "Validation loss decreased (0.076826 --> 0.075969).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0666012\n",
      "\tspeed: 0.0772s/iter; left time: 1627.9053s\n",
      "\titers: 200, epoch: 6 | loss: 0.0617591\n",
      "\tspeed: 0.0426s/iter; left time: 893.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0632363 Vali Loss: 0.0758135 Test Loss: 0.0876818\n",
      "Validation loss decreased (0.075969 --> 0.075813).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585363\n",
      "\tspeed: 0.0764s/iter; left time: 1593.3725s\n",
      "\titers: 200, epoch: 7 | loss: 0.0633577\n",
      "\tspeed: 0.0426s/iter; left time: 883.8353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0625940 Vali Loss: 0.0755322 Test Loss: 0.0875475\n",
      "Validation loss decreased (0.075813 --> 0.075532).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0626959\n",
      "\tspeed: 0.0771s/iter; left time: 1592.1634s\n",
      "\titers: 200, epoch: 8 | loss: 0.0624156\n",
      "\tspeed: 0.0425s/iter; left time: 873.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0619335 Vali Loss: 0.0756845 Test Loss: 0.0881885\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0658133\n",
      "\tspeed: 0.0755s/iter; left time: 1540.5036s\n",
      "\titers: 200, epoch: 9 | loss: 0.0612553\n",
      "\tspeed: 0.0426s/iter; left time: 865.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0614354 Vali Loss: 0.0754083 Test Loss: 0.0879239\n",
      "Validation loss decreased (0.075532 --> 0.075408).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0571346\n",
      "\tspeed: 0.0772s/iter; left time: 1558.3133s\n",
      "\titers: 200, epoch: 10 | loss: 0.0608960\n",
      "\tspeed: 0.0426s/iter; left time: 855.4101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0609741 Vali Loss: 0.0752998 Test Loss: 0.0884806\n",
      "Validation loss decreased (0.075408 --> 0.075300).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0601922\n",
      "\tspeed: 0.0769s/iter; left time: 1535.2761s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642126\n",
      "\tspeed: 0.0426s/iter; left time: 846.1209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0605561 Vali Loss: 0.0755705 Test Loss: 0.0886884\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0595557\n",
      "\tspeed: 0.0753s/iter; left time: 1486.7759s\n",
      "\titers: 200, epoch: 12 | loss: 0.0635985\n",
      "\tspeed: 0.0426s/iter; left time: 836.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0601814 Vali Loss: 0.0755608 Test Loss: 0.0883276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0604448\n",
      "\tspeed: 0.0757s/iter; left time: 1477.2736s\n",
      "\titers: 200, epoch: 13 | loss: 0.0586777\n",
      "\tspeed: 0.0426s/iter; left time: 826.6970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0598141 Vali Loss: 0.0753468 Test Loss: 0.0888019\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0574171\n",
      "\tspeed: 0.0758s/iter; left time: 1462.6341s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605751\n",
      "\tspeed: 0.0426s/iter; left time: 817.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0595079 Vali Loss: 0.0756135 Test Loss: 0.0885193\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0583936\n",
      "\tspeed: 0.0757s/iter; left time: 1444.8969s\n",
      "\titers: 200, epoch: 15 | loss: 0.0582936\n",
      "\tspeed: 0.0426s/iter; left time: 807.6200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0591883 Vali Loss: 0.0754839 Test Loss: 0.0893167\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0576946\n",
      "\tspeed: 0.0756s/iter; left time: 1424.6166s\n",
      "\titers: 200, epoch: 16 | loss: 0.0599246\n",
      "\tspeed: 0.0426s/iter; left time: 798.9218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0589706 Vali Loss: 0.0754589 Test Loss: 0.0887578\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0570811\n",
      "\tspeed: 0.0755s/iter; left time: 1407.5508s\n",
      "\titers: 200, epoch: 17 | loss: 0.0559282\n",
      "\tspeed: 0.0426s/iter; left time: 788.9323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0587052 Vali Loss: 0.0757231 Test Loss: 0.0894269\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0592673\n",
      "\tspeed: 0.0761s/iter; left time: 1401.6157s\n",
      "\titers: 200, epoch: 18 | loss: 0.0587642\n",
      "\tspeed: 0.0426s/iter; left time: 779.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0584797 Vali Loss: 0.0757971 Test Loss: 0.0895223\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0581048\n",
      "\tspeed: 0.0771s/iter; left time: 1402.8565s\n",
      "\titers: 200, epoch: 19 | loss: 0.0556847\n",
      "\tspeed: 0.0430s/iter; left time: 776.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 223 | Train Loss: 0.0583845 Vali Loss: 0.0757172 Test Loss: 0.0894682\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0584915\n",
      "\tspeed: 0.0764s/iter; left time: 1372.8196s\n",
      "\titers: 200, epoch: 20 | loss: 0.0591433\n",
      "\tspeed: 0.0425s/iter; left time: 759.4908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0581833 Vali Loss: 0.0757980 Test Loss: 0.0896036\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02110251970589161, rmse:0.1452670693397522, mae:0.08848056942224503, rse:0.5626330971717834\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1188243\n",
      "\tspeed: 0.0442s/iter; left time: 980.8067s\n",
      "\titers: 200, epoch: 1 | loss: 0.1097503\n",
      "\tspeed: 0.0425s/iter; left time: 939.6903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.1206074 Vali Loss: 0.1249007 Test Loss: 0.1393432\n",
      "Validation loss decreased (inf --> 0.124901).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0710360\n",
      "\tspeed: 0.0765s/iter; left time: 1680.9727s\n",
      "\titers: 200, epoch: 2 | loss: 0.0703140\n",
      "\tspeed: 0.0425s/iter; left time: 929.9508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0782399 Vali Loss: 0.0799150 Test Loss: 0.0890377\n",
      "Validation loss decreased (0.124901 --> 0.079915).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0686920\n",
      "\tspeed: 0.0771s/iter; left time: 1676.4317s\n",
      "\titers: 200, epoch: 3 | loss: 0.0669794\n",
      "\tspeed: 0.0426s/iter; left time: 921.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0680045 Vali Loss: 0.0777030 Test Loss: 0.0883915\n",
      "Validation loss decreased (0.079915 --> 0.077703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0687920\n",
      "\tspeed: 0.0768s/iter; left time: 1654.5862s\n",
      "\titers: 200, epoch: 4 | loss: 0.0625754\n",
      "\tspeed: 0.0425s/iter; left time: 911.3704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0655856 Vali Loss: 0.0768370 Test Loss: 0.0883045\n",
      "Validation loss decreased (0.077703 --> 0.076837).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0662790\n",
      "\tspeed: 0.0766s/iter; left time: 1632.5732s\n",
      "\titers: 200, epoch: 5 | loss: 0.0664349\n",
      "\tspeed: 0.0425s/iter; left time: 901.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0642683 Vali Loss: 0.0762139 Test Loss: 0.0878965\n",
      "Validation loss decreased (0.076837 --> 0.076214).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0642509\n",
      "\tspeed: 0.0764s/iter; left time: 1611.4528s\n",
      "\titers: 200, epoch: 6 | loss: 0.0635850\n",
      "\tspeed: 0.0426s/iter; left time: 893.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0633435 Vali Loss: 0.0759457 Test Loss: 0.0877568\n",
      "Validation loss decreased (0.076214 --> 0.075946).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607359\n",
      "\tspeed: 0.0762s/iter; left time: 1589.6072s\n",
      "\titers: 200, epoch: 7 | loss: 0.0600543\n",
      "\tspeed: 0.0425s/iter; left time: 883.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0624938 Vali Loss: 0.0757794 Test Loss: 0.0877522\n",
      "Validation loss decreased (0.075946 --> 0.075779).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640830\n",
      "\tspeed: 0.0764s/iter; left time: 1577.2283s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560839\n",
      "\tspeed: 0.0425s/iter; left time: 873.3305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0618970 Vali Loss: 0.0753602 Test Loss: 0.0876144\n",
      "Validation loss decreased (0.075779 --> 0.075360).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0622873\n",
      "\tspeed: 0.0765s/iter; left time: 1561.7475s\n",
      "\titers: 200, epoch: 9 | loss: 0.0610187\n",
      "\tspeed: 0.0425s/iter; left time: 863.4189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0613768 Vali Loss: 0.0755588 Test Loss: 0.0880555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0610971\n",
      "\tspeed: 0.0764s/iter; left time: 1543.7533s\n",
      "\titers: 200, epoch: 10 | loss: 0.0619647\n",
      "\tspeed: 0.0425s/iter; left time: 854.0016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0608380 Vali Loss: 0.0755213 Test Loss: 0.0878433\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0598250\n",
      "\tspeed: 0.0752s/iter; left time: 1502.5919s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568953\n",
      "\tspeed: 0.0424s/iter; left time: 843.3894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0604825 Vali Loss: 0.0753327 Test Loss: 0.0883517\n",
      "Validation loss decreased (0.075360 --> 0.075333).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0650479\n",
      "\tspeed: 0.0766s/iter; left time: 1511.9582s\n",
      "\titers: 200, epoch: 12 | loss: 0.0589150\n",
      "\tspeed: 0.0425s/iter; left time: 835.9401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0600851 Vali Loss: 0.0752878 Test Loss: 0.0881361\n",
      "Validation loss decreased (0.075333 --> 0.075288).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0590905\n",
      "\tspeed: 0.0767s/iter; left time: 1496.7399s\n",
      "\titers: 200, epoch: 13 | loss: 0.0612453\n",
      "\tspeed: 0.0426s/iter; left time: 827.3764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0597502 Vali Loss: 0.0754289 Test Loss: 0.0883999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0635281\n",
      "\tspeed: 0.0756s/iter; left time: 1459.6066s\n",
      "\titers: 200, epoch: 14 | loss: 0.0579555\n",
      "\tspeed: 0.0425s/iter; left time: 816.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0594261 Vali Loss: 0.0753699 Test Loss: 0.0886773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597168\n",
      "\tspeed: 0.0755s/iter; left time: 1440.9881s\n",
      "\titers: 200, epoch: 15 | loss: 0.0604776\n",
      "\tspeed: 0.0426s/iter; left time: 807.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0591478 Vali Loss: 0.0751815 Test Loss: 0.0885951\n",
      "Validation loss decreased (0.075288 --> 0.075181).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0589496\n",
      "\tspeed: 0.0765s/iter; left time: 1442.7705s\n",
      "\titers: 200, epoch: 16 | loss: 0.0610695\n",
      "\tspeed: 0.0425s/iter; left time: 797.2114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0589543 Vali Loss: 0.0751560 Test Loss: 0.0883089\n",
      "Validation loss decreased (0.075181 --> 0.075156).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0550328\n",
      "\tspeed: 0.0768s/iter; left time: 1431.0088s\n",
      "\titers: 200, epoch: 17 | loss: 0.0588443\n",
      "\tspeed: 0.0425s/iter; left time: 788.2971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0587267 Vali Loss: 0.0753057 Test Loss: 0.0887895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0589852\n",
      "\tspeed: 0.0756s/iter; left time: 1392.1435s\n",
      "\titers: 200, epoch: 18 | loss: 0.0540140\n",
      "\tspeed: 0.0424s/iter; left time: 777.2582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0585811 Vali Loss: 0.0752828 Test Loss: 0.0889161\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0613710\n",
      "\tspeed: 0.0759s/iter; left time: 1380.8301s\n",
      "\titers: 200, epoch: 19 | loss: 0.0610498\n",
      "\tspeed: 0.0425s/iter; left time: 768.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0583974 Vali Loss: 0.0751852 Test Loss: 0.0891550\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0590157\n",
      "\tspeed: 0.0758s/iter; left time: 1362.3051s\n",
      "\titers: 200, epoch: 20 | loss: 0.0577403\n",
      "\tspeed: 0.0426s/iter; left time: 760.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0581863 Vali Loss: 0.0754698 Test Loss: 0.0890949\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0588164\n",
      "\tspeed: 0.0754s/iter; left time: 1338.3577s\n",
      "\titers: 200, epoch: 21 | loss: 0.0568125\n",
      "\tspeed: 0.0426s/iter; left time: 750.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0580332 Vali Loss: 0.0751449 Test Loss: 0.0890774\n",
      "Validation loss decreased (0.075156 --> 0.075145).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0591515\n",
      "\tspeed: 0.0766s/iter; left time: 1341.7912s\n",
      "\titers: 200, epoch: 22 | loss: 0.0634039\n",
      "\tspeed: 0.0426s/iter; left time: 741.5917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0579535 Vali Loss: 0.0754300 Test Loss: 0.0893191\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0592452\n",
      "\tspeed: 0.0773s/iter; left time: 1336.1128s\n",
      "\titers: 200, epoch: 23 | loss: 0.0575206\n",
      "\tspeed: 0.0424s/iter; left time: 729.6740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0578123 Vali Loss: 0.0751504 Test Loss: 0.0893139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0615129\n",
      "\tspeed: 0.0764s/iter; left time: 1303.9488s\n",
      "\titers: 200, epoch: 24 | loss: 0.0616597\n",
      "\tspeed: 0.0425s/iter; left time: 721.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0577369 Vali Loss: 0.0753552 Test Loss: 0.0894956\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0577549\n",
      "\tspeed: 0.0755s/iter; left time: 1271.8893s\n",
      "\titers: 200, epoch: 25 | loss: 0.0567556\n",
      "\tspeed: 0.0425s/iter; left time: 712.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0577064 Vali Loss: 0.0753523 Test Loss: 0.0895203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0556293\n",
      "\tspeed: 0.0756s/iter; left time: 1256.2181s\n",
      "\titers: 200, epoch: 26 | loss: 0.0592692\n",
      "\tspeed: 0.0425s/iter; left time: 702.9587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0575957 Vali Loss: 0.0752099 Test Loss: 0.0895419\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0605084\n",
      "\tspeed: 0.0758s/iter; left time: 1243.0994s\n",
      "\titers: 200, epoch: 27 | loss: 0.0537401\n",
      "\tspeed: 0.0426s/iter; left time: 693.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0574944 Vali Loss: 0.0752354 Test Loss: 0.0897313\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0553524\n",
      "\tspeed: 0.0754s/iter; left time: 1219.6317s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644381\n",
      "\tspeed: 0.0425s/iter; left time: 683.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0574452 Vali Loss: 0.0751127 Test Loss: 0.0895886\n",
      "Validation loss decreased (0.075145 --> 0.075113).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0528446\n",
      "\tspeed: 0.0765s/iter; left time: 1220.0697s\n",
      "\titers: 200, epoch: 29 | loss: 0.0540518\n",
      "\tspeed: 0.0425s/iter; left time: 674.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0573492 Vali Loss: 0.0753453 Test Loss: 0.0897618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0544832\n",
      "\tspeed: 0.0762s/iter; left time: 1198.7870s\n",
      "\titers: 200, epoch: 30 | loss: 0.0593685\n",
      "\tspeed: 0.0425s/iter; left time: 664.9390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0573188 Vali Loss: 0.0752593 Test Loss: 0.0897383\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0577189\n",
      "\tspeed: 0.0758s/iter; left time: 1176.2468s\n",
      "\titers: 200, epoch: 31 | loss: 0.0564524\n",
      "\tspeed: 0.0425s/iter; left time: 654.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0572871 Vali Loss: 0.0752722 Test Loss: 0.0897646\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0579591\n",
      "\tspeed: 0.0754s/iter; left time: 1152.6390s\n",
      "\titers: 200, epoch: 32 | loss: 0.0566821\n",
      "\tspeed: 0.0425s/iter; left time: 646.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0572057 Vali Loss: 0.0752317 Test Loss: 0.0898037\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0567452\n",
      "\tspeed: 0.0757s/iter; left time: 1140.8596s\n",
      "\titers: 200, epoch: 33 | loss: 0.0603444\n",
      "\tspeed: 0.0425s/iter; left time: 636.3376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0571794 Vali Loss: 0.0752111 Test Loss: 0.0897663\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0596642\n",
      "\tspeed: 0.0764s/iter; left time: 1133.3197s\n",
      "\titers: 200, epoch: 34 | loss: 0.0565170\n",
      "\tspeed: 0.0425s/iter; left time: 626.2768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0571641 Vali Loss: 0.0751075 Test Loss: 0.0896395\n",
      "Validation loss decreased (0.075113 --> 0.075107).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0565159\n",
      "\tspeed: 0.0762s/iter; left time: 1114.6455s\n",
      "\titers: 200, epoch: 35 | loss: 0.0543115\n",
      "\tspeed: 0.0424s/iter; left time: 616.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0571129 Vali Loss: 0.0751775 Test Loss: 0.0898111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0575157\n",
      "\tspeed: 0.0756s/iter; left time: 1087.8771s\n",
      "\titers: 200, epoch: 36 | loss: 0.0590963\n",
      "\tspeed: 0.0424s/iter; left time: 606.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0570837 Vali Loss: 0.0752165 Test Loss: 0.0898423\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0554018\n",
      "\tspeed: 0.0762s/iter; left time: 1079.6209s\n",
      "\titers: 200, epoch: 37 | loss: 0.0596231\n",
      "\tspeed: 0.0426s/iter; left time: 599.0353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0571097 Vali Loss: 0.0752624 Test Loss: 0.0898242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0621724\n",
      "\tspeed: 0.0756s/iter; left time: 1055.0102s\n",
      "\titers: 200, epoch: 38 | loss: 0.0594966\n",
      "\tspeed: 0.0425s/iter; left time: 589.2088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0570916 Vali Loss: 0.0752899 Test Loss: 0.0897771\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0557170\n",
      "\tspeed: 0.0754s/iter; left time: 1035.0082s\n",
      "\titers: 200, epoch: 39 | loss: 0.0557038\n",
      "\tspeed: 0.0425s/iter; left time: 579.5831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0571168 Vali Loss: 0.0751440 Test Loss: 0.0898458\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0548218\n",
      "\tspeed: 0.0757s/iter; left time: 1022.1383s\n",
      "\titers: 200, epoch: 40 | loss: 0.0535119\n",
      "\tspeed: 0.0425s/iter; left time: 569.0838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0570778 Vali Loss: 0.0753414 Test Loss: 0.0898209\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0595047\n",
      "\tspeed: 0.0753s/iter; left time: 1000.4601s\n",
      "\titers: 200, epoch: 41 | loss: 0.0574232\n",
      "\tspeed: 0.0425s/iter; left time: 560.1403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0569935 Vali Loss: 0.0752454 Test Loss: 0.0898885\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0572772\n",
      "\tspeed: 0.0754s/iter; left time: 984.8854s\n",
      "\titers: 200, epoch: 42 | loss: 0.0556398\n",
      "\tspeed: 0.0425s/iter; left time: 551.1102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0570608 Vali Loss: 0.0753064 Test Loss: 0.0898839\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0548267\n",
      "\tspeed: 0.0755s/iter; left time: 968.4376s\n",
      "\titers: 200, epoch: 43 | loss: 0.0530517\n",
      "\tspeed: 0.0426s/iter; left time: 541.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0569894 Vali Loss: 0.0752069 Test Loss: 0.0898459\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0569659\n",
      "\tspeed: 0.0756s/iter; left time: 953.2257s\n",
      "\titers: 200, epoch: 44 | loss: 0.0594817\n",
      "\tspeed: 0.0425s/iter; left time: 531.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0569357 Vali Loss: 0.0752656 Test Loss: 0.0899255\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022022612392902374, rmse:0.1484001725912094, mae:0.08963943272829056, rse:0.5747678875923157\n",
      "Intermediate time for FR and pred_len 168: 00h:12m:50.76s\n",
      "Intermediate time for FR: 00h:36m:29.00s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1668762\n",
      "\tspeed: 0.0632s/iter; left time: 1410.1924s\n",
      "\titers: 200, epoch: 1 | loss: 0.1487154\n",
      "\tspeed: 0.0419s/iter; left time: 929.4824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.84s\n",
      "Steps: 224 | Train Loss: 0.1647057 Vali Loss: 0.1381319 Test Loss: 0.1453384\n",
      "Validation loss decreased (inf --> 0.138132).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0744973\n",
      "\tspeed: 0.0743s/iter; left time: 1640.0870s\n",
      "\titers: 200, epoch: 2 | loss: 0.0702725\n",
      "\tspeed: 0.0419s/iter; left time: 920.5090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0845355 Vali Loss: 0.0634649 Test Loss: 0.0669909\n",
      "Validation loss decreased (0.138132 --> 0.063465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0651665\n",
      "\tspeed: 0.0744s/iter; left time: 1626.7381s\n",
      "\titers: 200, epoch: 3 | loss: 0.0628549\n",
      "\tspeed: 0.0419s/iter; left time: 911.2587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0646237 Vali Loss: 0.0603763 Test Loss: 0.0639257\n",
      "Validation loss decreased (0.063465 --> 0.060376).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0586132\n",
      "\tspeed: 0.0749s/iter; left time: 1620.0159s\n",
      "\titers: 200, epoch: 4 | loss: 0.0582620\n",
      "\tspeed: 0.0420s/iter; left time: 903.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0615983 Vali Loss: 0.0585471 Test Loss: 0.0621628\n",
      "Validation loss decreased (0.060376 --> 0.058547).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0539563\n",
      "\tspeed: 0.0746s/iter; left time: 1597.0395s\n",
      "\titers: 200, epoch: 5 | loss: 0.0590897\n",
      "\tspeed: 0.0419s/iter; left time: 891.8719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0596819 Vali Loss: 0.0576238 Test Loss: 0.0609692\n",
      "Validation loss decreased (0.058547 --> 0.057624).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0563761\n",
      "\tspeed: 0.0749s/iter; left time: 1586.8317s\n",
      "\titers: 200, epoch: 6 | loss: 0.0547008\n",
      "\tspeed: 0.0418s/iter; left time: 881.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0583187 Vali Loss: 0.0567941 Test Loss: 0.0601914\n",
      "Validation loss decreased (0.057624 --> 0.056794).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0598481\n",
      "\tspeed: 0.0750s/iter; left time: 1572.1981s\n",
      "\titers: 200, epoch: 7 | loss: 0.0572359\n",
      "\tspeed: 0.0419s/iter; left time: 873.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0573916 Vali Loss: 0.0562816 Test Loss: 0.0596388\n",
      "Validation loss decreased (0.056794 --> 0.056282).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0574251\n",
      "\tspeed: 0.0748s/iter; left time: 1551.1427s\n",
      "\titers: 200, epoch: 8 | loss: 0.0573186\n",
      "\tspeed: 0.0419s/iter; left time: 863.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0567434 Vali Loss: 0.0557669 Test Loss: 0.0591180\n",
      "Validation loss decreased (0.056282 --> 0.055767).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559022\n",
      "\tspeed: 0.0743s/iter; left time: 1524.8342s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584287\n",
      "\tspeed: 0.0419s/iter; left time: 854.7080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0562328 Vali Loss: 0.0554319 Test Loss: 0.0587576\n",
      "Validation loss decreased (0.055767 --> 0.055432).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546298\n",
      "\tspeed: 0.0744s/iter; left time: 1509.0385s\n",
      "\titers: 200, epoch: 10 | loss: 0.0570061\n",
      "\tspeed: 0.0419s/iter; left time: 845.1574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0557634 Vali Loss: 0.0553139 Test Loss: 0.0584507\n",
      "Validation loss decreased (0.055432 --> 0.055314).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569785\n",
      "\tspeed: 0.0745s/iter; left time: 1495.5312s\n",
      "\titers: 200, epoch: 11 | loss: 0.0548771\n",
      "\tspeed: 0.0418s/iter; left time: 834.8738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0553908 Vali Loss: 0.0551920 Test Loss: 0.0583368\n",
      "Validation loss decreased (0.055314 --> 0.055192).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0560274\n",
      "\tspeed: 0.0755s/iter; left time: 1497.3163s\n",
      "\titers: 200, epoch: 12 | loss: 0.0540077\n",
      "\tspeed: 0.0419s/iter; left time: 826.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0550622 Vali Loss: 0.0551127 Test Loss: 0.0582354\n",
      "Validation loss decreased (0.055192 --> 0.055113).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0538228\n",
      "\tspeed: 0.0747s/iter; left time: 1464.8836s\n",
      "\titers: 200, epoch: 13 | loss: 0.0569437\n",
      "\tspeed: 0.0419s/iter; left time: 817.2700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0548389 Vali Loss: 0.0549542 Test Loss: 0.0579587\n",
      "Validation loss decreased (0.055113 --> 0.054954).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0516178\n",
      "\tspeed: 0.0745s/iter; left time: 1444.1845s\n",
      "\titers: 200, epoch: 14 | loss: 0.0514003\n",
      "\tspeed: 0.0419s/iter; left time: 807.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0545595 Vali Loss: 0.0548756 Test Loss: 0.0579918\n",
      "Validation loss decreased (0.054954 --> 0.054876).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533713\n",
      "\tspeed: 0.0750s/iter; left time: 1436.6809s\n",
      "\titers: 200, epoch: 15 | loss: 0.0543369\n",
      "\tspeed: 0.0418s/iter; left time: 797.7377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0544265 Vali Loss: 0.0548448 Test Loss: 0.0579394\n",
      "Validation loss decreased (0.054876 --> 0.054845).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0529609\n",
      "\tspeed: 0.0745s/iter; left time: 1410.7601s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552985\n",
      "\tspeed: 0.0419s/iter; left time: 788.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0542592 Vali Loss: 0.0548368 Test Loss: 0.0579324\n",
      "Validation loss decreased (0.054845 --> 0.054837).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0501005\n",
      "\tspeed: 0.0750s/iter; left time: 1404.2534s\n",
      "\titers: 200, epoch: 17 | loss: 0.0501565\n",
      "\tspeed: 0.0419s/iter; left time: 779.5288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0540546 Vali Loss: 0.0547614 Test Loss: 0.0578513\n",
      "Validation loss decreased (0.054837 --> 0.054761).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0539889\n",
      "\tspeed: 0.0746s/iter; left time: 1379.7234s\n",
      "\titers: 200, epoch: 18 | loss: 0.0508451\n",
      "\tspeed: 0.0419s/iter; left time: 770.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0539890 Vali Loss: 0.0546531 Test Loss: 0.0577155\n",
      "Validation loss decreased (0.054761 --> 0.054653).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0549342\n",
      "\tspeed: 0.0755s/iter; left time: 1378.6877s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539790\n",
      "\tspeed: 0.0419s/iter; left time: 760.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0539062 Vali Loss: 0.0547521 Test Loss: 0.0577877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0521993\n",
      "\tspeed: 0.0742s/iter; left time: 1338.0701s\n",
      "\titers: 200, epoch: 20 | loss: 0.0564071\n",
      "\tspeed: 0.0418s/iter; left time: 750.8693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0538328 Vali Loss: 0.0545932 Test Loss: 0.0576081\n",
      "Validation loss decreased (0.054653 --> 0.054593).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0518346\n",
      "\tspeed: 0.0741s/iter; left time: 1320.5455s\n",
      "\titers: 200, epoch: 21 | loss: 0.0492195\n",
      "\tspeed: 0.0419s/iter; left time: 741.7154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0536230 Vali Loss: 0.0545515 Test Loss: 0.0576098\n",
      "Validation loss decreased (0.054593 --> 0.054552).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0529903\n",
      "\tspeed: 0.0752s/iter; left time: 1323.5637s\n",
      "\titers: 200, epoch: 22 | loss: 0.0542470\n",
      "\tspeed: 0.0419s/iter; left time: 732.3690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0536617 Vali Loss: 0.0544110 Test Loss: 0.0575890\n",
      "Validation loss decreased (0.054552 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0522088\n",
      "\tspeed: 0.0746s/iter; left time: 1295.2877s\n",
      "\titers: 200, epoch: 23 | loss: 0.0597315\n",
      "\tspeed: 0.0419s/iter; left time: 723.3989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0535213 Vali Loss: 0.0544596 Test Loss: 0.0575021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0541264\n",
      "\tspeed: 0.0743s/iter; left time: 1273.4573s\n",
      "\titers: 200, epoch: 24 | loss: 0.0508696\n",
      "\tspeed: 0.0419s/iter; left time: 713.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0534724 Vali Loss: 0.0544801 Test Loss: 0.0575809\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0501939\n",
      "\tspeed: 0.0744s/iter; left time: 1258.4504s\n",
      "\titers: 200, epoch: 25 | loss: 0.0537891\n",
      "\tspeed: 0.0419s/iter; left time: 704.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0534406 Vali Loss: 0.0544176 Test Loss: 0.0574616\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0505069\n",
      "\tspeed: 0.0743s/iter; left time: 1240.5247s\n",
      "\titers: 200, epoch: 26 | loss: 0.0531720\n",
      "\tspeed: 0.0418s/iter; left time: 694.4466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0533208 Vali Loss: 0.0544965 Test Loss: 0.0575467\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0493177\n",
      "\tspeed: 0.0745s/iter; left time: 1228.0542s\n",
      "\titers: 200, epoch: 27 | loss: 0.0498824\n",
      "\tspeed: 0.0418s/iter; left time: 685.0864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0533288 Vali Loss: 0.0544455 Test Loss: 0.0574507\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0525627\n",
      "\tspeed: 0.0736s/iter; left time: 1196.7454s\n",
      "\titers: 200, epoch: 28 | loss: 0.0504644\n",
      "\tspeed: 0.0418s/iter; left time: 675.7472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0532673 Vali Loss: 0.0544091 Test Loss: 0.0574716\n",
      "Validation loss decreased (0.054411 --> 0.054409).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0531574\n",
      "\tspeed: 0.0747s/iter; left time: 1196.7584s\n",
      "\titers: 200, epoch: 29 | loss: 0.0548535\n",
      "\tspeed: 0.0418s/iter; left time: 665.3913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0532243 Vali Loss: 0.0543962 Test Loss: 0.0574245\n",
      "Validation loss decreased (0.054409 --> 0.054396).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0528839\n",
      "\tspeed: 0.0749s/iter; left time: 1183.9542s\n",
      "\titers: 200, epoch: 30 | loss: 0.0549718\n",
      "\tspeed: 0.0419s/iter; left time: 657.6614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0532229 Vali Loss: 0.0543955 Test Loss: 0.0574266\n",
      "Validation loss decreased (0.054396 --> 0.054395).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0496521\n",
      "\tspeed: 0.0744s/iter; left time: 1159.5301s\n",
      "\titers: 200, epoch: 31 | loss: 0.0537042\n",
      "\tspeed: 0.0418s/iter; left time: 647.6665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0531766 Vali Loss: 0.0543635 Test Loss: 0.0573991\n",
      "Validation loss decreased (0.054395 --> 0.054363).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0555401\n",
      "\tspeed: 0.0743s/iter; left time: 1140.3479s\n",
      "\titers: 200, epoch: 32 | loss: 0.0543907\n",
      "\tspeed: 0.0418s/iter; left time: 638.1366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0531708 Vali Loss: 0.0543848 Test Loss: 0.0573410\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0553831\n",
      "\tspeed: 0.0738s/iter; left time: 1117.4445s\n",
      "\titers: 200, epoch: 33 | loss: 0.0529029\n",
      "\tspeed: 0.0419s/iter; left time: 629.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0531169 Vali Loss: 0.0544931 Test Loss: 0.0574164\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0566949\n",
      "\tspeed: 0.0743s/iter; left time: 1107.9614s\n",
      "\titers: 200, epoch: 34 | loss: 0.0510905\n",
      "\tspeed: 0.0418s/iter; left time: 619.4739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0530960 Vali Loss: 0.0544281 Test Loss: 0.0574047\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0519415\n",
      "\tspeed: 0.0739s/iter; left time: 1085.4541s\n",
      "\titers: 200, epoch: 35 | loss: 0.0507861\n",
      "\tspeed: 0.0418s/iter; left time: 609.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0531171 Vali Loss: 0.0543847 Test Loss: 0.0573662\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0498729\n",
      "\tspeed: 0.0737s/iter; left time: 1065.9495s\n",
      "\titers: 200, epoch: 36 | loss: 0.0518879\n",
      "\tspeed: 0.0418s/iter; left time: 600.9679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0530941 Vali Loss: 0.0544304 Test Loss: 0.0573629\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0537743\n",
      "\tspeed: 0.0737s/iter; left time: 1049.4746s\n",
      "\titers: 200, epoch: 37 | loss: 0.0551615\n",
      "\tspeed: 0.0418s/iter; left time: 591.5337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0530242 Vali Loss: 0.0544074 Test Loss: 0.0573354\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0526531\n",
      "\tspeed: 0.0735s/iter; left time: 1030.5877s\n",
      "\titers: 200, epoch: 38 | loss: 0.0578634\n",
      "\tspeed: 0.0418s/iter; left time: 582.0774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0530546 Vali Loss: 0.0543200 Test Loss: 0.0573338\n",
      "Validation loss decreased (0.054363 --> 0.054320).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0526937\n",
      "\tspeed: 0.0746s/iter; left time: 1028.3645s\n",
      "\titers: 200, epoch: 39 | loss: 0.0528568\n",
      "\tspeed: 0.0418s/iter; left time: 572.5874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0530138 Vali Loss: 0.0542319 Test Loss: 0.0573226\n",
      "Validation loss decreased (0.054320 --> 0.054232).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0563120\n",
      "\tspeed: 0.0744s/iter; left time: 1009.9058s\n",
      "\titers: 200, epoch: 40 | loss: 0.0510091\n",
      "\tspeed: 0.0418s/iter; left time: 562.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0529836 Vali Loss: 0.0543886 Test Loss: 0.0573441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0574817\n",
      "\tspeed: 0.0749s/iter; left time: 998.7108s\n",
      "\titers: 200, epoch: 41 | loss: 0.0560694\n",
      "\tspeed: 0.0418s/iter; left time: 553.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0530532 Vali Loss: 0.0543912 Test Loss: 0.0573497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0537718\n",
      "\tspeed: 0.0740s/iter; left time: 970.0687s\n",
      "\titers: 200, epoch: 42 | loss: 0.0548852\n",
      "\tspeed: 0.0418s/iter; left time: 544.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0529759 Vali Loss: 0.0543679 Test Loss: 0.0573329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0538681\n",
      "\tspeed: 0.0739s/iter; left time: 952.8693s\n",
      "\titers: 200, epoch: 43 | loss: 0.0495705\n",
      "\tspeed: 0.0418s/iter; left time: 534.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0529634 Vali Loss: 0.0542869 Test Loss: 0.0573246\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0502725\n",
      "\tspeed: 0.0748s/iter; left time: 947.7138s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535956\n",
      "\tspeed: 0.0419s/iter; left time: 526.2463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0529778 Vali Loss: 0.0542852 Test Loss: 0.0573048\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0540188\n",
      "\tspeed: 0.0736s/iter; left time: 916.5252s\n",
      "\titers: 200, epoch: 45 | loss: 0.0544035\n",
      "\tspeed: 0.0418s/iter; left time: 516.6321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0529316 Vali Loss: 0.0543632 Test Loss: 0.0573138\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0547294\n",
      "\tspeed: 0.0752s/iter; left time: 919.0130s\n",
      "\titers: 200, epoch: 46 | loss: 0.0530386\n",
      "\tspeed: 0.0419s/iter; left time: 507.4683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0529451 Vali Loss: 0.0543928 Test Loss: 0.0573512\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0528816\n",
      "\tspeed: 0.0743s/iter; left time: 891.8318s\n",
      "\titers: 200, epoch: 47 | loss: 0.0518007\n",
      "\tspeed: 0.0419s/iter; left time: 497.9292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0529247 Vali Loss: 0.0543985 Test Loss: 0.0573596\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0547840\n",
      "\tspeed: 0.0751s/iter; left time: 884.6809s\n",
      "\titers: 200, epoch: 48 | loss: 0.0521973\n",
      "\tspeed: 0.0419s/iter; left time: 488.5531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0529457 Vali Loss: 0.0543617 Test Loss: 0.0573151\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0564644\n",
      "\tspeed: 0.0737s/iter; left time: 851.5835s\n",
      "\titers: 200, epoch: 49 | loss: 0.0526863\n",
      "\tspeed: 0.0418s/iter; left time: 478.6633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0529025 Vali Loss: 0.0543118 Test Loss: 0.0572813\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01028256956487894, rmse:0.10140300542116165, mae:0.05732264369726181, rse:0.383152037858963\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1616639\n",
      "\tspeed: 0.0433s/iter; left time: 966.2199s\n",
      "\titers: 200, epoch: 1 | loss: 0.1476239\n",
      "\tspeed: 0.0418s/iter; left time: 927.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.1636449 Vali Loss: 0.1371539 Test Loss: 0.1445717\n",
      "Validation loss decreased (inf --> 0.137154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0788116\n",
      "\tspeed: 0.0744s/iter; left time: 1641.4583s\n",
      "\titers: 200, epoch: 2 | loss: 0.0667151\n",
      "\tspeed: 0.0419s/iter; left time: 919.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0861281 Vali Loss: 0.0642575 Test Loss: 0.0675583\n",
      "Validation loss decreased (0.137154 --> 0.064257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0629694\n",
      "\tspeed: 0.0742s/iter; left time: 1620.8953s\n",
      "\titers: 200, epoch: 3 | loss: 0.0626399\n",
      "\tspeed: 0.0419s/iter; left time: 910.8908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0657113 Vali Loss: 0.0612823 Test Loss: 0.0645098\n",
      "Validation loss decreased (0.064257 --> 0.061282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0575715\n",
      "\tspeed: 0.0747s/iter; left time: 1615.8757s\n",
      "\titers: 200, epoch: 4 | loss: 0.0583651\n",
      "\tspeed: 0.0418s/iter; left time: 900.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0623427 Vali Loss: 0.0592041 Test Loss: 0.0625285\n",
      "Validation loss decreased (0.061282 --> 0.059204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582681\n",
      "\tspeed: 0.0746s/iter; left time: 1596.8355s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600793\n",
      "\tspeed: 0.0419s/iter; left time: 892.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0600875 Vali Loss: 0.0575578 Test Loss: 0.0608771\n",
      "Validation loss decreased (0.059204 --> 0.057558).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0581085\n",
      "\tspeed: 0.0745s/iter; left time: 1579.0175s\n",
      "\titers: 200, epoch: 6 | loss: 0.0590649\n",
      "\tspeed: 0.0418s/iter; left time: 882.0444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0586191 Vali Loss: 0.0568939 Test Loss: 0.0597674\n",
      "Validation loss decreased (0.057558 --> 0.056894).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588938\n",
      "\tspeed: 0.0745s/iter; left time: 1561.6143s\n",
      "\titers: 200, epoch: 7 | loss: 0.0554931\n",
      "\tspeed: 0.0418s/iter; left time: 872.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0575254 Vali Loss: 0.0565976 Test Loss: 0.0593791\n",
      "Validation loss decreased (0.056894 --> 0.056598).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0574277\n",
      "\tspeed: 0.0746s/iter; left time: 1547.6722s\n",
      "\titers: 200, epoch: 8 | loss: 0.0596510\n",
      "\tspeed: 0.0419s/iter; left time: 864.0850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0567334 Vali Loss: 0.0560192 Test Loss: 0.0589414\n",
      "Validation loss decreased (0.056598 --> 0.056019).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0523476\n",
      "\tspeed: 0.0747s/iter; left time: 1533.0372s\n",
      "\titers: 200, epoch: 9 | loss: 0.0539958\n",
      "\tspeed: 0.0419s/iter; left time: 854.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0562151 Vali Loss: 0.0557441 Test Loss: 0.0587535\n",
      "Validation loss decreased (0.056019 --> 0.055744).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577841\n",
      "\tspeed: 0.0745s/iter; left time: 1510.8485s\n",
      "\titers: 200, epoch: 10 | loss: 0.0528773\n",
      "\tspeed: 0.0418s/iter; left time: 844.3316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0557223 Vali Loss: 0.0554646 Test Loss: 0.0585298\n",
      "Validation loss decreased (0.055744 --> 0.055465).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0538761\n",
      "\tspeed: 0.0747s/iter; left time: 1498.1527s\n",
      "\titers: 200, epoch: 11 | loss: 0.0553195\n",
      "\tspeed: 0.0419s/iter; left time: 835.7565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0553937 Vali Loss: 0.0552108 Test Loss: 0.0581949\n",
      "Validation loss decreased (0.055465 --> 0.055211).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0535571\n",
      "\tspeed: 0.0750s/iter; left time: 1488.3766s\n",
      "\titers: 200, epoch: 12 | loss: 0.0548535\n",
      "\tspeed: 0.0418s/iter; left time: 825.5009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0550495 Vali Loss: 0.0551921 Test Loss: 0.0583735\n",
      "Validation loss decreased (0.055211 --> 0.055192).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0553481\n",
      "\tspeed: 0.0747s/iter; left time: 1464.5915s\n",
      "\titers: 200, epoch: 13 | loss: 0.0544968\n",
      "\tspeed: 0.0418s/iter; left time: 815.6076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0547886 Vali Loss: 0.0551847 Test Loss: 0.0580902\n",
      "Validation loss decreased (0.055192 --> 0.055185).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0511046\n",
      "\tspeed: 0.0746s/iter; left time: 1445.9497s\n",
      "\titers: 200, epoch: 14 | loss: 0.0555087\n",
      "\tspeed: 0.0419s/iter; left time: 807.3034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0545514 Vali Loss: 0.0548709 Test Loss: 0.0578461\n",
      "Validation loss decreased (0.055185 --> 0.054871).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0580758\n",
      "\tspeed: 0.0745s/iter; left time: 1428.6298s\n",
      "\titers: 200, epoch: 15 | loss: 0.0566910\n",
      "\tspeed: 0.0418s/iter; left time: 797.2411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0544231 Vali Loss: 0.0549199 Test Loss: 0.0578442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0568407\n",
      "\tspeed: 0.0738s/iter; left time: 1397.4190s\n",
      "\titers: 200, epoch: 16 | loss: 0.0580707\n",
      "\tspeed: 0.0418s/iter; left time: 787.6308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0542265 Vali Loss: 0.0546896 Test Loss: 0.0577216\n",
      "Validation loss decreased (0.054871 --> 0.054690).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0518764\n",
      "\tspeed: 0.0747s/iter; left time: 1397.8150s\n",
      "\titers: 200, epoch: 17 | loss: 0.0532458\n",
      "\tspeed: 0.0418s/iter; left time: 778.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0540888 Vali Loss: 0.0546941 Test Loss: 0.0577168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0508079\n",
      "\tspeed: 0.0741s/iter; left time: 1370.3762s\n",
      "\titers: 200, epoch: 18 | loss: 0.0514931\n",
      "\tspeed: 0.0418s/iter; left time: 769.3329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0539316 Vali Loss: 0.0545755 Test Loss: 0.0576704\n",
      "Validation loss decreased (0.054690 --> 0.054575).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0519903\n",
      "\tspeed: 0.0746s/iter; left time: 1362.6380s\n",
      "\titers: 200, epoch: 19 | loss: 0.0483813\n",
      "\tspeed: 0.0418s/iter; left time: 759.7713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0537805 Vali Loss: 0.0545462 Test Loss: 0.0575867\n",
      "Validation loss decreased (0.054575 --> 0.054546).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0535914\n",
      "\tspeed: 0.0748s/iter; left time: 1349.5709s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546892\n",
      "\tspeed: 0.0418s/iter; left time: 750.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0536743 Vali Loss: 0.0544524 Test Loss: 0.0574283\n",
      "Validation loss decreased (0.054546 --> 0.054452).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0540178\n",
      "\tspeed: 0.0747s/iter; left time: 1331.5933s\n",
      "\titers: 200, epoch: 21 | loss: 0.0522899\n",
      "\tspeed: 0.0419s/iter; left time: 741.6669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0536213 Vali Loss: 0.0543808 Test Loss: 0.0575519\n",
      "Validation loss decreased (0.054452 --> 0.054381).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0546879\n",
      "\tspeed: 0.0746s/iter; left time: 1313.4636s\n",
      "\titers: 200, epoch: 22 | loss: 0.0504863\n",
      "\tspeed: 0.0418s/iter; left time: 731.8208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0535170 Vali Loss: 0.0543309 Test Loss: 0.0574142\n",
      "Validation loss decreased (0.054381 --> 0.054331).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0541547\n",
      "\tspeed: 0.0765s/iter; left time: 1329.3613s\n",
      "\titers: 200, epoch: 23 | loss: 0.0524183\n",
      "\tspeed: 0.0418s/iter; left time: 722.7461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0534375 Vali Loss: 0.0543097 Test Loss: 0.0573499\n",
      "Validation loss decreased (0.054331 --> 0.054310).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0576624\n",
      "\tspeed: 0.0764s/iter; left time: 1309.7861s\n",
      "\titers: 200, epoch: 24 | loss: 0.0513303\n",
      "\tspeed: 0.0419s/iter; left time: 713.5872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0534079 Vali Loss: 0.0543459 Test Loss: 0.0574013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0521893\n",
      "\tspeed: 0.0838s/iter; left time: 1418.1088s\n",
      "\titers: 200, epoch: 25 | loss: 0.0516139\n",
      "\tspeed: 0.0419s/iter; left time: 704.3194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 224 | Train Loss: 0.0533243 Vali Loss: 0.0543876 Test Loss: 0.0573955\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0501922\n",
      "\tspeed: 0.0741s/iter; left time: 1237.2528s\n",
      "\titers: 200, epoch: 26 | loss: 0.0541352\n",
      "\tspeed: 0.0418s/iter; left time: 693.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0532546 Vali Loss: 0.0541978 Test Loss: 0.0573019\n",
      "Validation loss decreased (0.054310 --> 0.054198).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0493153\n",
      "\tspeed: 0.0856s/iter; left time: 1410.4585s\n",
      "\titers: 200, epoch: 27 | loss: 0.0526472\n",
      "\tspeed: 0.0418s/iter; left time: 685.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0532697 Vali Loss: 0.0542148 Test Loss: 0.0573098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0514517\n",
      "\tspeed: 0.0740s/iter; left time: 1203.2562s\n",
      "\titers: 200, epoch: 28 | loss: 0.0499882\n",
      "\tspeed: 0.0419s/iter; left time: 676.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0531714 Vali Loss: 0.0542701 Test Loss: 0.0573346\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0573119\n",
      "\tspeed: 0.0740s/iter; left time: 1186.0142s\n",
      "\titers: 200, epoch: 29 | loss: 0.0558033\n",
      "\tspeed: 0.0418s/iter; left time: 666.3228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0531370 Vali Loss: 0.0542226 Test Loss: 0.0572494\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0516919\n",
      "\tspeed: 0.0740s/iter; left time: 1168.7904s\n",
      "\titers: 200, epoch: 30 | loss: 0.0497717\n",
      "\tspeed: 0.0419s/iter; left time: 657.8128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0531310 Vali Loss: 0.0541556 Test Loss: 0.0572202\n",
      "Validation loss decreased (0.054198 --> 0.054156).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0527075\n",
      "\tspeed: 0.0747s/iter; left time: 1163.9633s\n",
      "\titers: 200, epoch: 31 | loss: 0.0537404\n",
      "\tspeed: 0.0418s/iter; left time: 646.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0530956 Vali Loss: 0.0541769 Test Loss: 0.0571595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0533048\n",
      "\tspeed: 0.0738s/iter; left time: 1133.7672s\n",
      "\titers: 200, epoch: 32 | loss: 0.0556948\n",
      "\tspeed: 0.0418s/iter; left time: 638.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0530611 Vali Loss: 0.0541787 Test Loss: 0.0571991\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0510798\n",
      "\tspeed: 0.0739s/iter; left time: 1118.2675s\n",
      "\titers: 200, epoch: 33 | loss: 0.0523759\n",
      "\tspeed: 0.0418s/iter; left time: 628.9161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0531029 Vali Loss: 0.0541814 Test Loss: 0.0571673\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0522886\n",
      "\tspeed: 0.0739s/iter; left time: 1101.8744s\n",
      "\titers: 200, epoch: 34 | loss: 0.0541572\n",
      "\tspeed: 0.0419s/iter; left time: 619.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0530245 Vali Loss: 0.0540877 Test Loss: 0.0571120\n",
      "Validation loss decreased (0.054156 --> 0.054088).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0515421\n",
      "\tspeed: 0.0744s/iter; left time: 1092.5634s\n",
      "\titers: 200, epoch: 35 | loss: 0.0513102\n",
      "\tspeed: 0.0418s/iter; left time: 610.3254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0529863 Vali Loss: 0.0541510 Test Loss: 0.0571679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0522429\n",
      "\tspeed: 0.0739s/iter; left time: 1068.3731s\n",
      "\titers: 200, epoch: 36 | loss: 0.0521231\n",
      "\tspeed: 0.0419s/iter; left time: 601.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0530019 Vali Loss: 0.0541704 Test Loss: 0.0571422\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0513952\n",
      "\tspeed: 0.0741s/iter; left time: 1054.2933s\n",
      "\titers: 200, epoch: 37 | loss: 0.0474398\n",
      "\tspeed: 0.0419s/iter; left time: 591.9197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0529754 Vali Loss: 0.0540476 Test Loss: 0.0571175\n",
      "Validation loss decreased (0.054088 --> 0.054048).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0502229\n",
      "\tspeed: 0.0745s/iter; left time: 1044.6058s\n",
      "\titers: 200, epoch: 38 | loss: 0.0529533\n",
      "\tspeed: 0.0419s/iter; left time: 582.7175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0529339 Vali Loss: 0.0542359 Test Loss: 0.0571858\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0542917\n",
      "\tspeed: 0.0740s/iter; left time: 1019.8536s\n",
      "\titers: 200, epoch: 39 | loss: 0.0531940\n",
      "\tspeed: 0.0419s/iter; left time: 573.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0529129 Vali Loss: 0.0540209 Test Loss: 0.0571142\n",
      "Validation loss decreased (0.054048 --> 0.054021).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0547552\n",
      "\tspeed: 0.0745s/iter; left time: 1010.3311s\n",
      "\titers: 200, epoch: 40 | loss: 0.0557019\n",
      "\tspeed: 0.0418s/iter; left time: 562.9143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0529163 Vali Loss: 0.0540310 Test Loss: 0.0571155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0534431\n",
      "\tspeed: 0.0740s/iter; left time: 986.6784s\n",
      "\titers: 200, epoch: 41 | loss: 0.0568288\n",
      "\tspeed: 0.0419s/iter; left time: 554.3730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0528946 Vali Loss: 0.0540863 Test Loss: 0.0571200\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0536664\n",
      "\tspeed: 0.0740s/iter; left time: 970.1198s\n",
      "\titers: 200, epoch: 42 | loss: 0.0512080\n",
      "\tspeed: 0.0419s/iter; left time: 545.1456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0529005 Vali Loss: 0.0540332 Test Loss: 0.0570927\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0552242\n",
      "\tspeed: 0.0744s/iter; left time: 958.8215s\n",
      "\titers: 200, epoch: 43 | loss: 0.0507111\n",
      "\tspeed: 0.0419s/iter; left time: 535.7786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0528627 Vali Loss: 0.0541517 Test Loss: 0.0571203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0526871\n",
      "\tspeed: 0.0738s/iter; left time: 934.8897s\n",
      "\titers: 200, epoch: 44 | loss: 0.0537241\n",
      "\tspeed: 0.0418s/iter; left time: 525.5206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0529090 Vali Loss: 0.0540866 Test Loss: 0.0571252\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0587728\n",
      "\tspeed: 0.0741s/iter; left time: 921.8914s\n",
      "\titers: 200, epoch: 45 | loss: 0.0491216\n",
      "\tspeed: 0.0418s/iter; left time: 516.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0528336 Vali Loss: 0.0541069 Test Loss: 0.0571408\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0522368\n",
      "\tspeed: 0.0740s/iter; left time: 903.8769s\n",
      "\titers: 200, epoch: 46 | loss: 0.0523553\n",
      "\tspeed: 0.0419s/iter; left time: 507.4014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0528736 Vali Loss: 0.0540359 Test Loss: 0.0571018\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0527549\n",
      "\tspeed: 0.0742s/iter; left time: 889.9456s\n",
      "\titers: 200, epoch: 47 | loss: 0.0514552\n",
      "\tspeed: 0.0418s/iter; left time: 497.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0528191 Vali Loss: 0.0540452 Test Loss: 0.0571226\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0518987\n",
      "\tspeed: 0.0739s/iter; left time: 870.1079s\n",
      "\titers: 200, epoch: 48 | loss: 0.0528718\n",
      "\tspeed: 0.0418s/iter; left time: 488.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0528364 Vali Loss: 0.0541071 Test Loss: 0.0571336\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0543009\n",
      "\tspeed: 0.0739s/iter; left time: 853.3450s\n",
      "\titers: 200, epoch: 49 | loss: 0.0517853\n",
      "\tspeed: 0.0418s/iter; left time: 478.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0528222 Vali Loss: 0.0540462 Test Loss: 0.0571074\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0101736169308424, rmse:0.10086435079574585, mae:0.05711417645215988, rse:0.38111668825149536\n",
      "Intermediate time for IT and pred_len 24: 00h:19m:12.11s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1709637\n",
      "\tspeed: 0.0628s/iter; left time: 1401.4907s\n",
      "\titers: 200, epoch: 1 | loss: 0.1590622\n",
      "\tspeed: 0.0423s/iter; left time: 940.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.1731405 Vali Loss: 0.1467602 Test Loss: 0.1548989\n",
      "Validation loss decreased (inf --> 0.146760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0915521\n",
      "\tspeed: 0.0775s/iter; left time: 1709.9081s\n",
      "\titers: 200, epoch: 2 | loss: 0.0813664\n",
      "\tspeed: 0.0423s/iter; left time: 928.5343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.1010438 Vali Loss: 0.0820178 Test Loss: 0.0875869\n",
      "Validation loss decreased (0.146760 --> 0.082018).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0834640\n",
      "\tspeed: 0.0785s/iter; left time: 1714.7168s\n",
      "\titers: 200, epoch: 3 | loss: 0.0890686\n",
      "\tspeed: 0.0423s/iter; left time: 919.0786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0845064 Vali Loss: 0.0791088 Test Loss: 0.0851409\n",
      "Validation loss decreased (0.082018 --> 0.079109).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0819988\n",
      "\tspeed: 0.0766s/iter; left time: 1657.1573s\n",
      "\titers: 200, epoch: 4 | loss: 0.0786908\n",
      "\tspeed: 0.0422s/iter; left time: 908.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0813391 Vali Loss: 0.0774892 Test Loss: 0.0833235\n",
      "Validation loss decreased (0.079109 --> 0.077489).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812265\n",
      "\tspeed: 0.0802s/iter; left time: 1716.1672s\n",
      "\titers: 200, epoch: 5 | loss: 0.0782264\n",
      "\tspeed: 0.0422s/iter; left time: 898.4396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0792095 Vali Loss: 0.0765936 Test Loss: 0.0825124\n",
      "Validation loss decreased (0.077489 --> 0.076594).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0764224\n",
      "\tspeed: 0.0775s/iter; left time: 1642.2676s\n",
      "\titers: 200, epoch: 6 | loss: 0.0783107\n",
      "\tspeed: 0.0422s/iter; left time: 889.2412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0779074 Vali Loss: 0.0763852 Test Loss: 0.0820518\n",
      "Validation loss decreased (0.076594 --> 0.076385).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0758527\n",
      "\tspeed: 0.0768s/iter; left time: 1610.0296s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771271\n",
      "\tspeed: 0.0422s/iter; left time: 881.1937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769735 Vali Loss: 0.0758655 Test Loss: 0.0815309\n",
      "Validation loss decreased (0.076385 --> 0.075866).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826955\n",
      "\tspeed: 0.0767s/iter; left time: 1589.9065s\n",
      "\titers: 200, epoch: 8 | loss: 0.0760676\n",
      "\tspeed: 0.0421s/iter; left time: 869.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0762410 Vali Loss: 0.0755869 Test Loss: 0.0812099\n",
      "Validation loss decreased (0.075866 --> 0.075587).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0707286\n",
      "\tspeed: 0.0770s/iter; left time: 1578.7741s\n",
      "\titers: 200, epoch: 9 | loss: 0.0743069\n",
      "\tspeed: 0.0421s/iter; left time: 859.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0756071 Vali Loss: 0.0752984 Test Loss: 0.0811832\n",
      "Validation loss decreased (0.075587 --> 0.075298).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0766918\n",
      "\tspeed: 0.0773s/iter; left time: 1567.9840s\n",
      "\titers: 200, epoch: 10 | loss: 0.0728842\n",
      "\tspeed: 0.0421s/iter; left time: 850.7283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0751414 Vali Loss: 0.0754443 Test Loss: 0.0811766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736202\n",
      "\tspeed: 0.0761s/iter; left time: 1526.8073s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760152\n",
      "\tspeed: 0.0422s/iter; left time: 842.1549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0747158 Vali Loss: 0.0752145 Test Loss: 0.0808049\n",
      "Validation loss decreased (0.075298 --> 0.075215).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0720106\n",
      "\tspeed: 0.0768s/iter; left time: 1524.2798s\n",
      "\titers: 200, epoch: 12 | loss: 0.0731059\n",
      "\tspeed: 0.0421s/iter; left time: 831.7771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0743176 Vali Loss: 0.0752223 Test Loss: 0.0806497\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700952\n",
      "\tspeed: 0.0765s/iter; left time: 1500.3928s\n",
      "\titers: 200, epoch: 13 | loss: 0.0709079\n",
      "\tspeed: 0.0421s/iter; left time: 821.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0739965 Vali Loss: 0.0750111 Test Loss: 0.0804848\n",
      "Validation loss decreased (0.075215 --> 0.075011).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0717369\n",
      "\tspeed: 0.0764s/iter; left time: 1481.0720s\n",
      "\titers: 200, epoch: 14 | loss: 0.0706455\n",
      "\tspeed: 0.0422s/iter; left time: 813.0598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0735995 Vali Loss: 0.0751630 Test Loss: 0.0805996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0726589\n",
      "\tspeed: 0.0753s/iter; left time: 1442.9068s\n",
      "\titers: 200, epoch: 15 | loss: 0.0723697\n",
      "\tspeed: 0.0422s/iter; left time: 803.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0733330 Vali Loss: 0.0750874 Test Loss: 0.0805799\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0707894\n",
      "\tspeed: 0.0762s/iter; left time: 1443.0990s\n",
      "\titers: 200, epoch: 16 | loss: 0.0748958\n",
      "\tspeed: 0.0422s/iter; left time: 795.2376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0730366 Vali Loss: 0.0752258 Test Loss: 0.0806013\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0713298\n",
      "\tspeed: 0.0759s/iter; left time: 1420.6176s\n",
      "\titers: 200, epoch: 17 | loss: 0.0706481\n",
      "\tspeed: 0.0422s/iter; left time: 785.3704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0728366 Vali Loss: 0.0750299 Test Loss: 0.0805444\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0766651\n",
      "\tspeed: 0.0759s/iter; left time: 1403.4191s\n",
      "\titers: 200, epoch: 18 | loss: 0.0755578\n",
      "\tspeed: 0.0422s/iter; left time: 776.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0726392 Vali Loss: 0.0750070 Test Loss: 0.0803575\n",
      "Validation loss decreased (0.075011 --> 0.075007).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0721044\n",
      "\tspeed: 0.0761s/iter; left time: 1389.8956s\n",
      "\titers: 200, epoch: 19 | loss: 0.0752852\n",
      "\tspeed: 0.0422s/iter; left time: 767.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0724808 Vali Loss: 0.0749559 Test Loss: 0.0802967\n",
      "Validation loss decreased (0.075007 --> 0.074956).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0686410\n",
      "\tspeed: 0.0765s/iter; left time: 1380.9826s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692698\n",
      "\tspeed: 0.0422s/iter; left time: 757.2277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0722542 Vali Loss: 0.0750252 Test Loss: 0.0803124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0693305\n",
      "\tspeed: 0.0768s/iter; left time: 1369.0937s\n",
      "\titers: 200, epoch: 21 | loss: 0.0740962\n",
      "\tspeed: 0.0422s/iter; left time: 747.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0721057 Vali Loss: 0.0750124 Test Loss: 0.0803431\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0718964\n",
      "\tspeed: 0.0764s/iter; left time: 1344.5747s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750140\n",
      "\tspeed: 0.0422s/iter; left time: 739.1659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0719894 Vali Loss: 0.0749805 Test Loss: 0.0802566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0679527\n",
      "\tspeed: 0.0761s/iter; left time: 1321.8060s\n",
      "\titers: 200, epoch: 23 | loss: 0.0706710\n",
      "\tspeed: 0.0422s/iter; left time: 728.9515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0718464 Vali Loss: 0.0750409 Test Loss: 0.0802397\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0731610\n",
      "\tspeed: 0.0756s/iter; left time: 1297.0458s\n",
      "\titers: 200, epoch: 24 | loss: 0.0708685\n",
      "\tspeed: 0.0422s/iter; left time: 719.1724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0716813 Vali Loss: 0.0750071 Test Loss: 0.0803240\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0706737\n",
      "\tspeed: 0.0760s/iter; left time: 1285.8573s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705063\n",
      "\tspeed: 0.0422s/iter; left time: 710.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0716176 Vali Loss: 0.0749813 Test Loss: 0.0803697\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0735623\n",
      "\tspeed: 0.0765s/iter; left time: 1278.3694s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690790\n",
      "\tspeed: 0.0421s/iter; left time: 699.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0715137 Vali Loss: 0.0749541 Test Loss: 0.0802607\n",
      "Validation loss decreased (0.074956 --> 0.074954).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0726354\n",
      "\tspeed: 0.0771s/iter; left time: 1270.4747s\n",
      "\titers: 200, epoch: 27 | loss: 0.0705061\n",
      "\tspeed: 0.0422s/iter; left time: 690.4923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0714466 Vali Loss: 0.0750012 Test Loss: 0.0802674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0757946\n",
      "\tspeed: 0.0758s/iter; left time: 1232.4026s\n",
      "\titers: 200, epoch: 28 | loss: 0.0710962\n",
      "\tspeed: 0.0422s/iter; left time: 682.0408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0714014 Vali Loss: 0.0750562 Test Loss: 0.0802803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0731476\n",
      "\tspeed: 0.0760s/iter; left time: 1217.4944s\n",
      "\titers: 200, epoch: 29 | loss: 0.0687728\n",
      "\tspeed: 0.0421s/iter; left time: 671.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0712709 Vali Loss: 0.0749656 Test Loss: 0.0802395\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0708239\n",
      "\tspeed: 0.0754s/iter; left time: 1192.3866s\n",
      "\titers: 200, epoch: 30 | loss: 0.0733953\n",
      "\tspeed: 0.0422s/iter; left time: 662.8391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0712485 Vali Loss: 0.0751104 Test Loss: 0.0802817\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0703984\n",
      "\tspeed: 0.0761s/iter; left time: 1185.9316s\n",
      "\titers: 200, epoch: 31 | loss: 0.0692999\n",
      "\tspeed: 0.0422s/iter; left time: 653.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0711721 Vali Loss: 0.0750923 Test Loss: 0.0802622\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0759123\n",
      "\tspeed: 0.0762s/iter; left time: 1170.1991s\n",
      "\titers: 200, epoch: 32 | loss: 0.0721979\n",
      "\tspeed: 0.0422s/iter; left time: 643.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0711303 Vali Loss: 0.0749914 Test Loss: 0.0802187\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0675400\n",
      "\tspeed: 0.0756s/iter; left time: 1143.3427s\n",
      "\titers: 200, epoch: 33 | loss: 0.0712444\n",
      "\tspeed: 0.0423s/iter; left time: 635.4187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0710815 Vali Loss: 0.0750909 Test Loss: 0.0803081\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0708706\n",
      "\tspeed: 0.0757s/iter; left time: 1128.5315s\n",
      "\titers: 200, epoch: 34 | loss: 0.0726558\n",
      "\tspeed: 0.0422s/iter; left time: 624.4773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0710599 Vali Loss: 0.0749457 Test Loss: 0.0802050\n",
      "Validation loss decreased (0.074954 --> 0.074946).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0705489\n",
      "\tspeed: 0.0765s/iter; left time: 1123.9537s\n",
      "\titers: 200, epoch: 35 | loss: 0.0747192\n",
      "\tspeed: 0.0422s/iter; left time: 615.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0710360 Vali Loss: 0.0750625 Test Loss: 0.0802698\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0733743\n",
      "\tspeed: 0.0758s/iter; left time: 1096.4568s\n",
      "\titers: 200, epoch: 36 | loss: 0.0699492\n",
      "\tspeed: 0.0422s/iter; left time: 605.8864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0709659 Vali Loss: 0.0749656 Test Loss: 0.0802171\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0723512\n",
      "\tspeed: 0.0760s/iter; left time: 1081.4515s\n",
      "\titers: 200, epoch: 37 | loss: 0.0751660\n",
      "\tspeed: 0.0422s/iter; left time: 596.7870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0709697 Vali Loss: 0.0749879 Test Loss: 0.0802169\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0702403\n",
      "\tspeed: 0.0759s/iter; left time: 1063.1375s\n",
      "\titers: 200, epoch: 38 | loss: 0.0739042\n",
      "\tspeed: 0.0422s/iter; left time: 586.5137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0709164 Vali Loss: 0.0750351 Test Loss: 0.0802318\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0726668\n",
      "\tspeed: 0.0754s/iter; left time: 1039.7809s\n",
      "\titers: 200, epoch: 39 | loss: 0.0694377\n",
      "\tspeed: 0.0421s/iter; left time: 576.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0709209 Vali Loss: 0.0750078 Test Loss: 0.0802350\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712593\n",
      "\tspeed: 0.0752s/iter; left time: 1019.8353s\n",
      "\titers: 200, epoch: 40 | loss: 0.0750139\n",
      "\tspeed: 0.0422s/iter; left time: 568.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0708410 Vali Loss: 0.0750490 Test Loss: 0.0802376\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0708972\n",
      "\tspeed: 0.0760s/iter; left time: 1013.7989s\n",
      "\titers: 200, epoch: 41 | loss: 0.0737602\n",
      "\tspeed: 0.0421s/iter; left time: 558.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0708548 Vali Loss: 0.0750213 Test Loss: 0.0802427\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0709119\n",
      "\tspeed: 0.0753s/iter; left time: 988.0675s\n",
      "\titers: 200, epoch: 42 | loss: 0.0701031\n",
      "\tspeed: 0.0422s/iter; left time: 548.6801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0708338 Vali Loss: 0.0750549 Test Loss: 0.0802160\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0709096\n",
      "\tspeed: 0.0755s/iter; left time: 973.0272s\n",
      "\titers: 200, epoch: 43 | loss: 0.0690312\n",
      "\tspeed: 0.0421s/iter; left time: 538.9894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0708735 Vali Loss: 0.0750550 Test Loss: 0.0802526\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0671204\n",
      "\tspeed: 0.0757s/iter; left time: 958.5804s\n",
      "\titers: 200, epoch: 44 | loss: 0.0687659\n",
      "\tspeed: 0.0422s/iter; left time: 529.9900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0708380 Vali Loss: 0.0750403 Test Loss: 0.0802399\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018426574766635895, rmse:0.13574452698230743, mae:0.08020501583814621, rse:0.5132646560668945\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1690528\n",
      "\tspeed: 0.0439s/iter; left time: 978.1898s\n",
      "\titers: 200, epoch: 1 | loss: 0.1593371\n",
      "\tspeed: 0.0422s/iter; left time: 936.4705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1715413 Vali Loss: 0.1460627 Test Loss: 0.1542718\n",
      "Validation loss decreased (inf --> 0.146063).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0974870\n",
      "\tspeed: 0.0763s/iter; left time: 1685.3289s\n",
      "\titers: 200, epoch: 2 | loss: 0.0848063\n",
      "\tspeed: 0.0422s/iter; left time: 927.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1027044 Vali Loss: 0.0821888 Test Loss: 0.0880603\n",
      "Validation loss decreased (0.146063 --> 0.082189).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0870626\n",
      "\tspeed: 0.0764s/iter; left time: 1668.8168s\n",
      "\titers: 200, epoch: 3 | loss: 0.0844888\n",
      "\tspeed: 0.0422s/iter; left time: 917.8942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0846875 Vali Loss: 0.0790373 Test Loss: 0.0849046\n",
      "Validation loss decreased (0.082189 --> 0.079037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0827117\n",
      "\tspeed: 0.0764s/iter; left time: 1652.0138s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803005\n",
      "\tspeed: 0.0422s/iter; left time: 907.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0816715 Vali Loss: 0.0771680 Test Loss: 0.0833144\n",
      "Validation loss decreased (0.079037 --> 0.077168).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0789151\n",
      "\tspeed: 0.0766s/iter; left time: 1639.4496s\n",
      "\titers: 200, epoch: 5 | loss: 0.0748166\n",
      "\tspeed: 0.0422s/iter; left time: 898.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0794953 Vali Loss: 0.0765681 Test Loss: 0.0823561\n",
      "Validation loss decreased (0.077168 --> 0.076568).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0762038\n",
      "\tspeed: 0.0764s/iter; left time: 1617.1734s\n",
      "\titers: 200, epoch: 6 | loss: 0.0740378\n",
      "\tspeed: 0.0421s/iter; left time: 888.2729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0782446 Vali Loss: 0.0759999 Test Loss: 0.0817863\n",
      "Validation loss decreased (0.076568 --> 0.076000).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763244\n",
      "\tspeed: 0.0767s/iter; left time: 1606.8378s\n",
      "\titers: 200, epoch: 7 | loss: 0.0782034\n",
      "\tspeed: 0.0421s/iter; left time: 878.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0771933 Vali Loss: 0.0759410 Test Loss: 0.0814095\n",
      "Validation loss decreased (0.076000 --> 0.075941).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0747644\n",
      "\tspeed: 0.0763s/iter; left time: 1582.0210s\n",
      "\titers: 200, epoch: 8 | loss: 0.0761208\n",
      "\tspeed: 0.0422s/iter; left time: 871.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0764373 Vali Loss: 0.0757183 Test Loss: 0.0811260\n",
      "Validation loss decreased (0.075941 --> 0.075718).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0750381\n",
      "\tspeed: 0.0765s/iter; left time: 1569.2628s\n",
      "\titers: 200, epoch: 9 | loss: 0.0731351\n",
      "\tspeed: 0.0422s/iter; left time: 860.9791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0757711 Vali Loss: 0.0755833 Test Loss: 0.0808182\n",
      "Validation loss decreased (0.075718 --> 0.075583).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0783068\n",
      "\tspeed: 0.0761s/iter; left time: 1543.9719s\n",
      "\titers: 200, epoch: 10 | loss: 0.0743017\n",
      "\tspeed: 0.0422s/iter; left time: 851.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0753262 Vali Loss: 0.0755877 Test Loss: 0.0805964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0771382\n",
      "\tspeed: 0.0756s/iter; left time: 1516.5527s\n",
      "\titers: 200, epoch: 11 | loss: 0.0740948\n",
      "\tspeed: 0.0422s/iter; left time: 842.0409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0747834 Vali Loss: 0.0756617 Test Loss: 0.0803652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0786360\n",
      "\tspeed: 0.0756s/iter; left time: 1499.9003s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729992\n",
      "\tspeed: 0.0422s/iter; left time: 832.2774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0743543 Vali Loss: 0.0755620 Test Loss: 0.0802146\n",
      "Validation loss decreased (0.075583 --> 0.075562).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0725833\n",
      "\tspeed: 0.0765s/iter; left time: 1499.4473s\n",
      "\titers: 200, epoch: 13 | loss: 0.0697948\n",
      "\tspeed: 0.0422s/iter; left time: 823.9641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0740273 Vali Loss: 0.0755412 Test Loss: 0.0800680\n",
      "Validation loss decreased (0.075562 --> 0.075541).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0740454\n",
      "\tspeed: 0.0764s/iter; left time: 1480.4458s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752891\n",
      "\tspeed: 0.0422s/iter; left time: 813.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0736795 Vali Loss: 0.0755513 Test Loss: 0.0800328\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793785\n",
      "\tspeed: 0.0758s/iter; left time: 1452.8962s\n",
      "\titers: 200, epoch: 15 | loss: 0.0747355\n",
      "\tspeed: 0.0422s/iter; left time: 804.0020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0733939 Vali Loss: 0.0753872 Test Loss: 0.0796960\n",
      "Validation loss decreased (0.075541 --> 0.075387).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0686066\n",
      "\tspeed: 0.0764s/iter; left time: 1447.3942s\n",
      "\titers: 200, epoch: 16 | loss: 0.0700632\n",
      "\tspeed: 0.0422s/iter; left time: 795.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0730653 Vali Loss: 0.0757043 Test Loss: 0.0799135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754684\n",
      "\tspeed: 0.0754s/iter; left time: 1410.9061s\n",
      "\titers: 200, epoch: 17 | loss: 0.0724376\n",
      "\tspeed: 0.0421s/iter; left time: 784.5095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0728220 Vali Loss: 0.0758647 Test Loss: 0.0800363\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0696758\n",
      "\tspeed: 0.0754s/iter; left time: 1394.1991s\n",
      "\titers: 200, epoch: 18 | loss: 0.0764009\n",
      "\tspeed: 0.0422s/iter; left time: 776.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0725893 Vali Loss: 0.0754318 Test Loss: 0.0797931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0728003\n",
      "\tspeed: 0.0752s/iter; left time: 1374.6866s\n",
      "\titers: 200, epoch: 19 | loss: 0.0710235\n",
      "\tspeed: 0.0421s/iter; left time: 765.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0723859 Vali Loss: 0.0757423 Test Loss: 0.0799313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0743600\n",
      "\tspeed: 0.0755s/iter; left time: 1362.9587s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744077\n",
      "\tspeed: 0.0422s/iter; left time: 757.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0721254 Vali Loss: 0.0756425 Test Loss: 0.0798354\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0732355\n",
      "\tspeed: 0.0757s/iter; left time: 1348.4602s\n",
      "\titers: 200, epoch: 21 | loss: 0.0718889\n",
      "\tspeed: 0.0422s/iter; left time: 747.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0720353 Vali Loss: 0.0757102 Test Loss: 0.0798239\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0769786\n",
      "\tspeed: 0.0757s/iter; left time: 1331.8141s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750980\n",
      "\tspeed: 0.0422s/iter; left time: 737.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0719278 Vali Loss: 0.0756645 Test Loss: 0.0797868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0732628\n",
      "\tspeed: 0.0757s/iter; left time: 1315.6078s\n",
      "\titers: 200, epoch: 23 | loss: 0.0671167\n",
      "\tspeed: 0.0422s/iter; left time: 728.6210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0717096 Vali Loss: 0.0756078 Test Loss: 0.0796641\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0737137\n",
      "\tspeed: 0.0758s/iter; left time: 1299.6338s\n",
      "\titers: 200, epoch: 24 | loss: 0.0736793\n",
      "\tspeed: 0.0421s/iter; left time: 718.0437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0714802 Vali Loss: 0.0756013 Test Loss: 0.0797363\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0705145\n",
      "\tspeed: 0.0755s/iter; left time: 1277.6675s\n",
      "\titers: 200, epoch: 25 | loss: 0.0737963\n",
      "\tspeed: 0.0421s/iter; left time: 708.8848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0715292 Vali Loss: 0.0757246 Test Loss: 0.0798351\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018040161579847336, rmse:0.1343136727809906, mae:0.07969599217176437, rse:0.5078544616699219\n",
      "Intermediate time for IT and pred_len 96: 00h:13m:47.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1685084\n",
      "\tspeed: 0.0612s/iter; left time: 1358.8251s\n",
      "\titers: 200, epoch: 1 | loss: 0.1568417\n",
      "\tspeed: 0.0426s/iter; left time: 941.2468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 223 | Train Loss: 0.1736281 Vali Loss: 0.1484829 Test Loss: 0.1557589\n",
      "Validation loss decreased (inf --> 0.148483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0974766\n",
      "\tspeed: 0.1101s/iter; left time: 2418.9825s\n",
      "\titers: 200, epoch: 2 | loss: 0.0909598\n",
      "\tspeed: 0.0427s/iter; left time: 933.3097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.1043616 Vali Loss: 0.0868721 Test Loss: 0.0920455\n",
      "Validation loss decreased (0.148483 --> 0.086872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0907705\n",
      "\tspeed: 0.0781s/iter; left time: 1698.4357s\n",
      "\titers: 200, epoch: 3 | loss: 0.0903725\n",
      "\tspeed: 0.0426s/iter; left time: 922.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0891924 Vali Loss: 0.0843571 Test Loss: 0.0895865\n",
      "Validation loss decreased (0.086872 --> 0.084357).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856451\n",
      "\tspeed: 0.0786s/iter; left time: 1691.3843s\n",
      "\titers: 200, epoch: 4 | loss: 0.0856527\n",
      "\tspeed: 0.0426s/iter; left time: 911.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0858986 Vali Loss: 0.0823978 Test Loss: 0.0877564\n",
      "Validation loss decreased (0.084357 --> 0.082398).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0821580\n",
      "\tspeed: 0.0772s/iter; left time: 1646.0170s\n",
      "\titers: 200, epoch: 5 | loss: 0.0865016\n",
      "\tspeed: 0.0426s/iter; left time: 902.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0836854 Vali Loss: 0.0821022 Test Loss: 0.0869493\n",
      "Validation loss decreased (0.082398 --> 0.082102).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0820099\n",
      "\tspeed: 0.0771s/iter; left time: 1626.0144s\n",
      "\titers: 200, epoch: 6 | loss: 0.0806738\n",
      "\tspeed: 0.0426s/iter; left time: 893.6441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0824466 Vali Loss: 0.0818127 Test Loss: 0.0865573\n",
      "Validation loss decreased (0.082102 --> 0.081813).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782823\n",
      "\tspeed: 0.0763s/iter; left time: 1591.4388s\n",
      "\titers: 200, epoch: 7 | loss: 0.0790035\n",
      "\tspeed: 0.0426s/iter; left time: 883.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0815521 Vali Loss: 0.0815402 Test Loss: 0.0861961\n",
      "Validation loss decreased (0.081813 --> 0.081540).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0853935\n",
      "\tspeed: 0.0768s/iter; left time: 1584.1711s\n",
      "\titers: 200, epoch: 8 | loss: 0.0811640\n",
      "\tspeed: 0.0426s/iter; left time: 874.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0807243 Vali Loss: 0.0813643 Test Loss: 0.0859200\n",
      "Validation loss decreased (0.081540 --> 0.081364).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0786720\n",
      "\tspeed: 0.0764s/iter; left time: 1560.1609s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794805\n",
      "\tspeed: 0.0426s/iter; left time: 865.6102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0800110 Vali Loss: 0.0811726 Test Loss: 0.0858258\n",
      "Validation loss decreased (0.081364 --> 0.081173).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747472\n",
      "\tspeed: 0.0768s/iter; left time: 1550.7885s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790480\n",
      "\tspeed: 0.0426s/iter; left time: 855.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0794431 Vali Loss: 0.0812832 Test Loss: 0.0858309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0785402\n",
      "\tspeed: 0.0763s/iter; left time: 1523.1569s\n",
      "\titers: 200, epoch: 11 | loss: 0.0822288\n",
      "\tspeed: 0.0426s/iter; left time: 845.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0789551 Vali Loss: 0.0812124 Test Loss: 0.0858182\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0803159\n",
      "\tspeed: 0.0760s/iter; left time: 1501.7685s\n",
      "\titers: 200, epoch: 12 | loss: 0.0763940\n",
      "\tspeed: 0.0426s/iter; left time: 836.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0784845 Vali Loss: 0.0816927 Test Loss: 0.0861263\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0770830\n",
      "\tspeed: 0.0756s/iter; left time: 1475.6543s\n",
      "\titers: 200, epoch: 13 | loss: 0.0745756\n",
      "\tspeed: 0.0426s/iter; left time: 826.9298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0780846 Vali Loss: 0.0811105 Test Loss: 0.0860111\n",
      "Validation loss decreased (0.081173 --> 0.081111).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754176\n",
      "\tspeed: 0.0782s/iter; left time: 1510.2850s\n",
      "\titers: 200, epoch: 14 | loss: 0.0782623\n",
      "\tspeed: 0.0426s/iter; left time: 817.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0777484 Vali Loss: 0.0813321 Test Loss: 0.0858601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0782674\n",
      "\tspeed: 0.0761s/iter; left time: 1452.0951s\n",
      "\titers: 200, epoch: 15 | loss: 0.0810125\n",
      "\tspeed: 0.0425s/iter; left time: 807.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0774745 Vali Loss: 0.0815115 Test Loss: 0.0860015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0776845\n",
      "\tspeed: 0.0762s/iter; left time: 1435.8855s\n",
      "\titers: 200, epoch: 16 | loss: 0.0781795\n",
      "\tspeed: 0.0426s/iter; left time: 798.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0771345 Vali Loss: 0.0815269 Test Loss: 0.0859353\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0737727\n",
      "\tspeed: 0.0763s/iter; left time: 1421.3241s\n",
      "\titers: 200, epoch: 17 | loss: 0.0730831\n",
      "\tspeed: 0.0426s/iter; left time: 788.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0769411 Vali Loss: 0.0812567 Test Loss: 0.0857312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0752616\n",
      "\tspeed: 0.0754s/iter; left time: 1388.9115s\n",
      "\titers: 200, epoch: 18 | loss: 0.0719897\n",
      "\tspeed: 0.0425s/iter; left time: 778.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0767019 Vali Loss: 0.0813096 Test Loss: 0.0859496\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0768243\n",
      "\tspeed: 0.0760s/iter; left time: 1382.7631s\n",
      "\titers: 200, epoch: 19 | loss: 0.0735799\n",
      "\tspeed: 0.0425s/iter; left time: 769.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0765290 Vali Loss: 0.0812752 Test Loss: 0.0859788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0761607\n",
      "\tspeed: 0.0761s/iter; left time: 1367.2224s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744282\n",
      "\tspeed: 0.0426s/iter; left time: 760.5971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0762922 Vali Loss: 0.0812472 Test Loss: 0.0858141\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0799511\n",
      "\tspeed: 0.0759s/iter; left time: 1346.6839s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779543\n",
      "\tspeed: 0.0426s/iter; left time: 751.0341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0761807 Vali Loss: 0.0814064 Test Loss: 0.0856810\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0768406\n",
      "\tspeed: 0.0777s/iter; left time: 1360.9688s\n",
      "\titers: 200, epoch: 22 | loss: 0.0725928\n",
      "\tspeed: 0.0431s/iter; left time: 750.6392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 223 | Train Loss: 0.0759702 Vali Loss: 0.0813204 Test Loss: 0.0858513\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0737765\n",
      "\tspeed: 0.0780s/iter; left time: 1348.2847s\n",
      "\titers: 200, epoch: 23 | loss: 0.0740322\n",
      "\tspeed: 0.0425s/iter; left time: 731.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0758253 Vali Loss: 0.0816101 Test Loss: 0.0858746\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019910652190446854, rmse:0.14110511541366577, mae:0.08601111173629761, rse:0.5340294241905212\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1738360\n",
      "\tspeed: 0.0442s/iter; left time: 981.7278s\n",
      "\titers: 200, epoch: 1 | loss: 0.1570505\n",
      "\tspeed: 0.0425s/iter; left time: 939.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.1732006 Vali Loss: 0.1485402 Test Loss: 0.1558604\n",
      "Validation loss decreased (inf --> 0.148540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986272\n",
      "\tspeed: 0.0770s/iter; left time: 1691.7702s\n",
      "\titers: 200, epoch: 2 | loss: 0.0931965\n",
      "\tspeed: 0.0425s/iter; left time: 929.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.1054054 Vali Loss: 0.0868926 Test Loss: 0.0923197\n",
      "Validation loss decreased (0.148540 --> 0.086893).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888634\n",
      "\tspeed: 0.0772s/iter; left time: 1678.5131s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917304\n",
      "\tspeed: 0.0425s/iter; left time: 919.9971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0895569 Vali Loss: 0.0843855 Test Loss: 0.0898747\n",
      "Validation loss decreased (0.086893 --> 0.084385).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0846417\n",
      "\tspeed: 0.0771s/iter; left time: 1659.5696s\n",
      "\titers: 200, epoch: 4 | loss: 0.0825565\n",
      "\tspeed: 0.0425s/iter; left time: 910.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0864843 Vali Loss: 0.0826916 Test Loss: 0.0881381\n",
      "Validation loss decreased (0.084385 --> 0.082692).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862233\n",
      "\tspeed: 0.0766s/iter; left time: 1632.0659s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826791\n",
      "\tspeed: 0.0425s/iter; left time: 902.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0839479 Vali Loss: 0.0819256 Test Loss: 0.0870442\n",
      "Validation loss decreased (0.082692 --> 0.081926).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0812812\n",
      "\tspeed: 0.0769s/iter; left time: 1620.5324s\n",
      "\titers: 200, epoch: 6 | loss: 0.0846281\n",
      "\tspeed: 0.0426s/iter; left time: 893.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0825281 Vali Loss: 0.0813871 Test Loss: 0.0863121\n",
      "Validation loss decreased (0.081926 --> 0.081387).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0798724\n",
      "\tspeed: 0.0772s/iter; left time: 1609.8902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0788262\n",
      "\tspeed: 0.0425s/iter; left time: 883.0556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0815098 Vali Loss: 0.0816422 Test Loss: 0.0858767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0786085\n",
      "\tspeed: 0.0763s/iter; left time: 1574.0331s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805364\n",
      "\tspeed: 0.0425s/iter; left time: 872.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0807263 Vali Loss: 0.0811599 Test Loss: 0.0855367\n",
      "Validation loss decreased (0.081387 --> 0.081160).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0814225\n",
      "\tspeed: 0.0767s/iter; left time: 1565.8337s\n",
      "\titers: 200, epoch: 9 | loss: 0.0816666\n",
      "\tspeed: 0.0425s/iter; left time: 863.4519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0800378 Vali Loss: 0.0809861 Test Loss: 0.0854724\n",
      "Validation loss decreased (0.081160 --> 0.080986).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825524\n",
      "\tspeed: 0.0765s/iter; left time: 1543.9701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0778407\n",
      "\tspeed: 0.0425s/iter; left time: 854.9402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0794228 Vali Loss: 0.0812544 Test Loss: 0.0852757\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0800575\n",
      "\tspeed: 0.0757s/iter; left time: 1511.8930s\n",
      "\titers: 200, epoch: 11 | loss: 0.0771785\n",
      "\tspeed: 0.0425s/iter; left time: 844.6290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0787776 Vali Loss: 0.0813259 Test Loss: 0.0853913\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0784340\n",
      "\tspeed: 0.0757s/iter; left time: 1495.1569s\n",
      "\titers: 200, epoch: 12 | loss: 0.0783378\n",
      "\tspeed: 0.0425s/iter; left time: 835.1028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0783605 Vali Loss: 0.0813706 Test Loss: 0.0855518\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0815431\n",
      "\tspeed: 0.0757s/iter; left time: 1478.1764s\n",
      "\titers: 200, epoch: 13 | loss: 0.0804912\n",
      "\tspeed: 0.0425s/iter; left time: 825.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0779481 Vali Loss: 0.0812705 Test Loss: 0.0853575\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0739288\n",
      "\tspeed: 0.0757s/iter; left time: 1461.2092s\n",
      "\titers: 200, epoch: 14 | loss: 0.0797356\n",
      "\tspeed: 0.0425s/iter; left time: 816.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0775050 Vali Loss: 0.0813125 Test Loss: 0.0853628\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0769799\n",
      "\tspeed: 0.0760s/iter; left time: 1449.5217s\n",
      "\titers: 200, epoch: 15 | loss: 0.0748191\n",
      "\tspeed: 0.0425s/iter; left time: 807.1497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0771534 Vali Loss: 0.0813744 Test Loss: 0.0854055\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0790950\n",
      "\tspeed: 0.0761s/iter; left time: 1435.8119s\n",
      "\titers: 200, epoch: 16 | loss: 0.0787604\n",
      "\tspeed: 0.0425s/iter; left time: 796.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0768260 Vali Loss: 0.0812937 Test Loss: 0.0853267\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0749521\n",
      "\tspeed: 0.0760s/iter; left time: 1416.8419s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770926\n",
      "\tspeed: 0.0425s/iter; left time: 787.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0765596 Vali Loss: 0.0813438 Test Loss: 0.0854356\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787697\n",
      "\tspeed: 0.0762s/iter; left time: 1403.4467s\n",
      "\titers: 200, epoch: 18 | loss: 0.0734112\n",
      "\tspeed: 0.0425s/iter; left time: 777.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0762949 Vali Loss: 0.0812519 Test Loss: 0.0853387\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0755710\n",
      "\tspeed: 0.0758s/iter; left time: 1378.9938s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773897\n",
      "\tspeed: 0.0425s/iter; left time: 768.9724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0761299 Vali Loss: 0.0814988 Test Loss: 0.0855493\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019644267857074738, rmse:0.140158012509346, mae:0.08547242730855942, rse:0.5304449796676636\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:37.41s\n",
      "Intermediate time for IT: 00h:41m:37.27s\n",
      "Total time: 03h:58m:51.50s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0213  0.1459  0.0891\n",
       "        96              0.0361  0.1899  0.1267\n",
       "        168             0.0395  0.1987  0.1348\n",
       "ES      24              0.0098  0.0990  0.0595\n",
       "        96              0.0185  0.1361  0.0864\n",
       "        168             0.0212  0.1456  0.0953\n",
       "FR      24              0.0101  0.1005  0.0552\n",
       "        96              0.0195  0.1397  0.0819\n",
       "        168             0.0216  0.1468  0.0891\n",
       "GB      24              0.0260  0.1614  0.1025\n",
       "        96              0.0431  0.2075  0.1421\n",
       "        168             0.0463  0.2151  0.1488\n",
       "IT      24              0.0102  0.1011  0.0572\n",
       "        96              0.0182  0.1350  0.0800\n",
       "        168             0.0198  0.1406  0.0857"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TS Decomposition + No RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2978909\n",
      "\tspeed: 0.1939s/iter; left time: 4323.4353s\n",
      "\titers: 200, epoch: 1 | loss: 0.2767988\n",
      "\tspeed: 0.2156s/iter; left time: 4787.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 224 | Train Loss: 0.3047940 Vali Loss: 0.2542751 Test Loss: 0.2520733\n",
      "Validation loss decreased (inf --> 0.254275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1704171\n",
      "\tspeed: 0.4150s/iter; left time: 9161.9562s\n",
      "\titers: 200, epoch: 2 | loss: 0.1421206\n",
      "\tspeed: 0.2168s/iter; left time: 4763.6454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.05s\n",
      "Steps: 224 | Train Loss: 0.1785526 Vali Loss: 0.1456259 Test Loss: 0.1532477\n",
      "Validation loss decreased (0.254275 --> 0.145626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1288416\n",
      "\tspeed: 0.3643s/iter; left time: 7960.8765s\n",
      "\titers: 200, epoch: 3 | loss: 0.1224569\n",
      "\tspeed: 0.2211s/iter; left time: 4809.9574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 224 | Train Loss: 0.1274180 Vali Loss: 0.1226776 Test Loss: 0.1287279\n",
      "Validation loss decreased (0.145626 --> 0.122678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1065466\n",
      "\tspeed: 0.3161s/iter; left time: 6835.8630s\n",
      "\titers: 200, epoch: 4 | loss: 0.1075251\n",
      "\tspeed: 0.2352s/iter; left time: 5064.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:52.48s\n",
      "Steps: 224 | Train Loss: 0.1097868 Vali Loss: 0.1121870 Test Loss: 0.1155603\n",
      "Validation loss decreased (0.122678 --> 0.112187).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0975109\n",
      "\tspeed: 0.3732s/iter; left time: 7989.0448s\n",
      "\titers: 200, epoch: 5 | loss: 0.0978445\n",
      "\tspeed: 0.2160s/iter; left time: 4601.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.65s\n",
      "Steps: 224 | Train Loss: 0.1018511 Vali Loss: 0.1071478 Test Loss: 0.1095119\n",
      "Validation loss decreased (0.112187 --> 0.107148).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0990339\n",
      "\tspeed: 0.2317s/iter; left time: 4908.4709s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977308\n",
      "\tspeed: 0.0682s/iter; left time: 1436.7371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0967687 Vali Loss: 0.1027594 Test Loss: 0.1059184\n",
      "Validation loss decreased (0.107148 --> 0.102759).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0925352\n",
      "\tspeed: 0.1321s/iter; left time: 2768.4167s\n",
      "\titers: 200, epoch: 7 | loss: 0.0914234\n",
      "\tspeed: 0.0828s/iter; left time: 1726.4455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 224 | Train Loss: 0.0925647 Vali Loss: 0.1002527 Test Loss: 0.1024643\n",
      "Validation loss decreased (0.102759 --> 0.100253).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0911155\n",
      "\tspeed: 0.1334s/iter; left time: 2765.1043s\n",
      "\titers: 200, epoch: 8 | loss: 0.0876559\n",
      "\tspeed: 0.0679s/iter; left time: 1401.1334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0905726 Vali Loss: 0.0992239 Test Loss: 0.1009226\n",
      "Validation loss decreased (0.100253 --> 0.099224).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0912128\n",
      "\tspeed: 0.1162s/iter; left time: 2384.1233s\n",
      "\titers: 200, epoch: 9 | loss: 0.0885861\n",
      "\tspeed: 0.0678s/iter; left time: 1383.4284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0881866 Vali Loss: 0.0977143 Test Loss: 0.0998565\n",
      "Validation loss decreased (0.099224 --> 0.097714).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0831624\n",
      "\tspeed: 0.1163s/iter; left time: 2359.1436s\n",
      "\titers: 200, epoch: 10 | loss: 0.0834773\n",
      "\tspeed: 0.0678s/iter; left time: 1367.6684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0870337 Vali Loss: 0.0983204 Test Loss: 0.0998652\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0881352\n",
      "\tspeed: 0.1155s/iter; left time: 2317.6996s\n",
      "\titers: 200, epoch: 11 | loss: 0.0902307\n",
      "\tspeed: 0.0678s/iter; left time: 1352.6715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0862425 Vali Loss: 0.0966851 Test Loss: 0.0991545\n",
      "Validation loss decreased (0.097714 --> 0.096685).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0859955\n",
      "\tspeed: 0.1164s/iter; left time: 2309.8704s\n",
      "\titers: 200, epoch: 12 | loss: 0.0856238\n",
      "\tspeed: 0.0678s/iter; left time: 1337.8706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0852433 Vali Loss: 0.0958275 Test Loss: 0.0981066\n",
      "Validation loss decreased (0.096685 --> 0.095827).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0806743\n",
      "\tspeed: 0.1162s/iter; left time: 2279.8900s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821045\n",
      "\tspeed: 0.0678s/iter; left time: 1323.6363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0843863 Vali Loss: 0.0952404 Test Loss: 0.0974914\n",
      "Validation loss decreased (0.095827 --> 0.095240).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0853380\n",
      "\tspeed: 0.1165s/iter; left time: 2258.9018s\n",
      "\titers: 200, epoch: 14 | loss: 0.0832664\n",
      "\tspeed: 0.0678s/iter; left time: 1308.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0837149 Vali Loss: 0.0948896 Test Loss: 0.0978565\n",
      "Validation loss decreased (0.095240 --> 0.094890).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0840781\n",
      "\tspeed: 0.1153s/iter; left time: 2209.5833s\n",
      "\titers: 200, epoch: 15 | loss: 0.0825981\n",
      "\tspeed: 0.0678s/iter; left time: 1292.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 224 | Train Loss: 0.0832805 Vali Loss: 0.0949776 Test Loss: 0.0973105\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0833322\n",
      "\tspeed: 0.1152s/iter; left time: 2182.7749s\n",
      "\titers: 200, epoch: 16 | loss: 0.0843381\n",
      "\tspeed: 0.0679s/iter; left time: 1279.7542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0826409 Vali Loss: 0.0944713 Test Loss: 0.0970281\n",
      "Validation loss decreased (0.094890 --> 0.094471).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0795454\n",
      "\tspeed: 0.1158s/iter; left time: 2167.7027s\n",
      "\titers: 200, epoch: 17 | loss: 0.0823224\n",
      "\tspeed: 0.0678s/iter; left time: 1261.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0821974 Vali Loss: 0.0948820 Test Loss: 0.0973552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0835974\n",
      "\tspeed: 0.1169s/iter; left time: 2161.6513s\n",
      "\titers: 200, epoch: 18 | loss: 0.0800899\n",
      "\tspeed: 0.0678s/iter; left time: 1246.6609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0817051 Vali Loss: 0.0942920 Test Loss: 0.0968263\n",
      "Validation loss decreased (0.094471 --> 0.094292).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0792392\n",
      "\tspeed: 0.1172s/iter; left time: 2140.6818s\n",
      "\titers: 200, epoch: 19 | loss: 0.0829155\n",
      "\tspeed: 0.0680s/iter; left time: 1234.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0815730 Vali Loss: 0.0947952 Test Loss: 0.0972022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0847640\n",
      "\tspeed: 0.1150s/iter; left time: 2075.1374s\n",
      "\titers: 200, epoch: 20 | loss: 0.0795714\n",
      "\tspeed: 0.0678s/iter; left time: 1216.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.32s\n",
      "Steps: 224 | Train Loss: 0.0811176 Vali Loss: 0.0934235 Test Loss: 0.0957889\n",
      "Validation loss decreased (0.094292 --> 0.093424).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0765191\n",
      "\tspeed: 0.1157s/iter; left time: 2061.5601s\n",
      "\titers: 200, epoch: 21 | loss: 0.0820356\n",
      "\tspeed: 0.0678s/iter; left time: 1201.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 224 | Train Loss: 0.0807856 Vali Loss: 0.0934691 Test Loss: 0.0957195\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0778834\n",
      "\tspeed: 0.1155s/iter; left time: 2032.0366s\n",
      "\titers: 200, epoch: 22 | loss: 0.0771559\n",
      "\tspeed: 0.0677s/iter; left time: 1184.5926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0805214 Vali Loss: 0.0942051 Test Loss: 0.0964066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0760334\n",
      "\tspeed: 0.1158s/iter; left time: 2012.0045s\n",
      "\titers: 200, epoch: 23 | loss: 0.0832556\n",
      "\tspeed: 0.0678s/iter; left time: 1171.6624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0802960 Vali Loss: 0.0933046 Test Loss: 0.0958302\n",
      "Validation loss decreased (0.093424 --> 0.093305).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0816744\n",
      "\tspeed: 0.1153s/iter; left time: 1976.8887s\n",
      "\titers: 200, epoch: 24 | loss: 0.0747576\n",
      "\tspeed: 0.0678s/iter; left time: 1155.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0801633 Vali Loss: 0.0930106 Test Loss: 0.0952925\n",
      "Validation loss decreased (0.093305 --> 0.093011).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0799048\n",
      "\tspeed: 0.1157s/iter; left time: 1958.7648s\n",
      "\titers: 200, epoch: 25 | loss: 0.0818526\n",
      "\tspeed: 0.0677s/iter; left time: 1139.8052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0799082 Vali Loss: 0.0927589 Test Loss: 0.0952428\n",
      "Validation loss decreased (0.093011 --> 0.092759).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0745649\n",
      "\tspeed: 0.1151s/iter; left time: 1922.0338s\n",
      "\titers: 200, epoch: 26 | loss: 0.0748562\n",
      "\tspeed: 0.0677s/iter; left time: 1123.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.31s\n",
      "Steps: 224 | Train Loss: 0.0798094 Vali Loss: 0.0936600 Test Loss: 0.0959827\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0785599\n",
      "\tspeed: 0.1148s/iter; left time: 1890.8345s\n",
      "\titers: 200, epoch: 27 | loss: 0.0821760\n",
      "\tspeed: 0.0677s/iter; left time: 1108.4668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.32s\n",
      "Steps: 224 | Train Loss: 0.0796826 Vali Loss: 0.0932283 Test Loss: 0.0955293\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0756524\n",
      "\tspeed: 0.1148s/iter; left time: 1865.8474s\n",
      "\titers: 200, epoch: 28 | loss: 0.0812988\n",
      "\tspeed: 0.0678s/iter; left time: 1095.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 224 | Train Loss: 0.0795731 Vali Loss: 0.0926397 Test Loss: 0.0950567\n",
      "Validation loss decreased (0.092759 --> 0.092640).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0794676\n",
      "\tspeed: 0.1153s/iter; left time: 1847.8171s\n",
      "\titers: 200, epoch: 29 | loss: 0.0814979\n",
      "\tspeed: 0.0678s/iter; left time: 1079.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0793656 Vali Loss: 0.0924627 Test Loss: 0.0952915\n",
      "Validation loss decreased (0.092640 --> 0.092463).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0827879\n",
      "\tspeed: 0.1154s/iter; left time: 1824.4542s\n",
      "\titers: 200, epoch: 30 | loss: 0.0792145\n",
      "\tspeed: 0.0677s/iter; left time: 1063.9502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0792429 Vali Loss: 0.0927997 Test Loss: 0.0953509\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0782702\n",
      "\tspeed: 0.1168s/iter; left time: 1819.4653s\n",
      "\titers: 200, epoch: 31 | loss: 0.0743653\n",
      "\tspeed: 0.0679s/iter; left time: 1050.4481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0792268 Vali Loss: 0.0921765 Test Loss: 0.0948172\n",
      "Validation loss decreased (0.092463 --> 0.092176).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0790537\n",
      "\tspeed: 0.1172s/iter; left time: 1799.2368s\n",
      "\titers: 200, epoch: 32 | loss: 0.0791195\n",
      "\tspeed: 0.0683s/iter; left time: 1042.5354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0790989 Vali Loss: 0.0921477 Test Loss: 0.0947526\n",
      "Validation loss decreased (0.092176 --> 0.092148).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0772805\n",
      "\tspeed: 0.1168s/iter; left time: 1767.3392s\n",
      "\titers: 200, epoch: 33 | loss: 0.0748811\n",
      "\tspeed: 0.0677s/iter; left time: 1018.3775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0789695 Vali Loss: 0.0923094 Test Loss: 0.0947423\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0797106\n",
      "\tspeed: 0.1150s/iter; left time: 1714.9655s\n",
      "\titers: 200, epoch: 34 | loss: 0.0836611\n",
      "\tspeed: 0.0677s/iter; left time: 1003.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.31s\n",
      "Steps: 224 | Train Loss: 0.0788768 Vali Loss: 0.0923987 Test Loss: 0.0948471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0801443\n",
      "\tspeed: 0.1160s/iter; left time: 1704.0420s\n",
      "\titers: 200, epoch: 35 | loss: 0.0746493\n",
      "\tspeed: 0.0681s/iter; left time: 992.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0789255 Vali Loss: 0.0923144 Test Loss: 0.0947724\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0748330\n",
      "\tspeed: 0.1151s/iter; left time: 1663.8649s\n",
      "\titers: 200, epoch: 36 | loss: 0.0810352\n",
      "\tspeed: 0.0678s/iter; left time: 973.1275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.32s\n",
      "Steps: 224 | Train Loss: 0.0788073 Vali Loss: 0.0922010 Test Loss: 0.0946740\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0791292\n",
      "\tspeed: 0.1154s/iter; left time: 1643.5854s\n",
      "\titers: 200, epoch: 37 | loss: 0.0799018\n",
      "\tspeed: 0.0677s/iter; left time: 956.9166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0788299 Vali Loss: 0.0921494 Test Loss: 0.0945371\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0842341\n",
      "\tspeed: 0.1154s/iter; left time: 1617.3613s\n",
      "\titers: 200, epoch: 38 | loss: 0.0791767\n",
      "\tspeed: 0.0678s/iter; left time: 942.6239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0787951 Vali Loss: 0.0920889 Test Loss: 0.0947171\n",
      "Validation loss decreased (0.092148 --> 0.092089).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0801652\n",
      "\tspeed: 0.1167s/iter; left time: 1608.9441s\n",
      "\titers: 200, epoch: 39 | loss: 0.0768192\n",
      "\tspeed: 0.0683s/iter; left time: 934.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0787082 Vali Loss: 0.0919955 Test Loss: 0.0946162\n",
      "Validation loss decreased (0.092089 --> 0.091996).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0783560\n",
      "\tspeed: 0.1163s/iter; left time: 1578.1536s\n",
      "\titers: 200, epoch: 40 | loss: 0.0765361\n",
      "\tspeed: 0.0682s/iter; left time: 918.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0786940 Vali Loss: 0.0920186 Test Loss: 0.0946152\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0777341\n",
      "\tspeed: 0.1161s/iter; left time: 1548.4885s\n",
      "\titers: 200, epoch: 41 | loss: 0.0750562\n",
      "\tspeed: 0.0681s/iter; left time: 902.1918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0786603 Vali Loss: 0.0920711 Test Loss: 0.0946730\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0769340\n",
      "\tspeed: 0.1156s/iter; left time: 1516.3179s\n",
      "\titers: 200, epoch: 42 | loss: 0.0777760\n",
      "\tspeed: 0.0683s/iter; left time: 889.4595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0786128 Vali Loss: 0.0920917 Test Loss: 0.0946780\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0799446\n",
      "\tspeed: 0.1159s/iter; left time: 1493.9207s\n",
      "\titers: 200, epoch: 43 | loss: 0.0753966\n",
      "\tspeed: 0.0679s/iter; left time: 868.4867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0785908 Vali Loss: 0.0919893 Test Loss: 0.0945267\n",
      "Validation loss decreased (0.091996 --> 0.091989).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0760699\n",
      "\tspeed: 0.1168s/iter; left time: 1479.3264s\n",
      "\titers: 200, epoch: 44 | loss: 0.0803866\n",
      "\tspeed: 0.0677s/iter; left time: 850.6048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0785387 Vali Loss: 0.0919314 Test Loss: 0.0945270\n",
      "Validation loss decreased (0.091989 --> 0.091931).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0779458\n",
      "\tspeed: 0.1162s/iter; left time: 1446.2722s\n",
      "\titers: 200, epoch: 45 | loss: 0.0797947\n",
      "\tspeed: 0.0679s/iter; left time: 837.7718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0786082 Vali Loss: 0.0919874 Test Loss: 0.0945368\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0788271\n",
      "\tspeed: 0.1156s/iter; left time: 1412.9598s\n",
      "\titers: 200, epoch: 46 | loss: 0.0826278\n",
      "\tspeed: 0.0682s/iter; left time: 826.6284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0785269 Vali Loss: 0.0919217 Test Loss: 0.0945333\n",
      "Validation loss decreased (0.091931 --> 0.091922).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0742670\n",
      "\tspeed: 0.1167s/iter; left time: 1400.0952s\n",
      "\titers: 200, epoch: 47 | loss: 0.0766125\n",
      "\tspeed: 0.0677s/iter; left time: 805.8862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0784700 Vali Loss: 0.0920018 Test Loss: 0.0945165\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0792254\n",
      "\tspeed: 0.1152s/iter; left time: 1356.0027s\n",
      "\titers: 200, epoch: 48 | loss: 0.0763653\n",
      "\tspeed: 0.0677s/iter; left time: 790.3346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.32s\n",
      "Steps: 224 | Train Loss: 0.0785080 Vali Loss: 0.0921359 Test Loss: 0.0946416\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0801329\n",
      "\tspeed: 0.1151s/iter; left time: 1329.1835s\n",
      "\titers: 200, epoch: 49 | loss: 0.0800373\n",
      "\tspeed: 0.0677s/iter; left time: 775.5393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.31s\n",
      "Steps: 224 | Train Loss: 0.0784778 Vali Loss: 0.0919315 Test Loss: 0.0945129\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0810615\n",
      "\tspeed: 0.1146s/iter; left time: 1297.5633s\n",
      "\titers: 200, epoch: 50 | loss: 0.0758900\n",
      "\tspeed: 0.0679s/iter; left time: 762.5609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0784717 Vali Loss: 0.0919314 Test Loss: 0.0945211\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0878889\n",
      "\tspeed: 0.1156s/iter; left time: 1282.9746s\n",
      "\titers: 200, epoch: 51 | loss: 0.0715310\n",
      "\tspeed: 0.0678s/iter; left time: 746.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0785260 Vali Loss: 0.0919718 Test Loss: 0.0945974\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0766984\n",
      "\tspeed: 0.1152s/iter; left time: 1252.6211s\n",
      "\titers: 200, epoch: 52 | loss: 0.0839603\n",
      "\tspeed: 0.0677s/iter; left time: 730.0446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0785069 Vali Loss: 0.0917799 Test Loss: 0.0945156\n",
      "Validation loss decreased (0.091922 --> 0.091780).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0800196\n",
      "\tspeed: 0.1154s/iter; left time: 1229.3442s\n",
      "\titers: 200, epoch: 53 | loss: 0.0770552\n",
      "\tspeed: 0.0678s/iter; left time: 714.9985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:15.32s\n",
      "Steps: 224 | Train Loss: 0.0784705 Vali Loss: 0.0918002 Test Loss: 0.0945091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0797130\n",
      "\tspeed: 0.1153s/iter; left time: 1202.1875s\n",
      "\titers: 200, epoch: 54 | loss: 0.0776369\n",
      "\tspeed: 0.0677s/iter; left time: 699.6087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0784293 Vali Loss: 0.0919519 Test Loss: 0.0944459\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0821734\n",
      "\tspeed: 0.1149s/iter; left time: 1172.9206s\n",
      "\titers: 200, epoch: 55 | loss: 0.0822216\n",
      "\tspeed: 0.0677s/iter; left time: 684.0574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:15.30s\n",
      "Steps: 224 | Train Loss: 0.0784459 Vali Loss: 0.0917490 Test Loss: 0.0944411\n",
      "Validation loss decreased (0.091780 --> 0.091749).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0781090\n",
      "\tspeed: 0.1160s/iter; left time: 1157.7095s\n",
      "\titers: 200, epoch: 56 | loss: 0.0825971\n",
      "\tspeed: 0.0677s/iter; left time: 668.9731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0783196 Vali Loss: 0.0919006 Test Loss: 0.0945025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0796882\n",
      "\tspeed: 0.1153s/iter; left time: 1124.6838s\n",
      "\titers: 200, epoch: 57 | loss: 0.0865246\n",
      "\tspeed: 0.0678s/iter; left time: 654.7693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:15.32s\n",
      "Steps: 224 | Train Loss: 0.0785030 Vali Loss: 0.0920226 Test Loss: 0.0945935\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0808862\n",
      "\tspeed: 0.1153s/iter; left time: 1099.5067s\n",
      "\titers: 200, epoch: 58 | loss: 0.0788584\n",
      "\tspeed: 0.0677s/iter; left time: 638.9024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0784456 Vali Loss: 0.0920648 Test Loss: 0.0946312\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0804970\n",
      "\tspeed: 0.1157s/iter; left time: 1076.8021s\n",
      "\titers: 200, epoch: 59 | loss: 0.0764873\n",
      "\tspeed: 0.0679s/iter; left time: 625.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0783153 Vali Loss: 0.0919520 Test Loss: 0.0945309\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0788187\n",
      "\tspeed: 0.1164s/iter; left time: 1057.7520s\n",
      "\titers: 200, epoch: 60 | loss: 0.0784902\n",
      "\tspeed: 0.0684s/iter; left time: 614.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0784838 Vali Loss: 0.0919221 Test Loss: 0.0944278\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0781934\n",
      "\tspeed: 0.1161s/iter; left time: 1028.4806s\n",
      "\titers: 200, epoch: 61 | loss: 0.0824686\n",
      "\tspeed: 0.0680s/iter; left time: 595.8070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0784290 Vali Loss: 0.0917775 Test Loss: 0.0943640\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0788295\n",
      "\tspeed: 0.1154s/iter; left time: 996.6555s\n",
      "\titers: 200, epoch: 62 | loss: 0.0759531\n",
      "\tspeed: 0.0680s/iter; left time: 580.4722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0784045 Vali Loss: 0.0917812 Test Loss: 0.0944869\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0734253\n",
      "\tspeed: 0.1156s/iter; left time: 972.1395s\n",
      "\titers: 200, epoch: 63 | loss: 0.0805587\n",
      "\tspeed: 0.0678s/iter; left time: 563.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0783300 Vali Loss: 0.0921035 Test Loss: 0.0945612\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0776079\n",
      "\tspeed: 0.1150s/iter; left time: 941.3804s\n",
      "\titers: 200, epoch: 64 | loss: 0.0786827\n",
      "\tspeed: 0.0678s/iter; left time: 548.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:15.31s\n",
      "Steps: 224 | Train Loss: 0.0784039 Vali Loss: 0.0918755 Test Loss: 0.0944305\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0781739\n",
      "\tspeed: 0.1151s/iter; left time: 917.0137s\n",
      "\titers: 200, epoch: 65 | loss: 0.0752231\n",
      "\tspeed: 0.0677s/iter; left time: 532.4000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:15.30s\n",
      "Steps: 224 | Train Loss: 0.0782916 Vali Loss: 0.0919616 Test Loss: 0.0944755\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022536464035511017, rmse:0.15012149512767792, mae:0.09444105625152588, rse:0.5297995209693909\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3034369\n",
      "\tspeed: 0.0692s/iter; left time: 1543.3483s\n",
      "\titers: 200, epoch: 1 | loss: 0.2744068\n",
      "\tspeed: 0.0677s/iter; left time: 1502.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 224 | Train Loss: 0.3114059 Vali Loss: 0.2494376 Test Loss: 0.2484347\n",
      "Validation loss decreased (inf --> 0.249438).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1704506\n",
      "\tspeed: 0.1164s/iter; left time: 2570.1362s\n",
      "\titers: 200, epoch: 2 | loss: 0.1423444\n",
      "\tspeed: 0.0684s/iter; left time: 1502.4404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.1791122 Vali Loss: 0.1505764 Test Loss: 0.1606440\n",
      "Validation loss decreased (0.249438 --> 0.150576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1288595\n",
      "\tspeed: 0.1158s/iter; left time: 2529.5264s\n",
      "\titers: 200, epoch: 3 | loss: 0.1249609\n",
      "\tspeed: 0.0677s/iter; left time: 1472.7171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.1311316 Vali Loss: 0.1294106 Test Loss: 0.1341609\n",
      "Validation loss decreased (0.150576 --> 0.129411).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1105047\n",
      "\tspeed: 0.1155s/iter; left time: 2497.1736s\n",
      "\titers: 200, epoch: 4 | loss: 0.1054970\n",
      "\tspeed: 0.0677s/iter; left time: 1457.1224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 224 | Train Loss: 0.1120117 Vali Loss: 0.1125154 Test Loss: 0.1165762\n",
      "Validation loss decreased (0.129411 --> 0.112515).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1119368\n",
      "\tspeed: 0.1160s/iter; left time: 2482.8109s\n",
      "\titers: 200, epoch: 5 | loss: 0.1030139\n",
      "\tspeed: 0.0679s/iter; left time: 1445.9354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.1034172 Vali Loss: 0.1077994 Test Loss: 0.1115385\n",
      "Validation loss decreased (0.112515 --> 0.107799).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0970223\n",
      "\tspeed: 0.1161s/iter; left time: 2458.8083s\n",
      "\titers: 200, epoch: 6 | loss: 0.0955317\n",
      "\tspeed: 0.0678s/iter; left time: 1429.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0976440 Vali Loss: 0.1043911 Test Loss: 0.1066969\n",
      "Validation loss decreased (0.107799 --> 0.104391).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0931138\n",
      "\tspeed: 0.1172s/iter; left time: 2455.1793s\n",
      "\titers: 200, epoch: 7 | loss: 0.0961715\n",
      "\tspeed: 0.0684s/iter; left time: 1425.5851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0939700 Vali Loss: 0.1016874 Test Loss: 0.1061795\n",
      "Validation loss decreased (0.104391 --> 0.101687).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0950383\n",
      "\tspeed: 0.1202s/iter; left time: 2493.0290s\n",
      "\titers: 200, epoch: 8 | loss: 0.0919921\n",
      "\tspeed: 0.0678s/iter; left time: 1398.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0914667 Vali Loss: 0.0996692 Test Loss: 0.1029872\n",
      "Validation loss decreased (0.101687 --> 0.099669).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0889014\n",
      "\tspeed: 0.1162s/iter; left time: 2382.6426s\n",
      "\titers: 200, epoch: 9 | loss: 0.0871516\n",
      "\tspeed: 0.0678s/iter; left time: 1383.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0896290 Vali Loss: 0.0994177 Test Loss: 0.1021520\n",
      "Validation loss decreased (0.099669 --> 0.099418).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0893146\n",
      "\tspeed: 0.1167s/iter; left time: 2367.7167s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846162\n",
      "\tspeed: 0.0679s/iter; left time: 1369.8917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0886544 Vali Loss: 0.0978712 Test Loss: 0.1009321\n",
      "Validation loss decreased (0.099418 --> 0.097871).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0872007\n",
      "\tspeed: 0.2431s/iter; left time: 4877.4501s\n",
      "\titers: 200, epoch: 11 | loss: 0.0866899\n",
      "\tspeed: 0.1136s/iter; left time: 2268.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.65s\n",
      "Steps: 224 | Train Loss: 0.0872330 Vali Loss: 0.0970078 Test Loss: 0.0998414\n",
      "Validation loss decreased (0.097871 --> 0.097008).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0823398\n",
      "\tspeed: 0.1193s/iter; left time: 2366.8623s\n",
      "\titers: 200, epoch: 12 | loss: 0.0839188\n",
      "\tspeed: 0.0706s/iter; left time: 1394.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.99s\n",
      "Steps: 224 | Train Loss: 0.0865644 Vali Loss: 0.0987337 Test Loss: 0.1008521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0890727\n",
      "\tspeed: 0.1209s/iter; left time: 2371.4940s\n",
      "\titers: 200, epoch: 13 | loss: 0.0827696\n",
      "\tspeed: 0.0683s/iter; left time: 1333.5388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 224 | Train Loss: 0.0860322 Vali Loss: 0.0965171 Test Loss: 0.0996699\n",
      "Validation loss decreased (0.097008 --> 0.096517).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0857354\n",
      "\tspeed: 0.1189s/iter; left time: 2305.4964s\n",
      "\titers: 200, epoch: 14 | loss: 0.0821219\n",
      "\tspeed: 0.0683s/iter; left time: 1317.1821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0853435 Vali Loss: 0.0956950 Test Loss: 0.0982409\n",
      "Validation loss decreased (0.096517 --> 0.095695).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0792053\n",
      "\tspeed: 0.1182s/iter; left time: 2265.0352s\n",
      "\titers: 200, epoch: 15 | loss: 0.0821431\n",
      "\tspeed: 0.0682s/iter; left time: 1300.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0848972 Vali Loss: 0.0953568 Test Loss: 0.0978062\n",
      "Validation loss decreased (0.095695 --> 0.095357).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0870282\n",
      "\tspeed: 0.1186s/iter; left time: 2247.3261s\n",
      "\titers: 200, epoch: 16 | loss: 0.0911901\n",
      "\tspeed: 0.0684s/iter; left time: 1289.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0841821 Vali Loss: 0.0950242 Test Loss: 0.0977606\n",
      "Validation loss decreased (0.095357 --> 0.095024).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0803875\n",
      "\tspeed: 0.1183s/iter; left time: 2213.8865s\n",
      "\titers: 200, epoch: 17 | loss: 0.0848739\n",
      "\tspeed: 0.0683s/iter; left time: 1270.8907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0840695 Vali Loss: 0.0957890 Test Loss: 0.0990289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0872624\n",
      "\tspeed: 0.1167s/iter; left time: 2158.3958s\n",
      "\titers: 200, epoch: 18 | loss: 0.0843478\n",
      "\tspeed: 0.0723s/iter; left time: 1330.3261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:16.07s\n",
      "Steps: 224 | Train Loss: 0.0834684 Vali Loss: 0.0951037 Test Loss: 0.0980896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0887336\n",
      "\tspeed: 0.1184s/iter; left time: 2162.1894s\n",
      "\titers: 200, epoch: 19 | loss: 0.0835272\n",
      "\tspeed: 0.0685s/iter; left time: 1243.8211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0832153 Vali Loss: 0.0952695 Test Loss: 0.0979027\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764513\n",
      "\tspeed: 0.1183s/iter; left time: 2133.9670s\n",
      "\titers: 200, epoch: 20 | loss: 0.0818660\n",
      "\tspeed: 0.0683s/iter; left time: 1224.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0826960 Vali Loss: 0.0944566 Test Loss: 0.0972297\n",
      "Validation loss decreased (0.095024 --> 0.094457).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0792475\n",
      "\tspeed: 0.1188s/iter; left time: 2117.4525s\n",
      "\titers: 200, epoch: 21 | loss: 0.0801615\n",
      "\tspeed: 0.0683s/iter; left time: 1211.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0826576 Vali Loss: 0.0967829 Test Loss: 0.0989861\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0837895\n",
      "\tspeed: 0.1183s/iter; left time: 2080.9624s\n",
      "\titers: 200, epoch: 22 | loss: 0.0782333\n",
      "\tspeed: 0.0681s/iter; left time: 1192.2853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0822480 Vali Loss: 0.0944862 Test Loss: 0.0970916\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0788991\n",
      "\tspeed: 0.1166s/iter; left time: 2025.5857s\n",
      "\titers: 200, epoch: 23 | loss: 0.0825829\n",
      "\tspeed: 0.0683s/iter; left time: 1179.7612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0819289 Vali Loss: 0.0940652 Test Loss: 0.0967649\n",
      "Validation loss decreased (0.094457 --> 0.094065).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0797777\n",
      "\tspeed: 0.1179s/iter; left time: 2022.1567s\n",
      "\titers: 200, epoch: 24 | loss: 0.0828606\n",
      "\tspeed: 0.0687s/iter; left time: 1171.5326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0819166 Vali Loss: 0.0935673 Test Loss: 0.0966664\n",
      "Validation loss decreased (0.094065 --> 0.093567).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0782837\n",
      "\tspeed: 0.1180s/iter; left time: 1997.4561s\n",
      "\titers: 200, epoch: 25 | loss: 0.0905191\n",
      "\tspeed: 0.0679s/iter; left time: 1142.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0816121 Vali Loss: 0.0938070 Test Loss: 0.0964996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0811846\n",
      "\tspeed: 0.1181s/iter; left time: 1972.7784s\n",
      "\titers: 200, epoch: 26 | loss: 0.0793279\n",
      "\tspeed: 0.0684s/iter; left time: 1135.2064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0813010 Vali Loss: 0.0944889 Test Loss: 0.0970466\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0827453\n",
      "\tspeed: 0.1179s/iter; left time: 1942.1205s\n",
      "\titers: 200, epoch: 27 | loss: 0.0806888\n",
      "\tspeed: 0.0696s/iter; left time: 1139.5713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0813680 Vali Loss: 0.0934313 Test Loss: 0.0963313\n",
      "Validation loss decreased (0.093567 --> 0.093431).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0821765\n",
      "\tspeed: 0.1157s/iter; left time: 1880.3006s\n",
      "\titers: 200, epoch: 28 | loss: 0.0809591\n",
      "\tspeed: 0.0677s/iter; left time: 1093.9687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 224 | Train Loss: 0.0811195 Vali Loss: 0.0936475 Test Loss: 0.0963400\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0813552\n",
      "\tspeed: 0.1151s/iter; left time: 1845.4050s\n",
      "\titers: 200, epoch: 29 | loss: 0.0802234\n",
      "\tspeed: 0.0677s/iter; left time: 1077.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0809724 Vali Loss: 0.0933138 Test Loss: 0.0961339\n",
      "Validation loss decreased (0.093431 --> 0.093314).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0765207\n",
      "\tspeed: 0.1190s/iter; left time: 1881.4595s\n",
      "\titers: 200, epoch: 30 | loss: 0.0824903\n",
      "\tspeed: 0.0995s/iter; left time: 1563.0671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.82s\n",
      "Steps: 224 | Train Loss: 0.0808817 Vali Loss: 0.0930901 Test Loss: 0.0960320\n",
      "Validation loss decreased (0.093314 --> 0.093090).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0807506\n",
      "\tspeed: 0.1229s/iter; left time: 1914.3562s\n",
      "\titers: 200, epoch: 31 | loss: 0.0852025\n",
      "\tspeed: 0.0694s/iter; left time: 1073.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 224 | Train Loss: 0.0806162 Vali Loss: 0.0930134 Test Loss: 0.0960329\n",
      "Validation loss decreased (0.093090 --> 0.093013).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0833379\n",
      "\tspeed: 0.3373s/iter; left time: 5180.2444s\n",
      "\titers: 200, epoch: 32 | loss: 0.0812490\n",
      "\tspeed: 0.0700s/iter; left time: 1068.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:23.88s\n",
      "Steps: 224 | Train Loss: 0.0806192 Vali Loss: 0.0929787 Test Loss: 0.0957522\n",
      "Validation loss decreased (0.093013 --> 0.092979).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0775918\n",
      "\tspeed: 0.1174s/iter; left time: 1776.4581s\n",
      "\titers: 200, epoch: 33 | loss: 0.0825094\n",
      "\tspeed: 0.0720s/iter; left time: 1082.8958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0805995 Vali Loss: 0.0929855 Test Loss: 0.0957746\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0804532\n",
      "\tspeed: 0.1171s/iter; left time: 1746.1131s\n",
      "\titers: 200, epoch: 34 | loss: 0.0826068\n",
      "\tspeed: 0.0682s/iter; left time: 1009.7905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0804968 Vali Loss: 0.0937455 Test Loss: 0.0964407\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0823962\n",
      "\tspeed: 0.1163s/iter; left time: 1707.9108s\n",
      "\titers: 200, epoch: 35 | loss: 0.0787133\n",
      "\tspeed: 0.0682s/iter; left time: 994.1967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0803679 Vali Loss: 0.0930884 Test Loss: 0.0958810\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0813658\n",
      "\tspeed: 0.1161s/iter; left time: 1679.3671s\n",
      "\titers: 200, epoch: 36 | loss: 0.0818544\n",
      "\tspeed: 0.0681s/iter; left time: 978.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0803174 Vali Loss: 0.0927824 Test Loss: 0.0957256\n",
      "Validation loss decreased (0.092979 --> 0.092782).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0873906\n",
      "\tspeed: 0.1177s/iter; left time: 1675.1554s\n",
      "\titers: 200, epoch: 37 | loss: 0.0810859\n",
      "\tspeed: 0.0691s/iter; left time: 976.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.84s\n",
      "Steps: 224 | Train Loss: 0.0804524 Vali Loss: 0.0929977 Test Loss: 0.0958103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0765538\n",
      "\tspeed: 0.1198s/iter; left time: 1679.1906s\n",
      "\titers: 200, epoch: 38 | loss: 0.0844332\n",
      "\tspeed: 0.0679s/iter; left time: 945.2555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0802362 Vali Loss: 0.0928513 Test Loss: 0.0957061\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0817609\n",
      "\tspeed: 0.1160s/iter; left time: 1598.8552s\n",
      "\titers: 200, epoch: 39 | loss: 0.0829158\n",
      "\tspeed: 0.0681s/iter; left time: 932.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0802491 Vali Loss: 0.0924879 Test Loss: 0.0955260\n",
      "Validation loss decreased (0.092782 --> 0.092488).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0838202\n",
      "\tspeed: 0.1172s/iter; left time: 1589.2299s\n",
      "\titers: 200, epoch: 40 | loss: 0.0779385\n",
      "\tspeed: 0.0680s/iter; left time: 915.4113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0801451 Vali Loss: 0.0933164 Test Loss: 0.0959587\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0767510\n",
      "\tspeed: 0.1166s/iter; left time: 1554.9071s\n",
      "\titers: 200, epoch: 41 | loss: 0.0798483\n",
      "\tspeed: 0.0681s/iter; left time: 901.0627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0800887 Vali Loss: 0.0926928 Test Loss: 0.0957201\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0793392\n",
      "\tspeed: 0.1162s/iter; left time: 1524.4598s\n",
      "\titers: 200, epoch: 42 | loss: 0.0814923\n",
      "\tspeed: 0.0678s/iter; left time: 883.0807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0800602 Vali Loss: 0.0928297 Test Loss: 0.0956234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0856377\n",
      "\tspeed: 0.1219s/iter; left time: 1571.3456s\n",
      "\titers: 200, epoch: 43 | loss: 0.0784587\n",
      "\tspeed: 0.0690s/iter; left time: 882.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:16.05s\n",
      "Steps: 224 | Train Loss: 0.0801263 Vali Loss: 0.0926303 Test Loss: 0.0955368\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0777858\n",
      "\tspeed: 0.1198s/iter; left time: 1517.5269s\n",
      "\titers: 200, epoch: 44 | loss: 0.0791884\n",
      "\tspeed: 0.0681s/iter; left time: 856.2736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0800520 Vali Loss: 0.0927855 Test Loss: 0.0956724\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0807493\n",
      "\tspeed: 0.1161s/iter; left time: 1444.8835s\n",
      "\titers: 200, epoch: 45 | loss: 0.0814552\n",
      "\tspeed: 0.0679s/iter; left time: 838.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0800503 Vali Loss: 0.0926700 Test Loss: 0.0955993\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0791580\n",
      "\tspeed: 0.1166s/iter; left time: 1424.7202s\n",
      "\titers: 200, epoch: 46 | loss: 0.0859638\n",
      "\tspeed: 0.0680s/iter; left time: 824.3143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0800218 Vali Loss: 0.0928298 Test Loss: 0.0957453\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0781649\n",
      "\tspeed: 0.1159s/iter; left time: 1391.0121s\n",
      "\titers: 200, epoch: 47 | loss: 0.0809923\n",
      "\tspeed: 0.0678s/iter; left time: 807.1429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0799785 Vali Loss: 0.0926413 Test Loss: 0.0954914\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0864054\n",
      "\tspeed: 0.1160s/iter; left time: 1366.0973s\n",
      "\titers: 200, epoch: 48 | loss: 0.0834777\n",
      "\tspeed: 0.0681s/iter; left time: 794.6485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0800955 Vali Loss: 0.0926520 Test Loss: 0.0955038\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0829252\n",
      "\tspeed: 0.1171s/iter; left time: 1352.7958s\n",
      "\titers: 200, epoch: 49 | loss: 0.0846550\n",
      "\tspeed: 0.0681s/iter; left time: 779.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0800592 Vali Loss: 0.0926591 Test Loss: 0.0955234\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022697528824210167, rmse:0.15065698325634003, mae:0.09552601724863052, rse:0.5316893458366394\n",
      "Intermediate time for DE and pred_len 24: 00h:39m:24.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3059685\n",
      "\tspeed: 0.0879s/iter; left time: 1960.0212s\n",
      "\titers: 200, epoch: 1 | loss: 0.2738290\n",
      "\tspeed: 0.0688s/iter; left time: 1526.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.90s\n",
      "Steps: 224 | Train Loss: 0.3101150 Vali Loss: 0.2563634 Test Loss: 0.2558177\n",
      "Validation loss decreased (inf --> 0.256363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1783906\n",
      "\tspeed: 0.1197s/iter; left time: 2641.8241s\n",
      "\titers: 200, epoch: 2 | loss: 0.1559198\n",
      "\tspeed: 0.0720s/iter; left time: 1583.2014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.91s\n",
      "Steps: 224 | Train Loss: 0.1848965 Vali Loss: 0.1677316 Test Loss: 0.1801729\n",
      "Validation loss decreased (0.256363 --> 0.167732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1471034\n",
      "\tspeed: 0.1197s/iter; left time: 2614.9998s\n",
      "\titers: 200, epoch: 3 | loss: 0.1369162\n",
      "\tspeed: 0.0684s/iter; left time: 1487.6930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1456007 Vali Loss: 0.1434932 Test Loss: 0.1546572\n",
      "Validation loss decreased (0.167732 --> 0.143493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1284247\n",
      "\tspeed: 0.1181s/iter; left time: 2553.5292s\n",
      "\titers: 200, epoch: 4 | loss: 0.1213347\n",
      "\tspeed: 0.0684s/iter; left time: 1471.9084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.1298016 Vali Loss: 0.1343086 Test Loss: 0.1449501\n",
      "Validation loss decreased (0.143493 --> 0.134309).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1235507\n",
      "\tspeed: 0.1183s/iter; left time: 2531.7089s\n",
      "\titers: 200, epoch: 5 | loss: 0.1193377\n",
      "\tspeed: 0.1088s/iter; left time: 2317.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:19.57s\n",
      "Steps: 224 | Train Loss: 0.1223353 Vali Loss: 0.1316904 Test Loss: 0.1437594\n",
      "Validation loss decreased (0.134309 --> 0.131690).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1177449\n",
      "\tspeed: 0.1191s/iter; left time: 2523.0808s\n",
      "\titers: 200, epoch: 6 | loss: 0.1206766\n",
      "\tspeed: 0.0683s/iter; left time: 1440.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.1175022 Vali Loss: 0.1294522 Test Loss: 0.1411384\n",
      "Validation loss decreased (0.131690 --> 0.129452).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1110433\n",
      "\tspeed: 0.1187s/iter; left time: 2487.7225s\n",
      "\titers: 200, epoch: 7 | loss: 0.1151398\n",
      "\tspeed: 0.0683s/iter; left time: 1424.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.1142460 Vali Loss: 0.1283847 Test Loss: 0.1400687\n",
      "Validation loss decreased (0.129452 --> 0.128385).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1104650\n",
      "\tspeed: 0.1192s/iter; left time: 2471.3152s\n",
      "\titers: 200, epoch: 8 | loss: 0.1105687\n",
      "\tspeed: 0.0686s/iter; left time: 1414.5461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1119440 Vali Loss: 0.1257421 Test Loss: 0.1372591\n",
      "Validation loss decreased (0.128385 --> 0.125742).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1057127\n",
      "\tspeed: 0.1194s/iter; left time: 2448.7580s\n",
      "\titers: 200, epoch: 9 | loss: 0.1114007\n",
      "\tspeed: 0.0684s/iter; left time: 1396.9279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1103601 Vali Loss: 0.1249790 Test Loss: 0.1363165\n",
      "Validation loss decreased (0.125742 --> 0.124979).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1055751\n",
      "\tspeed: 0.1195s/iter; left time: 2424.4855s\n",
      "\titers: 200, epoch: 10 | loss: 0.1075370\n",
      "\tspeed: 0.0685s/iter; left time: 1383.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.1090177 Vali Loss: 0.1246101 Test Loss: 0.1359729\n",
      "Validation loss decreased (0.124979 --> 0.124610).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1059352\n",
      "\tspeed: 0.1193s/iter; left time: 2393.9168s\n",
      "\titers: 200, epoch: 11 | loss: 0.1062222\n",
      "\tspeed: 0.0684s/iter; left time: 1365.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1084404 Vali Loss: 0.1228595 Test Loss: 0.1335179\n",
      "Validation loss decreased (0.124610 --> 0.122859).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1102383\n",
      "\tspeed: 0.1268s/iter; left time: 2515.4803s\n",
      "\titers: 200, epoch: 12 | loss: 0.1100874\n",
      "\tspeed: 0.0701s/iter; left time: 1384.4985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.93s\n",
      "Steps: 224 | Train Loss: 0.1076398 Vali Loss: 0.1246835 Test Loss: 0.1377749\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1067273\n",
      "\tspeed: 0.3437s/iter; left time: 6741.2634s\n",
      "\titers: 200, epoch: 13 | loss: 0.1033216\n",
      "\tspeed: 0.0686s/iter; left time: 1339.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:22.49s\n",
      "Steps: 224 | Train Loss: 0.1068675 Vali Loss: 0.1252436 Test Loss: 0.1377208\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1078398\n",
      "\tspeed: 0.1215s/iter; left time: 2355.5401s\n",
      "\titers: 200, epoch: 14 | loss: 0.1092169\n",
      "\tspeed: 0.0685s/iter; left time: 1321.4575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.87s\n",
      "Steps: 224 | Train Loss: 0.1065059 Vali Loss: 0.1240375 Test Loss: 0.1363292\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1020360\n",
      "\tspeed: 0.1178s/iter; left time: 2256.7694s\n",
      "\titers: 200, epoch: 15 | loss: 0.1042356\n",
      "\tspeed: 0.0686s/iter; left time: 1307.2267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.1057080 Vali Loss: 0.1239064 Test Loss: 0.1374485\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1056080\n",
      "\tspeed: 0.1177s/iter; left time: 2228.5796s\n",
      "\titers: 200, epoch: 16 | loss: 0.1025698\n",
      "\tspeed: 0.0690s/iter; left time: 1299.9694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.1052057 Vali Loss: 0.1234362 Test Loss: 0.1363141\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1016797\n",
      "\tspeed: 0.1188s/iter; left time: 2222.7135s\n",
      "\titers: 200, epoch: 17 | loss: 0.1011808\n",
      "\tspeed: 0.0683s/iter; left time: 1271.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1050238 Vali Loss: 0.1229588 Test Loss: 0.1360357\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1062100\n",
      "\tspeed: 0.1191s/iter; left time: 2203.4096s\n",
      "\titers: 200, epoch: 18 | loss: 0.1051248\n",
      "\tspeed: 0.0687s/iter; left time: 1264.0055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.1045724 Vali Loss: 0.1228588 Test Loss: 0.1359600\n",
      "Validation loss decreased (0.122859 --> 0.122859).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1050163\n",
      "\tspeed: 0.1193s/iter; left time: 2179.0484s\n",
      "\titers: 200, epoch: 19 | loss: 0.1050062\n",
      "\tspeed: 0.0684s/iter; left time: 1242.3385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1040371 Vali Loss: 0.1223500 Test Loss: 0.1348549\n",
      "Validation loss decreased (0.122859 --> 0.122350).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1047703\n",
      "\tspeed: 0.1199s/iter; left time: 2163.0917s\n",
      "\titers: 200, epoch: 20 | loss: 0.0979615\n",
      "\tspeed: 0.0683s/iter; left time: 1226.3656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1038258 Vali Loss: 0.1237260 Test Loss: 0.1376037\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1012707\n",
      "\tspeed: 0.1201s/iter; left time: 2140.3692s\n",
      "\titers: 200, epoch: 21 | loss: 0.1044584\n",
      "\tspeed: 0.0685s/iter; left time: 1213.1153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 224 | Train Loss: 0.1037022 Vali Loss: 0.1223343 Test Loss: 0.1351457\n",
      "Validation loss decreased (0.122350 --> 0.122334).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1020581\n",
      "\tspeed: 0.1189s/iter; left time: 2091.4349s\n",
      "\titers: 200, epoch: 22 | loss: 0.1077093\n",
      "\tspeed: 0.0685s/iter; left time: 1198.3565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1032425 Vali Loss: 0.1223297 Test Loss: 0.1345724\n",
      "Validation loss decreased (0.122334 --> 0.122330).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1057566\n",
      "\tspeed: 0.1398s/iter; left time: 2428.1581s\n",
      "\titers: 200, epoch: 23 | loss: 0.0996206\n",
      "\tspeed: 0.0684s/iter; left time: 1181.2230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.92s\n",
      "Steps: 224 | Train Loss: 0.1029948 Vali Loss: 0.1240655 Test Loss: 0.1386009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1043318\n",
      "\tspeed: 0.1254s/iter; left time: 2149.6505s\n",
      "\titers: 200, epoch: 24 | loss: 0.1034501\n",
      "\tspeed: 0.0686s/iter; left time: 1169.0925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.91s\n",
      "Steps: 224 | Train Loss: 0.1027788 Vali Loss: 0.1225742 Test Loss: 0.1359570\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1029170\n",
      "\tspeed: 0.1193s/iter; left time: 2018.9627s\n",
      "\titers: 200, epoch: 25 | loss: 0.1020236\n",
      "\tspeed: 0.0684s/iter; left time: 1150.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1027968 Vali Loss: 0.1229979 Test Loss: 0.1367246\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0962725\n",
      "\tspeed: 0.1193s/iter; left time: 1992.9790s\n",
      "\titers: 200, epoch: 26 | loss: 0.1040621\n",
      "\tspeed: 0.0685s/iter; left time: 1136.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1024025 Vali Loss: 0.1225143 Test Loss: 0.1358389\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1004935\n",
      "\tspeed: 0.1194s/iter; left time: 1967.5204s\n",
      "\titers: 200, epoch: 27 | loss: 0.1055677\n",
      "\tspeed: 0.0683s/iter; left time: 1118.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.1022262 Vali Loss: 0.1226057 Test Loss: 0.1364723\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0998341\n",
      "\tspeed: 0.1180s/iter; left time: 1917.9641s\n",
      "\titers: 200, epoch: 28 | loss: 0.0971127\n",
      "\tspeed: 0.0686s/iter; left time: 1107.6507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.1021904 Vali Loss: 0.1226728 Test Loss: 0.1363831\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0987750\n",
      "\tspeed: 0.1178s/iter; left time: 1887.4802s\n",
      "\titers: 200, epoch: 29 | loss: 0.1013355\n",
      "\tspeed: 0.0684s/iter; left time: 1089.2501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.1020389 Vali Loss: 0.1226236 Test Loss: 0.1364451\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1039578\n",
      "\tspeed: 0.1183s/iter; left time: 1869.8370s\n",
      "\titers: 200, epoch: 30 | loss: 0.0988776\n",
      "\tspeed: 0.0684s/iter; left time: 1073.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.1019278 Vali Loss: 0.1228691 Test Loss: 0.1367732\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0983272\n",
      "\tspeed: 0.1177s/iter; left time: 1833.5149s\n",
      "\titers: 200, epoch: 31 | loss: 0.0968188\n",
      "\tspeed: 0.0683s/iter; left time: 1057.8833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.1018364 Vali Loss: 0.1221021 Test Loss: 0.1354317\n",
      "Validation loss decreased (0.122330 --> 0.122102).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1081205\n",
      "\tspeed: 0.1205s/iter; left time: 1850.2794s\n",
      "\titers: 200, epoch: 32 | loss: 0.0997057\n",
      "\tspeed: 0.0736s/iter; left time: 1123.6768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:16.11s\n",
      "Steps: 224 | Train Loss: 0.1017768 Vali Loss: 0.1225066 Test Loss: 0.1362729\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1030826\n",
      "\tspeed: 0.1175s/iter; left time: 1778.1075s\n",
      "\titers: 200, epoch: 33 | loss: 0.1017273\n",
      "\tspeed: 0.0683s/iter; left time: 1026.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.1017350 Vali Loss: 0.1220553 Test Loss: 0.1354810\n",
      "Validation loss decreased (0.122102 --> 0.122055).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1009225\n",
      "\tspeed: 0.1182s/iter; left time: 1761.7583s\n",
      "\titers: 200, epoch: 34 | loss: 0.0983965\n",
      "\tspeed: 0.0683s/iter; left time: 1011.1987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1015421 Vali Loss: 0.1230403 Test Loss: 0.1372007\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0966460\n",
      "\tspeed: 0.1173s/iter; left time: 1722.5442s\n",
      "\titers: 200, epoch: 35 | loss: 0.1041403\n",
      "\tspeed: 0.0991s/iter; left time: 1445.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:18.57s\n",
      "Steps: 224 | Train Loss: 0.1015374 Vali Loss: 0.1223040 Test Loss: 0.1357256\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1022101\n",
      "\tspeed: 0.1192s/iter; left time: 1723.1234s\n",
      "\titers: 200, epoch: 36 | loss: 0.1011828\n",
      "\tspeed: 0.0683s/iter; left time: 980.5746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1015622 Vali Loss: 0.1224028 Test Loss: 0.1361803\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1025064\n",
      "\tspeed: 0.1172s/iter; left time: 1667.9461s\n",
      "\titers: 200, epoch: 37 | loss: 0.1033631\n",
      "\tspeed: 0.0683s/iter; left time: 965.1244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.1012889 Vali Loss: 0.1223902 Test Loss: 0.1358852\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1007226\n",
      "\tspeed: 0.1174s/iter; left time: 1645.3375s\n",
      "\titers: 200, epoch: 38 | loss: 0.1036172\n",
      "\tspeed: 0.0683s/iter; left time: 950.7941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.1012544 Vali Loss: 0.1227186 Test Loss: 0.1367655\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1028364\n",
      "\tspeed: 0.1185s/iter; left time: 1634.5853s\n",
      "\titers: 200, epoch: 39 | loss: 0.0950349\n",
      "\tspeed: 0.0683s/iter; left time: 934.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.1012257 Vali Loss: 0.1226540 Test Loss: 0.1367102\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0991346\n",
      "\tspeed: 0.1177s/iter; left time: 1596.4043s\n",
      "\titers: 200, epoch: 40 | loss: 0.1022036\n",
      "\tspeed: 0.0682s/iter; left time: 918.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.1012251 Vali Loss: 0.1227309 Test Loss: 0.1369026\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1046214\n",
      "\tspeed: 0.1176s/iter; left time: 1568.4565s\n",
      "\titers: 200, epoch: 41 | loss: 0.1013999\n",
      "\tspeed: 0.0683s/iter; left time: 904.4285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1011355 Vali Loss: 0.1222482 Test Loss: 0.1361136\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1012941\n",
      "\tspeed: 0.1178s/iter; left time: 1545.6708s\n",
      "\titers: 200, epoch: 42 | loss: 0.0985237\n",
      "\tspeed: 0.0718s/iter; left time: 934.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.87s\n",
      "Steps: 224 | Train Loss: 0.1011403 Vali Loss: 0.1228735 Test Loss: 0.1370903\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1055074\n",
      "\tspeed: 0.1227s/iter; left time: 1581.3405s\n",
      "\titers: 200, epoch: 43 | loss: 0.1021581\n",
      "\tspeed: 0.0960s/iter; left time: 1228.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:20.48s\n",
      "Steps: 224 | Train Loss: 0.1011047 Vali Loss: 0.1222370 Test Loss: 0.1360325\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042729347944259644, rmse:0.2067107856273651, mae:0.1354810893535614, rse:0.7320046424865723\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3167256\n",
      "\tspeed: 0.0715s/iter; left time: 1594.1483s\n",
      "\titers: 200, epoch: 1 | loss: 0.2842959\n",
      "\tspeed: 0.0684s/iter; left time: 1519.5162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 224 | Train Loss: 0.3156375 Vali Loss: 0.2551522 Test Loss: 0.2553556\n",
      "Validation loss decreased (inf --> 0.255152).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1800915\n",
      "\tspeed: 0.1255s/iter; left time: 2771.3016s\n",
      "\titers: 200, epoch: 2 | loss: 0.1581953\n",
      "\tspeed: 0.0685s/iter; left time: 1505.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.1855842 Vali Loss: 0.1670674 Test Loss: 0.1814904\n",
      "Validation loss decreased (0.255152 --> 0.167067).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1490371\n",
      "\tspeed: 0.1196s/iter; left time: 2613.3051s\n",
      "\titers: 200, epoch: 3 | loss: 0.1355666\n",
      "\tspeed: 0.0683s/iter; left time: 1485.4961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1453927 Vali Loss: 0.1433539 Test Loss: 0.1545125\n",
      "Validation loss decreased (0.167067 --> 0.143354).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1300694\n",
      "\tspeed: 0.1188s/iter; left time: 2570.0067s\n",
      "\titers: 200, epoch: 4 | loss: 0.1239330\n",
      "\tspeed: 0.0683s/iter; left time: 1470.9354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.1296256 Vali Loss: 0.1364199 Test Loss: 0.1473309\n",
      "Validation loss decreased (0.143354 --> 0.136420).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1185137\n",
      "\tspeed: 0.1185s/iter; left time: 2536.6473s\n",
      "\titers: 200, epoch: 5 | loss: 0.1228966\n",
      "\tspeed: 0.0685s/iter; left time: 1459.8409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1219797 Vali Loss: 0.1330307 Test Loss: 0.1445775\n",
      "Validation loss decreased (0.136420 --> 0.133031).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1187729\n",
      "\tspeed: 0.1182s/iter; left time: 2503.1765s\n",
      "\titers: 200, epoch: 6 | loss: 0.1125875\n",
      "\tspeed: 0.0683s/iter; left time: 1440.6714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.1171754 Vali Loss: 0.1280404 Test Loss: 0.1396428\n",
      "Validation loss decreased (0.133031 --> 0.128040).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1150701\n",
      "\tspeed: 0.1266s/iter; left time: 2653.9686s\n",
      "\titers: 200, epoch: 7 | loss: 0.1122115\n",
      "\tspeed: 0.0684s/iter; left time: 1426.4265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:16.96s\n",
      "Steps: 224 | Train Loss: 0.1143772 Vali Loss: 0.1256260 Test Loss: 0.1359162\n",
      "Validation loss decreased (0.128040 --> 0.125626).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1120165\n",
      "\tspeed: 0.2019s/iter; left time: 4185.0037s\n",
      "\titers: 200, epoch: 8 | loss: 0.1104594\n",
      "\tspeed: 0.0683s/iter; left time: 1410.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1123769 Vali Loss: 0.1251683 Test Loss: 0.1361449\n",
      "Validation loss decreased (0.125626 --> 0.125168).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1130151\n",
      "\tspeed: 0.1220s/iter; left time: 2501.6529s\n",
      "\titers: 200, epoch: 9 | loss: 0.1126224\n",
      "\tspeed: 0.0703s/iter; left time: 1433.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.00s\n",
      "Steps: 224 | Train Loss: 0.1109941 Vali Loss: 0.1236206 Test Loss: 0.1337896\n",
      "Validation loss decreased (0.125168 --> 0.123621).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1115353\n",
      "\tspeed: 0.1795s/iter; left time: 3641.4873s\n",
      "\titers: 200, epoch: 10 | loss: 0.1133533\n",
      "\tspeed: 0.2245s/iter; left time: 4532.4840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.09s\n",
      "Steps: 224 | Train Loss: 0.1099545 Vali Loss: 0.1243099 Test Loss: 0.1345125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1076723\n",
      "\tspeed: 0.7780s/iter; left time: 15606.9996s\n",
      "\titers: 200, epoch: 11 | loss: 0.1058418\n",
      "\tspeed: 0.2373s/iter; left time: 4737.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:54.97s\n",
      "Steps: 224 | Train Loss: 0.1092103 Vali Loss: 0.1238363 Test Loss: 0.1351819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034310\n",
      "\tspeed: 0.7316s/iter; left time: 14513.1598s\n",
      "\titers: 200, epoch: 12 | loss: 0.1102478\n",
      "\tspeed: 0.2381s/iter; left time: 4700.1655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:55.00s\n",
      "Steps: 224 | Train Loss: 0.1084008 Vali Loss: 0.1236204 Test Loss: 0.1348626\n",
      "Validation loss decreased (0.123621 --> 0.123620).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1040254\n",
      "\tspeed: 0.6789s/iter; left time: 13314.6947s\n",
      "\titers: 200, epoch: 13 | loss: 0.1056939\n",
      "\tspeed: 0.1001s/iter; left time: 1953.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 224 | Train Loss: 0.1077506 Vali Loss: 0.1230974 Test Loss: 0.1341851\n",
      "Validation loss decreased (0.123620 --> 0.123097).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1074073\n",
      "\tspeed: 0.1350s/iter; left time: 2617.7089s\n",
      "\titers: 200, epoch: 14 | loss: 0.1071782\n",
      "\tspeed: 0.0692s/iter; left time: 1334.3801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.80s\n",
      "Steps: 224 | Train Loss: 0.1073876 Vali Loss: 0.1226013 Test Loss: 0.1340931\n",
      "Validation loss decreased (0.123097 --> 0.122601).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1075989\n",
      "\tspeed: 0.1228s/iter; left time: 2353.3007s\n",
      "\titers: 200, epoch: 15 | loss: 0.1049697\n",
      "\tspeed: 0.0687s/iter; left time: 1310.3943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.1067923 Vali Loss: 0.1231454 Test Loss: 0.1341373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1084415\n",
      "\tspeed: 0.1193s/iter; left time: 2260.0193s\n",
      "\titers: 200, epoch: 16 | loss: 0.1053199\n",
      "\tspeed: 0.0689s/iter; left time: 1298.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 224 | Train Loss: 0.1062349 Vali Loss: 0.1235031 Test Loss: 0.1349915\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1046021\n",
      "\tspeed: 0.1188s/iter; left time: 2224.4722s\n",
      "\titers: 200, epoch: 17 | loss: 0.1051650\n",
      "\tspeed: 0.0686s/iter; left time: 1277.2353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.1059806 Vali Loss: 0.1226191 Test Loss: 0.1344964\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1010722\n",
      "\tspeed: 0.1192s/iter; left time: 2204.2885s\n",
      "\titers: 200, epoch: 18 | loss: 0.1037693\n",
      "\tspeed: 0.0687s/iter; left time: 1263.9499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.1055270 Vali Loss: 0.1224123 Test Loss: 0.1342617\n",
      "Validation loss decreased (0.122601 --> 0.122412).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1047748\n",
      "\tspeed: 0.1201s/iter; left time: 2194.7848s\n",
      "\titers: 200, epoch: 19 | loss: 0.1045243\n",
      "\tspeed: 0.0687s/iter; left time: 1248.7247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.1054257 Vali Loss: 0.1218871 Test Loss: 0.1336673\n",
      "Validation loss decreased (0.122412 --> 0.121887).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0981335\n",
      "\tspeed: 0.1195s/iter; left time: 2156.3503s\n",
      "\titers: 200, epoch: 20 | loss: 0.1056107\n",
      "\tspeed: 0.0685s/iter; left time: 1228.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1049427 Vali Loss: 0.1227211 Test Loss: 0.1346270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1077192\n",
      "\tspeed: 0.1190s/iter; left time: 2119.8914s\n",
      "\titers: 200, epoch: 21 | loss: 0.1036313\n",
      "\tspeed: 0.0685s/iter; left time: 1214.2215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1048339 Vali Loss: 0.1224712 Test Loss: 0.1344547\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1039696\n",
      "\tspeed: 0.1187s/iter; left time: 2089.5114s\n",
      "\titers: 200, epoch: 22 | loss: 0.1096918\n",
      "\tspeed: 0.0687s/iter; left time: 1202.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 224 | Train Loss: 0.1046202 Vali Loss: 0.1219045 Test Loss: 0.1341921\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0991493\n",
      "\tspeed: 0.1178s/iter; left time: 2047.0010s\n",
      "\titers: 200, epoch: 23 | loss: 0.1017294\n",
      "\tspeed: 0.0683s/iter; left time: 1179.9920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1041807 Vali Loss: 0.1220025 Test Loss: 0.1344409\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1023979\n",
      "\tspeed: 0.1179s/iter; left time: 2022.5771s\n",
      "\titers: 200, epoch: 24 | loss: 0.1073738\n",
      "\tspeed: 0.0685s/iter; left time: 1168.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1039323 Vali Loss: 0.1218158 Test Loss: 0.1345161\n",
      "Validation loss decreased (0.121887 --> 0.121816).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0990838\n",
      "\tspeed: 0.1190s/iter; left time: 2013.7500s\n",
      "\titers: 200, epoch: 25 | loss: 0.1056384\n",
      "\tspeed: 0.0684s/iter; left time: 1151.2401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1038240 Vali Loss: 0.1222058 Test Loss: 0.1350957\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1048337\n",
      "\tspeed: 0.1179s/iter; left time: 1969.1870s\n",
      "\titers: 200, epoch: 26 | loss: 0.1056976\n",
      "\tspeed: 0.0685s/iter; left time: 1136.5667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1036285 Vali Loss: 0.1224878 Test Loss: 0.1353846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1042969\n",
      "\tspeed: 0.1181s/iter; left time: 1945.9830s\n",
      "\titers: 200, epoch: 27 | loss: 0.0998127\n",
      "\tspeed: 0.0684s/iter; left time: 1120.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1034771 Vali Loss: 0.1229843 Test Loss: 0.1356229\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1011541\n",
      "\tspeed: 0.1176s/iter; left time: 1911.5896s\n",
      "\titers: 200, epoch: 28 | loss: 0.1069242\n",
      "\tspeed: 0.0682s/iter; left time: 1102.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.1033720 Vali Loss: 0.1219611 Test Loss: 0.1343135\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1019244\n",
      "\tspeed: 0.1278s/iter; left time: 2048.4197s\n",
      "\titers: 200, epoch: 29 | loss: 0.1008236\n",
      "\tspeed: 0.0712s/iter; left time: 1134.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:16.13s\n",
      "Steps: 224 | Train Loss: 0.1032716 Vali Loss: 0.1214662 Test Loss: 0.1338151\n",
      "Validation loss decreased (0.121816 --> 0.121466).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1064876\n",
      "\tspeed: 0.1252s/iter; left time: 1979.3040s\n",
      "\titers: 200, epoch: 30 | loss: 0.1026108\n",
      "\tspeed: 0.0687s/iter; left time: 1078.9506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 224 | Train Loss: 0.1032293 Vali Loss: 0.1216022 Test Loss: 0.1341514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0983601\n",
      "\tspeed: 0.1270s/iter; left time: 1979.3744s\n",
      "\titers: 200, epoch: 31 | loss: 0.1046089\n",
      "\tspeed: 0.0689s/iter; left time: 1066.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.83s\n",
      "Steps: 224 | Train Loss: 0.1031151 Vali Loss: 0.1217638 Test Loss: 0.1344297\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1022087\n",
      "\tspeed: 0.1181s/iter; left time: 1813.5806s\n",
      "\titers: 200, epoch: 32 | loss: 0.1024320\n",
      "\tspeed: 0.0685s/iter; left time: 1045.5074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1029765 Vali Loss: 0.1219929 Test Loss: 0.1349361\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1095870\n",
      "\tspeed: 0.1177s/iter; left time: 1780.5570s\n",
      "\titers: 200, epoch: 33 | loss: 0.1005828\n",
      "\tspeed: 0.0684s/iter; left time: 1028.4090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.1029165 Vali Loss: 0.1220645 Test Loss: 0.1345904\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1055579\n",
      "\tspeed: 0.1182s/iter; left time: 1762.6831s\n",
      "\titers: 200, epoch: 34 | loss: 0.1025307\n",
      "\tspeed: 0.0717s/iter; left time: 1061.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.88s\n",
      "Steps: 224 | Train Loss: 0.1027911 Vali Loss: 0.1226628 Test Loss: 0.1360058\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1005947\n",
      "\tspeed: 0.1472s/iter; left time: 2162.0948s\n",
      "\titers: 200, epoch: 35 | loss: 0.1048046\n",
      "\tspeed: 0.1028s/iter; left time: 1499.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:21.92s\n",
      "Steps: 224 | Train Loss: 0.1027363 Vali Loss: 0.1222086 Test Loss: 0.1355054\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1028178\n",
      "\tspeed: 0.2666s/iter; left time: 3854.5938s\n",
      "\titers: 200, epoch: 36 | loss: 0.1073968\n",
      "\tspeed: 0.1100s/iter; left time: 1580.2421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:25.31s\n",
      "Steps: 224 | Train Loss: 0.1027397 Vali Loss: 0.1217490 Test Loss: 0.1346724\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1042333\n",
      "\tspeed: 0.2516s/iter; left time: 3582.2058s\n",
      "\titers: 200, epoch: 37 | loss: 0.0993173\n",
      "\tspeed: 0.0825s/iter; left time: 1166.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:19.81s\n",
      "Steps: 224 | Train Loss: 0.1025789 Vali Loss: 0.1219371 Test Loss: 0.1348975\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1050989\n",
      "\tspeed: 0.1274s/iter; left time: 1785.4339s\n",
      "\titers: 200, epoch: 38 | loss: 0.1037650\n",
      "\tspeed: 0.1008s/iter; left time: 1402.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:19.35s\n",
      "Steps: 224 | Train Loss: 0.1025715 Vali Loss: 0.1223866 Test Loss: 0.1356707\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1023699\n",
      "\tspeed: 0.2372s/iter; left time: 3270.4149s\n",
      "\titers: 200, epoch: 39 | loss: 0.1046783\n",
      "\tspeed: 0.2542s/iter; left time: 3479.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:49.95s\n",
      "Steps: 224 | Train Loss: 0.1025082 Vali Loss: 0.1217840 Test Loss: 0.1347638\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04074832424521446, rmse:0.2018621414899826, mae:0.13381515443325043, rse:0.7148346304893494\n",
      "Intermediate time for DE and pred_len 96: 00h:33m:21.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3089305\n",
      "\tspeed: 0.1408s/iter; left time: 3125.6540s\n",
      "\titers: 200, epoch: 1 | loss: 0.2793981\n",
      "\tspeed: 0.0698s/iter; left time: 1543.4713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:20.02s\n",
      "Steps: 223 | Train Loss: 0.3169002 Vali Loss: 0.2524981 Test Loss: 0.2529816\n",
      "Validation loss decreased (inf --> 0.252498).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1750290\n",
      "\tspeed: 0.1210s/iter; left time: 2660.4177s\n",
      "\titers: 200, epoch: 2 | loss: 0.1667869\n",
      "\tspeed: 0.0690s/iter; left time: 1510.2875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1878878 Vali Loss: 0.1728162 Test Loss: 0.1864888\n",
      "Validation loss decreased (0.252498 --> 0.172816).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1533171\n",
      "\tspeed: 0.1185s/iter; left time: 2579.0216s\n",
      "\titers: 200, epoch: 3 | loss: 0.1389635\n",
      "\tspeed: 0.0688s/iter; left time: 1490.0694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 223 | Train Loss: 0.1504728 Vali Loss: 0.1461973 Test Loss: 0.1596431\n",
      "Validation loss decreased (0.172816 --> 0.146197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1359493\n",
      "\tspeed: 0.1184s/iter; left time: 2548.5273s\n",
      "\titers: 200, epoch: 4 | loss: 0.1292974\n",
      "\tspeed: 0.0688s/iter; left time: 1474.2508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 223 | Train Loss: 0.1330178 Vali Loss: 0.1371194 Test Loss: 0.1519027\n",
      "Validation loss decreased (0.146197 --> 0.137119).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1258482\n",
      "\tspeed: 0.1187s/iter; left time: 2530.1322s\n",
      "\titers: 200, epoch: 5 | loss: 0.1198046\n",
      "\tspeed: 0.0688s/iter; left time: 1459.2173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 223 | Train Loss: 0.1236051 Vali Loss: 0.1347550 Test Loss: 0.1505743\n",
      "Validation loss decreased (0.137119 --> 0.134755).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1250191\n",
      "\tspeed: 0.1182s/iter; left time: 2493.0344s\n",
      "\titers: 200, epoch: 6 | loss: 0.1164635\n",
      "\tspeed: 0.0688s/iter; left time: 1443.2017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 223 | Train Loss: 0.1198182 Vali Loss: 0.1335471 Test Loss: 0.1490577\n",
      "Validation loss decreased (0.134755 --> 0.133547).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1109469\n",
      "\tspeed: 0.1181s/iter; left time: 2463.1973s\n",
      "\titers: 200, epoch: 7 | loss: 0.1146396\n",
      "\tspeed: 0.0687s/iter; left time: 1427.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.1170534 Vali Loss: 0.1333801 Test Loss: 0.1497679\n",
      "Validation loss decreased (0.133547 --> 0.133380).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1148580\n",
      "\tspeed: 0.1184s/iter; left time: 2442.8745s\n",
      "\titers: 200, epoch: 8 | loss: 0.1164081\n",
      "\tspeed: 0.0688s/iter; left time: 1413.4002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 223 | Train Loss: 0.1153232 Vali Loss: 0.1323905 Test Loss: 0.1477720\n",
      "Validation loss decreased (0.133380 --> 0.132391).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1144284\n",
      "\tspeed: 0.1190s/iter; left time: 2428.9752s\n",
      "\titers: 200, epoch: 9 | loss: 0.1110926\n",
      "\tspeed: 0.0689s/iter; left time: 1400.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.1138163 Vali Loss: 0.1310200 Test Loss: 0.1459086\n",
      "Validation loss decreased (0.132391 --> 0.131020).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1079175\n",
      "\tspeed: 0.1214s/iter; left time: 2450.7672s\n",
      "\titers: 200, epoch: 10 | loss: 0.1114745\n",
      "\tspeed: 0.0688s/iter; left time: 1381.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.1134661 Vali Loss: 0.1288931 Test Loss: 0.1430508\n",
      "Validation loss decreased (0.131020 --> 0.128893).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1133640\n",
      "\tspeed: 0.1190s/iter; left time: 2377.3802s\n",
      "\titers: 200, epoch: 11 | loss: 0.1148287\n",
      "\tspeed: 0.0688s/iter; left time: 1366.6108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 223 | Train Loss: 0.1122180 Vali Loss: 0.1306645 Test Loss: 0.1447594\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1092662\n",
      "\tspeed: 0.1197s/iter; left time: 2363.0779s\n",
      "\titers: 200, epoch: 12 | loss: 0.1175463\n",
      "\tspeed: 0.0688s/iter; left time: 1352.4768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1117287 Vali Loss: 0.1300639 Test Loss: 0.1437110\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1157954\n",
      "\tspeed: 0.1189s/iter; left time: 2322.2881s\n",
      "\titers: 200, epoch: 13 | loss: 0.1062873\n",
      "\tspeed: 0.0688s/iter; left time: 1335.7429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 223 | Train Loss: 0.1109512 Vali Loss: 0.1302539 Test Loss: 0.1458002\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1110501\n",
      "\tspeed: 0.1189s/iter; left time: 2295.7297s\n",
      "\titers: 200, epoch: 14 | loss: 0.1112382\n",
      "\tspeed: 0.0688s/iter; left time: 1321.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1107298 Vali Loss: 0.1298235 Test Loss: 0.1443224\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1061642\n",
      "\tspeed: 0.1195s/iter; left time: 2280.7244s\n",
      "\titers: 200, epoch: 15 | loss: 0.1063025\n",
      "\tspeed: 0.0690s/iter; left time: 1310.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1097723 Vali Loss: 0.1290208 Test Loss: 0.1435063\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1125907\n",
      "\tspeed: 0.1195s/iter; left time: 2252.9550s\n",
      "\titers: 200, epoch: 16 | loss: 0.1112603\n",
      "\tspeed: 0.0689s/iter; left time: 1291.7316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1095192 Vali Loss: 0.1299604 Test Loss: 0.1455350\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1039979\n",
      "\tspeed: 0.1194s/iter; left time: 2224.8659s\n",
      "\titers: 200, epoch: 17 | loss: 0.1057618\n",
      "\tspeed: 0.0689s/iter; left time: 1276.1121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1090180 Vali Loss: 0.1303559 Test Loss: 0.1463655\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1109604\n",
      "\tspeed: 0.1198s/iter; left time: 2205.8989s\n",
      "\titers: 200, epoch: 18 | loss: 0.1081996\n",
      "\tspeed: 0.0689s/iter; left time: 1261.4507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1086616 Vali Loss: 0.1284531 Test Loss: 0.1442524\n",
      "Validation loss decreased (0.128893 --> 0.128453).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1045345\n",
      "\tspeed: 0.1211s/iter; left time: 2203.0193s\n",
      "\titers: 200, epoch: 19 | loss: 0.1039633\n",
      "\tspeed: 0.0689s/iter; left time: 1246.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.1083280 Vali Loss: 0.1294749 Test Loss: 0.1458836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1117495\n",
      "\tspeed: 0.1198s/iter; left time: 2152.3857s\n",
      "\titers: 200, epoch: 20 | loss: 0.1094562\n",
      "\tspeed: 0.0688s/iter; left time: 1228.7549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 223 | Train Loss: 0.1079449 Vali Loss: 0.1291340 Test Loss: 0.1454565\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1163952\n",
      "\tspeed: 0.1190s/iter; left time: 2111.9124s\n",
      "\titers: 200, epoch: 21 | loss: 0.1064837\n",
      "\tspeed: 0.0688s/iter; left time: 1213.7635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 223 | Train Loss: 0.1077255 Vali Loss: 0.1310600 Test Loss: 0.1485930\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1097246\n",
      "\tspeed: 0.1191s/iter; left time: 2087.2595s\n",
      "\titers: 200, epoch: 22 | loss: 0.1130534\n",
      "\tspeed: 0.0688s/iter; left time: 1198.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 223 | Train Loss: 0.1075293 Vali Loss: 0.1296354 Test Loss: 0.1461615\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1032586\n",
      "\tspeed: 0.1192s/iter; left time: 2062.3687s\n",
      "\titers: 200, epoch: 23 | loss: 0.1074259\n",
      "\tspeed: 0.0689s/iter; left time: 1184.7677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1073015 Vali Loss: 0.1294399 Test Loss: 0.1467985\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1110739\n",
      "\tspeed: 0.1208s/iter; left time: 2063.0101s\n",
      "\titers: 200, epoch: 24 | loss: 0.1060702\n",
      "\tspeed: 0.0690s/iter; left time: 1171.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 223 | Train Loss: 0.1070986 Vali Loss: 0.1303079 Test Loss: 0.1478788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1048723\n",
      "\tspeed: 0.1191s/iter; left time: 2007.4207s\n",
      "\titers: 200, epoch: 25 | loss: 0.1042885\n",
      "\tspeed: 0.0688s/iter; left time: 1151.9320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 223 | Train Loss: 0.1070235 Vali Loss: 0.1293807 Test Loss: 0.1469254\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1113830\n",
      "\tspeed: 0.1198s/iter; left time: 1991.9031s\n",
      "\titers: 200, epoch: 26 | loss: 0.1059836\n",
      "\tspeed: 0.0688s/iter; left time: 1137.5989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.1066703 Vali Loss: 0.1301347 Test Loss: 0.1477387\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1056639\n",
      "\tspeed: 0.1203s/iter; left time: 1972.8289s\n",
      "\titers: 200, epoch: 27 | loss: 0.1062128\n",
      "\tspeed: 0.0689s/iter; left time: 1122.5649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1066428 Vali Loss: 0.1297490 Test Loss: 0.1474406\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1095321\n",
      "\tspeed: 0.1187s/iter; left time: 1920.4518s\n",
      "\titers: 200, epoch: 28 | loss: 0.1064767\n",
      "\tspeed: 0.0689s/iter; left time: 1108.1316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.1066298 Vali Loss: 0.1296261 Test Loss: 0.1472347\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04620388522744179, rmse:0.21495088934898376, mae:0.14425238966941833, rse:0.7613733410835266\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3118428\n",
      "\tspeed: 0.0709s/iter; left time: 1574.1453s\n",
      "\titers: 200, epoch: 1 | loss: 0.2780857\n",
      "\tspeed: 0.0689s/iter; left time: 1522.6957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.3161772 Vali Loss: 0.2463245 Test Loss: 0.2469013\n",
      "Validation loss decreased (inf --> 0.246324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1733194\n",
      "\tspeed: 0.1199s/iter; left time: 2634.7214s\n",
      "\titers: 200, epoch: 2 | loss: 0.1658133\n",
      "\tspeed: 0.0688s/iter; left time: 1506.2081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 223 | Train Loss: 0.1858806 Vali Loss: 0.1717119 Test Loss: 0.1896407\n",
      "Validation loss decreased (0.246324 --> 0.171712).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1518567\n",
      "\tspeed: 0.1195s/iter; left time: 2599.2534s\n",
      "\titers: 200, epoch: 3 | loss: 0.1474415\n",
      "\tspeed: 0.0688s/iter; left time: 1489.2431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1545581 Vali Loss: 0.1556090 Test Loss: 0.1706835\n",
      "Validation loss decreased (0.171712 --> 0.155609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1424413\n",
      "\tspeed: 0.1198s/iter; left time: 2580.4610s\n",
      "\titers: 200, epoch: 4 | loss: 0.1205621\n",
      "\tspeed: 0.0688s/iter; left time: 1475.5594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1354567 Vali Loss: 0.1383103 Test Loss: 0.1522951\n",
      "Validation loss decreased (0.155609 --> 0.138310).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1216583\n",
      "\tspeed: 0.1194s/iter; left time: 2543.2627s\n",
      "\titers: 200, epoch: 5 | loss: 0.1203901\n",
      "\tspeed: 0.0688s/iter; left time: 1459.3112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 223 | Train Loss: 0.1240639 Vali Loss: 0.1323285 Test Loss: 0.1454230\n",
      "Validation loss decreased (0.138310 --> 0.132329).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1213670\n",
      "\tspeed: 0.1196s/iter; left time: 2520.9078s\n",
      "\titers: 200, epoch: 6 | loss: 0.1171147\n",
      "\tspeed: 0.0688s/iter; left time: 1443.1068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.1200226 Vali Loss: 0.1307740 Test Loss: 0.1453031\n",
      "Validation loss decreased (0.132329 --> 0.130774).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1186587\n",
      "\tspeed: 0.1192s/iter; left time: 2487.6390s\n",
      "\titers: 200, epoch: 7 | loss: 0.1197537\n",
      "\tspeed: 0.0688s/iter; left time: 1428.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.1176448 Vali Loss: 0.1277773 Test Loss: 0.1407545\n",
      "Validation loss decreased (0.130774 --> 0.127777).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1142998\n",
      "\tspeed: 0.1192s/iter; left time: 2459.7881s\n",
      "\titers: 200, epoch: 8 | loss: 0.1175111\n",
      "\tspeed: 0.0687s/iter; left time: 1411.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 223 | Train Loss: 0.1163457 Vali Loss: 0.1273996 Test Loss: 0.1412246\n",
      "Validation loss decreased (0.127777 --> 0.127400).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1108171\n",
      "\tspeed: 0.1192s/iter; left time: 2433.1035s\n",
      "\titers: 200, epoch: 9 | loss: 0.1136831\n",
      "\tspeed: 0.0688s/iter; left time: 1398.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1148199 Vali Loss: 0.1282919 Test Loss: 0.1418690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1141520\n",
      "\tspeed: 0.1181s/iter; left time: 2385.7618s\n",
      "\titers: 200, epoch: 10 | loss: 0.1134683\n",
      "\tspeed: 0.0688s/iter; left time: 1381.8428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 223 | Train Loss: 0.1133743 Vali Loss: 0.1276681 Test Loss: 0.1415059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1186068\n",
      "\tspeed: 0.1182s/iter; left time: 2359.7241s\n",
      "\titers: 200, epoch: 11 | loss: 0.1138272\n",
      "\tspeed: 0.0688s/iter; left time: 1366.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 223 | Train Loss: 0.1123241 Vali Loss: 0.1271408 Test Loss: 0.1422885\n",
      "Validation loss decreased (0.127400 --> 0.127141).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1132137\n",
      "\tspeed: 0.1186s/iter; left time: 2342.5723s\n",
      "\titers: 200, epoch: 12 | loss: 0.1136331\n",
      "\tspeed: 0.0688s/iter; left time: 1351.0867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.1118033 Vali Loss: 0.1276743 Test Loss: 0.1427432\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1135698\n",
      "\tspeed: 0.1182s/iter; left time: 2306.9523s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101747\n",
      "\tspeed: 0.0688s/iter; left time: 1336.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.1108762 Vali Loss: 0.1274901 Test Loss: 0.1435209\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1143445\n",
      "\tspeed: 0.1181s/iter; left time: 2279.4886s\n",
      "\titers: 200, epoch: 14 | loss: 0.1130615\n",
      "\tspeed: 0.0687s/iter; left time: 1320.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 223 | Train Loss: 0.1102874 Vali Loss: 0.1277355 Test Loss: 0.1435685\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1071717\n",
      "\tspeed: 0.1186s/iter; left time: 2263.4797s\n",
      "\titers: 200, epoch: 15 | loss: 0.1093684\n",
      "\tspeed: 0.0689s/iter; left time: 1306.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1100137 Vali Loss: 0.1268632 Test Loss: 0.1429005\n",
      "Validation loss decreased (0.127141 --> 0.126863).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1160561\n",
      "\tspeed: 0.1220s/iter; left time: 2300.9558s\n",
      "\titers: 200, epoch: 16 | loss: 0.1154489\n",
      "\tspeed: 0.0689s/iter; left time: 1292.5104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.1092905 Vali Loss: 0.1269351 Test Loss: 0.1429119\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1108780\n",
      "\tspeed: 0.1203s/iter; left time: 2241.8008s\n",
      "\titers: 200, epoch: 17 | loss: 0.1090916\n",
      "\tspeed: 0.0689s/iter; left time: 1276.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1090499 Vali Loss: 0.1291180 Test Loss: 0.1460651\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1079435\n",
      "\tspeed: 0.1205s/iter; left time: 2218.0781s\n",
      "\titers: 200, epoch: 18 | loss: 0.1102454\n",
      "\tspeed: 0.0688s/iter; left time: 1259.2995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1089586 Vali Loss: 0.1276255 Test Loss: 0.1440117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1111766\n",
      "\tspeed: 0.1200s/iter; left time: 2183.1467s\n",
      "\titers: 200, epoch: 19 | loss: 0.1027376\n",
      "\tspeed: 0.0690s/iter; left time: 1247.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1082691 Vali Loss: 0.1271328 Test Loss: 0.1427042\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1087112\n",
      "\tspeed: 0.1189s/iter; left time: 2135.9416s\n",
      "\titers: 200, epoch: 20 | loss: 0.1081457\n",
      "\tspeed: 0.0688s/iter; left time: 1229.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.1080461 Vali Loss: 0.1277898 Test Loss: 0.1442262\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1061458\n",
      "\tspeed: 0.1187s/iter; left time: 2105.9744s\n",
      "\titers: 200, epoch: 21 | loss: 0.1046224\n",
      "\tspeed: 0.0688s/iter; left time: 1212.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1077802 Vali Loss: 0.1263755 Test Loss: 0.1419977\n",
      "Validation loss decreased (0.126863 --> 0.126375).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1005296\n",
      "\tspeed: 0.1203s/iter; left time: 2108.0729s\n",
      "\titers: 200, epoch: 22 | loss: 0.1116337\n",
      "\tspeed: 0.0690s/iter; left time: 1201.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1075822 Vali Loss: 0.1269282 Test Loss: 0.1433026\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1117748\n",
      "\tspeed: 0.1203s/iter; left time: 2080.5508s\n",
      "\titers: 200, epoch: 23 | loss: 0.1091891\n",
      "\tspeed: 0.0687s/iter; left time: 1181.5540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 223 | Train Loss: 0.1074640 Vali Loss: 0.1274249 Test Loss: 0.1439884\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1092627\n",
      "\tspeed: 0.1203s/iter; left time: 2053.6380s\n",
      "\titers: 200, epoch: 24 | loss: 0.1067334\n",
      "\tspeed: 0.0703s/iter; left time: 1192.6782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 223 | Train Loss: 0.1072625 Vali Loss: 0.1274282 Test Loss: 0.1433213\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1081924\n",
      "\tspeed: 0.1598s/iter; left time: 2693.1104s\n",
      "\titers: 200, epoch: 25 | loss: 0.1119448\n",
      "\tspeed: 0.2509s/iter; left time: 4201.8835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:41.18s\n",
      "Steps: 223 | Train Loss: 0.1070743 Vali Loss: 0.1269876 Test Loss: 0.1436830\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1083587\n",
      "\tspeed: 0.7366s/iter; left time: 12246.8889s\n",
      "\titers: 200, epoch: 26 | loss: 0.1090440\n",
      "\tspeed: 0.2323s/iter; left time: 3838.6247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:53.56s\n",
      "Steps: 223 | Train Loss: 0.1069896 Vali Loss: 0.1268617 Test Loss: 0.1429699\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1072531\n",
      "\tspeed: 0.7394s/iter; left time: 12128.9892s\n",
      "\titers: 200, epoch: 27 | loss: 0.1056889\n",
      "\tspeed: 0.2455s/iter; left time: 4002.1118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:54.87s\n",
      "Steps: 223 | Train Loss: 0.1067912 Vali Loss: 0.1277991 Test Loss: 0.1439163\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1085324\n",
      "\tspeed: 0.7160s/iter; left time: 11584.3651s\n",
      "\titers: 200, epoch: 28 | loss: 0.1082245\n",
      "\tspeed: 0.2382s/iter; left time: 3830.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:53.39s\n",
      "Steps: 223 | Train Loss: 0.1067494 Vali Loss: 0.1272216 Test Loss: 0.1437127\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1067627\n",
      "\tspeed: 0.5176s/iter; left time: 8259.8734s\n",
      "\titers: 200, epoch: 29 | loss: 0.1115904\n",
      "\tspeed: 0.0783s/iter; left time: 1241.6624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:19.63s\n",
      "Steps: 223 | Train Loss: 0.1065454 Vali Loss: 0.1279469 Test Loss: 0.1445099\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1084134\n",
      "\tspeed: 0.1249s/iter; left time: 1964.6378s\n",
      "\titers: 200, epoch: 30 | loss: 0.1071904\n",
      "\tspeed: 0.0693s/iter; left time: 1083.7415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.79s\n",
      "Steps: 223 | Train Loss: 0.1065383 Vali Loss: 0.1270621 Test Loss: 0.1431437\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1070483\n",
      "\tspeed: 0.1225s/iter; left time: 1900.8246s\n",
      "\titers: 200, epoch: 31 | loss: 0.1052605\n",
      "\tspeed: 0.0692s/iter; left time: 1066.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.72s\n",
      "Steps: 223 | Train Loss: 0.1063381 Vali Loss: 0.1271256 Test Loss: 0.1432506\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045363716781139374, rmse:0.21298760175704956, mae:0.14199773967266083, rse:0.754419207572937\n",
      "Intermediate time for DE and pred_len 168: 00h:23m:51.65s\n",
      "Intermediate time for DE: 01h:36m:37.76s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3103972\n",
      "\tspeed: 0.0864s/iter; left time: 1925.8262s\n",
      "\titers: 200, epoch: 1 | loss: 0.2918056\n",
      "\tspeed: 0.0680s/iter; left time: 1509.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 224 | Train Loss: 0.3176245 Vali Loss: 0.2667150 Test Loss: 0.2789312\n",
      "Validation loss decreased (inf --> 0.266715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1606847\n",
      "\tspeed: 0.1177s/iter; left time: 2598.0907s\n",
      "\titers: 200, epoch: 2 | loss: 0.1318924\n",
      "\tspeed: 0.0680s/iter; left time: 1493.5738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.1721786 Vali Loss: 0.1329925 Test Loss: 0.1483844\n",
      "Validation loss decreased (0.266715 --> 0.132993).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1238292\n",
      "\tspeed: 0.1188s/iter; left time: 2595.4857s\n",
      "\titers: 200, epoch: 3 | loss: 0.1184152\n",
      "\tspeed: 0.0681s/iter; left time: 1482.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.1217720 Vali Loss: 0.1224356 Test Loss: 0.1371606\n",
      "Validation loss decreased (0.132993 --> 0.122436).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1065479\n",
      "\tspeed: 0.1186s/iter; left time: 2566.2541s\n",
      "\titers: 200, epoch: 4 | loss: 0.1109261\n",
      "\tspeed: 0.0680s/iter; left time: 1463.7158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1115242 Vali Loss: 0.1155245 Test Loss: 0.1305088\n",
      "Validation loss decreased (0.122436 --> 0.115525).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1002228\n",
      "\tspeed: 0.1176s/iter; left time: 2517.1250s\n",
      "\titers: 200, epoch: 5 | loss: 0.0962851\n",
      "\tspeed: 0.0681s/iter; left time: 1451.0842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.1038560 Vali Loss: 0.1093327 Test Loss: 0.1243860\n",
      "Validation loss decreased (0.115525 --> 0.109333).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0999769\n",
      "\tspeed: 0.1177s/iter; left time: 2492.0574s\n",
      "\titers: 200, epoch: 6 | loss: 0.0955643\n",
      "\tspeed: 0.0680s/iter; left time: 1433.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0986742 Vali Loss: 0.1049355 Test Loss: 0.1230808\n",
      "Validation loss decreased (0.109333 --> 0.104936).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0993074\n",
      "\tspeed: 0.1187s/iter; left time: 2487.8887s\n",
      "\titers: 200, epoch: 7 | loss: 0.0937699\n",
      "\tspeed: 0.0681s/iter; left time: 1420.7012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0950341 Vali Loss: 0.1019433 Test Loss: 0.1184804\n",
      "Validation loss decreased (0.104936 --> 0.101943).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0922895\n",
      "\tspeed: 0.1178s/iter; left time: 2441.9231s\n",
      "\titers: 200, epoch: 8 | loss: 0.0886704\n",
      "\tspeed: 0.0680s/iter; left time: 1403.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0924839 Vali Loss: 0.0999139 Test Loss: 0.1164169\n",
      "Validation loss decreased (0.101943 --> 0.099914).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0960675\n",
      "\tspeed: 0.1183s/iter; left time: 2427.1121s\n",
      "\titers: 200, epoch: 9 | loss: 0.0899758\n",
      "\tspeed: 0.0700s/iter; left time: 1429.5149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.96s\n",
      "Steps: 224 | Train Loss: 0.0904170 Vali Loss: 0.0987468 Test Loss: 0.1150122\n",
      "Validation loss decreased (0.099914 --> 0.098747).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0901307\n",
      "\tspeed: 0.1255s/iter; left time: 2546.7606s\n",
      "\titers: 200, epoch: 10 | loss: 0.0890948\n",
      "\tspeed: 0.0683s/iter; left time: 1379.5362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.85s\n",
      "Steps: 224 | Train Loss: 0.0887816 Vali Loss: 0.0996776 Test Loss: 0.1153803\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0869153\n",
      "\tspeed: 0.1213s/iter; left time: 2433.5779s\n",
      "\titers: 200, epoch: 11 | loss: 0.0884365\n",
      "\tspeed: 0.0689s/iter; left time: 1374.7423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.86s\n",
      "Steps: 224 | Train Loss: 0.0876129 Vali Loss: 0.0968768 Test Loss: 0.1132817\n",
      "Validation loss decreased (0.098747 --> 0.096877).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0809240\n",
      "\tspeed: 0.1202s/iter; left time: 2383.6341s\n",
      "\titers: 200, epoch: 12 | loss: 0.0844528\n",
      "\tspeed: 0.0694s/iter; left time: 1369.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 224 | Train Loss: 0.0865733 Vali Loss: 0.0976310 Test Loss: 0.1147074\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0879576\n",
      "\tspeed: 0.1196s/iter; left time: 2345.9491s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830674\n",
      "\tspeed: 0.0684s/iter; left time: 1335.5822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0856366 Vali Loss: 0.0969990 Test Loss: 0.1126259\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0845396\n",
      "\tspeed: 0.1190s/iter; left time: 2308.0514s\n",
      "\titers: 200, epoch: 14 | loss: 0.0864761\n",
      "\tspeed: 0.0775s/iter; left time: 1494.9167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:16.46s\n",
      "Steps: 224 | Train Loss: 0.0848632 Vali Loss: 0.0959683 Test Loss: 0.1117754\n",
      "Validation loss decreased (0.096877 --> 0.095968).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0850291\n",
      "\tspeed: 0.1199s/iter; left time: 2298.5940s\n",
      "\titers: 200, epoch: 15 | loss: 0.0823007\n",
      "\tspeed: 0.1099s/iter; left time: 2095.8523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:23.44s\n",
      "Steps: 224 | Train Loss: 0.0843513 Vali Loss: 0.0954413 Test Loss: 0.1105400\n",
      "Validation loss decreased (0.095968 --> 0.095441).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0867651\n",
      "\tspeed: 0.5235s/iter; left time: 9915.8694s\n",
      "\titers: 200, epoch: 16 | loss: 0.0804142\n",
      "\tspeed: 0.2307s/iter; left time: 4346.2262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:54.19s\n",
      "Steps: 224 | Train Loss: 0.0837347 Vali Loss: 0.0954213 Test Loss: 0.1110339\n",
      "Validation loss decreased (0.095441 --> 0.095421).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0782402\n",
      "\tspeed: 0.3895s/iter; left time: 7290.7833s\n",
      "\titers: 200, epoch: 17 | loss: 0.0827721\n",
      "\tspeed: 0.0695s/iter; left time: 1293.4273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:19.81s\n",
      "Steps: 224 | Train Loss: 0.0832381 Vali Loss: 0.0963180 Test Loss: 0.1115227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0833778\n",
      "\tspeed: 0.1185s/iter; left time: 2191.4636s\n",
      "\titers: 200, epoch: 18 | loss: 0.0823466\n",
      "\tspeed: 0.0679s/iter; left time: 1249.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0829708 Vali Loss: 0.0959884 Test Loss: 0.1106819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0797588\n",
      "\tspeed: 0.1165s/iter; left time: 2127.4257s\n",
      "\titers: 200, epoch: 19 | loss: 0.0812764\n",
      "\tspeed: 0.0678s/iter; left time: 1232.1383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0827155 Vali Loss: 0.0947987 Test Loss: 0.1108401\n",
      "Validation loss decreased (0.095421 --> 0.094799).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0879408\n",
      "\tspeed: 0.1189s/iter; left time: 2146.1614s\n",
      "\titers: 200, epoch: 20 | loss: 0.0812260\n",
      "\tspeed: 0.0680s/iter; left time: 1220.0014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0822553 Vali Loss: 0.0951414 Test Loss: 0.1106498\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0777991\n",
      "\tspeed: 0.1164s/iter; left time: 2074.1462s\n",
      "\titers: 200, epoch: 21 | loss: 0.0859361\n",
      "\tspeed: 0.0681s/iter; left time: 1206.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0820260 Vali Loss: 0.0947133 Test Loss: 0.1101060\n",
      "Validation loss decreased (0.094799 --> 0.094713).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0836640\n",
      "\tspeed: 0.1171s/iter; left time: 2060.8821s\n",
      "\titers: 200, epoch: 22 | loss: 0.0850131\n",
      "\tspeed: 0.0679s/iter; left time: 1187.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0816894 Vali Loss: 0.0953884 Test Loss: 0.1104233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0824851\n",
      "\tspeed: 0.1154s/iter; left time: 2004.4164s\n",
      "\titers: 200, epoch: 23 | loss: 0.0856660\n",
      "\tspeed: 0.0678s/iter; left time: 1171.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 224 | Train Loss: 0.0814880 Vali Loss: 0.0950758 Test Loss: 0.1107358\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0811106\n",
      "\tspeed: 0.1160s/iter; left time: 1988.6194s\n",
      "\titers: 200, epoch: 24 | loss: 0.0752342\n",
      "\tspeed: 0.0679s/iter; left time: 1157.5019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0813338 Vali Loss: 0.0943376 Test Loss: 0.1095935\n",
      "Validation loss decreased (0.094713 --> 0.094338).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0866992\n",
      "\tspeed: 0.1170s/iter; left time: 1979.4149s\n",
      "\titers: 200, epoch: 25 | loss: 0.0789551\n",
      "\tspeed: 0.0680s/iter; left time: 1143.6928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0811264 Vali Loss: 0.0941992 Test Loss: 0.1095877\n",
      "Validation loss decreased (0.094338 --> 0.094199).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0852271\n",
      "\tspeed: 0.1170s/iter; left time: 1953.2527s\n",
      "\titers: 200, epoch: 26 | loss: 0.0767275\n",
      "\tspeed: 0.0679s/iter; left time: 1126.7344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0810153 Vali Loss: 0.0951884 Test Loss: 0.1101739\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0794628\n",
      "\tspeed: 0.1158s/iter; left time: 1908.7852s\n",
      "\titers: 200, epoch: 27 | loss: 0.0837027\n",
      "\tspeed: 0.0679s/iter; left time: 1111.8939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0808015 Vali Loss: 0.0944285 Test Loss: 0.1096465\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0837456\n",
      "\tspeed: 0.1157s/iter; left time: 1880.8496s\n",
      "\titers: 200, epoch: 28 | loss: 0.0791942\n",
      "\tspeed: 0.0678s/iter; left time: 1094.7835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0807987 Vali Loss: 0.0944479 Test Loss: 0.1103889\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0854103\n",
      "\tspeed: 0.1157s/iter; left time: 1854.3877s\n",
      "\titers: 200, epoch: 29 | loss: 0.0849250\n",
      "\tspeed: 0.0679s/iter; left time: 1081.2875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0806139 Vali Loss: 0.0950442 Test Loss: 0.1105168\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0814106\n",
      "\tspeed: 0.1157s/iter; left time: 1828.1950s\n",
      "\titers: 200, epoch: 30 | loss: 0.0780639\n",
      "\tspeed: 0.0679s/iter; left time: 1066.1683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0804462 Vali Loss: 0.0941141 Test Loss: 0.1095955\n",
      "Validation loss decreased (0.094199 --> 0.094114).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0759575\n",
      "\tspeed: 0.1172s/iter; left time: 1825.8721s\n",
      "\titers: 200, epoch: 31 | loss: 0.0795375\n",
      "\tspeed: 0.0679s/iter; left time: 1051.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0803483 Vali Loss: 0.0939389 Test Loss: 0.1093440\n",
      "Validation loss decreased (0.094114 --> 0.093939).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0815100\n",
      "\tspeed: 0.1163s/iter; left time: 1786.7363s\n",
      "\titers: 200, epoch: 32 | loss: 0.0751769\n",
      "\tspeed: 0.0679s/iter; left time: 1036.0041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0803568 Vali Loss: 0.0937918 Test Loss: 0.1095269\n",
      "Validation loss decreased (0.093939 --> 0.093792).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0794339\n",
      "\tspeed: 0.1182s/iter; left time: 1788.1069s\n",
      "\titers: 200, epoch: 33 | loss: 0.0829026\n",
      "\tspeed: 0.0678s/iter; left time: 1019.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0802788 Vali Loss: 0.0938579 Test Loss: 0.1093477\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0802516\n",
      "\tspeed: 0.1155s/iter; left time: 1721.7551s\n",
      "\titers: 200, epoch: 34 | loss: 0.0812640\n",
      "\tspeed: 0.0679s/iter; left time: 1005.5386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0801686 Vali Loss: 0.0945188 Test Loss: 0.1099514\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0798175\n",
      "\tspeed: 0.1153s/iter; left time: 1693.0166s\n",
      "\titers: 200, epoch: 35 | loss: 0.0785168\n",
      "\tspeed: 0.0678s/iter; left time: 989.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.34s\n",
      "Steps: 224 | Train Loss: 0.0802166 Vali Loss: 0.0939948 Test Loss: 0.1093734\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0813604\n",
      "\tspeed: 0.1158s/iter; left time: 1674.0228s\n",
      "\titers: 200, epoch: 36 | loss: 0.0839157\n",
      "\tspeed: 0.0679s/iter; left time: 974.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0799958 Vali Loss: 0.0940286 Test Loss: 0.1095501\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0769886\n",
      "\tspeed: 0.1156s/iter; left time: 1645.4806s\n",
      "\titers: 200, epoch: 37 | loss: 0.0761550\n",
      "\tspeed: 0.0679s/iter; left time: 959.9380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0800327 Vali Loss: 0.0938194 Test Loss: 0.1096124\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0806935\n",
      "\tspeed: 0.1156s/iter; left time: 1620.3121s\n",
      "\titers: 200, epoch: 38 | loss: 0.0839414\n",
      "\tspeed: 0.0678s/iter; left time: 942.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.33s\n",
      "Steps: 224 | Train Loss: 0.0799501 Vali Loss: 0.0939694 Test Loss: 0.1095691\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0768669\n",
      "\tspeed: 0.1172s/iter; left time: 1615.9281s\n",
      "\titers: 200, epoch: 39 | loss: 0.0812318\n",
      "\tspeed: 0.0680s/iter; left time: 930.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0799085 Vali Loss: 0.0942529 Test Loss: 0.1096605\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0788171\n",
      "\tspeed: 0.1152s/iter; left time: 1562.6817s\n",
      "\titers: 200, epoch: 40 | loss: 0.0786404\n",
      "\tspeed: 0.0678s/iter; left time: 913.3624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0799737 Vali Loss: 0.0938576 Test Loss: 0.1093392\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0789754\n",
      "\tspeed: 0.2533s/iter; left time: 3379.6633s\n",
      "\titers: 200, epoch: 41 | loss: 0.0768950\n",
      "\tspeed: 0.2416s/iter; left time: 3199.0467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:50.06s\n",
      "Steps: 224 | Train Loss: 0.0798871 Vali Loss: 0.0938818 Test Loss: 0.1094634\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0793687\n",
      "\tspeed: 0.5199s/iter; left time: 6819.7719s\n",
      "\titers: 200, epoch: 42 | loss: 0.0801241\n",
      "\tspeed: 0.2219s/iter; left time: 2887.9839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:52.21s\n",
      "Steps: 224 | Train Loss: 0.0798778 Vali Loss: 0.0937657 Test Loss: 0.1095182\n",
      "Validation loss decreased (0.093792 --> 0.093766).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0819623\n",
      "\tspeed: 0.5013s/iter; left time: 6462.9202s\n",
      "\titers: 200, epoch: 43 | loss: 0.0777785\n",
      "\tspeed: 0.2276s/iter; left time: 2911.2359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:51.95s\n",
      "Steps: 224 | Train Loss: 0.0797599 Vali Loss: 0.0939041 Test Loss: 0.1093650\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0789351\n",
      "\tspeed: 0.5396s/iter; left time: 6836.5684s\n",
      "\titers: 200, epoch: 44 | loss: 0.0811415\n",
      "\tspeed: 0.2342s/iter; left time: 2943.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:54.27s\n",
      "Steps: 224 | Train Loss: 0.0798095 Vali Loss: 0.0938729 Test Loss: 0.1094565\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0839762\n",
      "\tspeed: 0.5360s/iter; left time: 6670.5341s\n",
      "\titers: 200, epoch: 45 | loss: 0.0806607\n",
      "\tspeed: 0.2389s/iter; left time: 2949.7032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:53.73s\n",
      "Steps: 224 | Train Loss: 0.0797772 Vali Loss: 0.0937436 Test Loss: 0.1092578\n",
      "Validation loss decreased (0.093766 --> 0.093744).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0858392\n",
      "\tspeed: 0.2708s/iter; left time: 3309.4626s\n",
      "\titers: 200, epoch: 46 | loss: 0.0830120\n",
      "\tspeed: 0.0701s/iter; left time: 849.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 224 | Train Loss: 0.0798345 Vali Loss: 0.0937057 Test Loss: 0.1092092\n",
      "Validation loss decreased (0.093744 --> 0.093706).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0765997\n",
      "\tspeed: 0.1212s/iter; left time: 1454.5916s\n",
      "\titers: 200, epoch: 47 | loss: 0.0772259\n",
      "\tspeed: 0.0683s/iter; left time: 812.7880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0797400 Vali Loss: 0.0938477 Test Loss: 0.1093067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0788990\n",
      "\tspeed: 0.1184s/iter; left time: 1394.4042s\n",
      "\titers: 200, epoch: 48 | loss: 0.0765106\n",
      "\tspeed: 0.0680s/iter; left time: 794.3041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0798101 Vali Loss: 0.0939935 Test Loss: 0.1094495\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0806689\n",
      "\tspeed: 0.1168s/iter; left time: 1348.8615s\n",
      "\titers: 200, epoch: 49 | loss: 0.0753171\n",
      "\tspeed: 0.0679s/iter; left time: 777.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0797495 Vali Loss: 0.0938690 Test Loss: 0.1093126\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0826202\n",
      "\tspeed: 0.1175s/iter; left time: 1330.9921s\n",
      "\titers: 200, epoch: 50 | loss: 0.0787105\n",
      "\tspeed: 0.0679s/iter; left time: 762.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0797176 Vali Loss: 0.0940041 Test Loss: 0.1093912\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0837858\n",
      "\tspeed: 0.1156s/iter; left time: 1282.9867s\n",
      "\titers: 200, epoch: 51 | loss: 0.0746192\n",
      "\tspeed: 0.0678s/iter; left time: 746.1101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0796683 Vali Loss: 0.0940240 Test Loss: 0.1095512\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0794291\n",
      "\tspeed: 0.1160s/iter; left time: 1261.9984s\n",
      "\titers: 200, epoch: 52 | loss: 0.0842566\n",
      "\tspeed: 0.0678s/iter; left time: 730.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0796527 Vali Loss: 0.0938112 Test Loss: 0.1095843\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0794171\n",
      "\tspeed: 0.1155s/iter; left time: 1230.5735s\n",
      "\titers: 200, epoch: 53 | loss: 0.0777329\n",
      "\tspeed: 0.0677s/iter; left time: 714.8317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0797028 Vali Loss: 0.0938407 Test Loss: 0.1094160\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0810683\n",
      "\tspeed: 0.1153s/iter; left time: 1202.1990s\n",
      "\titers: 200, epoch: 54 | loss: 0.0781190\n",
      "\tspeed: 0.0677s/iter; left time: 699.5051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:15.31s\n",
      "Steps: 224 | Train Loss: 0.0795873 Vali Loss: 0.0939529 Test Loss: 0.1093818\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0787092\n",
      "\tspeed: 0.1158s/iter; left time: 1181.2393s\n",
      "\titers: 200, epoch: 55 | loss: 0.0751580\n",
      "\tspeed: 0.0679s/iter; left time: 686.5018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0796908 Vali Loss: 0.0936953 Test Loss: 0.1091532\n",
      "Validation loss decreased (0.093706 --> 0.093695).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0782375\n",
      "\tspeed: 0.1189s/iter; left time: 1187.0316s\n",
      "\titers: 200, epoch: 56 | loss: 0.0768067\n",
      "\tspeed: 0.0677s/iter; left time: 668.7187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:15.32s\n",
      "Steps: 224 | Train Loss: 0.0795776 Vali Loss: 0.0939255 Test Loss: 0.1094217\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0782846\n",
      "\tspeed: 0.1145s/iter; left time: 1117.2936s\n",
      "\titers: 200, epoch: 57 | loss: 0.0824307\n",
      "\tspeed: 0.0677s/iter; left time: 654.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:15.31s\n",
      "Steps: 224 | Train Loss: 0.0797071 Vali Loss: 0.0939826 Test Loss: 0.1094131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0774219\n",
      "\tspeed: 0.1179s/iter; left time: 1123.6218s\n",
      "\titers: 200, epoch: 58 | loss: 0.0789580\n",
      "\tspeed: 0.0739s/iter; left time: 697.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:16.30s\n",
      "Steps: 224 | Train Loss: 0.0796531 Vali Loss: 0.0938628 Test Loss: 0.1094121\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0807209\n",
      "\tspeed: 0.1225s/iter; left time: 1140.2504s\n",
      "\titers: 200, epoch: 59 | loss: 0.0793883\n",
      "\tspeed: 0.0702s/iter; left time: 646.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:15.79s\n",
      "Steps: 224 | Train Loss: 0.0796394 Vali Loss: 0.0939050 Test Loss: 0.1095356\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0789314\n",
      "\tspeed: 0.1220s/iter; left time: 1108.6534s\n",
      "\titers: 200, epoch: 60 | loss: 0.0791493\n",
      "\tspeed: 0.0687s/iter; left time: 617.6276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.0796108 Vali Loss: 0.0937325 Test Loss: 0.1092400\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0789648\n",
      "\tspeed: 0.1220s/iter; left time: 1081.1206s\n",
      "\titers: 200, epoch: 61 | loss: 0.0825171\n",
      "\tspeed: 0.0686s/iter; left time: 600.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:15.92s\n",
      "Steps: 224 | Train Loss: 0.0796363 Vali Loss: 0.0938056 Test Loss: 0.1092568\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0775879\n",
      "\tspeed: 0.1189s/iter; left time: 1026.8523s\n",
      "\titers: 200, epoch: 62 | loss: 0.0853904\n",
      "\tspeed: 0.0681s/iter; left time: 581.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0796473 Vali Loss: 0.0937431 Test Loss: 0.1092565\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0776334\n",
      "\tspeed: 0.1347s/iter; left time: 1133.2918s\n",
      "\titers: 200, epoch: 63 | loss: 0.0765420\n",
      "\tspeed: 0.0716s/iter; left time: 595.1474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:16.00s\n",
      "Steps: 224 | Train Loss: 0.0796711 Vali Loss: 0.0938779 Test Loss: 0.1092572\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0747456\n",
      "\tspeed: 0.4350s/iter; left time: 3561.9697s\n",
      "\titers: 200, epoch: 64 | loss: 0.0763237\n",
      "\tspeed: 0.2387s/iter; left time: 1930.4480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:54.90s\n",
      "Steps: 224 | Train Loss: 0.0796111 Vali Loss: 0.0935991 Test Loss: 0.1091278\n",
      "Validation loss decreased (0.093695 --> 0.093599).  Saving model ...\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0802288\n",
      "\tspeed: 0.5034s/iter; left time: 4009.8453s\n",
      "\titers: 200, epoch: 65 | loss: 0.0786180\n",
      "\tspeed: 0.0873s/iter; left time: 686.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:31.38s\n",
      "Steps: 224 | Train Loss: 0.0795877 Vali Loss: 0.0937994 Test Loss: 0.1092964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0766752\n",
      "\tspeed: 0.1201s/iter; left time: 929.3980s\n",
      "\titers: 200, epoch: 66 | loss: 0.0839382\n",
      "\tspeed: 0.0682s/iter; left time: 521.3117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0796165 Vali Loss: 0.0937209 Test Loss: 0.1091665\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0775077\n",
      "\tspeed: 0.1176s/iter; left time: 884.3215s\n",
      "\titers: 200, epoch: 67 | loss: 0.0802540\n",
      "\tspeed: 0.0681s/iter; left time: 505.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0796510 Vali Loss: 0.0938005 Test Loss: 0.1092435\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0769433\n",
      "\tspeed: 0.1172s/iter; left time: 854.4687s\n",
      "\titers: 200, epoch: 68 | loss: 0.0783113\n",
      "\tspeed: 0.0680s/iter; left time: 488.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0795104 Vali Loss: 0.0939225 Test Loss: 0.1092780\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0814788\n",
      "\tspeed: 0.1171s/iter; left time: 827.9469s\n",
      "\titers: 200, epoch: 69 | loss: 0.0802993\n",
      "\tspeed: 0.0679s/iter; left time: 473.1445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0796401 Vali Loss: 0.0940889 Test Loss: 0.1095062\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0799032\n",
      "\tspeed: 0.1158s/iter; left time: 792.3234s\n",
      "\titers: 200, epoch: 70 | loss: 0.0803926\n",
      "\tspeed: 0.0678s/iter; left time: 457.5913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0795255 Vali Loss: 0.0937263 Test Loss: 0.1092823\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0795657\n",
      "\tspeed: 0.1163s/iter; left time: 770.2990s\n",
      "\titers: 200, epoch: 71 | loss: 0.0781796\n",
      "\tspeed: 0.0678s/iter; left time: 442.3802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0796017 Vali Loss: 0.0937493 Test Loss: 0.1092873\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0814884\n",
      "\tspeed: 0.1174s/iter; left time: 751.1430s\n",
      "\titers: 200, epoch: 72 | loss: 0.0803019\n",
      "\tspeed: 0.0679s/iter; left time: 427.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0795672 Vali Loss: 0.0937267 Test Loss: 0.1090898\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0770385\n",
      "\tspeed: 0.1166s/iter; left time: 719.7624s\n",
      "\titers: 200, epoch: 73 | loss: 0.0806665\n",
      "\tspeed: 0.0678s/iter; left time: 411.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0795377 Vali Loss: 0.0938016 Test Loss: 0.1093636\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0794328\n",
      "\tspeed: 0.1163s/iter; left time: 691.9588s\n",
      "\titers: 200, epoch: 74 | loss: 0.0786658\n",
      "\tspeed: 0.0679s/iter; left time: 396.9021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0795583 Vali Loss: 0.0939235 Test Loss: 0.1093461\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028249364346265793, rmse:0.16807547211647034, mae:0.10912777483463287, rse:0.57981276512146\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3222283\n",
      "\tspeed: 0.0694s/iter; left time: 1548.6658s\n",
      "\titers: 200, epoch: 1 | loss: 0.2901604\n",
      "\tspeed: 0.0678s/iter; left time: 1504.7609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.3275235 Vali Loss: 0.2707392 Test Loss: 0.2808403\n",
      "Validation loss decreased (inf --> 0.270739).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1602906\n",
      "\tspeed: 0.1180s/iter; left time: 2604.2701s\n",
      "\titers: 200, epoch: 2 | loss: 0.1321118\n",
      "\tspeed: 0.0678s/iter; left time: 1490.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.1730665 Vali Loss: 0.1333407 Test Loss: 0.1507682\n",
      "Validation loss decreased (0.270739 --> 0.133341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1174136\n",
      "\tspeed: 0.1168s/iter; left time: 2552.2343s\n",
      "\titers: 200, epoch: 3 | loss: 0.1147236\n",
      "\tspeed: 0.0678s/iter; left time: 1474.9590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.1211365 Vali Loss: 0.1201252 Test Loss: 0.1346429\n",
      "Validation loss decreased (0.133341 --> 0.120125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086948\n",
      "\tspeed: 0.1170s/iter; left time: 2529.5320s\n",
      "\titers: 200, epoch: 4 | loss: 0.0996017\n",
      "\tspeed: 0.0678s/iter; left time: 1460.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.1074401 Vali Loss: 0.1075814 Test Loss: 0.1217205\n",
      "Validation loss decreased (0.120125 --> 0.107581).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0978587\n",
      "\tspeed: 0.1169s/iter; left time: 2502.6732s\n",
      "\titers: 200, epoch: 5 | loss: 0.0936922\n",
      "\tspeed: 0.0678s/iter; left time: 1444.7480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0990007 Vali Loss: 0.1022365 Test Loss: 0.1164719\n",
      "Validation loss decreased (0.107581 --> 0.102237).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0936737\n",
      "\tspeed: 0.1169s/iter; left time: 2476.5431s\n",
      "\titers: 200, epoch: 6 | loss: 0.0959559\n",
      "\tspeed: 0.0678s/iter; left time: 1429.3522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0955178 Vali Loss: 0.1066734 Test Loss: 0.1196931\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0883605\n",
      "\tspeed: 0.1162s/iter; left time: 2434.7179s\n",
      "\titers: 200, epoch: 7 | loss: 0.0905260\n",
      "\tspeed: 0.0678s/iter; left time: 1414.6496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0927021 Vali Loss: 0.0995970 Test Loss: 0.1136282\n",
      "Validation loss decreased (0.102237 --> 0.099597).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0895844\n",
      "\tspeed: 0.1170s/iter; left time: 2426.3955s\n",
      "\titers: 200, epoch: 8 | loss: 0.0906024\n",
      "\tspeed: 0.0678s/iter; left time: 1399.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0912533 Vali Loss: 0.0982151 Test Loss: 0.1121057\n",
      "Validation loss decreased (0.099597 --> 0.098215).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0919642\n",
      "\tspeed: 0.1170s/iter; left time: 2400.1665s\n",
      "\titers: 200, epoch: 9 | loss: 0.0885517\n",
      "\tspeed: 0.0678s/iter; left time: 1384.3499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0894342 Vali Loss: 0.1016691 Test Loss: 0.1151735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0839253\n",
      "\tspeed: 0.1165s/iter; left time: 2363.6825s\n",
      "\titers: 200, epoch: 10 | loss: 0.0854219\n",
      "\tspeed: 0.0679s/iter; left time: 1369.7043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0887283 Vali Loss: 0.0998190 Test Loss: 0.1137019\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0851813\n",
      "\tspeed: 0.1166s/iter; left time: 2339.2198s\n",
      "\titers: 200, epoch: 11 | loss: 0.0841998\n",
      "\tspeed: 0.0678s/iter; left time: 1354.2493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0878774 Vali Loss: 0.1002150 Test Loss: 0.1143990\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0846358\n",
      "\tspeed: 0.1164s/iter; left time: 2309.0575s\n",
      "\titers: 200, epoch: 12 | loss: 0.0845194\n",
      "\tspeed: 0.0678s/iter; left time: 1339.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0876602 Vali Loss: 0.0968735 Test Loss: 0.1114437\n",
      "Validation loss decreased (0.098215 --> 0.096873).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0870290\n",
      "\tspeed: 0.1169s/iter; left time: 2292.7583s\n",
      "\titers: 200, epoch: 13 | loss: 0.0865705\n",
      "\tspeed: 0.0678s/iter; left time: 1323.1310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0865886 Vali Loss: 0.1000299 Test Loss: 0.1141507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0909818\n",
      "\tspeed: 0.1161s/iter; left time: 2251.8984s\n",
      "\titers: 200, epoch: 14 | loss: 0.0896840\n",
      "\tspeed: 0.0678s/iter; left time: 1308.5278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0863740 Vali Loss: 0.0974694 Test Loss: 0.1123440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0841452\n",
      "\tspeed: 0.1161s/iter; left time: 2225.1642s\n",
      "\titers: 200, epoch: 15 | loss: 0.0885803\n",
      "\tspeed: 0.0678s/iter; left time: 1292.3045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0858258 Vali Loss: 0.0963815 Test Loss: 0.1107828\n",
      "Validation loss decreased (0.096873 --> 0.096381).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0865181\n",
      "\tspeed: 0.1166s/iter; left time: 2208.6558s\n",
      "\titers: 200, epoch: 16 | loss: 0.0901845\n",
      "\tspeed: 0.0678s/iter; left time: 1277.3758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0852364 Vali Loss: 0.0962136 Test Loss: 0.1103416\n",
      "Validation loss decreased (0.096381 --> 0.096214).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0889527\n",
      "\tspeed: 0.1605s/iter; left time: 3003.7332s\n",
      "\titers: 200, epoch: 17 | loss: 0.0878888\n",
      "\tspeed: 0.2342s/iter; left time: 4359.8137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:41.17s\n",
      "Steps: 224 | Train Loss: 0.0850811 Vali Loss: 0.0966598 Test Loss: 0.1109239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0886646\n",
      "\tspeed: 0.5369s/iter; left time: 9929.7277s\n",
      "\titers: 200, epoch: 18 | loss: 0.0831276\n",
      "\tspeed: 0.2332s/iter; left time: 4288.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:53.58s\n",
      "Steps: 224 | Train Loss: 0.0847246 Vali Loss: 0.0965277 Test Loss: 0.1106905\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0835528\n",
      "\tspeed: 0.5253s/iter; left time: 9597.3463s\n",
      "\titers: 200, epoch: 19 | loss: 0.0871794\n",
      "\tspeed: 0.2535s/iter; left time: 4605.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:53.94s\n",
      "Steps: 224 | Train Loss: 0.0843650 Vali Loss: 0.0961800 Test Loss: 0.1103212\n",
      "Validation loss decreased (0.096214 --> 0.096180).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0837552\n",
      "\tspeed: 0.1848s/iter; left time: 3334.5298s\n",
      "\titers: 200, epoch: 20 | loss: 0.0884110\n",
      "\tspeed: 0.0687s/iter; left time: 1233.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:16.18s\n",
      "Steps: 224 | Train Loss: 0.0843691 Vali Loss: 0.0984204 Test Loss: 0.1122508\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0854865\n",
      "\tspeed: 0.1197s/iter; left time: 2132.8330s\n",
      "\titers: 200, epoch: 21 | loss: 0.0842613\n",
      "\tspeed: 0.0685s/iter; left time: 1213.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 224 | Train Loss: 0.0841011 Vali Loss: 0.0965334 Test Loss: 0.1107563\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0791378\n",
      "\tspeed: 0.1183s/iter; left time: 2081.4819s\n",
      "\titers: 200, epoch: 22 | loss: 0.0875408\n",
      "\tspeed: 0.0683s/iter; left time: 1195.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0838343 Vali Loss: 0.0960553 Test Loss: 0.1100987\n",
      "Validation loss decreased (0.096180 --> 0.096055).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0863478\n",
      "\tspeed: 0.1177s/iter; left time: 2045.1952s\n",
      "\titers: 200, epoch: 23 | loss: 0.0897733\n",
      "\tspeed: 0.0680s/iter; left time: 1175.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0835647 Vali Loss: 0.0959386 Test Loss: 0.1100854\n",
      "Validation loss decreased (0.096055 --> 0.095939).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0884134\n",
      "\tspeed: 0.1176s/iter; left time: 2016.3650s\n",
      "\titers: 200, epoch: 24 | loss: 0.0875004\n",
      "\tspeed: 0.0680s/iter; left time: 1160.1223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0834458 Vali Loss: 0.0961582 Test Loss: 0.1099524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0872043\n",
      "\tspeed: 0.1171s/iter; left time: 1982.0131s\n",
      "\titers: 200, epoch: 25 | loss: 0.0858168\n",
      "\tspeed: 0.0681s/iter; left time: 1145.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0833030 Vali Loss: 0.0958514 Test Loss: 0.1103542\n",
      "Validation loss decreased (0.095939 --> 0.095851).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0881693\n",
      "\tspeed: 0.1177s/iter; left time: 1965.8446s\n",
      "\titers: 200, epoch: 26 | loss: 0.0787844\n",
      "\tspeed: 0.0681s/iter; left time: 1129.9292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0830345 Vali Loss: 0.0969319 Test Loss: 0.1107478\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0833040\n",
      "\tspeed: 0.1184s/iter; left time: 1951.1995s\n",
      "\titers: 200, epoch: 27 | loss: 0.0814600\n",
      "\tspeed: 0.0679s/iter; left time: 1112.7441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0829640 Vali Loss: 0.0961889 Test Loss: 0.1100811\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0829232\n",
      "\tspeed: 0.1166s/iter; left time: 1895.6568s\n",
      "\titers: 200, epoch: 28 | loss: 0.0826397\n",
      "\tspeed: 0.0681s/iter; left time: 1099.8548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0829745 Vali Loss: 0.0955726 Test Loss: 0.1097509\n",
      "Validation loss decreased (0.095851 --> 0.095573).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0743591\n",
      "\tspeed: 0.1177s/iter; left time: 1886.8317s\n",
      "\titers: 200, epoch: 29 | loss: 0.0796629\n",
      "\tspeed: 0.0679s/iter; left time: 1081.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0825501 Vali Loss: 0.0956070 Test Loss: 0.1094433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0834069\n",
      "\tspeed: 0.1170s/iter; left time: 1848.5244s\n",
      "\titers: 200, epoch: 30 | loss: 0.0827394\n",
      "\tspeed: 0.0681s/iter; left time: 1070.2409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0827461 Vali Loss: 0.0955111 Test Loss: 0.1095720\n",
      "Validation loss decreased (0.095573 --> 0.095511).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0870066\n",
      "\tspeed: 0.1189s/iter; left time: 1852.6963s\n",
      "\titers: 200, epoch: 31 | loss: 0.0869385\n",
      "\tspeed: 0.0681s/iter; left time: 1054.6517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0824202 Vali Loss: 0.0959376 Test Loss: 0.1099364\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0776116\n",
      "\tspeed: 0.1452s/iter; left time: 2229.8420s\n",
      "\titers: 200, epoch: 32 | loss: 0.0833593\n",
      "\tspeed: 0.2368s/iter; left time: 3612.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:39.03s\n",
      "Steps: 224 | Train Loss: 0.0824004 Vali Loss: 0.0955581 Test Loss: 0.1095486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0834297\n",
      "\tspeed: 0.4609s/iter; left time: 6974.5121s\n",
      "\titers: 200, epoch: 33 | loss: 0.0834464\n",
      "\tspeed: 0.0693s/iter; left time: 1042.0232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:24.89s\n",
      "Steps: 224 | Train Loss: 0.0821927 Vali Loss: 0.0952279 Test Loss: 0.1095006\n",
      "Validation loss decreased (0.095511 --> 0.095228).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0857229\n",
      "\tspeed: 0.1180s/iter; left time: 1759.7723s\n",
      "\titers: 200, epoch: 34 | loss: 0.0865955\n",
      "\tspeed: 0.0679s/iter; left time: 1005.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0822489 Vali Loss: 0.0953129 Test Loss: 0.1096318\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0862923\n",
      "\tspeed: 0.1157s/iter; left time: 1698.4167s\n",
      "\titers: 200, epoch: 35 | loss: 0.0826288\n",
      "\tspeed: 0.0677s/iter; left time: 988.1228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0821300 Vali Loss: 0.0952242 Test Loss: 0.1096192\n",
      "Validation loss decreased (0.095228 --> 0.095224).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0869841\n",
      "\tspeed: 0.1161s/iter; left time: 1679.5380s\n",
      "\titers: 200, epoch: 36 | loss: 0.0835670\n",
      "\tspeed: 0.0678s/iter; left time: 973.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0819915 Vali Loss: 0.0953858 Test Loss: 0.1095225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0890101\n",
      "\tspeed: 0.1153s/iter; left time: 1641.8199s\n",
      "\titers: 200, epoch: 37 | loss: 0.0876297\n",
      "\tspeed: 0.0677s/iter; left time: 957.4478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0819985 Vali Loss: 0.0952123 Test Loss: 0.1095570\n",
      "Validation loss decreased (0.095224 --> 0.095212).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0811275\n",
      "\tspeed: 0.1164s/iter; left time: 1630.8776s\n",
      "\titers: 200, epoch: 38 | loss: 0.0857123\n",
      "\tspeed: 0.0678s/iter; left time: 943.8249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0819279 Vali Loss: 0.0954286 Test Loss: 0.1094303\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0845944\n",
      "\tspeed: 0.1154s/iter; left time: 1590.5735s\n",
      "\titers: 200, epoch: 39 | loss: 0.0808392\n",
      "\tspeed: 0.0677s/iter; left time: 927.3094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0818573 Vali Loss: 0.0951859 Test Loss: 0.1093045\n",
      "Validation loss decreased (0.095212 --> 0.095186).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0794496\n",
      "\tspeed: 0.1169s/iter; left time: 1586.3884s\n",
      "\titers: 200, epoch: 40 | loss: 0.0806374\n",
      "\tspeed: 0.1487s/iter; left time: 2002.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:27.43s\n",
      "Steps: 224 | Train Loss: 0.0818810 Vali Loss: 0.0951958 Test Loss: 0.1095362\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0854377\n",
      "\tspeed: 0.5507s/iter; left time: 7346.9333s\n",
      "\titers: 200, epoch: 41 | loss: 0.0792054\n",
      "\tspeed: 0.2231s/iter; left time: 2954.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:54.79s\n",
      "Steps: 224 | Train Loss: 0.0818115 Vali Loss: 0.0957065 Test Loss: 0.1097157\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0811376\n",
      "\tspeed: 0.5386s/iter; left time: 7064.9166s\n",
      "\titers: 200, epoch: 42 | loss: 0.0831758\n",
      "\tspeed: 0.2431s/iter; left time: 3164.2063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:55.59s\n",
      "Steps: 224 | Train Loss: 0.0818207 Vali Loss: 0.0955534 Test Loss: 0.1096729\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0813392\n",
      "\tspeed: 0.3414s/iter; left time: 4401.7674s\n",
      "\titers: 200, epoch: 43 | loss: 0.0761101\n",
      "\tspeed: 0.0694s/iter; left time: 888.1284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:18.01s\n",
      "Steps: 224 | Train Loss: 0.0817577 Vali Loss: 0.0953017 Test Loss: 0.1095580\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0789302\n",
      "\tspeed: 0.1193s/iter; left time: 1511.3482s\n",
      "\titers: 200, epoch: 44 | loss: 0.0800888\n",
      "\tspeed: 0.0683s/iter; left time: 858.5705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0816636 Vali Loss: 0.0953180 Test Loss: 0.1094334\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0850189\n",
      "\tspeed: 0.1180s/iter; left time: 1468.5961s\n",
      "\titers: 200, epoch: 45 | loss: 0.0759723\n",
      "\tspeed: 0.0681s/iter; left time: 840.8248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0816955 Vali Loss: 0.0952263 Test Loss: 0.1094747\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0808012\n",
      "\tspeed: 0.1173s/iter; left time: 1433.3018s\n",
      "\titers: 200, epoch: 46 | loss: 0.0745684\n",
      "\tspeed: 0.0680s/iter; left time: 824.3763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0816511 Vali Loss: 0.0952656 Test Loss: 0.1095939\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0792706\n",
      "\tspeed: 0.1170s/iter; left time: 1403.9327s\n",
      "\titers: 200, epoch: 47 | loss: 0.0797736\n",
      "\tspeed: 0.0680s/iter; left time: 808.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0816263 Vali Loss: 0.0951350 Test Loss: 0.1094019\n",
      "Validation loss decreased (0.095186 --> 0.095135).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0832611\n",
      "\tspeed: 0.1179s/iter; left time: 1388.4546s\n",
      "\titers: 200, epoch: 48 | loss: 0.0824482\n",
      "\tspeed: 0.0681s/iter; left time: 794.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0817104 Vali Loss: 0.0954311 Test Loss: 0.1095216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0850974\n",
      "\tspeed: 0.1167s/iter; left time: 1347.6910s\n",
      "\titers: 200, epoch: 49 | loss: 0.0852645\n",
      "\tspeed: 0.0679s/iter; left time: 777.5195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0815837 Vali Loss: 0.0953491 Test Loss: 0.1093834\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0816431\n",
      "\tspeed: 0.1164s/iter; left time: 1318.4017s\n",
      "\titers: 200, epoch: 50 | loss: 0.0794944\n",
      "\tspeed: 0.0686s/iter; left time: 769.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0817087 Vali Loss: 0.0956946 Test Loss: 0.1098228\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0795038\n",
      "\tspeed: 0.1172s/iter; left time: 1301.3400s\n",
      "\titers: 200, epoch: 51 | loss: 0.0822431\n",
      "\tspeed: 0.0677s/iter; left time: 745.2495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0816681 Vali Loss: 0.0954143 Test Loss: 0.1096816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0877521\n",
      "\tspeed: 0.1161s/iter; left time: 1263.0205s\n",
      "\titers: 200, epoch: 52 | loss: 0.0765089\n",
      "\tspeed: 0.0678s/iter; left time: 730.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0815730 Vali Loss: 0.0951431 Test Loss: 0.1093641\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0802581\n",
      "\tspeed: 0.1157s/iter; left time: 1232.5248s\n",
      "\titers: 200, epoch: 53 | loss: 0.0837467\n",
      "\tspeed: 0.0678s/iter; left time: 715.2543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:15.35s\n",
      "Steps: 224 | Train Loss: 0.0815726 Vali Loss: 0.0951393 Test Loss: 0.1095178\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0794972\n",
      "\tspeed: 0.1165s/iter; left time: 1214.6291s\n",
      "\titers: 200, epoch: 54 | loss: 0.0821079\n",
      "\tspeed: 0.0678s/iter; left time: 700.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:15.37s\n",
      "Steps: 224 | Train Loss: 0.0815569 Vali Loss: 0.0952007 Test Loss: 0.1094604\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0811375\n",
      "\tspeed: 0.1157s/iter; left time: 1181.1909s\n",
      "\titers: 200, epoch: 55 | loss: 0.0770600\n",
      "\tspeed: 0.0678s/iter; left time: 685.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:15.38s\n",
      "Steps: 224 | Train Loss: 0.0815982 Vali Loss: 0.0953157 Test Loss: 0.1096376\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0796626\n",
      "\tspeed: 0.3489s/iter; left time: 3482.6155s\n",
      "\titers: 200, epoch: 56 | loss: 0.0827317\n",
      "\tspeed: 0.2227s/iter; left time: 2200.2785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:50.95s\n",
      "Steps: 224 | Train Loss: 0.0815271 Vali Loss: 0.0955043 Test Loss: 0.1098639\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0818036\n",
      "\tspeed: 0.2666s/iter; left time: 2601.1444s\n",
      "\titers: 200, epoch: 57 | loss: 0.0811589\n",
      "\tspeed: 0.0681s/iter; left time: 657.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:16.09s\n",
      "Steps: 224 | Train Loss: 0.0815377 Vali Loss: 0.0952988 Test Loss: 0.1093765\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028333809226751328, rmse:0.1683264970779419, mae:0.10940185934305191, rse:0.5806787014007568\n",
      "Intermediate time for GB and pred_len 24: 00h:54m:57.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3169750\n",
      "\tspeed: 0.0880s/iter; left time: 1963.3611s\n",
      "\titers: 200, epoch: 1 | loss: 0.2881276\n",
      "\tspeed: 0.0684s/iter; left time: 1517.5596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.77s\n",
      "Steps: 224 | Train Loss: 0.3206219 Vali Loss: 0.2645365 Test Loss: 0.2790965\n",
      "Validation loss decreased (inf --> 0.264536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1663200\n",
      "\tspeed: 0.1196s/iter; left time: 2640.4586s\n",
      "\titers: 200, epoch: 2 | loss: 0.1473166\n",
      "\tspeed: 0.0683s/iter; left time: 1501.9468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1757093 Vali Loss: 0.1537643 Test Loss: 0.1774506\n",
      "Validation loss decreased (0.264536 --> 0.153764).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1424125\n",
      "\tspeed: 0.1189s/iter; left time: 2597.5845s\n",
      "\titers: 200, epoch: 3 | loss: 0.1317283\n",
      "\tspeed: 0.0684s/iter; left time: 1488.3266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.1381992 Vali Loss: 0.1436413 Test Loss: 0.1684080\n",
      "Validation loss decreased (0.153764 --> 0.143641).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1251180\n",
      "\tspeed: 0.1190s/iter; left time: 2573.2823s\n",
      "\titers: 200, epoch: 4 | loss: 0.1242898\n",
      "\tspeed: 0.0685s/iter; left time: 1474.2977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1275144 Vali Loss: 0.1348831 Test Loss: 0.1587188\n",
      "Validation loss decreased (0.143641 --> 0.134883).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1227738\n",
      "\tspeed: 0.1191s/iter; left time: 2548.9742s\n",
      "\titers: 200, epoch: 5 | loss: 0.1203855\n",
      "\tspeed: 0.0685s/iter; left time: 1459.8222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1208138 Vali Loss: 0.1313551 Test Loss: 0.1568579\n",
      "Validation loss decreased (0.134883 --> 0.131355).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1178383\n",
      "\tspeed: 0.1190s/iter; left time: 2519.6887s\n",
      "\titers: 200, epoch: 6 | loss: 0.1207001\n",
      "\tspeed: 0.0686s/iter; left time: 1447.1948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1166023 Vali Loss: 0.1303846 Test Loss: 0.1578488\n",
      "Validation loss decreased (0.131355 --> 0.130385).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1098919\n",
      "\tspeed: 0.2714s/iter; left time: 5687.2663s\n",
      "\titers: 200, epoch: 7 | loss: 0.1204749\n",
      "\tspeed: 0.2462s/iter; left time: 5134.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.06s\n",
      "Steps: 224 | Train Loss: 0.1142685 Vali Loss: 0.1317136 Test Loss: 0.1583632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1117856\n",
      "\tspeed: 0.7455s/iter; left time: 15457.1694s\n",
      "\titers: 200, epoch: 8 | loss: 0.1085995\n",
      "\tspeed: 0.2278s/iter; left time: 4699.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:53.73s\n",
      "Steps: 224 | Train Loss: 0.1120069 Vali Loss: 0.1299827 Test Loss: 0.1577891\n",
      "Validation loss decreased (0.130385 --> 0.129983).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1104676\n",
      "\tspeed: 0.5713s/iter; left time: 11717.4158s\n",
      "\titers: 200, epoch: 9 | loss: 0.1100380\n",
      "\tspeed: 0.0692s/iter; left time: 1411.9155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.86s\n",
      "Steps: 224 | Train Loss: 0.1103160 Vali Loss: 0.1283327 Test Loss: 0.1568402\n",
      "Validation loss decreased (0.129983 --> 0.128333).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1062403\n",
      "\tspeed: 0.1221s/iter; left time: 2476.8274s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068847\n",
      "\tspeed: 0.0689s/iter; left time: 1390.9383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 224 | Train Loss: 0.1088186 Vali Loss: 0.1298223 Test Loss: 0.1571273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1070098\n",
      "\tspeed: 0.1197s/iter; left time: 2400.8612s\n",
      "\titers: 200, epoch: 11 | loss: 0.1091668\n",
      "\tspeed: 0.0686s/iter; left time: 1368.5480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1076475 Vali Loss: 0.1281295 Test Loss: 0.1562259\n",
      "Validation loss decreased (0.128333 --> 0.128129).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1109729\n",
      "\tspeed: 0.1198s/iter; left time: 2376.9822s\n",
      "\titers: 200, epoch: 12 | loss: 0.1091709\n",
      "\tspeed: 0.0683s/iter; left time: 1349.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1066719 Vali Loss: 0.1278947 Test Loss: 0.1572595\n",
      "Validation loss decreased (0.128129 --> 0.127895).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1025066\n",
      "\tspeed: 0.1184s/iter; left time: 2322.7134s\n",
      "\titers: 200, epoch: 13 | loss: 0.1075737\n",
      "\tspeed: 0.0683s/iter; left time: 1332.6086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.1058173 Vali Loss: 0.1292874 Test Loss: 0.1587619\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1080727\n",
      "\tspeed: 0.1173s/iter; left time: 2273.3856s\n",
      "\titers: 200, epoch: 14 | loss: 0.1040775\n",
      "\tspeed: 0.0683s/iter; left time: 1316.6614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.1050803 Vali Loss: 0.1268543 Test Loss: 0.1559605\n",
      "Validation loss decreased (0.127895 --> 0.126854).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1028651\n",
      "\tspeed: 0.1185s/iter; left time: 2270.9510s\n",
      "\titers: 200, epoch: 15 | loss: 0.1053593\n",
      "\tspeed: 0.0684s/iter; left time: 1303.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1044952 Vali Loss: 0.1285409 Test Loss: 0.1579565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1055906\n",
      "\tspeed: 0.1198s/iter; left time: 2269.6850s\n",
      "\titers: 200, epoch: 16 | loss: 0.1045404\n",
      "\tspeed: 0.0686s/iter; left time: 1291.7970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 224 | Train Loss: 0.1042184 Vali Loss: 0.1278868 Test Loss: 0.1568979\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1035954\n",
      "\tspeed: 0.1193s/iter; left time: 2233.2393s\n",
      "\titers: 200, epoch: 17 | loss: 0.1085246\n",
      "\tspeed: 0.0684s/iter; left time: 1272.5934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1037721 Vali Loss: 0.1290704 Test Loss: 0.1582800\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1056426\n",
      "\tspeed: 0.1193s/iter; left time: 2206.7668s\n",
      "\titers: 200, epoch: 18 | loss: 0.1035921\n",
      "\tspeed: 0.0687s/iter; left time: 1262.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.1032619 Vali Loss: 0.1292010 Test Loss: 0.1578627\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1053136\n",
      "\tspeed: 0.1193s/iter; left time: 2179.8487s\n",
      "\titers: 200, epoch: 19 | loss: 0.1067798\n",
      "\tspeed: 0.0687s/iter; left time: 1248.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.1031445 Vali Loss: 0.1300372 Test Loss: 0.1596100\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1016013\n",
      "\tspeed: 0.1210s/iter; left time: 2183.0293s\n",
      "\titers: 200, epoch: 20 | loss: 0.0956857\n",
      "\tspeed: 0.0702s/iter; left time: 1259.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.71s\n",
      "Steps: 224 | Train Loss: 0.1027117 Vali Loss: 0.1283159 Test Loss: 0.1576624\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1028783\n",
      "\tspeed: 0.4277s/iter; left time: 7621.9504s\n",
      "\titers: 200, epoch: 21 | loss: 0.1029517\n",
      "\tspeed: 0.2703s/iter; left time: 4789.5018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:59.35s\n",
      "Steps: 224 | Train Loss: 0.1026000 Vali Loss: 0.1266621 Test Loss: 0.1562652\n",
      "Validation loss decreased (0.126854 --> 0.126662).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1030157\n",
      "\tspeed: 0.1803s/iter; left time: 3171.9816s\n",
      "\titers: 200, epoch: 22 | loss: 0.1059813\n",
      "\tspeed: 0.0685s/iter; left time: 1198.4003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.1024473 Vali Loss: 0.1277447 Test Loss: 0.1570010\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1030701\n",
      "\tspeed: 0.1182s/iter; left time: 2054.3143s\n",
      "\titers: 200, epoch: 23 | loss: 0.1007732\n",
      "\tspeed: 0.0685s/iter; left time: 1183.4668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.1021506 Vali Loss: 0.1280225 Test Loss: 0.1575824\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1041662\n",
      "\tspeed: 0.1182s/iter; left time: 2027.5730s\n",
      "\titers: 200, epoch: 24 | loss: 0.1004910\n",
      "\tspeed: 0.0683s/iter; left time: 1164.1934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.1018550 Vali Loss: 0.1277011 Test Loss: 0.1572106\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1045048\n",
      "\tspeed: 0.1184s/iter; left time: 2004.2968s\n",
      "\titers: 200, epoch: 25 | loss: 0.1033388\n",
      "\tspeed: 0.0684s/iter; left time: 1150.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.1019648 Vali Loss: 0.1304723 Test Loss: 0.1601168\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1009486\n",
      "\tspeed: 0.1183s/iter; left time: 1976.1048s\n",
      "\titers: 200, epoch: 26 | loss: 0.1023198\n",
      "\tspeed: 0.0684s/iter; left time: 1135.7174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1016380 Vali Loss: 0.1280326 Test Loss: 0.1581513\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1040925\n",
      "\tspeed: 0.1183s/iter; left time: 1948.4230s\n",
      "\titers: 200, epoch: 27 | loss: 0.1032559\n",
      "\tspeed: 0.0684s/iter; left time: 1119.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.1015795 Vali Loss: 0.1279158 Test Loss: 0.1578829\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1010879\n",
      "\tspeed: 0.1191s/iter; left time: 1936.1266s\n",
      "\titers: 200, epoch: 28 | loss: 0.1000379\n",
      "\tspeed: 0.0684s/iter; left time: 1104.4238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.1014702 Vali Loss: 0.1279325 Test Loss: 0.1577735\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1014915\n",
      "\tspeed: 0.2012s/iter; left time: 3224.3768s\n",
      "\titers: 200, epoch: 29 | loss: 0.1022139\n",
      "\tspeed: 0.2260s/iter; left time: 3600.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:43.57s\n",
      "Steps: 224 | Train Loss: 0.1013546 Vali Loss: 0.1278439 Test Loss: 0.1582338\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0974159\n",
      "\tspeed: 0.7040s/iter; left time: 11126.2065s\n",
      "\titers: 200, epoch: 30 | loss: 0.0999115\n",
      "\tspeed: 0.2275s/iter; left time: 3572.5390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:52.21s\n",
      "Steps: 224 | Train Loss: 0.1012432 Vali Loss: 0.1281213 Test Loss: 0.1585170\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0977734\n",
      "\tspeed: 0.6626s/iter; left time: 10323.8093s\n",
      "\titers: 200, epoch: 31 | loss: 0.0993328\n",
      "\tspeed: 0.0829s/iter; left time: 1282.9985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:28.04s\n",
      "Steps: 224 | Train Loss: 0.1012069 Vali Loss: 0.1279055 Test Loss: 0.1578110\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.055297575891017914, rmse:0.23515436053276062, mae:0.1562652289867401, rse:0.8131965398788452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3213263\n",
      "\tspeed: 0.0708s/iter; left time: 1579.3922s\n",
      "\titers: 200, epoch: 1 | loss: 0.2936852\n",
      "\tspeed: 0.0689s/iter; left time: 1528.8254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 224 | Train Loss: 0.3264387 Vali Loss: 0.2631293 Test Loss: 0.2773281\n",
      "Validation loss decreased (inf --> 0.263129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1595035\n",
      "\tspeed: 0.1207s/iter; left time: 2665.6040s\n",
      "\titers: 200, epoch: 2 | loss: 0.1426246\n",
      "\tspeed: 0.0685s/iter; left time: 1506.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1768859 Vali Loss: 0.1548763 Test Loss: 0.1791462\n",
      "Validation loss decreased (0.263129 --> 0.154876).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1387125\n",
      "\tspeed: 0.1198s/iter; left time: 2618.9319s\n",
      "\titers: 200, epoch: 3 | loss: 0.1331362\n",
      "\tspeed: 0.0686s/iter; left time: 1492.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 224 | Train Loss: 0.1403248 Vali Loss: 0.1462416 Test Loss: 0.1698453\n",
      "Validation loss decreased (0.154876 --> 0.146242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1306412\n",
      "\tspeed: 0.1200s/iter; left time: 2594.6199s\n",
      "\titers: 200, epoch: 4 | loss: 0.1249516\n",
      "\tspeed: 0.0686s/iter; left time: 1476.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.1287224 Vali Loss: 0.1353822 Test Loss: 0.1601337\n",
      "Validation loss decreased (0.146242 --> 0.135382).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1205061\n",
      "\tspeed: 0.1194s/iter; left time: 2555.8680s\n",
      "\titers: 200, epoch: 5 | loss: 0.1171620\n",
      "\tspeed: 0.0684s/iter; left time: 1458.3135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1206041 Vali Loss: 0.1304662 Test Loss: 0.1546565\n",
      "Validation loss decreased (0.135382 --> 0.130466).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1144768\n",
      "\tspeed: 0.1197s/iter; left time: 2536.0689s\n",
      "\titers: 200, epoch: 6 | loss: 0.1183978\n",
      "\tspeed: 0.0686s/iter; left time: 1445.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.1167651 Vali Loss: 0.1297387 Test Loss: 0.1534602\n",
      "Validation loss decreased (0.130466 --> 0.129739).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1131930\n",
      "\tspeed: 0.1205s/iter; left time: 2524.7275s\n",
      "\titers: 200, epoch: 7 | loss: 0.1124424\n",
      "\tspeed: 0.0684s/iter; left time: 1427.1647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.1145741 Vali Loss: 0.1282972 Test Loss: 0.1531454\n",
      "Validation loss decreased (0.129739 --> 0.128297).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1138488\n",
      "\tspeed: 0.1186s/iter; left time: 2459.0336s\n",
      "\titers: 200, epoch: 8 | loss: 0.1083686\n",
      "\tspeed: 0.0684s/iter; left time: 1410.7710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1124879 Vali Loss: 0.1277906 Test Loss: 0.1520347\n",
      "Validation loss decreased (0.128297 --> 0.127791).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1138233\n",
      "\tspeed: 0.1201s/iter; left time: 2462.3419s\n",
      "\titers: 200, epoch: 9 | loss: 0.1063962\n",
      "\tspeed: 0.0686s/iter; left time: 1399.3770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.1112998 Vali Loss: 0.1299300 Test Loss: 0.1535692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1071215\n",
      "\tspeed: 0.1202s/iter; left time: 2438.7776s\n",
      "\titers: 200, epoch: 10 | loss: 0.1096780\n",
      "\tspeed: 0.0686s/iter; left time: 1384.9010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.1098623 Vali Loss: 0.1278667 Test Loss: 0.1535793\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1067223\n",
      "\tspeed: 0.1188s/iter; left time: 2383.9452s\n",
      "\titers: 200, epoch: 11 | loss: 0.1072859\n",
      "\tspeed: 0.0684s/iter; left time: 1365.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1085397 Vali Loss: 0.1272833 Test Loss: 0.1533077\n",
      "Validation loss decreased (0.127791 --> 0.127283).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1120278\n",
      "\tspeed: 0.2179s/iter; left time: 4322.1502s\n",
      "\titers: 200, epoch: 12 | loss: 0.1073823\n",
      "\tspeed: 0.2707s/iter; left time: 5343.3400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:50.09s\n",
      "Steps: 224 | Train Loss: 0.1077275 Vali Loss: 0.1265597 Test Loss: 0.1526796\n",
      "Validation loss decreased (0.127283 --> 0.126560).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1074749\n",
      "\tspeed: 0.3960s/iter; left time: 7767.3823s\n",
      "\titers: 200, epoch: 13 | loss: 0.1117152\n",
      "\tspeed: 0.0686s/iter; left time: 1337.6282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 224 | Train Loss: 0.1072227 Vali Loss: 0.1283648 Test Loss: 0.1544634\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1083647\n",
      "\tspeed: 0.1194s/iter; left time: 2314.4319s\n",
      "\titers: 200, epoch: 14 | loss: 0.1020139\n",
      "\tspeed: 0.0683s/iter; left time: 1316.9464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.1060189 Vali Loss: 0.1270502 Test Loss: 0.1537802\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1088050\n",
      "\tspeed: 0.1181s/iter; left time: 2264.2362s\n",
      "\titers: 200, epoch: 15 | loss: 0.0997452\n",
      "\tspeed: 0.0683s/iter; left time: 1302.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.1052837 Vali Loss: 0.1263013 Test Loss: 0.1530301\n",
      "Validation loss decreased (0.126560 --> 0.126301).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1048165\n",
      "\tspeed: 0.1194s/iter; left time: 2261.4386s\n",
      "\titers: 200, epoch: 16 | loss: 0.1058916\n",
      "\tspeed: 0.0683s/iter; left time: 1286.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.1046668 Vali Loss: 0.1277527 Test Loss: 0.1541391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1060658\n",
      "\tspeed: 0.1179s/iter; left time: 2206.8614s\n",
      "\titers: 200, epoch: 17 | loss: 0.1065919\n",
      "\tspeed: 0.0682s/iter; left time: 1270.5721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.1041877 Vali Loss: 0.1258110 Test Loss: 0.1539601\n",
      "Validation loss decreased (0.126301 --> 0.125811).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1041066\n",
      "\tspeed: 0.1182s/iter; left time: 2185.3229s\n",
      "\titers: 200, epoch: 18 | loss: 0.1046039\n",
      "\tspeed: 0.0682s/iter; left time: 1254.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.1038303 Vali Loss: 0.1250694 Test Loss: 0.1528935\n",
      "Validation loss decreased (0.125811 --> 0.125069).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0996255\n",
      "\tspeed: 0.1194s/iter; left time: 2180.7608s\n",
      "\titers: 200, epoch: 19 | loss: 0.1016979\n",
      "\tspeed: 0.0684s/iter; left time: 1242.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1033228 Vali Loss: 0.1253313 Test Loss: 0.1538103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1015119\n",
      "\tspeed: 0.1198s/iter; left time: 2161.8295s\n",
      "\titers: 200, epoch: 20 | loss: 0.0996533\n",
      "\tspeed: 0.0683s/iter; left time: 1225.0933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1030283 Vali Loss: 0.1250338 Test Loss: 0.1535553\n",
      "Validation loss decreased (0.125069 --> 0.125034).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1045069\n",
      "\tspeed: 0.1194s/iter; left time: 2128.2372s\n",
      "\titers: 200, epoch: 21 | loss: 0.1053994\n",
      "\tspeed: 0.0694s/iter; left time: 1230.2314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 224 | Train Loss: 0.1027459 Vali Loss: 0.1257903 Test Loss: 0.1535688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1027952\n",
      "\tspeed: 0.1194s/iter; left time: 2101.1229s\n",
      "\titers: 200, epoch: 22 | loss: 0.1054411\n",
      "\tspeed: 0.0685s/iter; left time: 1198.0984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1024764 Vali Loss: 0.1263182 Test Loss: 0.1534296\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0980702\n",
      "\tspeed: 0.1177s/iter; left time: 2044.3500s\n",
      "\titers: 200, epoch: 23 | loss: 0.1013577\n",
      "\tspeed: 0.0682s/iter; left time: 1178.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1023788 Vali Loss: 0.1270278 Test Loss: 0.1544092\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1023272\n",
      "\tspeed: 0.1188s/iter; left time: 2037.7057s\n",
      "\titers: 200, epoch: 24 | loss: 0.0994013\n",
      "\tspeed: 0.0683s/iter; left time: 1164.0986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.1022891 Vali Loss: 0.1256508 Test Loss: 0.1534510\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1017031\n",
      "\tspeed: 0.1183s/iter; left time: 2001.3982s\n",
      "\titers: 200, epoch: 25 | loss: 0.1011073\n",
      "\tspeed: 0.0683s/iter; left time: 1149.8186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.1019940 Vali Loss: 0.1252772 Test Loss: 0.1540989\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1007030\n",
      "\tspeed: 0.1192s/iter; left time: 1990.8955s\n",
      "\titers: 200, epoch: 26 | loss: 0.1028015\n",
      "\tspeed: 0.0685s/iter; left time: 1137.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 224 | Train Loss: 0.1017584 Vali Loss: 0.1257090 Test Loss: 0.1534888\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1060814\n",
      "\tspeed: 0.1181s/iter; left time: 1946.7532s\n",
      "\titers: 200, epoch: 27 | loss: 0.1012279\n",
      "\tspeed: 0.0683s/iter; left time: 1118.7954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.1017259 Vali Loss: 0.1256571 Test Loss: 0.1538251\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0997682\n",
      "\tspeed: 0.1189s/iter; left time: 1932.2005s\n",
      "\titers: 200, epoch: 28 | loss: 0.1026273\n",
      "\tspeed: 0.0688s/iter; left time: 1111.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 224 | Train Loss: 0.1015348 Vali Loss: 0.1256919 Test Loss: 0.1535066\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1027262\n",
      "\tspeed: 0.1191s/iter; left time: 1909.2206s\n",
      "\titers: 200, epoch: 29 | loss: 0.1005225\n",
      "\tspeed: 0.0685s/iter; left time: 1090.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1014530 Vali Loss: 0.1255419 Test Loss: 0.1533530\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0991079\n",
      "\tspeed: 0.1191s/iter; left time: 1881.8601s\n",
      "\titers: 200, epoch: 30 | loss: 0.1062865\n",
      "\tspeed: 0.0683s/iter; left time: 1073.2761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.1014423 Vali Loss: 0.1252416 Test Loss: 0.1534597\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05025710538029671, rmse:0.22418096661567688, mae:0.15355531871318817, rse:0.7752490043640137\n",
      "Intermediate time for GB and pred_len 96: 00h:26m:22.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3178788\n",
      "\tspeed: 0.0911s/iter; left time: 2023.0771s\n",
      "\titers: 200, epoch: 1 | loss: 0.2923456\n",
      "\tspeed: 0.0688s/iter; left time: 1520.8768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.80s\n",
      "Steps: 223 | Train Loss: 0.3259949 Vali Loss: 0.2644332 Test Loss: 0.2767115\n",
      "Validation loss decreased (inf --> 0.264433).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1662774\n",
      "\tspeed: 0.1199s/iter; left time: 2634.2229s\n",
      "\titers: 200, epoch: 2 | loss: 0.1549429\n",
      "\tspeed: 0.0689s/iter; left time: 1506.3061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1773751 Vali Loss: 0.1603866 Test Loss: 0.1843281\n",
      "Validation loss decreased (0.264433 --> 0.160387).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1436700\n",
      "\tspeed: 0.1191s/iter; left time: 2590.7280s\n",
      "\titers: 200, epoch: 3 | loss: 0.1387264\n",
      "\tspeed: 0.0687s/iter; left time: 1487.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 223 | Train Loss: 0.1429458 Vali Loss: 0.1490315 Test Loss: 0.1747674\n",
      "Validation loss decreased (0.160387 --> 0.149031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1370865\n",
      "\tspeed: 0.1228s/iter; left time: 2643.0602s\n",
      "\titers: 200, epoch: 4 | loss: 0.1259754\n",
      "\tspeed: 0.1034s/iter; left time: 2215.6762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:22.01s\n",
      "Steps: 223 | Train Loss: 0.1320976 Vali Loss: 0.1395856 Test Loss: 0.1673454\n",
      "Validation loss decreased (0.149031 --> 0.139586).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1263173\n",
      "\tspeed: 0.1509s/iter; left time: 3216.5060s\n",
      "\titers: 200, epoch: 5 | loss: 0.1211762\n",
      "\tspeed: 0.0686s/iter; left time: 1455.8749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.1243704 Vali Loss: 0.1347578 Test Loss: 0.1628246\n",
      "Validation loss decreased (0.139586 --> 0.134758).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1221866\n",
      "\tspeed: 0.1188s/iter; left time: 2504.6750s\n",
      "\titers: 200, epoch: 6 | loss: 0.1171794\n",
      "\tspeed: 0.0686s/iter; left time: 1439.2015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 223 | Train Loss: 0.1202449 Vali Loss: 0.1317599 Test Loss: 0.1594147\n",
      "Validation loss decreased (0.134758 --> 0.131760).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1144894\n",
      "\tspeed: 0.1190s/iter; left time: 2483.7325s\n",
      "\titers: 200, epoch: 7 | loss: 0.1136859\n",
      "\tspeed: 0.0685s/iter; left time: 1423.1621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 223 | Train Loss: 0.1172293 Vali Loss: 0.1319752 Test Loss: 0.1599068\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1169451\n",
      "\tspeed: 0.1168s/iter; left time: 2411.5134s\n",
      "\titers: 200, epoch: 8 | loss: 0.1151907\n",
      "\tspeed: 0.0686s/iter; left time: 1409.1092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 223 | Train Loss: 0.1143793 Vali Loss: 0.1314791 Test Loss: 0.1604246\n",
      "Validation loss decreased (0.131760 --> 0.131479).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1114159\n",
      "\tspeed: 0.1194s/iter; left time: 2437.5203s\n",
      "\titers: 200, epoch: 9 | loss: 0.1129710\n",
      "\tspeed: 0.0688s/iter; left time: 1396.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 223 | Train Loss: 0.1123416 Vali Loss: 0.1316020 Test Loss: 0.1608790\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1090529\n",
      "\tspeed: 0.1179s/iter; left time: 2380.0649s\n",
      "\titers: 200, epoch: 10 | loss: 0.1097888\n",
      "\tspeed: 0.0686s/iter; left time: 1378.1498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 223 | Train Loss: 0.1111040 Vali Loss: 0.1299448 Test Loss: 0.1607411\n",
      "Validation loss decreased (0.131479 --> 0.129945).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1063335\n",
      "\tspeed: 0.1183s/iter; left time: 2362.0418s\n",
      "\titers: 200, epoch: 11 | loss: 0.1076859\n",
      "\tspeed: 0.0685s/iter; left time: 1361.3396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 223 | Train Loss: 0.1096988 Vali Loss: 0.1294195 Test Loss: 0.1610959\n",
      "Validation loss decreased (0.129945 --> 0.129420).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066805\n",
      "\tspeed: 0.1191s/iter; left time: 2352.0233s\n",
      "\titers: 200, epoch: 12 | loss: 0.1117710\n",
      "\tspeed: 0.0686s/iter; left time: 1347.7398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 223 | Train Loss: 0.1091393 Vali Loss: 0.1304026 Test Loss: 0.1628561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1104881\n",
      "\tspeed: 0.1172s/iter; left time: 2287.8485s\n",
      "\titers: 200, epoch: 13 | loss: 0.1052860\n",
      "\tspeed: 0.0686s/iter; left time: 1331.9721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 223 | Train Loss: 0.1086703 Vali Loss: 0.1302683 Test Loss: 0.1632497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1065604\n",
      "\tspeed: 0.1178s/iter; left time: 2272.9136s\n",
      "\titers: 200, epoch: 14 | loss: 0.1098467\n",
      "\tspeed: 0.0712s/iter; left time: 1367.3552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.78s\n",
      "Steps: 223 | Train Loss: 0.1083066 Vali Loss: 0.1298479 Test Loss: 0.1623888\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1055012\n",
      "\tspeed: 0.1476s/iter; left time: 2815.3931s\n",
      "\titers: 200, epoch: 15 | loss: 0.1074526\n",
      "\tspeed: 0.1128s/iter; left time: 2140.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:21.01s\n",
      "Steps: 223 | Train Loss: 0.1078273 Vali Loss: 0.1314518 Test Loss: 0.1649764\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1113422\n",
      "\tspeed: 0.1280s/iter; left time: 2414.1605s\n",
      "\titers: 200, epoch: 16 | loss: 0.1098947\n",
      "\tspeed: 0.0691s/iter; left time: 1296.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.84s\n",
      "Steps: 223 | Train Loss: 0.1072573 Vali Loss: 0.1303975 Test Loss: 0.1639729\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1040608\n",
      "\tspeed: 0.1193s/iter; left time: 2222.6138s\n",
      "\titers: 200, epoch: 17 | loss: 0.1045298\n",
      "\tspeed: 0.0690s/iter; left time: 1278.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1069617 Vali Loss: 0.1305258 Test Loss: 0.1648742\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1084698\n",
      "\tspeed: 0.1209s/iter; left time: 2224.9621s\n",
      "\titers: 200, epoch: 18 | loss: 0.1086834\n",
      "\tspeed: 0.0690s/iter; left time: 1263.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.73s\n",
      "Steps: 223 | Train Loss: 0.1067326 Vali Loss: 0.1302603 Test Loss: 0.1646431\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1046197\n",
      "\tspeed: 0.1195s/iter; left time: 2172.4388s\n",
      "\titers: 200, epoch: 19 | loss: 0.1044805\n",
      "\tspeed: 0.0692s/iter; left time: 1250.8741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.1066076 Vali Loss: 0.1311304 Test Loss: 0.1665234\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1003867\n",
      "\tspeed: 0.1194s/iter; left time: 2144.9069s\n",
      "\titers: 200, epoch: 20 | loss: 0.1106835\n",
      "\tspeed: 0.0688s/iter; left time: 1229.6783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1061735 Vali Loss: 0.1302620 Test Loss: 0.1650163\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1092662\n",
      "\tspeed: 0.1189s/iter; left time: 2108.7792s\n",
      "\titers: 200, epoch: 21 | loss: 0.1012440\n",
      "\tspeed: 0.0691s/iter; left time: 1219.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1060473 Vali Loss: 0.1307661 Test Loss: 0.1661282\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05553150922060013, rmse:0.23565123975276947, mae:0.16109596192836761, rse:0.8170367479324341\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3220937\n",
      "\tspeed: 0.0708s/iter; left time: 1570.8923s\n",
      "\titers: 200, epoch: 1 | loss: 0.2928682\n",
      "\tspeed: 0.0690s/iter; left time: 1524.0984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.3265411 Vali Loss: 0.2711862 Test Loss: 0.2827702\n",
      "Validation loss decreased (inf --> 0.271186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1627164\n",
      "\tspeed: 0.1197s/iter; left time: 2630.2133s\n",
      "\titers: 200, epoch: 2 | loss: 0.1544721\n",
      "\tspeed: 0.0688s/iter; left time: 1505.6711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1790929 Vali Loss: 0.1578119 Test Loss: 0.1843138\n",
      "Validation loss decreased (0.271186 --> 0.157812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1483633\n",
      "\tspeed: 0.1201s/iter; left time: 2612.1727s\n",
      "\titers: 200, epoch: 3 | loss: 0.1423856\n",
      "\tspeed: 0.0689s/iter; left time: 1492.9238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.1446987 Vali Loss: 0.1530322 Test Loss: 0.1813037\n",
      "Validation loss decreased (0.157812 --> 0.153032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1387016\n",
      "\tspeed: 0.1203s/iter; left time: 2589.3054s\n",
      "\titers: 200, epoch: 4 | loss: 0.1318670\n",
      "\tspeed: 0.0691s/iter; left time: 1481.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:16.01s\n",
      "Steps: 223 | Train Loss: 0.1359290 Vali Loss: 0.1431802 Test Loss: 0.1688612\n",
      "Validation loss decreased (0.153032 --> 0.143180).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1262301\n",
      "\tspeed: 0.1343s/iter; left time: 2861.1616s\n",
      "\titers: 200, epoch: 5 | loss: 0.1240572\n",
      "\tspeed: 0.0697s/iter; left time: 1477.4584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.83s\n",
      "Steps: 223 | Train Loss: 0.1251006 Vali Loss: 0.1364144 Test Loss: 0.1612130\n",
      "Validation loss decreased (0.143180 --> 0.136414).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1194480\n",
      "\tspeed: 0.2065s/iter; left time: 4353.4483s\n",
      "\titers: 200, epoch: 6 | loss: 0.1151888\n",
      "\tspeed: 0.0687s/iter; left time: 1442.0837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.77s\n",
      "Steps: 223 | Train Loss: 0.1200589 Vali Loss: 0.1322296 Test Loss: 0.1575359\n",
      "Validation loss decreased (0.136414 --> 0.132230).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1191554\n",
      "\tspeed: 0.1195s/iter; left time: 2492.3958s\n",
      "\titers: 200, epoch: 7 | loss: 0.1147207\n",
      "\tspeed: 0.0691s/iter; left time: 1435.2921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1171536 Vali Loss: 0.1331214 Test Loss: 0.1579510\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1157147\n",
      "\tspeed: 0.1199s/iter; left time: 2475.1647s\n",
      "\titers: 200, epoch: 8 | loss: 0.1100614\n",
      "\tspeed: 0.0689s/iter; left time: 1415.9962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1151288 Vali Loss: 0.1319912 Test Loss: 0.1596739\n",
      "Validation loss decreased (0.132230 --> 0.131991).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1139205\n",
      "\tspeed: 0.1201s/iter; left time: 2451.0841s\n",
      "\titers: 200, epoch: 9 | loss: 0.1132901\n",
      "\tspeed: 0.0690s/iter; left time: 1402.5731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1136131 Vali Loss: 0.1328341 Test Loss: 0.1612450\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1065240\n",
      "\tspeed: 0.1190s/iter; left time: 2402.3414s\n",
      "\titers: 200, epoch: 10 | loss: 0.1097321\n",
      "\tspeed: 0.0690s/iter; left time: 1386.7280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1121639 Vali Loss: 0.1334039 Test Loss: 0.1620989\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1148773\n",
      "\tspeed: 0.1194s/iter; left time: 2383.8792s\n",
      "\titers: 200, epoch: 11 | loss: 0.1111459\n",
      "\tspeed: 0.0691s/iter; left time: 1373.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1111891 Vali Loss: 0.1326617 Test Loss: 0.1618879\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1088561\n",
      "\tspeed: 0.1254s/iter; left time: 2476.8834s\n",
      "\titers: 200, epoch: 12 | loss: 0.1096667\n",
      "\tspeed: 0.0785s/iter; left time: 1543.2015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:17.36s\n",
      "Steps: 223 | Train Loss: 0.1103449 Vali Loss: 0.1305904 Test Loss: 0.1611860\n",
      "Validation loss decreased (0.131991 --> 0.130590).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1115055\n",
      "\tspeed: 0.1630s/iter; left time: 3183.2037s\n",
      "\titers: 200, epoch: 13 | loss: 0.1067614\n",
      "\tspeed: 0.0921s/iter; left time: 1788.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:21.93s\n",
      "Steps: 223 | Train Loss: 0.1095131 Vali Loss: 0.1315813 Test Loss: 0.1615302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1109182\n",
      "\tspeed: 0.1201s/iter; left time: 2318.6851s\n",
      "\titers: 200, epoch: 14 | loss: 0.1072092\n",
      "\tspeed: 0.0690s/iter; left time: 1325.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1087886 Vali Loss: 0.1307806 Test Loss: 0.1619557\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1068741\n",
      "\tspeed: 0.1199s/iter; left time: 2287.6378s\n",
      "\titers: 200, epoch: 15 | loss: 0.1098697\n",
      "\tspeed: 0.0691s/iter; left time: 1310.5394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1082469 Vali Loss: 0.1311381 Test Loss: 0.1631835\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1080603\n",
      "\tspeed: 0.1207s/iter; left time: 2275.6380s\n",
      "\titers: 200, epoch: 16 | loss: 0.1063543\n",
      "\tspeed: 0.0692s/iter; left time: 1297.4792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1077243 Vali Loss: 0.1322044 Test Loss: 0.1632189\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1060837\n",
      "\tspeed: 0.1198s/iter; left time: 2231.8059s\n",
      "\titers: 200, epoch: 17 | loss: 0.1058377\n",
      "\tspeed: 0.0704s/iter; left time: 1303.9550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:16.74s\n",
      "Steps: 223 | Train Loss: 0.1073986 Vali Loss: 0.1311881 Test Loss: 0.1625414\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1099386\n",
      "\tspeed: 0.1776s/iter; left time: 3269.5204s\n",
      "\titers: 200, epoch: 18 | loss: 0.1083792\n",
      "\tspeed: 0.0698s/iter; left time: 1278.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:19.16s\n",
      "Steps: 223 | Train Loss: 0.1070542 Vali Loss: 0.1302419 Test Loss: 0.1622773\n",
      "Validation loss decreased (0.130590 --> 0.130242).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1097532\n",
      "\tspeed: 0.1219s/iter; left time: 2217.4112s\n",
      "\titers: 200, epoch: 19 | loss: 0.1098061\n",
      "\tspeed: 0.0690s/iter; left time: 1247.5618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1068559 Vali Loss: 0.1312371 Test Loss: 0.1628828\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1067220\n",
      "\tspeed: 0.1206s/iter; left time: 2166.4471s\n",
      "\titers: 200, epoch: 20 | loss: 0.1064276\n",
      "\tspeed: 0.0690s/iter; left time: 1233.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1065932 Vali Loss: 0.1302826 Test Loss: 0.1624851\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1061018\n",
      "\tspeed: 0.1197s/iter; left time: 2123.7099s\n",
      "\titers: 200, epoch: 21 | loss: 0.1063297\n",
      "\tspeed: 0.0691s/iter; left time: 1218.8795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 223 | Train Loss: 0.1062003 Vali Loss: 0.1306002 Test Loss: 0.1627120\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1040815\n",
      "\tspeed: 0.1223s/iter; left time: 2142.4732s\n",
      "\titers: 200, epoch: 22 | loss: 0.1036279\n",
      "\tspeed: 0.0818s/iter; left time: 1424.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:19.72s\n",
      "Steps: 223 | Train Loss: 0.1061612 Vali Loss: 0.1303557 Test Loss: 0.1619841\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1106365\n",
      "\tspeed: 0.1477s/iter; left time: 2554.1691s\n",
      "\titers: 200, epoch: 23 | loss: 0.1084486\n",
      "\tspeed: 0.0690s/iter; left time: 1186.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1059767 Vali Loss: 0.1316426 Test Loss: 0.1628718\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1054377\n",
      "\tspeed: 0.1212s/iter; left time: 2069.8940s\n",
      "\titers: 200, epoch: 24 | loss: 0.1064952\n",
      "\tspeed: 0.0690s/iter; left time: 1171.8834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1058640 Vali Loss: 0.1304258 Test Loss: 0.1627181\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1057636\n",
      "\tspeed: 0.1206s/iter; left time: 2032.4510s\n",
      "\titers: 200, epoch: 25 | loss: 0.1093200\n",
      "\tspeed: 0.0689s/iter; left time: 1154.4997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1056778 Vali Loss: 0.1304266 Test Loss: 0.1620312\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1097632\n",
      "\tspeed: 0.1202s/iter; left time: 1998.3310s\n",
      "\titers: 200, epoch: 26 | loss: 0.1009003\n",
      "\tspeed: 0.0697s/iter; left time: 1151.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.81s\n",
      "Steps: 223 | Train Loss: 0.1054972 Vali Loss: 0.1302184 Test Loss: 0.1619411\n",
      "Validation loss decreased (0.130242 --> 0.130218).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1061511\n",
      "\tspeed: 0.2126s/iter; left time: 3487.6126s\n",
      "\titers: 200, epoch: 27 | loss: 0.1052709\n",
      "\tspeed: 0.0691s/iter; left time: 1126.6861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:23.85s\n",
      "Steps: 223 | Train Loss: 0.1053943 Vali Loss: 0.1298898 Test Loss: 0.1619652\n",
      "Validation loss decreased (0.130218 --> 0.129890).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1031668\n",
      "\tspeed: 0.1211s/iter; left time: 1959.0123s\n",
      "\titers: 200, epoch: 28 | loss: 0.1052970\n",
      "\tspeed: 0.0691s/iter; left time: 1111.2382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.1052712 Vali Loss: 0.1301293 Test Loss: 0.1614759\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1024620\n",
      "\tspeed: 0.1195s/iter; left time: 1906.3538s\n",
      "\titers: 200, epoch: 29 | loss: 0.1065765\n",
      "\tspeed: 0.0691s/iter; left time: 1095.8002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.1051527 Vali Loss: 0.1301431 Test Loss: 0.1615664\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1087524\n",
      "\tspeed: 0.1207s/iter; left time: 1898.7900s\n",
      "\titers: 200, epoch: 30 | loss: 0.1060289\n",
      "\tspeed: 0.0690s/iter; left time: 1078.6829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 223 | Train Loss: 0.1051834 Vali Loss: 0.1301136 Test Loss: 0.1617431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1069650\n",
      "\tspeed: 0.2394s/iter; left time: 3712.7325s\n",
      "\titers: 200, epoch: 31 | loss: 0.1068179\n",
      "\tspeed: 0.0695s/iter; left time: 1070.9556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:23.96s\n",
      "Steps: 223 | Train Loss: 0.1050143 Vali Loss: 0.1305795 Test Loss: 0.1626422\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1043643\n",
      "\tspeed: 0.1205s/iter; left time: 1842.3756s\n",
      "\titers: 200, epoch: 32 | loss: 0.1073723\n",
      "\tspeed: 0.0691s/iter; left time: 1049.6293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 223 | Train Loss: 0.1050087 Vali Loss: 0.1300123 Test Loss: 0.1617196\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1067722\n",
      "\tspeed: 0.1204s/iter; left time: 1813.2039s\n",
      "\titers: 200, epoch: 33 | loss: 0.1065389\n",
      "\tspeed: 0.0690s/iter; left time: 1033.3138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1049209 Vali Loss: 0.1302650 Test Loss: 0.1618643\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1038698\n",
      "\tspeed: 0.1204s/iter; left time: 1787.2659s\n",
      "\titers: 200, epoch: 34 | loss: 0.1042006\n",
      "\tspeed: 0.0689s/iter; left time: 1016.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.1049528 Vali Loss: 0.1303447 Test Loss: 0.1622289\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.1084744\n",
      "\tspeed: 0.1230s/iter; left time: 1797.9720s\n",
      "\titers: 200, epoch: 35 | loss: 0.1047620\n",
      "\tspeed: 0.1377s/iter; left time: 1998.6257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:26.54s\n",
      "Steps: 223 | Train Loss: 0.1048341 Vali Loss: 0.1300388 Test Loss: 0.1617792\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.1027426\n",
      "\tspeed: 0.1940s/iter; left time: 2792.4356s\n",
      "\titers: 200, epoch: 36 | loss: 0.1072583\n",
      "\tspeed: 0.0690s/iter; left time: 986.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 223 | Train Loss: 0.1048162 Vali Loss: 0.1305285 Test Loss: 0.1625042\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1053733\n",
      "\tspeed: 0.1211s/iter; left time: 1716.1365s\n",
      "\titers: 200, epoch: 37 | loss: 0.1041081\n",
      "\tspeed: 0.0691s/iter; left time: 972.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 223 | Train Loss: 0.1047742 Vali Loss: 0.1298221 Test Loss: 0.1615249\n",
      "Validation loss decreased (0.129890 --> 0.129822).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1018013\n",
      "\tspeed: 0.1210s/iter; left time: 1687.4342s\n",
      "\titers: 200, epoch: 38 | loss: 0.1034053\n",
      "\tspeed: 0.0690s/iter; left time: 955.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.1047052 Vali Loss: 0.1301800 Test Loss: 0.1619754\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1040500\n",
      "\tspeed: 0.1201s/iter; left time: 1648.9457s\n",
      "\titers: 200, epoch: 39 | loss: 0.1008664\n",
      "\tspeed: 0.0698s/iter; left time: 950.9382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:16.79s\n",
      "Steps: 223 | Train Loss: 0.1046929 Vali Loss: 0.1297173 Test Loss: 0.1614800\n",
      "Validation loss decreased (0.129822 --> 0.129717).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1047179\n",
      "\tspeed: 0.1921s/iter; left time: 2593.5476s\n",
      "\titers: 200, epoch: 40 | loss: 0.1029734\n",
      "\tspeed: 0.0689s/iter; left time: 923.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:17.92s\n",
      "Steps: 223 | Train Loss: 0.1046336 Vali Loss: 0.1303146 Test Loss: 0.1619093\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1006989\n",
      "\tspeed: 0.1202s/iter; left time: 1596.7122s\n",
      "\titers: 200, epoch: 41 | loss: 0.1067691\n",
      "\tspeed: 0.0689s/iter; left time: 907.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1046242 Vali Loss: 0.1300258 Test Loss: 0.1617959\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1054534\n",
      "\tspeed: 0.1205s/iter; left time: 1573.3208s\n",
      "\titers: 200, epoch: 42 | loss: 0.1008451\n",
      "\tspeed: 0.0689s/iter; left time: 893.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 223 | Train Loss: 0.1045559 Vali Loss: 0.1304386 Test Loss: 0.1622602\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1041698\n",
      "\tspeed: 0.1211s/iter; left time: 1554.9490s\n",
      "\titers: 200, epoch: 43 | loss: 0.1043242\n",
      "\tspeed: 0.0688s/iter; left time: 876.7623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 223 | Train Loss: 0.1045775 Vali Loss: 0.1302977 Test Loss: 0.1620952\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1055942\n",
      "\tspeed: 0.1783s/iter; left time: 2248.3389s\n",
      "\titers: 200, epoch: 44 | loss: 0.1080230\n",
      "\tspeed: 0.1270s/iter; left time: 1589.2029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:27.14s\n",
      "Steps: 223 | Train Loss: 0.1044857 Vali Loss: 0.1301301 Test Loss: 0.1619160\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1044759\n",
      "\tspeed: 0.1203s/iter; left time: 1490.7396s\n",
      "\titers: 200, epoch: 45 | loss: 0.1024707\n",
      "\tspeed: 0.0688s/iter; left time: 845.5333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1046082 Vali Loss: 0.1303020 Test Loss: 0.1620725\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.1046853\n",
      "\tspeed: 0.1197s/iter; left time: 1456.0108s\n",
      "\titers: 200, epoch: 46 | loss: 0.1021922\n",
      "\tspeed: 0.0688s/iter; left time: 830.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 223 | Train Loss: 0.1044413 Vali Loss: 0.1303281 Test Loss: 0.1624765\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1080352\n",
      "\tspeed: 0.1199s/iter; left time: 1431.3807s\n",
      "\titers: 200, epoch: 47 | loss: 0.1057504\n",
      "\tspeed: 0.0688s/iter; left time: 814.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 223 | Train Loss: 0.1044894 Vali Loss: 0.1299390 Test Loss: 0.1618173\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1029571\n",
      "\tspeed: 0.1198s/iter; left time: 1404.1667s\n",
      "\titers: 200, epoch: 48 | loss: 0.1027101\n",
      "\tspeed: 0.1075s/iter; left time: 1248.7892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:19.43s\n",
      "Steps: 223 | Train Loss: 0.1045584 Vali Loss: 0.1296446 Test Loss: 0.1616373\n",
      "Validation loss decreased (0.129717 --> 0.129645).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1035345\n",
      "\tspeed: 0.1231s/iter; left time: 1415.3637s\n",
      "\titers: 200, epoch: 49 | loss: 0.1063920\n",
      "\tspeed: 0.0690s/iter; left time: 786.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 223 | Train Loss: 0.1044722 Vali Loss: 0.1300142 Test Loss: 0.1618235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1072999\n",
      "\tspeed: 0.1204s/iter; left time: 1357.3371s\n",
      "\titers: 200, epoch: 50 | loss: 0.1009309\n",
      "\tspeed: 0.0687s/iter; left time: 768.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 223 | Train Loss: 0.1044818 Vali Loss: 0.1299371 Test Loss: 0.1617304\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.1040873\n",
      "\tspeed: 0.1205s/iter; left time: 1331.4214s\n",
      "\titers: 200, epoch: 51 | loss: 0.1042919\n",
      "\tspeed: 0.0688s/iter; left time: 753.7172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 223 | Train Loss: 0.1044255 Vali Loss: 0.1302332 Test Loss: 0.1618712\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1018477\n",
      "\tspeed: 0.1197s/iter; left time: 1296.5005s\n",
      "\titers: 200, epoch: 52 | loss: 0.1011517\n",
      "\tspeed: 0.0688s/iter; left time: 737.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 223 | Train Loss: 0.1044164 Vali Loss: 0.1305412 Test Loss: 0.1623348\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1037970\n",
      "\tspeed: 0.1191s/iter; left time: 1262.6722s\n",
      "\titers: 200, epoch: 53 | loss: 0.1016964\n",
      "\tspeed: 0.0691s/iter; left time: 725.5527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:15.60s\n",
      "Steps: 223 | Train Loss: 0.1044532 Vali Loss: 0.1299148 Test Loss: 0.1617085\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.1061640\n",
      "\tspeed: 0.1197s/iter; left time: 1242.4980s\n",
      "\titers: 200, epoch: 54 | loss: 0.1015586\n",
      "\tspeed: 0.0687s/iter; left time: 706.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 223 | Train Loss: 0.1044523 Vali Loss: 0.1298204 Test Loss: 0.1616988\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.1027038\n",
      "\tspeed: 0.1199s/iter; left time: 1217.8123s\n",
      "\titers: 200, epoch: 55 | loss: 0.1028765\n",
      "\tspeed: 0.0687s/iter; left time: 691.4185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 223 | Train Loss: 0.1044153 Vali Loss: 0.1303736 Test Loss: 0.1622828\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1009147\n",
      "\tspeed: 0.1189s/iter; left time: 1181.8185s\n",
      "\titers: 200, epoch: 56 | loss: 0.1017771\n",
      "\tspeed: 0.0687s/iter; left time: 676.0785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 223 | Train Loss: 0.1044141 Vali Loss: 0.1299971 Test Loss: 0.1618284\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1031989\n",
      "\tspeed: 0.1199s/iter; left time: 1164.2418s\n",
      "\titers: 200, epoch: 57 | loss: 0.1005976\n",
      "\tspeed: 0.0687s/iter; left time: 660.6761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 223 | Train Loss: 0.1043671 Vali Loss: 0.1300140 Test Loss: 0.1617794\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.1040037\n",
      "\tspeed: 0.1209s/iter; left time: 1146.8853s\n",
      "\titers: 200, epoch: 58 | loss: 0.1038934\n",
      "\tspeed: 0.0692s/iter; left time: 649.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 223 | Train Loss: 0.1043640 Vali Loss: 0.1302291 Test Loss: 0.1621135\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05833651125431061, rmse:0.24152952432632446, mae:0.16163721680641174, rse:0.8374176025390625\n",
      "Intermediate time for GB and pred_len 168: 00h:26m:47.21s\n",
      "Intermediate time for GB: 01h:48m:07.78s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2969782\n",
      "\tspeed: 0.0624s/iter; left time: 1390.8227s\n",
      "\titers: 200, epoch: 1 | loss: 0.2848181\n",
      "\tspeed: 0.0420s/iter; left time: 933.3561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.3099947 Vali Loss: 0.2417072 Test Loss: 0.2518757\n",
      "Validation loss decreased (inf --> 0.241707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1848290\n",
      "\tspeed: 0.0756s/iter; left time: 1669.5229s\n",
      "\titers: 200, epoch: 2 | loss: 0.1344738\n",
      "\tspeed: 0.0419s/iter; left time: 920.1177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.1867603 Vali Loss: 0.1019580 Test Loss: 0.1337464\n",
      "Validation loss decreased (0.241707 --> 0.101958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1083067\n",
      "\tspeed: 0.0781s/iter; left time: 1707.3355s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986517\n",
      "\tspeed: 0.0419s/iter; left time: 910.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.1076227 Vali Loss: 0.0923575 Test Loss: 0.1274782\n",
      "Validation loss decreased (0.101958 --> 0.092357).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0901957\n",
      "\tspeed: 0.0766s/iter; left time: 1657.5418s\n",
      "\titers: 200, epoch: 4 | loss: 0.0860348\n",
      "\tspeed: 0.0420s/iter; left time: 904.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0903861 Vali Loss: 0.0826420 Test Loss: 0.1175130\n",
      "Validation loss decreased (0.092357 --> 0.082642).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0816583\n",
      "\tspeed: 0.0770s/iter; left time: 1648.8002s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792675\n",
      "\tspeed: 0.0419s/iter; left time: 892.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0825027 Vali Loss: 0.0785552 Test Loss: 0.1155358\n",
      "Validation loss decreased (0.082642 --> 0.078555).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831332\n",
      "\tspeed: 0.0778s/iter; left time: 1648.8032s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752746\n",
      "\tspeed: 0.0421s/iter; left time: 886.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0781817 Vali Loss: 0.0751555 Test Loss: 0.1114127\n",
      "Validation loss decreased (0.078555 --> 0.075156).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0757811\n",
      "\tspeed: 0.0771s/iter; left time: 1616.4075s\n",
      "\titers: 200, epoch: 7 | loss: 0.0727671\n",
      "\tspeed: 0.0419s/iter; left time: 874.4401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0755778 Vali Loss: 0.0740144 Test Loss: 0.1110919\n",
      "Validation loss decreased (0.075156 --> 0.074014).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0735922\n",
      "\tspeed: 0.0778s/iter; left time: 1612.5484s\n",
      "\titers: 200, epoch: 8 | loss: 0.0741481\n",
      "\tspeed: 0.0421s/iter; left time: 867.6276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0732737 Vali Loss: 0.0728997 Test Loss: 0.1096075\n",
      "Validation loss decreased (0.074014 --> 0.072900).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0683214\n",
      "\tspeed: 0.0767s/iter; left time: 1573.6396s\n",
      "\titers: 200, epoch: 9 | loss: 0.0727066\n",
      "\tspeed: 0.0420s/iter; left time: 856.7859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0718948 Vali Loss: 0.0706776 Test Loss: 0.1056429\n",
      "Validation loss decreased (0.072900 --> 0.070678).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0714071\n",
      "\tspeed: 0.0759s/iter; left time: 1539.6958s\n",
      "\titers: 200, epoch: 10 | loss: 0.0670859\n",
      "\tspeed: 0.0416s/iter; left time: 839.7293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0711862 Vali Loss: 0.0718091 Test Loss: 0.1094606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0712777\n",
      "\tspeed: 0.0759s/iter; left time: 1521.9330s\n",
      "\titers: 200, epoch: 11 | loss: 0.0714442\n",
      "\tspeed: 0.0418s/iter; left time: 835.3330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0704958 Vali Loss: 0.0744896 Test Loss: 0.1100109\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0679891\n",
      "\tspeed: 0.0753s/iter; left time: 1494.1520s\n",
      "\titers: 200, epoch: 12 | loss: 0.0675681\n",
      "\tspeed: 0.0430s/iter; left time: 849.1508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0688420 Vali Loss: 0.0727523 Test Loss: 0.1088118\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0696221\n",
      "\tspeed: 0.0759s/iter; left time: 1489.5738s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666364\n",
      "\tspeed: 0.0416s/iter; left time: 811.9774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0680980 Vali Loss: 0.0674424 Test Loss: 0.1055937\n",
      "Validation loss decreased (0.070678 --> 0.067442).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0671240\n",
      "\tspeed: 0.1610s/iter; left time: 3120.7558s\n",
      "\titers: 200, epoch: 14 | loss: 0.0711570\n",
      "\tspeed: 0.0426s/iter; left time: 821.0765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.60s\n",
      "Steps: 224 | Train Loss: 0.0672431 Vali Loss: 0.0685481 Test Loss: 0.1062085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0692275\n",
      "\tspeed: 0.0755s/iter; left time: 1446.0461s\n",
      "\titers: 200, epoch: 15 | loss: 0.0640853\n",
      "\tspeed: 0.0419s/iter; left time: 798.8950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0666175 Vali Loss: 0.0665498 Test Loss: 0.1033899\n",
      "Validation loss decreased (0.067442 --> 0.066550).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718984\n",
      "\tspeed: 0.0783s/iter; left time: 1483.1596s\n",
      "\titers: 200, epoch: 16 | loss: 0.0619983\n",
      "\tspeed: 0.0419s/iter; left time: 789.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0665043 Vali Loss: 0.0672393 Test Loss: 0.1047364\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0612650\n",
      "\tspeed: 0.0760s/iter; left time: 1421.8094s\n",
      "\titers: 200, epoch: 17 | loss: 0.0667755\n",
      "\tspeed: 0.0421s/iter; left time: 783.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0661099 Vali Loss: 0.0681034 Test Loss: 0.1057227\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0666565\n",
      "\tspeed: 0.0760s/iter; left time: 1405.9048s\n",
      "\titers: 200, epoch: 18 | loss: 0.0573703\n",
      "\tspeed: 0.0417s/iter; left time: 767.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0659246 Vali Loss: 0.0679260 Test Loss: 0.1050604\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0652420\n",
      "\tspeed: 0.0766s/iter; left time: 1399.3956s\n",
      "\titers: 200, epoch: 19 | loss: 0.0657160\n",
      "\tspeed: 0.0417s/iter; left time: 757.4383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0656611 Vali Loss: 0.0677988 Test Loss: 0.1053374\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0633934\n",
      "\tspeed: 0.0763s/iter; left time: 1376.0678s\n",
      "\titers: 200, epoch: 20 | loss: 0.0637959\n",
      "\tspeed: 0.0419s/iter; left time: 751.5554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0647019 Vali Loss: 0.0653679 Test Loss: 0.1040552\n",
      "Validation loss decreased (0.066550 --> 0.065368).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0646965\n",
      "\tspeed: 0.0768s/iter; left time: 1367.8146s\n",
      "\titers: 200, epoch: 21 | loss: 0.0633042\n",
      "\tspeed: 0.0419s/iter; left time: 742.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0643590 Vali Loss: 0.0650362 Test Loss: 0.1035038\n",
      "Validation loss decreased (0.065368 --> 0.065036).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0607972\n",
      "\tspeed: 0.0777s/iter; left time: 1367.4388s\n",
      "\titers: 200, epoch: 22 | loss: 0.0621712\n",
      "\tspeed: 0.0419s/iter; left time: 732.3608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0643140 Vali Loss: 0.0645524 Test Loss: 0.1033063\n",
      "Validation loss decreased (0.065036 --> 0.064552).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0633903\n",
      "\tspeed: 0.0772s/iter; left time: 1341.4228s\n",
      "\titers: 200, epoch: 23 | loss: 0.0652632\n",
      "\tspeed: 0.0419s/iter; left time: 723.9299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0641129 Vali Loss: 0.0644914 Test Loss: 0.1031610\n",
      "Validation loss decreased (0.064552 --> 0.064491).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0647882\n",
      "\tspeed: 0.0769s/iter; left time: 1317.9686s\n",
      "\titers: 200, epoch: 24 | loss: 0.0620209\n",
      "\tspeed: 0.0418s/iter; left time: 712.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0636890 Vali Loss: 0.0654922 Test Loss: 0.1041104\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0607424\n",
      "\tspeed: 0.0759s/iter; left time: 1284.1643s\n",
      "\titers: 200, epoch: 25 | loss: 0.0637143\n",
      "\tspeed: 0.0418s/iter; left time: 703.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0637573 Vali Loss: 0.0649770 Test Loss: 0.1038786\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0602002\n",
      "\tspeed: 0.0761s/iter; left time: 1270.1305s\n",
      "\titers: 200, epoch: 26 | loss: 0.0627217\n",
      "\tspeed: 0.0419s/iter; left time: 695.2978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0638854 Vali Loss: 0.0643979 Test Loss: 0.1035589\n",
      "Validation loss decreased (0.064491 --> 0.064398).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0634241\n",
      "\tspeed: 0.0762s/iter; left time: 1255.3470s\n",
      "\titers: 200, epoch: 27 | loss: 0.0613509\n",
      "\tspeed: 0.0420s/iter; left time: 688.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0633666 Vali Loss: 0.0646030 Test Loss: 0.1034520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0636885\n",
      "\tspeed: 0.0758s/iter; left time: 1231.8313s\n",
      "\titers: 200, epoch: 28 | loss: 0.0625637\n",
      "\tspeed: 0.0421s/iter; left time: 680.8065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0632894 Vali Loss: 0.0640186 Test Loss: 0.1026007\n",
      "Validation loss decreased (0.064398 --> 0.064019).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0603631\n",
      "\tspeed: 0.0772s/iter; left time: 1237.2408s\n",
      "\titers: 200, epoch: 29 | loss: 0.0655534\n",
      "\tspeed: 0.0420s/iter; left time: 668.3015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0634083 Vali Loss: 0.0644178 Test Loss: 0.1025875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0612983\n",
      "\tspeed: 0.0785s/iter; left time: 1240.8103s\n",
      "\titers: 200, epoch: 30 | loss: 0.0626814\n",
      "\tspeed: 0.0571s/iter; left time: 896.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:11.12s\n",
      "Steps: 224 | Train Loss: 0.0632753 Vali Loss: 0.0638927 Test Loss: 0.1024270\n",
      "Validation loss decreased (0.064019 --> 0.063893).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0659513\n",
      "\tspeed: 0.1045s/iter; left time: 1627.6579s\n",
      "\titers: 200, epoch: 31 | loss: 0.0602627\n",
      "\tspeed: 0.0869s/iter; left time: 1345.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:16.72s\n",
      "Steps: 224 | Train Loss: 0.0628989 Vali Loss: 0.0637835 Test Loss: 0.1026227\n",
      "Validation loss decreased (0.063893 --> 0.063784).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0610498\n",
      "\tspeed: 0.0782s/iter; left time: 1200.5528s\n",
      "\titers: 200, epoch: 32 | loss: 0.0619866\n",
      "\tspeed: 0.0419s/iter; left time: 639.4519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 224 | Train Loss: 0.0629406 Vali Loss: 0.0635268 Test Loss: 0.1017295\n",
      "Validation loss decreased (0.063784 --> 0.063527).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0594108\n",
      "\tspeed: 0.0770s/iter; left time: 1164.7958s\n",
      "\titers: 200, epoch: 33 | loss: 0.0657239\n",
      "\tspeed: 0.0417s/iter; left time: 626.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0628200 Vali Loss: 0.0632554 Test Loss: 0.1015375\n",
      "Validation loss decreased (0.063527 --> 0.063255).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0617365\n",
      "\tspeed: 0.0771s/iter; left time: 1148.8868s\n",
      "\titers: 200, epoch: 34 | loss: 0.0654174\n",
      "\tspeed: 0.0420s/iter; left time: 621.4962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0628480 Vali Loss: 0.0634023 Test Loss: 0.1022384\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0830358\n",
      "\tspeed: 0.0761s/iter; left time: 1116.7988s\n",
      "\titers: 200, epoch: 35 | loss: 0.0660892\n",
      "\tspeed: 0.0420s/iter; left time: 612.2474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0625988 Vali Loss: 0.0634901 Test Loss: 0.1023343\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0614504\n",
      "\tspeed: 0.0761s/iter; left time: 1100.1748s\n",
      "\titers: 200, epoch: 36 | loss: 0.0634940\n",
      "\tspeed: 0.0419s/iter; left time: 601.9032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0624937 Vali Loss: 0.0635237 Test Loss: 0.1021846\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0619065\n",
      "\tspeed: 0.0760s/iter; left time: 1081.7083s\n",
      "\titers: 200, epoch: 37 | loss: 0.0641240\n",
      "\tspeed: 0.0420s/iter; left time: 593.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0625420 Vali Loss: 0.0637189 Test Loss: 0.1024002\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0638381\n",
      "\tspeed: 0.0758s/iter; left time: 1062.2565s\n",
      "\titers: 200, epoch: 38 | loss: 0.0661423\n",
      "\tspeed: 0.0418s/iter; left time: 581.0056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0625353 Vali Loss: 0.0632093 Test Loss: 0.1016678\n",
      "Validation loss decreased (0.063255 --> 0.063209).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0633878\n",
      "\tspeed: 0.0780s/iter; left time: 1075.8652s\n",
      "\titers: 200, epoch: 39 | loss: 0.0671987\n",
      "\tspeed: 0.0422s/iter; left time: 577.9476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 224 | Train Loss: 0.0624482 Vali Loss: 0.0633314 Test Loss: 0.1021873\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0602313\n",
      "\tspeed: 0.0769s/iter; left time: 1043.7254s\n",
      "\titers: 200, epoch: 40 | loss: 0.0633773\n",
      "\tspeed: 0.0420s/iter; left time: 565.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0623474 Vali Loss: 0.0629474 Test Loss: 0.1011494\n",
      "Validation loss decreased (0.063209 --> 0.062947).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0638251\n",
      "\tspeed: 0.0770s/iter; left time: 1026.6839s\n",
      "\titers: 200, epoch: 41 | loss: 0.0603166\n",
      "\tspeed: 0.0419s/iter; left time: 555.3844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0624631 Vali Loss: 0.0636755 Test Loss: 0.1026333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0580806\n",
      "\tspeed: 0.0762s/iter; left time: 999.9439s\n",
      "\titers: 200, epoch: 42 | loss: 0.0627259\n",
      "\tspeed: 0.0420s/iter; left time: 547.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0623971 Vali Loss: 0.0633200 Test Loss: 0.1019768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0651261\n",
      "\tspeed: 0.0763s/iter; left time: 984.2956s\n",
      "\titers: 200, epoch: 43 | loss: 0.0596089\n",
      "\tspeed: 0.0419s/iter; left time: 536.1444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0624995 Vali Loss: 0.0632033 Test Loss: 0.1015226\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0612748\n",
      "\tspeed: 0.0761s/iter; left time: 964.3878s\n",
      "\titers: 200, epoch: 44 | loss: 0.0605403\n",
      "\tspeed: 0.0420s/iter; left time: 527.9146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0622573 Vali Loss: 0.0633831 Test Loss: 0.1021693\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0630317\n",
      "\tspeed: 0.0752s/iter; left time: 936.4736s\n",
      "\titers: 200, epoch: 45 | loss: 0.0618033\n",
      "\tspeed: 0.0417s/iter; left time: 515.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0621072 Vali Loss: 0.0631078 Test Loss: 0.1017102\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0653242\n",
      "\tspeed: 0.0756s/iter; left time: 923.4849s\n",
      "\titers: 200, epoch: 46 | loss: 0.0600338\n",
      "\tspeed: 0.0417s/iter; left time: 505.7184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0623204 Vali Loss: 0.0632553 Test Loss: 0.1021422\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0627592\n",
      "\tspeed: 0.0769s/iter; left time: 922.3536s\n",
      "\titers: 200, epoch: 47 | loss: 0.0620785\n",
      "\tspeed: 0.0421s/iter; left time: 500.5321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0626384 Vali Loss: 0.0632824 Test Loss: 0.1017535\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0619225\n",
      "\tspeed: 0.0757s/iter; left time: 890.6959s\n",
      "\titers: 200, epoch: 48 | loss: 0.0617065\n",
      "\tspeed: 0.0419s/iter; left time: 489.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0623582 Vali Loss: 0.0636189 Test Loss: 0.1024202\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0646035\n",
      "\tspeed: 0.0810s/iter; left time: 935.1205s\n",
      "\titers: 200, epoch: 49 | loss: 0.0649961\n",
      "\tspeed: 0.0576s/iter; left time: 659.7773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0625608 Vali Loss: 0.0634351 Test Loss: 0.1020974\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0722272\n",
      "\tspeed: 0.0874s/iter; left time: 989.3676s\n",
      "\titers: 200, epoch: 50 | loss: 0.0626167\n",
      "\tspeed: 0.0962s/iter; left time: 1080.2464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:16.05s\n",
      "Steps: 224 | Train Loss: 0.0620980 Vali Loss: 0.0634771 Test Loss: 0.1022312\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03204134851694107, rmse:0.17900097370147705, mae:0.10114945471286774, rse:0.5267782211303711\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3040702\n",
      "\tspeed: 0.0454s/iter; left time: 1012.8011s\n",
      "\titers: 200, epoch: 1 | loss: 0.2848296\n",
      "\tspeed: 0.0419s/iter; left time: 930.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 224 | Train Loss: 0.3129976 Vali Loss: 0.2367104 Test Loss: 0.2497184\n",
      "Validation loss decreased (inf --> 0.236710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1877909\n",
      "\tspeed: 0.0760s/iter; left time: 1677.0614s\n",
      "\titers: 200, epoch: 2 | loss: 0.1270314\n",
      "\tspeed: 0.0420s/iter; left time: 922.0211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.1846337 Vali Loss: 0.0989219 Test Loss: 0.1295060\n",
      "Validation loss decreased (0.236710 --> 0.098922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1082149\n",
      "\tspeed: 0.0764s/iter; left time: 1668.7557s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017429\n",
      "\tspeed: 0.0420s/iter; left time: 913.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.1078061 Vali Loss: 0.0898247 Test Loss: 0.1228970\n",
      "Validation loss decreased (0.098922 --> 0.089825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0940109\n",
      "\tspeed: 0.0839s/iter; left time: 1815.6201s\n",
      "\titers: 200, epoch: 4 | loss: 0.0900475\n",
      "\tspeed: 0.0419s/iter; left time: 901.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0931928 Vali Loss: 0.0837358 Test Loss: 0.1193305\n",
      "Validation loss decreased (0.089825 --> 0.083736).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0800315\n",
      "\tspeed: 0.0763s/iter; left time: 1632.7743s\n",
      "\titers: 200, epoch: 5 | loss: 0.0798925\n",
      "\tspeed: 0.0419s/iter; left time: 893.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0840470 Vali Loss: 0.0809535 Test Loss: 0.1171062\n",
      "Validation loss decreased (0.083736 --> 0.080954).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0761936\n",
      "\tspeed: 0.0755s/iter; left time: 1598.4760s\n",
      "\titers: 200, epoch: 6 | loss: 0.0752984\n",
      "\tspeed: 0.0422s/iter; left time: 888.8327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0782517 Vali Loss: 0.0773642 Test Loss: 0.1099562\n",
      "Validation loss decreased (0.080954 --> 0.077364).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0761986\n",
      "\tspeed: 0.0769s/iter; left time: 1612.6226s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771992\n",
      "\tspeed: 0.0421s/iter; left time: 877.5079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0748932 Vali Loss: 0.0782370 Test Loss: 0.1114239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758020\n",
      "\tspeed: 0.0754s/iter; left time: 1562.4008s\n",
      "\titers: 200, epoch: 8 | loss: 0.0688515\n",
      "\tspeed: 0.0419s/iter; left time: 864.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0732379 Vali Loss: 0.0822971 Test Loss: 0.1163146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742006\n",
      "\tspeed: 0.0755s/iter; left time: 1549.2195s\n",
      "\titers: 200, epoch: 9 | loss: 0.0742987\n",
      "\tspeed: 0.0419s/iter; left time: 855.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0726769 Vali Loss: 0.0728387 Test Loss: 0.1075436\n",
      "Validation loss decreased (0.077364 --> 0.072839).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0723879\n",
      "\tspeed: 0.0761s/iter; left time: 1544.4314s\n",
      "\titers: 200, epoch: 10 | loss: 0.0694383\n",
      "\tspeed: 0.0453s/iter; left time: 914.1750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0705322 Vali Loss: 0.0697538 Test Loss: 0.1041736\n",
      "Validation loss decreased (0.072839 --> 0.069754).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0654747\n",
      "\tspeed: 0.0980s/iter; left time: 1965.2806s\n",
      "\titers: 200, epoch: 11 | loss: 0.0674724\n",
      "\tspeed: 0.0428s/iter; left time: 853.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 224 | Train Loss: 0.0694558 Vali Loss: 0.0677067 Test Loss: 0.1030403\n",
      "Validation loss decreased (0.069754 --> 0.067707).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0690965\n",
      "\tspeed: 0.1628s/iter; left time: 3229.6745s\n",
      "\titers: 200, epoch: 12 | loss: 0.0623102\n",
      "\tspeed: 0.0418s/iter; left time: 825.9349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 224 | Train Loss: 0.0689204 Vali Loss: 0.0714320 Test Loss: 0.1070745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0670562\n",
      "\tspeed: 0.0765s/iter; left time: 1501.3036s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728040\n",
      "\tspeed: 0.0418s/iter; left time: 814.8391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0682545 Vali Loss: 0.0684639 Test Loss: 0.1046136\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0674113\n",
      "\tspeed: 0.0755s/iter; left time: 1464.2614s\n",
      "\titers: 200, epoch: 14 | loss: 0.0678724\n",
      "\tspeed: 0.0419s/iter; left time: 808.3386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0667886 Vali Loss: 0.0661299 Test Loss: 0.1019469\n",
      "Validation loss decreased (0.067707 --> 0.066130).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0645410\n",
      "\tspeed: 0.0760s/iter; left time: 1456.4805s\n",
      "\titers: 200, epoch: 15 | loss: 0.0658526\n",
      "\tspeed: 0.0417s/iter; left time: 795.1016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0676263 Vali Loss: 0.0656435 Test Loss: 0.1016600\n",
      "Validation loss decreased (0.066130 --> 0.065644).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0635019\n",
      "\tspeed: 0.0757s/iter; left time: 1433.7949s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626586\n",
      "\tspeed: 0.0418s/iter; left time: 787.0239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0659775 Vali Loss: 0.0662502 Test Loss: 0.1030600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0665868\n",
      "\tspeed: 0.0754s/iter; left time: 1410.9728s\n",
      "\titers: 200, epoch: 17 | loss: 0.0627290\n",
      "\tspeed: 0.0417s/iter; left time: 776.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0665784 Vali Loss: 0.0672984 Test Loss: 0.1040684\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0658090\n",
      "\tspeed: 0.0746s/iter; left time: 1378.9309s\n",
      "\titers: 200, epoch: 18 | loss: 0.0630280\n",
      "\tspeed: 0.0415s/iter; left time: 763.8913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0653366 Vali Loss: 0.0644701 Test Loss: 0.1009772\n",
      "Validation loss decreased (0.065644 --> 0.064470).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0608536\n",
      "\tspeed: 0.0985s/iter; left time: 1800.0980s\n",
      "\titers: 200, epoch: 19 | loss: 0.0632304\n",
      "\tspeed: 0.0420s/iter; left time: 762.6525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 224 | Train Loss: 0.0648644 Vali Loss: 0.0650027 Test Loss: 0.1031399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0614164\n",
      "\tspeed: 0.2970s/iter; left time: 5358.5950s\n",
      "\titers: 200, epoch: 20 | loss: 0.0647077\n",
      "\tspeed: 0.0431s/iter; left time: 772.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:14.61s\n",
      "Steps: 224 | Train Loss: 0.0647560 Vali Loss: 0.0649638 Test Loss: 0.1027986\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0654586\n",
      "\tspeed: 0.0765s/iter; left time: 1362.8960s\n",
      "\titers: 200, epoch: 21 | loss: 0.0650276\n",
      "\tspeed: 0.0416s/iter; left time: 737.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0647231 Vali Loss: 0.0655589 Test Loss: 0.1038612\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0635779\n",
      "\tspeed: 0.0762s/iter; left time: 1340.6459s\n",
      "\titers: 200, epoch: 22 | loss: 0.0621915\n",
      "\tspeed: 0.0416s/iter; left time: 727.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0642539 Vali Loss: 0.0649902 Test Loss: 0.1028115\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0669944\n",
      "\tspeed: 0.0753s/iter; left time: 1308.8789s\n",
      "\titers: 200, epoch: 23 | loss: 0.0618597\n",
      "\tspeed: 0.0416s/iter; left time: 718.1342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0636678 Vali Loss: 0.0637351 Test Loss: 0.1002939\n",
      "Validation loss decreased (0.064470 --> 0.063735).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0658914\n",
      "\tspeed: 0.0756s/iter; left time: 1296.8298s\n",
      "\titers: 200, epoch: 24 | loss: 0.0621620\n",
      "\tspeed: 0.0416s/iter; left time: 709.4555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0636545 Vali Loss: 0.0643962 Test Loss: 0.1022475\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0671881\n",
      "\tspeed: 0.0746s/iter; left time: 1262.2913s\n",
      "\titers: 200, epoch: 25 | loss: 0.0649349\n",
      "\tspeed: 0.0416s/iter; left time: 700.2971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0634709 Vali Loss: 0.0677023 Test Loss: 0.1059123\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0605779\n",
      "\tspeed: 0.0761s/iter; left time: 1270.7019s\n",
      "\titers: 200, epoch: 26 | loss: 0.0651757\n",
      "\tspeed: 0.0417s/iter; left time: 691.9109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0635207 Vali Loss: 0.0637382 Test Loss: 0.1018251\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0597215\n",
      "\tspeed: 0.0810s/iter; left time: 1335.0692s\n",
      "\titers: 200, epoch: 27 | loss: 0.0621646\n",
      "\tspeed: 0.1280s/iter; left time: 2096.0977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:20.06s\n",
      "Steps: 224 | Train Loss: 0.0635524 Vali Loss: 0.0654647 Test Loss: 0.1033429\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0673666\n",
      "\tspeed: 0.1374s/iter; left time: 2233.2312s\n",
      "\titers: 200, epoch: 28 | loss: 0.0635607\n",
      "\tspeed: 0.0437s/iter; left time: 706.5381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0634994 Vali Loss: 0.0635891 Test Loss: 0.1011490\n",
      "Validation loss decreased (0.063735 --> 0.063589).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0622385\n",
      "\tspeed: 0.0768s/iter; left time: 1230.6723s\n",
      "\titers: 200, epoch: 29 | loss: 0.0602465\n",
      "\tspeed: 0.0416s/iter; left time: 663.3179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0628856 Vali Loss: 0.0634477 Test Loss: 0.1011946\n",
      "Validation loss decreased (0.063589 --> 0.063448).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0617370\n",
      "\tspeed: 0.0762s/iter; left time: 1203.7771s\n",
      "\titers: 200, epoch: 30 | loss: 0.0633987\n",
      "\tspeed: 0.0417s/iter; left time: 655.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0627095 Vali Loss: 0.0634105 Test Loss: 0.1006842\n",
      "Validation loss decreased (0.063448 --> 0.063411).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0655387\n",
      "\tspeed: 0.0761s/iter; left time: 1185.4354s\n",
      "\titers: 200, epoch: 31 | loss: 0.0592907\n",
      "\tspeed: 0.0417s/iter; left time: 645.5897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0626497 Vali Loss: 0.0630981 Test Loss: 0.1011334\n",
      "Validation loss decreased (0.063411 --> 0.063098).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0612220\n",
      "\tspeed: 0.0773s/iter; left time: 1187.0219s\n",
      "\titers: 200, epoch: 32 | loss: 0.0605436\n",
      "\tspeed: 0.0417s/iter; left time: 635.5668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0626984 Vali Loss: 0.0638133 Test Loss: 0.1022748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0625021\n",
      "\tspeed: 0.0761s/iter; left time: 1151.8337s\n",
      "\titers: 200, epoch: 33 | loss: 0.0645759\n",
      "\tspeed: 0.0416s/iter; left time: 625.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0627295 Vali Loss: 0.0641849 Test Loss: 0.1019510\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0592388\n",
      "\tspeed: 0.0754s/iter; left time: 1124.8320s\n",
      "\titers: 200, epoch: 34 | loss: 0.0611952\n",
      "\tspeed: 0.0417s/iter; left time: 617.6710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0625513 Vali Loss: 0.0635446 Test Loss: 0.1014543\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0619458\n",
      "\tspeed: 0.0854s/iter; left time: 1253.4111s\n",
      "\titers: 200, epoch: 35 | loss: 0.0619243\n",
      "\tspeed: 0.0737s/iter; left time: 1074.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.14s\n",
      "Steps: 224 | Train Loss: 0.0623944 Vali Loss: 0.0633176 Test Loss: 0.1009187\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0644926\n",
      "\tspeed: 0.0904s/iter; left time: 1307.9778s\n",
      "\titers: 200, epoch: 36 | loss: 0.0587738\n",
      "\tspeed: 0.0417s/iter; left time: 598.3905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0623452 Vali Loss: 0.0631995 Test Loss: 0.1008759\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0635146\n",
      "\tspeed: 0.0758s/iter; left time: 1079.3263s\n",
      "\titers: 200, epoch: 37 | loss: 0.0632380\n",
      "\tspeed: 0.0416s/iter; left time: 588.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0624457 Vali Loss: 0.0635798 Test Loss: 0.1015082\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0625577\n",
      "\tspeed: 0.0750s/iter; left time: 1050.4604s\n",
      "\titers: 200, epoch: 38 | loss: 0.0650744\n",
      "\tspeed: 0.0416s/iter; left time: 578.9047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0624375 Vali Loss: 0.0639941 Test Loss: 0.1020741\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0653115\n",
      "\tspeed: 0.0751s/iter; left time: 1035.3735s\n",
      "\titers: 200, epoch: 39 | loss: 0.0665073\n",
      "\tspeed: 0.0416s/iter; left time: 569.8415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0622527 Vali Loss: 0.0632746 Test Loss: 0.1006721\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0627151\n",
      "\tspeed: 0.0756s/iter; left time: 1025.9839s\n",
      "\titers: 200, epoch: 40 | loss: 0.0645964\n",
      "\tspeed: 0.0416s/iter; left time: 560.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0621078 Vali Loss: 0.0628876 Test Loss: 0.1005665\n",
      "Validation loss decreased (0.063098 --> 0.062888).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0613665\n",
      "\tspeed: 0.0766s/iter; left time: 1022.0149s\n",
      "\titers: 200, epoch: 41 | loss: 0.0573908\n",
      "\tspeed: 0.0417s/iter; left time: 551.9259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0622834 Vali Loss: 0.0632954 Test Loss: 0.1009018\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0634290\n",
      "\tspeed: 0.0764s/iter; left time: 1001.8366s\n",
      "\titers: 200, epoch: 42 | loss: 0.0548260\n",
      "\tspeed: 0.0449s/iter; left time: 584.8318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 224 | Train Loss: 0.0620527 Vali Loss: 0.0632992 Test Loss: 0.1009582\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0617153\n",
      "\tspeed: 0.1851s/iter; left time: 2385.8729s\n",
      "\titers: 200, epoch: 43 | loss: 0.0625328\n",
      "\tspeed: 0.0418s/iter; left time: 534.4132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0620691 Vali Loss: 0.0632673 Test Loss: 0.1013953\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0610393\n",
      "\tspeed: 0.0752s/iter; left time: 952.9348s\n",
      "\titers: 200, epoch: 44 | loss: 0.0624791\n",
      "\tspeed: 0.0416s/iter; left time: 522.8355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0621833 Vali Loss: 0.0636538 Test Loss: 0.1015647\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0608374\n",
      "\tspeed: 0.0749s/iter; left time: 932.7178s\n",
      "\titers: 200, epoch: 45 | loss: 0.0614959\n",
      "\tspeed: 0.0418s/iter; left time: 515.6441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0620772 Vali Loss: 0.0634565 Test Loss: 0.1016685\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0637056\n",
      "\tspeed: 0.0762s/iter; left time: 930.8150s\n",
      "\titers: 200, epoch: 46 | loss: 0.0631933\n",
      "\tspeed: 0.0417s/iter; left time: 505.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0618619 Vali Loss: 0.0628713 Test Loss: 0.1008504\n",
      "Validation loss decreased (0.062888 --> 0.062871).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0628224\n",
      "\tspeed: 0.0755s/iter; left time: 905.1982s\n",
      "\titers: 200, epoch: 47 | loss: 0.0623958\n",
      "\tspeed: 0.0417s/iter; left time: 495.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0619418 Vali Loss: 0.0629015 Test Loss: 0.1010758\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0659553\n",
      "\tspeed: 0.0748s/iter; left time: 880.9730s\n",
      "\titers: 200, epoch: 48 | loss: 0.0597100\n",
      "\tspeed: 0.0416s/iter; left time: 485.4296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0618976 Vali Loss: 0.0629732 Test Loss: 0.1012003\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0644205\n",
      "\tspeed: 0.0753s/iter; left time: 869.2546s\n",
      "\titers: 200, epoch: 49 | loss: 0.0637023\n",
      "\tspeed: 0.0620s/iter; left time: 709.6771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:11.72s\n",
      "Steps: 224 | Train Loss: 0.0619386 Vali Loss: 0.0629265 Test Loss: 0.1010930\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0593881\n",
      "\tspeed: 0.2115s/iter; left time: 2394.7524s\n",
      "\titers: 200, epoch: 50 | loss: 0.0633009\n",
      "\tspeed: 0.0428s/iter; left time: 479.9596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:23.08s\n",
      "Steps: 224 | Train Loss: 0.0620564 Vali Loss: 0.0631971 Test Loss: 0.1012427\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0635366\n",
      "\tspeed: 0.0750s/iter; left time: 832.1735s\n",
      "\titers: 200, epoch: 51 | loss: 0.0612375\n",
      "\tspeed: 0.0417s/iter; left time: 458.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0618229 Vali Loss: 0.0629101 Test Loss: 0.1008691\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0619527\n",
      "\tspeed: 0.0750s/iter; left time: 815.3063s\n",
      "\titers: 200, epoch: 52 | loss: 0.0622246\n",
      "\tspeed: 0.0417s/iter; left time: 449.0900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0618092 Vali Loss: 0.0630093 Test Loss: 0.1011522\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0611701\n",
      "\tspeed: 0.0770s/iter; left time: 820.6236s\n",
      "\titers: 200, epoch: 53 | loss: 0.0612065\n",
      "\tspeed: 0.0417s/iter; left time: 439.9508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0620469 Vali Loss: 0.0628645 Test Loss: 0.1008271\n",
      "Validation loss decreased (0.062871 --> 0.062865).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0615999\n",
      "\tspeed: 0.0755s/iter; left time: 787.1044s\n",
      "\titers: 200, epoch: 54 | loss: 0.0630129\n",
      "\tspeed: 0.0417s/iter; left time: 430.3998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0619450 Vali Loss: 0.0628033 Test Loss: 0.1007278\n",
      "Validation loss decreased (0.062865 --> 0.062803).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0621613\n",
      "\tspeed: 0.0764s/iter; left time: 779.9759s\n",
      "\titers: 200, epoch: 55 | loss: 0.0630365\n",
      "\tspeed: 0.0417s/iter; left time: 421.4517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0619853 Vali Loss: 0.0630330 Test Loss: 0.1013185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0601366\n",
      "\tspeed: 0.0759s/iter; left time: 757.1667s\n",
      "\titers: 200, epoch: 56 | loss: 0.0617825\n",
      "\tspeed: 0.0796s/iter; left time: 786.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 224 | Train Loss: 0.0619285 Vali Loss: 0.0630218 Test Loss: 0.1012214\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0639688\n",
      "\tspeed: 0.1118s/iter; left time: 1090.6127s\n",
      "\titers: 200, epoch: 57 | loss: 0.0590051\n",
      "\tspeed: 0.0417s/iter; left time: 402.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0619671 Vali Loss: 0.0629334 Test Loss: 0.1011345\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0615265\n",
      "\tspeed: 0.0761s/iter; left time: 725.1945s\n",
      "\titers: 200, epoch: 58 | loss: 0.0592138\n",
      "\tspeed: 0.0416s/iter; left time: 392.3215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0618692 Vali Loss: 0.0629413 Test Loss: 0.1011890\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0593725\n",
      "\tspeed: 0.0750s/iter; left time: 698.4985s\n",
      "\titers: 200, epoch: 59 | loss: 0.0606491\n",
      "\tspeed: 0.0416s/iter; left time: 383.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0619292 Vali Loss: 0.0628457 Test Loss: 0.1008809\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0625145\n",
      "\tspeed: 0.0748s/iter; left time: 679.3154s\n",
      "\titers: 200, epoch: 60 | loss: 0.0610032\n",
      "\tspeed: 0.0416s/iter; left time: 373.7383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0619508 Vali Loss: 0.0628701 Test Loss: 0.1009763\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0613283\n",
      "\tspeed: 0.0747s/iter; left time: 661.7374s\n",
      "\titers: 200, epoch: 61 | loss: 0.0625177\n",
      "\tspeed: 0.0416s/iter; left time: 364.6442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0617994 Vali Loss: 0.0626751 Test Loss: 0.1007946\n",
      "Validation loss decreased (0.062803 --> 0.062675).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0626988\n",
      "\tspeed: 0.0763s/iter; left time: 658.5892s\n",
      "\titers: 200, epoch: 62 | loss: 0.0642374\n",
      "\tspeed: 0.0416s/iter; left time: 355.4961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0619335 Vali Loss: 0.0627436 Test Loss: 0.1008799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0639445\n",
      "\tspeed: 0.0781s/iter; left time: 657.2581s\n",
      "\titers: 200, epoch: 63 | loss: 0.0610277\n",
      "\tspeed: 0.0480s/iter; left time: 399.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 224 | Train Loss: 0.0618982 Vali Loss: 0.0627897 Test Loss: 0.1006443\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0622498\n",
      "\tspeed: 0.2015s/iter; left time: 1649.7592s\n",
      "\titers: 200, epoch: 64 | loss: 0.0611407\n",
      "\tspeed: 0.0421s/iter; left time: 340.3320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0617660 Vali Loss: 0.0628946 Test Loss: 0.1010937\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0648730\n",
      "\tspeed: 0.0760s/iter; left time: 605.4297s\n",
      "\titers: 200, epoch: 65 | loss: 0.0612919\n",
      "\tspeed: 0.0423s/iter; left time: 332.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0617090 Vali Loss: 0.0628330 Test Loss: 0.1009734\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0602756\n",
      "\tspeed: 0.0750s/iter; left time: 580.3947s\n",
      "\titers: 200, epoch: 66 | loss: 0.0579793\n",
      "\tspeed: 0.0416s/iter; left time: 317.6725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0619142 Vali Loss: 0.0628568 Test Loss: 0.1010279\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0570452\n",
      "\tspeed: 0.0753s/iter; left time: 565.8636s\n",
      "\titers: 200, epoch: 67 | loss: 0.0611297\n",
      "\tspeed: 0.0416s/iter; left time: 308.6849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0619276 Vali Loss: 0.0628833 Test Loss: 0.1011084\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0610014\n",
      "\tspeed: 0.0745s/iter; left time: 542.9996s\n",
      "\titers: 200, epoch: 68 | loss: 0.0606992\n",
      "\tspeed: 0.0417s/iter; left time: 300.0249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0618986 Vali Loss: 0.0630477 Test Loss: 0.1010355\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0616395\n",
      "\tspeed: 0.0755s/iter; left time: 533.3874s\n",
      "\titers: 200, epoch: 69 | loss: 0.0615485\n",
      "\tspeed: 0.0422s/iter; left time: 294.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0617822 Vali Loss: 0.0628332 Test Loss: 0.1008187\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0591795\n",
      "\tspeed: 0.1202s/iter; left time: 822.6796s\n",
      "\titers: 200, epoch: 70 | loss: 0.0618585\n",
      "\tspeed: 0.0427s/iter; left time: 288.2754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:14.02s\n",
      "Steps: 224 | Train Loss: 0.0619106 Vali Loss: 0.0628561 Test Loss: 0.1009100\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0650764\n",
      "\tspeed: 0.0757s/iter; left time: 501.2404s\n",
      "\titers: 200, epoch: 71 | loss: 0.0606281\n",
      "\tspeed: 0.0416s/iter; left time: 271.3764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0617328 Vali Loss: 0.0628059 Test Loss: 0.1008126\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03535137325525284, rmse:0.18801960349082947, mae:0.10079458355903625, rse:0.553318977355957\n",
      "Intermediate time for ES and pred_len 24: 00h:26m:13.40s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3087198\n",
      "\tspeed: 0.0614s/iter; left time: 1368.5308s\n",
      "\titers: 200, epoch: 1 | loss: 0.2841245\n",
      "\tspeed: 0.0421s/iter; left time: 934.4956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.3164368 Vali Loss: 0.2425799 Test Loss: 0.2544897\n",
      "Validation loss decreased (inf --> 0.242580).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1625078\n",
      "\tspeed: 0.0775s/iter; left time: 1711.4316s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235806\n",
      "\tspeed: 0.0421s/iter; left time: 924.9340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.1711263 Vali Loss: 0.1113969 Test Loss: 0.1446621\n",
      "Validation loss decreased (0.242580 --> 0.111397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1179232\n",
      "\tspeed: 0.0782s/iter; left time: 1708.8111s\n",
      "\titers: 200, epoch: 3 | loss: 0.1097096\n",
      "\tspeed: 0.0419s/iter; left time: 911.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.1160062 Vali Loss: 0.1052200 Test Loss: 0.1445315\n",
      "Validation loss decreased (0.111397 --> 0.105220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1037342\n",
      "\tspeed: 0.0770s/iter; left time: 1665.4593s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954844\n",
      "\tspeed: 0.0419s/iter; left time: 902.3732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.1023617 Vali Loss: 0.0980151 Test Loss: 0.1420692\n",
      "Validation loss decreased (0.105220 --> 0.098015).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0980011\n",
      "\tspeed: 0.0774s/iter; left time: 1655.7258s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963536\n",
      "\tspeed: 0.0422s/iter; left time: 898.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0957805 Vali Loss: 0.1012498 Test Loss: 0.1467813\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0895021\n",
      "\tspeed: 0.0758s/iter; left time: 1604.7527s\n",
      "\titers: 200, epoch: 6 | loss: 0.0939216\n",
      "\tspeed: 0.0421s/iter; left time: 888.0160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0926919 Vali Loss: 0.0934690 Test Loss: 0.1358151\n",
      "Validation loss decreased (0.098015 --> 0.093469).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0887770\n",
      "\tspeed: 0.0768s/iter; left time: 1609.1550s\n",
      "\titers: 200, epoch: 7 | loss: 0.0859136\n",
      "\tspeed: 0.0420s/iter; left time: 875.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0895946 Vali Loss: 0.0899492 Test Loss: 0.1322697\n",
      "Validation loss decreased (0.093469 --> 0.089949).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0881179\n",
      "\tspeed: 0.0777s/iter; left time: 1610.1754s\n",
      "\titers: 200, epoch: 8 | loss: 0.0889688\n",
      "\tspeed: 0.0423s/iter; left time: 872.0680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0890039 Vali Loss: 0.0889007 Test Loss: 0.1310800\n",
      "Validation loss decreased (0.089949 --> 0.088901).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0859029\n",
      "\tspeed: 0.0768s/iter; left time: 1575.9227s\n",
      "\titers: 200, epoch: 9 | loss: 0.0837611\n",
      "\tspeed: 0.0423s/iter; left time: 864.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0874600 Vali Loss: 0.0873071 Test Loss: 0.1304284\n",
      "Validation loss decreased (0.088901 --> 0.087307).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0841728\n",
      "\tspeed: 0.0777s/iter; left time: 1575.5670s\n",
      "\titers: 200, epoch: 10 | loss: 0.0854805\n",
      "\tspeed: 0.0422s/iter; left time: 850.8200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0873564 Vali Loss: 0.0863593 Test Loss: 0.1296678\n",
      "Validation loss decreased (0.087307 --> 0.086359).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0862924\n",
      "\tspeed: 0.0768s/iter; left time: 1540.8670s\n",
      "\titers: 200, epoch: 11 | loss: 0.0879009\n",
      "\tspeed: 0.0421s/iter; left time: 840.3491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0850815 Vali Loss: 0.0865189 Test Loss: 0.1287254\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0851573\n",
      "\tspeed: 0.0759s/iter; left time: 1505.3564s\n",
      "\titers: 200, epoch: 12 | loss: 0.0824953\n",
      "\tspeed: 0.0421s/iter; left time: 831.0078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0848088 Vali Loss: 0.0879292 Test Loss: 0.1291375\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0828711\n",
      "\tspeed: 0.0761s/iter; left time: 1492.8932s\n",
      "\titers: 200, epoch: 13 | loss: 0.0817625\n",
      "\tspeed: 0.0421s/iter; left time: 821.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0845817 Vali Loss: 0.0890451 Test Loss: 0.1311177\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0819097\n",
      "\tspeed: 0.0759s/iter; left time: 1470.7210s\n",
      "\titers: 200, epoch: 14 | loss: 0.0821618\n",
      "\tspeed: 0.0421s/iter; left time: 812.2886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0846507 Vali Loss: 0.0880299 Test Loss: 0.1307947\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0858055\n",
      "\tspeed: 0.0765s/iter; left time: 1465.4989s\n",
      "\titers: 200, epoch: 15 | loss: 0.0840013\n",
      "\tspeed: 0.0421s/iter; left time: 801.9049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0828693 Vali Loss: 0.0869172 Test Loss: 0.1300860\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0793703\n",
      "\tspeed: 0.0761s/iter; left time: 1441.4035s\n",
      "\titers: 200, epoch: 16 | loss: 0.0809559\n",
      "\tspeed: 0.0421s/iter; left time: 792.5769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0829215 Vali Loss: 0.0850276 Test Loss: 0.1273034\n",
      "Validation loss decreased (0.086359 --> 0.085028).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0808793\n",
      "\tspeed: 0.0773s/iter; left time: 1446.4199s\n",
      "\titers: 200, epoch: 17 | loss: 0.0817350\n",
      "\tspeed: 0.0421s/iter; left time: 783.9591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0824002 Vali Loss: 0.0864496 Test Loss: 0.1287947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0829623\n",
      "\tspeed: 0.0763s/iter; left time: 1411.3096s\n",
      "\titers: 200, epoch: 18 | loss: 0.0803460\n",
      "\tspeed: 0.0421s/iter; left time: 774.4548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0823772 Vali Loss: 0.0858532 Test Loss: 0.1292593\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0811778\n",
      "\tspeed: 0.0765s/iter; left time: 1397.9256s\n",
      "\titers: 200, epoch: 19 | loss: 0.0791778\n",
      "\tspeed: 0.0421s/iter; left time: 764.1561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0818599 Vali Loss: 0.0852665 Test Loss: 0.1280922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0874328\n",
      "\tspeed: 0.0757s/iter; left time: 1365.2106s\n",
      "\titers: 200, epoch: 20 | loss: 0.0816875\n",
      "\tspeed: 0.0421s/iter; left time: 755.1438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0817455 Vali Loss: 0.0844748 Test Loss: 0.1278079\n",
      "Validation loss decreased (0.085028 --> 0.084475).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0809045\n",
      "\tspeed: 0.0770s/iter; left time: 1371.3957s\n",
      "\titers: 200, epoch: 21 | loss: 0.0800690\n",
      "\tspeed: 0.0419s/iter; left time: 742.8468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0817827 Vali Loss: 0.0851829 Test Loss: 0.1272947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0801938\n",
      "\tspeed: 0.0763s/iter; left time: 1341.8377s\n",
      "\titers: 200, epoch: 22 | loss: 0.0797980\n",
      "\tspeed: 0.0421s/iter; left time: 736.1053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0815894 Vali Loss: 0.0847048 Test Loss: 0.1269838\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0778394\n",
      "\tspeed: 0.0765s/iter; left time: 1329.5167s\n",
      "\titers: 200, epoch: 23 | loss: 0.0767134\n",
      "\tspeed: 0.0421s/iter; left time: 727.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0817548 Vali Loss: 0.0850162 Test Loss: 0.1280266\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0805036\n",
      "\tspeed: 0.0766s/iter; left time: 1313.7218s\n",
      "\titers: 200, epoch: 24 | loss: 0.0821056\n",
      "\tspeed: 0.0421s/iter; left time: 717.8255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0809530 Vali Loss: 0.0848329 Test Loss: 0.1271944\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0846178\n",
      "\tspeed: 0.0758s/iter; left time: 1282.9266s\n",
      "\titers: 200, epoch: 25 | loss: 0.0792887\n",
      "\tspeed: 0.0420s/iter; left time: 707.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0807924 Vali Loss: 0.0845227 Test Loss: 0.1269221\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0848567\n",
      "\tspeed: 0.0756s/iter; left time: 1262.8559s\n",
      "\titers: 200, epoch: 26 | loss: 0.0794096\n",
      "\tspeed: 0.0421s/iter; left time: 698.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0809273 Vali Loss: 0.0840913 Test Loss: 0.1267855\n",
      "Validation loss decreased (0.084475 --> 0.084091).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0836163\n",
      "\tspeed: 0.0774s/iter; left time: 1275.3085s\n",
      "\titers: 200, epoch: 27 | loss: 0.0780838\n",
      "\tspeed: 0.0421s/iter; left time: 689.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0812665 Vali Loss: 0.0854141 Test Loss: 0.1274106\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0790672\n",
      "\tspeed: 0.0771s/iter; left time: 1253.6695s\n",
      "\titers: 200, epoch: 28 | loss: 0.0812228\n",
      "\tspeed: 0.0423s/iter; left time: 682.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 224 | Train Loss: 0.0807881 Vali Loss: 0.0842933 Test Loss: 0.1262354\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0798723\n",
      "\tspeed: 0.0771s/iter; left time: 1235.8278s\n",
      "\titers: 200, epoch: 29 | loss: 0.0792975\n",
      "\tspeed: 0.0419s/iter; left time: 667.6813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0807040 Vali Loss: 0.0845440 Test Loss: 0.1268535\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0828021\n",
      "\tspeed: 0.0769s/iter; left time: 1215.9875s\n",
      "\titers: 200, epoch: 30 | loss: 0.0804253\n",
      "\tspeed: 0.0421s/iter; left time: 661.0938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0805380 Vali Loss: 0.0843365 Test Loss: 0.1264631\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0821606\n",
      "\tspeed: 0.0761s/iter; left time: 1186.3620s\n",
      "\titers: 200, epoch: 31 | loss: 0.0804204\n",
      "\tspeed: 0.0421s/iter; left time: 652.3220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0804519 Vali Loss: 0.0847423 Test Loss: 0.1268339\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0848085\n",
      "\tspeed: 0.0766s/iter; left time: 1176.3034s\n",
      "\titers: 200, epoch: 32 | loss: 0.0788091\n",
      "\tspeed: 0.0419s/iter; left time: 639.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0803715 Vali Loss: 0.0841484 Test Loss: 0.1263743\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0774874\n",
      "\tspeed: 0.0757s/iter; left time: 1146.3147s\n",
      "\titers: 200, epoch: 33 | loss: 0.0770135\n",
      "\tspeed: 0.0422s/iter; left time: 633.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0802958 Vali Loss: 0.0844072 Test Loss: 0.1265383\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0782122\n",
      "\tspeed: 0.0759s/iter; left time: 1132.1942s\n",
      "\titers: 200, epoch: 34 | loss: 0.0789347\n",
      "\tspeed: 0.0421s/iter; left time: 624.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0801236 Vali Loss: 0.0840895 Test Loss: 0.1261504\n",
      "Validation loss decreased (0.084091 --> 0.084089).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0824917\n",
      "\tspeed: 0.0778s/iter; left time: 1142.3244s\n",
      "\titers: 200, epoch: 35 | loss: 0.0795255\n",
      "\tspeed: 0.0421s/iter; left time: 613.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0801616 Vali Loss: 0.0839974 Test Loss: 0.1260976\n",
      "Validation loss decreased (0.084089 --> 0.083997).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0767485\n",
      "\tspeed: 0.0787s/iter; left time: 1137.4309s\n",
      "\titers: 200, epoch: 36 | loss: 0.0818702\n",
      "\tspeed: 0.0422s/iter; left time: 605.4487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0800176 Vali Loss: 0.0851612 Test Loss: 0.1273272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0786922\n",
      "\tspeed: 0.0762s/iter; left time: 1084.5657s\n",
      "\titers: 200, epoch: 37 | loss: 0.0785943\n",
      "\tspeed: 0.0421s/iter; left time: 595.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0801165 Vali Loss: 0.0846944 Test Loss: 0.1270023\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0805799\n",
      "\tspeed: 0.0765s/iter; left time: 1071.2978s\n",
      "\titers: 200, epoch: 38 | loss: 0.0770007\n",
      "\tspeed: 0.0422s/iter; left time: 587.4057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0800650 Vali Loss: 0.0844370 Test Loss: 0.1266247\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0858888\n",
      "\tspeed: 0.0765s/iter; left time: 1055.1162s\n",
      "\titers: 200, epoch: 39 | loss: 0.0776416\n",
      "\tspeed: 0.0421s/iter; left time: 576.3131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0800842 Vali Loss: 0.0841426 Test Loss: 0.1263395\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0777371\n",
      "\tspeed: 0.0770s/iter; left time: 1045.0016s\n",
      "\titers: 200, epoch: 40 | loss: 0.0765271\n",
      "\tspeed: 0.0424s/iter; left time: 570.4762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0800065 Vali Loss: 0.0840029 Test Loss: 0.1260867\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0858129\n",
      "\tspeed: 0.0775s/iter; left time: 1034.0713s\n",
      "\titers: 200, epoch: 41 | loss: 0.0803346\n",
      "\tspeed: 0.0422s/iter; left time: 558.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0799613 Vali Loss: 0.0847550 Test Loss: 0.1269996\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0791873\n",
      "\tspeed: 0.0756s/iter; left time: 992.0701s\n",
      "\titers: 200, epoch: 42 | loss: 0.0863588\n",
      "\tspeed: 0.0421s/iter; left time: 548.0121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0799551 Vali Loss: 0.0843744 Test Loss: 0.1265150\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0817365\n",
      "\tspeed: 0.0758s/iter; left time: 976.9495s\n",
      "\titers: 200, epoch: 43 | loss: 0.0819361\n",
      "\tspeed: 0.0421s/iter; left time: 538.1063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0799319 Vali Loss: 0.0840537 Test Loss: 0.1262547\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0773737\n",
      "\tspeed: 0.0760s/iter; left time: 963.0111s\n",
      "\titers: 200, epoch: 44 | loss: 0.0767789\n",
      "\tspeed: 0.0421s/iter; left time: 529.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0798650 Vali Loss: 0.0845061 Test Loss: 0.1269356\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0860606\n",
      "\tspeed: 0.0759s/iter; left time: 944.2509s\n",
      "\titers: 200, epoch: 45 | loss: 0.0768966\n",
      "\tspeed: 0.0421s/iter; left time: 519.8802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0799102 Vali Loss: 0.0838536 Test Loss: 0.1257681\n",
      "Validation loss decreased (0.083997 --> 0.083854).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0779544\n",
      "\tspeed: 0.0770s/iter; left time: 940.5241s\n",
      "\titers: 200, epoch: 46 | loss: 0.0796066\n",
      "\tspeed: 0.0423s/iter; left time: 512.2185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0796805 Vali Loss: 0.0840271 Test Loss: 0.1261687\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0815915\n",
      "\tspeed: 0.0760s/iter; left time: 912.1001s\n",
      "\titers: 200, epoch: 47 | loss: 0.0807313\n",
      "\tspeed: 0.0422s/iter; left time: 501.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0798926 Vali Loss: 0.0839672 Test Loss: 0.1259792\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0794357\n",
      "\tspeed: 0.0754s/iter; left time: 888.2686s\n",
      "\titers: 200, epoch: 48 | loss: 0.0773939\n",
      "\tspeed: 0.0422s/iter; left time: 492.1681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0798242 Vali Loss: 0.0844074 Test Loss: 0.1263041\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0819494\n",
      "\tspeed: 0.0767s/iter; left time: 886.1695s\n",
      "\titers: 200, epoch: 49 | loss: 0.0802049\n",
      "\tspeed: 0.0421s/iter; left time: 482.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0798116 Vali Loss: 0.0844085 Test Loss: 0.1264632\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0837329\n",
      "\tspeed: 0.0753s/iter; left time: 852.2082s\n",
      "\titers: 200, epoch: 50 | loss: 0.0769495\n",
      "\tspeed: 0.0421s/iter; left time: 472.4702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0797098 Vali Loss: 0.0841260 Test Loss: 0.1261045\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0799097\n",
      "\tspeed: 0.0765s/iter; left time: 849.6486s\n",
      "\titers: 200, epoch: 51 | loss: 0.0775151\n",
      "\tspeed: 0.0422s/iter; left time: 464.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0796103 Vali Loss: 0.0842327 Test Loss: 0.1263418\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0778547\n",
      "\tspeed: 0.0764s/iter; left time: 831.1271s\n",
      "\titers: 200, epoch: 52 | loss: 0.0804180\n",
      "\tspeed: 0.0423s/iter; left time: 455.7021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0797461 Vali Loss: 0.0838414 Test Loss: 0.1261225\n",
      "Validation loss decreased (0.083854 --> 0.083841).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0754200\n",
      "\tspeed: 0.0770s/iter; left time: 819.8107s\n",
      "\titers: 200, epoch: 53 | loss: 0.0808285\n",
      "\tspeed: 0.0421s/iter; left time: 444.5978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0798154 Vali Loss: 0.0840659 Test Loss: 0.1261967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0785020\n",
      "\tspeed: 0.0761s/iter; left time: 793.9312s\n",
      "\titers: 200, epoch: 54 | loss: 0.0752731\n",
      "\tspeed: 0.0422s/iter; left time: 435.9183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0796046 Vali Loss: 0.0838090 Test Loss: 0.1260109\n",
      "Validation loss decreased (0.083841 --> 0.083809).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0825825\n",
      "\tspeed: 0.0777s/iter; left time: 793.3868s\n",
      "\titers: 200, epoch: 55 | loss: 0.0817265\n",
      "\tspeed: 0.0421s/iter; left time: 425.2760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0800314 Vali Loss: 0.0842552 Test Loss: 0.1263213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0752808\n",
      "\tspeed: 0.0773s/iter; left time: 771.7904s\n",
      "\titers: 200, epoch: 56 | loss: 0.0764887\n",
      "\tspeed: 0.0421s/iter; left time: 415.9694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0796388 Vali Loss: 0.0841034 Test Loss: 0.1263881\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0788198\n",
      "\tspeed: 0.0769s/iter; left time: 750.6642s\n",
      "\titers: 200, epoch: 57 | loss: 0.0789635\n",
      "\tspeed: 0.0423s/iter; left time: 408.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 224 | Train Loss: 0.0797300 Vali Loss: 0.0844516 Test Loss: 0.1264094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0764003\n",
      "\tspeed: 0.0761s/iter; left time: 725.1136s\n",
      "\titers: 200, epoch: 58 | loss: 0.0826123\n",
      "\tspeed: 0.0421s/iter; left time: 397.3062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0796161 Vali Loss: 0.0843361 Test Loss: 0.1262343\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0806784\n",
      "\tspeed: 0.0771s/iter; left time: 717.9092s\n",
      "\titers: 200, epoch: 59 | loss: 0.0810902\n",
      "\tspeed: 0.0424s/iter; left time: 390.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 224 | Train Loss: 0.0799136 Vali Loss: 0.0840306 Test Loss: 0.1261222\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0787030\n",
      "\tspeed: 0.0768s/iter; left time: 697.9680s\n",
      "\titers: 200, epoch: 60 | loss: 0.0834874\n",
      "\tspeed: 0.0421s/iter; left time: 378.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0797784 Vali Loss: 0.0839924 Test Loss: 0.1261431\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0793075\n",
      "\tspeed: 0.0765s/iter; left time: 678.1834s\n",
      "\titers: 200, epoch: 61 | loss: 0.0804190\n",
      "\tspeed: 0.0421s/iter; left time: 368.9325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0797349 Vali Loss: 0.0841568 Test Loss: 0.1262410\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0793499\n",
      "\tspeed: 0.0767s/iter; left time: 662.1804s\n",
      "\titers: 200, epoch: 62 | loss: 0.0765225\n",
      "\tspeed: 0.0422s/iter; left time: 360.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0797543 Vali Loss: 0.0845716 Test Loss: 0.1264919\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0800374\n",
      "\tspeed: 0.0761s/iter; left time: 640.1876s\n",
      "\titers: 200, epoch: 63 | loss: 0.0816643\n",
      "\tspeed: 0.0422s/iter; left time: 350.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0796806 Vali Loss: 0.0841349 Test Loss: 0.1262351\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0754169\n",
      "\tspeed: 0.0755s/iter; left time: 618.0901s\n",
      "\titers: 200, epoch: 64 | loss: 0.0819454\n",
      "\tspeed: 0.0423s/iter; left time: 342.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0796245 Vali Loss: 0.0837776 Test Loss: 0.1259758\n",
      "Validation loss decreased (0.083809 --> 0.083778).  Saving model ...\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0779732\n",
      "\tspeed: 0.0776s/iter; left time: 618.0772s\n",
      "\titers: 200, epoch: 65 | loss: 0.0826116\n",
      "\tspeed: 0.0420s/iter; left time: 330.2282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0797378 Vali Loss: 0.0841580 Test Loss: 0.1260502\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0772293\n",
      "\tspeed: 0.0759s/iter; left time: 587.6660s\n",
      "\titers: 200, epoch: 66 | loss: 0.0806191\n",
      "\tspeed: 0.0421s/iter; left time: 321.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0795788 Vali Loss: 0.0838310 Test Loss: 0.1261772\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0835375\n",
      "\tspeed: 0.0755s/iter; left time: 567.5217s\n",
      "\titers: 200, epoch: 67 | loss: 0.0784040\n",
      "\tspeed: 0.0419s/iter; left time: 310.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0795988 Vali Loss: 0.0836332 Test Loss: 0.1258920\n",
      "Validation loss decreased (0.083778 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0772682\n",
      "\tspeed: 0.0776s/iter; left time: 566.0134s\n",
      "\titers: 200, epoch: 68 | loss: 0.0778781\n",
      "\tspeed: 0.0421s/iter; left time: 303.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0796445 Vali Loss: 0.0837293 Test Loss: 0.1258417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0776555\n",
      "\tspeed: 0.0769s/iter; left time: 543.2529s\n",
      "\titers: 200, epoch: 69 | loss: 0.0783635\n",
      "\tspeed: 0.0421s/iter; left time: 293.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0795583 Vali Loss: 0.0841830 Test Loss: 0.1262607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0768350\n",
      "\tspeed: 0.0767s/iter; left time: 524.9667s\n",
      "\titers: 200, epoch: 70 | loss: 0.0798154\n",
      "\tspeed: 0.0423s/iter; left time: 285.1127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0798403 Vali Loss: 0.0842745 Test Loss: 0.1261821\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0794284\n",
      "\tspeed: 0.0765s/iter; left time: 506.6365s\n",
      "\titers: 200, epoch: 71 | loss: 0.0775854\n",
      "\tspeed: 0.0421s/iter; left time: 274.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0796033 Vali Loss: 0.0849895 Test Loss: 0.1264999\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0786594\n",
      "\tspeed: 0.0757s/iter; left time: 484.1595s\n",
      "\titers: 200, epoch: 72 | loss: 0.0800284\n",
      "\tspeed: 0.0422s/iter; left time: 265.7168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0796449 Vali Loss: 0.0840122 Test Loss: 0.1261873\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0791136\n",
      "\tspeed: 0.0753s/iter; left time: 465.0138s\n",
      "\titers: 200, epoch: 73 | loss: 0.0782163\n",
      "\tspeed: 0.0421s/iter; left time: 255.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0795402 Vali Loss: 0.0841222 Test Loss: 0.1262444\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0774276\n",
      "\tspeed: 0.0768s/iter; left time: 456.7263s\n",
      "\titers: 200, epoch: 74 | loss: 0.0775962\n",
      "\tspeed: 0.0420s/iter; left time: 245.6931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0797737 Vali Loss: 0.0839510 Test Loss: 0.1260631\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0803613\n",
      "\tspeed: 0.0759s/iter; left time: 434.7102s\n",
      "\titers: 200, epoch: 75 | loss: 0.0785409\n",
      "\tspeed: 0.0420s/iter; left time: 236.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0797646 Vali Loss: 0.0840968 Test Loss: 0.1261225\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0813321\n",
      "\tspeed: 0.0763s/iter; left time: 419.5077s\n",
      "\titers: 200, epoch: 76 | loss: 0.0805857\n",
      "\tspeed: 0.0421s/iter; left time: 227.3696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0796123 Vali Loss: 0.0841005 Test Loss: 0.1263806\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0830069\n",
      "\tspeed: 0.0758s/iter; left time: 399.9250s\n",
      "\titers: 200, epoch: 77 | loss: 0.0810858\n",
      "\tspeed: 0.0421s/iter; left time: 217.9819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0797536 Vali Loss: 0.0843223 Test Loss: 0.1263319\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042682427912950516, rmse:0.2065972536802292, mae:0.1258920431137085, rse:0.606920599937439\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3130980\n",
      "\tspeed: 0.0441s/iter; left time: 982.9223s\n",
      "\titers: 200, epoch: 1 | loss: 0.2915918\n",
      "\tspeed: 0.0422s/iter; left time: 937.7684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.3196867 Vali Loss: 0.2395402 Test Loss: 0.2518374\n",
      "Validation loss decreased (inf --> 0.239540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1531602\n",
      "\tspeed: 0.0765s/iter; left time: 1688.0484s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265273\n",
      "\tspeed: 0.0422s/iter; left time: 926.4055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.1688354 Vali Loss: 0.1148870 Test Loss: 0.1587172\n",
      "Validation loss decreased (0.239540 --> 0.114887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1152440\n",
      "\tspeed: 0.0767s/iter; left time: 1675.1213s\n",
      "\titers: 200, epoch: 3 | loss: 0.1068793\n",
      "\tspeed: 0.0420s/iter; left time: 914.5649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1131850 Vali Loss: 0.1069025 Test Loss: 0.1547198\n",
      "Validation loss decreased (0.114887 --> 0.106903).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0962493\n",
      "\tspeed: 0.0774s/iter; left time: 1674.5479s\n",
      "\titers: 200, epoch: 4 | loss: 0.0985312\n",
      "\tspeed: 0.0421s/iter; left time: 907.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.1007845 Vali Loss: 0.1004068 Test Loss: 0.1535980\n",
      "Validation loss decreased (0.106903 --> 0.100407).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0910604\n",
      "\tspeed: 0.0773s/iter; left time: 1654.9078s\n",
      "\titers: 200, epoch: 5 | loss: 0.0952017\n",
      "\tspeed: 0.0423s/iter; left time: 900.2529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 224 | Train Loss: 0.0954305 Vali Loss: 0.0990412 Test Loss: 0.1484472\n",
      "Validation loss decreased (0.100407 --> 0.099041).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0956823\n",
      "\tspeed: 0.0764s/iter; left time: 1619.1958s\n",
      "\titers: 200, epoch: 6 | loss: 0.0905359\n",
      "\tspeed: 0.0421s/iter; left time: 887.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0930845 Vali Loss: 0.0969028 Test Loss: 0.1511683\n",
      "Validation loss decreased (0.099041 --> 0.096903).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0851769\n",
      "\tspeed: 0.0779s/iter; left time: 1632.9418s\n",
      "\titers: 200, epoch: 7 | loss: 0.0869169\n",
      "\tspeed: 0.0424s/iter; left time: 883.6174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0903284 Vali Loss: 0.0900123 Test Loss: 0.1451179\n",
      "Validation loss decreased (0.096903 --> 0.090012).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0914346\n",
      "\tspeed: 0.0774s/iter; left time: 1604.2724s\n",
      "\titers: 200, epoch: 8 | loss: 0.0882436\n",
      "\tspeed: 0.0424s/iter; left time: 874.4908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0885029 Vali Loss: 0.0895465 Test Loss: 0.1426073\n",
      "Validation loss decreased (0.090012 --> 0.089547).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0869583\n",
      "\tspeed: 0.0774s/iter; left time: 1586.4032s\n",
      "\titers: 200, epoch: 9 | loss: 0.0810998\n",
      "\tspeed: 0.0421s/iter; left time: 859.3513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0875724 Vali Loss: 0.0895228 Test Loss: 0.1416580\n",
      "Validation loss decreased (0.089547 --> 0.089523).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0865016\n",
      "\tspeed: 0.0773s/iter; left time: 1568.8199s\n",
      "\titers: 200, epoch: 10 | loss: 0.0828000\n",
      "\tspeed: 0.0421s/iter; left time: 850.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0860751 Vali Loss: 0.0887545 Test Loss: 0.1420505\n",
      "Validation loss decreased (0.089523 --> 0.088754).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0871508\n",
      "\tspeed: 0.0777s/iter; left time: 1557.7631s\n",
      "\titers: 200, epoch: 11 | loss: 0.0838031\n",
      "\tspeed: 0.0422s/iter; left time: 841.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0857281 Vali Loss: 0.0876555 Test Loss: 0.1382597\n",
      "Validation loss decreased (0.088754 --> 0.087655).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0814604\n",
      "\tspeed: 0.0770s/iter; left time: 1526.6555s\n",
      "\titers: 200, epoch: 12 | loss: 0.0815106\n",
      "\tspeed: 0.0422s/iter; left time: 832.1597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0850020 Vali Loss: 0.0873017 Test Loss: 0.1373932\n",
      "Validation loss decreased (0.087655 --> 0.087302).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0799510\n",
      "\tspeed: 0.0766s/iter; left time: 1502.1244s\n",
      "\titers: 200, epoch: 13 | loss: 0.0852346\n",
      "\tspeed: 0.0421s/iter; left time: 821.1987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0846373 Vali Loss: 0.0870578 Test Loss: 0.1364176\n",
      "Validation loss decreased (0.087302 --> 0.087058).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0842823\n",
      "\tspeed: 0.0769s/iter; left time: 1490.1964s\n",
      "\titers: 200, epoch: 14 | loss: 0.0829000\n",
      "\tspeed: 0.0421s/iter; left time: 811.4863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0841642 Vali Loss: 0.0878197 Test Loss: 0.1370017\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0856471\n",
      "\tspeed: 0.0757s/iter; left time: 1451.3418s\n",
      "\titers: 200, epoch: 15 | loss: 0.0872531\n",
      "\tspeed: 0.0421s/iter; left time: 802.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0847864 Vali Loss: 0.0863888 Test Loss: 0.1350420\n",
      "Validation loss decreased (0.087058 --> 0.086389).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0827353\n",
      "\tspeed: 0.0775s/iter; left time: 1467.4734s\n",
      "\titers: 200, epoch: 16 | loss: 0.0851015\n",
      "\tspeed: 0.0421s/iter; left time: 794.1237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0832300 Vali Loss: 0.0854593 Test Loss: 0.1337171\n",
      "Validation loss decreased (0.086389 --> 0.085459).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0813225\n",
      "\tspeed: 0.0773s/iter; left time: 1446.7585s\n",
      "\titers: 200, epoch: 17 | loss: 0.0882458\n",
      "\tspeed: 0.0421s/iter; left time: 784.5648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 224 | Train Loss: 0.0829464 Vali Loss: 0.0880908 Test Loss: 0.1366234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0806421\n",
      "\tspeed: 0.0760s/iter; left time: 1405.5946s\n",
      "\titers: 200, epoch: 18 | loss: 0.0821322\n",
      "\tspeed: 0.0423s/iter; left time: 778.4742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0827360 Vali Loss: 0.0862494 Test Loss: 0.1334437\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0768325\n",
      "\tspeed: 0.0767s/iter; left time: 1401.7808s\n",
      "\titers: 200, epoch: 19 | loss: 0.0841644\n",
      "\tspeed: 0.0422s/iter; left time: 766.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0828404 Vali Loss: 0.0862542 Test Loss: 0.1329487\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0864196\n",
      "\tspeed: 0.0764s/iter; left time: 1378.5805s\n",
      "\titers: 200, epoch: 20 | loss: 0.0817531\n",
      "\tspeed: 0.0421s/iter; left time: 755.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0824830 Vali Loss: 0.0848606 Test Loss: 0.1328086\n",
      "Validation loss decreased (0.085459 --> 0.084861).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0804224\n",
      "\tspeed: 0.0774s/iter; left time: 1380.1172s\n",
      "\titers: 200, epoch: 21 | loss: 0.0838056\n",
      "\tspeed: 0.0422s/iter; left time: 747.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0817197 Vali Loss: 0.0853078 Test Loss: 0.1334176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0856846\n",
      "\tspeed: 0.0758s/iter; left time: 1333.9582s\n",
      "\titers: 200, epoch: 22 | loss: 0.0836715\n",
      "\tspeed: 0.0423s/iter; left time: 739.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0819957 Vali Loss: 0.0849479 Test Loss: 0.1327053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0817166\n",
      "\tspeed: 0.0761s/iter; left time: 1322.1528s\n",
      "\titers: 200, epoch: 23 | loss: 0.0847958\n",
      "\tspeed: 0.0421s/iter; left time: 727.7395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0816453 Vali Loss: 0.0845920 Test Loss: 0.1333073\n",
      "Validation loss decreased (0.084861 --> 0.084592).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0802909\n",
      "\tspeed: 0.0779s/iter; left time: 1336.3229s\n",
      "\titers: 200, epoch: 24 | loss: 0.0789565\n",
      "\tspeed: 0.0422s/iter; left time: 719.2262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0816638 Vali Loss: 0.0844885 Test Loss: 0.1322215\n",
      "Validation loss decreased (0.084592 --> 0.084488).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0800138\n",
      "\tspeed: 0.0769s/iter; left time: 1300.9746s\n",
      "\titers: 200, epoch: 25 | loss: 0.0808960\n",
      "\tspeed: 0.0421s/iter; left time: 707.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0813565 Vali Loss: 0.0855885 Test Loss: 0.1335429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0775807\n",
      "\tspeed: 0.0762s/iter; left time: 1272.8756s\n",
      "\titers: 200, epoch: 26 | loss: 0.0801371\n",
      "\tspeed: 0.0421s/iter; left time: 698.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0812894 Vali Loss: 0.0852949 Test Loss: 0.1329506\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0820362\n",
      "\tspeed: 0.0758s/iter; left time: 1248.2547s\n",
      "\titers: 200, epoch: 27 | loss: 0.0838453\n",
      "\tspeed: 0.0421s/iter; left time: 689.7449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0810125 Vali Loss: 0.0848204 Test Loss: 0.1334669\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0778222\n",
      "\tspeed: 0.0762s/iter; left time: 1238.8931s\n",
      "\titers: 200, epoch: 28 | loss: 0.0814470\n",
      "\tspeed: 0.0423s/iter; left time: 682.7607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0809611 Vali Loss: 0.0843190 Test Loss: 0.1323339\n",
      "Validation loss decreased (0.084488 --> 0.084319).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0809756\n",
      "\tspeed: 0.0782s/iter; left time: 1253.8126s\n",
      "\titers: 200, epoch: 29 | loss: 0.0849491\n",
      "\tspeed: 0.0423s/iter; left time: 674.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 224 | Train Loss: 0.0808642 Vali Loss: 0.0847727 Test Loss: 0.1327025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0825583\n",
      "\tspeed: 0.0763s/iter; left time: 1206.5114s\n",
      "\titers: 200, epoch: 30 | loss: 0.0942832\n",
      "\tspeed: 0.0421s/iter; left time: 661.0061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0811853 Vali Loss: 0.0848764 Test Loss: 0.1325917\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0822298\n",
      "\tspeed: 0.0762s/iter; left time: 1186.4996s\n",
      "\titers: 200, epoch: 31 | loss: 0.0778463\n",
      "\tspeed: 0.0421s/iter; left time: 652.0440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0808567 Vali Loss: 0.0842703 Test Loss: 0.1319457\n",
      "Validation loss decreased (0.084319 --> 0.084270).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0879390\n",
      "\tspeed: 0.0768s/iter; left time: 1178.9212s\n",
      "\titers: 200, epoch: 32 | loss: 0.0832444\n",
      "\tspeed: 0.0419s/iter; left time: 639.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0807399 Vali Loss: 0.0852468 Test Loss: 0.1327529\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0823667\n",
      "\tspeed: 0.0763s/iter; left time: 1154.8744s\n",
      "\titers: 200, epoch: 33 | loss: 0.0833741\n",
      "\tspeed: 0.0421s/iter; left time: 633.5127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0805911 Vali Loss: 0.0846417 Test Loss: 0.1327233\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0813722\n",
      "\tspeed: 0.0769s/iter; left time: 1147.1574s\n",
      "\titers: 200, epoch: 34 | loss: 0.0838023\n",
      "\tspeed: 0.0421s/iter; left time: 623.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0806440 Vali Loss: 0.0842408 Test Loss: 0.1320810\n",
      "Validation loss decreased (0.084270 --> 0.084241).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0761102\n",
      "\tspeed: 0.0767s/iter; left time: 1126.9542s\n",
      "\titers: 200, epoch: 35 | loss: 0.0802371\n",
      "\tspeed: 0.0421s/iter; left time: 613.8959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0809558 Vali Loss: 0.0843488 Test Loss: 0.1316327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0790779\n",
      "\tspeed: 0.0759s/iter; left time: 1097.0784s\n",
      "\titers: 200, epoch: 36 | loss: 0.0827025\n",
      "\tspeed: 0.0421s/iter; left time: 604.3448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0805936 Vali Loss: 0.0843448 Test Loss: 0.1320925\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0783880\n",
      "\tspeed: 0.0755s/iter; left time: 1074.8082s\n",
      "\titers: 200, epoch: 37 | loss: 0.0804148\n",
      "\tspeed: 0.0421s/iter; left time: 595.2123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0803717 Vali Loss: 0.0840268 Test Loss: 0.1315762\n",
      "Validation loss decreased (0.084241 --> 0.084027).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0784172\n",
      "\tspeed: 0.0770s/iter; left time: 1078.6552s\n",
      "\titers: 200, epoch: 38 | loss: 0.0820902\n",
      "\tspeed: 0.0421s/iter; left time: 586.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0807300 Vali Loss: 0.0848791 Test Loss: 0.1322204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0803019\n",
      "\tspeed: 0.0758s/iter; left time: 1045.4343s\n",
      "\titers: 200, epoch: 39 | loss: 0.0800881\n",
      "\tspeed: 0.0423s/iter; left time: 579.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0803412 Vali Loss: 0.0836483 Test Loss: 0.1307262\n",
      "Validation loss decreased (0.084027 --> 0.083648).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0780669\n",
      "\tspeed: 0.0776s/iter; left time: 1052.1677s\n",
      "\titers: 200, epoch: 40 | loss: 0.0830132\n",
      "\tspeed: 0.0421s/iter; left time: 567.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0803537 Vali Loss: 0.0839512 Test Loss: 0.1318338\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0804674\n",
      "\tspeed: 0.0759s/iter; left time: 1012.8156s\n",
      "\titers: 200, epoch: 41 | loss: 0.0770516\n",
      "\tspeed: 0.0421s/iter; left time: 557.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0802819 Vali Loss: 0.0843457 Test Loss: 0.1320690\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0760739\n",
      "\tspeed: 0.0766s/iter; left time: 1004.5418s\n",
      "\titers: 200, epoch: 42 | loss: 0.0809930\n",
      "\tspeed: 0.0423s/iter; left time: 550.8853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0802771 Vali Loss: 0.0837378 Test Loss: 0.1311669\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0787418\n",
      "\tspeed: 0.0763s/iter; left time: 983.2286s\n",
      "\titers: 200, epoch: 43 | loss: 0.0817545\n",
      "\tspeed: 0.0421s/iter; left time: 539.0267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0802796 Vali Loss: 0.0843429 Test Loss: 0.1320245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0794135\n",
      "\tspeed: 0.0774s/iter; left time: 981.0295s\n",
      "\titers: 200, epoch: 44 | loss: 0.0808015\n",
      "\tspeed: 0.0423s/iter; left time: 531.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0804098 Vali Loss: 0.0845812 Test Loss: 0.1322879\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0793280\n",
      "\tspeed: 0.0766s/iter; left time: 953.1838s\n",
      "\titers: 200, epoch: 45 | loss: 0.0824687\n",
      "\tspeed: 0.0421s/iter; left time: 519.4734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0802785 Vali Loss: 0.0838787 Test Loss: 0.1311870\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0790013\n",
      "\tspeed: 0.0761s/iter; left time: 929.7289s\n",
      "\titers: 200, epoch: 46 | loss: 0.0804564\n",
      "\tspeed: 0.0424s/iter; left time: 513.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 224 | Train Loss: 0.0804381 Vali Loss: 0.0837640 Test Loss: 0.1313289\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0791075\n",
      "\tspeed: 0.0774s/iter; left time: 929.0803s\n",
      "\titers: 200, epoch: 47 | loss: 0.0794566\n",
      "\tspeed: 0.0423s/iter; left time: 503.6919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 224 | Train Loss: 0.0803667 Vali Loss: 0.0844842 Test Loss: 0.1321007\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0787983\n",
      "\tspeed: 0.0763s/iter; left time: 898.3175s\n",
      "\titers: 200, epoch: 48 | loss: 0.0810100\n",
      "\tspeed: 0.0421s/iter; left time: 491.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0801021 Vali Loss: 0.0843818 Test Loss: 0.1323378\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0797586\n",
      "\tspeed: 0.0764s/iter; left time: 882.1635s\n",
      "\titers: 200, epoch: 49 | loss: 0.0831404\n",
      "\tspeed: 0.0423s/iter; left time: 484.5075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0803223 Vali Loss: 0.0843202 Test Loss: 0.1316219\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.049442559480667114, rmse:0.22235682606697083, mae:0.13072609901428223, rse:0.6532174944877625\n",
      "Intermediate time for ES and pred_len 96: 00h:25m:06.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3142997\n",
      "\tspeed: 0.0641s/iter; left time: 1422.5444s\n",
      "\titers: 200, epoch: 1 | loss: 0.2885112\n",
      "\tspeed: 0.0425s/iter; left time: 939.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 223 | Train Loss: 0.3200624 Vali Loss: 0.2418508 Test Loss: 0.2516354\n",
      "Validation loss decreased (inf --> 0.241851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1532281\n",
      "\tspeed: 0.0769s/iter; left time: 1689.1563s\n",
      "\titers: 200, epoch: 2 | loss: 0.1282265\n",
      "\tspeed: 0.0424s/iter; left time: 926.7463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.1667858 Vali Loss: 0.1184693 Test Loss: 0.1563282\n",
      "Validation loss decreased (0.241851 --> 0.118469).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147629\n",
      "\tspeed: 0.0774s/iter; left time: 1682.8075s\n",
      "\titers: 200, epoch: 3 | loss: 0.1102348\n",
      "\tspeed: 0.0425s/iter; left time: 921.1758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.1133253 Vali Loss: 0.1069713 Test Loss: 0.1496237\n",
      "Validation loss decreased (0.118469 --> 0.106971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1064510\n",
      "\tspeed: 0.0779s/iter; left time: 1676.3672s\n",
      "\titers: 200, epoch: 4 | loss: 0.1006971\n",
      "\tspeed: 0.0429s/iter; left time: 919.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 223 | Train Loss: 0.1040483 Vali Loss: 0.1062297 Test Loss: 0.1483485\n",
      "Validation loss decreased (0.106971 --> 0.106230).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0973843\n",
      "\tspeed: 0.0774s/iter; left time: 1649.9838s\n",
      "\titers: 200, epoch: 5 | loss: 0.0964848\n",
      "\tspeed: 0.0426s/iter; left time: 904.3327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0986818 Vali Loss: 0.0979595 Test Loss: 0.1400647\n",
      "Validation loss decreased (0.106230 --> 0.097960).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0981557\n",
      "\tspeed: 0.0771s/iter; left time: 1624.7163s\n",
      "\titers: 200, epoch: 6 | loss: 0.1084668\n",
      "\tspeed: 0.0426s/iter; left time: 893.9329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0977323 Vali Loss: 0.1025606 Test Loss: 0.1445120\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0966817\n",
      "\tspeed: 0.0763s/iter; left time: 1591.9032s\n",
      "\titers: 200, epoch: 7 | loss: 0.0992524\n",
      "\tspeed: 0.0427s/iter; left time: 886.4793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0937855 Vali Loss: 0.0996726 Test Loss: 0.1424522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0945621\n",
      "\tspeed: 0.0773s/iter; left time: 1595.5992s\n",
      "\titers: 200, epoch: 8 | loss: 0.0939109\n",
      "\tspeed: 0.0426s/iter; left time: 875.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0936755 Vali Loss: 0.1024916 Test Loss: 0.1467435\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0887522\n",
      "\tspeed: 0.0760s/iter; left time: 1551.4934s\n",
      "\titers: 200, epoch: 9 | loss: 0.0920229\n",
      "\tspeed: 0.0426s/iter; left time: 865.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0919150 Vali Loss: 0.0953999 Test Loss: 0.1427314\n",
      "Validation loss decreased (0.097960 --> 0.095400).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0884007\n",
      "\tspeed: 0.0784s/iter; left time: 1583.0353s\n",
      "\titers: 200, epoch: 10 | loss: 0.0903946\n",
      "\tspeed: 0.0425s/iter; left time: 854.8632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0908494 Vali Loss: 0.0931042 Test Loss: 0.1378654\n",
      "Validation loss decreased (0.095400 --> 0.093104).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0914468\n",
      "\tspeed: 0.0790s/iter; left time: 1577.1547s\n",
      "\titers: 200, epoch: 11 | loss: 0.0901907\n",
      "\tspeed: 0.0425s/iter; left time: 845.0532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0896935 Vali Loss: 0.0930687 Test Loss: 0.1398153\n",
      "Validation loss decreased (0.093104 --> 0.093069).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0928008\n",
      "\tspeed: 0.0779s/iter; left time: 1537.7719s\n",
      "\titers: 200, epoch: 12 | loss: 0.0888951\n",
      "\tspeed: 0.0426s/iter; left time: 837.5085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0892324 Vali Loss: 0.0942460 Test Loss: 0.1390823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0872152\n",
      "\tspeed: 0.0758s/iter; left time: 1480.7912s\n",
      "\titers: 200, epoch: 13 | loss: 0.0851387\n",
      "\tspeed: 0.0426s/iter; left time: 826.6887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0881592 Vali Loss: 0.0938593 Test Loss: 0.1383692\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0895490\n",
      "\tspeed: 0.0772s/iter; left time: 1489.4213s\n",
      "\titers: 200, epoch: 14 | loss: 0.0853068\n",
      "\tspeed: 0.0426s/iter; left time: 817.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0888112 Vali Loss: 0.0914987 Test Loss: 0.1358218\n",
      "Validation loss decreased (0.093069 --> 0.091499).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0881773\n",
      "\tspeed: 0.0792s/iter; left time: 1511.9911s\n",
      "\titers: 200, epoch: 15 | loss: 0.0827637\n",
      "\tspeed: 0.0426s/iter; left time: 808.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 223 | Train Loss: 0.0874914 Vali Loss: 0.0908197 Test Loss: 0.1358706\n",
      "Validation loss decreased (0.091499 --> 0.090820).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0862552\n",
      "\tspeed: 0.0774s/iter; left time: 1459.9201s\n",
      "\titers: 200, epoch: 16 | loss: 0.0883041\n",
      "\tspeed: 0.0425s/iter; left time: 796.5954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0872136 Vali Loss: 0.0907012 Test Loss: 0.1373940\n",
      "Validation loss decreased (0.090820 --> 0.090701).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0840904\n",
      "\tspeed: 0.0781s/iter; left time: 1454.9958s\n",
      "\titers: 200, epoch: 17 | loss: 0.0898115\n",
      "\tspeed: 0.0427s/iter; left time: 790.7168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 223 | Train Loss: 0.0869106 Vali Loss: 0.0912499 Test Loss: 0.1379926\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0886178\n",
      "\tspeed: 0.0772s/iter; left time: 1421.3983s\n",
      "\titers: 200, epoch: 18 | loss: 0.0859052\n",
      "\tspeed: 0.0426s/iter; left time: 779.1043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0876215 Vali Loss: 0.0946320 Test Loss: 0.1392124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0867052\n",
      "\tspeed: 0.0770s/iter; left time: 1401.0992s\n",
      "\titers: 200, epoch: 19 | loss: 0.0860051\n",
      "\tspeed: 0.0426s/iter; left time: 770.0303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0873270 Vali Loss: 0.0892550 Test Loss: 0.1359103\n",
      "Validation loss decreased (0.090701 --> 0.089255).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0867018\n",
      "\tspeed: 0.0779s/iter; left time: 1399.8553s\n",
      "\titers: 200, epoch: 20 | loss: 0.0863457\n",
      "\tspeed: 0.0426s/iter; left time: 760.7921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 223 | Train Loss: 0.0862757 Vali Loss: 0.0908372 Test Loss: 0.1369751\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0888121\n",
      "\tspeed: 0.0765s/iter; left time: 1356.4379s\n",
      "\titers: 200, epoch: 21 | loss: 0.0877481\n",
      "\tspeed: 0.0426s/iter; left time: 751.4654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0863021 Vali Loss: 0.0917473 Test Loss: 0.1382900\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0832196\n",
      "\tspeed: 0.0774s/iter; left time: 1356.0485s\n",
      "\titers: 200, epoch: 22 | loss: 0.0858888\n",
      "\tspeed: 0.0427s/iter; left time: 743.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0856748 Vali Loss: 0.0892366 Test Loss: 0.1354188\n",
      "Validation loss decreased (0.089255 --> 0.089237).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0855522\n",
      "\tspeed: 0.0771s/iter; left time: 1332.6996s\n",
      "\titers: 200, epoch: 23 | loss: 0.0853086\n",
      "\tspeed: 0.0426s/iter; left time: 732.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0857599 Vali Loss: 0.0893353 Test Loss: 0.1353781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0914187\n",
      "\tspeed: 0.0767s/iter; left time: 1309.0933s\n",
      "\titers: 200, epoch: 24 | loss: 0.0799562\n",
      "\tspeed: 0.0427s/iter; left time: 724.0269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0859845 Vali Loss: 0.0921442 Test Loss: 0.1365087\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0853375\n",
      "\tspeed: 0.0769s/iter; left time: 1295.6289s\n",
      "\titers: 200, epoch: 25 | loss: 0.0820595\n",
      "\tspeed: 0.0426s/iter; left time: 713.6852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0856542 Vali Loss: 0.0891722 Test Loss: 0.1356185\n",
      "Validation loss decreased (0.089237 --> 0.089172).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0888816\n",
      "\tspeed: 0.0782s/iter; left time: 1299.7566s\n",
      "\titers: 200, epoch: 26 | loss: 0.0827245\n",
      "\tspeed: 0.0425s/iter; left time: 702.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0850530 Vali Loss: 0.0898851 Test Loss: 0.1366554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0862198\n",
      "\tspeed: 0.0776s/iter; left time: 1273.1719s\n",
      "\titers: 200, epoch: 27 | loss: 0.0878539\n",
      "\tspeed: 0.0426s/iter; left time: 694.1700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 223 | Train Loss: 0.0850625 Vali Loss: 0.0892707 Test Loss: 0.1363073\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0839304\n",
      "\tspeed: 0.0772s/iter; left time: 1249.1944s\n",
      "\titers: 200, epoch: 28 | loss: 0.0821010\n",
      "\tspeed: 0.0426s/iter; left time: 684.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0852617 Vali Loss: 0.0900035 Test Loss: 0.1367089\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0843386\n",
      "\tspeed: 0.0779s/iter; left time: 1242.9421s\n",
      "\titers: 200, epoch: 29 | loss: 0.0893352\n",
      "\tspeed: 0.0428s/iter; left time: 679.2721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 223 | Train Loss: 0.0849218 Vali Loss: 0.0892000 Test Loss: 0.1362580\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0848396\n",
      "\tspeed: 0.0767s/iter; left time: 1206.5649s\n",
      "\titers: 200, epoch: 30 | loss: 0.0863243\n",
      "\tspeed: 0.0425s/iter; left time: 665.0665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 223 | Train Loss: 0.0848348 Vali Loss: 0.0898100 Test Loss: 0.1367810\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0845568\n",
      "\tspeed: 0.0769s/iter; left time: 1192.3978s\n",
      "\titers: 200, epoch: 31 | loss: 0.0850878\n",
      "\tspeed: 0.0425s/iter; left time: 655.1131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0847634 Vali Loss: 0.0890932 Test Loss: 0.1358228\n",
      "Validation loss decreased (0.089172 --> 0.089093).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0850394\n",
      "\tspeed: 0.0786s/iter; left time: 1201.4420s\n",
      "\titers: 200, epoch: 32 | loss: 0.0882436\n",
      "\tspeed: 0.0426s/iter; left time: 647.0890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0846847 Vali Loss: 0.0891982 Test Loss: 0.1360674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0844422\n",
      "\tspeed: 0.0766s/iter; left time: 1154.7084s\n",
      "\titers: 200, epoch: 33 | loss: 0.0839714\n",
      "\tspeed: 0.0426s/iter; left time: 638.0113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0847114 Vali Loss: 0.0892607 Test Loss: 0.1359668\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0820594\n",
      "\tspeed: 0.0771s/iter; left time: 1144.6395s\n",
      "\titers: 200, epoch: 34 | loss: 0.0816068\n",
      "\tspeed: 0.0427s/iter; left time: 629.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0845782 Vali Loss: 0.0899430 Test Loss: 0.1364044\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0824568\n",
      "\tspeed: 0.0764s/iter; left time: 1116.8210s\n",
      "\titers: 200, epoch: 35 | loss: 0.0838376\n",
      "\tspeed: 0.0425s/iter; left time: 617.3643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0844194 Vali Loss: 0.0888675 Test Loss: 0.1354093\n",
      "Validation loss decreased (0.089093 --> 0.088868).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0895643\n",
      "\tspeed: 0.0771s/iter; left time: 1109.6644s\n",
      "\titers: 200, epoch: 36 | loss: 0.0875119\n",
      "\tspeed: 0.0426s/iter; left time: 609.2161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0845278 Vali Loss: 0.0889360 Test Loss: 0.1354685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0870122\n",
      "\tspeed: 0.0771s/iter; left time: 1092.6925s\n",
      "\titers: 200, epoch: 37 | loss: 0.0836079\n",
      "\tspeed: 0.0426s/iter; left time: 600.1585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0846099 Vali Loss: 0.0888024 Test Loss: 0.1353566\n",
      "Validation loss decreased (0.088868 --> 0.088802).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0847118\n",
      "\tspeed: 0.0777s/iter; left time: 1084.5107s\n",
      "\titers: 200, epoch: 38 | loss: 0.0843020\n",
      "\tspeed: 0.0427s/iter; left time: 591.8061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 223 | Train Loss: 0.0844919 Vali Loss: 0.0888627 Test Loss: 0.1354519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0845254\n",
      "\tspeed: 0.0775s/iter; left time: 1063.7204s\n",
      "\titers: 200, epoch: 39 | loss: 0.0836778\n",
      "\tspeed: 0.0426s/iter; left time: 580.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 223 | Train Loss: 0.0844431 Vali Loss: 0.0895282 Test Loss: 0.1363617\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0807033\n",
      "\tspeed: 0.0762s/iter; left time: 1029.2698s\n",
      "\titers: 200, epoch: 40 | loss: 0.0824700\n",
      "\tspeed: 0.0425s/iter; left time: 569.8980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0842815 Vali Loss: 0.0891515 Test Loss: 0.1358767\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0839139\n",
      "\tspeed: 0.0768s/iter; left time: 1019.4313s\n",
      "\titers: 200, epoch: 41 | loss: 0.0878254\n",
      "\tspeed: 0.0425s/iter; left time: 560.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0844357 Vali Loss: 0.0890781 Test Loss: 0.1354391\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0846736\n",
      "\tspeed: 0.0783s/iter; left time: 1023.0406s\n",
      "\titers: 200, epoch: 42 | loss: 0.0825054\n",
      "\tspeed: 0.0426s/iter; left time: 552.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0842559 Vali Loss: 0.0894227 Test Loss: 0.1359987\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0880081\n",
      "\tspeed: 0.0773s/iter; left time: 992.3558s\n",
      "\titers: 200, epoch: 43 | loss: 0.0812643\n",
      "\tspeed: 0.0426s/iter; left time: 542.4969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0843002 Vali Loss: 0.0894387 Test Loss: 0.1364313\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0822579\n",
      "\tspeed: 0.0767s/iter; left time: 966.7598s\n",
      "\titers: 200, epoch: 44 | loss: 0.0823426\n",
      "\tspeed: 0.0425s/iter; left time: 532.2013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0841654 Vali Loss: 0.0890323 Test Loss: 0.1358647\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0849962\n",
      "\tspeed: 0.0770s/iter; left time: 953.8431s\n",
      "\titers: 200, epoch: 45 | loss: 0.0849998\n",
      "\tspeed: 0.0426s/iter; left time: 523.7765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0841882 Vali Loss: 0.0891828 Test Loss: 0.1361771\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0842887\n",
      "\tspeed: 0.0764s/iter; left time: 929.3669s\n",
      "\titers: 200, epoch: 46 | loss: 0.0864327\n",
      "\tspeed: 0.0425s/iter; left time: 512.9070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0841576 Vali Loss: 0.0890473 Test Loss: 0.1356513\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0837607\n",
      "\tspeed: 0.0772s/iter; left time: 921.6854s\n",
      "\titers: 200, epoch: 47 | loss: 0.0823900\n",
      "\tspeed: 0.0425s/iter; left time: 503.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0842981 Vali Loss: 0.0890231 Test Loss: 0.1358115\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04962244629859924, rmse:0.22276096045970917, mae:0.13535654544830322, rse:0.6544516682624817\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3174087\n",
      "\tspeed: 0.0446s/iter; left time: 989.1500s\n",
      "\titers: 200, epoch: 1 | loss: 0.2956870\n",
      "\tspeed: 0.0425s/iter; left time: 938.7683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.3239668 Vali Loss: 0.2482776 Test Loss: 0.2581214\n",
      "Validation loss decreased (inf --> 0.248278).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1453250\n",
      "\tspeed: 0.0774s/iter; left time: 1700.5007s\n",
      "\titers: 200, epoch: 2 | loss: 0.1266367\n",
      "\tspeed: 0.0426s/iter; left time: 931.5137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.1682984 Vali Loss: 0.1195645 Test Loss: 0.1576260\n",
      "Validation loss decreased (0.248278 --> 0.119565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1138143\n",
      "\tspeed: 0.0775s/iter; left time: 1685.3293s\n",
      "\titers: 200, epoch: 3 | loss: 0.1135432\n",
      "\tspeed: 0.0425s/iter; left time: 920.5848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.1166305 Vali Loss: 0.1092892 Test Loss: 0.1569457\n",
      "Validation loss decreased (0.119565 --> 0.109289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1035430\n",
      "\tspeed: 0.0778s/iter; left time: 1675.8382s\n",
      "\titers: 200, epoch: 4 | loss: 0.0960807\n",
      "\tspeed: 0.0425s/iter; left time: 911.6021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 223 | Train Loss: 0.1048550 Vali Loss: 0.1047863 Test Loss: 0.1545392\n",
      "Validation loss decreased (0.109289 --> 0.104786).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1019759\n",
      "\tspeed: 0.0778s/iter; left time: 1658.5272s\n",
      "\titers: 200, epoch: 5 | loss: 0.0986392\n",
      "\tspeed: 0.0425s/iter; left time: 902.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0997270 Vali Loss: 0.0984374 Test Loss: 0.1516262\n",
      "Validation loss decreased (0.104786 --> 0.098437).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0933840\n",
      "\tspeed: 0.0775s/iter; left time: 1633.2959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0976910\n",
      "\tspeed: 0.0425s/iter; left time: 891.7732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0963777 Vali Loss: 0.0967850 Test Loss: 0.1519897\n",
      "Validation loss decreased (0.098437 --> 0.096785).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0973160\n",
      "\tspeed: 0.0779s/iter; left time: 1624.2715s\n",
      "\titers: 200, epoch: 7 | loss: 0.0931314\n",
      "\tspeed: 0.0426s/iter; left time: 885.3029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0943244 Vali Loss: 0.0982957 Test Loss: 0.1547878\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0915598\n",
      "\tspeed: 0.0763s/iter; left time: 1575.0463s\n",
      "\titers: 200, epoch: 8 | loss: 0.0909589\n",
      "\tspeed: 0.0427s/iter; left time: 878.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0931408 Vali Loss: 0.0965113 Test Loss: 0.1531991\n",
      "Validation loss decreased (0.096785 --> 0.096511).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0902992\n",
      "\tspeed: 0.0780s/iter; left time: 1592.1857s\n",
      "\titers: 200, epoch: 9 | loss: 0.0897999\n",
      "\tspeed: 0.0427s/iter; left time: 867.8457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 223 | Train Loss: 0.0909445 Vali Loss: 0.0935875 Test Loss: 0.1520923\n",
      "Validation loss decreased (0.096511 --> 0.093587).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0894575\n",
      "\tspeed: 0.0785s/iter; left time: 1585.2978s\n",
      "\titers: 200, epoch: 10 | loss: 0.0912405\n",
      "\tspeed: 0.0426s/iter; left time: 856.8554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 223 | Train Loss: 0.0908273 Vali Loss: 0.0922674 Test Loss: 0.1516985\n",
      "Validation loss decreased (0.093587 --> 0.092267).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0874624\n",
      "\tspeed: 0.0783s/iter; left time: 1562.9026s\n",
      "\titers: 200, epoch: 11 | loss: 0.0883814\n",
      "\tspeed: 0.0427s/iter; left time: 848.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 223 | Train Loss: 0.0894625 Vali Loss: 0.0915795 Test Loss: 0.1535198\n",
      "Validation loss decreased (0.092267 --> 0.091580).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0908414\n",
      "\tspeed: 0.0774s/iter; left time: 1528.7713s\n",
      "\titers: 200, epoch: 12 | loss: 0.0866251\n",
      "\tspeed: 0.0427s/iter; left time: 839.2324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 223 | Train Loss: 0.0890035 Vali Loss: 0.0905755 Test Loss: 0.1515832\n",
      "Validation loss decreased (0.091580 --> 0.090575).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0875662\n",
      "\tspeed: 0.0776s/iter; left time: 1514.8279s\n",
      "\titers: 200, epoch: 13 | loss: 0.0869797\n",
      "\tspeed: 0.0426s/iter; left time: 828.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0891852 Vali Loss: 0.0904725 Test Loss: 0.1533539\n",
      "Validation loss decreased (0.090575 --> 0.090472).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0881678\n",
      "\tspeed: 0.0778s/iter; left time: 1501.2393s\n",
      "\titers: 200, epoch: 14 | loss: 0.0887098\n",
      "\tspeed: 0.0427s/iter; left time: 820.1749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 223 | Train Loss: 0.0888152 Vali Loss: 0.0939325 Test Loss: 0.1557537\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0888099\n",
      "\tspeed: 0.0765s/iter; left time: 1459.3374s\n",
      "\titers: 200, epoch: 15 | loss: 0.0902969\n",
      "\tspeed: 0.0427s/iter; left time: 810.6968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0881121 Vali Loss: 0.0916452 Test Loss: 0.1510668\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0889186\n",
      "\tspeed: 0.0769s/iter; left time: 1450.2112s\n",
      "\titers: 200, epoch: 16 | loss: 0.0851880\n",
      "\tspeed: 0.0426s/iter; left time: 798.1429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0873790 Vali Loss: 0.0959542 Test Loss: 0.1548239\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0874300\n",
      "\tspeed: 0.0765s/iter; left time: 1425.7119s\n",
      "\titers: 200, epoch: 17 | loss: 0.0877072\n",
      "\tspeed: 0.0425s/iter; left time: 787.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0875404 Vali Loss: 0.0936111 Test Loss: 0.1543681\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0828515\n",
      "\tspeed: 0.0760s/iter; left time: 1398.6850s\n",
      "\titers: 200, epoch: 18 | loss: 0.0876014\n",
      "\tspeed: 0.0425s/iter; left time: 778.8774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0868518 Vali Loss: 0.0896772 Test Loss: 0.1498744\n",
      "Validation loss decreased (0.090472 --> 0.089677).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0847368\n",
      "\tspeed: 0.0776s/iter; left time: 1412.0987s\n",
      "\titers: 200, epoch: 19 | loss: 0.0819657\n",
      "\tspeed: 0.0426s/iter; left time: 770.0687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0866791 Vali Loss: 0.0898687 Test Loss: 0.1504312\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0887018\n",
      "\tspeed: 0.0764s/iter; left time: 1373.3230s\n",
      "\titers: 200, epoch: 20 | loss: 0.0845105\n",
      "\tspeed: 0.0425s/iter; left time: 758.7293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0864550 Vali Loss: 0.0895001 Test Loss: 0.1507046\n",
      "Validation loss decreased (0.089677 --> 0.089500).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0938381\n",
      "\tspeed: 0.0776s/iter; left time: 1376.7744s\n",
      "\titers: 200, epoch: 21 | loss: 0.0841959\n",
      "\tspeed: 0.0426s/iter; left time: 750.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0860503 Vali Loss: 0.0924025 Test Loss: 0.1525994\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0845747\n",
      "\tspeed: 0.0764s/iter; left time: 1339.0244s\n",
      "\titers: 200, epoch: 22 | loss: 0.0819900\n",
      "\tspeed: 0.0426s/iter; left time: 741.5720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0859649 Vali Loss: 0.0892289 Test Loss: 0.1493178\n",
      "Validation loss decreased (0.089500 --> 0.089229).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0813451\n",
      "\tspeed: 0.0789s/iter; left time: 1363.9508s\n",
      "\titers: 200, epoch: 23 | loss: 0.0870861\n",
      "\tspeed: 0.0425s/iter; left time: 730.1748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 223 | Train Loss: 0.0862434 Vali Loss: 0.0892832 Test Loss: 0.1498053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0860874\n",
      "\tspeed: 0.0767s/iter; left time: 1308.6264s\n",
      "\titers: 200, epoch: 24 | loss: 0.0840734\n",
      "\tspeed: 0.0425s/iter; left time: 722.0557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0857432 Vali Loss: 0.0915567 Test Loss: 0.1527874\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0869654\n",
      "\tspeed: 0.0764s/iter; left time: 1286.7451s\n",
      "\titers: 200, epoch: 25 | loss: 0.0831245\n",
      "\tspeed: 0.0425s/iter; left time: 712.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0854230 Vali Loss: 0.0895353 Test Loss: 0.1513790\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0833266\n",
      "\tspeed: 0.0766s/iter; left time: 1274.3122s\n",
      "\titers: 200, epoch: 26 | loss: 0.0840288\n",
      "\tspeed: 0.0425s/iter; left time: 703.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0852122 Vali Loss: 0.0891337 Test Loss: 0.1507527\n",
      "Validation loss decreased (0.089229 --> 0.089134).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0865420\n",
      "\tspeed: 0.0771s/iter; left time: 1263.9972s\n",
      "\titers: 200, epoch: 27 | loss: 0.0833434\n",
      "\tspeed: 0.0425s/iter; left time: 692.8177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0853875 Vali Loss: 0.0896702 Test Loss: 0.1515306\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0822393\n",
      "\tspeed: 0.0761s/iter; left time: 1230.5802s\n",
      "\titers: 200, epoch: 28 | loss: 0.0832239\n",
      "\tspeed: 0.0425s/iter; left time: 683.8783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0848986 Vali Loss: 0.0893864 Test Loss: 0.1503136\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0859011\n",
      "\tspeed: 0.0762s/iter; left time: 1215.5466s\n",
      "\titers: 200, epoch: 29 | loss: 0.0861550\n",
      "\tspeed: 0.0426s/iter; left time: 674.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0852147 Vali Loss: 0.0890079 Test Loss: 0.1498092\n",
      "Validation loss decreased (0.089134 --> 0.089008).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0791517\n",
      "\tspeed: 0.0771s/iter; left time: 1213.0669s\n",
      "\titers: 200, epoch: 30 | loss: 0.0835869\n",
      "\tspeed: 0.0426s/iter; left time: 665.3750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0848367 Vali Loss: 0.0889438 Test Loss: 0.1496054\n",
      "Validation loss decreased (0.089008 --> 0.088944).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0852168\n",
      "\tspeed: 0.0773s/iter; left time: 1198.2362s\n",
      "\titers: 200, epoch: 31 | loss: 0.0841717\n",
      "\tspeed: 0.0426s/iter; left time: 656.3466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0846574 Vali Loss: 0.0890308 Test Loss: 0.1495505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0834046\n",
      "\tspeed: 0.0768s/iter; left time: 1174.7683s\n",
      "\titers: 200, epoch: 32 | loss: 0.0846137\n",
      "\tspeed: 0.0426s/iter; left time: 646.8894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0847139 Vali Loss: 0.0894200 Test Loss: 0.1504884\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0831619\n",
      "\tspeed: 0.0765s/iter; left time: 1153.0845s\n",
      "\titers: 200, epoch: 33 | loss: 0.0848146\n",
      "\tspeed: 0.0425s/iter; left time: 636.7029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0847628 Vali Loss: 0.0894922 Test Loss: 0.1500004\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0859950\n",
      "\tspeed: 0.0761s/iter; left time: 1128.8995s\n",
      "\titers: 200, epoch: 34 | loss: 0.0817617\n",
      "\tspeed: 0.0425s/iter; left time: 626.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0847459 Vali Loss: 0.0888795 Test Loss: 0.1499576\n",
      "Validation loss decreased (0.088944 --> 0.088879).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0822178\n",
      "\tspeed: 0.0784s/iter; left time: 1146.3422s\n",
      "\titers: 200, epoch: 35 | loss: 0.0889144\n",
      "\tspeed: 0.0425s/iter; left time: 617.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0845112 Vali Loss: 0.0887832 Test Loss: 0.1498219\n",
      "Validation loss decreased (0.088879 --> 0.088783).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0824975\n",
      "\tspeed: 0.0782s/iter; left time: 1125.6975s\n",
      "\titers: 200, epoch: 36 | loss: 0.0856030\n",
      "\tspeed: 0.0426s/iter; left time: 608.4591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0846783 Vali Loss: 0.0891520 Test Loss: 0.1501730\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0838164\n",
      "\tspeed: 0.0762s/iter; left time: 1080.2782s\n",
      "\titers: 200, epoch: 37 | loss: 0.0826987\n",
      "\tspeed: 0.0426s/iter; left time: 599.2454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0845627 Vali Loss: 0.0896718 Test Loss: 0.1519541\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0831691\n",
      "\tspeed: 0.0765s/iter; left time: 1066.7499s\n",
      "\titers: 200, epoch: 38 | loss: 0.0818885\n",
      "\tspeed: 0.0424s/iter; left time: 587.7090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0845236 Vali Loss: 0.0895209 Test Loss: 0.1512006\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0855364\n",
      "\tspeed: 0.0766s/iter; left time: 1051.8799s\n",
      "\titers: 200, epoch: 39 | loss: 0.0853109\n",
      "\tspeed: 0.0426s/iter; left time: 580.0020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0845177 Vali Loss: 0.0888840 Test Loss: 0.1495702\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0861219\n",
      "\tspeed: 0.0766s/iter; left time: 1035.0608s\n",
      "\titers: 200, epoch: 40 | loss: 0.0863606\n",
      "\tspeed: 0.0426s/iter; left time: 570.6562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0846398 Vali Loss: 0.0897976 Test Loss: 0.1514753\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0830814\n",
      "\tspeed: 0.0762s/iter; left time: 1012.1944s\n",
      "\titers: 200, epoch: 41 | loss: 0.0849512\n",
      "\tspeed: 0.0424s/iter; left time: 559.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0843972 Vali Loss: 0.0889827 Test Loss: 0.1506425\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0821308\n",
      "\tspeed: 0.0757s/iter; left time: 988.8870s\n",
      "\titers: 200, epoch: 42 | loss: 0.0825726\n",
      "\tspeed: 0.0423s/iter; left time: 548.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0843426 Vali Loss: 0.0889790 Test Loss: 0.1502305\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0843784\n",
      "\tspeed: 0.0758s/iter; left time: 973.1669s\n",
      "\titers: 200, epoch: 43 | loss: 0.0854534\n",
      "\tspeed: 0.0424s/iter; left time: 539.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0843659 Vali Loss: 0.0890807 Test Loss: 0.1505471\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0811433\n",
      "\tspeed: 0.0756s/iter; left time: 953.3141s\n",
      "\titers: 200, epoch: 44 | loss: 0.0825480\n",
      "\tspeed: 0.0424s/iter; left time: 530.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0843423 Vali Loss: 0.0891931 Test Loss: 0.1505951\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0798439\n",
      "\tspeed: 0.0762s/iter; left time: 943.8919s\n",
      "\titers: 200, epoch: 45 | loss: 0.0855255\n",
      "\tspeed: 0.0424s/iter; left time: 520.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0843182 Vali Loss: 0.0889193 Test Loss: 0.1498464\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06905001401901245, rmse:0.26277369260787964, mae:0.14982187747955322, rse:0.7720054388046265\n",
      "Intermediate time for ES and pred_len 168: 00h:18m:32.94s\n",
      "Intermediate time for ES: 01h:09m:52.98s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2744154\n",
      "\tspeed: 0.0599s/iter; left time: 1335.8801s\n",
      "\titers: 200, epoch: 1 | loss: 0.2455048\n",
      "\tspeed: 0.0417s/iter; left time: 925.5854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.2809687 Vali Loss: 0.2048170 Test Loss: 0.2064111\n",
      "Validation loss decreased (inf --> 0.204817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1816107\n",
      "\tspeed: 0.0751s/iter; left time: 1657.3033s\n",
      "\titers: 200, epoch: 2 | loss: 0.1347806\n",
      "\tspeed: 0.0416s/iter; left time: 915.2331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.1726157 Vali Loss: 0.1280546 Test Loss: 0.1516940\n",
      "Validation loss decreased (0.204817 --> 0.128055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1040350\n",
      "\tspeed: 0.0752s/iter; left time: 1643.1794s\n",
      "\titers: 200, epoch: 3 | loss: 0.0927908\n",
      "\tspeed: 0.0417s/iter; left time: 906.8518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.1025130 Vali Loss: 0.0900932 Test Loss: 0.1007738\n",
      "Validation loss decreased (0.128055 --> 0.090093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0741331\n",
      "\tspeed: 0.0749s/iter; left time: 1619.1462s\n",
      "\titers: 200, epoch: 4 | loss: 0.0658076\n",
      "\tspeed: 0.0418s/iter; left time: 899.4427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0775603 Vali Loss: 0.0756710 Test Loss: 0.0841894\n",
      "Validation loss decreased (0.090093 --> 0.075671).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0648920\n",
      "\tspeed: 0.0743s/iter; left time: 1590.7210s\n",
      "\titers: 200, epoch: 5 | loss: 0.0691439\n",
      "\tspeed: 0.0417s/iter; left time: 887.6224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0676531 Vali Loss: 0.0749461 Test Loss: 0.0816077\n",
      "Validation loss decreased (0.075671 --> 0.074946).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0644313\n",
      "\tspeed: 0.0744s/iter; left time: 1574.8791s\n",
      "\titers: 200, epoch: 6 | loss: 0.0638870\n",
      "\tspeed: 0.0416s/iter; left time: 877.6873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0635680 Vali Loss: 0.0683489 Test Loss: 0.0749693\n",
      "Validation loss decreased (0.074946 --> 0.068349).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0659980\n",
      "\tspeed: 0.0747s/iter; left time: 1566.0012s\n",
      "\titers: 200, epoch: 7 | loss: 0.0587756\n",
      "\tspeed: 0.0416s/iter; left time: 868.5560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0605888 Vali Loss: 0.0674125 Test Loss: 0.0741246\n",
      "Validation loss decreased (0.068349 --> 0.067413).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0618482\n",
      "\tspeed: 0.0744s/iter; left time: 1542.9243s\n",
      "\titers: 200, epoch: 8 | loss: 0.0578309\n",
      "\tspeed: 0.0416s/iter; left time: 859.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0585786 Vali Loss: 0.0651830 Test Loss: 0.0712655\n",
      "Validation loss decreased (0.067413 --> 0.065183).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0582443\n",
      "\tspeed: 0.0751s/iter; left time: 1540.0107s\n",
      "\titers: 200, epoch: 9 | loss: 0.0573370\n",
      "\tspeed: 0.0417s/iter; left time: 850.2550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0569201 Vali Loss: 0.0643942 Test Loss: 0.0703640\n",
      "Validation loss decreased (0.065183 --> 0.064394).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0563221\n",
      "\tspeed: 0.0747s/iter; left time: 1515.1724s\n",
      "\titers: 200, epoch: 10 | loss: 0.0525484\n",
      "\tspeed: 0.0416s/iter; left time: 840.6906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0561697 Vali Loss: 0.0650444 Test Loss: 0.0709822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0585912\n",
      "\tspeed: 0.0747s/iter; left time: 1498.0314s\n",
      "\titers: 200, epoch: 11 | loss: 0.0543757\n",
      "\tspeed: 0.0417s/iter; left time: 831.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0558713 Vali Loss: 0.0622902 Test Loss: 0.0678145\n",
      "Validation loss decreased (0.064394 --> 0.062290).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0527112\n",
      "\tspeed: 0.0756s/iter; left time: 1499.8650s\n",
      "\titers: 200, epoch: 12 | loss: 0.0530497\n",
      "\tspeed: 0.0416s/iter; left time: 821.4673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0546492 Vali Loss: 0.0622032 Test Loss: 0.0677312\n",
      "Validation loss decreased (0.062290 --> 0.062203).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0517155\n",
      "\tspeed: 0.0754s/iter; left time: 1478.8887s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571001\n",
      "\tspeed: 0.0416s/iter; left time: 812.4368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0540908 Vali Loss: 0.0621205 Test Loss: 0.0681590\n",
      "Validation loss decreased (0.062203 --> 0.062120).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0594438\n",
      "\tspeed: 0.0752s/iter; left time: 1458.8613s\n",
      "\titers: 200, epoch: 14 | loss: 0.0578507\n",
      "\tspeed: 0.0417s/iter; left time: 803.4161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0535914 Vali Loss: 0.0614007 Test Loss: 0.0669506\n",
      "Validation loss decreased (0.062120 --> 0.061401).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0558920\n",
      "\tspeed: 0.0749s/iter; left time: 1434.8975s\n",
      "\titers: 200, epoch: 15 | loss: 0.0542835\n",
      "\tspeed: 0.0417s/iter; left time: 794.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0531507 Vali Loss: 0.0614685 Test Loss: 0.0665809\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0532119\n",
      "\tspeed: 0.0747s/iter; left time: 1414.6229s\n",
      "\titers: 200, epoch: 16 | loss: 0.0499860\n",
      "\tspeed: 0.0417s/iter; left time: 784.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0532788 Vali Loss: 0.0624567 Test Loss: 0.0680153\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0478848\n",
      "\tspeed: 0.0740s/iter; left time: 1384.4114s\n",
      "\titers: 200, epoch: 17 | loss: 0.0487295\n",
      "\tspeed: 0.0417s/iter; left time: 776.5468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0522900 Vali Loss: 0.0604911 Test Loss: 0.0655435\n",
      "Validation loss decreased (0.061401 --> 0.060491).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0507799\n",
      "\tspeed: 0.0748s/iter; left time: 1383.4913s\n",
      "\titers: 200, epoch: 18 | loss: 0.0492917\n",
      "\tspeed: 0.0417s/iter; left time: 766.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0519890 Vali Loss: 0.0601076 Test Loss: 0.0655397\n",
      "Validation loss decreased (0.060491 --> 0.060108).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0498037\n",
      "\tspeed: 0.0747s/iter; left time: 1364.2611s\n",
      "\titers: 200, epoch: 19 | loss: 0.0520305\n",
      "\tspeed: 0.0416s/iter; left time: 756.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0518739 Vali Loss: 0.0599856 Test Loss: 0.0653419\n",
      "Validation loss decreased (0.060108 --> 0.059986).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0514498\n",
      "\tspeed: 0.0745s/iter; left time: 1345.0001s\n",
      "\titers: 200, epoch: 20 | loss: 0.0513590\n",
      "\tspeed: 0.0417s/iter; left time: 747.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0516221 Vali Loss: 0.0599160 Test Loss: 0.0650086\n",
      "Validation loss decreased (0.059986 --> 0.059916).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0494265\n",
      "\tspeed: 0.0750s/iter; left time: 1336.3447s\n",
      "\titers: 200, epoch: 21 | loss: 0.0510286\n",
      "\tspeed: 0.0416s/iter; left time: 737.7779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0515325 Vali Loss: 0.0600282 Test Loss: 0.0656256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0513238\n",
      "\tspeed: 0.0749s/iter; left time: 1317.4451s\n",
      "\titers: 200, epoch: 22 | loss: 0.0535172\n",
      "\tspeed: 0.0417s/iter; left time: 728.8879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0513477 Vali Loss: 0.0596492 Test Loss: 0.0651364\n",
      "Validation loss decreased (0.059916 --> 0.059649).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0491816\n",
      "\tspeed: 0.0751s/iter; left time: 1304.6278s\n",
      "\titers: 200, epoch: 23 | loss: 0.0549327\n",
      "\tspeed: 0.0416s/iter; left time: 718.3010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0511812 Vali Loss: 0.0594210 Test Loss: 0.0646627\n",
      "Validation loss decreased (0.059649 --> 0.059421).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0513367\n",
      "\tspeed: 0.0745s/iter; left time: 1277.4637s\n",
      "\titers: 200, epoch: 24 | loss: 0.0520185\n",
      "\tspeed: 0.0416s/iter; left time: 709.7633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0510116 Vali Loss: 0.0600830 Test Loss: 0.0651694\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0492416\n",
      "\tspeed: 0.0742s/iter; left time: 1255.0663s\n",
      "\titers: 200, epoch: 25 | loss: 0.0482893\n",
      "\tspeed: 0.0417s/iter; left time: 700.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0507646 Vali Loss: 0.0596981 Test Loss: 0.0648979\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0519148\n",
      "\tspeed: 0.0751s/iter; left time: 1253.7687s\n",
      "\titers: 200, epoch: 26 | loss: 0.0505695\n",
      "\tspeed: 0.0417s/iter; left time: 691.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0505561 Vali Loss: 0.0592686 Test Loss: 0.0646921\n",
      "Validation loss decreased (0.059421 --> 0.059269).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0495308\n",
      "\tspeed: 0.0745s/iter; left time: 1227.5694s\n",
      "\titers: 200, epoch: 27 | loss: 0.0507753\n",
      "\tspeed: 0.0417s/iter; left time: 682.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0504014 Vali Loss: 0.0588614 Test Loss: 0.0641813\n",
      "Validation loss decreased (0.059269 --> 0.058861).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0513166\n",
      "\tspeed: 0.0753s/iter; left time: 1223.7534s\n",
      "\titers: 200, epoch: 28 | loss: 0.0529209\n",
      "\tspeed: 0.0427s/iter; left time: 689.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0503364 Vali Loss: 0.0589944 Test Loss: 0.0641192\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0495144\n",
      "\tspeed: 0.1630s/iter; left time: 2612.0342s\n",
      "\titers: 200, epoch: 29 | loss: 0.0514437\n",
      "\tspeed: 0.1526s/iter; left time: 2431.0625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:31.94s\n",
      "Steps: 224 | Train Loss: 0.0502687 Vali Loss: 0.0589600 Test Loss: 0.0645798\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0519220\n",
      "\tspeed: 0.3582s/iter; left time: 5661.2509s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523719\n",
      "\tspeed: 0.1632s/iter; left time: 2563.2949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 224 | Train Loss: 0.0500986 Vali Loss: 0.0589234 Test Loss: 0.0643626\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0501572\n",
      "\tspeed: 0.3632s/iter; left time: 5658.4237s\n",
      "\titers: 200, epoch: 31 | loss: 0.0470353\n",
      "\tspeed: 0.1776s/iter; left time: 2750.0260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:39.45s\n",
      "Steps: 224 | Train Loss: 0.0500797 Vali Loss: 0.0589552 Test Loss: 0.0642499\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0510898\n",
      "\tspeed: 0.4070s/iter; left time: 6250.4553s\n",
      "\titers: 200, epoch: 32 | loss: 0.0475605\n",
      "\tspeed: 0.1887s/iter; left time: 2879.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 224 | Train Loss: 0.0502002 Vali Loss: 0.0590570 Test Loss: 0.0642686\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0476251\n",
      "\tspeed: 0.4470s/iter; left time: 6764.7782s\n",
      "\titers: 200, epoch: 33 | loss: 0.0523661\n",
      "\tspeed: 0.1773s/iter; left time: 2664.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 224 | Train Loss: 0.0500152 Vali Loss: 0.0596466 Test Loss: 0.0648174\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0526686\n",
      "\tspeed: 0.4890s/iter; left time: 7289.7996s\n",
      "\titers: 200, epoch: 34 | loss: 0.0527698\n",
      "\tspeed: 0.2163s/iter; left time: 3203.9056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 224 | Train Loss: 0.0498218 Vali Loss: 0.0586464 Test Loss: 0.0641060\n",
      "Validation loss decreased (0.058861 --> 0.058646).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0513071\n",
      "\tspeed: 0.4501s/iter; left time: 6609.4866s\n",
      "\titers: 200, epoch: 35 | loss: 0.0536175\n",
      "\tspeed: 0.1948s/iter; left time: 2841.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:45.60s\n",
      "Steps: 224 | Train Loss: 0.0498959 Vali Loss: 0.0585357 Test Loss: 0.0639039\n",
      "Validation loss decreased (0.058646 --> 0.058536).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0465184\n",
      "\tspeed: 0.4349s/iter; left time: 6288.6260s\n",
      "\titers: 200, epoch: 36 | loss: 0.0550243\n",
      "\tspeed: 0.2101s/iter; left time: 3017.3533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:46.88s\n",
      "Steps: 224 | Train Loss: 0.0498468 Vali Loss: 0.0585325 Test Loss: 0.0639212\n",
      "Validation loss decreased (0.058536 --> 0.058533).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0543824\n",
      "\tspeed: 0.4118s/iter; left time: 5862.1299s\n",
      "\titers: 200, epoch: 37 | loss: 0.0473417\n",
      "\tspeed: 0.1815s/iter; left time: 2565.3716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:40.89s\n",
      "Steps: 224 | Train Loss: 0.0498052 Vali Loss: 0.0592615 Test Loss: 0.0645180\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0509938\n",
      "\tspeed: 0.4021s/iter; left time: 5634.6227s\n",
      "\titers: 200, epoch: 38 | loss: 0.0528439\n",
      "\tspeed: 0.1762s/iter; left time: 2451.3006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:40.51s\n",
      "Steps: 224 | Train Loss: 0.0498821 Vali Loss: 0.0585832 Test Loss: 0.0639575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0478516\n",
      "\tspeed: 0.3956s/iter; left time: 5455.1730s\n",
      "\titers: 200, epoch: 39 | loss: 0.0480606\n",
      "\tspeed: 0.1719s/iter; left time: 2353.5261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:39.39s\n",
      "Steps: 224 | Train Loss: 0.0497037 Vali Loss: 0.0585227 Test Loss: 0.0639874\n",
      "Validation loss decreased (0.058533 --> 0.058523).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0485846\n",
      "\tspeed: 0.4034s/iter; left time: 5472.0416s\n",
      "\titers: 200, epoch: 40 | loss: 0.0477140\n",
      "\tspeed: 0.1730s/iter; left time: 2329.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:40.63s\n",
      "Steps: 224 | Train Loss: 0.0494786 Vali Loss: 0.0584221 Test Loss: 0.0637564\n",
      "Validation loss decreased (0.058523 --> 0.058422).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0480269\n",
      "\tspeed: 0.4150s/iter; left time: 5536.2011s\n",
      "\titers: 200, epoch: 41 | loss: 0.0482628\n",
      "\tspeed: 0.1829s/iter; left time: 2421.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:42.34s\n",
      "Steps: 224 | Train Loss: 0.0498068 Vali Loss: 0.0587276 Test Loss: 0.0642620\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0490004\n",
      "\tspeed: 0.4125s/iter; left time: 5411.2002s\n",
      "\titers: 200, epoch: 42 | loss: 0.0464057\n",
      "\tspeed: 0.1892s/iter; left time: 2462.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:43.03s\n",
      "Steps: 224 | Train Loss: 0.0495300 Vali Loss: 0.0588621 Test Loss: 0.0641031\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0499761\n",
      "\tspeed: 0.4755s/iter; left time: 6131.2149s\n",
      "\titers: 200, epoch: 43 | loss: 0.0463296\n",
      "\tspeed: 0.2123s/iter; left time: 2716.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:50.68s\n",
      "Steps: 224 | Train Loss: 0.0495820 Vali Loss: 0.0585252 Test Loss: 0.0638718\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0476585\n",
      "\tspeed: 0.4794s/iter; left time: 6073.1968s\n",
      "\titers: 200, epoch: 44 | loss: 0.0475723\n",
      "\tspeed: 0.1803s/iter; left time: 2265.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:46.44s\n",
      "Steps: 224 | Train Loss: 0.0495591 Vali Loss: 0.0584720 Test Loss: 0.0638972\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0514856\n",
      "\tspeed: 0.4197s/iter; left time: 5223.3192s\n",
      "\titers: 200, epoch: 45 | loss: 0.0504974\n",
      "\tspeed: 0.2673s/iter; left time: 3299.8632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:52.64s\n",
      "Steps: 224 | Train Loss: 0.0496650 Vali Loss: 0.0584983 Test Loss: 0.0637249\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0537138\n",
      "\tspeed: 0.4892s/iter; left time: 5978.3725s\n",
      "\titers: 200, epoch: 46 | loss: 0.0478734\n",
      "\tspeed: 0.2099s/iter; left time: 2543.9263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:50.89s\n",
      "Steps: 224 | Train Loss: 0.0495438 Vali Loss: 0.0584651 Test Loss: 0.0637259\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0467970\n",
      "\tspeed: 0.4711s/iter; left time: 5652.0249s\n",
      "\titers: 200, epoch: 47 | loss: 0.0491301\n",
      "\tspeed: 0.2334s/iter; left time: 2777.1202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:51.06s\n",
      "Steps: 224 | Train Loss: 0.0495026 Vali Loss: 0.0582984 Test Loss: 0.0637098\n",
      "Validation loss decreased (0.058422 --> 0.058298).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0481624\n",
      "\tspeed: 0.4772s/iter; left time: 5617.6628s\n",
      "\titers: 200, epoch: 48 | loss: 0.0469702\n",
      "\tspeed: 0.2058s/iter; left time: 2402.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:47.31s\n",
      "Steps: 224 | Train Loss: 0.0494533 Vali Loss: 0.0584296 Test Loss: 0.0636781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0505976\n",
      "\tspeed: 0.4124s/iter; left time: 4763.2895s\n",
      "\titers: 200, epoch: 49 | loss: 0.0514662\n",
      "\tspeed: 0.1918s/iter; left time: 2195.9231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:43.62s\n",
      "Steps: 224 | Train Loss: 0.0494859 Vali Loss: 0.0585631 Test Loss: 0.0637790\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0540853\n",
      "\tspeed: 0.4236s/iter; left time: 4797.3853s\n",
      "\titers: 200, epoch: 50 | loss: 0.0478464\n",
      "\tspeed: 0.1802s/iter; left time: 2022.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:42.82s\n",
      "Steps: 224 | Train Loss: 0.0494602 Vali Loss: 0.0584945 Test Loss: 0.0637686\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0519015\n",
      "\tspeed: 0.4368s/iter; left time: 4848.7110s\n",
      "\titers: 200, epoch: 51 | loss: 0.0465237\n",
      "\tspeed: 0.2148s/iter; left time: 2362.7099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 224 | Train Loss: 0.0495478 Vali Loss: 0.0583360 Test Loss: 0.0635690\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0491508\n",
      "\tspeed: 0.5051s/iter; left time: 5493.9693s\n",
      "\titers: 200, epoch: 52 | loss: 0.0576108\n",
      "\tspeed: 0.1831s/iter; left time: 1973.4958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:46.06s\n",
      "Steps: 224 | Train Loss: 0.0494949 Vali Loss: 0.0583718 Test Loss: 0.0637015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0490683\n",
      "\tspeed: 0.4462s/iter; left time: 4753.4398s\n",
      "\titers: 200, epoch: 53 | loss: 0.0510037\n",
      "\tspeed: 0.2068s/iter; left time: 2182.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:47.24s\n",
      "Steps: 224 | Train Loss: 0.0494326 Vali Loss: 0.0583692 Test Loss: 0.0638704\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0486989\n",
      "\tspeed: 0.4335s/iter; left time: 4521.4452s\n",
      "\titers: 200, epoch: 54 | loss: 0.0475745\n",
      "\tspeed: 0.1717s/iter; left time: 1773.1919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:40.83s\n",
      "Steps: 224 | Train Loss: 0.0494098 Vali Loss: 0.0583060 Test Loss: 0.0636654\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0467159\n",
      "\tspeed: 0.4736s/iter; left time: 4833.0524s\n",
      "\titers: 200, epoch: 55 | loss: 0.0480135\n",
      "\tspeed: 0.1886s/iter; left time: 1905.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 224 | Train Loss: 0.0494484 Vali Loss: 0.0584418 Test Loss: 0.0637180\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0488755\n",
      "\tspeed: 0.4183s/iter; left time: 4174.7010s\n",
      "\titers: 200, epoch: 56 | loss: 0.0469072\n",
      "\tspeed: 0.2029s/iter; left time: 2004.6858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:44.88s\n",
      "Steps: 224 | Train Loss: 0.0493449 Vali Loss: 0.0584621 Test Loss: 0.0637813\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0472983\n",
      "\tspeed: 0.4566s/iter; left time: 4454.9259s\n",
      "\titers: 200, epoch: 57 | loss: 0.0542266\n",
      "\tspeed: 0.1885s/iter; left time: 1820.5345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:43.35s\n",
      "Steps: 224 | Train Loss: 0.0493377 Vali Loss: 0.0584344 Test Loss: 0.0637869\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012042210437357426, rmse:0.10973700881004333, mae:0.06370984017848969, rse:0.4233623445034027\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2933473\n",
      "\tspeed: 0.1898s/iter; left time: 4232.2642s\n",
      "\titers: 200, epoch: 1 | loss: 0.2517735\n",
      "\tspeed: 0.1822s/iter; left time: 4045.4633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.65s\n",
      "Steps: 224 | Train Loss: 0.2929630 Vali Loss: 0.2023631 Test Loss: 0.2044013\n",
      "Validation loss decreased (inf --> 0.202363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1801826\n",
      "\tspeed: 0.4136s/iter; left time: 9131.5050s\n",
      "\titers: 200, epoch: 2 | loss: 0.1349611\n",
      "\tspeed: 0.2065s/iter; left time: 4538.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.15s\n",
      "Steps: 224 | Train Loss: 0.1729048 Vali Loss: 0.1320642 Test Loss: 0.1554732\n",
      "Validation loss decreased (0.202363 --> 0.132064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007261\n",
      "\tspeed: 0.3985s/iter; left time: 8709.5079s\n",
      "\titers: 200, epoch: 3 | loss: 0.0879164\n",
      "\tspeed: 0.1828s/iter; left time: 3976.5925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 224 | Train Loss: 0.1035889 Vali Loss: 0.0913764 Test Loss: 0.1009853\n",
      "Validation loss decreased (0.132064 --> 0.091376).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0795344\n",
      "\tspeed: 0.4238s/iter; left time: 9166.5316s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749387\n",
      "\tspeed: 0.1972s/iter; left time: 4245.3788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.26s\n",
      "Steps: 224 | Train Loss: 0.0810392 Vali Loss: 0.0749335 Test Loss: 0.0809090\n",
      "Validation loss decreased (0.091376 --> 0.074934).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0675564\n",
      "\tspeed: 0.4090s/iter; left time: 8753.8043s\n",
      "\titers: 200, epoch: 5 | loss: 0.0634038\n",
      "\tspeed: 0.2347s/iter; left time: 4999.7879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.94s\n",
      "Steps: 224 | Train Loss: 0.0714958 Vali Loss: 0.0712945 Test Loss: 0.0762415\n",
      "Validation loss decreased (0.074934 --> 0.071295).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0652999\n",
      "\tspeed: 0.4055s/iter; left time: 8588.8592s\n",
      "\titers: 200, epoch: 6 | loss: 0.0641626\n",
      "\tspeed: 0.1947s/iter; left time: 4103.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.85s\n",
      "Steps: 224 | Train Loss: 0.0658761 Vali Loss: 0.0673823 Test Loss: 0.0732708\n",
      "Validation loss decreased (0.071295 --> 0.067382).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0632652\n",
      "\tspeed: 0.3867s/iter; left time: 8103.7075s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620025\n",
      "\tspeed: 0.1964s/iter; left time: 4096.5652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.18s\n",
      "Steps: 224 | Train Loss: 0.0628965 Vali Loss: 0.0650187 Test Loss: 0.0698291\n",
      "Validation loss decreased (0.067382 --> 0.065019).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0645029\n",
      "\tspeed: 0.4426s/iter; left time: 9176.9788s\n",
      "\titers: 200, epoch: 8 | loss: 0.0608486\n",
      "\tspeed: 0.1751s/iter; left time: 3612.9466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.87s\n",
      "Steps: 224 | Train Loss: 0.0611643 Vali Loss: 0.0641744 Test Loss: 0.0685803\n",
      "Validation loss decreased (0.065019 --> 0.064174).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0557670\n",
      "\tspeed: 0.3990s/iter; left time: 8182.3319s\n",
      "\titers: 200, epoch: 9 | loss: 0.0574109\n",
      "\tspeed: 0.1735s/iter; left time: 3540.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 224 | Train Loss: 0.0597023 Vali Loss: 0.0633536 Test Loss: 0.0681139\n",
      "Validation loss decreased (0.064174 --> 0.063354).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0613277\n",
      "\tspeed: 0.4357s/iter; left time: 8839.0136s\n",
      "\titers: 200, epoch: 10 | loss: 0.0571376\n",
      "\tspeed: 0.1766s/iter; left time: 3564.5459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 224 | Train Loss: 0.0592184 Vali Loss: 0.0627687 Test Loss: 0.0678161\n",
      "Validation loss decreased (0.063354 --> 0.062769).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0601034\n",
      "\tspeed: 0.3907s/iter; left time: 7837.6477s\n",
      "\titers: 200, epoch: 11 | loss: 0.0557833\n",
      "\tspeed: 0.1776s/iter; left time: 3545.3415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:43.33s\n",
      "Steps: 224 | Train Loss: 0.0577908 Vali Loss: 0.0631864 Test Loss: 0.0678108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0539125\n",
      "\tspeed: 0.4673s/iter; left time: 9270.4816s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550658\n",
      "\tspeed: 0.1789s/iter; left time: 3530.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:43.25s\n",
      "Steps: 224 | Train Loss: 0.0570311 Vali Loss: 0.0633058 Test Loss: 0.0677815\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0707978\n",
      "\tspeed: 0.4042s/iter; left time: 7927.3391s\n",
      "\titers: 200, epoch: 13 | loss: 0.0557120\n",
      "\tspeed: 0.1809s/iter; left time: 3529.9506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.18s\n",
      "Steps: 224 | Train Loss: 0.0573269 Vali Loss: 0.0625271 Test Loss: 0.0671649\n",
      "Validation loss decreased (0.062769 --> 0.062527).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0631695\n",
      "\tspeed: 0.4045s/iter; left time: 7842.2060s\n",
      "\titers: 200, epoch: 14 | loss: 0.0595798\n",
      "\tspeed: 0.1697s/iter; left time: 3272.8358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:39.99s\n",
      "Steps: 224 | Train Loss: 0.0560766 Vali Loss: 0.0615972 Test Loss: 0.0661349\n",
      "Validation loss decreased (0.062527 --> 0.061597).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0580922\n",
      "\tspeed: 0.3913s/iter; left time: 7499.6065s\n",
      "\titers: 200, epoch: 15 | loss: 0.0533066\n",
      "\tspeed: 0.1775s/iter; left time: 3383.4800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.10s\n",
      "Steps: 224 | Train Loss: 0.0555723 Vali Loss: 0.0631530 Test Loss: 0.0679427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0584847\n",
      "\tspeed: 0.4277s/iter; left time: 8100.9757s\n",
      "\titers: 200, epoch: 16 | loss: 0.0535371\n",
      "\tspeed: 0.2009s/iter; left time: 3784.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:45.90s\n",
      "Steps: 224 | Train Loss: 0.0547458 Vali Loss: 0.0613156 Test Loss: 0.0657339\n",
      "Validation loss decreased (0.061597 --> 0.061316).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0603475\n",
      "\tspeed: 0.4303s/iter; left time: 8053.9523s\n",
      "\titers: 200, epoch: 17 | loss: 0.0584039\n",
      "\tspeed: 0.2012s/iter; left time: 3746.6351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:44.51s\n",
      "Steps: 224 | Train Loss: 0.0549637 Vali Loss: 0.0615999 Test Loss: 0.0662316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0574655\n",
      "\tspeed: 0.4504s/iter; left time: 8329.3496s\n",
      "\titers: 200, epoch: 18 | loss: 0.0531739\n",
      "\tspeed: 0.1810s/iter; left time: 3329.5260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:43.22s\n",
      "Steps: 224 | Train Loss: 0.0543052 Vali Loss: 0.0606388 Test Loss: 0.0655022\n",
      "Validation loss decreased (0.061316 --> 0.060639).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0592601\n",
      "\tspeed: 0.4133s/iter; left time: 7550.0247s\n",
      "\titers: 200, epoch: 19 | loss: 0.0557037\n",
      "\tspeed: 0.2004s/iter; left time: 3640.8401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:44.32s\n",
      "Steps: 224 | Train Loss: 0.0538332 Vali Loss: 0.0604538 Test Loss: 0.0651153\n",
      "Validation loss decreased (0.060639 --> 0.060454).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0498872\n",
      "\tspeed: 0.4050s/iter; left time: 7308.7033s\n",
      "\titers: 200, epoch: 20 | loss: 0.0552771\n",
      "\tspeed: 0.1894s/iter; left time: 3399.4059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:42.05s\n",
      "Steps: 224 | Train Loss: 0.0539296 Vali Loss: 0.0606586 Test Loss: 0.0652723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0537916\n",
      "\tspeed: 0.3990s/iter; left time: 7109.7663s\n",
      "\titers: 200, epoch: 21 | loss: 0.0536685\n",
      "\tspeed: 0.2037s/iter; left time: 3609.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:45.57s\n",
      "Steps: 224 | Train Loss: 0.0535598 Vali Loss: 0.0603527 Test Loss: 0.0649235\n",
      "Validation loss decreased (0.060454 --> 0.060353).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0539150\n",
      "\tspeed: 0.4283s/iter; left time: 7536.4103s\n",
      "\titers: 200, epoch: 22 | loss: 0.0556060\n",
      "\tspeed: 0.2056s/iter; left time: 3597.6601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 224 | Train Loss: 0.0531485 Vali Loss: 0.0601966 Test Loss: 0.0650251\n",
      "Validation loss decreased (0.060353 --> 0.060197).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0528313\n",
      "\tspeed: 0.4279s/iter; left time: 7434.7283s\n",
      "\titers: 200, epoch: 23 | loss: 0.0567675\n",
      "\tspeed: 0.1726s/iter; left time: 2981.9024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:40.94s\n",
      "Steps: 224 | Train Loss: 0.0531289 Vali Loss: 0.0601042 Test Loss: 0.0646801\n",
      "Validation loss decreased (0.060197 --> 0.060104).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0545829\n",
      "\tspeed: 0.4101s/iter; left time: 7032.0991s\n",
      "\titers: 200, epoch: 24 | loss: 0.0562717\n",
      "\tspeed: 0.2042s/iter; left time: 3481.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:44.41s\n",
      "Steps: 224 | Train Loss: 0.0528769 Vali Loss: 0.0599695 Test Loss: 0.0645967\n",
      "Validation loss decreased (0.060104 --> 0.059970).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0492652\n",
      "\tspeed: 0.4566s/iter; left time: 7727.6853s\n",
      "\titers: 200, epoch: 25 | loss: 0.0506045\n",
      "\tspeed: 0.2023s/iter; left time: 3404.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 224 | Train Loss: 0.0527650 Vali Loss: 0.0600911 Test Loss: 0.0647843\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0548348\n",
      "\tspeed: 0.4065s/iter; left time: 6788.7881s\n",
      "\titers: 200, epoch: 26 | loss: 0.0552894\n",
      "\tspeed: 0.1245s/iter; left time: 2066.4358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:32.31s\n",
      "Steps: 224 | Train Loss: 0.0524160 Vali Loss: 0.0597911 Test Loss: 0.0644789\n",
      "Validation loss decreased (0.059970 --> 0.059791).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0530885\n",
      "\tspeed: 0.0916s/iter; left time: 1509.5573s\n",
      "\titers: 200, epoch: 27 | loss: 0.0488368\n",
      "\tspeed: 0.0423s/iter; left time: 693.0160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 224 | Train Loss: 0.0525539 Vali Loss: 0.0598261 Test Loss: 0.0644288\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0494458\n",
      "\tspeed: 0.0756s/iter; left time: 1227.9336s\n",
      "\titers: 200, epoch: 28 | loss: 0.0527309\n",
      "\tspeed: 0.0419s/iter; left time: 676.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0522100 Vali Loss: 0.0598003 Test Loss: 0.0646612\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0510996\n",
      "\tspeed: 0.0857s/iter; left time: 1373.8946s\n",
      "\titers: 200, epoch: 29 | loss: 0.0494976\n",
      "\tspeed: 0.0417s/iter; left time: 663.5569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0522823 Vali Loss: 0.0596074 Test Loss: 0.0642797\n",
      "Validation loss decreased (0.059791 --> 0.059607).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0516432\n",
      "\tspeed: 0.0747s/iter; left time: 1180.9303s\n",
      "\titers: 200, epoch: 30 | loss: 0.0507252\n",
      "\tspeed: 0.0417s/iter; left time: 654.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0521002 Vali Loss: 0.0595522 Test Loss: 0.0643986\n",
      "Validation loss decreased (0.059607 --> 0.059552).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0541912\n",
      "\tspeed: 0.0748s/iter; left time: 1166.0195s\n",
      "\titers: 200, epoch: 31 | loss: 0.0509274\n",
      "\tspeed: 0.0416s/iter; left time: 644.7734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0518280 Vali Loss: 0.0593942 Test Loss: 0.0641329\n",
      "Validation loss decreased (0.059552 --> 0.059394).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0534501\n",
      "\tspeed: 0.0742s/iter; left time: 1138.9082s\n",
      "\titers: 200, epoch: 32 | loss: 0.0561974\n",
      "\tspeed: 0.0416s/iter; left time: 635.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0519500 Vali Loss: 0.0595385 Test Loss: 0.0643136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0501906\n",
      "\tspeed: 0.0961s/iter; left time: 1454.9570s\n",
      "\titers: 200, epoch: 33 | loss: 0.0541711\n",
      "\tspeed: 0.0477s/iter; left time: 716.6731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.22s\n",
      "Steps: 224 | Train Loss: 0.0517857 Vali Loss: 0.0596524 Test Loss: 0.0644904\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0527989\n",
      "\tspeed: 0.1849s/iter; left time: 2757.3265s\n",
      "\titers: 200, epoch: 34 | loss: 0.0503455\n",
      "\tspeed: 0.0416s/iter; left time: 616.7274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:13.21s\n",
      "Steps: 224 | Train Loss: 0.0517596 Vali Loss: 0.0594876 Test Loss: 0.0642313\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0539313\n",
      "\tspeed: 0.1243s/iter; left time: 1825.4247s\n",
      "\titers: 200, epoch: 35 | loss: 0.0493086\n",
      "\tspeed: 0.0754s/iter; left time: 1100.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:18.57s\n",
      "Steps: 224 | Train Loss: 0.0516085 Vali Loss: 0.0596206 Test Loss: 0.0643752\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0513187\n",
      "\tspeed: 0.2016s/iter; left time: 2915.3161s\n",
      "\titers: 200, epoch: 36 | loss: 0.0509694\n",
      "\tspeed: 0.0911s/iter; left time: 1307.7786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:21.26s\n",
      "Steps: 224 | Train Loss: 0.0515385 Vali Loss: 0.0594285 Test Loss: 0.0641411\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0507096\n",
      "\tspeed: 0.0792s/iter; left time: 1127.3531s\n",
      "\titers: 200, epoch: 37 | loss: 0.0538229\n",
      "\tspeed: 0.0417s/iter; left time: 588.8323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:10.62s\n",
      "Steps: 224 | Train Loss: 0.0514933 Vali Loss: 0.0595617 Test Loss: 0.0644006\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0517380\n",
      "\tspeed: 0.2153s/iter; left time: 3016.7216s\n",
      "\titers: 200, epoch: 38 | loss: 0.0536429\n",
      "\tspeed: 0.1101s/iter; left time: 1531.6794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:25.06s\n",
      "Steps: 224 | Train Loss: 0.0515057 Vali Loss: 0.0592238 Test Loss: 0.0641012\n",
      "Validation loss decreased (0.059394 --> 0.059224).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0567034\n",
      "\tspeed: 0.2207s/iter; left time: 3043.5314s\n",
      "\titers: 200, epoch: 39 | loss: 0.0540155\n",
      "\tspeed: 0.0696s/iter; left time: 952.4868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 224 | Train Loss: 0.0513036 Vali Loss: 0.0592987 Test Loss: 0.0639957\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0517767\n",
      "\tspeed: 0.0740s/iter; left time: 1004.2624s\n",
      "\titers: 200, epoch: 40 | loss: 0.0505518\n",
      "\tspeed: 0.0417s/iter; left time: 561.9566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0513119 Vali Loss: 0.0592858 Test Loss: 0.0640597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0500877\n",
      "\tspeed: 0.2107s/iter; left time: 2811.2921s\n",
      "\titers: 200, epoch: 41 | loss: 0.0549211\n",
      "\tspeed: 0.0783s/iter; left time: 1036.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:22.46s\n",
      "Steps: 224 | Train Loss: 0.0513141 Vali Loss: 0.0593257 Test Loss: 0.0640916\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0555865\n",
      "\tspeed: 0.1564s/iter; left time: 2051.3777s\n",
      "\titers: 200, epoch: 42 | loss: 0.0550289\n",
      "\tspeed: 0.1096s/iter; left time: 1426.0545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:21.72s\n",
      "Steps: 224 | Train Loss: 0.0512890 Vali Loss: 0.0592066 Test Loss: 0.0639760\n",
      "Validation loss decreased (0.059224 --> 0.059207).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0550325\n",
      "\tspeed: 0.1904s/iter; left time: 2454.7900s\n",
      "\titers: 200, epoch: 43 | loss: 0.0528899\n",
      "\tspeed: 0.0417s/iter; left time: 533.2867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:12.24s\n",
      "Steps: 224 | Train Loss: 0.0512912 Vali Loss: 0.0593540 Test Loss: 0.0642930\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0512926\n",
      "\tspeed: 0.0738s/iter; left time: 934.8371s\n",
      "\titers: 200, epoch: 44 | loss: 0.0497794\n",
      "\tspeed: 0.0417s/iter; left time: 523.9127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0513882 Vali Loss: 0.0592619 Test Loss: 0.0641506\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0510292\n",
      "\tspeed: 0.1132s/iter; left time: 1408.4245s\n",
      "\titers: 200, epoch: 45 | loss: 0.0534041\n",
      "\tspeed: 0.1042s/iter; left time: 1286.2745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:20.47s\n",
      "Steps: 224 | Train Loss: 0.0513503 Vali Loss: 0.0592136 Test Loss: 0.0641380\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0539803\n",
      "\tspeed: 0.2573s/iter; left time: 3143.9525s\n",
      "\titers: 200, epoch: 46 | loss: 0.0519279\n",
      "\tspeed: 0.1296s/iter; left time: 1570.5114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:30.74s\n",
      "Steps: 224 | Train Loss: 0.0513347 Vali Loss: 0.0592464 Test Loss: 0.0640026\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0520047\n",
      "\tspeed: 0.2449s/iter; left time: 2938.2301s\n",
      "\titers: 200, epoch: 47 | loss: 0.0523824\n",
      "\tspeed: 0.0872s/iter; left time: 1037.8247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:20.84s\n",
      "Steps: 224 | Train Loss: 0.0512515 Vali Loss: 0.0592967 Test Loss: 0.0641128\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0500804\n",
      "\tspeed: 0.1146s/iter; left time: 1349.5622s\n",
      "\titers: 200, epoch: 48 | loss: 0.0506332\n",
      "\tspeed: 0.0417s/iter; left time: 486.8514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0512094 Vali Loss: 0.0591376 Test Loss: 0.0639523\n",
      "Validation loss decreased (0.059207 --> 0.059138).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0484078\n",
      "\tspeed: 0.0745s/iter; left time: 860.0748s\n",
      "\titers: 200, epoch: 49 | loss: 0.0498689\n",
      "\tspeed: 0.0417s/iter; left time: 477.5138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0510413 Vali Loss: 0.0593387 Test Loss: 0.0642556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0497994\n",
      "\tspeed: 0.0892s/iter; left time: 1010.6760s\n",
      "\titers: 200, epoch: 50 | loss: 0.0530633\n",
      "\tspeed: 0.1065s/iter; left time: 1195.0891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:19.60s\n",
      "Steps: 224 | Train Loss: 0.0511456 Vali Loss: 0.0592477 Test Loss: 0.0640090\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0516696\n",
      "\tspeed: 0.2864s/iter; left time: 3179.0777s\n",
      "\titers: 200, epoch: 51 | loss: 0.0513780\n",
      "\tspeed: 0.0884s/iter; left time: 972.5354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 224 | Train Loss: 0.0511384 Vali Loss: 0.0591914 Test Loss: 0.0640956\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0505384\n",
      "\tspeed: 0.1935s/iter; left time: 2105.0003s\n",
      "\titers: 200, epoch: 52 | loss: 0.0517436\n",
      "\tspeed: 0.1274s/iter; left time: 1373.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:26.16s\n",
      "Steps: 224 | Train Loss: 0.0510999 Vali Loss: 0.0591145 Test Loss: 0.0638874\n",
      "Validation loss decreased (0.059138 --> 0.059114).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0495390\n",
      "\tspeed: 0.2764s/iter; left time: 2944.8035s\n",
      "\titers: 200, epoch: 53 | loss: 0.0513844\n",
      "\tspeed: 0.1240s/iter; left time: 1308.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:25.98s\n",
      "Steps: 224 | Train Loss: 0.0510828 Vali Loss: 0.0591081 Test Loss: 0.0639524\n",
      "Validation loss decreased (0.059114 --> 0.059108).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0498141\n",
      "\tspeed: 0.0934s/iter; left time: 973.9070s\n",
      "\titers: 200, epoch: 54 | loss: 0.0533516\n",
      "\tspeed: 0.0417s/iter; left time: 430.4813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0511223 Vali Loss: 0.0592377 Test Loss: 0.0641577\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0535265\n",
      "\tspeed: 0.0741s/iter; left time: 755.8108s\n",
      "\titers: 200, epoch: 55 | loss: 0.0499624\n",
      "\tspeed: 0.0417s/iter; left time: 421.0965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0512137 Vali Loss: 0.0592125 Test Loss: 0.0640222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0491734\n",
      "\tspeed: 0.0743s/iter; left time: 741.8665s\n",
      "\titers: 200, epoch: 56 | loss: 0.0511874\n",
      "\tspeed: 0.0417s/iter; left time: 412.0730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0510958 Vali Loss: 0.0590838 Test Loss: 0.0639271\n",
      "Validation loss decreased (0.059108 --> 0.059084).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0532260\n",
      "\tspeed: 0.2388s/iter; left time: 2330.2895s\n",
      "\titers: 200, epoch: 57 | loss: 0.0526194\n",
      "\tspeed: 0.1333s/iter; left time: 1286.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:27.75s\n",
      "Steps: 224 | Train Loss: 0.0511105 Vali Loss: 0.0591735 Test Loss: 0.0639281\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0538222\n",
      "\tspeed: 0.2442s/iter; left time: 2328.1541s\n",
      "\titers: 200, epoch: 58 | loss: 0.0500002\n",
      "\tspeed: 0.1171s/iter; left time: 1105.0390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:25.76s\n",
      "Steps: 224 | Train Loss: 0.0511195 Vali Loss: 0.0591639 Test Loss: 0.0640076\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0525414\n",
      "\tspeed: 0.2313s/iter; left time: 2153.5781s\n",
      "\titers: 200, epoch: 59 | loss: 0.0489037\n",
      "\tspeed: 0.0802s/iter; left time: 738.3756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:19.19s\n",
      "Steps: 224 | Train Loss: 0.0510503 Vali Loss: 0.0591206 Test Loss: 0.0638685\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0465500\n",
      "\tspeed: 0.1784s/iter; left time: 1620.9891s\n",
      "\titers: 200, epoch: 60 | loss: 0.0511261\n",
      "\tspeed: 0.0845s/iter; left time: 759.5828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:23.14s\n",
      "Steps: 224 | Train Loss: 0.0511120 Vali Loss: 0.0591726 Test Loss: 0.0640554\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0527056\n",
      "\tspeed: 0.1362s/iter; left time: 1206.5603s\n",
      "\titers: 200, epoch: 61 | loss: 0.0480326\n",
      "\tspeed: 0.0417s/iter; left time: 364.9149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:10.27s\n",
      "Steps: 224 | Train Loss: 0.0510372 Vali Loss: 0.0591474 Test Loss: 0.0640253\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0516957\n",
      "\tspeed: 0.0739s/iter; left time: 637.9560s\n",
      "\titers: 200, epoch: 62 | loss: 0.0473931\n",
      "\tspeed: 0.0417s/iter; left time: 355.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0510720 Vali Loss: 0.0592059 Test Loss: 0.0640264\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0489913\n",
      "\tspeed: 0.0741s/iter; left time: 623.4376s\n",
      "\titers: 200, epoch: 63 | loss: 0.0484107\n",
      "\tspeed: 0.0417s/iter; left time: 346.6704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0510801 Vali Loss: 0.0591340 Test Loss: 0.0640175\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0492582\n",
      "\tspeed: 0.0740s/iter; left time: 605.7107s\n",
      "\titers: 200, epoch: 64 | loss: 0.0498149\n",
      "\tspeed: 0.0416s/iter; left time: 336.7818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0511197 Vali Loss: 0.0591524 Test Loss: 0.0640580\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0485964\n",
      "\tspeed: 0.1615s/iter; left time: 1286.2756s\n",
      "\titers: 200, epoch: 65 | loss: 0.0511242\n",
      "\tspeed: 0.0680s/iter; left time: 534.5698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:19.45s\n",
      "Steps: 224 | Train Loss: 0.0512186 Vali Loss: 0.0590871 Test Loss: 0.0638940\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0507133\n",
      "\tspeed: 0.2639s/iter; left time: 2043.2126s\n",
      "\titers: 200, epoch: 66 | loss: 0.0500526\n",
      "\tspeed: 0.1124s/iter; left time: 858.6425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:25.96s\n",
      "Steps: 224 | Train Loss: 0.0511367 Vali Loss: 0.0590489 Test Loss: 0.0638688\n",
      "Validation loss decreased (0.059084 --> 0.059049).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0543191\n",
      "\tspeed: 0.2480s/iter; left time: 1864.1362s\n",
      "\titers: 200, epoch: 67 | loss: 0.0499928\n",
      "\tspeed: 0.1095s/iter; left time: 812.2842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:24.35s\n",
      "Steps: 224 | Train Loss: 0.0511195 Vali Loss: 0.0591323 Test Loss: 0.0640361\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0515359\n",
      "\tspeed: 0.2434s/iter; left time: 1775.1147s\n",
      "\titers: 200, epoch: 68 | loss: 0.0533843\n",
      "\tspeed: 0.1142s/iter; left time: 821.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:25.95s\n",
      "Steps: 224 | Train Loss: 0.0510691 Vali Loss: 0.0591961 Test Loss: 0.0640013\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0524609\n",
      "\tspeed: 0.2514s/iter; left time: 1777.0722s\n",
      "\titers: 200, epoch: 69 | loss: 0.0526743\n",
      "\tspeed: 0.1202s/iter; left time: 837.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:27.21s\n",
      "Steps: 224 | Train Loss: 0.0510440 Vali Loss: 0.0592330 Test Loss: 0.0640318\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0500452\n",
      "\tspeed: 0.1112s/iter; left time: 761.2844s\n",
      "\titers: 200, epoch: 70 | loss: 0.0532179\n",
      "\tspeed: 0.0417s/iter; left time: 281.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0510939 Vali Loss: 0.0591295 Test Loss: 0.0640275\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0513597\n",
      "\tspeed: 0.0737s/iter; left time: 487.9427s\n",
      "\titers: 200, epoch: 71 | loss: 0.0497628\n",
      "\tspeed: 0.0417s/iter; left time: 271.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0511651 Vali Loss: 0.0590576 Test Loss: 0.0639405\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0540537\n",
      "\tspeed: 0.0737s/iter; left time: 471.1899s\n",
      "\titers: 200, epoch: 72 | loss: 0.0496654\n",
      "\tspeed: 0.0417s/iter; left time: 262.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0511559 Vali Loss: 0.0591218 Test Loss: 0.0640488\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0530733\n",
      "\tspeed: 0.0735s/iter; left time: 453.9373s\n",
      "\titers: 200, epoch: 73 | loss: 0.0549077\n",
      "\tspeed: 0.0417s/iter; left time: 253.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0510475 Vali Loss: 0.0593209 Test Loss: 0.0643389\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0506013\n",
      "\tspeed: 0.0739s/iter; left time: 439.3729s\n",
      "\titers: 200, epoch: 74 | loss: 0.0516912\n",
      "\tspeed: 0.0422s/iter; left time: 247.0066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0511532 Vali Loss: 0.0590940 Test Loss: 0.0639356\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0493049\n",
      "\tspeed: 0.2407s/iter; left time: 1378.2779s\n",
      "\titers: 200, epoch: 75 | loss: 0.0532170\n",
      "\tspeed: 0.0893s/iter; left time: 502.2265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:23.07s\n",
      "Steps: 224 | Train Loss: 0.0510975 Vali Loss: 0.0590736 Test Loss: 0.0639730\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0532152\n",
      "\tspeed: 0.2601s/iter; left time: 1430.5528s\n",
      "\titers: 200, epoch: 76 | loss: 0.0511168\n",
      "\tspeed: 0.1069s/iter; left time: 577.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 224 | Train Loss: 0.0510901 Vali Loss: 0.0590307 Test Loss: 0.0638470\n",
      "Validation loss decreased (0.059049 --> 0.059031).  Saving model ...\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0546010\n",
      "\tspeed: 0.2406s/iter; left time: 1269.4647s\n",
      "\titers: 200, epoch: 77 | loss: 0.0508184\n",
      "\tspeed: 0.1091s/iter; left time: 564.9667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:25.08s\n",
      "Steps: 224 | Train Loss: 0.0510807 Vali Loss: 0.0592730 Test Loss: 0.0640740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0528530\n",
      "\tspeed: 0.2505s/iter; left time: 1265.8737s\n",
      "\titers: 200, epoch: 78 | loss: 0.0525099\n",
      "\tspeed: 0.1183s/iter; left time: 585.8517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:26.60s\n",
      "Steps: 224 | Train Loss: 0.0510233 Vali Loss: 0.0591739 Test Loss: 0.0639885\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0510422\n",
      "\tspeed: 0.2733s/iter; left time: 1319.8121s\n",
      "\titers: 200, epoch: 79 | loss: 0.0498171\n",
      "\tspeed: 0.1226s/iter; left time: 579.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:28.57s\n",
      "Steps: 224 | Train Loss: 0.0510219 Vali Loss: 0.0591010 Test Loss: 0.0639886\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0494655\n",
      "\tspeed: 0.2798s/iter; left time: 1288.3060s\n",
      "\titers: 200, epoch: 80 | loss: 0.0511409\n",
      "\tspeed: 0.1229s/iter; left time: 553.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:28.04s\n",
      "Steps: 224 | Train Loss: 0.0510748 Vali Loss: 0.0590027 Test Loss: 0.0639398\n",
      "Validation loss decreased (0.059031 --> 0.059003).  Saving model ...\n",
      "Updating learning rate to 2.996906728784534e-08\n",
      "\titers: 100, epoch: 81 | loss: 0.0492338\n",
      "\tspeed: 0.0901s/iter; left time: 394.6484s\n",
      "\titers: 200, epoch: 81 | loss: 0.0556761\n",
      "\tspeed: 0.0417s/iter; left time: 178.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 81\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0510589 Vali Loss: 0.0591073 Test Loss: 0.0640907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.697216055906081e-08\n",
      "\titers: 100, epoch: 82 | loss: 0.0514840\n",
      "\tspeed: 0.0738s/iter; left time: 306.8269s\n",
      "\titers: 200, epoch: 82 | loss: 0.0507986\n",
      "\tspeed: 0.0416s/iter; left time: 168.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 82\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0510595 Vali Loss: 0.0590954 Test Loss: 0.0639711\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.427494450315473e-08\n",
      "\titers: 100, epoch: 83 | loss: 0.0478585\n",
      "\tspeed: 0.0737s/iter; left time: 289.7827s\n",
      "\titers: 200, epoch: 83 | loss: 0.0519537\n",
      "\tspeed: 0.0417s/iter; left time: 159.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 83\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0510912 Vali Loss: 0.0589478 Test Loss: 0.0638571\n",
      "Validation loss decreased (0.059003 --> 0.058948).  Saving model ...\n",
      "Updating learning rate to 2.1847450052839257e-08\n",
      "\titers: 100, epoch: 84 | loss: 0.0517703\n",
      "\tspeed: 0.0754s/iter; left time: 279.5441s\n",
      "\titers: 200, epoch: 84 | loss: 0.0511455\n",
      "\tspeed: 0.0417s/iter; left time: 150.3179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 84\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0509887 Vali Loss: 0.0591225 Test Loss: 0.0639347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9662705047555332e-08\n",
      "\titers: 100, epoch: 85 | loss: 0.0519673\n",
      "\tspeed: 0.0750s/iter; left time: 261.5429s\n",
      "\titers: 200, epoch: 85 | loss: 0.0509474\n",
      "\tspeed: 0.0421s/iter; left time: 142.3707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 85\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0511205 Vali Loss: 0.0591150 Test Loss: 0.0640081\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.7696434542799797e-08\n",
      "\titers: 100, epoch: 86 | loss: 0.0484817\n",
      "\tspeed: 0.0747s/iter; left time: 243.5101s\n",
      "\titers: 200, epoch: 86 | loss: 0.0520188\n",
      "\tspeed: 0.0416s/iter; left time: 131.6028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 86\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0509900 Vali Loss: 0.0590956 Test Loss: 0.0639777\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5926791088519817e-08\n",
      "\titers: 100, epoch: 87 | loss: 0.0484154\n",
      "\tspeed: 0.2442s/iter; left time: 741.4947s\n",
      "\titers: 200, epoch: 87 | loss: 0.0516866\n",
      "\tspeed: 0.1190s/iter; left time: 349.6059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 87\n",
      "Cost time: 00h:00m:28.48s\n",
      "Steps: 224 | Train Loss: 0.0510122 Vali Loss: 0.0591284 Test Loss: 0.0640107\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4334111979667836e-08\n",
      "\titers: 100, epoch: 88 | loss: 0.0468134\n",
      "\tspeed: 0.2499s/iter; left time: 703.0309s\n",
      "\titers: 200, epoch: 88 | loss: 0.0529882\n",
      "\tspeed: 0.1179s/iter; left time: 319.8306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 88\n",
      "Cost time: 00h:00m:26.56s\n",
      "Steps: 224 | Train Loss: 0.0510190 Vali Loss: 0.0590569 Test Loss: 0.0639346\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2900700781701054e-08\n",
      "\titers: 100, epoch: 89 | loss: 0.0488283\n",
      "\tspeed: 0.2782s/iter; left time: 720.2031s\n",
      "\titers: 200, epoch: 89 | loss: 0.0530808\n",
      "\tspeed: 0.1156s/iter; left time: 287.7930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 89\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 224 | Train Loss: 0.0510235 Vali Loss: 0.0589770 Test Loss: 0.0639253\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.161063070353095e-08\n",
      "\titers: 100, epoch: 90 | loss: 0.0534647\n",
      "\tspeed: 0.2717s/iter; left time: 642.5098s\n",
      "\titers: 200, epoch: 90 | loss: 0.0510958\n",
      "\tspeed: 0.0821s/iter; left time: 186.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 90\n",
      "Cost time: 00h:00m:21.95s\n",
      "Steps: 224 | Train Loss: 0.0509969 Vali Loss: 0.0591477 Test Loss: 0.0639230\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0449567633177854e-08\n",
      "\titers: 100, epoch: 91 | loss: 0.0524147\n",
      "\tspeed: 0.2655s/iter; left time: 568.4614s\n",
      "\titers: 200, epoch: 91 | loss: 0.0529485\n",
      "\tspeed: 0.1320s/iter; left time: 269.4348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 91\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 224 | Train Loss: 0.0510627 Vali Loss: 0.0591924 Test Loss: 0.0640552\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.404610869860069e-09\n",
      "\titers: 100, epoch: 92 | loss: 0.0524008\n",
      "\tspeed: 0.3006s/iter; left time: 576.3030s\n",
      "\titers: 200, epoch: 92 | loss: 0.0529933\n",
      "\tspeed: 0.1328s/iter; left time: 241.3065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 92\n",
      "Cost time: 00h:00m:32.11s\n",
      "Steps: 224 | Train Loss: 0.0509620 Vali Loss: 0.0592307 Test Loss: 0.0640423\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.464149782874063e-09\n",
      "\titers: 100, epoch: 93 | loss: 0.0538015\n",
      "\tspeed: 0.3051s/iter; left time: 516.5951s\n",
      "\titers: 200, epoch: 93 | loss: 0.0542387\n",
      "\tspeed: 0.1352s/iter; left time: 215.3227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 93\n",
      "Cost time: 00h:00m:31.73s\n",
      "Steps: 224 | Train Loss: 0.0511368 Vali Loss: 0.0590666 Test Loss: 0.0639405\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011843698099255562, rmse:0.10882875323295593, mae:0.0638570636510849, rse:0.41985830664634705\n",
      "Intermediate time for FR and pred_len 24: 01h:28m:47.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2785380\n",
      "\tspeed: 0.0638s/iter; left time: 1423.6739s\n",
      "\titers: 200, epoch: 1 | loss: 0.2438505\n",
      "\tspeed: 0.0418s/iter; left time: 928.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 224 | Train Loss: 0.2863792 Vali Loss: 0.2043708 Test Loss: 0.2063307\n",
      "Validation loss decreased (inf --> 0.204371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1634590\n",
      "\tspeed: 0.0762s/iter; left time: 1681.5141s\n",
      "\titers: 200, epoch: 2 | loss: 0.1185003\n",
      "\tspeed: 0.0419s/iter; left time: 921.4024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.1601796 Vali Loss: 0.1280431 Test Loss: 0.1506276\n",
      "Validation loss decreased (0.204371 --> 0.128043).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0959548\n",
      "\tspeed: 0.0763s/iter; left time: 1667.5565s\n",
      "\titers: 200, epoch: 3 | loss: 0.0878113\n",
      "\tspeed: 0.0419s/iter; left time: 911.6686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0984047 Vali Loss: 0.1002913 Test Loss: 0.1147392\n",
      "Validation loss decreased (0.128043 --> 0.100291).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801477\n",
      "\tspeed: 0.0761s/iter; left time: 1646.1536s\n",
      "\titers: 200, epoch: 4 | loss: 0.0765528\n",
      "\tspeed: 0.0419s/iter; left time: 901.7944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0830463 Vali Loss: 0.0903842 Test Loss: 0.1023376\n",
      "Validation loss decreased (0.100291 --> 0.090384).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776027\n",
      "\tspeed: 0.0770s/iter; left time: 1648.5550s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750058\n",
      "\tspeed: 0.0425s/iter; left time: 904.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 224 | Train Loss: 0.0772237 Vali Loss: 0.0867912 Test Loss: 0.0981902\n",
      "Validation loss decreased (0.090384 --> 0.086791).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0749626\n",
      "\tspeed: 0.0775s/iter; left time: 1641.0112s\n",
      "\titers: 200, epoch: 6 | loss: 0.0761939\n",
      "\tspeed: 0.0423s/iter; left time: 892.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 224 | Train Loss: 0.0739349 Vali Loss: 0.0851976 Test Loss: 0.0970451\n",
      "Validation loss decreased (0.086791 --> 0.085198).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0685472\n",
      "\tspeed: 0.0784s/iter; left time: 1642.3709s\n",
      "\titers: 200, epoch: 7 | loss: 0.0687319\n",
      "\tspeed: 0.0561s/iter; left time: 1169.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 224 | Train Loss: 0.0720550 Vali Loss: 0.0830700 Test Loss: 0.0942580\n",
      "Validation loss decreased (0.085198 --> 0.083070).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0709714\n",
      "\tspeed: 0.5242s/iter; left time: 10868.2618s\n",
      "\titers: 200, epoch: 8 | loss: 0.0737696\n",
      "\tspeed: 0.1515s/iter; left time: 3125.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:36.18s\n",
      "Steps: 224 | Train Loss: 0.0704184 Vali Loss: 0.0824060 Test Loss: 0.0944704\n",
      "Validation loss decreased (0.083070 --> 0.082406).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0665019\n",
      "\tspeed: 0.5064s/iter; left time: 10385.0296s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718655\n",
      "\tspeed: 0.1670s/iter; left time: 3407.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:36.81s\n",
      "Steps: 224 | Train Loss: 0.0707386 Vali Loss: 0.0819731 Test Loss: 0.0939734\n",
      "Validation loss decreased (0.082406 --> 0.081973).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0656182\n",
      "\tspeed: 0.4524s/iter; left time: 9176.4401s\n",
      "\titers: 200, epoch: 10 | loss: 0.0714746\n",
      "\tspeed: 0.1526s/iter; left time: 3080.4090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.90s\n",
      "Steps: 224 | Train Loss: 0.0686382 Vali Loss: 0.0823397 Test Loss: 0.0946822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0701325\n",
      "\tspeed: 0.4338s/iter; left time: 8702.0197s\n",
      "\titers: 200, epoch: 11 | loss: 0.0660572\n",
      "\tspeed: 0.1518s/iter; left time: 3030.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.39s\n",
      "Steps: 224 | Train Loss: 0.0680132 Vali Loss: 0.0845559 Test Loss: 0.0969710\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0664862\n",
      "\tspeed: 0.4322s/iter; left time: 8574.4598s\n",
      "\titers: 200, epoch: 12 | loss: 0.0645966\n",
      "\tspeed: 0.0583s/iter; left time: 1150.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:20.75s\n",
      "Steps: 224 | Train Loss: 0.0677685 Vali Loss: 0.0811616 Test Loss: 0.0939580\n",
      "Validation loss decreased (0.081973 --> 0.081162).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0704345\n",
      "\tspeed: 0.0757s/iter; left time: 1485.0616s\n",
      "\titers: 200, epoch: 13 | loss: 0.0629627\n",
      "\tspeed: 0.0419s/iter; left time: 816.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0674960 Vali Loss: 0.0817723 Test Loss: 0.0953847\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0703101\n",
      "\tspeed: 0.0750s/iter; left time: 1454.4957s\n",
      "\titers: 200, epoch: 14 | loss: 0.0671552\n",
      "\tspeed: 0.0418s/iter; left time: 807.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0666561 Vali Loss: 0.0806725 Test Loss: 0.0936615\n",
      "Validation loss decreased (0.081162 --> 0.080673).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0670406\n",
      "\tspeed: 0.0760s/iter; left time: 1456.2463s\n",
      "\titers: 200, epoch: 15 | loss: 0.0652435\n",
      "\tspeed: 0.0418s/iter; left time: 797.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0664780 Vali Loss: 0.0803879 Test Loss: 0.0935760\n",
      "Validation loss decreased (0.080673 --> 0.080388).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0650779\n",
      "\tspeed: 0.0753s/iter; left time: 1427.1492s\n",
      "\titers: 200, epoch: 16 | loss: 0.0652056\n",
      "\tspeed: 0.0418s/iter; left time: 787.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0659695 Vali Loss: 0.0807838 Test Loss: 0.0944766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0661424\n",
      "\tspeed: 0.0748s/iter; left time: 1399.6565s\n",
      "\titers: 200, epoch: 17 | loss: 0.0682761\n",
      "\tspeed: 0.0418s/iter; left time: 778.2712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0658615 Vali Loss: 0.0800553 Test Loss: 0.0930544\n",
      "Validation loss decreased (0.080388 --> 0.080055).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0682063\n",
      "\tspeed: 0.0983s/iter; left time: 1817.8124s\n",
      "\titers: 200, epoch: 18 | loss: 0.0641912\n",
      "\tspeed: 0.0419s/iter; left time: 769.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0656144 Vali Loss: 0.0800278 Test Loss: 0.0932201\n",
      "Validation loss decreased (0.080055 --> 0.080028).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0650383\n",
      "\tspeed: 0.0751s/iter; left time: 1371.3839s\n",
      "\titers: 200, epoch: 19 | loss: 0.0670301\n",
      "\tspeed: 0.0418s/iter; left time: 760.2087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0653203 Vali Loss: 0.0804027 Test Loss: 0.0938009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0650052\n",
      "\tspeed: 0.0743s/iter; left time: 1341.4737s\n",
      "\titers: 200, epoch: 20 | loss: 0.0641293\n",
      "\tspeed: 0.0418s/iter; left time: 750.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0650634 Vali Loss: 0.0804500 Test Loss: 0.0938397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0633472\n",
      "\tspeed: 0.0747s/iter; left time: 1331.0870s\n",
      "\titers: 200, epoch: 21 | loss: 0.0626172\n",
      "\tspeed: 0.0419s/iter; left time: 742.8346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0650295 Vali Loss: 0.0797055 Test Loss: 0.0933753\n",
      "Validation loss decreased (0.080028 --> 0.079706).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0659973\n",
      "\tspeed: 0.1998s/iter; left time: 3515.2081s\n",
      "\titers: 200, epoch: 22 | loss: 0.0645176\n",
      "\tspeed: 0.1667s/iter; left time: 2916.5532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 224 | Train Loss: 0.0648412 Vali Loss: 0.0804262 Test Loss: 0.0935686\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0643545\n",
      "\tspeed: 0.5288s/iter; left time: 9187.3907s\n",
      "\titers: 200, epoch: 23 | loss: 0.0657546\n",
      "\tspeed: 0.1448s/iter; left time: 2501.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:34.71s\n",
      "Steps: 224 | Train Loss: 0.0644434 Vali Loss: 0.0797682 Test Loss: 0.0934020\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0667420\n",
      "\tspeed: 0.4845s/iter; left time: 8309.0895s\n",
      "\titers: 200, epoch: 24 | loss: 0.0632750\n",
      "\tspeed: 0.1885s/iter; left time: 3214.5239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:39.06s\n",
      "Steps: 224 | Train Loss: 0.0642964 Vali Loss: 0.0799125 Test Loss: 0.0934044\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0663899\n",
      "\tspeed: 0.5533s/iter; left time: 9364.0669s\n",
      "\titers: 200, epoch: 25 | loss: 0.0655905\n",
      "\tspeed: 0.1642s/iter; left time: 2762.9852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:38.49s\n",
      "Steps: 224 | Train Loss: 0.0642425 Vali Loss: 0.0795075 Test Loss: 0.0933580\n",
      "Validation loss decreased (0.079706 --> 0.079507).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0608333\n",
      "\tspeed: 0.5573s/iter; left time: 9307.2531s\n",
      "\titers: 200, epoch: 26 | loss: 0.0614710\n",
      "\tspeed: 0.1573s/iter; left time: 2610.6648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 224 | Train Loss: 0.0642664 Vali Loss: 0.0796318 Test Loss: 0.0934958\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0635140\n",
      "\tspeed: 0.5698s/iter; left time: 9389.2339s\n",
      "\titers: 200, epoch: 27 | loss: 0.0656573\n",
      "\tspeed: 0.1770s/iter; left time: 2898.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:40.24s\n",
      "Steps: 224 | Train Loss: 0.0640007 Vali Loss: 0.0793139 Test Loss: 0.0925829\n",
      "Validation loss decreased (0.079507 --> 0.079314).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0633120\n",
      "\tspeed: 0.4121s/iter; left time: 6697.1457s\n",
      "\titers: 200, epoch: 28 | loss: 0.0581166\n",
      "\tspeed: 0.0418s/iter; left time: 675.4829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0639677 Vali Loss: 0.0795294 Test Loss: 0.0930078\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0614765\n",
      "\tspeed: 0.0748s/iter; left time: 1198.8869s\n",
      "\titers: 200, epoch: 29 | loss: 0.0621394\n",
      "\tspeed: 0.0418s/iter; left time: 666.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0638119 Vali Loss: 0.0793790 Test Loss: 0.0933414\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0641990\n",
      "\tspeed: 0.0759s/iter; left time: 1199.1543s\n",
      "\titers: 200, epoch: 30 | loss: 0.0630770\n",
      "\tspeed: 0.0426s/iter; left time: 668.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 224 | Train Loss: 0.0639651 Vali Loss: 0.0792751 Test Loss: 0.0932567\n",
      "Validation loss decreased (0.079314 --> 0.079275).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0597113\n",
      "\tspeed: 0.0762s/iter; left time: 1186.7728s\n",
      "\titers: 200, epoch: 31 | loss: 0.0634587\n",
      "\tspeed: 0.0419s/iter; left time: 648.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0637547 Vali Loss: 0.0795216 Test Loss: 0.0933807\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0643149\n",
      "\tspeed: 0.0746s/iter; left time: 1146.0092s\n",
      "\titers: 200, epoch: 32 | loss: 0.0628956\n",
      "\tspeed: 0.0418s/iter; left time: 638.3173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0636290 Vali Loss: 0.0790046 Test Loss: 0.0923734\n",
      "Validation loss decreased (0.079275 --> 0.079005).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0644692\n",
      "\tspeed: 0.0765s/iter; left time: 1156.9195s\n",
      "\titers: 200, epoch: 33 | loss: 0.0635413\n",
      "\tspeed: 0.0419s/iter; left time: 629.5782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0636522 Vali Loss: 0.0790990 Test Loss: 0.0927422\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0582698\n",
      "\tspeed: 0.0758s/iter; left time: 1129.8615s\n",
      "\titers: 200, epoch: 34 | loss: 0.0597609\n",
      "\tspeed: 0.0419s/iter; left time: 620.4463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0636507 Vali Loss: 0.0791375 Test Loss: 0.0932653\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0627506\n",
      "\tspeed: 0.0754s/iter; left time: 1107.3579s\n",
      "\titers: 200, epoch: 35 | loss: 0.0657120\n",
      "\tspeed: 0.0419s/iter; left time: 610.4528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0634283 Vali Loss: 0.0790597 Test Loss: 0.0927880\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0644230\n",
      "\tspeed: 0.0751s/iter; left time: 1085.6647s\n",
      "\titers: 200, epoch: 36 | loss: 0.0598439\n",
      "\tspeed: 0.0418s/iter; left time: 600.6802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0634662 Vali Loss: 0.0799949 Test Loss: 0.0935473\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0625077\n",
      "\tspeed: 0.0760s/iter; left time: 1082.3172s\n",
      "\titers: 200, epoch: 37 | loss: 0.0677801\n",
      "\tspeed: 0.0418s/iter; left time: 590.2785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0633959 Vali Loss: 0.0790704 Test Loss: 0.0929340\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0667498\n",
      "\tspeed: 0.0750s/iter; left time: 1051.6563s\n",
      "\titers: 200, epoch: 38 | loss: 0.0610832\n",
      "\tspeed: 0.0418s/iter; left time: 582.1869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0633871 Vali Loss: 0.0791227 Test Loss: 0.0931682\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0654644\n",
      "\tspeed: 0.0747s/iter; left time: 1030.3095s\n",
      "\titers: 200, epoch: 39 | loss: 0.0626859\n",
      "\tspeed: 0.1468s/iter; left time: 2010.0272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 224 | Train Loss: 0.0632844 Vali Loss: 0.0790846 Test Loss: 0.0929794\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0616706\n",
      "\tspeed: 0.6134s/iter; left time: 8320.6954s\n",
      "\titers: 200, epoch: 40 | loss: 0.0609713\n",
      "\tspeed: 0.1984s/iter; left time: 2671.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:43.86s\n",
      "Steps: 224 | Train Loss: 0.0633373 Vali Loss: 0.0789445 Test Loss: 0.0929876\n",
      "Validation loss decreased (0.079005 --> 0.078945).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0650316\n",
      "\tspeed: 0.6580s/iter; left time: 8778.9649s\n",
      "\titers: 200, epoch: 41 | loss: 0.0682558\n",
      "\tspeed: 0.2010s/iter; left time: 2660.8505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:44.05s\n",
      "Steps: 224 | Train Loss: 0.0632581 Vali Loss: 0.0792361 Test Loss: 0.0931899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0609731\n",
      "\tspeed: 0.5991s/iter; left time: 7858.4581s\n",
      "\titers: 200, epoch: 42 | loss: 0.0650049\n",
      "\tspeed: 0.1611s/iter; left time: 2097.4239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:39.94s\n",
      "Steps: 224 | Train Loss: 0.0632549 Vali Loss: 0.0789966 Test Loss: 0.0930019\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0621077\n",
      "\tspeed: 0.5985s/iter; left time: 7716.7200s\n",
      "\titers: 200, epoch: 43 | loss: 0.0628854\n",
      "\tspeed: 0.1614s/iter; left time: 2064.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 224 | Train Loss: 0.0633288 Vali Loss: 0.0789689 Test Loss: 0.0929525\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0624934\n",
      "\tspeed: 0.5557s/iter; left time: 7040.2848s\n",
      "\titers: 200, epoch: 44 | loss: 0.0644861\n",
      "\tspeed: 0.1726s/iter; left time: 2168.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:39.48s\n",
      "Steps: 224 | Train Loss: 0.0631652 Vali Loss: 0.0789988 Test Loss: 0.0932605\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0684832\n",
      "\tspeed: 0.5664s/iter; left time: 7048.2510s\n",
      "\titers: 200, epoch: 45 | loss: 0.0618675\n",
      "\tspeed: 0.1721s/iter; left time: 2124.1920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:40.18s\n",
      "Steps: 224 | Train Loss: 0.0632587 Vali Loss: 0.0790012 Test Loss: 0.0928832\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0629681\n",
      "\tspeed: 0.5000s/iter; left time: 6111.1074s\n",
      "\titers: 200, epoch: 46 | loss: 0.0633838\n",
      "\tspeed: 0.1369s/iter; left time: 1659.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 224 | Train Loss: 0.0632321 Vali Loss: 0.0789852 Test Loss: 0.0930597\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0648111\n",
      "\tspeed: 0.0784s/iter; left time: 940.1107s\n",
      "\titers: 200, epoch: 47 | loss: 0.0595840\n",
      "\tspeed: 0.0425s/iter; left time: 505.3005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 224 | Train Loss: 0.0630872 Vali Loss: 0.0789986 Test Loss: 0.0932322\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0617039\n",
      "\tspeed: 0.0765s/iter; left time: 900.2986s\n",
      "\titers: 200, epoch: 48 | loss: 0.0638452\n",
      "\tspeed: 0.0420s/iter; left time: 490.4424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0631533 Vali Loss: 0.0789290 Test Loss: 0.0932044\n",
      "Validation loss decreased (0.078945 --> 0.078929).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0609793\n",
      "\tspeed: 0.0780s/iter; left time: 901.1790s\n",
      "\titers: 200, epoch: 49 | loss: 0.0610199\n",
      "\tspeed: 0.0420s/iter; left time: 480.8675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0631891 Vali Loss: 0.0789642 Test Loss: 0.0929784\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0608738\n",
      "\tspeed: 0.0769s/iter; left time: 870.4881s\n",
      "\titers: 200, epoch: 50 | loss: 0.0621751\n",
      "\tspeed: 0.0425s/iter; left time: 477.2037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 224 | Train Loss: 0.0631609 Vali Loss: 0.0790410 Test Loss: 0.0928521\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0638805\n",
      "\tspeed: 0.0758s/iter; left time: 841.6293s\n",
      "\titers: 200, epoch: 51 | loss: 0.0643284\n",
      "\tspeed: 0.0419s/iter; left time: 460.6454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0630638 Vali Loss: 0.0790290 Test Loss: 0.0928206\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0630477\n",
      "\tspeed: 0.0769s/iter; left time: 836.5905s\n",
      "\titers: 200, epoch: 52 | loss: 0.0641070\n",
      "\tspeed: 0.0420s/iter; left time: 452.3637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0631099 Vali Loss: 0.0789091 Test Loss: 0.0927619\n",
      "Validation loss decreased (0.078929 --> 0.078909).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0669004\n",
      "\tspeed: 0.0776s/iter; left time: 826.5458s\n",
      "\titers: 200, epoch: 53 | loss: 0.0596565\n",
      "\tspeed: 0.0421s/iter; left time: 443.8592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0631420 Vali Loss: 0.0789568 Test Loss: 0.0930475\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0602315\n",
      "\tspeed: 0.0766s/iter; left time: 798.4978s\n",
      "\titers: 200, epoch: 54 | loss: 0.0621255\n",
      "\tspeed: 0.0420s/iter; left time: 433.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0630773 Vali Loss: 0.0789600 Test Loss: 0.0928337\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0617227\n",
      "\tspeed: 0.0751s/iter; left time: 766.9013s\n",
      "\titers: 200, epoch: 55 | loss: 0.0648788\n",
      "\tspeed: 0.0420s/iter; left time: 424.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0630464 Vali Loss: 0.0789093 Test Loss: 0.0928378\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0600466\n",
      "\tspeed: 0.0761s/iter; left time: 759.4443s\n",
      "\titers: 200, epoch: 56 | loss: 0.0646280\n",
      "\tspeed: 0.0420s/iter; left time: 415.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0630426 Vali Loss: 0.0789059 Test Loss: 0.0931741\n",
      "Validation loss decreased (0.078909 --> 0.078906).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0658869\n",
      "\tspeed: 0.0783s/iter; left time: 764.1096s\n",
      "\titers: 200, epoch: 57 | loss: 0.0609886\n",
      "\tspeed: 0.0420s/iter; left time: 405.6281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0630270 Vali Loss: 0.0789534 Test Loss: 0.0928169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0615651\n",
      "\tspeed: 0.0768s/iter; left time: 732.5230s\n",
      "\titers: 200, epoch: 58 | loss: 0.0683493\n",
      "\tspeed: 0.0422s/iter; left time: 397.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0630960 Vali Loss: 0.0789230 Test Loss: 0.0932469\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0620781\n",
      "\tspeed: 0.0763s/iter; left time: 709.8810s\n",
      "\titers: 200, epoch: 59 | loss: 0.0628968\n",
      "\tspeed: 0.0422s/iter; left time: 388.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0630943 Vali Loss: 0.0788920 Test Loss: 0.0928739\n",
      "Validation loss decreased (0.078906 --> 0.078892).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0617018\n",
      "\tspeed: 0.0775s/iter; left time: 704.1477s\n",
      "\titers: 200, epoch: 60 | loss: 0.0675012\n",
      "\tspeed: 0.0423s/iter; left time: 380.4150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0630677 Vali Loss: 0.0788956 Test Loss: 0.0929953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0652720\n",
      "\tspeed: 0.0757s/iter; left time: 670.5820s\n",
      "\titers: 200, epoch: 61 | loss: 0.0644553\n",
      "\tspeed: 0.0424s/iter; left time: 371.2191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 224 | Train Loss: 0.0630442 Vali Loss: 0.0789685 Test Loss: 0.0930535\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0597754\n",
      "\tspeed: 0.0762s/iter; left time: 657.7201s\n",
      "\titers: 200, epoch: 62 | loss: 0.0608089\n",
      "\tspeed: 0.0421s/iter; left time: 359.0084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0630565 Vali Loss: 0.0789922 Test Loss: 0.0928148\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0624134\n",
      "\tspeed: 0.3928s/iter; left time: 3304.5659s\n",
      "\titers: 200, epoch: 63 | loss: 0.0600524\n",
      "\tspeed: 0.1865s/iter; left time: 1550.5388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:40.77s\n",
      "Steps: 224 | Train Loss: 0.0631179 Vali Loss: 0.0789101 Test Loss: 0.0929638\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0618037\n",
      "\tspeed: 0.5524s/iter; left time: 4523.4325s\n",
      "\titers: 200, epoch: 64 | loss: 0.0652177\n",
      "\tspeed: 0.1683s/iter; left time: 1361.5745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:40.22s\n",
      "Steps: 224 | Train Loss: 0.0630719 Vali Loss: 0.0789382 Test Loss: 0.0928304\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0621355\n",
      "\tspeed: 0.5383s/iter; left time: 4287.4311s\n",
      "\titers: 200, epoch: 65 | loss: 0.0645739\n",
      "\tspeed: 0.1668s/iter; left time: 1311.6753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 224 | Train Loss: 0.0630983 Vali Loss: 0.0789015 Test Loss: 0.0927540\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0632698\n",
      "\tspeed: 0.4602s/iter; left time: 3562.6947s\n",
      "\titers: 200, epoch: 66 | loss: 0.0621226\n",
      "\tspeed: 0.1467s/iter; left time: 1120.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:36.15s\n",
      "Steps: 224 | Train Loss: 0.0630500 Vali Loss: 0.0789771 Test Loss: 0.0930219\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0639428\n",
      "\tspeed: 0.4684s/iter; left time: 3521.0725s\n",
      "\titers: 200, epoch: 67 | loss: 0.0628222\n",
      "\tspeed: 0.1434s/iter; left time: 1063.7505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:34.45s\n",
      "Steps: 224 | Train Loss: 0.0630603 Vali Loss: 0.0788703 Test Loss: 0.0928909\n",
      "Validation loss decreased (0.078892 --> 0.078870).  Saving model ...\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0571191\n",
      "\tspeed: 0.4677s/iter; left time: 3411.1231s\n",
      "\titers: 200, epoch: 68 | loss: 0.0630834\n",
      "\tspeed: 0.1646s/iter; left time: 1183.8404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:37.61s\n",
      "Steps: 224 | Train Loss: 0.0630747 Vali Loss: 0.0789868 Test Loss: 0.0931674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0616116\n",
      "\tspeed: 0.3946s/iter; left time: 2789.2272s\n",
      "\titers: 200, epoch: 69 | loss: 0.0637883\n",
      "\tspeed: 0.1656s/iter; left time: 1153.7259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:34.37s\n",
      "Steps: 224 | Train Loss: 0.0630323 Vali Loss: 0.0790034 Test Loss: 0.0928830\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0588588\n",
      "\tspeed: 0.4188s/iter; left time: 2866.6419s\n",
      "\titers: 200, epoch: 70 | loss: 0.0577286\n",
      "\tspeed: 0.1450s/iter; left time: 977.9552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:35.17s\n",
      "Steps: 224 | Train Loss: 0.0629732 Vali Loss: 0.0789365 Test Loss: 0.0931186\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0599831\n",
      "\tspeed: 0.4702s/iter; left time: 3112.9868s\n",
      "\titers: 200, epoch: 71 | loss: 0.0630289\n",
      "\tspeed: 0.1443s/iter; left time: 940.7898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:34.36s\n",
      "Steps: 224 | Train Loss: 0.0629860 Vali Loss: 0.0789220 Test Loss: 0.0928321\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0628952\n",
      "\tspeed: 0.4036s/iter; left time: 2581.5500s\n",
      "\titers: 200, epoch: 72 | loss: 0.0601508\n",
      "\tspeed: 0.1508s/iter; left time: 949.8682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:34.64s\n",
      "Steps: 224 | Train Loss: 0.0629236 Vali Loss: 0.0790278 Test Loss: 0.0931257\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0588616\n",
      "\tspeed: 0.3770s/iter; left time: 2327.0108s\n",
      "\titers: 200, epoch: 73 | loss: 0.0627553\n",
      "\tspeed: 0.0656s/iter; left time: 398.5644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:19.40s\n",
      "Steps: 224 | Train Loss: 0.0631041 Vali Loss: 0.0789813 Test Loss: 0.0932674\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0663354\n",
      "\tspeed: 0.0766s/iter; left time: 455.4684s\n",
      "\titers: 200, epoch: 74 | loss: 0.0612077\n",
      "\tspeed: 0.0422s/iter; left time: 246.5526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0630126 Vali Loss: 0.0789555 Test Loss: 0.0927254\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0659768\n",
      "\tspeed: 0.0768s/iter; left time: 439.8837s\n",
      "\titers: 200, epoch: 75 | loss: 0.0619751\n",
      "\tspeed: 0.0420s/iter; left time: 236.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0630071 Vali Loss: 0.0789748 Test Loss: 0.0928801\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0605391\n",
      "\tspeed: 0.0762s/iter; left time: 419.3570s\n",
      "\titers: 200, epoch: 76 | loss: 0.0680468\n",
      "\tspeed: 0.0419s/iter; left time: 226.4036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0630060 Vali Loss: 0.0789759 Test Loss: 0.0932184\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0675645\n",
      "\tspeed: 0.0760s/iter; left time: 400.8010s\n",
      "\titers: 200, epoch: 77 | loss: 0.0588716\n",
      "\tspeed: 0.0419s/iter; left time: 217.1051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0630600 Vali Loss: 0.0789383 Test Loss: 0.0928094\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02625122480094433, rmse:0.16202229261398315, mae:0.09289092570543289, rse:0.6267452836036682\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2845494\n",
      "\tspeed: 0.0438s/iter; left time: 976.3353s\n",
      "\titers: 200, epoch: 1 | loss: 0.2515332\n",
      "\tspeed: 0.0419s/iter; left time: 930.9662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.2899645 Vali Loss: 0.2018218 Test Loss: 0.2044672\n",
      "Validation loss decreased (inf --> 0.201822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1569842\n",
      "\tspeed: 0.0764s/iter; left time: 1687.1769s\n",
      "\titers: 200, epoch: 2 | loss: 0.1271602\n",
      "\tspeed: 0.0420s/iter; left time: 923.3376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.1585166 Vali Loss: 0.1369186 Test Loss: 0.1609530\n",
      "Validation loss decreased (0.201822 --> 0.136919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1052520\n",
      "\tspeed: 0.0768s/iter; left time: 1678.8764s\n",
      "\titers: 200, epoch: 3 | loss: 0.0934173\n",
      "\tspeed: 0.0423s/iter; left time: 920.3939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.1058298 Vali Loss: 0.1071875 Test Loss: 0.1235044\n",
      "Validation loss decreased (0.136919 --> 0.107187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0846484\n",
      "\tspeed: 0.0770s/iter; left time: 1665.8269s\n",
      "\titers: 200, epoch: 4 | loss: 0.0857118\n",
      "\tspeed: 0.0423s/iter; left time: 910.8570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0853149 Vali Loss: 0.0975358 Test Loss: 0.1117983\n",
      "Validation loss decreased (0.107187 --> 0.097536).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0798377\n",
      "\tspeed: 0.0762s/iter; left time: 1631.8045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0796242\n",
      "\tspeed: 0.0420s/iter; left time: 894.3774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0774607 Vali Loss: 0.0924072 Test Loss: 0.1069786\n",
      "Validation loss decreased (0.097536 --> 0.092407).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730040\n",
      "\tspeed: 0.0769s/iter; left time: 1628.5667s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736011\n",
      "\tspeed: 0.0420s/iter; left time: 885.3845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0739611 Vali Loss: 0.0921916 Test Loss: 0.1062103\n",
      "Validation loss decreased (0.092407 --> 0.092192).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0661268\n",
      "\tspeed: 0.0764s/iter; left time: 1601.4347s\n",
      "\titers: 200, epoch: 7 | loss: 0.0722003\n",
      "\tspeed: 0.0420s/iter; left time: 875.9216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0725923 Vali Loss: 0.0871613 Test Loss: 0.1019333\n",
      "Validation loss decreased (0.092192 --> 0.087161).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0722545\n",
      "\tspeed: 0.0767s/iter; left time: 1591.1455s\n",
      "\titers: 200, epoch: 8 | loss: 0.0696333\n",
      "\tspeed: 0.0419s/iter; left time: 865.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0707744 Vali Loss: 0.0889532 Test Loss: 0.1042534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0701538\n",
      "\tspeed: 0.0761s/iter; left time: 1560.5031s\n",
      "\titers: 200, epoch: 9 | loss: 0.0695688\n",
      "\tspeed: 0.0420s/iter; left time: 857.1390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0697226 Vali Loss: 0.0845768 Test Loss: 0.0992957\n",
      "Validation loss decreased (0.087161 --> 0.084577).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0724357\n",
      "\tspeed: 0.0765s/iter; left time: 1551.5956s\n",
      "\titers: 200, epoch: 10 | loss: 0.0677047\n",
      "\tspeed: 0.0420s/iter; left time: 847.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0687021 Vali Loss: 0.0844887 Test Loss: 0.0988666\n",
      "Validation loss decreased (0.084577 --> 0.084489).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642779\n",
      "\tspeed: 0.0763s/iter; left time: 1529.7838s\n",
      "\titers: 200, epoch: 11 | loss: 0.0720053\n",
      "\tspeed: 0.0419s/iter; left time: 837.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0679375 Vali Loss: 0.0855586 Test Loss: 0.1007391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0653119\n",
      "\tspeed: 0.0759s/iter; left time: 1505.8239s\n",
      "\titers: 200, epoch: 12 | loss: 0.0671105\n",
      "\tspeed: 0.0423s/iter; left time: 835.6056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0676362 Vali Loss: 0.0839147 Test Loss: 0.0988455\n",
      "Validation loss decreased (0.084489 --> 0.083915).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0629413\n",
      "\tspeed: 0.1319s/iter; left time: 2586.4007s\n",
      "\titers: 200, epoch: 13 | loss: 0.0684093\n",
      "\tspeed: 0.1426s/iter; left time: 2781.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.12s\n",
      "Steps: 224 | Train Loss: 0.0676487 Vali Loss: 0.0838420 Test Loss: 0.0987272\n",
      "Validation loss decreased (0.083915 --> 0.083842).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689519\n",
      "\tspeed: 0.4062s/iter; left time: 7875.1737s\n",
      "\titers: 200, epoch: 14 | loss: 0.0624177\n",
      "\tspeed: 0.1368s/iter; left time: 2638.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:30.54s\n",
      "Steps: 224 | Train Loss: 0.0663525 Vali Loss: 0.0842641 Test Loss: 0.0989582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0657323\n",
      "\tspeed: 0.3815s/iter; left time: 7310.6391s\n",
      "\titers: 200, epoch: 15 | loss: 0.0692649\n",
      "\tspeed: 0.1549s/iter; left time: 2952.8914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:34.22s\n",
      "Steps: 224 | Train Loss: 0.0662114 Vali Loss: 0.0844805 Test Loss: 0.0991221\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0730609\n",
      "\tspeed: 0.3729s/iter; left time: 7063.2146s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633044\n",
      "\tspeed: 0.1376s/iter; left time: 2592.2835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 224 | Train Loss: 0.0662310 Vali Loss: 0.0839134 Test Loss: 0.0986774\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0635985\n",
      "\tspeed: 0.3882s/iter; left time: 7266.1517s\n",
      "\titers: 200, epoch: 17 | loss: 0.0644041\n",
      "\tspeed: 0.1384s/iter; left time: 2576.6769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:30.64s\n",
      "Steps: 224 | Train Loss: 0.0656802 Vali Loss: 0.0830043 Test Loss: 0.0974622\n",
      "Validation loss decreased (0.083842 --> 0.083004).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0631628\n",
      "\tspeed: 0.3549s/iter; left time: 6562.7614s\n",
      "\titers: 200, epoch: 18 | loss: 0.0648742\n",
      "\tspeed: 0.1571s/iter; left time: 2890.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:33.29s\n",
      "Steps: 224 | Train Loss: 0.0651817 Vali Loss: 0.0825143 Test Loss: 0.0971201\n",
      "Validation loss decreased (0.083004 --> 0.082514).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0634684\n",
      "\tspeed: 0.4282s/iter; left time: 7822.0692s\n",
      "\titers: 200, epoch: 19 | loss: 0.0669521\n",
      "\tspeed: 0.1527s/iter; left time: 2773.5220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:36.51s\n",
      "Steps: 224 | Train Loss: 0.0651133 Vali Loss: 0.0815570 Test Loss: 0.0961889\n",
      "Validation loss decreased (0.082514 --> 0.081557).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0653302\n",
      "\tspeed: 0.4736s/iter; left time: 8546.6596s\n",
      "\titers: 200, epoch: 20 | loss: 0.0643898\n",
      "\tspeed: 0.1624s/iter; left time: 2914.1524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:35.82s\n",
      "Steps: 224 | Train Loss: 0.0663717 Vali Loss: 0.0838726 Test Loss: 0.0985533\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0673339\n",
      "\tspeed: 0.4754s/iter; left time: 8471.7429s\n",
      "\titers: 200, epoch: 21 | loss: 0.0643994\n",
      "\tspeed: 0.1672s/iter; left time: 2962.9427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:36.52s\n",
      "Steps: 224 | Train Loss: 0.0649173 Vali Loss: 0.0831560 Test Loss: 0.0979416\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0662313\n",
      "\tspeed: 0.4268s/iter; left time: 7510.0589s\n",
      "\titers: 200, epoch: 22 | loss: 0.0669869\n",
      "\tspeed: 0.1381s/iter; left time: 2415.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:32.56s\n",
      "Steps: 224 | Train Loss: 0.0646145 Vali Loss: 0.0830209 Test Loss: 0.0977372\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0607866\n",
      "\tspeed: 0.4542s/iter; left time: 7891.4307s\n",
      "\titers: 200, epoch: 23 | loss: 0.0679601\n",
      "\tspeed: 0.1556s/iter; left time: 2687.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:35.86s\n",
      "Steps: 224 | Train Loss: 0.0646694 Vali Loss: 0.0834833 Test Loss: 0.0983098\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0628281\n",
      "\tspeed: 0.4141s/iter; left time: 7100.9577s\n",
      "\titers: 200, epoch: 24 | loss: 0.0634609\n",
      "\tspeed: 0.1551s/iter; left time: 2645.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:33.86s\n",
      "Steps: 224 | Train Loss: 0.0644849 Vali Loss: 0.0822763 Test Loss: 0.0970377\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0655281\n",
      "\tspeed: 0.4531s/iter; left time: 7668.4236s\n",
      "\titers: 200, epoch: 25 | loss: 0.0604132\n",
      "\tspeed: 0.1516s/iter; left time: 2550.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:34.46s\n",
      "Steps: 224 | Train Loss: 0.0642798 Vali Loss: 0.0819565 Test Loss: 0.0963529\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0603797\n",
      "\tspeed: 0.2776s/iter; left time: 4635.3799s\n",
      "\titers: 200, epoch: 26 | loss: 0.0655584\n",
      "\tspeed: 0.0419s/iter; left time: 696.0300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0642384 Vali Loss: 0.0817743 Test Loss: 0.0962923\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0645313\n",
      "\tspeed: 0.0757s/iter; left time: 1247.4751s\n",
      "\titers: 200, epoch: 27 | loss: 0.0651646\n",
      "\tspeed: 0.0419s/iter; left time: 686.3291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0642643 Vali Loss: 0.0822567 Test Loss: 0.0968923\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0612690\n",
      "\tspeed: 0.0758s/iter; left time: 1231.9881s\n",
      "\titers: 200, epoch: 28 | loss: 0.0668315\n",
      "\tspeed: 0.0420s/iter; left time: 677.6786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0640586 Vali Loss: 0.0822472 Test Loss: 0.0968043\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0637272\n",
      "\tspeed: 0.0754s/iter; left time: 1207.9611s\n",
      "\titers: 200, epoch: 29 | loss: 0.0634250\n",
      "\tspeed: 0.0419s/iter; left time: 667.1177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0639551 Vali Loss: 0.0821071 Test Loss: 0.0966107\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.026170752942562103, rmse:0.16177377104759216, mae:0.09618891030550003, rse:0.6257839202880859\n",
      "Intermediate time for FR and pred_len 96: 00h:57m:09.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2891012\n",
      "\tspeed: 0.0598s/iter; left time: 1328.0210s\n",
      "\titers: 200, epoch: 1 | loss: 0.2479672\n",
      "\tspeed: 0.0424s/iter; left time: 936.3504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 223 | Train Loss: 0.2937163 Vali Loss: 0.2023989 Test Loss: 0.2035932\n",
      "Validation loss decreased (inf --> 0.202399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1531174\n",
      "\tspeed: 0.0762s/iter; left time: 1673.6525s\n",
      "\titers: 200, epoch: 2 | loss: 0.1154135\n",
      "\tspeed: 0.0424s/iter; left time: 927.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.1552813 Vali Loss: 0.1212952 Test Loss: 0.1412372\n",
      "Validation loss decreased (0.202399 --> 0.121295).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0972536\n",
      "\tspeed: 0.0763s/iter; left time: 1659.2693s\n",
      "\titers: 200, epoch: 3 | loss: 0.0872820\n",
      "\tspeed: 0.0423s/iter; left time: 915.9547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0967903 Vali Loss: 0.0996024 Test Loss: 0.1146979\n",
      "Validation loss decreased (0.121295 --> 0.099602).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0840371\n",
      "\tspeed: 0.0771s/iter; left time: 1659.9547s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806364\n",
      "\tspeed: 0.0425s/iter; left time: 909.8920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0834953 Vali Loss: 0.0952818 Test Loss: 0.1083529\n",
      "Validation loss decreased (0.099602 --> 0.095282).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0839048\n",
      "\tspeed: 0.0778s/iter; left time: 1657.3652s\n",
      "\titers: 200, epoch: 5 | loss: 0.0804710\n",
      "\tspeed: 0.0423s/iter; left time: 897.3833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0794209 Vali Loss: 0.0909963 Test Loss: 0.1049566\n",
      "Validation loss decreased (0.095282 --> 0.090996).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0776387\n",
      "\tspeed: 0.0761s/iter; left time: 1604.6161s\n",
      "\titers: 200, epoch: 6 | loss: 0.0722568\n",
      "\tspeed: 0.0423s/iter; left time: 888.2556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 223 | Train Loss: 0.0764063 Vali Loss: 0.0900245 Test Loss: 0.1048404\n",
      "Validation loss decreased (0.090996 --> 0.090025).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0699515\n",
      "\tspeed: 0.0774s/iter; left time: 1615.5811s\n",
      "\titers: 200, epoch: 7 | loss: 0.0738886\n",
      "\tspeed: 0.0423s/iter; left time: 879.0879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0748134 Vali Loss: 0.0888954 Test Loss: 0.1040644\n",
      "Validation loss decreased (0.090025 --> 0.088895).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749131\n",
      "\tspeed: 0.0761s/iter; left time: 1570.3506s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728233\n",
      "\tspeed: 0.0423s/iter; left time: 869.3339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0736474 Vali Loss: 0.0890404 Test Loss: 0.1031678\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0784748\n",
      "\tspeed: 0.0756s/iter; left time: 1544.1108s\n",
      "\titers: 200, epoch: 9 | loss: 0.0724108\n",
      "\tspeed: 0.0424s/iter; left time: 860.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 223 | Train Loss: 0.0727466 Vali Loss: 0.0905571 Test Loss: 0.1067179\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0670860\n",
      "\tspeed: 0.0752s/iter; left time: 1519.3180s\n",
      "\titers: 200, epoch: 10 | loss: 0.0717777\n",
      "\tspeed: 0.0425s/iter; left time: 853.9432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 223 | Train Loss: 0.0721090 Vali Loss: 0.0889585 Test Loss: 0.1062376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0709042\n",
      "\tspeed: 0.0754s/iter; left time: 1505.5882s\n",
      "\titers: 200, epoch: 11 | loss: 0.0748976\n",
      "\tspeed: 0.0434s/iter; left time: 863.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0714268 Vali Loss: 0.0874368 Test Loss: 0.1041026\n",
      "Validation loss decreased (0.088895 --> 0.087437).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0688976\n",
      "\tspeed: 0.0774s/iter; left time: 1528.5360s\n",
      "\titers: 200, epoch: 12 | loss: 0.0735624\n",
      "\tspeed: 0.0424s/iter; left time: 832.5611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0707678 Vali Loss: 0.0876229 Test Loss: 0.1043460\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0706713\n",
      "\tspeed: 0.0765s/iter; left time: 1493.5150s\n",
      "\titers: 200, epoch: 13 | loss: 0.0674837\n",
      "\tspeed: 0.0423s/iter; left time: 822.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0704175 Vali Loss: 0.0872320 Test Loss: 0.1038151\n",
      "Validation loss decreased (0.087437 --> 0.087232).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0678241\n",
      "\tspeed: 0.0762s/iter; left time: 1470.9561s\n",
      "\titers: 200, epoch: 14 | loss: 0.0723473\n",
      "\tspeed: 0.0424s/iter; left time: 814.3759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 223 | Train Loss: 0.0701870 Vali Loss: 0.0877375 Test Loss: 0.1052995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0681348\n",
      "\tspeed: 0.0749s/iter; left time: 1428.8177s\n",
      "\titers: 200, epoch: 15 | loss: 0.0679457\n",
      "\tspeed: 0.0425s/iter; left time: 805.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0697102 Vali Loss: 0.0898765 Test Loss: 0.1073388\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0678202\n",
      "\tspeed: 0.0754s/iter; left time: 1421.4108s\n",
      "\titers: 200, epoch: 16 | loss: 0.0727796\n",
      "\tspeed: 0.0422s/iter; left time: 792.3960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0696029 Vali Loss: 0.0866433 Test Loss: 0.1039286\n",
      "Validation loss decreased (0.087232 --> 0.086643).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0660874\n",
      "\tspeed: 0.0770s/iter; left time: 1434.3072s\n",
      "\titers: 200, epoch: 17 | loss: 0.0659480\n",
      "\tspeed: 0.0423s/iter; left time: 783.3349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0688840 Vali Loss: 0.0866731 Test Loss: 0.1046079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0679716\n",
      "\tspeed: 0.0753s/iter; left time: 1386.3824s\n",
      "\titers: 200, epoch: 18 | loss: 0.0686383\n",
      "\tspeed: 0.0425s/iter; left time: 777.2962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0687001 Vali Loss: 0.0866199 Test Loss: 0.1050284\n",
      "Validation loss decreased (0.086643 --> 0.086620).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0678474\n",
      "\tspeed: 0.0758s/iter; left time: 1378.2973s\n",
      "\titers: 200, epoch: 19 | loss: 0.0649718\n",
      "\tspeed: 0.0423s/iter; left time: 764.9912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 223 | Train Loss: 0.0684154 Vali Loss: 0.0866094 Test Loss: 0.1044375\n",
      "Validation loss decreased (0.086620 --> 0.086609).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0688738\n",
      "\tspeed: 0.0758s/iter; left time: 1361.9382s\n",
      "\titers: 200, epoch: 20 | loss: 0.0691909\n",
      "\tspeed: 0.0423s/iter; left time: 754.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0681373 Vali Loss: 0.0872521 Test Loss: 0.1054630\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0732692\n",
      "\tspeed: 0.0745s/iter; left time: 1321.6251s\n",
      "\titers: 200, epoch: 21 | loss: 0.0660727\n",
      "\tspeed: 0.0704s/iter; left time: 1241.5600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.25s\n",
      "Steps: 223 | Train Loss: 0.0679729 Vali Loss: 0.0869237 Test Loss: 0.1050174\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0686969\n",
      "\tspeed: 0.4144s/iter; left time: 7258.9797s\n",
      "\titers: 200, epoch: 22 | loss: 0.0715697\n",
      "\tspeed: 0.1323s/iter; left time: 2304.9688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:30.94s\n",
      "Steps: 223 | Train Loss: 0.0677472 Vali Loss: 0.0869204 Test Loss: 0.1052202\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0646252\n",
      "\tspeed: 0.3996s/iter; left time: 6910.4045s\n",
      "\titers: 200, epoch: 23 | loss: 0.0674202\n",
      "\tspeed: 0.1554s/iter; left time: 2671.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:33.71s\n",
      "Steps: 223 | Train Loss: 0.0675562 Vali Loss: 0.0864254 Test Loss: 0.1049217\n",
      "Validation loss decreased (0.086609 --> 0.086425).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0697529\n",
      "\tspeed: 0.4230s/iter; left time: 7220.9939s\n",
      "\titers: 200, epoch: 24 | loss: 0.0642757\n",
      "\tspeed: 0.1580s/iter; left time: 2682.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:33.75s\n",
      "Steps: 223 | Train Loss: 0.0675126 Vali Loss: 0.0862039 Test Loss: 0.1045620\n",
      "Validation loss decreased (0.086425 --> 0.086204).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0662682\n",
      "\tspeed: 0.3934s/iter; left time: 6628.3691s\n",
      "\titers: 200, epoch: 25 | loss: 0.0697864\n",
      "\tspeed: 0.1393s/iter; left time: 2333.1667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:31.23s\n",
      "Steps: 223 | Train Loss: 0.0674486 Vali Loss: 0.0861740 Test Loss: 0.1042963\n",
      "Validation loss decreased (0.086204 --> 0.086174).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0699408\n",
      "\tspeed: 0.4105s/iter; left time: 6825.0426s\n",
      "\titers: 200, epoch: 26 | loss: 0.0647758\n",
      "\tspeed: 0.1406s/iter; left time: 2323.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:33.25s\n",
      "Steps: 223 | Train Loss: 0.0678501 Vali Loss: 0.0872798 Test Loss: 0.1054474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0684276\n",
      "\tspeed: 0.3854s/iter; left time: 6321.3224s\n",
      "\titers: 200, epoch: 27 | loss: 0.0666208\n",
      "\tspeed: 0.1280s/iter; left time: 2086.1285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:30.80s\n",
      "Steps: 223 | Train Loss: 0.0673611 Vali Loss: 0.0871673 Test Loss: 0.1056729\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0698926\n",
      "\tspeed: 0.3778s/iter; left time: 6113.1440s\n",
      "\titers: 200, epoch: 28 | loss: 0.0647745\n",
      "\tspeed: 0.1349s/iter; left time: 2168.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:30.18s\n",
      "Steps: 223 | Train Loss: 0.0672058 Vali Loss: 0.0864746 Test Loss: 0.1050593\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0650351\n",
      "\tspeed: 0.3731s/iter; left time: 5954.2696s\n",
      "\titers: 200, epoch: 29 | loss: 0.0630869\n",
      "\tspeed: 0.1291s/iter; left time: 2047.1750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 223 | Train Loss: 0.0670882 Vali Loss: 0.0865399 Test Loss: 0.1051718\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0697693\n",
      "\tspeed: 0.3845s/iter; left time: 6049.6614s\n",
      "\titers: 200, epoch: 30 | loss: 0.0703529\n",
      "\tspeed: 0.1247s/iter; left time: 1950.1509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:31.26s\n",
      "Steps: 223 | Train Loss: 0.0670739 Vali Loss: 0.0865641 Test Loss: 0.1050234\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0675831\n",
      "\tspeed: 0.3857s/iter; left time: 5982.4276s\n",
      "\titers: 200, epoch: 31 | loss: 0.0656035\n",
      "\tspeed: 0.1383s/iter; left time: 2131.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:33.28s\n",
      "Steps: 223 | Train Loss: 0.0667800 Vali Loss: 0.0859759 Test Loss: 0.1047636\n",
      "Validation loss decreased (0.086174 --> 0.085976).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0677801\n",
      "\tspeed: 0.3706s/iter; left time: 5666.4051s\n",
      "\titers: 200, epoch: 32 | loss: 0.0784659\n",
      "\tspeed: 0.1204s/iter; left time: 1828.1769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:30.95s\n",
      "Steps: 223 | Train Loss: 0.0669325 Vali Loss: 0.0866903 Test Loss: 0.1055695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0650436\n",
      "\tspeed: 0.4525s/iter; left time: 6817.5841s\n",
      "\titers: 200, epoch: 33 | loss: 0.0672974\n",
      "\tspeed: 0.1620s/iter; left time: 2424.0426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:36.52s\n",
      "Steps: 223 | Train Loss: 0.0669047 Vali Loss: 0.0865528 Test Loss: 0.1051391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0667239\n",
      "\tspeed: 0.4822s/iter; left time: 7156.4773s\n",
      "\titers: 200, epoch: 34 | loss: 0.0632527\n",
      "\tspeed: 0.1658s/iter; left time: 2443.8249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 223 | Train Loss: 0.0667610 Vali Loss: 0.0865676 Test Loss: 0.1050450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0672861\n",
      "\tspeed: 0.4935s/iter; left time: 7214.6384s\n",
      "\titers: 200, epoch: 35 | loss: 0.0681471\n",
      "\tspeed: 0.1678s/iter; left time: 2436.1224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:37.48s\n",
      "Steps: 223 | Train Loss: 0.0667749 Vali Loss: 0.0862838 Test Loss: 0.1050298\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0666826\n",
      "\tspeed: 0.4798s/iter; left time: 6907.6570s\n",
      "\titers: 200, epoch: 36 | loss: 0.0645803\n",
      "\tspeed: 0.1637s/iter; left time: 2340.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:36.96s\n",
      "Steps: 223 | Train Loss: 0.0665924 Vali Loss: 0.0858469 Test Loss: 0.1047405\n",
      "Validation loss decreased (0.085976 --> 0.085847).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0676375\n",
      "\tspeed: 0.2726s/iter; left time: 3863.4169s\n",
      "\titers: 200, epoch: 37 | loss: 0.0688319\n",
      "\tspeed: 0.0424s/iter; left time: 596.1270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0666901 Vali Loss: 0.0860729 Test Loss: 0.1048188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0674546\n",
      "\tspeed: 0.0746s/iter; left time: 1040.9594s\n",
      "\titers: 200, epoch: 38 | loss: 0.0687214\n",
      "\tspeed: 0.0421s/iter; left time: 583.4391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0666443 Vali Loss: 0.0862865 Test Loss: 0.1049131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0685240\n",
      "\tspeed: 0.0745s/iter; left time: 1023.2765s\n",
      "\titers: 200, epoch: 39 | loss: 0.0644329\n",
      "\tspeed: 0.0422s/iter; left time: 574.6637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0665832 Vali Loss: 0.0860131 Test Loss: 0.1047742\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0659139\n",
      "\tspeed: 0.0745s/iter; left time: 1006.5139s\n",
      "\titers: 200, epoch: 40 | loss: 0.0651233\n",
      "\tspeed: 0.0422s/iter; left time: 565.1893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0665743 Vali Loss: 0.0860929 Test Loss: 0.1044649\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0723175\n",
      "\tspeed: 0.0739s/iter; left time: 980.8662s\n",
      "\titers: 200, epoch: 41 | loss: 0.0675524\n",
      "\tspeed: 0.0421s/iter; left time: 555.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0664646 Vali Loss: 0.0859663 Test Loss: 0.1044729\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0684293\n",
      "\tspeed: 0.0753s/iter; left time: 983.0563s\n",
      "\titers: 200, epoch: 42 | loss: 0.0637561\n",
      "\tspeed: 0.0423s/iter; left time: 547.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0665393 Vali Loss: 0.0860530 Test Loss: 0.1052073\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0674790\n",
      "\tspeed: 0.0750s/iter; left time: 962.8343s\n",
      "\titers: 200, epoch: 43 | loss: 0.0666185\n",
      "\tspeed: 0.0423s/iter; left time: 538.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0665143 Vali Loss: 0.0858357 Test Loss: 0.1046557\n",
      "Validation loss decreased (0.085847 --> 0.085836).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0651106\n",
      "\tspeed: 0.0758s/iter; left time: 955.3599s\n",
      "\titers: 200, epoch: 44 | loss: 0.0690341\n",
      "\tspeed: 0.0422s/iter; left time: 527.7036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0663940 Vali Loss: 0.0859474 Test Loss: 0.1046102\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0668602\n",
      "\tspeed: 0.0745s/iter; left time: 923.0263s\n",
      "\titers: 200, epoch: 45 | loss: 0.0693783\n",
      "\tspeed: 0.0422s/iter; left time: 518.1358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0665222 Vali Loss: 0.0859476 Test Loss: 0.1048393\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0638679\n",
      "\tspeed: 0.0746s/iter; left time: 907.3889s\n",
      "\titers: 200, epoch: 46 | loss: 0.0686687\n",
      "\tspeed: 0.0422s/iter; left time: 509.0725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0664938 Vali Loss: 0.0860606 Test Loss: 0.1045544\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0665852\n",
      "\tspeed: 0.0759s/iter; left time: 906.1223s\n",
      "\titers: 200, epoch: 47 | loss: 0.0639723\n",
      "\tspeed: 0.0422s/iter; left time: 499.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 223 | Train Loss: 0.0665483 Vali Loss: 0.0859672 Test Loss: 0.1047814\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0667988\n",
      "\tspeed: 0.0750s/iter; left time: 878.5697s\n",
      "\titers: 200, epoch: 48 | loss: 0.0676787\n",
      "\tspeed: 0.0422s/iter; left time: 490.6266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 223 | Train Loss: 0.0664204 Vali Loss: 0.0860267 Test Loss: 0.1047460\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0638899\n",
      "\tspeed: 0.0755s/iter; left time: 868.4253s\n",
      "\titers: 200, epoch: 49 | loss: 0.0662672\n",
      "\tspeed: 0.0422s/iter; left time: 481.0867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0662952 Vali Loss: 0.0860566 Test Loss: 0.1045868\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0662047\n",
      "\tspeed: 0.0751s/iter; left time: 846.6492s\n",
      "\titers: 200, epoch: 50 | loss: 0.0688732\n",
      "\tspeed: 0.0421s/iter; left time: 470.5092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0664094 Vali Loss: 0.0859878 Test Loss: 0.1047474\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0663367\n",
      "\tspeed: 0.0745s/iter; left time: 822.9104s\n",
      "\titers: 200, epoch: 51 | loss: 0.0666947\n",
      "\tspeed: 0.0421s/iter; left time: 460.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0667478 Vali Loss: 0.0859076 Test Loss: 0.1047956\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0697146\n",
      "\tspeed: 0.0745s/iter; left time: 807.1150s\n",
      "\titers: 200, epoch: 52 | loss: 0.0681353\n",
      "\tspeed: 0.0422s/iter; left time: 452.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0662494 Vali Loss: 0.0859539 Test Loss: 0.1050173\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0632726\n",
      "\tspeed: 0.0747s/iter; left time: 792.1965s\n",
      "\titers: 200, epoch: 53 | loss: 0.0635815\n",
      "\tspeed: 0.0422s/iter; left time: 443.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0663979 Vali Loss: 0.0857722 Test Loss: 0.1048720\n",
      "Validation loss decreased (0.085836 --> 0.085772).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0695221\n",
      "\tspeed: 0.0759s/iter; left time: 788.3014s\n",
      "\titers: 200, epoch: 54 | loss: 0.0661346\n",
      "\tspeed: 0.0422s/iter; left time: 433.6057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 223 | Train Loss: 0.0665474 Vali Loss: 0.0859458 Test Loss: 0.1047746\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0629701\n",
      "\tspeed: 0.0750s/iter; left time: 762.0132s\n",
      "\titers: 200, epoch: 55 | loss: 0.0651106\n",
      "\tspeed: 0.0422s/iter; left time: 424.0200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0663513 Vali Loss: 0.0857662 Test Loss: 0.1042586\n",
      "Validation loss decreased (0.085772 --> 0.085766).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0645872\n",
      "\tspeed: 0.0760s/iter; left time: 755.5447s\n",
      "\titers: 200, epoch: 56 | loss: 0.0637607\n",
      "\tspeed: 0.0424s/iter; left time: 416.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0664517 Vali Loss: 0.0859972 Test Loss: 0.1046425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0703630\n",
      "\tspeed: 0.0741s/iter; left time: 719.4610s\n",
      "\titers: 200, epoch: 57 | loss: 0.0687405\n",
      "\tspeed: 0.0421s/iter; left time: 405.1842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0663632 Vali Loss: 0.0858034 Test Loss: 0.1044436\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0665828\n",
      "\tspeed: 0.0743s/iter; left time: 705.5209s\n",
      "\titers: 200, epoch: 58 | loss: 0.0678301\n",
      "\tspeed: 0.0422s/iter; left time: 395.7930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0665004 Vali Loss: 0.0857389 Test Loss: 0.1046943\n",
      "Validation loss decreased (0.085766 --> 0.085739).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0638114\n",
      "\tspeed: 0.0753s/iter; left time: 697.9047s\n",
      "\titers: 200, epoch: 59 | loss: 0.0623198\n",
      "\tspeed: 0.0422s/iter; left time: 386.4789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0664122 Vali Loss: 0.0858287 Test Loss: 0.1046391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0647889\n",
      "\tspeed: 0.0751s/iter; left time: 679.5182s\n",
      "\titers: 200, epoch: 60 | loss: 0.0654907\n",
      "\tspeed: 0.0421s/iter; left time: 376.9744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 223 | Train Loss: 0.0663315 Vali Loss: 0.0858679 Test Loss: 0.1046122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0650465\n",
      "\tspeed: 0.0744s/iter; left time: 656.1123s\n",
      "\titers: 200, epoch: 61 | loss: 0.0626970\n",
      "\tspeed: 0.0422s/iter; left time: 367.9941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0664157 Vali Loss: 0.0862066 Test Loss: 0.1049400\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0692500\n",
      "\tspeed: 0.0744s/iter; left time: 639.5370s\n",
      "\titers: 200, epoch: 62 | loss: 0.0644360\n",
      "\tspeed: 0.0421s/iter; left time: 357.5396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0662909 Vali Loss: 0.0859662 Test Loss: 0.1048562\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0654990\n",
      "\tspeed: 0.0756s/iter; left time: 632.8769s\n",
      "\titers: 200, epoch: 63 | loss: 0.0707715\n",
      "\tspeed: 0.0424s/iter; left time: 350.6038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 223 | Train Loss: 0.0665499 Vali Loss: 0.0858950 Test Loss: 0.1046011\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0632397\n",
      "\tspeed: 0.0749s/iter; left time: 610.4041s\n",
      "\titers: 200, epoch: 64 | loss: 0.0677355\n",
      "\tspeed: 0.0423s/iter; left time: 340.2445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 223 | Train Loss: 0.0663828 Vali Loss: 0.0861323 Test Loss: 0.1049801\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0677933\n",
      "\tspeed: 0.0748s/iter; left time: 592.8601s\n",
      "\titers: 200, epoch: 65 | loss: 0.0684443\n",
      "\tspeed: 0.0421s/iter; left time: 329.7975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0662847 Vali Loss: 0.0860327 Test Loss: 0.1048426\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0676592\n",
      "\tspeed: 0.0748s/iter; left time: 576.3310s\n",
      "\titers: 200, epoch: 66 | loss: 0.0655084\n",
      "\tspeed: 0.0422s/iter; left time: 320.6748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 223 | Train Loss: 0.0662993 Vali Loss: 0.0860737 Test Loss: 0.1049353\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0659778\n",
      "\tspeed: 0.4219s/iter; left time: 3156.9689s\n",
      "\titers: 200, epoch: 67 | loss: 0.0662597\n",
      "\tspeed: 0.1480s/iter; left time: 1093.0473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:33.43s\n",
      "Steps: 223 | Train Loss: 0.0663125 Vali Loss: 0.0863724 Test Loss: 0.1052356\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0649479\n",
      "\tspeed: 0.4238s/iter; left time: 3076.7560s\n",
      "\titers: 200, epoch: 68 | loss: 0.0655732\n",
      "\tspeed: 0.1353s/iter; left time: 968.4532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 223 | Train Loss: 0.0663403 Vali Loss: 0.0861435 Test Loss: 0.1051087\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03116077184677124, rmse:0.17652413249015808, mae:0.10469435155391693, rse:0.6836947202682495\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2927404\n",
      "\tspeed: 0.1534s/iter; left time: 3406.2944s\n",
      "\titers: 200, epoch: 1 | loss: 0.2533216\n",
      "\tspeed: 0.1476s/iter; left time: 3262.2612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 223 | Train Loss: 0.2970449 Vali Loss: 0.2036885 Test Loss: 0.2041611\n",
      "Validation loss decreased (inf --> 0.203688).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1508944\n",
      "\tspeed: 0.3955s/iter; left time: 8692.3569s\n",
      "\titers: 200, epoch: 2 | loss: 0.1184911\n",
      "\tspeed: 0.1585s/iter; left time: 3468.5760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.35s\n",
      "Steps: 223 | Train Loss: 0.1577305 Vali Loss: 0.1302606 Test Loss: 0.1505485\n",
      "Validation loss decreased (0.203688 --> 0.130261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1021141\n",
      "\tspeed: 0.4241s/iter; left time: 9226.5316s\n",
      "\titers: 200, epoch: 3 | loss: 0.0841632\n",
      "\tspeed: 0.1481s/iter; left time: 3206.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.08s\n",
      "Steps: 223 | Train Loss: 0.0986189 Vali Loss: 0.0990562 Test Loss: 0.1137558\n",
      "Validation loss decreased (0.130261 --> 0.099056).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0809749\n",
      "\tspeed: 0.3948s/iter; left time: 8500.7127s\n",
      "\titers: 200, epoch: 4 | loss: 0.0837273\n",
      "\tspeed: 0.1298s/iter; left time: 2782.8113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.06s\n",
      "Steps: 223 | Train Loss: 0.0837285 Vali Loss: 0.0953971 Test Loss: 0.1089194\n",
      "Validation loss decreased (0.099056 --> 0.095397).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0754063\n",
      "\tspeed: 0.3992s/iter; left time: 8505.6513s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757783\n",
      "\tspeed: 0.1194s/iter; left time: 2532.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.69s\n",
      "Steps: 223 | Train Loss: 0.0786105 Vali Loss: 0.0918990 Test Loss: 0.1077366\n",
      "Validation loss decreased (0.095397 --> 0.091899).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0739125\n",
      "\tspeed: 0.3734s/iter; left time: 7874.3798s\n",
      "\titers: 200, epoch: 6 | loss: 0.0757515\n",
      "\tspeed: 0.1217s/iter; left time: 2554.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:30.10s\n",
      "Steps: 223 | Train Loss: 0.0764652 Vali Loss: 0.0899220 Test Loss: 0.1066380\n",
      "Validation loss decreased (0.091899 --> 0.089922).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0749864\n",
      "\tspeed: 0.3815s/iter; left time: 7958.8244s\n",
      "\titers: 200, epoch: 7 | loss: 0.0717871\n",
      "\tspeed: 0.1410s/iter; left time: 2928.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.10s\n",
      "Steps: 223 | Train Loss: 0.0742425 Vali Loss: 0.0882019 Test Loss: 0.1049898\n",
      "Validation loss decreased (0.089922 --> 0.088202).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0735129\n",
      "\tspeed: 0.3810s/iter; left time: 7864.7103s\n",
      "\titers: 200, epoch: 8 | loss: 0.0725281\n",
      "\tspeed: 0.1412s/iter; left time: 2899.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.22s\n",
      "Steps: 223 | Train Loss: 0.0731610 Vali Loss: 0.0890609 Test Loss: 0.1082026\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0724494\n",
      "\tspeed: 0.3500s/iter; left time: 7145.8549s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740974\n",
      "\tspeed: 0.1106s/iter; left time: 2246.4875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.94s\n",
      "Steps: 223 | Train Loss: 0.0728666 Vali Loss: 0.0869373 Test Loss: 0.1055785\n",
      "Validation loss decreased (0.088202 --> 0.086937).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0713085\n",
      "\tspeed: 0.3905s/iter; left time: 7886.0512s\n",
      "\titers: 200, epoch: 10 | loss: 0.0680546\n",
      "\tspeed: 0.1248s/iter; left time: 2508.1283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:30.73s\n",
      "Steps: 223 | Train Loss: 0.0716452 Vali Loss: 0.0871202 Test Loss: 0.1055537\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0721431\n",
      "\tspeed: 0.3622s/iter; left time: 7233.1133s\n",
      "\titers: 200, epoch: 11 | loss: 0.0731563\n",
      "\tspeed: 0.1277s/iter; left time: 2537.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:30.23s\n",
      "Steps: 223 | Train Loss: 0.0708880 Vali Loss: 0.0863051 Test Loss: 0.1044729\n",
      "Validation loss decreased (0.086937 --> 0.086305).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0670274\n",
      "\tspeed: 0.4221s/iter; left time: 8336.3787s\n",
      "\titers: 200, epoch: 12 | loss: 0.0706704\n",
      "\tspeed: 0.1340s/iter; left time: 2633.7403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:33.56s\n",
      "Steps: 223 | Train Loss: 0.0708302 Vali Loss: 0.0860932 Test Loss: 0.1042071\n",
      "Validation loss decreased (0.086305 --> 0.086093).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0702334\n",
      "\tspeed: 0.4117s/iter; left time: 8038.0828s\n",
      "\titers: 200, epoch: 13 | loss: 0.0698955\n",
      "\tspeed: 0.1439s/iter; left time: 2796.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:33.02s\n",
      "Steps: 223 | Train Loss: 0.0702704 Vali Loss: 0.0859134 Test Loss: 0.1051288\n",
      "Validation loss decreased (0.086093 --> 0.085913).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0707551\n",
      "\tspeed: 0.3763s/iter; left time: 7263.7098s\n",
      "\titers: 200, epoch: 14 | loss: 0.0712942\n",
      "\tspeed: 0.1461s/iter; left time: 2804.5104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.37s\n",
      "Steps: 223 | Train Loss: 0.0693690 Vali Loss: 0.0863314 Test Loss: 0.1046887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662443\n",
      "\tspeed: 0.3451s/iter; left time: 6584.4773s\n",
      "\titers: 200, epoch: 15 | loss: 0.0666913\n",
      "\tspeed: 0.1354s/iter; left time: 2569.9870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.77s\n",
      "Steps: 223 | Train Loss: 0.0692295 Vali Loss: 0.0862531 Test Loss: 0.1042612\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0677853\n",
      "\tspeed: 0.3856s/iter; left time: 7270.7183s\n",
      "\titers: 200, epoch: 16 | loss: 0.0696240\n",
      "\tspeed: 0.1507s/iter; left time: 2825.5977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:33.67s\n",
      "Steps: 223 | Train Loss: 0.0692279 Vali Loss: 0.0857303 Test Loss: 0.1048810\n",
      "Validation loss decreased (0.085913 --> 0.085730).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727441\n",
      "\tspeed: 0.3755s/iter; left time: 6995.7866s\n",
      "\titers: 200, epoch: 17 | loss: 0.0691768\n",
      "\tspeed: 0.1415s/iter; left time: 2622.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:32.11s\n",
      "Steps: 223 | Train Loss: 0.0686956 Vali Loss: 0.0855698 Test Loss: 0.1042315\n",
      "Validation loss decreased (0.085730 --> 0.085570).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0661308\n",
      "\tspeed: 0.3733s/iter; left time: 6872.3187s\n",
      "\titers: 200, epoch: 18 | loss: 0.0710338\n",
      "\tspeed: 0.1451s/iter; left time: 2656.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.26s\n",
      "Steps: 223 | Train Loss: 0.0682434 Vali Loss: 0.0855440 Test Loss: 0.1040367\n",
      "Validation loss decreased (0.085570 --> 0.085544).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0699997\n",
      "\tspeed: 0.3534s/iter; left time: 6427.3513s\n",
      "\titers: 200, epoch: 19 | loss: 0.0669575\n",
      "\tspeed: 0.1379s/iter; left time: 2494.8693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.86s\n",
      "Steps: 223 | Train Loss: 0.0683837 Vali Loss: 0.0864809 Test Loss: 0.1049829\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0694757\n",
      "\tspeed: 0.0757s/iter; left time: 1359.5253s\n",
      "\titers: 200, epoch: 20 | loss: 0.0662269\n",
      "\tspeed: 0.0422s/iter; left time: 753.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0681277 Vali Loss: 0.0851363 Test Loss: 0.1030623\n",
      "Validation loss decreased (0.085544 --> 0.085136).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0678531\n",
      "\tspeed: 0.0761s/iter; left time: 1350.0216s\n",
      "\titers: 200, epoch: 21 | loss: 0.0652275\n",
      "\tspeed: 0.0424s/iter; left time: 748.1614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0676840 Vali Loss: 0.0856104 Test Loss: 0.1040968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0669399\n",
      "\tspeed: 0.0752s/iter; left time: 1318.2151s\n",
      "\titers: 200, epoch: 22 | loss: 0.0664632\n",
      "\tspeed: 0.0423s/iter; left time: 736.5703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0676572 Vali Loss: 0.0855321 Test Loss: 0.1033216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0646945\n",
      "\tspeed: 0.0751s/iter; left time: 1298.7104s\n",
      "\titers: 200, epoch: 23 | loss: 0.0682219\n",
      "\tspeed: 0.0421s/iter; left time: 724.5634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0675430 Vali Loss: 0.0856400 Test Loss: 0.1035615\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0648574\n",
      "\tspeed: 0.0749s/iter; left time: 1278.8714s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680826\n",
      "\tspeed: 0.0422s/iter; left time: 716.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0674333 Vali Loss: 0.0860382 Test Loss: 0.1042629\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0662488\n",
      "\tspeed: 0.0758s/iter; left time: 1276.9496s\n",
      "\titers: 200, epoch: 25 | loss: 0.0660610\n",
      "\tspeed: 0.0424s/iter; left time: 709.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0673959 Vali Loss: 0.0856787 Test Loss: 0.1037422\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0668349\n",
      "\tspeed: 0.0750s/iter; left time: 1246.9743s\n",
      "\titers: 200, epoch: 26 | loss: 0.0677131\n",
      "\tspeed: 0.0422s/iter; left time: 697.7387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0671501 Vali Loss: 0.0850125 Test Loss: 0.1027840\n",
      "Validation loss decreased (0.085136 --> 0.085012).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0642348\n",
      "\tspeed: 0.0762s/iter; left time: 1249.4815s\n",
      "\titers: 200, epoch: 27 | loss: 0.0702509\n",
      "\tspeed: 0.0422s/iter; left time: 687.7654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0671857 Vali Loss: 0.0853610 Test Loss: 0.1030005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0716490\n",
      "\tspeed: 0.0747s/iter; left time: 1208.8103s\n",
      "\titers: 200, epoch: 28 | loss: 0.0663618\n",
      "\tspeed: 0.0422s/iter; left time: 679.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0671161 Vali Loss: 0.0854254 Test Loss: 0.1035366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0681024\n",
      "\tspeed: 0.0748s/iter; left time: 1193.3968s\n",
      "\titers: 200, epoch: 29 | loss: 0.0665200\n",
      "\tspeed: 0.0422s/iter; left time: 669.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0669668 Vali Loss: 0.0854746 Test Loss: 0.1036541\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0691152\n",
      "\tspeed: 0.0747s/iter; left time: 1174.8110s\n",
      "\titers: 200, epoch: 30 | loss: 0.0655242\n",
      "\tspeed: 0.0422s/iter; left time: 660.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0670553 Vali Loss: 0.0855400 Test Loss: 0.1033476\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0636503\n",
      "\tspeed: 0.0749s/iter; left time: 1162.2056s\n",
      "\titers: 200, epoch: 31 | loss: 0.0663491\n",
      "\tspeed: 0.0423s/iter; left time: 651.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0668301 Vali Loss: 0.0850089 Test Loss: 0.1033278\n",
      "Validation loss decreased (0.085012 --> 0.085009).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0646706\n",
      "\tspeed: 0.0766s/iter; left time: 1170.7337s\n",
      "\titers: 200, epoch: 32 | loss: 0.0648494\n",
      "\tspeed: 0.0424s/iter; left time: 644.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0667986 Vali Loss: 0.0851346 Test Loss: 0.1030435\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0667772\n",
      "\tspeed: 0.0752s/iter; left time: 1133.5099s\n",
      "\titers: 200, epoch: 33 | loss: 0.0665545\n",
      "\tspeed: 0.0421s/iter; left time: 629.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0667472 Vali Loss: 0.0850343 Test Loss: 0.1027071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0660733\n",
      "\tspeed: 0.0750s/iter; left time: 1113.3920s\n",
      "\titers: 200, epoch: 34 | loss: 0.0660400\n",
      "\tspeed: 0.0422s/iter; left time: 622.0392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0666711 Vali Loss: 0.0855329 Test Loss: 0.1032914\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0632180\n",
      "\tspeed: 0.0750s/iter; left time: 1096.2221s\n",
      "\titers: 200, epoch: 35 | loss: 0.0664075\n",
      "\tspeed: 0.0421s/iter; left time: 611.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0666620 Vali Loss: 0.0854720 Test Loss: 0.1032831\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0651354\n",
      "\tspeed: 0.0750s/iter; left time: 1080.3793s\n",
      "\titers: 200, epoch: 36 | loss: 0.0683504\n",
      "\tspeed: 0.0422s/iter; left time: 602.9080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0666273 Vali Loss: 0.0851709 Test Loss: 0.1027252\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0654115\n",
      "\tspeed: 0.0747s/iter; left time: 1059.3291s\n",
      "\titers: 200, epoch: 37 | loss: 0.0668962\n",
      "\tspeed: 0.0422s/iter; left time: 593.5250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0665635 Vali Loss: 0.0851574 Test Loss: 0.1027513\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0661501\n",
      "\tspeed: 0.0746s/iter; left time: 1041.1987s\n",
      "\titers: 200, epoch: 38 | loss: 0.0694724\n",
      "\tspeed: 0.0422s/iter; left time: 584.3425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0665336 Vali Loss: 0.0852741 Test Loss: 0.1031784\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0661168\n",
      "\tspeed: 0.0748s/iter; left time: 1026.7815s\n",
      "\titers: 200, epoch: 39 | loss: 0.0671704\n",
      "\tspeed: 0.0422s/iter; left time: 574.8595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0664374 Vali Loss: 0.0850923 Test Loss: 0.1026572\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0666707\n",
      "\tspeed: 0.0751s/iter; left time: 1013.9320s\n",
      "\titers: 200, epoch: 40 | loss: 0.0643548\n",
      "\tspeed: 0.0422s/iter; left time: 565.7830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 223 | Train Loss: 0.0664657 Vali Loss: 0.0851806 Test Loss: 0.1026053\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0638251\n",
      "\tspeed: 0.0749s/iter; left time: 994.9540s\n",
      "\titers: 200, epoch: 41 | loss: 0.0625447\n",
      "\tspeed: 0.0422s/iter; left time: 556.1203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0664765 Vali Loss: 0.0854597 Test Loss: 0.1029494\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.030091414228081703, rmse:0.17346876859664917, mae:0.10332779586315155, rse:0.6718609929084778\n",
      "Intermediate time for FR and pred_len 168: 00h:47m:24.27s\n",
      "Intermediate time for FR: 03h:13m:20.60s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2917297\n",
      "\tspeed: 0.0592s/iter; left time: 1319.4394s\n",
      "\titers: 200, epoch: 1 | loss: 0.2724768\n",
      "\tspeed: 0.0417s/iter; left time: 926.7913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 224 | Train Loss: 0.3044934 Vali Loss: 0.2135511 Test Loss: 0.2156564\n",
      "Validation loss decreased (inf --> 0.213551).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1888063\n",
      "\tspeed: 0.0748s/iter; left time: 1650.3325s\n",
      "\titers: 200, epoch: 2 | loss: 0.1292061\n",
      "\tspeed: 0.0417s/iter; left time: 915.9798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.1826854 Vali Loss: 0.1063293 Test Loss: 0.1123506\n",
      "Validation loss decreased (0.213551 --> 0.106329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1072841\n",
      "\tspeed: 0.0745s/iter; left time: 1628.6302s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986646\n",
      "\tspeed: 0.0418s/iter; left time: 908.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.1061663 Vali Loss: 0.0890767 Test Loss: 0.0976192\n",
      "Validation loss decreased (0.106329 --> 0.089077).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0887372\n",
      "\tspeed: 0.0755s/iter; left time: 1632.2350s\n",
      "\titers: 200, epoch: 4 | loss: 0.0822716\n",
      "\tspeed: 0.0417s/iter; left time: 898.1496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0898723 Vali Loss: 0.0813280 Test Loss: 0.0887356\n",
      "Validation loss decreased (0.089077 --> 0.081328).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0783869\n",
      "\tspeed: 0.0745s/iter; left time: 1594.6240s\n",
      "\titers: 200, epoch: 5 | loss: 0.0839057\n",
      "\tspeed: 0.0417s/iter; left time: 888.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0827718 Vali Loss: 0.0758382 Test Loss: 0.0827545\n",
      "Validation loss decreased (0.081328 --> 0.075838).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0773783\n",
      "\tspeed: 0.0743s/iter; left time: 1573.0719s\n",
      "\titers: 200, epoch: 6 | loss: 0.0770648\n",
      "\tspeed: 0.0417s/iter; left time: 878.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0782117 Vali Loss: 0.0740963 Test Loss: 0.0812490\n",
      "Validation loss decreased (0.075838 --> 0.074096).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0762288\n",
      "\tspeed: 0.0733s/iter; left time: 1536.2520s\n",
      "\titers: 200, epoch: 7 | loss: 0.0753255\n",
      "\tspeed: 0.0417s/iter; left time: 870.2246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0742979 Vali Loss: 0.0709323 Test Loss: 0.0775291\n",
      "Validation loss decreased (0.074096 --> 0.070932).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0752273\n",
      "\tspeed: 0.0739s/iter; left time: 1531.9685s\n",
      "\titers: 200, epoch: 8 | loss: 0.0729069\n",
      "\tspeed: 0.0416s/iter; left time: 859.1343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0734921 Vali Loss: 0.0712854 Test Loss: 0.0774302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0686214\n",
      "\tspeed: 0.0736s/iter; left time: 1510.2242s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725606\n",
      "\tspeed: 0.0416s/iter; left time: 850.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0711182 Vali Loss: 0.0684491 Test Loss: 0.0745013\n",
      "Validation loss decreased (0.070932 --> 0.068449).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700538\n",
      "\tspeed: 0.0739s/iter; left time: 1500.0630s\n",
      "\titers: 200, epoch: 10 | loss: 0.0698337\n",
      "\tspeed: 0.0416s/iter; left time: 840.6008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0697098 Vali Loss: 0.0673903 Test Loss: 0.0740120\n",
      "Validation loss decreased (0.068449 --> 0.067390).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0732256\n",
      "\tspeed: 0.0735s/iter; left time: 1474.3335s\n",
      "\titers: 200, epoch: 11 | loss: 0.0660177\n",
      "\tspeed: 0.0417s/iter; left time: 831.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 224 | Train Loss: 0.0685296 Vali Loss: 0.0684466 Test Loss: 0.0746895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0653241\n",
      "\tspeed: 0.0740s/iter; left time: 1468.3195s\n",
      "\titers: 200, epoch: 12 | loss: 0.0666564\n",
      "\tspeed: 0.0416s/iter; left time: 821.7169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 224 | Train Loss: 0.0677339 Vali Loss: 0.0643723 Test Loss: 0.0714744\n",
      "Validation loss decreased (0.067390 --> 0.064372).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698513\n",
      "\tspeed: 0.0797s/iter; left time: 1562.9739s\n",
      "\titers: 200, epoch: 13 | loss: 0.0657439\n",
      "\tspeed: 0.1101s/iter; left time: 2149.2503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.72s\n",
      "Steps: 224 | Train Loss: 0.0674957 Vali Loss: 0.0648832 Test Loss: 0.0713484\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661578\n",
      "\tspeed: 0.2367s/iter; left time: 4590.2791s\n",
      "\titers: 200, epoch: 14 | loss: 0.0666153\n",
      "\tspeed: 0.1102s/iter; left time: 2125.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.12s\n",
      "Steps: 224 | Train Loss: 0.0668794 Vali Loss: 0.0642530 Test Loss: 0.0704647\n",
      "Validation loss decreased (0.064372 --> 0.064253).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0653142\n",
      "\tspeed: 0.2409s/iter; left time: 4616.7437s\n",
      "\titers: 200, epoch: 15 | loss: 0.0639981\n",
      "\tspeed: 0.1162s/iter; left time: 2215.9834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.55s\n",
      "Steps: 224 | Train Loss: 0.0658752 Vali Loss: 0.0650121 Test Loss: 0.0710732\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0655565\n",
      "\tspeed: 0.2325s/iter; left time: 4403.8315s\n",
      "\titers: 200, epoch: 16 | loss: 0.0645918\n",
      "\tspeed: 0.0864s/iter; left time: 1626.9766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.23s\n",
      "Steps: 224 | Train Loss: 0.0654310 Vali Loss: 0.0632677 Test Loss: 0.0690901\n",
      "Validation loss decreased (0.064253 --> 0.063268).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0623885\n",
      "\tspeed: 0.2237s/iter; left time: 4186.9443s\n",
      "\titers: 200, epoch: 17 | loss: 0.0640620\n",
      "\tspeed: 0.1171s/iter; left time: 2180.0061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.74s\n",
      "Steps: 224 | Train Loss: 0.0660954 Vali Loss: 0.0670141 Test Loss: 0.0727273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0638051\n",
      "\tspeed: 0.2243s/iter; left time: 4147.7010s\n",
      "\titers: 200, epoch: 18 | loss: 0.0613892\n",
      "\tspeed: 0.0958s/iter; left time: 1761.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:24.54s\n",
      "Steps: 224 | Train Loss: 0.0647964 Vali Loss: 0.0624434 Test Loss: 0.0683326\n",
      "Validation loss decreased (0.063268 --> 0.062443).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0652143\n",
      "\tspeed: 0.2535s/iter; left time: 4631.2459s\n",
      "\titers: 200, epoch: 19 | loss: 0.0633825\n",
      "\tspeed: 0.1125s/iter; left time: 2044.8106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:26.13s\n",
      "Steps: 224 | Train Loss: 0.0641431 Vali Loss: 0.0624334 Test Loss: 0.0680263\n",
      "Validation loss decreased (0.062443 --> 0.062433).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0619974\n",
      "\tspeed: 0.2504s/iter; left time: 4517.7321s\n",
      "\titers: 200, epoch: 20 | loss: 0.0655706\n",
      "\tspeed: 0.1149s/iter; left time: 2062.4778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:26.13s\n",
      "Steps: 224 | Train Loss: 0.0640469 Vali Loss: 0.0632245 Test Loss: 0.0692085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0621486\n",
      "\tspeed: 0.2468s/iter; left time: 4397.8770s\n",
      "\titers: 200, epoch: 21 | loss: 0.0604584\n",
      "\tspeed: 0.1248s/iter; left time: 2211.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:25.84s\n",
      "Steps: 224 | Train Loss: 0.0637700 Vali Loss: 0.0622434 Test Loss: 0.0681685\n",
      "Validation loss decreased (0.062433 --> 0.062243).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0632059\n",
      "\tspeed: 0.2537s/iter; left time: 4464.4627s\n",
      "\titers: 200, epoch: 22 | loss: 0.0628312\n",
      "\tspeed: 0.1249s/iter; left time: 2185.1032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:27.38s\n",
      "Steps: 224 | Train Loss: 0.0635047 Vali Loss: 0.0620577 Test Loss: 0.0682117\n",
      "Validation loss decreased (0.062243 --> 0.062058).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0626523\n",
      "\tspeed: 0.2585s/iter; left time: 4490.3168s\n",
      "\titers: 200, epoch: 23 | loss: 0.0709764\n",
      "\tspeed: 0.1082s/iter; left time: 1868.6132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:25.97s\n",
      "Steps: 224 | Train Loss: 0.0633799 Vali Loss: 0.0622608 Test Loss: 0.0680840\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0678532\n",
      "\tspeed: 0.2688s/iter; left time: 4610.1706s\n",
      "\titers: 200, epoch: 24 | loss: 0.0626774\n",
      "\tspeed: 0.1168s/iter; left time: 1991.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:27.30s\n",
      "Steps: 224 | Train Loss: 0.0632103 Vali Loss: 0.0615027 Test Loss: 0.0675611\n",
      "Validation loss decreased (0.062058 --> 0.061503).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0570536\n",
      "\tspeed: 0.2513s/iter; left time: 4252.8604s\n",
      "\titers: 200, epoch: 25 | loss: 0.0626429\n",
      "\tspeed: 0.1128s/iter; left time: 1897.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:26.30s\n",
      "Steps: 224 | Train Loss: 0.0628826 Vali Loss: 0.0617426 Test Loss: 0.0672014\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0604851\n",
      "\tspeed: 0.2679s/iter; left time: 4473.5068s\n",
      "\titers: 200, epoch: 26 | loss: 0.0629006\n",
      "\tspeed: 0.1123s/iter; left time: 1864.1692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:26.60s\n",
      "Steps: 224 | Train Loss: 0.0630620 Vali Loss: 0.0613229 Test Loss: 0.0673806\n",
      "Validation loss decreased (0.061503 --> 0.061323).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0593049\n",
      "\tspeed: 0.2634s/iter; left time: 4339.6818s\n",
      "\titers: 200, epoch: 27 | loss: 0.0613664\n",
      "\tspeed: 0.1158s/iter; left time: 1896.8388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:28.09s\n",
      "Steps: 224 | Train Loss: 0.0627284 Vali Loss: 0.0613110 Test Loss: 0.0672141\n",
      "Validation loss decreased (0.061323 --> 0.061311).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0610138\n",
      "\tspeed: 0.2757s/iter; left time: 4481.7434s\n",
      "\titers: 200, epoch: 28 | loss: 0.0590416\n",
      "\tspeed: 0.1233s/iter; left time: 1991.5217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:29.25s\n",
      "Steps: 224 | Train Loss: 0.0626667 Vali Loss: 0.0622489 Test Loss: 0.0680730\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0616920\n",
      "\tspeed: 0.2682s/iter; left time: 4298.3920s\n",
      "\titers: 200, epoch: 29 | loss: 0.0635657\n",
      "\tspeed: 0.1274s/iter; left time: 2028.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:29.28s\n",
      "Steps: 224 | Train Loss: 0.0625903 Vali Loss: 0.0610113 Test Loss: 0.0668681\n",
      "Validation loss decreased (0.061311 --> 0.061011).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0591496\n",
      "\tspeed: 0.2589s/iter; left time: 4092.3355s\n",
      "\titers: 200, epoch: 30 | loss: 0.0642186\n",
      "\tspeed: 0.1188s/iter; left time: 1866.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:27.51s\n",
      "Steps: 224 | Train Loss: 0.0624432 Vali Loss: 0.0608447 Test Loss: 0.0665070\n",
      "Validation loss decreased (0.061011 --> 0.060845).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0595470\n",
      "\tspeed: 0.2838s/iter; left time: 4421.9299s\n",
      "\titers: 200, epoch: 31 | loss: 0.0611045\n",
      "\tspeed: 0.1226s/iter; left time: 1898.4525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:28.79s\n",
      "Steps: 224 | Train Loss: 0.0622612 Vali Loss: 0.0610894 Test Loss: 0.0666248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0628343\n",
      "\tspeed: 0.2811s/iter; left time: 4316.5628s\n",
      "\titers: 200, epoch: 32 | loss: 0.0632370\n",
      "\tspeed: 0.1088s/iter; left time: 1660.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:26.71s\n",
      "Steps: 224 | Train Loss: 0.0622680 Vali Loss: 0.0609502 Test Loss: 0.0667441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0649866\n",
      "\tspeed: 0.2701s/iter; left time: 4087.2758s\n",
      "\titers: 200, epoch: 33 | loss: 0.0640624\n",
      "\tspeed: 0.1228s/iter; left time: 1846.5020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:29.38s\n",
      "Steps: 224 | Train Loss: 0.0621523 Vali Loss: 0.0610435 Test Loss: 0.0666443\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0655937\n",
      "\tspeed: 0.3025s/iter; left time: 4510.2302s\n",
      "\titers: 200, epoch: 34 | loss: 0.0629595\n",
      "\tspeed: 0.1204s/iter; left time: 1782.7316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:29.78s\n",
      "Steps: 224 | Train Loss: 0.0622847 Vali Loss: 0.0607267 Test Loss: 0.0665016\n",
      "Validation loss decreased (0.060845 --> 0.060727).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0594194\n",
      "\tspeed: 0.3042s/iter; left time: 4467.8145s\n",
      "\titers: 200, epoch: 35 | loss: 0.0620636\n",
      "\tspeed: 0.1441s/iter; left time: 2102.1511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:32.27s\n",
      "Steps: 224 | Train Loss: 0.0619337 Vali Loss: 0.0606677 Test Loss: 0.0664799\n",
      "Validation loss decreased (0.060727 --> 0.060668).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0597334\n",
      "\tspeed: 0.3144s/iter; left time: 4546.4933s\n",
      "\titers: 200, epoch: 36 | loss: 0.0602577\n",
      "\tspeed: 0.1271s/iter; left time: 1825.4646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:31.30s\n",
      "Steps: 224 | Train Loss: 0.0620153 Vali Loss: 0.0609261 Test Loss: 0.0665951\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0631386\n",
      "\tspeed: 0.2973s/iter; left time: 4233.0152s\n",
      "\titers: 200, epoch: 37 | loss: 0.0647588\n",
      "\tspeed: 0.1342s/iter; left time: 1897.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:30.78s\n",
      "Steps: 224 | Train Loss: 0.0618793 Vali Loss: 0.0607782 Test Loss: 0.0664139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0610640\n",
      "\tspeed: 0.2985s/iter; left time: 4182.5739s\n",
      "\titers: 200, epoch: 38 | loss: 0.0681329\n",
      "\tspeed: 0.1355s/iter; left time: 1885.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 224 | Train Loss: 0.0618328 Vali Loss: 0.0605610 Test Loss: 0.0662870\n",
      "Validation loss decreased (0.060668 --> 0.060561).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0586811\n",
      "\tspeed: 0.2952s/iter; left time: 4069.9963s\n",
      "\titers: 200, epoch: 39 | loss: 0.0614277\n",
      "\tspeed: 0.1273s/iter; left time: 1741.9860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:30.34s\n",
      "Steps: 224 | Train Loss: 0.0617635 Vali Loss: 0.0605189 Test Loss: 0.0663409\n",
      "Validation loss decreased (0.060561 --> 0.060519).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0644318\n",
      "\tspeed: 0.3083s/iter; left time: 4182.6601s\n",
      "\titers: 200, epoch: 40 | loss: 0.0596459\n",
      "\tspeed: 0.1348s/iter; left time: 1815.5212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:30.99s\n",
      "Steps: 224 | Train Loss: 0.0618507 Vali Loss: 0.0606428 Test Loss: 0.0661161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0652421\n",
      "\tspeed: 0.3012s/iter; left time: 4018.4747s\n",
      "\titers: 200, epoch: 41 | loss: 0.0628047\n",
      "\tspeed: 0.1415s/iter; left time: 1873.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:31.67s\n",
      "Steps: 224 | Train Loss: 0.0618174 Vali Loss: 0.0605845 Test Loss: 0.0665455\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0620182\n",
      "\tspeed: 0.2709s/iter; left time: 3554.0447s\n",
      "\titers: 200, epoch: 42 | loss: 0.0632689\n",
      "\tspeed: 0.1265s/iter; left time: 1646.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:29.43s\n",
      "Steps: 224 | Train Loss: 0.0616981 Vali Loss: 0.0608216 Test Loss: 0.0663332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0646770\n",
      "\tspeed: 0.2908s/iter; left time: 3748.9751s\n",
      "\titers: 200, epoch: 43 | loss: 0.0601987\n",
      "\tspeed: 0.1165s/iter; left time: 1490.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:28.31s\n",
      "Steps: 224 | Train Loss: 0.0618877 Vali Loss: 0.0605895 Test Loss: 0.0662475\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0591183\n",
      "\tspeed: 0.2864s/iter; left time: 3628.4505s\n",
      "\titers: 200, epoch: 44 | loss: 0.0627355\n",
      "\tspeed: 0.1295s/iter; left time: 1628.1595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:30.20s\n",
      "Steps: 224 | Train Loss: 0.0618639 Vali Loss: 0.0608744 Test Loss: 0.0663739\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0635198\n",
      "\tspeed: 0.2898s/iter; left time: 3606.9519s\n",
      "\titers: 200, epoch: 45 | loss: 0.0625949\n",
      "\tspeed: 0.1181s/iter; left time: 1458.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:28.13s\n",
      "Steps: 224 | Train Loss: 0.0617342 Vali Loss: 0.0606902 Test Loss: 0.0663077\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0636682\n",
      "\tspeed: 0.2433s/iter; left time: 2973.8836s\n",
      "\titers: 200, epoch: 46 | loss: 0.0600934\n",
      "\tspeed: 0.0461s/iter; left time: 558.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:14.86s\n",
      "Steps: 224 | Train Loss: 0.0617285 Vali Loss: 0.0607403 Test Loss: 0.0663031\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0615292\n",
      "\tspeed: 0.0743s/iter; left time: 890.7954s\n",
      "\titers: 200, epoch: 47 | loss: 0.0614299\n",
      "\tspeed: 0.0418s/iter; left time: 496.8515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0616634 Vali Loss: 0.0605102 Test Loss: 0.0661031\n",
      "Validation loss decreased (0.060519 --> 0.060510).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0625498\n",
      "\tspeed: 0.0742s/iter; left time: 873.1476s\n",
      "\titers: 200, epoch: 48 | loss: 0.0603152\n",
      "\tspeed: 0.0416s/iter; left time: 485.9397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 224 | Train Loss: 0.0616194 Vali Loss: 0.0604620 Test Loss: 0.0663444\n",
      "Validation loss decreased (0.060510 --> 0.060462).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0631341\n",
      "\tspeed: 0.0736s/iter; left time: 850.1628s\n",
      "\titers: 200, epoch: 49 | loss: 0.0625081\n",
      "\tspeed: 0.0415s/iter; left time: 475.3761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 224 | Train Loss: 0.0617447 Vali Loss: 0.0606789 Test Loss: 0.0663243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0615285\n",
      "\tspeed: 0.0729s/iter; left time: 825.7322s\n",
      "\titers: 200, epoch: 50 | loss: 0.0604248\n",
      "\tspeed: 0.0415s/iter; left time: 465.6882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 224 | Train Loss: 0.0615640 Vali Loss: 0.0605634 Test Loss: 0.0661869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0625956\n",
      "\tspeed: 0.0733s/iter; left time: 813.6426s\n",
      "\titers: 200, epoch: 51 | loss: 0.0569833\n",
      "\tspeed: 0.0415s/iter; left time: 456.8736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 224 | Train Loss: 0.0616949 Vali Loss: 0.0604246 Test Loss: 0.0659672\n",
      "Validation loss decreased (0.060462 --> 0.060425).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0617187\n",
      "\tspeed: 0.0740s/iter; left time: 804.7240s\n",
      "\titers: 200, epoch: 52 | loss: 0.0628102\n",
      "\tspeed: 0.0416s/iter; left time: 447.9388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0615435 Vali Loss: 0.0604823 Test Loss: 0.0661739\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0623108\n",
      "\tspeed: 0.0732s/iter; left time: 780.1060s\n",
      "\titers: 200, epoch: 53 | loss: 0.0621993\n",
      "\tspeed: 0.0415s/iter; left time: 437.9143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 224 | Train Loss: 0.0615073 Vali Loss: 0.0603704 Test Loss: 0.0660927\n",
      "Validation loss decreased (0.060425 --> 0.060370).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0620758\n",
      "\tspeed: 0.0735s/iter; left time: 766.9118s\n",
      "\titers: 200, epoch: 54 | loss: 0.0604014\n",
      "\tspeed: 0.0415s/iter; left time: 429.0874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 224 | Train Loss: 0.0616027 Vali Loss: 0.0604690 Test Loss: 0.0659661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0601131\n",
      "\tspeed: 0.0733s/iter; left time: 748.0254s\n",
      "\titers: 200, epoch: 55 | loss: 0.0603976\n",
      "\tspeed: 0.0417s/iter; left time: 420.9194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0614927 Vali Loss: 0.0603823 Test Loss: 0.0659811\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0581978\n",
      "\tspeed: 0.0730s/iter; left time: 728.5746s\n",
      "\titers: 200, epoch: 56 | loss: 0.0591273\n",
      "\tspeed: 0.0416s/iter; left time: 411.3623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0614959 Vali Loss: 0.0604900 Test Loss: 0.0660132\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0639590\n",
      "\tspeed: 0.0732s/iter; left time: 713.9299s\n",
      "\titers: 200, epoch: 57 | loss: 0.0671721\n",
      "\tspeed: 0.0416s/iter; left time: 401.7320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0615000 Vali Loss: 0.0605640 Test Loss: 0.0663754\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0617524\n",
      "\tspeed: 0.0732s/iter; left time: 697.4967s\n",
      "\titers: 200, epoch: 58 | loss: 0.0631058\n",
      "\tspeed: 0.0415s/iter; left time: 391.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 224 | Train Loss: 0.0615586 Vali Loss: 0.0606981 Test Loss: 0.0660661\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0598889\n",
      "\tspeed: 0.0726s/iter; left time: 676.0652s\n",
      "\titers: 200, epoch: 59 | loss: 0.0638118\n",
      "\tspeed: 0.0415s/iter; left time: 382.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 224 | Train Loss: 0.0615825 Vali Loss: 0.0605288 Test Loss: 0.0661115\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0600361\n",
      "\tspeed: 0.0729s/iter; left time: 662.3739s\n",
      "\titers: 200, epoch: 60 | loss: 0.0586136\n",
      "\tspeed: 0.0415s/iter; left time: 372.9694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 224 | Train Loss: 0.0615134 Vali Loss: 0.0605186 Test Loss: 0.0662728\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0632229\n",
      "\tspeed: 0.0729s/iter; left time: 646.0709s\n",
      "\titers: 200, epoch: 61 | loss: 0.0599240\n",
      "\tspeed: 0.0415s/iter; left time: 363.7203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 224 | Train Loss: 0.0614804 Vali Loss: 0.0605308 Test Loss: 0.0660020\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0616387\n",
      "\tspeed: 0.0736s/iter; left time: 636.1094s\n",
      "\titers: 200, epoch: 62 | loss: 0.0627798\n",
      "\tspeed: 0.0415s/iter; left time: 354.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0615172 Vali Loss: 0.0604335 Test Loss: 0.0659738\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0603693\n",
      "\tspeed: 0.0737s/iter; left time: 619.6625s\n",
      "\titers: 200, epoch: 63 | loss: 0.0630263\n",
      "\tspeed: 0.0415s/iter; left time: 344.9291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 224 | Train Loss: 0.0614819 Vali Loss: 0.0607274 Test Loss: 0.0661610\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011679589748382568, rmse:0.10807215422391891, mae:0.06609266251325607, rse:0.40835145115852356\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3217534\n",
      "\tspeed: 0.0433s/iter; left time: 965.0894s\n",
      "\titers: 200, epoch: 1 | loss: 0.2913452\n",
      "\tspeed: 0.0416s/iter; left time: 922.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.3237289 Vali Loss: 0.2061298 Test Loss: 0.2092441\n",
      "Validation loss decreased (inf --> 0.206130).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1948700\n",
      "\tspeed: 0.0737s/iter; left time: 1626.1986s\n",
      "\titers: 200, epoch: 2 | loss: 0.1398393\n",
      "\tspeed: 0.0415s/iter; left time: 912.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 224 | Train Loss: 0.1872122 Vali Loss: 0.1039812 Test Loss: 0.1084776\n",
      "Validation loss decreased (0.206130 --> 0.103981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1111320\n",
      "\tspeed: 0.0741s/iter; left time: 1618.4444s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017483\n",
      "\tspeed: 0.0416s/iter; left time: 903.9509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 224 | Train Loss: 0.1118625 Vali Loss: 0.0933935 Test Loss: 0.1011429\n",
      "Validation loss decreased (0.103981 --> 0.093394).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0916267\n",
      "\tspeed: 0.0740s/iter; left time: 1600.9118s\n",
      "\titers: 200, epoch: 4 | loss: 0.0904128\n",
      "\tspeed: 0.0416s/iter; left time: 896.3129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0955088 Vali Loss: 0.0842757 Test Loss: 0.0920033\n",
      "Validation loss decreased (0.093394 --> 0.084276).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812495\n",
      "\tspeed: 0.0736s/iter; left time: 1576.1974s\n",
      "\titers: 200, epoch: 5 | loss: 0.0777355\n",
      "\tspeed: 0.0417s/iter; left time: 887.5328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0856019 Vali Loss: 0.0777626 Test Loss: 0.0853814\n",
      "Validation loss decreased (0.084276 --> 0.077763).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0794361\n",
      "\tspeed: 0.0738s/iter; left time: 1562.1171s\n",
      "\titers: 200, epoch: 6 | loss: 0.0858391\n",
      "\tspeed: 0.0417s/iter; left time: 878.0487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0800813 Vali Loss: 0.0764579 Test Loss: 0.0833858\n",
      "Validation loss decreased (0.077763 --> 0.076458).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776286\n",
      "\tspeed: 0.0746s/iter; left time: 1563.1984s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747041\n",
      "\tspeed: 0.0419s/iter; left time: 874.1821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0770415 Vali Loss: 0.0714079 Test Loss: 0.0786141\n",
      "Validation loss decreased (0.076458 --> 0.071408).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780737\n",
      "\tspeed: 0.0744s/iter; left time: 1541.6756s\n",
      "\titers: 200, epoch: 8 | loss: 0.0724441\n",
      "\tspeed: 0.0417s/iter; left time: 861.0532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0737597 Vali Loss: 0.0704909 Test Loss: 0.0774264\n",
      "Validation loss decreased (0.071408 --> 0.070491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0744584\n",
      "\tspeed: 0.0749s/iter; left time: 1535.8958s\n",
      "\titers: 200, epoch: 9 | loss: 0.0686658\n",
      "\tspeed: 0.0415s/iter; left time: 847.9889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 224 | Train Loss: 0.0714942 Vali Loss: 0.0676812 Test Loss: 0.0741912\n",
      "Validation loss decreased (0.070491 --> 0.067681).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0719348\n",
      "\tspeed: 0.0733s/iter; left time: 1487.1323s\n",
      "\titers: 200, epoch: 10 | loss: 0.0674667\n",
      "\tspeed: 0.0416s/iter; left time: 839.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 224 | Train Loss: 0.0700719 Vali Loss: 0.0672213 Test Loss: 0.0736170\n",
      "Validation loss decreased (0.067681 --> 0.067221).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0662554\n",
      "\tspeed: 0.0745s/iter; left time: 1494.1254s\n",
      "\titers: 200, epoch: 11 | loss: 0.0717076\n",
      "\tspeed: 0.0415s/iter; left time: 829.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 224 | Train Loss: 0.0689506 Vali Loss: 0.0659062 Test Loss: 0.0726366\n",
      "Validation loss decreased (0.067221 --> 0.065906).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0641014\n",
      "\tspeed: 0.0742s/iter; left time: 1471.7220s\n",
      "\titers: 200, epoch: 12 | loss: 0.0725762\n",
      "\tspeed: 0.0418s/iter; left time: 824.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0681378 Vali Loss: 0.0654700 Test Loss: 0.0715337\n",
      "Validation loss decreased (0.065906 --> 0.065470).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0617555\n",
      "\tspeed: 0.0750s/iter; left time: 1470.1933s\n",
      "\titers: 200, epoch: 13 | loss: 0.0661084\n",
      "\tspeed: 0.0417s/iter; left time: 814.5324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0675447 Vali Loss: 0.0650619 Test Loss: 0.0711744\n",
      "Validation loss decreased (0.065470 --> 0.065062).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0669054\n",
      "\tspeed: 0.0742s/iter; left time: 1439.4180s\n",
      "\titers: 200, epoch: 14 | loss: 0.0637817\n",
      "\tspeed: 0.0415s/iter; left time: 801.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0671282 Vali Loss: 0.0651271 Test Loss: 0.0709381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0702557\n",
      "\tspeed: 0.0729s/iter; left time: 1397.1663s\n",
      "\titers: 200, epoch: 15 | loss: 0.0664976\n",
      "\tspeed: 0.0416s/iter; left time: 792.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 224 | Train Loss: 0.0661000 Vali Loss: 0.0648557 Test Loss: 0.0708089\n",
      "Validation loss decreased (0.065062 --> 0.064856).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0636443\n",
      "\tspeed: 0.0734s/iter; left time: 1390.3543s\n",
      "\titers: 200, epoch: 16 | loss: 0.0596380\n",
      "\tspeed: 0.0416s/iter; left time: 783.2864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 224 | Train Loss: 0.0659747 Vali Loss: 0.0640434 Test Loss: 0.0698044\n",
      "Validation loss decreased (0.064856 --> 0.064043).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0657413\n",
      "\tspeed: 0.0739s/iter; left time: 1383.6064s\n",
      "\titers: 200, epoch: 17 | loss: 0.0673499\n",
      "\tspeed: 0.0418s/iter; left time: 777.5463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0656761 Vali Loss: 0.0649851 Test Loss: 0.0706540\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0643936\n",
      "\tspeed: 0.0732s/iter; left time: 1352.9487s\n",
      "\titers: 200, epoch: 18 | loss: 0.0670563\n",
      "\tspeed: 0.0416s/iter; left time: 764.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 224 | Train Loss: 0.0650429 Vali Loss: 0.0633892 Test Loss: 0.0696071\n",
      "Validation loss decreased (0.064043 --> 0.063389).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0624130\n",
      "\tspeed: 0.0736s/iter; left time: 1344.0556s\n",
      "\titers: 200, epoch: 19 | loss: 0.0629785\n",
      "\tspeed: 0.0418s/iter; left time: 758.6006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0644731 Vali Loss: 0.0628346 Test Loss: 0.0688114\n",
      "Validation loss decreased (0.063389 --> 0.062835).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0615936\n",
      "\tspeed: 0.0736s/iter; left time: 1327.3517s\n",
      "\titers: 200, epoch: 20 | loss: 0.0636711\n",
      "\tspeed: 0.0415s/iter; left time: 745.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 224 | Train Loss: 0.0642418 Vali Loss: 0.0628086 Test Loss: 0.0686350\n",
      "Validation loss decreased (0.062835 --> 0.062809).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0621032\n",
      "\tspeed: 0.0766s/iter; left time: 1364.5588s\n",
      "\titers: 200, epoch: 21 | loss: 0.0623691\n",
      "\tspeed: 0.0416s/iter; left time: 737.9325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0645503 Vali Loss: 0.0638931 Test Loss: 0.0695166\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0620706\n",
      "\tspeed: 0.0728s/iter; left time: 1281.2890s\n",
      "\titers: 200, epoch: 22 | loss: 0.0638893\n",
      "\tspeed: 0.0417s/iter; left time: 728.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 224 | Train Loss: 0.0641950 Vali Loss: 0.0624556 Test Loss: 0.0681500\n",
      "Validation loss decreased (0.062809 --> 0.062456).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0590081\n",
      "\tspeed: 0.0739s/iter; left time: 1284.5696s\n",
      "\titers: 200, epoch: 23 | loss: 0.0567660\n",
      "\tspeed: 0.0416s/iter; left time: 719.0715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0637332 Vali Loss: 0.0626191 Test Loss: 0.0681291\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0607724\n",
      "\tspeed: 0.0732s/iter; left time: 1254.6004s\n",
      "\titers: 200, epoch: 24 | loss: 0.0618241\n",
      "\tspeed: 0.0416s/iter; left time: 709.9119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 224 | Train Loss: 0.0635896 Vali Loss: 0.0620817 Test Loss: 0.0675022\n",
      "Validation loss decreased (0.062456 --> 0.062082).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0645353\n",
      "\tspeed: 0.0736s/iter; left time: 1245.9129s\n",
      "\titers: 200, epoch: 25 | loss: 0.0656299\n",
      "\tspeed: 0.0416s/iter; left time: 699.4357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0634094 Vali Loss: 0.0619683 Test Loss: 0.0677347\n",
      "Validation loss decreased (0.062082 --> 0.061968).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0664649\n",
      "\tspeed: 0.0745s/iter; left time: 1244.9128s\n",
      "\titers: 200, epoch: 26 | loss: 0.0645464\n",
      "\tspeed: 0.0418s/iter; left time: 694.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0633351 Vali Loss: 0.0618910 Test Loss: 0.0674401\n",
      "Validation loss decreased (0.061968 --> 0.061891).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0620179\n",
      "\tspeed: 0.0743s/iter; left time: 1224.7320s\n",
      "\titers: 200, epoch: 27 | loss: 0.0661390\n",
      "\tspeed: 0.0418s/iter; left time: 684.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0630540 Vali Loss: 0.0618430 Test Loss: 0.0675030\n",
      "Validation loss decreased (0.061891 --> 0.061843).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0630711\n",
      "\tspeed: 0.0739s/iter; left time: 1201.7919s\n",
      "\titers: 200, epoch: 28 | loss: 0.0600399\n",
      "\tspeed: 0.0418s/iter; left time: 675.2979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0628444 Vali Loss: 0.0613792 Test Loss: 0.0668591\n",
      "Validation loss decreased (0.061843 --> 0.061379).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0644085\n",
      "\tspeed: 0.0753s/iter; left time: 1207.6591s\n",
      "\titers: 200, epoch: 29 | loss: 0.0609098\n",
      "\tspeed: 0.0418s/iter; left time: 665.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0627127 Vali Loss: 0.0614608 Test Loss: 0.0670995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0602106\n",
      "\tspeed: 0.0734s/iter; left time: 1159.8460s\n",
      "\titers: 200, epoch: 30 | loss: 0.0634614\n",
      "\tspeed: 0.0417s/iter; left time: 655.4296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0628340 Vali Loss: 0.0620946 Test Loss: 0.0675802\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0683950\n",
      "\tspeed: 0.0733s/iter; left time: 1142.4383s\n",
      "\titers: 200, epoch: 31 | loss: 0.0610068\n",
      "\tspeed: 0.0417s/iter; left time: 646.2618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0627574 Vali Loss: 0.0619489 Test Loss: 0.0674784\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0611862\n",
      "\tspeed: 0.0740s/iter; left time: 1136.1768s\n",
      "\titers: 200, epoch: 32 | loss: 0.0621431\n",
      "\tspeed: 0.0417s/iter; left time: 636.7966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0626426 Vali Loss: 0.0618672 Test Loss: 0.0676445\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0632995\n",
      "\tspeed: 0.0732s/iter; left time: 1107.9153s\n",
      "\titers: 200, epoch: 33 | loss: 0.0597948\n",
      "\tspeed: 0.0418s/iter; left time: 627.8358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0623649 Vali Loss: 0.0613640 Test Loss: 0.0666906\n",
      "Validation loss decreased (0.061379 --> 0.061364).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0605670\n",
      "\tspeed: 0.0786s/iter; left time: 1172.5230s\n",
      "\titers: 200, epoch: 34 | loss: 0.0628915\n",
      "\tspeed: 0.0417s/iter; left time: 618.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0623842 Vali Loss: 0.0613382 Test Loss: 0.0666819\n",
      "Validation loss decreased (0.061364 --> 0.061338).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0621457\n",
      "\tspeed: 0.0747s/iter; left time: 1097.0387s\n",
      "\titers: 200, epoch: 35 | loss: 0.0605722\n",
      "\tspeed: 0.0418s/iter; left time: 609.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0623165 Vali Loss: 0.0617706 Test Loss: 0.0671594\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0660500\n",
      "\tspeed: 0.0734s/iter; left time: 1061.5399s\n",
      "\titers: 200, epoch: 36 | loss: 0.0612010\n",
      "\tspeed: 0.0418s/iter; left time: 599.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0623945 Vali Loss: 0.0612620 Test Loss: 0.0666340\n",
      "Validation loss decreased (0.061338 --> 0.061262).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0624794\n",
      "\tspeed: 0.0745s/iter; left time: 1060.9160s\n",
      "\titers: 200, epoch: 37 | loss: 0.0635218\n",
      "\tspeed: 0.0417s/iter; left time: 590.2135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0624420 Vali Loss: 0.0614089 Test Loss: 0.0667850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0581783\n",
      "\tspeed: 0.0736s/iter; left time: 1030.7417s\n",
      "\titers: 200, epoch: 38 | loss: 0.0620820\n",
      "\tspeed: 0.0419s/iter; left time: 583.0109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0622227 Vali Loss: 0.0610454 Test Loss: 0.0667137\n",
      "Validation loss decreased (0.061262 --> 0.061045).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0599941\n",
      "\tspeed: 0.0758s/iter; left time: 1045.0432s\n",
      "\titers: 200, epoch: 39 | loss: 0.0639912\n",
      "\tspeed: 0.0418s/iter; left time: 571.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0621129 Vali Loss: 0.0610032 Test Loss: 0.0665490\n",
      "Validation loss decreased (0.061045 --> 0.061003).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0633811\n",
      "\tspeed: 0.0742s/iter; left time: 1006.7803s\n",
      "\titers: 200, epoch: 40 | loss: 0.0629305\n",
      "\tspeed: 0.0418s/iter; left time: 562.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0620979 Vali Loss: 0.0610276 Test Loss: 0.0665840\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0607262\n",
      "\tspeed: 0.0735s/iter; left time: 980.1977s\n",
      "\titers: 200, epoch: 41 | loss: 0.0638720\n",
      "\tspeed: 0.0417s/iter; left time: 552.5844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0620613 Vali Loss: 0.0612012 Test Loss: 0.0665561\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0629673\n",
      "\tspeed: 0.0734s/iter; left time: 963.4088s\n",
      "\titers: 200, epoch: 42 | loss: 0.0592270\n",
      "\tspeed: 0.0417s/iter; left time: 543.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0619375 Vali Loss: 0.0610041 Test Loss: 0.0663851\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0600283\n",
      "\tspeed: 0.0735s/iter; left time: 947.7556s\n",
      "\titers: 200, epoch: 43 | loss: 0.0615772\n",
      "\tspeed: 0.0418s/iter; left time: 535.1259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0621816 Vali Loss: 0.0612075 Test Loss: 0.0666657\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0618864\n",
      "\tspeed: 0.0734s/iter; left time: 929.8340s\n",
      "\titers: 200, epoch: 44 | loss: 0.0663386\n",
      "\tspeed: 0.0419s/iter; left time: 526.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0619905 Vali Loss: 0.0610679 Test Loss: 0.0665237\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0630645\n",
      "\tspeed: 0.0736s/iter; left time: 915.7235s\n",
      "\titers: 200, epoch: 45 | loss: 0.0624654\n",
      "\tspeed: 0.0419s/iter; left time: 516.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0619096 Vali Loss: 0.0610669 Test Loss: 0.0665683\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0579027\n",
      "\tspeed: 0.0735s/iter; left time: 898.7130s\n",
      "\titers: 200, epoch: 46 | loss: 0.0615248\n",
      "\tspeed: 0.0418s/iter; left time: 507.0260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0620733 Vali Loss: 0.0610197 Test Loss: 0.0663510\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0613477\n",
      "\tspeed: 0.0739s/iter; left time: 887.1124s\n",
      "\titers: 200, epoch: 47 | loss: 0.0627428\n",
      "\tspeed: 0.0419s/iter; left time: 498.3700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0620618 Vali Loss: 0.0609272 Test Loss: 0.0663232\n",
      "Validation loss decreased (0.061003 --> 0.060927).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0623852\n",
      "\tspeed: 0.0741s/iter; left time: 872.3265s\n",
      "\titers: 200, epoch: 48 | loss: 0.0635967\n",
      "\tspeed: 0.0419s/iter; left time: 488.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0618970 Vali Loss: 0.0607905 Test Loss: 0.0663396\n",
      "Validation loss decreased (0.060927 --> 0.060790).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0636465\n",
      "\tspeed: 0.0744s/iter; left time: 859.2687s\n",
      "\titers: 200, epoch: 49 | loss: 0.0656432\n",
      "\tspeed: 0.0419s/iter; left time: 479.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0619471 Vali Loss: 0.0608618 Test Loss: 0.0663249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0626932\n",
      "\tspeed: 0.0735s/iter; left time: 832.2807s\n",
      "\titers: 200, epoch: 50 | loss: 0.0629831\n",
      "\tspeed: 0.0419s/iter; left time: 469.8874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0618413 Vali Loss: 0.0609641 Test Loss: 0.0661131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0592961\n",
      "\tspeed: 0.0734s/iter; left time: 815.1794s\n",
      "\titers: 200, epoch: 51 | loss: 0.0632951\n",
      "\tspeed: 0.0418s/iter; left time: 460.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0621002 Vali Loss: 0.0609625 Test Loss: 0.0663819\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0630677\n",
      "\tspeed: 0.0736s/iter; left time: 800.5936s\n",
      "\titers: 200, epoch: 52 | loss: 0.0643648\n",
      "\tspeed: 0.0419s/iter; left time: 451.2659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0619182 Vali Loss: 0.0610262 Test Loss: 0.0662577\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0610833\n",
      "\tspeed: 0.0734s/iter; left time: 782.4464s\n",
      "\titers: 200, epoch: 53 | loss: 0.0610413\n",
      "\tspeed: 0.0419s/iter; left time: 441.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0618627 Vali Loss: 0.0609296 Test Loss: 0.0661752\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0623450\n",
      "\tspeed: 0.0734s/iter; left time: 765.4214s\n",
      "\titers: 200, epoch: 54 | loss: 0.0564224\n",
      "\tspeed: 0.0419s/iter; left time: 432.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0618609 Vali Loss: 0.0608931 Test Loss: 0.0663055\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0643856\n",
      "\tspeed: 0.0737s/iter; left time: 752.4809s\n",
      "\titers: 200, epoch: 55 | loss: 0.0602120\n",
      "\tspeed: 0.0418s/iter; left time: 421.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0619194 Vali Loss: 0.0608653 Test Loss: 0.0662267\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0664839\n",
      "\tspeed: 0.0734s/iter; left time: 733.0430s\n",
      "\titers: 200, epoch: 56 | loss: 0.0566268\n",
      "\tspeed: 0.0418s/iter; left time: 412.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0619431 Vali Loss: 0.0610673 Test Loss: 0.0664549\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0569132\n",
      "\tspeed: 0.0735s/iter; left time: 717.1299s\n",
      "\titers: 200, epoch: 57 | loss: 0.0617042\n",
      "\tspeed: 0.0419s/iter; left time: 404.2307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0617681 Vali Loss: 0.0608570 Test Loss: 0.0662712\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0599865\n",
      "\tspeed: 0.0734s/iter; left time: 700.0582s\n",
      "\titers: 200, epoch: 58 | loss: 0.0596393\n",
      "\tspeed: 0.0418s/iter; left time: 393.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0617956 Vali Loss: 0.0607454 Test Loss: 0.0661575\n",
      "Validation loss decreased (0.060790 --> 0.060745).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0634213\n",
      "\tspeed: 0.0739s/iter; left time: 687.9255s\n",
      "\titers: 200, epoch: 59 | loss: 0.0561794\n",
      "\tspeed: 0.0416s/iter; left time: 383.5015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0618519 Vali Loss: 0.0606596 Test Loss: 0.0661748\n",
      "Validation loss decreased (0.060745 --> 0.060660).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0619132\n",
      "\tspeed: 0.0784s/iter; left time: 711.9369s\n",
      "\titers: 200, epoch: 60 | loss: 0.0588030\n",
      "\tspeed: 0.0418s/iter; left time: 375.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.0617652 Vali Loss: 0.0609231 Test Loss: 0.0663251\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0671052\n",
      "\tspeed: 0.0737s/iter; left time: 653.1122s\n",
      "\titers: 200, epoch: 61 | loss: 0.0605213\n",
      "\tspeed: 0.0418s/iter; left time: 366.5041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0618615 Vali Loss: 0.0607945 Test Loss: 0.0662515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0685258\n",
      "\tspeed: 0.0733s/iter; left time: 633.0677s\n",
      "\titers: 200, epoch: 62 | loss: 0.0614418\n",
      "\tspeed: 0.0418s/iter; left time: 356.7789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0618146 Vali Loss: 0.0608335 Test Loss: 0.0661645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0615282\n",
      "\tspeed: 0.0735s/iter; left time: 618.0138s\n",
      "\titers: 200, epoch: 63 | loss: 0.0675343\n",
      "\tspeed: 0.0418s/iter; left time: 347.3839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0615781 Vali Loss: 0.0609407 Test Loss: 0.0662388\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0622861\n",
      "\tspeed: 0.0735s/iter; left time: 601.8691s\n",
      "\titers: 200, epoch: 64 | loss: 0.0584475\n",
      "\tspeed: 0.0418s/iter; left time: 338.1138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0618433 Vali Loss: 0.0607368 Test Loss: 0.0663676\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0620696\n",
      "\tspeed: 0.0732s/iter; left time: 582.8604s\n",
      "\titers: 200, epoch: 65 | loss: 0.0628217\n",
      "\tspeed: 0.0417s/iter; left time: 328.3099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0620804 Vali Loss: 0.0609739 Test Loss: 0.0663319\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0598481\n",
      "\tspeed: 0.0731s/iter; left time: 565.7042s\n",
      "\titers: 200, epoch: 66 | loss: 0.0582869\n",
      "\tspeed: 0.0417s/iter; left time: 318.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0618415 Vali Loss: 0.0609449 Test Loss: 0.0662617\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0634116\n",
      "\tspeed: 0.0733s/iter; left time: 550.9956s\n",
      "\titers: 200, epoch: 67 | loss: 0.0627104\n",
      "\tspeed: 0.0418s/iter; left time: 309.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 224 | Train Loss: 0.0616766 Vali Loss: 0.0609148 Test Loss: 0.0662733\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0618952\n",
      "\tspeed: 0.0734s/iter; left time: 535.3842s\n",
      "\titers: 200, epoch: 68 | loss: 0.0553651\n",
      "\tspeed: 0.0417s/iter; left time: 300.2581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0617927 Vali Loss: 0.0608640 Test Loss: 0.0661779\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0594267\n",
      "\tspeed: 0.0731s/iter; left time: 516.8538s\n",
      "\titers: 200, epoch: 69 | loss: 0.0601975\n",
      "\tspeed: 0.0417s/iter; left time: 290.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0618049 Vali Loss: 0.0608008 Test Loss: 0.0660916\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011820029467344284, rmse:0.10871995985507965, mae:0.06617479771375656, rse:0.41079920530319214\n",
      "Intermediate time for IT and pred_len 24: 00h:40m:42.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3033874\n",
      "\tspeed: 0.0610s/iter; left time: 1359.7773s\n",
      "\titers: 200, epoch: 1 | loss: 0.2777488\n",
      "\tspeed: 0.0420s/iter; left time: 931.9935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.3122951 Vali Loss: 0.2118877 Test Loss: 0.2145622\n",
      "Validation loss decreased (inf --> 0.211888).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1579943\n",
      "\tspeed: 0.0790s/iter; left time: 1742.9812s\n",
      "\titers: 200, epoch: 2 | loss: 0.1231459\n",
      "\tspeed: 0.0420s/iter; left time: 922.6514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.1701643 Vali Loss: 0.1097780 Test Loss: 0.1166455\n",
      "Validation loss decreased (0.211888 --> 0.109778).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1148010\n",
      "\tspeed: 0.0942s/iter; left time: 2058.4955s\n",
      "\titers: 200, epoch: 3 | loss: 0.1127268\n",
      "\tspeed: 0.0420s/iter; left time: 913.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1168379 Vali Loss: 0.1037746 Test Loss: 0.1128726\n",
      "Validation loss decreased (0.109778 --> 0.103775).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1036756\n",
      "\tspeed: 0.0762s/iter; left time: 1648.1353s\n",
      "\titers: 200, epoch: 4 | loss: 0.0969169\n",
      "\tspeed: 0.0420s/iter; left time: 904.4038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.1032846 Vali Loss: 0.0953781 Test Loss: 0.1029985\n",
      "Validation loss decreased (0.103775 --> 0.095378).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0978223\n",
      "\tspeed: 0.0761s/iter; left time: 1628.7710s\n",
      "\titers: 200, epoch: 5 | loss: 0.0952708\n",
      "\tspeed: 0.0420s/iter; left time: 894.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0970201 Vali Loss: 0.0920589 Test Loss: 0.0990828\n",
      "Validation loss decreased (0.095378 --> 0.092059).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897622\n",
      "\tspeed: 0.0769s/iter; left time: 1628.2952s\n",
      "\titers: 200, epoch: 6 | loss: 0.0940132\n",
      "\tspeed: 0.0420s/iter; left time: 885.0715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0930080 Vali Loss: 0.0919379 Test Loss: 0.0997749\n",
      "Validation loss decreased (0.092059 --> 0.091938).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891138\n",
      "\tspeed: 0.0762s/iter; left time: 1597.7183s\n",
      "\titers: 200, epoch: 7 | loss: 0.0909407\n",
      "\tspeed: 0.0420s/iter; left time: 875.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0907236 Vali Loss: 0.0870714 Test Loss: 0.0952341\n",
      "Validation loss decreased (0.091938 --> 0.087071).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0935186\n",
      "\tspeed: 0.0820s/iter; left time: 1700.9455s\n",
      "\titers: 200, epoch: 8 | loss: 0.0879851\n",
      "\tspeed: 0.0419s/iter; left time: 865.5441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 224 | Train Loss: 0.0885519 Vali Loss: 0.0874213 Test Loss: 0.0945482\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0823577\n",
      "\tspeed: 0.0847s/iter; left time: 1736.5153s\n",
      "\titers: 200, epoch: 9 | loss: 0.0868695\n",
      "\tspeed: 0.0424s/iter; left time: 864.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0879633 Vali Loss: 0.0871931 Test Loss: 0.0948530\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0888301\n",
      "\tspeed: 0.0830s/iter; left time: 1683.4373s\n",
      "\titers: 200, epoch: 10 | loss: 0.0811055\n",
      "\tspeed: 0.0420s/iter; left time: 848.6865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0872202 Vali Loss: 0.0837260 Test Loss: 0.0904906\n",
      "Validation loss decreased (0.087071 --> 0.083726).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0862022\n",
      "\tspeed: 0.0849s/iter; left time: 1702.3254s\n",
      "\titers: 200, epoch: 11 | loss: 0.0868671\n",
      "\tspeed: 0.0424s/iter; left time: 845.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0857327 Vali Loss: 0.0846165 Test Loss: 0.0916002\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0834118\n",
      "\tspeed: 0.0817s/iter; left time: 1620.0548s\n",
      "\titers: 200, epoch: 12 | loss: 0.0818707\n",
      "\tspeed: 0.0422s/iter; left time: 833.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 224 | Train Loss: 0.0850589 Vali Loss: 0.0828718 Test Loss: 0.0905823\n",
      "Validation loss decreased (0.083726 --> 0.082872).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0793066\n",
      "\tspeed: 0.0847s/iter; left time: 1661.0510s\n",
      "\titers: 200, epoch: 13 | loss: 0.0834324\n",
      "\tspeed: 0.0422s/iter; left time: 823.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0842972 Vali Loss: 0.0829470 Test Loss: 0.0898282\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0830043\n",
      "\tspeed: 0.0812s/iter; left time: 1574.1516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0798370\n",
      "\tspeed: 0.0424s/iter; left time: 818.7930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 224 | Train Loss: 0.0841319 Vali Loss: 0.0823089 Test Loss: 0.0888954\n",
      "Validation loss decreased (0.082872 --> 0.082309).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0833945\n",
      "\tspeed: 0.0829s/iter; left time: 1587.8818s\n",
      "\titers: 200, epoch: 15 | loss: 0.0819691\n",
      "\tspeed: 0.0422s/iter; left time: 804.1008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 224 | Train Loss: 0.0836172 Vali Loss: 0.0822908 Test Loss: 0.0896239\n",
      "Validation loss decreased (0.082309 --> 0.082291).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0821435\n",
      "\tspeed: 0.0839s/iter; left time: 1589.8537s\n",
      "\titers: 200, epoch: 16 | loss: 0.0831206\n",
      "\tspeed: 0.0422s/iter; left time: 795.4624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.98s\n",
      "Steps: 224 | Train Loss: 0.0830830 Vali Loss: 0.0820856 Test Loss: 0.0892529\n",
      "Validation loss decreased (0.082291 --> 0.082086).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0805000\n",
      "\tspeed: 0.0838s/iter; left time: 1567.7982s\n",
      "\titers: 200, epoch: 17 | loss: 0.0794616\n",
      "\tspeed: 0.0422s/iter; left time: 786.2925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.95s\n",
      "Steps: 224 | Train Loss: 0.0824271 Vali Loss: 0.0818703 Test Loss: 0.0883285\n",
      "Validation loss decreased (0.082086 --> 0.081870).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0838323\n",
      "\tspeed: 0.0832s/iter; left time: 1539.2125s\n",
      "\titers: 200, epoch: 18 | loss: 0.0842612\n",
      "\tspeed: 0.0421s/iter; left time: 774.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 224 | Train Loss: 0.0822711 Vali Loss: 0.0826126 Test Loss: 0.0891127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0804820\n",
      "\tspeed: 0.0828s/iter; left time: 1513.2811s\n",
      "\titers: 200, epoch: 19 | loss: 0.0865838\n",
      "\tspeed: 0.0419s/iter; left time: 760.7375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 224 | Train Loss: 0.0817427 Vali Loss: 0.0819513 Test Loss: 0.0888486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0768593\n",
      "\tspeed: 0.0817s/iter; left time: 1474.0946s\n",
      "\titers: 200, epoch: 20 | loss: 0.0776417\n",
      "\tspeed: 0.1032s/iter; left time: 1851.9574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:20.29s\n",
      "Steps: 224 | Train Loss: 0.0814718 Vali Loss: 0.0835181 Test Loss: 0.0903085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0786750\n",
      "\tspeed: 0.6873s/iter; left time: 12249.2282s\n",
      "\titers: 200, epoch: 21 | loss: 0.0840735\n",
      "\tspeed: 0.2063s/iter; left time: 3656.4734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:47.92s\n",
      "Steps: 224 | Train Loss: 0.0815539 Vali Loss: 0.0823129 Test Loss: 0.0889414\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0806076\n",
      "\tspeed: 0.6593s/iter; left time: 11602.1189s\n",
      "\titers: 200, epoch: 22 | loss: 0.0823731\n",
      "\tspeed: 0.2037s/iter; left time: 3564.4422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:47.63s\n",
      "Steps: 224 | Train Loss: 0.0812577 Vali Loss: 0.0810208 Test Loss: 0.0879357\n",
      "Validation loss decreased (0.081870 --> 0.081021).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0758791\n",
      "\tspeed: 0.6324s/iter; left time: 10986.1900s\n",
      "\titers: 200, epoch: 23 | loss: 0.0789187\n",
      "\tspeed: 0.1907s/iter; left time: 3293.2736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:43.98s\n",
      "Steps: 224 | Train Loss: 0.0806942 Vali Loss: 0.0817863 Test Loss: 0.0882221\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0814178\n",
      "\tspeed: 0.5915s/iter; left time: 10143.3215s\n",
      "\titers: 200, epoch: 24 | loss: 0.0777875\n",
      "\tspeed: 0.1856s/iter; left time: 3165.1134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:42.38s\n",
      "Steps: 224 | Train Loss: 0.0807592 Vali Loss: 0.0808705 Test Loss: 0.0874797\n",
      "Validation loss decreased (0.081021 --> 0.080870).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0798416\n",
      "\tspeed: 0.5075s/iter; left time: 8589.5295s\n",
      "\titers: 200, epoch: 25 | loss: 0.0825350\n",
      "\tspeed: 0.0466s/iter; left time: 784.8162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:23.17s\n",
      "Steps: 224 | Train Loss: 0.0808549 Vali Loss: 0.0815378 Test Loss: 0.0885549\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0841141\n",
      "\tspeed: 0.0761s/iter; left time: 1271.7090s\n",
      "\titers: 200, epoch: 26 | loss: 0.0793692\n",
      "\tspeed: 0.0420s/iter; left time: 696.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0806925 Vali Loss: 0.0806132 Test Loss: 0.0873098\n",
      "Validation loss decreased (0.080870 --> 0.080613).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0826468\n",
      "\tspeed: 0.0916s/iter; left time: 1509.1969s\n",
      "\titers: 200, epoch: 27 | loss: 0.0812661\n",
      "\tspeed: 0.0420s/iter; left time: 687.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 224 | Train Loss: 0.0804301 Vali Loss: 0.0811280 Test Loss: 0.0879107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0837244\n",
      "\tspeed: 0.0754s/iter; left time: 1225.9487s\n",
      "\titers: 200, epoch: 28 | loss: 0.0818750\n",
      "\tspeed: 0.0419s/iter; left time: 677.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 224 | Train Loss: 0.0802230 Vali Loss: 0.0805943 Test Loss: 0.0871057\n",
      "Validation loss decreased (0.080613 --> 0.080594).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0832478\n",
      "\tspeed: 0.0978s/iter; left time: 1566.9448s\n",
      "\titers: 200, epoch: 29 | loss: 0.0779603\n",
      "\tspeed: 0.0420s/iter; left time: 668.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0801523 Vali Loss: 0.0818863 Test Loss: 0.0885974\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0818147\n",
      "\tspeed: 0.0754s/iter; left time: 1191.0977s\n",
      "\titers: 200, epoch: 30 | loss: 0.0814996\n",
      "\tspeed: 0.0420s/iter; left time: 658.9139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0799691 Vali Loss: 0.0805403 Test Loss: 0.0874550\n",
      "Validation loss decreased (0.080594 --> 0.080540).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0807634\n",
      "\tspeed: 0.1114s/iter; left time: 1735.2873s\n",
      "\titers: 200, epoch: 31 | loss: 0.0794287\n",
      "\tspeed: 0.0420s/iter; left time: 649.7494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0797637 Vali Loss: 0.0804008 Test Loss: 0.0871221\n",
      "Validation loss decreased (0.080540 --> 0.080401).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0841223\n",
      "\tspeed: 0.0799s/iter; left time: 1226.6060s\n",
      "\titers: 200, epoch: 32 | loss: 0.0808743\n",
      "\tspeed: 0.0420s/iter; left time: 640.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0798307 Vali Loss: 0.0804842 Test Loss: 0.0872027\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0774307\n",
      "\tspeed: 0.0753s/iter; left time: 1140.2686s\n",
      "\titers: 200, epoch: 33 | loss: 0.0795123\n",
      "\tspeed: 0.0420s/iter; left time: 631.2194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0795720 Vali Loss: 0.0807000 Test Loss: 0.0877222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0760335\n",
      "\tspeed: 0.0761s/iter; left time: 1134.8360s\n",
      "\titers: 200, epoch: 34 | loss: 0.0800049\n",
      "\tspeed: 0.0420s/iter; left time: 622.4577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0794358 Vali Loss: 0.0804116 Test Loss: 0.0873153\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0791039\n",
      "\tspeed: 0.0760s/iter; left time: 1116.2542s\n",
      "\titers: 200, epoch: 35 | loss: 0.0817805\n",
      "\tspeed: 0.0420s/iter; left time: 612.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0795749 Vali Loss: 0.0802729 Test Loss: 0.0870454\n",
      "Validation loss decreased (0.080401 --> 0.080273).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0850670\n",
      "\tspeed: 0.0819s/iter; left time: 1184.9341s\n",
      "\titers: 200, epoch: 36 | loss: 0.0763640\n",
      "\tspeed: 0.0420s/iter; left time: 603.0978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0795413 Vali Loss: 0.0809100 Test Loss: 0.0880168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0804887\n",
      "\tspeed: 0.0758s/iter; left time: 1078.5048s\n",
      "\titers: 200, epoch: 37 | loss: 0.0833887\n",
      "\tspeed: 0.0420s/iter; left time: 593.1818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0793805 Vali Loss: 0.0811483 Test Loss: 0.0879123\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0797944\n",
      "\tspeed: 0.0755s/iter; left time: 1057.6256s\n",
      "\titers: 200, epoch: 38 | loss: 0.0816977\n",
      "\tspeed: 0.0420s/iter; left time: 584.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0793918 Vali Loss: 0.0806087 Test Loss: 0.0878156\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0842078\n",
      "\tspeed: 0.0753s/iter; left time: 1038.4215s\n",
      "\titers: 200, epoch: 39 | loss: 0.0785331\n",
      "\tspeed: 0.0492s/iter; left time: 673.0303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0792174 Vali Loss: 0.0806207 Test Loss: 0.0875706\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0787128\n",
      "\tspeed: 0.1285s/iter; left time: 1743.6822s\n",
      "\titers: 200, epoch: 40 | loss: 0.0828887\n",
      "\tspeed: 0.0420s/iter; left time: 565.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0791452 Vali Loss: 0.0806383 Test Loss: 0.0874881\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0793891\n",
      "\tspeed: 0.0816s/iter; left time: 1089.2634s\n",
      "\titers: 200, epoch: 41 | loss: 0.0807572\n",
      "\tspeed: 0.0420s/iter; left time: 555.9442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 224 | Train Loss: 0.0792993 Vali Loss: 0.0807004 Test Loss: 0.0877278\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0786184\n",
      "\tspeed: 0.0813s/iter; left time: 1065.8385s\n",
      "\titers: 200, epoch: 42 | loss: 0.0812269\n",
      "\tspeed: 0.0419s/iter; left time: 545.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 224 | Train Loss: 0.0792596 Vali Loss: 0.0805590 Test Loss: 0.0877936\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0784530\n",
      "\tspeed: 0.0799s/iter; left time: 1030.1429s\n",
      "\titers: 200, epoch: 43 | loss: 0.0763785\n",
      "\tspeed: 0.0419s/iter; left time: 536.6086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0792555 Vali Loss: 0.0805167 Test Loss: 0.0874984\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0762247\n",
      "\tspeed: 0.0814s/iter; left time: 1031.2180s\n",
      "\titers: 200, epoch: 44 | loss: 0.0777945\n",
      "\tspeed: 0.0420s/iter; left time: 527.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 224 | Train Loss: 0.0792330 Vali Loss: 0.0807736 Test Loss: 0.0877837\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0782107\n",
      "\tspeed: 0.0786s/iter; left time: 978.5929s\n",
      "\titers: 200, epoch: 45 | loss: 0.0799510\n",
      "\tspeed: 0.0419s/iter; left time: 517.7171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 224 | Train Loss: 0.0791709 Vali Loss: 0.0807043 Test Loss: 0.0878261\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019629549235105515, rmse:0.1401054859161377, mae:0.08704537153244019, rse:0.5297539830207825\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3090570\n",
      "\tspeed: 0.0438s/iter; left time: 977.7433s\n",
      "\titers: 200, epoch: 1 | loss: 0.2792575\n",
      "\tspeed: 0.0419s/iter; left time: 931.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.3135203 Vali Loss: 0.2085152 Test Loss: 0.2117713\n",
      "Validation loss decreased (inf --> 0.208515).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1643469\n",
      "\tspeed: 0.0762s/iter; left time: 1682.7137s\n",
      "\titers: 200, epoch: 2 | loss: 0.1319450\n",
      "\tspeed: 0.0420s/iter; left time: 923.1054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.1719351 Vali Loss: 0.1128838 Test Loss: 0.1208498\n",
      "Validation loss decreased (0.208515 --> 0.112884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1185897\n",
      "\tspeed: 0.0774s/iter; left time: 1691.8092s\n",
      "\titers: 200, epoch: 3 | loss: 0.1083731\n",
      "\tspeed: 0.0420s/iter; left time: 913.2028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.1162499 Vali Loss: 0.1030288 Test Loss: 0.1107394\n",
      "Validation loss decreased (0.112884 --> 0.103029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1020575\n",
      "\tspeed: 0.0761s/iter; left time: 1646.6038s\n",
      "\titers: 200, epoch: 4 | loss: 0.0988437\n",
      "\tspeed: 0.0420s/iter; left time: 903.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.1031529 Vali Loss: 0.0967370 Test Loss: 0.1040709\n",
      "Validation loss decreased (0.103029 --> 0.096737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0971257\n",
      "\tspeed: 0.0842s/iter; left time: 1802.8698s\n",
      "\titers: 200, epoch: 5 | loss: 0.0906017\n",
      "\tspeed: 0.0419s/iter; left time: 893.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0972423 Vali Loss: 0.0950984 Test Loss: 0.1030870\n",
      "Validation loss decreased (0.096737 --> 0.095098).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0919377\n",
      "\tspeed: 0.0778s/iter; left time: 1648.5153s\n",
      "\titers: 200, epoch: 6 | loss: 0.0906588\n",
      "\tspeed: 0.0419s/iter; left time: 883.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0942135 Vali Loss: 0.0907184 Test Loss: 0.0966009\n",
      "Validation loss decreased (0.095098 --> 0.090718).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0887761\n",
      "\tspeed: 0.0780s/iter; left time: 1634.9845s\n",
      "\titers: 200, epoch: 7 | loss: 0.0900030\n",
      "\tspeed: 0.0420s/iter; left time: 875.7505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0913509 Vali Loss: 0.0930781 Test Loss: 0.1004891\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0881057\n",
      "\tspeed: 0.0755s/iter; left time: 1565.2831s\n",
      "\titers: 200, epoch: 8 | loss: 0.0882010\n",
      "\tspeed: 0.0419s/iter; left time: 865.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0896948 Vali Loss: 0.0880174 Test Loss: 0.0948503\n",
      "Validation loss decreased (0.090718 --> 0.088017).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0893628\n",
      "\tspeed: 0.0764s/iter; left time: 1566.2718s\n",
      "\titers: 200, epoch: 9 | loss: 0.0870908\n",
      "\tspeed: 0.0420s/iter; left time: 857.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0882184 Vali Loss: 0.0863725 Test Loss: 0.0929327\n",
      "Validation loss decreased (0.088017 --> 0.086373).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0931022\n",
      "\tspeed: 0.0769s/iter; left time: 1559.2017s\n",
      "\titers: 200, epoch: 10 | loss: 0.0881774\n",
      "\tspeed: 0.0420s/iter; left time: 846.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0883281 Vali Loss: 0.0885273 Test Loss: 0.0955867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0911532\n",
      "\tspeed: 0.0757s/iter; left time: 1517.9777s\n",
      "\titers: 200, epoch: 11 | loss: 0.0837905\n",
      "\tspeed: 0.0420s/iter; left time: 838.1752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0869120 Vali Loss: 0.0861084 Test Loss: 0.0929381\n",
      "Validation loss decreased (0.086373 --> 0.086108).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0844133\n",
      "\tspeed: 0.0769s/iter; left time: 1524.6674s\n",
      "\titers: 200, epoch: 12 | loss: 0.0827353\n",
      "\tspeed: 0.0420s/iter; left time: 828.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.33s\n",
      "Steps: 224 | Train Loss: 0.0864352 Vali Loss: 0.0851455 Test Loss: 0.0914010\n",
      "Validation loss decreased (0.086108 --> 0.085145).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0835373\n",
      "\tspeed: 0.1243s/iter; left time: 2436.9981s\n",
      "\titers: 200, epoch: 13 | loss: 0.0849871\n",
      "\tspeed: 0.0419s/iter; left time: 817.5242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0850428 Vali Loss: 0.0848374 Test Loss: 0.0902159\n",
      "Validation loss decreased (0.085145 --> 0.084837).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0885543\n",
      "\tspeed: 0.0763s/iter; left time: 1479.7755s\n",
      "\titers: 200, epoch: 14 | loss: 0.0842042\n",
      "\tspeed: 0.0420s/iter; left time: 809.4010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0844533 Vali Loss: 0.0837008 Test Loss: 0.0895525\n",
      "Validation loss decreased (0.084837 --> 0.083701).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0831713\n",
      "\tspeed: 0.0776s/iter; left time: 1486.4493s\n",
      "\titers: 200, epoch: 15 | loss: 0.0819003\n",
      "\tspeed: 0.0419s/iter; left time: 799.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0841621 Vali Loss: 0.0840708 Test Loss: 0.0907441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0853118\n",
      "\tspeed: 0.0754s/iter; left time: 1428.6377s\n",
      "\titers: 200, epoch: 16 | loss: 0.0828740\n",
      "\tspeed: 0.0420s/iter; left time: 790.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0836715 Vali Loss: 0.0836548 Test Loss: 0.0891761\n",
      "Validation loss decreased (0.083701 --> 0.083655).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0811331\n",
      "\tspeed: 0.0784s/iter; left time: 1468.0354s\n",
      "\titers: 200, epoch: 17 | loss: 0.0853928\n",
      "\tspeed: 0.0419s/iter; left time: 780.3804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0840085 Vali Loss: 0.0842173 Test Loss: 0.0910272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0847173\n",
      "\tspeed: 0.0753s/iter; left time: 1392.7673s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812628\n",
      "\tspeed: 0.0419s/iter; left time: 771.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0830284 Vali Loss: 0.0836014 Test Loss: 0.0893349\n",
      "Validation loss decreased (0.083655 --> 0.083601).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0835484\n",
      "\tspeed: 0.1021s/iter; left time: 1866.0839s\n",
      "\titers: 200, epoch: 19 | loss: 0.0840662\n",
      "\tspeed: 0.0420s/iter; left time: 762.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 224 | Train Loss: 0.0826856 Vali Loss: 0.0842833 Test Loss: 0.0912348\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0822008\n",
      "\tspeed: 0.0752s/iter; left time: 1356.2868s\n",
      "\titers: 200, epoch: 20 | loss: 0.0792388\n",
      "\tspeed: 0.0419s/iter; left time: 752.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0823751 Vali Loss: 0.0834512 Test Loss: 0.0891977\n",
      "Validation loss decreased (0.083601 --> 0.083451).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0883453\n",
      "\tspeed: 0.0783s/iter; left time: 1394.7976s\n",
      "\titers: 200, epoch: 21 | loss: 0.0847178\n",
      "\tspeed: 0.0419s/iter; left time: 742.5765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0822310 Vali Loss: 0.0843993 Test Loss: 0.0912151\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0840654\n",
      "\tspeed: 0.0755s/iter; left time: 1328.9296s\n",
      "\titers: 200, epoch: 22 | loss: 0.0772431\n",
      "\tspeed: 0.0419s/iter; left time: 733.9099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0820229 Vali Loss: 0.0840294 Test Loss: 0.0907720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0830905\n",
      "\tspeed: 0.0754s/iter; left time: 1310.5559s\n",
      "\titers: 200, epoch: 23 | loss: 0.0835822\n",
      "\tspeed: 0.0420s/iter; left time: 724.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0817503 Vali Loss: 0.0825368 Test Loss: 0.0888381\n",
      "Validation loss decreased (0.083451 --> 0.082537).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0803106\n",
      "\tspeed: 0.0765s/iter; left time: 1312.0930s\n",
      "\titers: 200, epoch: 24 | loss: 0.0842318\n",
      "\tspeed: 0.0419s/iter; left time: 714.3577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 224 | Train Loss: 0.0814916 Vali Loss: 0.0826496 Test Loss: 0.0893006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0775431\n",
      "\tspeed: 0.0756s/iter; left time: 1278.8197s\n",
      "\titers: 200, epoch: 25 | loss: 0.0792991\n",
      "\tspeed: 0.0419s/iter; left time: 705.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0815112 Vali Loss: 0.0821019 Test Loss: 0.0882986\n",
      "Validation loss decreased (0.082537 --> 0.082102).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0772318\n",
      "\tspeed: 0.0763s/iter; left time: 1275.0740s\n",
      "\titers: 200, epoch: 26 | loss: 0.0832283\n",
      "\tspeed: 0.0419s/iter; left time: 695.5094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0816322 Vali Loss: 0.0841764 Test Loss: 0.0913790\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0849195\n",
      "\tspeed: 0.2158s/iter; left time: 3555.0123s\n",
      "\titers: 200, epoch: 27 | loss: 0.0835870\n",
      "\tspeed: 0.1848s/iter; left time: 3026.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:40.70s\n",
      "Steps: 224 | Train Loss: 0.0811418 Vali Loss: 0.0821694 Test Loss: 0.0886885\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0805119\n",
      "\tspeed: 0.3453s/iter; left time: 5612.5473s\n",
      "\titers: 200, epoch: 28 | loss: 0.0842224\n",
      "\tspeed: 0.1255s/iter; left time: 2027.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:29.33s\n",
      "Steps: 224 | Train Loss: 0.0814539 Vali Loss: 0.0840324 Test Loss: 0.0911599\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0784688\n",
      "\tspeed: 0.2804s/iter; left time: 4494.0482s\n",
      "\titers: 200, epoch: 29 | loss: 0.0777813\n",
      "\tspeed: 0.1262s/iter; left time: 2009.6920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:28.81s\n",
      "Steps: 224 | Train Loss: 0.0809979 Vali Loss: 0.0822212 Test Loss: 0.0889588\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0803840\n",
      "\tspeed: 0.3091s/iter; left time: 4885.1526s\n",
      "\titers: 200, epoch: 30 | loss: 0.0780515\n",
      "\tspeed: 0.1397s/iter; left time: 2194.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:32.41s\n",
      "Steps: 224 | Train Loss: 0.0808966 Vali Loss: 0.0819800 Test Loss: 0.0887210\n",
      "Validation loss decreased (0.082102 --> 0.081980).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778789\n",
      "\tspeed: 0.3139s/iter; left time: 4890.8780s\n",
      "\titers: 200, epoch: 31 | loss: 0.0851455\n",
      "\tspeed: 0.1372s/iter; left time: 2124.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:32.28s\n",
      "Steps: 224 | Train Loss: 0.0814616 Vali Loss: 0.0836898 Test Loss: 0.0898621\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0776651\n",
      "\tspeed: 0.3003s/iter; left time: 4611.6447s\n",
      "\titers: 200, epoch: 32 | loss: 0.0783355\n",
      "\tspeed: 0.1394s/iter; left time: 2126.2426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:31.78s\n",
      "Steps: 224 | Train Loss: 0.0809511 Vali Loss: 0.0827436 Test Loss: 0.0890025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0782904\n",
      "\tspeed: 0.3058s/iter; left time: 4627.9325s\n",
      "\titers: 200, epoch: 33 | loss: 0.0776886\n",
      "\tspeed: 0.1384s/iter; left time: 2080.9846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 224 | Train Loss: 0.0807315 Vali Loss: 0.0834039 Test Loss: 0.0901810\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0806391\n",
      "\tspeed: 0.2853s/iter; left time: 4253.5541s\n",
      "\titers: 200, epoch: 34 | loss: 0.0798898\n",
      "\tspeed: 0.1348s/iter; left time: 1995.5708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:30.19s\n",
      "Steps: 224 | Train Loss: 0.0805491 Vali Loss: 0.0826289 Test Loss: 0.0894941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0788520\n",
      "\tspeed: 0.2933s/iter; left time: 4307.0606s\n",
      "\titers: 200, epoch: 35 | loss: 0.0811834\n",
      "\tspeed: 0.1287s/iter; left time: 1877.7981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:30.35s\n",
      "Steps: 224 | Train Loss: 0.0806915 Vali Loss: 0.0828573 Test Loss: 0.0898479\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0815910\n",
      "\tspeed: 0.2955s/iter; left time: 4272.9475s\n",
      "\titers: 200, epoch: 36 | loss: 0.0833699\n",
      "\tspeed: 0.1407s/iter; left time: 2020.8061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:31.61s\n",
      "Steps: 224 | Train Loss: 0.0805118 Vali Loss: 0.0827111 Test Loss: 0.0895883\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0810727\n",
      "\tspeed: 0.2927s/iter; left time: 4166.5412s\n",
      "\titers: 200, epoch: 37 | loss: 0.0772694\n",
      "\tspeed: 0.1409s/iter; left time: 1991.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 224 | Train Loss: 0.0804737 Vali Loss: 0.0822540 Test Loss: 0.0891069\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0820878\n",
      "\tspeed: 0.3000s/iter; left time: 4204.5454s\n",
      "\titers: 200, epoch: 38 | loss: 0.0789899\n",
      "\tspeed: 0.1342s/iter; left time: 1866.5968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:30.59s\n",
      "Steps: 224 | Train Loss: 0.0804687 Vali Loss: 0.0825305 Test Loss: 0.0893301\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0775217\n",
      "\tspeed: 0.2948s/iter; left time: 4065.1507s\n",
      "\titers: 200, epoch: 39 | loss: 0.0815636\n",
      "\tspeed: 0.1396s/iter; left time: 1911.4255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:31.78s\n",
      "Steps: 224 | Train Loss: 0.0803775 Vali Loss: 0.0827858 Test Loss: 0.0897900\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0841308\n",
      "\tspeed: 0.2972s/iter; left time: 4031.4224s\n",
      "\titers: 200, epoch: 40 | loss: 0.0843587\n",
      "\tspeed: 0.1402s/iter; left time: 1888.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:31.80s\n",
      "Steps: 224 | Train Loss: 0.0804021 Vali Loss: 0.0826596 Test Loss: 0.0894620\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020970260724425316, rmse:0.14481112360954285, mae:0.08872104436159134, rse:0.5475464463233948\n",
      "Intermediate time for IT and pred_len 96: 00h:30m:51.53s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3090603\n",
      "\tspeed: 0.1765s/iter; left time: 3919.2226s\n",
      "\titers: 200, epoch: 1 | loss: 0.2783697\n",
      "\tspeed: 0.1393s/iter; left time: 3079.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.80s\n",
      "Steps: 223 | Train Loss: 0.3160053 Vali Loss: 0.2090608 Test Loss: 0.2108025\n",
      "Validation loss decreased (inf --> 0.209061).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1526921\n",
      "\tspeed: 0.3074s/iter; left time: 6755.2132s\n",
      "\titers: 200, epoch: 2 | loss: 0.1254985\n",
      "\tspeed: 0.1432s/iter; left time: 3132.5283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.20s\n",
      "Steps: 223 | Train Loss: 0.1666672 Vali Loss: 0.1150013 Test Loss: 0.1222079\n",
      "Validation loss decreased (0.209061 --> 0.115001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156092\n",
      "\tspeed: 0.2993s/iter; left time: 6511.7552s\n",
      "\titers: 200, epoch: 3 | loss: 0.1111682\n",
      "\tspeed: 0.1471s/iter; left time: 3185.0023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.27s\n",
      "Steps: 223 | Train Loss: 0.1144641 Vali Loss: 0.1052501 Test Loss: 0.1140268\n",
      "Validation loss decreased (0.115001 --> 0.105250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1058354\n",
      "\tspeed: 0.2957s/iter; left time: 6367.2891s\n",
      "\titers: 200, epoch: 4 | loss: 0.1020715\n",
      "\tspeed: 0.1432s/iter; left time: 3069.9057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.83s\n",
      "Steps: 223 | Train Loss: 0.1049203 Vali Loss: 0.1045048 Test Loss: 0.1132254\n",
      "Validation loss decreased (0.105250 --> 0.104505).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0978590\n",
      "\tspeed: 0.3018s/iter; left time: 6431.8555s\n",
      "\titers: 200, epoch: 5 | loss: 0.0977052\n",
      "\tspeed: 0.1417s/iter; left time: 3005.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.62s\n",
      "Steps: 223 | Train Loss: 0.0998697 Vali Loss: 0.0966925 Test Loss: 0.1042047\n",
      "Validation loss decreased (0.104505 --> 0.096692).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0939743\n",
      "\tspeed: 0.3050s/iter; left time: 6432.0673s\n",
      "\titers: 200, epoch: 6 | loss: 0.0930459\n",
      "\tspeed: 0.1448s/iter; left time: 3038.1597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.38s\n",
      "Steps: 223 | Train Loss: 0.0967864 Vali Loss: 0.0923649 Test Loss: 0.0991602\n",
      "Validation loss decreased (0.096692 --> 0.092365).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0945567\n",
      "\tspeed: 0.3043s/iter; left time: 6347.8119s\n",
      "\titers: 200, epoch: 7 | loss: 0.0900540\n",
      "\tspeed: 0.1421s/iter; left time: 2949.4971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.55s\n",
      "Steps: 223 | Train Loss: 0.0954707 Vali Loss: 0.0912829 Test Loss: 0.0986720\n",
      "Validation loss decreased (0.092365 --> 0.091283).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0975327\n",
      "\tspeed: 0.3086s/iter; left time: 6369.1851s\n",
      "\titers: 200, epoch: 8 | loss: 0.0927937\n",
      "\tspeed: 0.1412s/iter; left time: 2899.5666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.18s\n",
      "Steps: 223 | Train Loss: 0.0924523 Vali Loss: 0.0895004 Test Loss: 0.0964793\n",
      "Validation loss decreased (0.091283 --> 0.089500).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0922139\n",
      "\tspeed: 0.2962s/iter; left time: 6047.4214s\n",
      "\titers: 200, epoch: 9 | loss: 0.0897620\n",
      "\tspeed: 0.1325s/iter; left time: 2691.5334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:30.28s\n",
      "Steps: 223 | Train Loss: 0.0920468 Vali Loss: 0.0912078 Test Loss: 0.0980457\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0865797\n",
      "\tspeed: 0.2998s/iter; left time: 6055.0728s\n",
      "\titers: 200, epoch: 10 | loss: 0.0885145\n",
      "\tspeed: 0.1391s/iter; left time: 2794.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 223 | Train Loss: 0.0907396 Vali Loss: 0.0885022 Test Loss: 0.0958225\n",
      "Validation loss decreased (0.089500 --> 0.088502).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0893342\n",
      "\tspeed: 0.2955s/iter; left time: 5901.1467s\n",
      "\titers: 200, epoch: 11 | loss: 0.0962399\n",
      "\tspeed: 0.1331s/iter; left time: 2644.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:30.96s\n",
      "Steps: 223 | Train Loss: 0.0898600 Vali Loss: 0.0923510 Test Loss: 0.0983299\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0904688\n",
      "\tspeed: 0.2970s/iter; left time: 5866.1370s\n",
      "\titers: 200, epoch: 12 | loss: 0.0899063\n",
      "\tspeed: 0.1381s/iter; left time: 2712.7683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.29s\n",
      "Steps: 223 | Train Loss: 0.0897455 Vali Loss: 0.0915725 Test Loss: 0.0984831\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0887031\n",
      "\tspeed: 0.2946s/iter; left time: 5751.5882s\n",
      "\titers: 200, epoch: 13 | loss: 0.0880902\n",
      "\tspeed: 0.1417s/iter; left time: 2751.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.89s\n",
      "Steps: 223 | Train Loss: 0.0887913 Vali Loss: 0.0929795 Test Loss: 0.0996968\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0867643\n",
      "\tspeed: 0.3105s/iter; left time: 5992.4697s\n",
      "\titers: 200, epoch: 14 | loss: 0.0880158\n",
      "\tspeed: 0.1328s/iter; left time: 2549.4142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:30.69s\n",
      "Steps: 223 | Train Loss: 0.0879361 Vali Loss: 0.0911428 Test Loss: 0.0980461\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0888512\n",
      "\tspeed: 0.2978s/iter; left time: 5681.1235s\n",
      "\titers: 200, epoch: 15 | loss: 0.0903949\n",
      "\tspeed: 0.1428s/iter; left time: 2710.5693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.95s\n",
      "Steps: 223 | Train Loss: 0.0878312 Vali Loss: 0.0881839 Test Loss: 0.0943494\n",
      "Validation loss decreased (0.088502 --> 0.088184).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0880147\n",
      "\tspeed: 0.3050s/iter; left time: 5750.4032s\n",
      "\titers: 200, epoch: 16 | loss: 0.0909810\n",
      "\tspeed: 0.1417s/iter; left time: 2656.9203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:32.12s\n",
      "Steps: 223 | Train Loss: 0.0883053 Vali Loss: 0.0924598 Test Loss: 0.0993620\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0843160\n",
      "\tspeed: 0.2980s/iter; left time: 5553.5030s\n",
      "\titers: 200, epoch: 17 | loss: 0.0836008\n",
      "\tspeed: 0.1354s/iter; left time: 2509.8260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:30.82s\n",
      "Steps: 223 | Train Loss: 0.0880031 Vali Loss: 0.0881283 Test Loss: 0.0945172\n",
      "Validation loss decreased (0.088184 --> 0.088128).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0833773\n",
      "\tspeed: 0.2995s/iter; left time: 5514.3010s\n",
      "\titers: 200, epoch: 18 | loss: 0.0820165\n",
      "\tspeed: 0.1396s/iter; left time: 2555.8418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.81s\n",
      "Steps: 223 | Train Loss: 0.0865549 Vali Loss: 0.0880355 Test Loss: 0.0939667\n",
      "Validation loss decreased (0.088128 --> 0.088035).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0850477\n",
      "\tspeed: 0.2929s/iter; left time: 5326.2439s\n",
      "\titers: 200, epoch: 19 | loss: 0.0832367\n",
      "\tspeed: 0.1387s/iter; left time: 2508.0211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.33s\n",
      "Steps: 223 | Train Loss: 0.0861331 Vali Loss: 0.0890603 Test Loss: 0.0954525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0846910\n",
      "\tspeed: 0.2888s/iter; left time: 5188.5053s\n",
      "\titers: 200, epoch: 20 | loss: 0.0835269\n",
      "\tspeed: 0.1464s/iter; left time: 2615.6300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:31.90s\n",
      "Steps: 223 | Train Loss: 0.0858045 Vali Loss: 0.0876941 Test Loss: 0.0943628\n",
      "Validation loss decreased (0.088035 --> 0.087694).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0869538\n",
      "\tspeed: 0.2983s/iter; left time: 5291.4584s\n",
      "\titers: 200, epoch: 21 | loss: 0.0862980\n",
      "\tspeed: 0.1420s/iter; left time: 2504.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 223 | Train Loss: 0.0858076 Vali Loss: 0.0899610 Test Loss: 0.0959305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0856543\n",
      "\tspeed: 0.2954s/iter; left time: 5175.4897s\n",
      "\titers: 200, epoch: 22 | loss: 0.0816218\n",
      "\tspeed: 0.1362s/iter; left time: 2372.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:30.60s\n",
      "Steps: 223 | Train Loss: 0.0856021 Vali Loss: 0.0881165 Test Loss: 0.0942591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0840538\n",
      "\tspeed: 0.2978s/iter; left time: 5150.8571s\n",
      "\titers: 200, epoch: 23 | loss: 0.0824600\n",
      "\tspeed: 0.1326s/iter; left time: 2279.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:30.42s\n",
      "Steps: 223 | Train Loss: 0.0851822 Vali Loss: 0.0870054 Test Loss: 0.0930882\n",
      "Validation loss decreased (0.087694 --> 0.087005).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0843242\n",
      "\tspeed: 0.2797s/iter; left time: 4774.6216s\n",
      "\titers: 200, epoch: 24 | loss: 0.0829674\n",
      "\tspeed: 0.1326s/iter; left time: 2249.8061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:29.85s\n",
      "Steps: 223 | Train Loss: 0.0848958 Vali Loss: 0.0875537 Test Loss: 0.0937990\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0849497\n",
      "\tspeed: 0.2844s/iter; left time: 4791.9560s\n",
      "\titers: 200, epoch: 25 | loss: 0.0863091\n",
      "\tspeed: 0.1270s/iter; left time: 2126.4429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:29.30s\n",
      "Steps: 223 | Train Loss: 0.0849637 Vali Loss: 0.0868416 Test Loss: 0.0925735\n",
      "Validation loss decreased (0.087005 --> 0.086842).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0866634\n",
      "\tspeed: 0.2963s/iter; left time: 4926.7187s\n",
      "\titers: 200, epoch: 26 | loss: 0.0829534\n",
      "\tspeed: 0.1323s/iter; left time: 2185.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:29.98s\n",
      "Steps: 223 | Train Loss: 0.0845835 Vali Loss: 0.0870112 Test Loss: 0.0926165\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0881318\n",
      "\tspeed: 0.2795s/iter; left time: 4584.6099s\n",
      "\titers: 200, epoch: 27 | loss: 0.0877667\n",
      "\tspeed: 0.1331s/iter; left time: 2169.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:29.52s\n",
      "Steps: 223 | Train Loss: 0.0846803 Vali Loss: 0.0885832 Test Loss: 0.0947686\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0828443\n",
      "\tspeed: 0.2903s/iter; left time: 4696.9130s\n",
      "\titers: 200, epoch: 28 | loss: 0.0830530\n",
      "\tspeed: 0.1351s/iter; left time: 2171.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:30.14s\n",
      "Steps: 223 | Train Loss: 0.0842606 Vali Loss: 0.0870710 Test Loss: 0.0931308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0840472\n",
      "\tspeed: 0.2936s/iter; left time: 4684.8425s\n",
      "\titers: 200, epoch: 29 | loss: 0.0838416\n",
      "\tspeed: 0.1259s/iter; left time: 1996.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:29.23s\n",
      "Steps: 223 | Train Loss: 0.0842970 Vali Loss: 0.0887125 Test Loss: 0.0948914\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0843665\n",
      "\tspeed: 0.2810s/iter; left time: 4421.8531s\n",
      "\titers: 200, epoch: 30 | loss: 0.0879552\n",
      "\tspeed: 0.1337s/iter; left time: 2090.5600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:29.55s\n",
      "Steps: 223 | Train Loss: 0.0842581 Vali Loss: 0.0875452 Test Loss: 0.0935176\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0831420\n",
      "\tspeed: 0.2903s/iter; left time: 4502.6822s\n",
      "\titers: 200, epoch: 31 | loss: 0.0829317\n",
      "\tspeed: 0.1379s/iter; left time: 2124.4839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:30.63s\n",
      "Steps: 223 | Train Loss: 0.0841736 Vali Loss: 0.0870453 Test Loss: 0.0927685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0846684\n",
      "\tspeed: 0.2760s/iter; left time: 4219.5825s\n",
      "\titers: 200, epoch: 32 | loss: 0.0862432\n",
      "\tspeed: 0.1238s/iter; left time: 1880.3040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 223 | Train Loss: 0.0839742 Vali Loss: 0.0874853 Test Loss: 0.0932041\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0841518\n",
      "\tspeed: 0.2766s/iter; left time: 4167.2877s\n",
      "\titers: 200, epoch: 33 | loss: 0.0839738\n",
      "\tspeed: 0.1288s/iter; left time: 1928.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:29.13s\n",
      "Steps: 223 | Train Loss: 0.0838999 Vali Loss: 0.0878902 Test Loss: 0.0941452\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0853512\n",
      "\tspeed: 0.2771s/iter; left time: 4112.1793s\n",
      "\titers: 200, epoch: 34 | loss: 0.0823654\n",
      "\tspeed: 0.1289s/iter; left time: 1900.4105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:29.36s\n",
      "Steps: 223 | Train Loss: 0.0838370 Vali Loss: 0.0877326 Test Loss: 0.0937572\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0837178\n",
      "\tspeed: 0.2778s/iter; left time: 4061.2672s\n",
      "\titers: 200, epoch: 35 | loss: 0.0856247\n",
      "\tspeed: 0.1244s/iter; left time: 1806.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:28.78s\n",
      "Steps: 223 | Train Loss: 0.0837407 Vali Loss: 0.0873936 Test Loss: 0.0935010\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021762898191809654, rmse:0.14752253890037537, mae:0.09257349371910095, rse:0.5583169460296631\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3124060\n",
      "\tspeed: 0.1428s/iter; left time: 3170.6618s\n",
      "\titers: 200, epoch: 1 | loss: 0.2816474\n",
      "\tspeed: 0.1345s/iter; left time: 2972.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.96s\n",
      "Steps: 223 | Train Loss: 0.3159779 Vali Loss: 0.2078168 Test Loss: 0.2107630\n",
      "Validation loss decreased (inf --> 0.207817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1492635\n",
      "\tspeed: 0.2907s/iter; left time: 6388.6398s\n",
      "\titers: 200, epoch: 2 | loss: 0.1309185\n",
      "\tspeed: 0.1275s/iter; left time: 2789.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.40s\n",
      "Steps: 223 | Train Loss: 0.1663718 Vali Loss: 0.1147883 Test Loss: 0.1231182\n",
      "Validation loss decreased (0.207817 --> 0.114788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1142819\n",
      "\tspeed: 0.2959s/iter; left time: 6436.5660s\n",
      "\titers: 200, epoch: 3 | loss: 0.1069315\n",
      "\tspeed: 0.1343s/iter; left time: 2908.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.34s\n",
      "Steps: 223 | Train Loss: 0.1154346 Vali Loss: 0.1037279 Test Loss: 0.1134890\n",
      "Validation loss decreased (0.114788 --> 0.103728).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1056129\n",
      "\tspeed: 0.2956s/iter; left time: 6363.9431s\n",
      "\titers: 200, epoch: 4 | loss: 0.1035643\n",
      "\tspeed: 0.1274s/iter; left time: 2731.4702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.69s\n",
      "Steps: 223 | Train Loss: 0.1034678 Vali Loss: 0.1007274 Test Loss: 0.1069765\n",
      "Validation loss decreased (0.103728 --> 0.100727).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0978519\n",
      "\tspeed: 0.2958s/iter; left time: 6302.3923s\n",
      "\titers: 200, epoch: 5 | loss: 0.0992856\n",
      "\tspeed: 0.1332s/iter; left time: 2825.3524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.37s\n",
      "Steps: 223 | Train Loss: 0.0987640 Vali Loss: 0.0959482 Test Loss: 0.1017942\n",
      "Validation loss decreased (0.100727 --> 0.095948).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0952063\n",
      "\tspeed: 0.2835s/iter; left time: 5977.3564s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931887\n",
      "\tspeed: 0.1316s/iter; left time: 2761.7718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.66s\n",
      "Steps: 223 | Train Loss: 0.0961461 Vali Loss: 0.0948464 Test Loss: 0.1009750\n",
      "Validation loss decreased (0.095948 --> 0.094846).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0909539\n",
      "\tspeed: 0.2835s/iter; left time: 5914.3243s\n",
      "\titers: 200, epoch: 7 | loss: 0.0949086\n",
      "\tspeed: 0.1349s/iter; left time: 2801.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.26s\n",
      "Steps: 223 | Train Loss: 0.0945210 Vali Loss: 0.0915820 Test Loss: 0.0972508\n",
      "Validation loss decreased (0.094846 --> 0.091582).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0915987\n",
      "\tspeed: 0.2940s/iter; left time: 6068.9702s\n",
      "\titers: 200, epoch: 8 | loss: 0.0903535\n",
      "\tspeed: 0.1320s/iter; left time: 2711.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.65s\n",
      "Steps: 223 | Train Loss: 0.0924912 Vali Loss: 0.0898781 Test Loss: 0.0962457\n",
      "Validation loss decreased (0.091582 --> 0.089878).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0911546\n",
      "\tspeed: 0.2915s/iter; left time: 5951.9265s\n",
      "\titers: 200, epoch: 9 | loss: 0.0927263\n",
      "\tspeed: 0.1358s/iter; left time: 2758.9585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:30.31s\n",
      "Steps: 223 | Train Loss: 0.0915381 Vali Loss: 0.0916647 Test Loss: 0.0981733\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0968438\n",
      "\tspeed: 0.2838s/iter; left time: 5730.2991s\n",
      "\titers: 200, epoch: 10 | loss: 0.0894129\n",
      "\tspeed: 0.1353s/iter; left time: 2718.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.96s\n",
      "Steps: 223 | Train Loss: 0.0906432 Vali Loss: 0.0897433 Test Loss: 0.0960415\n",
      "Validation loss decreased (0.089878 --> 0.089743).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0897145\n",
      "\tspeed: 0.2940s/iter; left time: 5870.6865s\n",
      "\titers: 200, epoch: 11 | loss: 0.0929175\n",
      "\tspeed: 0.1361s/iter; left time: 2705.2051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:30.16s\n",
      "Steps: 223 | Train Loss: 0.0899008 Vali Loss: 0.0917099 Test Loss: 0.0985339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0906454\n",
      "\tspeed: 0.2887s/iter; left time: 5700.8697s\n",
      "\titers: 200, epoch: 12 | loss: 0.0869474\n",
      "\tspeed: 0.1360s/iter; left time: 2671.2265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:30.38s\n",
      "Steps: 223 | Train Loss: 0.0892581 Vali Loss: 0.0874877 Test Loss: 0.0941771\n",
      "Validation loss decreased (0.089743 --> 0.087488).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0873292\n",
      "\tspeed: 0.2921s/iter; left time: 5702.6324s\n",
      "\titers: 200, epoch: 13 | loss: 0.0926962\n",
      "\tspeed: 0.1349s/iter; left time: 2619.5545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.83s\n",
      "Steps: 223 | Train Loss: 0.0887239 Vali Loss: 0.0876333 Test Loss: 0.0935583\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0858689\n",
      "\tspeed: 0.3000s/iter; left time: 5791.0556s\n",
      "\titers: 200, epoch: 14 | loss: 0.0868087\n",
      "\tspeed: 0.1365s/iter; left time: 2621.1753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:30.88s\n",
      "Steps: 223 | Train Loss: 0.0878602 Vali Loss: 0.0875576 Test Loss: 0.0934865\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0878929\n",
      "\tspeed: 0.3066s/iter; left time: 5848.9621s\n",
      "\titers: 200, epoch: 15 | loss: 0.0877452\n",
      "\tspeed: 0.1369s/iter; left time: 2598.5176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.26s\n",
      "Steps: 223 | Train Loss: 0.0871861 Vali Loss: 0.0870064 Test Loss: 0.0941509\n",
      "Validation loss decreased (0.087488 --> 0.087006).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0849537\n",
      "\tspeed: 0.3151s/iter; left time: 5940.7043s\n",
      "\titers: 200, epoch: 16 | loss: 0.0838782\n",
      "\tspeed: 0.1442s/iter; left time: 2705.4735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:32.61s\n",
      "Steps: 223 | Train Loss: 0.0868628 Vali Loss: 0.0875531 Test Loss: 0.0938154\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0862761\n",
      "\tspeed: 0.3137s/iter; left time: 5845.8825s\n",
      "\titers: 200, epoch: 17 | loss: 0.0887492\n",
      "\tspeed: 0.1379s/iter; left time: 2555.8458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.64s\n",
      "Steps: 223 | Train Loss: 0.0865727 Vali Loss: 0.0867154 Test Loss: 0.0934756\n",
      "Validation loss decreased (0.087006 --> 0.086715).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0863073\n",
      "\tspeed: 0.3086s/iter; left time: 5681.9043s\n",
      "\titers: 200, epoch: 18 | loss: 0.0865732\n",
      "\tspeed: 0.1376s/iter; left time: 2520.0600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 223 | Train Loss: 0.0861008 Vali Loss: 0.0881334 Test Loss: 0.0949035\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0855111\n",
      "\tspeed: 0.3025s/iter; left time: 5501.7634s\n",
      "\titers: 200, epoch: 19 | loss: 0.0831657\n",
      "\tspeed: 0.1364s/iter; left time: 2467.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:30.94s\n",
      "Steps: 223 | Train Loss: 0.0862969 Vali Loss: 0.0881205 Test Loss: 0.0946031\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0866475\n",
      "\tspeed: 0.2964s/iter; left time: 5325.1127s\n",
      "\titers: 200, epoch: 20 | loss: 0.0843303\n",
      "\tspeed: 0.1328s/iter; left time: 2372.9126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:30.29s\n",
      "Steps: 223 | Train Loss: 0.0857847 Vali Loss: 0.0870916 Test Loss: 0.0939039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0890283\n",
      "\tspeed: 0.2977s/iter; left time: 5281.9670s\n",
      "\titers: 200, epoch: 21 | loss: 0.0849071\n",
      "\tspeed: 0.1396s/iter; left time: 2462.0319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:31.00s\n",
      "Steps: 223 | Train Loss: 0.0863172 Vali Loss: 0.0869943 Test Loss: 0.0934484\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0852840\n",
      "\tspeed: 0.2935s/iter; left time: 5140.7951s\n",
      "\titers: 200, epoch: 22 | loss: 0.0885105\n",
      "\tspeed: 0.1297s/iter; left time: 2259.3607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:29.99s\n",
      "Steps: 223 | Train Loss: 0.0855531 Vali Loss: 0.0869336 Test Loss: 0.0933120\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0879844\n",
      "\tspeed: 0.2853s/iter; left time: 4934.1597s\n",
      "\titers: 200, epoch: 23 | loss: 0.0855408\n",
      "\tspeed: 0.1367s/iter; left time: 2350.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:30.05s\n",
      "Steps: 223 | Train Loss: 0.0852261 Vali Loss: 0.0879142 Test Loss: 0.0944752\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0812746\n",
      "\tspeed: 0.2867s/iter; left time: 4894.4954s\n",
      "\titers: 200, epoch: 24 | loss: 0.0863697\n",
      "\tspeed: 0.1365s/iter; left time: 2316.2467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:30.86s\n",
      "Steps: 223 | Train Loss: 0.0849814 Vali Loss: 0.0865731 Test Loss: 0.0926893\n",
      "Validation loss decreased (0.086715 --> 0.086573).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0848241\n",
      "\tspeed: 0.2889s/iter; left time: 4868.0863s\n",
      "\titers: 200, epoch: 25 | loss: 0.0844347\n",
      "\tspeed: 0.1341s/iter; left time: 2245.4585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:30.74s\n",
      "Steps: 223 | Train Loss: 0.0850466 Vali Loss: 0.0865710 Test Loss: 0.0929987\n",
      "Validation loss decreased (0.086573 --> 0.086571).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0855051\n",
      "\tspeed: 0.3052s/iter; left time: 5074.6395s\n",
      "\titers: 200, epoch: 26 | loss: 0.0863475\n",
      "\tspeed: 0.1299s/iter; left time: 2146.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:30.14s\n",
      "Steps: 223 | Train Loss: 0.0845380 Vali Loss: 0.0872452 Test Loss: 0.0941403\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0849269\n",
      "\tspeed: 0.3127s/iter; left time: 5128.9947s\n",
      "\titers: 200, epoch: 27 | loss: 0.0826865\n",
      "\tspeed: 0.1404s/iter; left time: 2289.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:31.92s\n"
     ]
    }
   ],
   "source": [
    "patchtst_results = []\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition_no_revin.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patchtst_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpatchtst_results\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patchtst_results' is not defined"
     ]
    }
   ],
   "source": [
    "DE 24\n",
    "Scaled mse:0.022536464035511017, rmse:0.15012149512767792, mae:0.09444105625152588, rse:0.5297995209693909\n",
    "Scaled mse:0.022697528824210167, rmse:0.15065698325634003, mae:0.09552601724863052, rse:0.5316893458366394\n",
    "\n",
    "DE 96\n",
    "Scaled mse:0.042729347944259644, rmse:0.2067107856273651, mae:0.1354810893535614, rse:0.7320046424865723\n",
    "Scaled mse:0.04074832424521446, rmse:0.2018621414899826, mae:0.13381515443325043, rse:0.7148346304893494\n",
    "\n",
    "DE 168\n",
    "Scaled mse:0.04620388522744179, rmse:0.21495088934898376, mae:0.14425238966941833, rse:0.7613733410835266\n",
    "Scaled mse:0.045363716781139374, rmse:0.21298760175704956, mae:0.14199773967266083, rse:0.754419207572937\n",
    "\n",
    "GB 24\n",
    "Scaled mse:0.028249364346265793, rmse:0.16807547211647034, mae:0.10912777483463287, rse:0.57981276512146\n",
    "Scaled mse:0.028333809226751328, rmse:0.1683264970779419, mae:0.10940185934305191, rse:0.5806787014007568\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN + Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.0743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.0925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>0.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            -RevIN + Decomposition                 \n",
       "Metrics                              MSE    RMSE     MAE\n",
       "Country Pred_len                                        \n",
       "DE      24                        0.0217  0.1474  0.0912\n",
       "        96                        0.0407  0.2015  0.1325\n",
       "        168                       0.0425  0.2060  0.1390\n",
       "ES      24                        0.0158  0.1228  0.0743\n",
       "        96                        0.0291  0.1677  0.1059\n",
       "        168                       0.0314  0.1747  0.1126\n",
       "FR      24                        0.0111  0.1053  0.0598\n",
       "        96                        0.0215  0.1463  0.0856\n",
       "        168                       0.0243  0.1554  0.0925\n",
       "GB      24                        0.0266  0.1631  0.1045\n",
       "        96                        0.0489  0.2210  0.1490\n",
       "        168                       0.0518  0.2275  0.1552\n",
       "IT      24                        0.0108  0.1041  0.0611\n",
       "        96                        0.0190  0.1378  0.0836\n",
       "        168                       0.0206  0.1434  0.0886"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN + Decomposition '], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
